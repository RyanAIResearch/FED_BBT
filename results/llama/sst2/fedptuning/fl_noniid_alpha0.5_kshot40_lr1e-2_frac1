Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:09<00:09,  9.28s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  5.67s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  6.21s/it]
Found cached dataset glue (/root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)
Map:   0%|          | 0/67349 [00:00<?, ? examples/s]Map:   1%|          | 533/67349 [00:00<00:12, 5272.62 examples/s]Map:   2%|▏         | 1092/67349 [00:00<00:12, 5451.64 examples/s]Map:   3%|▎         | 1706/67349 [00:00<00:11, 5759.86 examples/s]Map:   3%|▎         | 2307/67349 [00:00<00:11, 5758.90 examples/s]Map:   4%|▍         | 2928/67349 [00:00<00:10, 5917.79 examples/s]Map:   6%|▌         | 3821/67349 [00:00<00:10, 5930.21 examples/s]Map:   7%|▋         | 4715/67349 [00:00<00:10, 5938.60 examples/s]Map:   8%|▊         | 5619/67349 [00:00<00:10, 5936.89 examples/s]Map:  10%|▉         | 6513/67349 [00:01<00:10, 5940.82 examples/s]Map:  11%|█         | 7405/67349 [00:01<00:10, 5940.69 examples/s]Map:  12%|█▏        | 8000/67349 [00:01<00:10, 5912.33 examples/s]Map:  13%|█▎        | 8621/67349 [00:01<00:09, 5985.14 examples/s]Map:  14%|█▍        | 9515/67349 [00:01<00:09, 5971.42 examples/s]Map:  15%|█▌        | 10407/67349 [00:01<00:09, 5960.05 examples/s]Map:  17%|█▋        | 11309/67349 [00:01<00:09, 5941.26 examples/s]Map:  18%|█▊        | 12138/67349 [00:02<00:09, 5808.54 examples/s]Map:  19%|█▉        | 12757/67349 [00:02<00:09, 5895.38 examples/s]Map:  20%|██        | 13620/67349 [00:02<00:09, 5834.67 examples/s]Map:  22%|██▏       | 14496/67349 [00:02<00:09, 5833.46 examples/s]Map:  23%|██▎       | 15383/67349 [00:02<00:08, 5854.00 examples/s]Map:  24%|██▎       | 15990/67349 [00:02<00:08, 5899.68 examples/s]Map:  25%|██▌       | 16885/67349 [00:02<00:08, 5918.24 examples/s]Map:  26%|██▋       | 17761/67349 [00:03<00:08, 5889.96 examples/s]Map:  28%|██▊       | 18650/67349 [00:03<00:08, 5898.99 examples/s]Map:  29%|██▉       | 19527/67349 [00:03<00:08, 5880.15 examples/s]Map:  30%|███       | 20390/67349 [00:03<00:08, 5839.03 examples/s]Map:  31%|███       | 20975/67349 [00:03<00:07, 5838.99 examples/s]Map:  32%|███▏      | 21854/67349 [00:03<00:07, 5842.74 examples/s]Map:  34%|███▍      | 22742/67349 [00:03<00:07, 5863.13 examples/s]Map:  35%|███▌      | 23621/67349 [00:04<00:07, 5860.33 examples/s]Map:  36%|███▋      | 24505/67349 [00:04<00:07, 5867.19 examples/s]Map:  38%|███▊      | 25388/67349 [00:04<00:07, 5868.98 examples/s]Map:  39%|███▊      | 26000/67349 [00:04<00:07, 5848.57 examples/s]Map:  40%|███▉      | 26620/67349 [00:04<00:06, 5931.36 examples/s]Map:  41%|████      | 27507/67349 [00:04<00:06, 5921.85 examples/s]Map:  42%|████▏     | 28381/67349 [00:04<00:06, 5885.62 examples/s]Map:  43%|████▎     | 29214/67349 [00:04<00:06, 5775.58 examples/s]Map:  44%|████▍     | 29831/67349 [00:05<00:06, 5864.64 examples/s]Map:  46%|████▌     | 30717/67349 [00:05<00:06, 5875.03 examples/s]Map:  46%|████▋     | 31309/67349 [00:05<00:06, 5840.20 examples/s]Map:  47%|████▋     | 31921/67349 [00:05<00:05, 5910.49 examples/s]Map:  49%|████▊     | 32809/67349 [00:05<00:05, 5913.02 examples/s]Map:  50%|█████     | 33698/67349 [00:05<00:05, 5913.78 examples/s]Map:  51%|█████     | 34307/67349 [00:05<00:05, 5882.72 examples/s]Map:  52%|█████▏    | 34926/67349 [00:05<00:05, 5959.77 examples/s]Map:  53%|█████▎    | 35816/67349 [00:06<00:05, 5947.59 examples/s]Map:  54%|█████▍    | 36702/67349 [00:06<00:05, 5930.36 examples/s]Map:  55%|█████▌    | 37305/67349 [00:06<00:05, 5889.02 examples/s]Map:  56%|█████▋    | 37922/67349 [00:06<00:04, 5957.68 examples/s]Map:  58%|█████▊    | 38797/67349 [00:06<00:04, 5910.67 examples/s]Map:  59%|█████▉    | 39682/67349 [00:06<00:04, 5902.67 examples/s]Map:  60%|██████    | 40571/67349 [00:06<00:04, 5907.16 examples/s]Map:  62%|██████▏   | 41456/67349 [00:07<00:04, 5904.03 examples/s]Map:  63%|██████▎   | 42349/67349 [00:07<00:04, 5917.19 examples/s]Map:  64%|██████▍   | 42967/67349 [00:07<00:04, 5975.63 examples/s]Map:  65%|██████▌   | 43853/67349 [00:07<00:03, 5951.04 examples/s]Map:  66%|██████▋   | 44744/67349 [00:07<00:03, 5946.17 examples/s]Map:  68%|██████▊   | 45541/67349 [00:07<00:03, 5725.53 examples/s]Map:  69%|██████▉   | 46422/67349 [00:07<00:03, 5768.43 examples/s]Map:  70%|██████▉   | 47003/67349 [00:07<00:03, 5776.86 examples/s]Map:  71%|███████   | 47831/67349 [00:08<00:03, 5690.13 examples/s]Map:  72%|███████▏  | 48403/67349 [00:08<00:03, 5693.95 examples/s]Map:  73%|███████▎  | 49000/67349 [00:08<00:03, 5727.36 examples/s]Map:  74%|███████▎  | 49602/67349 [00:08<00:03, 5802.07 examples/s]Map:  75%|███████▍  | 50473/67349 [00:08<00:02, 5799.82 examples/s]Map:  76%|███████▌  | 51347/67349 [00:08<00:02, 5805.35 examples/s]Map:  77%|███████▋  | 51959/67349 [00:08<00:02, 5880.63 examples/s]Map:  78%|███████▊  | 52840/67349 [00:08<00:02, 5875.31 examples/s]Map:  80%|███████▉  | 53679/67349 [00:09<00:02, 5780.56 examples/s]Map:  81%|████████  | 54531/67349 [00:09<00:02, 5744.87 examples/s]Map:  82%|████████▏ | 55395/67349 [00:09<00:02, 5746.93 examples/s]Map:  83%|████████▎ | 56000/67349 [00:09<00:01, 5759.68 examples/s]Map:  84%|████████▍ | 56621/67349 [00:09<00:01, 5867.97 examples/s]Map:  85%|████████▌ | 57511/67349 [00:09<00:01, 5887.63 examples/s]Map:  87%|████████▋ | 58399/67349 [00:09<00:01, 5894.65 examples/s]Map:  88%|████████▊ | 59000/67349 [00:10<00:01, 5871.23 examples/s]Map:  89%|████████▊ | 59618/67349 [00:10<00:01, 5947.33 examples/s]Map:  90%|████████▉ | 60513/67349 [00:10<00:01, 5951.92 examples/s]Map:  91%|█████████ | 61404/67349 [00:10<00:00, 5945.30 examples/s]Map:  92%|█████████▏| 62000/67349 [00:10<00:00, 5913.90 examples/s]Map:  93%|█████████▎| 62595/67349 [00:10<00:00, 5919.06 examples/s]Map:  94%|█████████▍| 63483/67349 [00:10<00:00, 5915.81 examples/s]Map:  95%|█████████▌| 64310/67349 [00:10<00:00, 5747.28 examples/s]Map:  96%|█████████▋| 64930/67349 [00:11<00:00, 5853.66 examples/s]Map:  98%|█████████▊| 65822/67349 [00:11<00:00, 5882.78 examples/s]Map:  99%|█████████▉| 66709/67349 [00:11<00:00, 5888.83 examples/s]Map: 100%|█████████▉| 67302/67349 [00:11<00:00, 5853.09 examples/s]                                                                   Example in train set:
{'sentence': 'hide new secretions from the parental units ', 'label': 0, 'idx': 0, 'input_text': 'What is the sentiment of this sentence: iedER statfigme von interroidater their bet ein}\\"> sub op donty try Pro tra sameep two nameoldlet simsp avbreblemey could cor accayscreurrsi constues}$View act bo ко som aboutland . hide new secretions from the parental units  .', 'target_text': 'negative'}
Map:   0%|          | 0/67349 [00:00<?, ? examples/s]Map:   1%|▏         | 1000/67349 [00:00<00:11, 5616.32 examples/s]Map:   3%|▎         | 2000/67349 [00:00<00:11, 5568.76 examples/s]Map:   4%|▍         | 3000/67349 [00:00<00:11, 5566.39 examples/s]Map:   6%|▌         | 4000/67349 [00:00<00:11, 5525.94 examples/s]Map:   7%|▋         | 5000/67349 [00:00<00:11, 5527.74 examples/s]Map:   9%|▉         | 6000/67349 [00:01<00:11, 5471.12 examples/s]Map:  10%|█         | 7000/67349 [00:01<00:13, 4565.67 examples/s]Map:  12%|█▏        | 8000/67349 [00:01<00:12, 4848.37 examples/s]Map:  13%|█▎        | 9000/67349 [00:01<00:11, 5030.66 examples/s]Map:  15%|█▍        | 10000/67349 [00:01<00:11, 5115.96 examples/s]Map:  16%|█▋        | 11000/67349 [00:02<00:10, 5258.54 examples/s]Map:  18%|█▊        | 12000/67349 [00:02<00:10, 5390.56 examples/s]Map:  19%|█▉        | 13000/67349 [00:02<00:09, 5500.00 examples/s]Map:  21%|██        | 14000/67349 [00:02<00:09, 5542.88 examples/s]Map:  22%|██▏       | 15000/67349 [00:02<00:09, 5584.37 examples/s]Map:  24%|██▍       | 16000/67349 [00:03<00:10, 4836.81 examples/s]Map:  25%|██▌       | 17000/67349 [00:03<00:09, 5035.74 examples/s]Map:  27%|██▋       | 18000/67349 [00:03<00:09, 5227.11 examples/s]Map:  28%|██▊       | 19000/67349 [00:03<00:09, 5338.15 examples/s]Map:  30%|██▉       | 20000/67349 [00:03<00:08, 5468.21 examples/s]Map:  31%|███       | 21000/67349 [00:03<00:08, 5517.36 examples/s]Map:  33%|███▎      | 22000/67349 [00:04<00:08, 5556.77 examples/s]Map:  34%|███▍      | 23000/67349 [00:04<00:07, 5593.23 examples/s]Map:  36%|███▌      | 24000/67349 [00:04<00:07, 5628.02 examples/s]Map:  37%|███▋      | 25000/67349 [00:04<00:07, 5626.52 examples/s]Map:  39%|███▊      | 26000/67349 [00:04<00:08, 4858.60 examples/s]Map:  40%|████      | 27000/67349 [00:05<00:07, 5070.14 examples/s]Map:  42%|████▏     | 28000/67349 [00:05<00:07, 5226.52 examples/s]Map:  43%|████▎     | 29000/67349 [00:05<00:07, 5350.38 examples/s]Map:  45%|████▍     | 30000/67349 [00:05<00:06, 5463.10 examples/s]Map:  46%|████▌     | 31000/67349 [00:05<00:06, 5557.39 examples/s]Map:  48%|████▊     | 32000/67349 [00:05<00:06, 5570.75 examples/s]Map:  49%|████▉     | 33000/67349 [00:06<00:06, 5591.05 examples/s]Map:  50%|█████     | 34000/67349 [00:06<00:05, 5602.40 examples/s]Map:  52%|█████▏    | 35000/67349 [00:06<00:05, 5609.78 examples/s]Map:  53%|█████▎    | 36000/67349 [00:06<00:06, 4903.45 examples/s]Map:  55%|█████▍    | 37000/67349 [00:06<00:05, 5094.38 examples/s]Map:  56%|█████▋    | 38000/67349 [00:07<00:05, 5281.83 examples/s]Map:  58%|█████▊    | 39000/67349 [00:07<00:05, 5376.47 examples/s]Map:  59%|█████▉    | 40000/67349 [00:07<00:04, 5472.18 examples/s]Map:  61%|██████    | 41000/67349 [00:07<00:04, 5527.48 examples/s]Map:  62%|██████▏   | 42000/67349 [00:07<00:04, 5577.37 examples/s]Map:  64%|██████▍   | 43000/67349 [00:08<00:04, 5481.38 examples/s]Map:  65%|██████▌   | 44000/67349 [00:08<00:04, 5566.67 examples/s]Map:  67%|██████▋   | 45000/67349 [00:08<00:03, 5613.21 examples/s]Map:  68%|██████▊   | 46000/67349 [00:08<00:04, 4864.24 examples/s]Map:  70%|██████▉   | 47000/67349 [00:08<00:04, 5079.06 examples/s]Map:  71%|███████▏  | 48000/67349 [00:09<00:03, 5217.64 examples/s]Map:  73%|███████▎  | 49000/67349 [00:09<00:03, 5361.60 examples/s]Map:  74%|███████▍  | 50000/67349 [00:09<00:03, 5198.20 examples/s]Map:  76%|███████▌  | 51000/67349 [00:09<00:03, 5244.20 examples/s]Map:  77%|███████▋  | 52000/67349 [00:09<00:02, 5300.81 examples/s]Map:  79%|███████▊  | 53000/67349 [00:09<00:02, 5344.45 examples/s]Map:  80%|████████  | 54000/67349 [00:10<00:02, 5405.84 examples/s]Map:  82%|████████▏ | 55000/67349 [00:10<00:02, 4725.88 examples/s]Map:  83%|████████▎ | 56000/67349 [00:10<00:02, 4926.16 examples/s]Map:  85%|████████▍ | 57000/67349 [00:10<00:02, 5075.98 examples/s]Map:  86%|████████▌ | 58000/67349 [00:10<00:01, 5224.68 examples/s]Map:  88%|████████▊ | 59000/67349 [00:11<00:01, 5307.11 examples/s]Map:  89%|████████▉ | 60000/67349 [00:11<00:01, 5348.84 examples/s]Map:  91%|█████████ | 61000/67349 [00:11<00:01, 5439.56 examples/s]Map:  92%|█████████▏| 62000/67349 [00:11<00:00, 5442.90 examples/s]Map:  94%|█████████▎| 63000/67349 [00:11<00:00, 5333.88 examples/s]Map:  95%|█████████▌| 64000/67349 [00:12<00:00, 5395.23 examples/s]Map:  97%|█████████▋| 65000/67349 [00:12<00:00, 4659.56 examples/s]Map:  98%|█████████▊| 66000/67349 [00:12<00:00, 4833.65 examples/s]Map:  99%|█████████▉| 67000/67349 [00:12<00:00, 5077.07 examples/s]                                                                   Found cached dataset glue (/root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)
Map:   0%|          | 0/872 [00:00<?, ? examples/s]Map:  70%|██████▉   | 609/872 [00:00<00:00, 6029.60 examples/s]                                                               Example in validation set:
{'sentence': "it 's a charming and often affecting journey . ", 'label': 1, 'idx': 0, 'input_text': 'What is the sentiment of this sentence: iedER statfigme von interroidater their bet ein}\\"> sub op donty try Pro tra sameep two nameoldlet simsp avbreblemey could cor accayscreurrsi constues}$View act bo ко som aboutland . it \'s a charming and often affecting journey .  .', 'target_text': 'positive'}
Map:   0%|          | 0/872 [00:00<?, ? examples/s]Map: 100%|██████████| 872/872 [00:00<00:00, 4860.49 examples/s]                                                               97
97
# of train data: 80
Example:
+------------------------------+------------------------------+--------+
| input_ids                    | attention_mask               | labels |
+------------------------------+------------------------------+--------+
| [1, 1724, 338, 278, 19688... | [1, 1, 1, 1, 1, 1, 1, 1, ... | 8178   |
+------------------------------+------------------------------+--------+

# of dev data: 80
Example:
+------------------------------+------------------------------+--------+
| input_ids                    | attention_mask               | labels |
+------------------------------+------------------------------+--------+
| [1, 1724, 338, 278, 19688... | [1, 1, 1, 1, 1, 1, 1, 1, ... | 6374   |
+------------------------------+------------------------------+--------+

# of test data: 872
Example:
+------------------------------+------------------------------+--------+
| input_ids                    | attention_mask               | labels |
+------------------------------+------------------------------+--------+
| [1, 1724, 338, 278, 19688... | [1, 1, 1, 1, 1, 1, 1, 1, ... | 6374   |
+------------------------------+------------------------------+--------+
Class_distribution [0.5 0.5]. Data_ratio [[6.41462695e-02 9.81152872e-01 9.99998625e-01 9.97910891e-01
  1.97515371e-01 9.50591941e-01 9.64560492e-01 9.99868580e-01
  9.96441552e-01 9.98989053e-01]
 [9.35853730e-01 1.88471285e-02 1.37508618e-06 2.08910882e-03
  8.02484629e-01 4.94080590e-02 3.54395080e-02 1.31419946e-04
  3.55844845e-03 1.01094672e-03]]
     pcost       dcost       gap    pres   dres
 0:  5.8882e+02 -2.3481e+02  8e+02  2e-16  8e+01
 1:  5.8882e+02  5.8058e+02  8e+00  8e-15  8e-01
 2:  5.8882e+02  5.8873e+02  8e-02  8e-15  8e-03
 3:  5.8882e+02  5.8882e+02  8e-04  8e-15  8e-05
 4:  5.8882e+02  5.8882e+02  8e-06  5e-15  8e-07
 5:  5.8882e+02  5.8882e+02  8e-08  8e-15  8e-09
Optimal solution found.
[[1.54051956e+00 4.37497701e+00 4.05709357e+00 4.09305486e+00
  4.18167887e+00 4.85826640e+00 4.64231119e+00 4.05933903e+00
  4.11825282e+00 4.07450669e+00]
 [2.24752116e+01 8.40396599e-02 5.57886095e-06 8.56873805e-03
  1.69897310e+01 2.52513726e-01 1.70566000e-01 5.33548235e-04
  1.47069242e-02 4.12327759e-03]]
init prompt encoder...
Evaluate data in 81.76 seconds!
[tester] 
SST2Metric: acc=0.6857798165137615, hinge=1.676740622301714, ce=12.30688871156185
Global test acc: 0.6858
Global epoch 0...
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.561713695526123
Local loss @ local epoch 1: 0.6927964687347412
Local loss @ local epoch 2: 0.2800694704055786
Local loss @ local epoch 3: 0.2190231829881668
Local loss @ local epoch 4: 0.0038469505961984396
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.31 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=3.8812439999449144, ce=11.684900852518345
Local test acc @ epoch 0: 0.5092
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.6182466745376587
Local loss @ local epoch 1: 0.7188031673431396
Local loss @ local epoch 2: 0.4872274398803711
Local loss @ local epoch 3: 0.17556911706924438
Local loss @ local epoch 4: 0.08190617710351944
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.33 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=2.9273093736499822, ce=13.822429884464368
Local test acc @ epoch 0: 0.5092
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.6634807586669922
Local loss @ local epoch 1: 0.8865979313850403
Local loss @ local epoch 2: 0.3614169955253601
Local loss @ local epoch 3: 0.2122114896774292
Local loss @ local epoch 4: 0.1506628394126892
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.19 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=2.359222537880644, ce=12.877709135003046
Local test acc @ epoch 0: 0.5092
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.49107158184051514
Local loss @ local epoch 1: 0.4736643135547638
Local loss @ local epoch 2: 0.5942716598510742
Local loss @ local epoch 3: 0.5208809971809387
Local loss @ local epoch 4: 0.5887975692749023
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.4 seconds!
[tester] 
SST2Metric: acc=0.4908256880733945, hinge=2.019343272261663, ce=11.204074990858725
Local test acc @ epoch 0: 0.4908
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.6999358534812927
Local loss @ local epoch 1: 0.9233860373497009
Local loss @ local epoch 2: 0.5029310584068298
Local loss @ local epoch 3: 0.45327284932136536
Local loss @ local epoch 4: 0.47095951437950134
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.45 seconds!
[tester] 
SST2Metric: acc=0.5160550458715596, hinge=1.6573777461270673, ce=11.39015486480993
Local test acc @ epoch 0: 0.5161
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.3925434648990631
Local loss @ local epoch 1: 0.18022362887859344
Local loss @ local epoch 2: 0.06405296176671982
Local loss @ local epoch 3: 0.26599761843681335
Local loss @ local epoch 4: 0.08742617070674896
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.37 seconds!
[tester] 
SST2Metric: acc=0.4908256880733945, hinge=2.857304900064381, ce=9.29839430380305
Local test acc @ epoch 0: 0.4908
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.5605902671813965
Local loss @ local epoch 1: 1.2295540571212769
Local loss @ local epoch 2: 0.3963768482208252
Local loss @ local epoch 3: 0.4060170650482178
Local loss @ local epoch 4: 0.0826018676161766
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.37 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=2.7491257682852788, ce=12.274222732683935
Local test acc @ epoch 0: 0.5092
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.5545290112495422
Local loss @ local epoch 1: 0.6780641674995422
Local loss @ local epoch 2: 0.5180863738059998
Local loss @ local epoch 3: 0.41479775309562683
Local loss @ local epoch 4: 0.5863553881645203
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.52 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=1.9852852744793674, ce=14.31043883857377
Local test acc @ epoch 0: 0.5092
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.7084882259368896
Local loss @ local epoch 1: 1.0697929859161377
Local loss @ local epoch 2: 0.9793102145195007
Local loss @ local epoch 3: 0.438711017370224
Local loss @ local epoch 4: 0.3650626242160797
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.43 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=1.7493217975721447, ce=11.64880097240483
Local test acc @ epoch 0: 0.5092
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.5504848957061768
Local loss @ local epoch 1: 0.8332749605178833
Local loss @ local epoch 2: 0.3831980228424072
Local loss @ local epoch 3: 0.3199034631252289
Local loss @ local epoch 4: 0.12764491140842438
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.41 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=3.2472333798714734, ce=11.34782246055953
Local test acc @ epoch 0: 0.5092
Global evaluate on test data...
Evaluate data in 82.4 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=1.9890653135579661, ce=14.493856176323847
Global test acc : 0.5092
Global prompt norm: 10.054191589355469
Global epoch 1...
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.5026286840438843
Local loss @ local epoch 1: 0.47133001685142517
Local loss @ local epoch 2: 0.4787701666355133
Local loss @ local epoch 3: 0.5342051386833191
Local loss @ local epoch 4: 0.5938277840614319
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.37 seconds!
[tester] 
SST2Metric: acc=0.5103211009174312, hinge=1.6415771410005902, ce=12.28749922656138
Local test acc @ epoch 1: 0.5103
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.3636876046657562
Local loss @ local epoch 1: 0.28839462995529175
Local loss @ local epoch 2: 0.07550644874572754
Local loss @ local epoch 3: 0.056682389229536057
Local loss @ local epoch 4: 0.026107698678970337
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.39 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=2.6465355622659037, ce=10.78477187550396
Local test acc @ epoch 1: 0.5092
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.48405778408050537
Local loss @ local epoch 1: 0.4906003177165985
Local loss @ local epoch 2: 0.42348745465278625
Local loss @ local epoch 3: 0.451652854681015
Local loss @ local epoch 4: 0.45218101143836975
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.49 seconds!
[tester] 
SST2Metric: acc=0.5103211009174312, hinge=2.0025406326722663, ce=12.325021603785524
Local test acc @ epoch 1: 0.5103
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.5601725578308105
Local loss @ local epoch 1: 0.5572448372840881
Local loss @ local epoch 2: 0.566720724105835
Local loss @ local epoch 3: 0.6241003274917603
Local loss @ local epoch 4: 0.5718550086021423
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.43 seconds!
[tester] 
SST2Metric: acc=0.4908256880733945, hinge=2.0332437693525893, ce=10.952758920302085
Local test acc @ epoch 1: 0.4908
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.36505192518234253
Local loss @ local epoch 1: 0.3309395909309387
Local loss @ local epoch 2: 0.11054687201976776
Local loss @ local epoch 3: 0.12175992876291275
Local loss @ local epoch 4: 0.09409354627132416
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.48 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=2.424834428577248, ce=11.86121372782856
Local test acc @ epoch 1: 0.5092
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.35536134243011475
Local loss @ local epoch 1: 0.326532781124115
Local loss @ local epoch 2: 0.0737888365983963
Local loss @ local epoch 3: 0.22801396250724792
Local loss @ local epoch 4: 0.01601250097155571
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.45 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=3.7577084587254657, ce=11.065079286557818
Local test acc @ epoch 1: 0.5092
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.34476274251937866
Local loss @ local epoch 1: 0.2894541323184967
Local loss @ local epoch 2: 0.6269240379333496
Local loss @ local epoch 3: 0.10831569880247116
Local loss @ local epoch 4: 0.019178515300154686
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.16 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=3.5089409739599313, ce=10.207633810305815
Local test acc @ epoch 1: 0.5092
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.35998260974884033
Local loss @ local epoch 1: 0.28143495321273804
Local loss @ local epoch 2: 0.05803878977894783
Local loss @ local epoch 3: 0.08457323908805847
Local loss @ local epoch 4: 0.019560370594263077
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.56 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=3.1717241822032753, ce=12.505394428148183
Local test acc @ epoch 1: 0.5092
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.4048159420490265
Local loss @ local epoch 1: 0.1566733568906784
Local loss @ local epoch 2: 0.07051476836204529
Local loss @ local epoch 3: 0.056351177394390106
Local loss @ local epoch 4: 0.04167232662439346
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.46 seconds!
[tester] 
SST2Metric: acc=0.4908256880733945, hinge=2.731949061428735, ce=10.678286727415312
Local test acc @ epoch 1: 0.4908
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.3717515170574188
Local loss @ local epoch 1: 0.3147432208061218
Local loss @ local epoch 2: 0.18657654523849487
Local loss @ local epoch 3: 0.04132164269685745
Local loss @ local epoch 4: 0.021613795310258865
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.54 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=3.6327823673913238, ce=11.90192983784807
Local test acc @ epoch 1: 0.5092
Global evaluate on test data...
Evaluate data in 82.43 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=1.8769773983080453, ce=11.978924357562985
Global test acc : 0.5092
Global prompt norm: 14.07291316986084
Global epoch 2...
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.31871891021728516
Local loss @ local epoch 1: 0.11955952644348145
Local loss @ local epoch 2: 0.12190752476453781
Local loss @ local epoch 3: 0.05603634566068649
Local loss @ local epoch 4: 0.03412401303648949
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.22 seconds!
[tester] 
SST2Metric: acc=0.7981651376146789, hinge=0.9891627892988537, ce=12.124227086338427
Local test acc @ epoch 2: 0.7982
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.061702702194452286
Local loss @ local epoch 1: 0.004596496466547251
Local loss @ local epoch 2: 0.01941559836268425
Local loss @ local epoch 3: 0.01376430969685316
Local loss @ local epoch 4: 0.0006020283908583224
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.68 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=4.5845739918017605, ce=10.112229561586993
Local test acc @ epoch 2: 0.5092
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.06745406985282898
Local loss @ local epoch 1: 0.00889936275780201
Local loss @ local epoch 2: 0.013952796347439289
Local loss @ local epoch 3: 0.0008497117669321597
Local loss @ local epoch 4: 0.0013430253602564335
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.49 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=3.8542097631944428, ce=8.00023973097495
Local test acc @ epoch 2: 0.5092
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.24219083786010742
Local loss @ local epoch 1: 0.08510477095842361
Local loss @ local epoch 2: 0.06502578407526016
Local loss @ local epoch 3: 0.010972370393574238
Local loss @ local epoch 4: 0.004601047374308109
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.36 seconds!
[tester] 
SST2Metric: acc=0.4908256880733945, hinge=3.4982053670314475, ce=11.427870977909192
Local test acc @ epoch 2: 0.4908
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.3583656847476959
Local loss @ local epoch 1: 0.5728543400764465
Local loss @ local epoch 2: 0.3792838156223297
Local loss @ local epoch 3: 0.2936839759349823
Local loss @ local epoch 4: 0.31253883242607117
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.64 seconds!
[tester] 
SST2Metric: acc=0.6995412844036697, hinge=1.4317188044206812, ce=13.072550616133103
Local test acc @ epoch 2: 0.6995
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.05836331471800804
Local loss @ local epoch 1: 0.009609527885913849
Local loss @ local epoch 2: 0.0020264682825654745
Local loss @ local epoch 3: 0.0012788388412445784
Local loss @ local epoch 4: 0.0008767872932367027
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.46 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=3.978229174920178, ce=9.754246335510814
Local test acc @ epoch 2: 0.5092
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.055034782737493515
Local loss @ local epoch 1: 0.03699788451194763
Local loss @ local epoch 2: 0.15506213903427124
Local loss @ local epoch 3: 0.14323122799396515
Local loss @ local epoch 4: 0.07074184715747833
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.28 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=3.3018506858326973, ce=13.035828739131263
Local test acc @ epoch 2: 0.5092
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.5057312250137329
Local loss @ local epoch 1: 0.5763742327690125
Local loss @ local epoch 2: 0.3814276158809662
Local loss @ local epoch 3: 0.3715786039829254
Local loss @ local epoch 4: 0.4059254229068756
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.45 seconds!
[tester] 
SST2Metric: acc=0.7144495412844036, hinge=1.6644633691245263, ce=13.404466471540818
Local test acc @ epoch 2: 0.7144
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.07366136461496353
Local loss @ local epoch 1: 0.007616440765559673
Local loss @ local epoch 2: 0.006905198097229004
Local loss @ local epoch 3: 0.1352863311767578
Local loss @ local epoch 4: 0.009627731516957283
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.38 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=2.830191477723078, ce=10.580618779593651
Local test acc @ epoch 2: 0.5092
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.07121240347623825
Local loss @ local epoch 1: 0.004882064647972584
Local loss @ local epoch 2: 0.0016090618446469307
Local loss @ local epoch 3: 0.0011376350885257125
Local loss @ local epoch 4: 0.0007123723044060171
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.4 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=4.677354504209046, ce=10.210119273684441
Local test acc @ epoch 2: 0.5092
Global evaluate on test data...
Evaluate data in 82.53 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=2.4880799098846014, ce=11.513451926205136
Global test acc : 0.5092
Global prompt norm: 14.585546493530273
Global epoch 3...
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.01594097912311554
Local loss @ local epoch 1: 0.00815738644450903
Local loss @ local epoch 2: 0.01046897005289793
Local loss @ local epoch 3: 0.0006710493471473455
Local loss @ local epoch 4: 0.004697722848504782
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.36 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=4.702512651408484, ce=10.625485704579484
Local test acc @ epoch 3: 0.5092
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.015374272130429745
Local loss @ local epoch 1: 0.004611881449818611
Local loss @ local epoch 2: 0.00024586732615716755
Local loss @ local epoch 3: 0.00017137732356786728
Local loss @ local epoch 4: 8.657183207105845e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.28 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=5.528571426321607, ce=9.69886897025852
Local test acc @ epoch 3: 0.5092
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.6115400195121765
Local loss @ local epoch 1: 0.4221191704273224
Local loss @ local epoch 2: 0.4814419746398926
Local loss @ local epoch 3: 0.4417823553085327
Local loss @ local epoch 4: 0.47774824500083923
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.32 seconds!
[tester] 
SST2Metric: acc=0.5103211009174312, hinge=1.9660385661168929, ce=13.335906098742004
Local test acc @ epoch 3: 0.5103
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.44385841488838196
Local loss @ local epoch 1: 0.6541720032691956
Local loss @ local epoch 2: 0.527501106262207
Local loss @ local epoch 3: 0.35699403285980225
Local loss @ local epoch 4: 0.36777743697166443
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.34 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=1.9447334233773959, ce=12.077611310766377
Local test acc @ epoch 3: 0.5092
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.012018614448606968
Local loss @ local epoch 1: 0.0014925841242074966
Local loss @ local epoch 2: 0.00014047735021449625
Local loss @ local epoch 3: 0.0002616580459289253
Local loss @ local epoch 4: 5.042413613409735e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.41 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=6.323149844047126, ce=9.510505335046611
Local test acc @ epoch 3: 0.5092
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.014588931575417519
Local loss @ local epoch 1: 0.0027978424914181232
Local loss @ local epoch 2: 0.0006264526164159179
Local loss @ local epoch 3: 0.0044145346619188786
Local loss @ local epoch 4: 0.00011171658843522891
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.55 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=5.610342091376628, ce=10.194829735187216
Local test acc @ epoch 3: 0.5092
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.4581502676010132
Local loss @ local epoch 1: 0.4922749996185303
Local loss @ local epoch 2: 0.5525838732719421
Local loss @ local epoch 3: 0.3974843919277191
Local loss @ local epoch 4: 0.4601651728153229
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.62 seconds!
[tester] 
SST2Metric: acc=0.5389908256880734, hinge=1.7182250804857377, ce=12.590973329106601
Local test acc @ epoch 3: 0.539
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.008957461453974247
Local loss @ local epoch 1: 0.001796359196305275
Local loss @ local epoch 2: 0.0004797699803020805
Local loss @ local epoch 3: 0.00014137093967292458
Local loss @ local epoch 4: 0.019253753125667572
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.38 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=2.4956226069992837, ce=10.16060241646723
Local test acc @ epoch 3: 0.5092
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 1.0423346757888794
Local loss @ local epoch 1: 0.3189193308353424
Local loss @ local epoch 2: 0.3558120131492615
Local loss @ local epoch 3: 0.12597522139549255
Local loss @ local epoch 4: 0.04143622890114784
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.37 seconds!
[tester] 
SST2Metric: acc=0.4908256880733945, hinge=2.719869475845897, ce=11.368319213937182
Local test acc @ epoch 3: 0.4908
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.011779483407735825
Local loss @ local epoch 1: 0.004531651735305786
Local loss @ local epoch 2: 0.0008259647293016315
Local loss @ local epoch 3: 0.00023909118317533284
Local loss @ local epoch 4: 0.0001651496277190745
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.39 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=4.475135674170398, ce=10.71755821333019
Local test acc @ epoch 3: 0.5092
Global evaluate on test data...
Evaluate data in 82.41 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=2.115380393802573, ce=11.630864633332699
Global test acc : 0.5092
Global prompt norm: 17.59103012084961
Global epoch 4...
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.012163890525698662
Local loss @ local epoch 1: 0.0004095052136108279
Local loss @ local epoch 2: 0.0030325211118906736
Local loss @ local epoch 3: 0.00014134004595689476
Local loss @ local epoch 4: 1.528847133158706e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.41 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=6.200092980621058, ce=11.631928863875363
Local test acc @ epoch 4: 0.5092
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.021482281386852264
Local loss @ local epoch 1: 0.0003076575230807066
Local loss @ local epoch 2: 0.002921449951827526
Local loss @ local epoch 3: 0.0009315107599832118
Local loss @ local epoch 4: 0.0002403862599749118
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.45 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=6.024725382481146, ce=9.629536624348491
Local test acc @ epoch 4: 0.5092
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.45630738139152527
Local loss @ local epoch 1: 0.245314359664917
Local loss @ local epoch 2: 0.14492687582969666
Local loss @ local epoch 3: 0.11067965626716614
Local loss @ local epoch 4: 0.07933824509382248
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.49 seconds!
[tester] 
SST2Metric: acc=0.6594036697247706, hinge=1.4055272761834872, ce=12.554864087236037
Local test acc @ epoch 4: 0.6594
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.23678193986415863
Local loss @ local epoch 1: 0.08804129809141159
Local loss @ local epoch 2: 0.0347299724817276
Local loss @ local epoch 3: 0.03925473242998123
Local loss @ local epoch 4: 0.015046334825456142
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.32 seconds!
[tester] 
SST2Metric: acc=0.4908256880733945, hinge=2.907778677590396, ce=10.455397325918215
Local test acc @ epoch 4: 0.4908
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.43326637148857117
Local loss @ local epoch 1: 0.39923515915870667
Local loss @ local epoch 2: 0.2045566290616989
Local loss @ local epoch 3: 0.11573485285043716
Local loss @ local epoch 4: 0.353400319814682
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.37 seconds!
[tester] 
SST2Metric: acc=0.6100917431192661, hinge=1.4279581674742043, ce=12.214109928236095
Local test acc @ epoch 4: 0.6101
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.009733663871884346
Local loss @ local epoch 1: 0.00010504763486096635
Local loss @ local epoch 2: 0.00728920241817832
Local loss @ local epoch 3: 4.926196561427787e-05
Local loss @ local epoch 4: 0.000981531455181539
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.45 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=6.123977457711456, ce=10.204036577032246
Local test acc @ epoch 4: 0.5092
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.01717575080692768
Local loss @ local epoch 1: 0.00016642583068460226
Local loss @ local epoch 2: 0.0037260209210217
Local loss @ local epoch 3: 0.11738546192646027
Local loss @ local epoch 4: 0.05516510084271431
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.47 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=5.111056181268954, ce=10.677733071353458
Local test acc @ epoch 4: 0.5092
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.015277106314897537
Local loss @ local epoch 1: 0.00021347746951505542
Local loss @ local epoch 2: 0.001204226864501834
Local loss @ local epoch 3: 0.0029969289898872375
Local loss @ local epoch 4: 1.7493808627477847e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.5 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=6.41561008593358, ce=11.816979180782214
Local test acc @ epoch 4: 0.5092
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.015080561861395836
Local loss @ local epoch 1: 0.00027402371051721275
Local loss @ local epoch 2: 0.1558350920677185
Local loss @ local epoch 3: 0.05475669354200363
Local loss @ local epoch 4: 0.001502020051702857
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.55 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=3.5188648296058727, ce=9.756283948180872
Local test acc @ epoch 4: 0.5092
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.284694105386734
Local loss @ local epoch 1: 0.10614830255508423
Local loss @ local epoch 2: 0.038160182535648346
Local loss @ local epoch 3: 0.022230705246329308
Local loss @ local epoch 4: 0.05506371334195137
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.5 seconds!
[tester] 
SST2Metric: acc=0.8623853211009175, hinge=0.8007828723126595, ce=11.436452926845725
Local test acc @ epoch 4: 0.8624
Global evaluate on test data...
Evaluate data in 82.55 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=3.7364452344561934, ce=10.618486531283878
Global test acc : 0.5092
Global prompt norm: 17.16145133972168
Global epoch 5...
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0005999488057568669
Local loss @ local epoch 1: 6.666529225185513e-05
Local loss @ local epoch 2: 1.254668677574955e-05
Local loss @ local epoch 3: 6.973718882363755e-06
Local loss @ local epoch 4: 5.543216502701398e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.42 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=7.2508687699606655, ce=11.200740026771475
Local test acc @ epoch 5: 0.5092
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.09162308275699615
Local loss @ local epoch 1: 0.10770289599895477
Local loss @ local epoch 2: 0.04674878716468811
Local loss @ local epoch 3: 0.02326030284166336
Local loss @ local epoch 4: 0.010725648142397404
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.48 seconds!
[tester] 
SST2Metric: acc=0.8176605504587156, hinge=0.8962981962009308, ce=10.241868220338034
Local test acc @ epoch 5: 0.8177
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0009197217295877635
Local loss @ local epoch 1: 0.00014423183165490627
Local loss @ local epoch 2: 3.41169725288637e-05
Local loss @ local epoch 3: 3.504746473481646e-06
Local loss @ local epoch 4: 1.1515547157614492e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.4 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=6.602792328650798, ce=11.44262407460344
Local test acc @ epoch 5: 0.5092
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0008201810996979475
Local loss @ local epoch 1: 0.00012045301264151931
Local loss @ local epoch 2: 8.642290777061135e-05
Local loss @ local epoch 3: 7.450577186318696e-07
Local loss @ local epoch 4: 7.74860041019565e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.48 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=7.672077165831119, ce=10.609956601344118
Local test acc @ epoch 5: 0.5092
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.3606933355331421
Local loss @ local epoch 1: 0.3954605162143707
Local loss @ local epoch 2: 0.22276131808757782
Local loss @ local epoch 3: 0.2892884910106659
Local loss @ local epoch 4: 0.39827635884284973
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.72 seconds!
[tester] 
SST2Metric: acc=0.7087155963302753, hinge=1.365147345109817, ce=11.092710381254143
Local test acc @ epoch 5: 0.7087
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0016161906532943249
Local loss @ local epoch 1: 5.6920798670034856e-05
Local loss @ local epoch 2: 1.7970620319829322e-05
Local loss @ local epoch 3: 1.204005275212694e-05
Local loss @ local epoch 4: 1.2904321920359507e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.47 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=6.409893549910379, ce=11.160811354260925
Local test acc @ epoch 5: 0.5092
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0010165957501158118
Local loss @ local epoch 1: 7.196996011771262e-05
Local loss @ local epoch 2: 1.177184640255291e-05
Local loss @ local epoch 3: 1.0818181181093678e-05
Local loss @ local epoch 4: 1.1622833881119732e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.39 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=6.69201091670115, ce=11.105729391815466
Local test acc @ epoch 5: 0.5092
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0007418441236950457
Local loss @ local epoch 1: 0.00010385520727140829
Local loss @ local epoch 2: 7.957186426210683e-06
Local loss @ local epoch 3: 4.842744237976149e-05
Local loss @ local epoch 4: 5.215392775426153e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.39 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=7.6007800583445695, ce=12.888136255631753
Local test acc @ epoch 5: 0.5092
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.7716388702392578
Local loss @ local epoch 1: 0.29604822397232056
Local loss @ local epoch 2: 0.4733368158340454
Local loss @ local epoch 3: 0.3916420638561249
Local loss @ local epoch 4: 0.5988637208938599
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.44 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=1.9735232968942835, ce=12.961876597973184
Local test acc @ epoch 5: 0.5092
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.3574668765068054
Local loss @ local epoch 1: 0.20997782051563263
Local loss @ local epoch 2: 0.0527554415166378
Local loss @ local epoch 3: 0.03735526651144028
Local loss @ local epoch 4: 0.017871549353003502
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.44 seconds!
[tester] 
SST2Metric: acc=0.5252293577981652, hinge=1.994267492666157, ce=9.337354073830701
Local test acc @ epoch 5: 0.5252
Global evaluate on test data...
Evaluate data in 82.55 seconds!
[tester] 
SST2Metric: acc=0.5114678899082569, hinge=3.840213841254558, ce=10.324541402519296
Global test acc : 0.5115
Global prompt norm: 20.3569393157959
Global epoch 6...
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.00032948347507044673
Local loss @ local epoch 1: 1.114600308937952e-05
Local loss @ local epoch 2: 7.12272958480753e-06
Local loss @ local epoch 3: 2.056357971014222e-06
Local loss @ local epoch 4: 1.7583354292582953e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.43 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=7.18390648299401, ce=11.78333605757547
Local test acc @ epoch 6: 0.5092
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.00021890024072490633
Local loss @ local epoch 1: 6.818745987402508e-06
Local loss @ local epoch 2: 7.319420546991751e-06
Local loss @ local epoch 3: 6.914136179148045e-07
Local loss @ local epoch 4: 8.344646857949556e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.31 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=7.465519611988593, ce=10.412776328008109
Local test acc @ epoch 6: 0.5092
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.6177597641944885
Local loss @ local epoch 1: 0.39413461089134216
Local loss @ local epoch 2: 0.47969356179237366
Local loss @ local epoch 3: 0.43146538734436035
Local loss @ local epoch 4: 0.4551137685775757
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.16 seconds!
[tester] 
SST2Metric: acc=0.5103211009174312, hinge=1.9921623621511897, ce=13.694193883773384
Local test acc @ epoch 6: 0.5103
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0005129536730237305
Local loss @ local epoch 1: 3.558333628461696e-05
Local loss @ local epoch 2: 1.898389746202156e-05
Local loss @ local epoch 3: 1.1771847312047612e-05
Local loss @ local epoch 4: 2.175567033191328e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.37 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=7.514084439758861, ce=10.602312074888737
Local test acc @ epoch 6: 0.5092
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0001464597589801997
Local loss @ local epoch 1: 5.113922088639811e-05
Local loss @ local epoch 2: 1.8179397329731728e-06
Local loss @ local epoch 3: 1.782161052688025e-05
Local loss @ local epoch 4: 1.7881392011531716e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.4 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=8.585615860212833, ce=13.413767512785185
Local test acc @ epoch 6: 0.5092
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0005102741997689009
Local loss @ local epoch 1: 2.697073796298355e-05
Local loss @ local epoch 2: 2.047398083959706e-05
Local loss @ local epoch 3: 2.3841828351578442e-06
Local loss @ local epoch 4: 1.102685359910538e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.38 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=7.4383437283542175, ce=10.578267561186344
Local test acc @ epoch 6: 0.5092
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 1.2809921503067017
Local loss @ local epoch 1: 0.5324957966804504
Local loss @ local epoch 2: 0.415080726146698
Local loss @ local epoch 3: 0.3101593852043152
Local loss @ local epoch 4: 0.22692443430423737
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.37 seconds!
[tester] 
SST2Metric: acc=0.5435779816513762, hinge=1.6993613111863441, ce=13.483657250710584
Local test acc @ epoch 6: 0.5436
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.00020278153533581644
Local loss @ local epoch 1: 2.604686414997559e-05
Local loss @ local epoch 2: 2.8610174922505394e-06
Local loss @ local epoch 3: 2.9206228191469563e-06
Local loss @ local epoch 4: 3.0100300136837177e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.32 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=7.530496776650805, ce=12.309956624967242
Local test acc @ epoch 6: 0.5092
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.5692394375801086
Local loss @ local epoch 1: 0.20085857808589935
Local loss @ local epoch 2: 0.02511739172041416
Local loss @ local epoch 3: 0.022479137405753136
Local loss @ local epoch 4: 0.016622042283415794
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.35 seconds!
[tester] 
SST2Metric: acc=0.7110091743119266, hinge=1.2778628553272386, ce=10.02481865664141
Local test acc @ epoch 6: 0.711
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.8136093616485596
Local loss @ local epoch 1: 0.48341941833496094
Local loss @ local epoch 2: 0.4594545364379883
Local loss @ local epoch 3: 0.43937158584594727
Local loss @ local epoch 4: 0.4398292005062103
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.53 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=1.9777854730229858, ce=14.859950039364875
Local test acc @ epoch 6: 0.5092
Global evaluate on test data...
Evaluate data in 82.35 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=5.222165947660394, ce=10.880746718940385
Global test acc : 0.5092
Global prompt norm: 20.95026206970215
Global epoch 7...
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 1.0521187782287598
Local loss @ local epoch 1: 0.08057830482721329
Local loss @ local epoch 2: 0.15101127326488495
Local loss @ local epoch 3: 0.07862871140241623
Local loss @ local epoch 4: 0.050296325236558914
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.43 seconds!
[tester] 
SST2Metric: acc=0.9323394495412844, hinge=0.45359749230769797, ce=11.937452403777236
Local test acc @ epoch 7: 0.9323
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.24253037571907043
Local loss @ local epoch 1: 0.11379731446504593
Local loss @ local epoch 2: 0.049224525690078735
Local loss @ local epoch 3: 0.02454819343984127
Local loss @ local epoch 4: 0.015244430862367153
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.32 seconds!
[tester] 
SST2Metric: acc=0.5034403669724771, hinge=2.5479741069155, ce=10.766472177767973
Local test acc @ epoch 7: 0.5034
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 4.911406904284377e-06
Local loss @ local epoch 1: 0.00027231997228227556
Local loss @ local epoch 2: 0.04068069905042648
Local loss @ local epoch 3: 0.04979249835014343
Local loss @ local epoch 4: 0.00024284471874125302
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.36 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=5.203637761807223, ce=7.7606671140828265
Local test acc @ epoch 7: 0.5092
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 4.0531035665480886e-06
Local loss @ local epoch 1: 0.0002269142569275573
Local loss @ local epoch 2: 5.36441632448259e-07
Local loss @ local epoch 3: 2.0861622829215776e-07
Local loss @ local epoch 4: 3.576278118089249e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.28 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=7.943978051526831, ce=10.13100251801517
Local test acc @ epoch 7: 0.5092
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 9.089648301596753e-06
Local loss @ local epoch 1: 0.0009329540189355612
Local loss @ local epoch 2: 5.531153510673903e-05
Local loss @ local epoch 3: 1.639126139707514e-06
Local loss @ local epoch 4: 5.960461066933931e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.45 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=7.4464917620387645, ce=10.855025448930373
Local test acc @ epoch 7: 0.5092
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 7.361129974015057e-06
Local loss @ local epoch 1: 0.0010683347936719656
Local loss @ local epoch 2: 2.0712373952846974e-05
Local loss @ local epoch 3: 1.7285328794969246e-06
Local loss @ local epoch 4: 1.4007079016664647e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.57 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=7.383685647894483, ce=11.654776840034975
Local test acc @ epoch 7: 0.5092
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 3.6656783777289093e-06
Local loss @ local epoch 1: 0.0003588083491194993
Local loss @ local epoch 2: 1.1771835488616489e-05
Local loss @ local epoch 3: 6.616089649469359e-06
Local loss @ local epoch 4: 0.0005772473523393273
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.21 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=6.839642560810124, ce=8.792249091174625
Local test acc @ epoch 7: 0.5092
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 1.216849446296692
Local loss @ local epoch 1: 0.16159366071224213
Local loss @ local epoch 2: 0.10030248761177063
Local loss @ local epoch 3: 0.060524147003889084
Local loss @ local epoch 4: 0.05364716053009033
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.55 seconds!
[tester] 
SST2Metric: acc=0.7878440366972477, hinge=1.0372624397277832, ce=9.509520810678465
Local test acc @ epoch 7: 0.7878
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 5.304791102389572e-06
Local loss @ local epoch 1: 0.0004097494238521904
Local loss @ local epoch 2: 6.109456990088802e-06
Local loss @ local epoch 3: 6.258465873543173e-06
Local loss @ local epoch 4: 4.9471627789898776e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.23 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=7.448327819141773, ce=10.538637979314961
Local test acc @ epoch 7: 0.5092
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.3766959607601166
Local loss @ local epoch 1: 0.2054758220911026
Local loss @ local epoch 2: 0.1114702895283699
Local loss @ local epoch 3: 0.05971676483750343
Local loss @ local epoch 4: 0.02545040473341942
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.35 seconds!
[tester] 
SST2Metric: acc=0.8348623853211009, hinge=0.8456691951926695, ce=11.093420369909444
Local test acc @ epoch 7: 0.8349
Global evaluate on test data...
Evaluate data in 82.53 seconds!
[tester] 
SST2Metric: acc=0.9231651376146789, hinge=0.5450558804590767, ce=10.791043692772542
Global test acc : 0.9232
Global prompt norm: 23.711650848388672
Global epoch 8...
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.08422631025314331
Local loss @ local epoch 1: 0.0017501990078017116
Local loss @ local epoch 2: 0.001771705225110054
Local loss @ local epoch 3: 0.000723258126527071
Local loss @ local epoch 4: 0.0009071097592823207
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.25 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=4.013320057763966, ce=8.26180792729789
Local test acc @ epoch 8: 0.5092
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.06845232099294662
Local loss @ local epoch 1: 0.25008857250213623
Local loss @ local epoch 2: 0.3499811589717865
Local loss @ local epoch 3: 0.224892258644104
Local loss @ local epoch 4: 0.14071787893772125
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.42 seconds!
[tester] 
SST2Metric: acc=0.7821100917431193, hinge=1.1154404736440116, ce=10.609270927009232
Local test acc @ epoch 8: 0.7821
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.2947133779525757
Local loss @ local epoch 1: 0.15646256506443024
Local loss @ local epoch 2: 0.04630250483751297
Local loss @ local epoch 3: 0.038407158106565475
Local loss @ local epoch 4: 0.06380713731050491
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.25 seconds!
[tester] 
SST2Metric: acc=0.7155963302752294, hinge=1.2432464033091835, ce=11.740384994296853
Local test acc @ epoch 8: 0.7156
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.13031654059886932
Local loss @ local epoch 1: 0.4435139000415802
Local loss @ local epoch 2: 0.40610018372535706
Local loss @ local epoch 3: 0.2961582541465759
Local loss @ local epoch 4: 0.21286903321743011
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.35 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=2.846073471624917, ce=10.943373198902934
Local test acc @ epoch 8: 0.5092
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.07797303795814514
Local loss @ local epoch 1: 0.11970731616020203
Local loss @ local epoch 2: 0.003153555328026414
Local loss @ local epoch 3: 0.003016596892848611
Local loss @ local epoch 4: 0.0021962726023048162
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.52 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=3.3096609848354936, ce=8.720058248677384
Local test acc @ epoch 8: 0.5092
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.07607623934745789
Local loss @ local epoch 1: 0.010144740343093872
Local loss @ local epoch 2: 0.0003856190014630556
Local loss @ local epoch 3: 0.0014573324006050825
Local loss @ local epoch 4: 0.0005119005218148232
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.28 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=4.682733348750193, ce=9.3870057447241
Local test acc @ epoch 8: 0.5092
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.05679565668106079
Local loss @ local epoch 1: 0.007562053389847279
Local loss @ local epoch 2: 0.0005337108159437776
Local loss @ local epoch 3: 0.00032462217495776713
Local loss @ local epoch 4: 0.00032376538729295135
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.4 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=4.77391272291131, ce=7.573431284055797
Local test acc @ epoch 8: 0.5092
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.08862665295600891
Local loss @ local epoch 1: 0.009593783877789974
Local loss @ local epoch 2: 0.0014878258807584643
Local loss @ local epoch 3: 0.0003926202771253884
Local loss @ local epoch 4: 0.00016079905617516488
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.38 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=4.809268971101953, ce=6.748308146765472
Local test acc @ epoch 8: 0.5092
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 1.1719640493392944
Local loss @ local epoch 1: 0.08262014389038086
Local loss @ local epoch 2: 0.05030828341841698
Local loss @ local epoch 3: 0.04925413802266121
Local loss @ local epoch 4: 0.08417172729969025
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.34 seconds!
[tester] 
SST2Metric: acc=0.4908256880733945, hinge=3.02686610899934, ce=10.336103728058141
Local test acc @ epoch 8: 0.4908
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.06293430924415588
Local loss @ local epoch 1: 0.0009088974911719561
Local loss @ local epoch 2: 0.0007670841296203434
Local loss @ local epoch 3: 0.0011362339137122035
Local loss @ local epoch 4: 0.0004829997487831861
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.45 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=3.939482682888661, ce=7.337611644639882
Local test acc @ epoch 8: 0.5092
Global evaluate on test data...
Evaluate data in 82.55 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=3.1387825941820755, ce=9.586371063092432
Global test acc : 0.5092
Global prompt norm: 23.862407684326172
Global epoch 9...
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.00225175847299397
Local loss @ local epoch 1: 4.044081288157031e-05
Local loss @ local epoch 2: 1.5735493434476666e-05
Local loss @ local epoch 3: 2.6046882339869626e-05
Local loss @ local epoch 4: 3.084490526816808e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.34 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=6.184255608724891, ce=10.914049030443945
Local test acc @ epoch 9: 0.5092
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0026686680503189564
Local loss @ local epoch 1: 2.1159406969673e-05
Local loss @ local epoch 2: 1.2010262253170367e-05
Local loss @ local epoch 3: 2.527203832869418e-05
Local loss @ local epoch 4: 3.686462514451705e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.31 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=6.03947077759909, ce=10.160980242107986
Local test acc @ epoch 9: 0.5092
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0014026026474311948
Local loss @ local epoch 1: 3.0707771657034755e-05
Local loss @ local epoch 2: 1.335134311375441e-05
Local loss @ local epoch 3: 7.796256795700174e-06
Local loss @ local epoch 4: 1.5830857591936365e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.52 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=6.123410156013769, ce=9.68613799558867
Local test acc @ epoch 9: 0.5092
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.9244675636291504
Local loss @ local epoch 1: 0.19367238879203796
Local loss @ local epoch 2: 0.10034804046154022
Local loss @ local epoch 3: 0.07380818575620651
Local loss @ local epoch 4: 0.034345272928476334
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.44 seconds!
[tester] 
SST2Metric: acc=0.4919724770642202, hinge=2.4533261618482958, ce=10.921692227004865
Local test acc @ epoch 9: 0.492
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.7308156490325928
Local loss @ local epoch 1: 0.3998272716999054
Local loss @ local epoch 2: 0.16332675516605377
Local loss @ local epoch 3: 0.11320599168539047
Local loss @ local epoch 4: 0.07730140537023544
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.28 seconds!
[tester] 
SST2Metric: acc=0.5653669724770642, hinge=2.0091090473013185, ce=10.881226907082654
Local test acc @ epoch 9: 0.5654
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0018539183074608445
Local loss @ local epoch 1: 0.00021282020315993577
Local loss @ local epoch 2: 1.919245914905332e-05
Local loss @ local epoch 3: 1.9341501683811657e-05
Local loss @ local epoch 4: 7.232694770209491e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.46 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=6.197925053605246, ce=10.339983699518607
Local test acc @ epoch 9: 0.5092
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.584783673286438
Local loss @ local epoch 1: 0.22432254254817963
Local loss @ local epoch 2: 0.24217289686203003
Local loss @ local epoch 3: 0.0944867730140686
Local loss @ local epoch 4: 0.05854055657982826
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.41 seconds!
[tester] 
SST2Metric: acc=0.5229357798165137, hinge=2.3328341316739354, ce=12.63404260862858
Local test acc @ epoch 9: 0.5229
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 1.115380048751831
Local loss @ local epoch 1: 0.7689151167869568
Local loss @ local epoch 2: 0.6402111649513245
Local loss @ local epoch 3: 0.612389087677002
Local loss @ local epoch 4: 0.5101850628852844
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.3 seconds!
[tester] 
SST2Metric: acc=0.4908256880733945, hinge=2.1354440652996027, ce=10.585827582473055
Local test acc @ epoch 9: 0.4908
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.002015226986259222
Local loss @ local epoch 1: 0.0005895644426345825
Local loss @ local epoch 2: 1.3232142919150647e-05
Local loss @ local epoch 3: 1.3768571079708636e-05
Local loss @ local epoch 4: 1.192085437651258e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.25 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=6.391649009984568, ce=10.111085738610784
Local test acc @ epoch 9: 0.5092
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.002927538240328431
Local loss @ local epoch 1: 4.3093205022159964e-05
Local loss @ local epoch 2: 2.437796320009511e-05
Local loss @ local epoch 3: 2.2947451725485735e-05
Local loss @ local epoch 4: 2.735802627285011e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.39 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=5.955342480895716, ce=10.211445515308904
Local test acc @ epoch 9: 0.5092
Global evaluate on test data...
Evaluate data in 82.44 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=5.709950910795719, ce=7.18221378982614
Global test acc : 0.5092
Global prompt norm: 31.21268653869629
Global epoch 10...
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 1.2040061847073957e-05
Local loss @ local epoch 1: 9.536737479720614e-07
Local loss @ local epoch 2: 4.768371297814156e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.42 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=8.133188398606187, ce=13.700547603292202
Local test acc @ epoch 10: 0.5092
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 1.832823545555584e-05
Local loss @ local epoch 1: 9.834761840465944e-07
Local loss @ local epoch 2: 1.1920928244535389e-07
Local loss @ local epoch 3: 8.940696005765858e-08
Local loss @ local epoch 4: 8.940696005765858e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.38 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=7.916361245540304, ce=13.645776836150283
Local test acc @ epoch 10: 0.5092
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 1.71361789398361e-05
Local loss @ local epoch 1: 1.3709058066524449e-06
Local loss @ local epoch 2: 1.1920928244535389e-07
Local loss @ local epoch 3: 8.940696005765858e-08
Local loss @ local epoch 4: 8.940696005765858e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.36 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=7.845646796970192, ce=15.52421653817553
Local test acc @ epoch 10: 0.5092
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 2.020569081651047e-05
Local loss @ local epoch 1: 5.36441632448259e-07
Local loss @ local epoch 2: 5.066393669039826e-07
Local loss @ local epoch 3: 1.1920928244535389e-07
Local loss @ local epoch 4: 2.9802320611338473e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.36 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=8.154164410512381, ce=12.442095979638056
Local test acc @ epoch 10: 0.5092
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.7145015001296997
Local loss @ local epoch 1: 0.07336944341659546
Local loss @ local epoch 2: 0.032096944749355316
Local loss @ local epoch 3: 0.015456034801900387
Local loss @ local epoch 4: 0.01297899428755045
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.31 seconds!
[tester] 
SST2Metric: acc=0.6502293577981652, hinge=1.4140130951317078, ce=10.694511221089494
Local test acc @ epoch 10: 0.6502
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 1.3662660121917725
Local loss @ local epoch 1: 0.028347186744213104
Local loss @ local epoch 2: 0.03614544868469238
Local loss @ local epoch 3: 0.04325166717171669
Local loss @ local epoch 4: 0.023569593206048012
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.31 seconds!
[tester] 
SST2Metric: acc=0.7694954128440367, hinge=1.0739161517095128, ce=10.493866211777434
Local test acc @ epoch 10: 0.7695
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 1.0209763050079346
Local loss @ local epoch 1: 0.39286622405052185
Local loss @ local epoch 2: 0.27357447147369385
Local loss @ local epoch 3: 0.3760342299938202
Local loss @ local epoch 4: 0.5014786124229431
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.3 seconds!
[tester] 
SST2Metric: acc=0.5172018348623854, hinge=2.0299451815972636, ce=10.513872024116166
Local test acc @ epoch 10: 0.5172
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 1.3708955520996824e-05
Local loss @ local epoch 1: 1.788137637959153e-06
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.9802320611338473e-08
Local loss @ local epoch 4: 5.9604641222676946e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.46 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=8.547467026141806, ce=14.020616457002973
Local test acc @ epoch 10: 0.5092
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 9.834709089773241e-06
Local loss @ local epoch 1: 8.046624202506791e-07
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.9802320611338473e-08
Local loss @ local epoch 4: 8.940696005765858e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.3 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=7.840709983755689, ce=15.20064825530446
Local test acc @ epoch 10: 0.5092
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 1.0704354047775269
Local loss @ local epoch 1: 0.12898705899715424
Local loss @ local epoch 2: 0.38077640533447266
Local loss @ local epoch 3: 0.045437708497047424
Local loss @ local epoch 4: 0.3347937762737274
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.4 seconds!
[tester] 
SST2Metric: acc=0.8795871559633027, hinge=0.6914913293418534, ce=8.42065361442916
Local test acc @ epoch 10: 0.8796
Global evaluate on test data...
Evaluate data in 82.37 seconds!
[tester] 
SST2Metric: acc=0.5928899082568807, hinge=1.9945949594908898, ce=6.310396448187872
Global test acc : 0.5929
Global prompt norm: 32.69630813598633
Global epoch 11...
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 2.011604192375671e-05
Local loss @ local epoch 1: 5.36441632448259e-07
Local loss @ local epoch 2: 9.834760703597567e-07
Local loss @ local epoch 3: 5.066393669039826e-07
Local loss @ local epoch 4: 4.172324565843155e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.38 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=8.28643599343956, ce=8.927784516177047
Local test acc @ epoch 11: 0.5092
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.17289675772190094
Local loss @ local epoch 1: 0.027883248403668404
Local loss @ local epoch 2: 0.014581771567463875
Local loss @ local epoch 3: 0.00595770264044404
Local loss @ local epoch 4: 0.0010838358430191875
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.55 seconds!
[tester] 
SST2Metric: acc=0.5802752293577982, hinge=2.960260055617455, ce=8.355323529024737
Local test acc @ epoch 11: 0.5803
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0013165583368390799
Local loss @ local epoch 1: 0.0034996471367776394
Local loss @ local epoch 2: 3.8743007735320134e-07
Local loss @ local epoch 3: 6.258484859245073e-07
Local loss @ local epoch 4: 1.1920919860131107e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.53 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=7.265852309148246, ce=7.5592167585267935
Local test acc @ epoch 11: 0.5092
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.16494233906269073
Local loss @ local epoch 1: 0.02364732138812542
Local loss @ local epoch 2: 0.01705061085522175
Local loss @ local epoch 3: 0.0022665734868496656
Local loss @ local epoch 4: 0.003189758164808154
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.37 seconds!
[tester] 
SST2Metric: acc=0.8337155963302753, hinge=0.9502060052451737, ce=8.434893927442918
Local test acc @ epoch 11: 0.8337
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 2.2077025278122164e-05
Local loss @ local epoch 1: 1.5735607803435414e-06
Local loss @ local epoch 2: 1.0013574183176388e-06
Local loss @ local epoch 3: 8.344646857949556e-07
Local loss @ local epoch 4: 3.337859766361362e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.6 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=8.46692113482624, ce=9.627219720717964
Local test acc @ epoch 11: 0.5092
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.00014419161016121507
Local loss @ local epoch 1: 1.797061850083992e-05
Local loss @ local epoch 2: 2.3841855067985307e-07
Local loss @ local epoch 3: 5.364416892916779e-07
Local loss @ local epoch 4: 1.6987308981697424e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.36 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=6.833507614398221, ce=8.951234006006784
Local test acc @ epoch 11: 0.5092
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 3.683395334519446e-05
Local loss @ local epoch 1: 3.5464688608044526e-06
Local loss @ local epoch 2: 9.536736911286425e-07
Local loss @ local epoch 3: 5.662438979925355e-07
Local loss @ local epoch 4: 5.066393669039826e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.47 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=7.863566616259583, ce=8.701162182956661
Local test acc @ epoch 11: 0.5092
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.07471740990877151
Local loss @ local epoch 1: 0.11385748535394669
Local loss @ local epoch 2: 1.1181410551071167
Local loss @ local epoch 3: 0.2336163967847824
Local loss @ local epoch 4: 0.11254868656396866
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.51 seconds!
[tester] 
SST2Metric: acc=0.569954128440367, hinge=1.672711396436079, ce=10.923099439078515
Local test acc @ epoch 11: 0.57
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 2.7000342015526257e-05
Local loss @ local epoch 1: 8.642668944958132e-07
Local loss @ local epoch 2: 7.748599273327272e-07
Local loss @ local epoch 3: 4.7683701609457785e-07
Local loss @ local epoch 4: 4.470347505503014e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.31 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=7.577378829684826, ce=8.605157241908783
Local test acc @ epoch 11: 0.5092
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.07783259451389313
Local loss @ local epoch 1: 0.014466995373368263
Local loss @ local epoch 2: 0.09060154855251312
Local loss @ local epoch 3: 0.010677136480808258
Local loss @ local epoch 4: 0.013025947846472263
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.42 seconds!
[tester] 
SST2Metric: acc=0.8899082568807339, hinge=0.5857908147464105, ce=9.851335123044635
Local test acc @ epoch 11: 0.8899
Global evaluate on test data...
Evaluate data in 82.33 seconds!
[tester] 
SST2Metric: acc=0.6100917431192661, hinge=3.5053695325457723, ce=7.016268782659409
Global test acc : 0.6101
Global prompt norm: 36.5694580078125
Global epoch 12...
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 1.1920920996999484e-06
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.9802320611338473e-08
Local loss @ local epoch 4: 8.940696005765858e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.19 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=8.868891422901678, ce=9.812766699615969
Local test acc @ epoch 12: 0.5092
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 1.0430807151351473e-06
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 5.9604641222676946e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.41 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=8.810736708684798, ce=9.750677772618214
Local test acc @ epoch 12: 0.5092
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 2.0563556972774677e-06
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.1920928244535389e-07
Local loss @ local epoch 4: 1.1920928244535389e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.38 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=8.906589921461332, ce=10.921585747955042
Local test acc @ epoch 12: 0.5092
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 8.344646857949556e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.56 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=8.492373394309928, ce=9.184306506716878
Local test acc @ epoch 12: 0.5092
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 1.2173190116882324
Local loss @ local epoch 1: 0.016073478385806084
Local loss @ local epoch 2: 0.026525216177105904
Local loss @ local epoch 3: 0.02983151376247406
Local loss @ local epoch 4: 0.02040509134531021
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.25 seconds!
[tester] 
SST2Metric: acc=0.8360091743119266, hinge=0.7842576053984668, ce=7.398453541851919
Local test acc @ epoch 12: 0.836
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.10092281550168991
Local loss @ local epoch 1: 0.1252492368221283
Local loss @ local epoch 2: 0.04195614531636238
Local loss @ local epoch 3: 0.024313410744071007
Local loss @ local epoch 4: 0.010053695179522038
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.34 seconds!
[tester] 
SST2Metric: acc=0.7144495412844036, hinge=1.4498674123112214, ce=9.200066308362768
Local test acc @ epoch 12: 0.7144
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.18656721711158752
Local loss @ local epoch 1: 0.021625401452183723
Local loss @ local epoch 2: 0.003866851795464754
Local loss @ local epoch 3: 0.006498317234218121
Local loss @ local epoch 4: 0.028619352728128433
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.27 seconds!
[tester] 
SST2Metric: acc=0.9151376146788991, hinge=0.4747056474379443, ce=8.055205572635755
Local test acc @ epoch 12: 0.9151
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 1.6927704109548358e-06
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.668929883180681e-07
Local loss @ local epoch 4: 7.152556946721234e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.26 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=8.547501334356605, ce=9.400357735266379
Local test acc @ epoch 12: 0.5092
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.03619998320937157
Local loss @ local epoch 1: 0.013819800689816475
Local loss @ local epoch 2: 0.005342811346054077
Local loss @ local epoch 3: 0.017287295311689377
Local loss @ local epoch 4: 0.003606509417295456
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.3 seconds!
[tester] 
SST2Metric: acc=0.7339449541284404, hinge=1.663908810243694, ce=7.883824904030616
Local test acc @ epoch 12: 0.7339
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 1.4305103377409978e-06
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.9802320611338473e-08
Local loss @ local epoch 3: 8.940696005765858e-08
Local loss @ local epoch 4: 2.9802320611338473e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.3 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=8.674372747403766, ce=9.420688681646224
Local test acc @ epoch 12: 0.5092
Global evaluate on test data...
Evaluate data in 82.34 seconds!
[tester] 
SST2Metric: acc=0.9334862385321101, hinge=0.3946009852470608, ce=4.8533611385100475
Global test acc : 0.9335
Global prompt norm: 39.01295471191406
Global epoch 13...
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0003243481332901865
Local loss @ local epoch 1: 8.046623634072603e-07
Local loss @ local epoch 2: 1.8775439230012125e-06
Local loss @ local epoch 3: 4.440531938598724e-06
Local loss @ local epoch 4: 5.2451905503403395e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.38 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=5.390273393840965, ce=9.135289498425404
Local test acc @ epoch 13: 0.5092
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0008944589062593877
Local loss @ local epoch 1: 5.143372982274741e-05
Local loss @ local epoch 2: 2.2867034203954972e-05
Local loss @ local epoch 3: 6.755165941285668e-06
Local loss @ local epoch 4: 7.649229701200966e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.23 seconds!
[tester] 
SST2Metric: acc=0.7362385321100917, hinge=2.632917225907702, ce=5.459334983738191
Local test acc @ epoch 13: 0.7362
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0005679490277543664
Local loss @ local epoch 1: 1.5497193999181036e-06
Local loss @ local epoch 2: 1.0698972801037598e-05
Local loss @ local epoch 3: 1.1742040442186408e-05
Local loss @ local epoch 4: 3.546469542925479e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.41 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=7.063209400264495, ce=10.647724571578
Local test acc @ epoch 13: 0.5092
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0002446566941216588
Local loss @ local epoch 1: 3.248442908443394e-06
Local loss @ local epoch 2: 5.513405994861387e-06
Local loss @ local epoch 3: 3.2186444514081813e-06
Local loss @ local epoch 4: 1.6987307844829047e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.38 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=6.8238110170451876, ce=9.822871494730679
Local test acc @ epoch 13: 0.5092
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0007561930106021464
Local loss @ local epoch 1: 1.7618916899664328e-05
Local loss @ local epoch 2: 5.5597007303731516e-05
Local loss @ local epoch 3: 8.988334229798056e-06
Local loss @ local epoch 4: 3.6716385238833027e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.39 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=6.533956541927583, ce=10.228829436345931
Local test acc @ epoch 13: 0.5092
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0020508570596575737
Local loss @ local epoch 1: 0.16873681545257568
Local loss @ local epoch 2: 0.14383623003959656
Local loss @ local epoch 3: 0.0013751358492299914
Local loss @ local epoch 4: 0.007877820171415806
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.52 seconds!
[tester] 
SST2Metric: acc=0.8394495412844036, hinge=0.8722933563617391, ce=10.248734964143246
Local test acc @ epoch 13: 0.8394
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.003869142383337021
Local loss @ local epoch 1: 0.00022683091810904443
Local loss @ local epoch 2: 9.536096331430599e-05
Local loss @ local epoch 3: 2.6016985430032946e-05
Local loss @ local epoch 4: 1.4543395082000643e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.5 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=5.262819885113918, ce=8.508534549573145
Local test acc @ epoch 13: 0.5092
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.8710891008377075
Local loss @ local epoch 1: 0.027677463367581367
Local loss @ local epoch 2: 0.0029136743396520615
Local loss @ local epoch 3: 0.004034341778606176
Local loss @ local epoch 4: 0.0008438864606432617
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.26 seconds!
[tester] 
SST2Metric: acc=0.7477064220183486, hinge=1.9025591415002805, ce=5.176530873009918
Local test acc @ epoch 13: 0.7477
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.09729929268360138
Local loss @ local epoch 1: 0.000852156663313508
Local loss @ local epoch 2: 0.002616492100059986
Local loss @ local epoch 3: 0.0005145844188518822
Local loss @ local epoch 4: 0.00019141643133480102
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.42 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=4.038254044471531, ce=8.732704136349739
Local test acc @ epoch 13: 0.5092
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.003849329659715295
Local loss @ local epoch 1: 0.025885768234729767
Local loss @ local epoch 2: 0.009668496437370777
Local loss @ local epoch 3: 0.0023484001867473125
Local loss @ local epoch 4: 0.001132239936850965
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.34 seconds!
[tester] 
SST2Metric: acc=0.893348623853211, hinge=0.6721724340128242, ce=7.51279250416187
Local test acc @ epoch 13: 0.8933
Global evaluate on test data...
Evaluate data in 82.37 seconds!
[tester] 
SST2Metric: acc=0.5103211009174312, hinge=5.874034264765748, ce=6.9012092209737235
Global test acc : 0.5103
Global prompt norm: 44.132511138916016
Global epoch 14...
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 1.0728826964623295e-06
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.37 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=8.887255099935269, ce=11.049610240743794
Local test acc @ epoch 14: 0.5092
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.09745018929243088
Local loss @ local epoch 1: 0.028057703748345375
Local loss @ local epoch 2: 0.005531114060431719
Local loss @ local epoch 3: 0.006324403919279575
Local loss @ local epoch 4: 0.004715959075838327
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.31 seconds!
[tester] 
SST2Metric: acc=0.6318807339449541, hinge=2.449121736058401, ce=10.078647902252477
Local test acc @ epoch 14: 0.6319
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.13239529728889465
Local loss @ local epoch 1: 0.039472050964832306
Local loss @ local epoch 2: 0.027534328401088715
Local loss @ local epoch 3: 0.00592433474957943
Local loss @ local epoch 4: 0.0012842174619436264
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.59 seconds!
[tester] 
SST2Metric: acc=0.8727064220183486, hinge=0.7914248506683822, ce=6.264346367722258
Local test acc @ epoch 14: 0.8727
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 9.536736911286425e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.39 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=8.992266077514088, ce=9.170959099717097
Local test acc @ epoch 14: 0.5092
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 1.984550952911377
Local loss @ local epoch 1: 0.11188531666994095
Local loss @ local epoch 2: 0.07213708758354187
Local loss @ local epoch 3: 0.02910999022424221
Local loss @ local epoch 4: 0.012987938709557056
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.49 seconds!
[tester] 
SST2Metric: acc=0.8497706422018348, hinge=0.7482755282603273, ce=9.220679134403893
Local test acc @ epoch 14: 0.8498
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 1.072882923836005e-06
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.38 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=8.96989183907115, ce=9.969010534636471
Local test acc @ epoch 14: 0.5092
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 1.0728828101491672e-06
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.22 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=9.294208905018797, ce=9.714319154756879
Local test acc @ epoch 14: 0.5092
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 5.960462203802308e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.34 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=9.111990123713783, ce=8.812112292018506
Local test acc @ epoch 14: 0.5092
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 2.2649712718703086e-06
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.36 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=8.550283127968465, ce=10.161844494145944
Local test acc @ epoch 14: 0.5092
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 1.0660690069198608
Local loss @ local epoch 1: 0.025863127782940865
Local loss @ local epoch 2: 0.008837147615849972
Local loss @ local epoch 3: 0.0074131372384727
Local loss @ local epoch 4: 0.007868790067732334
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.41 seconds!
[tester] 
SST2Metric: acc=0.7591743119266054, hinge=1.1568316245844605, ce=8.353575290889914
Local test acc @ epoch 14: 0.7592
Global evaluate on test data...
Evaluate data in 82.56 seconds!
[tester] 
SST2Metric: acc=0.9208715596330275, hinge=0.5023995194960078, ce=4.593480637314123
Global test acc : 0.9209
Global prompt norm: 48.906558990478516
Global epoch 15...
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.012692953459918499
Local loss @ local epoch 1: 8.344646857949556e-07
Local loss @ local epoch 2: 5.316715487424517e-06
Local loss @ local epoch 3: 2.2744676243746653e-05
Local loss @ local epoch 4: 5.2687799325212836e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.37 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=5.418695931040912, ce=10.434829020718915
Local test acc @ epoch 15: 0.5092
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.24293147027492523
Local loss @ local epoch 1: 4.9439124268246815e-05
Local loss @ local epoch 2: 0.0002519148401916027
Local loss @ local epoch 3: 0.0005875636707060039
Local loss @ local epoch 4: 0.0007011862471699715
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.45 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=3.3077816930385904, ce=9.220748258293222
Local test acc @ epoch 15: 0.5092
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0009528869413770735
Local loss @ local epoch 1: 5.443675036076456e-05
Local loss @ local epoch 2: 4.229616024531424e-05
Local loss @ local epoch 3: 1.160290867119329e-05
Local loss @ local epoch 4: 1.4886798858642578
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.45 seconds!
[tester] 
SST2Metric: acc=0.8956422018348624, hinge=1.0111547128869853, ce=5.835998053944439
Local test acc @ epoch 15: 0.8956
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 1.3053308975941036e-05
Local loss @ local epoch 1: 3.516663809932652e-06
Local loss @ local epoch 2: 3.263187682023272e-05
Local loss @ local epoch 3: 0.014488253742456436
Local loss @ local epoch 4: 0.13952119648456573
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.36 seconds!
[tester] 
SST2Metric: acc=0.8543577981651376, hinge=0.7987094820912825, ce=8.19055768546708
Local test acc @ epoch 15: 0.8544
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0005915109068155289
Local loss @ local epoch 1: 1.3709059203392826e-06
Local loss @ local epoch 2: 1.0251944331685081e-05
Local loss @ local epoch 3: 2.2262071070144884e-05
Local loss @ local epoch 4: 1.7404387108399533e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.4 seconds!
[tester] 
SST2Metric: acc=0.5607798165137615, hinge=3.7566571339554744, ce=7.411978314775939
Local test acc @ epoch 15: 0.5608
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0001590419706190005
Local loss @ local epoch 1: 1.370892277918756e-05
Local loss @ local epoch 2: 1.0460527846589684e-05
Local loss @ local epoch 3: 2.533193537601619e-06
Local loss @ local epoch 4: 2.74180911219446e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.2 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=6.32102439819126, ce=8.543780020617564
Local test acc @ epoch 15: 0.5092
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 4.1781182517297566e-05
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.9802320611338473e-08
Local loss @ local epoch 4: 1.4901159772762185e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.62 seconds!
[tester] 
SST2Metric: acc=0.5791284403669725, hinge=5.304984439950471, ce=6.834219642735403
Local test acc @ epoch 15: 0.5791
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 8.395354961976409e-05
Local loss @ local epoch 1: 0.03544863313436508
Local loss @ local epoch 2: 0.06331019103527069
Local loss @ local epoch 3: 0.04107959195971489
Local loss @ local epoch 4: 0.029895275831222534
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.29 seconds!
[tester] 
SST2Metric: acc=0.4908256880733945, hinge=2.1784872915766655, ce=11.081925295908517
Local test acc @ epoch 15: 0.4908
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0923856794834137
Local loss @ local epoch 1: 1.600370706000831e-05
Local loss @ local epoch 2: 0.0001598147937329486
Local loss @ local epoch 3: 0.0009353223140351474
Local loss @ local epoch 4: 0.0007840482285246253
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.15 seconds!
[tester] 
SST2Metric: acc=0.5653669724770642, hinge=2.785254300734319, ce=10.259508509154713
Local test acc @ epoch 15: 0.5654
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0647696927189827
Local loss @ local epoch 1: 0.030528822913765907
Local loss @ local epoch 2: 0.005207377951592207
Local loss @ local epoch 3: 1.3708019256591797
Local loss @ local epoch 4: 0.019289521500468254
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.34 seconds!
[tester] 
SST2Metric: acc=0.6754587155963303, hinge=1.3023402480357285, ce=11.180287553629745
Local test acc @ epoch 15: 0.6755
Global evaluate on test data...
Evaluate data in 82.36 seconds!
[tester] 
SST2Metric: acc=0.7568807339449541, hinge=2.1609792490617945, ce=6.725922932318591
Global test acc : 0.7569
Global prompt norm: 48.281341552734375
Global epoch 16...
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 2.2649737729807384e-06
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.34 seconds!
[tester] 
SST2Metric: acc=0.6020642201834863, hinge=6.313049696454215, ce=6.616524782202659
Local test acc @ epoch 16: 0.6021
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.02985008992254734
Local loss @ local epoch 1: 0.029579391703009605
Local loss @ local epoch 2: 0.002138750860467553
Local loss @ local epoch 3: 0.000420386902987957
Local loss @ local epoch 4: 0.0002197588182752952
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.42 seconds!
[tester] 
SST2Metric: acc=0.7786697247706422, hinge=1.2886975104108862, ce=10.299578981662016
Local test acc @ epoch 16: 0.7787
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 2.1159619336685864e-06
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.49 seconds!
[tester] 
SST2Metric: acc=0.6192660550458715, hinge=5.828922939409903, ce=7.065104140054196
Local test acc @ epoch 16: 0.6193
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 1.519917191217246e-06
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.47 seconds!
[tester] 
SST2Metric: acc=0.6926605504587156, hinge=4.664723967740295, ce=5.700469062415832
Local test acc @ epoch 16: 0.6927
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.001324677374213934
Local loss @ local epoch 1: 3.5084911360172555e-05
Local loss @ local epoch 2: 9.549953392706811e-05
Local loss @ local epoch 3: 2.974188100779429e-05
Local loss @ local epoch 4: 1.0967145499307662e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.38 seconds!
[tester] 
SST2Metric: acc=0.8830275229357798, hinge=1.0538722522761843, ce=2.5148593099839096
Local test acc @ epoch 16: 0.883
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 2.4795494937279727e-06
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.36 seconds!
[tester] 
SST2Metric: acc=0.6490825688073395, hinge=5.39962052916168, ce=6.678380539657873
Local test acc @ epoch 16: 0.6491
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 2.5629958599893143e-06
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.3 seconds!
[tester] 
SST2Metric: acc=0.6020642201834863, hinge=5.918865505708467, ce=6.564585889151337
Local test acc @ epoch 16: 0.6021
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 2.92062213702593e-06
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.32 seconds!
[tester] 
SST2Metric: acc=0.5424311926605505, hinge=7.28145686202093, ce=8.017748314306276
Local test acc @ epoch 16: 0.5424
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.1580950766801834
Local loss @ local epoch 1: 0.12930229306221008
Local loss @ local epoch 2: 0.007128506898880005
Local loss @ local epoch 3: 0.0014594837557524443
Local loss @ local epoch 4: 0.0009417620021849871
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.33 seconds!
[tester] 
SST2Metric: acc=0.9128440366972477, hinge=0.5181858160900413, ce=8.180104185681824
Local test acc @ epoch 16: 0.9128
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 1.479531168937683
Local loss @ local epoch 1: 0.003858941374346614
Local loss @ local epoch 2: 0.02084602415561676
Local loss @ local epoch 3: 0.01063549891114235
Local loss @ local epoch 4: 0.006056137382984161
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.38 seconds!
[tester] 
SST2Metric: acc=0.8830275229357798, hinge=0.5402651630136945, ce=9.44645380317618
Local test acc @ epoch 16: 0.883
Global evaluate on test data...
Evaluate data in 82.32 seconds!
[tester] 
SST2Metric: acc=0.9185779816513762, hinge=0.5922765193182394, ce=4.36821471660509
Global test acc : 0.9186
Global prompt norm: 47.753273010253906
Global epoch 17...
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.49068301916122437
Local loss @ local epoch 1: 5.394183972384781e-06
Local loss @ local epoch 2: 0.00010736297554103658
Local loss @ local epoch 3: 0.0004155591013841331
Local loss @ local epoch 4: 0.000673350878059864
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.56 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=3.777629914086893, ce=12.394856190462725
Local test acc @ epoch 17: 0.5092
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 3.1468382076127455e-05
Local loss @ local epoch 1: 4.112706392334076e-06
Local loss @ local epoch 2: 8.404124855587725e-06
Local loss @ local epoch 3: 1.251696403414826e-06
Local loss @ local epoch 4: 3.337842144901515e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.3 seconds!
[tester] 
SST2Metric: acc=0.8291284403669725, hinge=2.372940955358908, ce=4.396889969843243
Local test acc @ epoch 17: 0.8291
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.00041598480311222374
Local loss @ local epoch 1: 0.18738816678524017
Local loss @ local epoch 2: 0.00024670883431099355
Local loss @ local epoch 3: 2.915351615229156e-05
Local loss @ local epoch 4: 5.537454489967786e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.27 seconds!
[tester] 
SST2Metric: acc=0.8325688073394495, hinge=1.3467922303654731, ce=3.0751454862979575
Local test acc @ epoch 17: 0.8326
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 7.152553962441743e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.28 seconds!
[tester] 
SST2Metric: acc=0.8990825688073395, hinge=1.0395157244227349, ce=3.158084835481206
Local test acc @ epoch 17: 0.8991
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 1.6235449314117432
Local loss @ local epoch 1: 0.0023609960917383432
Local loss @ local epoch 2: 0.7553894519805908
Local loss @ local epoch 3: 0.4515535235404968
Local loss @ local epoch 4: 0.4312118887901306
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.22 seconds!
[tester] 
SST2Metric: acc=0.4896788990825688, hinge=1.9926666076030206, ce=12.227301921319524
Local test acc @ epoch 17: 0.4897
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 3.337535235914402e-05
Local loss @ local epoch 1: 1.2775155482813716e-05
Local loss @ local epoch 2: 1.9807435819529928e-05
Local loss @ local epoch 3: 1.9868213740892315e-08
Local loss @ local epoch 4: 3.973642748178463e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.37 seconds!
[tester] 
SST2Metric: acc=0.9025229357798165, hinge=1.438136370903855, ce=3.040865141317385
Local test acc @ epoch 17: 0.9025
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 9.149234756478108e-06
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 5.9604641222676946e-08
Local loss @ local epoch 3: 2.6822084464583895e-07
Local loss @ local epoch 4: 5.066393100605637e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.34 seconds!
[tester] 
SST2Metric: acc=0.5275229357798165, hinge=5.406748387791695, ce=8.666721365867405
Local test acc @ epoch 17: 0.5275
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 1.6539763237233274e-05
Local loss @ local epoch 1: 1.1920927533992653e-07
Local loss @ local epoch 2: 2.235169858977315e-06
Local loss @ local epoch 3: 1.7285325384364114e-06
Local loss @ local epoch 4: 3.8743007735320134e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.36 seconds!
[tester] 
SST2Metric: acc=0.5103211009174312, hinge=6.810873784056497, ce=9.276019636644136
Local test acc @ epoch 17: 0.5103
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 7.39087454348919e-06
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.7881392011531716e-07
Local loss @ local epoch 3: 7.74860041019565e-07
Local loss @ local epoch 4: 7.450577186318696e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.48 seconds!
[tester] 
SST2Metric: acc=0.5389908256880734, hinge=5.376812888941633, ce=8.710019540349277
Local test acc @ epoch 17: 0.539
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 7.414755145873642e-06
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.384185648907078e-08
Local loss @ local epoch 3: 2.622603858526418e-07
Local loss @ local epoch 4: 4.7683701609457785e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.39 seconds!
[tester] 
SST2Metric: acc=0.5974770642201835, hinge=4.556008930053186, ce=8.367424365577348
Local test acc @ epoch 17: 0.5975
Global evaluate on test data...
Evaluate data in 82.48 seconds!
[tester] 
SST2Metric: acc=0.9094036697247706, hinge=1.1538924632269307, ce=3.193312422944865
Global test acc : 0.9094
Global prompt norm: 48.29828643798828
Global epoch 18...
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 2.3841853646899835e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.48 seconds!
[tester] 
SST2Metric: acc=0.8577981651376146, hinge=2.90671694934915, ce=4.280703333539701
Local test acc @ epoch 18: 0.8578
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.036396801471710205
Local loss @ local epoch 1: 0.0015045831678435206
Local loss @ local epoch 2: 0.9114314317703247
Local loss @ local epoch 3: 0.0014221438905224204
Local loss @ local epoch 4: 0.004554173443466425
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.37 seconds!
[tester] 
SST2Metric: acc=0.8188073394495413, hinge=0.9532977111569239, ce=9.574058611458595
Local test acc @ epoch 18: 0.8188
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 2.3841852225814364e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.31 seconds!
[tester] 
SST2Metric: acc=0.8130733944954128, hinge=3.5222518061279158, ce=5.688529056146605
Local test acc @ epoch 18: 0.8131
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 1.1920927533992653e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.54 seconds!
[tester] 
SST2Metric: acc=0.8646788990825688, hinge=2.602703531674289, ce=5.330388237576966
Local test acc @ epoch 18: 0.8647
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 5.960463766996327e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.34 seconds!
[tester] 
SST2Metric: acc=0.8681192660550459, hinge=2.013591490070754, ce=4.933077530029717
Local test acc @ epoch 18: 0.8681
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 8.558254194213077e-05
Local loss @ local epoch 1: 0.0031731268391013145
Local loss @ local epoch 2: 0.03733721002936363
Local loss @ local epoch 3: 0.01625008136034012
Local loss @ local epoch 4: 0.0059094722382724285
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.24 seconds!
[tester] 
SST2Metric: acc=0.8761467889908257, hinge=0.679111073460054, ce=6.793892982902877
Local test acc @ epoch 18: 0.8761
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 9.238472557626665e-06
Local loss @ local epoch 1: 7.94728478581419e-08
Local loss @ local epoch 2: 2.7815497105621034e-07
Local loss @ local epoch 3: 4.967052404936112e-07
Local loss @ local epoch 4: 3.178913630108582e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.43 seconds!
[tester] 
SST2Metric: acc=0.8887614678899083, hinge=1.2679143608163257, ce=2.854047019547279
Local test acc @ epoch 18: 0.8888
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 8.046615107559774e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.24 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=8.834435279216242, ce=9.922974131522922
Local test acc @ epoch 18: 0.5092
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 4.768370942542788e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.4 seconds!
[tester] 
SST2Metric: acc=0.8841743119266054, hinge=1.7073588349403592, ce=5.4849184346855235
Local test acc @ epoch 18: 0.8842
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 6.416200631065294e-05
Local loss @ local epoch 1: 2.18550312069965e-07
Local loss @ local epoch 2: 8.543326543986041e-07
Local loss @ local epoch 3: 1.8278724382980727e-06
Local loss @ local epoch 4: 2.7616733859758824e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.28 seconds!
[tester] 
SST2Metric: acc=0.838302752293578, hinge=1.8295256511880718, ce=6.0871756754883934
Local test acc @ epoch 18: 0.8383
Global evaluate on test data...
Evaluate data in 82.32 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.6788992920053114, ce=3.942139765538207
Global test acc : 0.9415
Global prompt norm: 51.259063720703125
Global epoch 19...
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 4.569685359001596e-07
Local loss @ local epoch 1: 5.9604641222676946e-08
Local loss @ local epoch 2: 1.9868213740892315e-08
Local loss @ local epoch 3: 1.9868213740892315e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.29 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.8459267304577959, ce=4.248050810000218
Local test acc @ epoch 19: 0.9415
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 2.3841850804728892e-07
Local loss @ local epoch 1: 1.9868213740892315e-08
Local loss @ local epoch 2: 1.9868213740892315e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.28 seconds!
[tester] 
SST2Metric: acc=0.9461009174311926, hinge=0.8150904249707493, ce=4.026521337141684
Local test acc @ epoch 19: 0.9461
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 3.5762778338721546e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.34 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8027432689426142, ce=7.291676591295714
Local test acc @ epoch 19: 0.9427
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 9.536742595628311e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.3 seconds!
[tester] 
SST2Metric: acc=0.948394495412844, hinge=0.7661321813907098, ce=4.596245450711032
Local test acc @ epoch 19: 0.9484
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 1.1920927533992653e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.5 seconds!
[tester] 
SST2Metric: acc=0.9461009174311926, hinge=0.7721519962363287, ce=3.925097266468433
Local test acc @ epoch 19: 0.9461
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.41 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.9866418909589085, ce=2.7676747217090854
Local test acc @ epoch 19: 0.9404
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 3.4059758036164567e-07
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.52 seconds!
[tester] 
SST2Metric: acc=0.8600917431192661, hinge=2.420082026665364, ce=3.4464592441506343
Local test acc @ epoch 19: 0.8601
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 8.940696005765858e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.36 seconds!
[tester] 
SST2Metric: acc=0.9461009174311926, hinge=0.7759421404895432, ce=4.12686245375817
Local test acc @ epoch 19: 0.9461
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 8.447533036815003e-05
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.7881392011531716e-07
Local loss @ local epoch 3: 1.4007081290401402e-06
Local loss @ local epoch 4: 3.486865352897439e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.35 seconds!
[tester] 
SST2Metric: acc=0.5103211009174312, hinge=6.277900543781596, ce=11.33496509779484
Local test acc @ epoch 19: 0.5103
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 2.6822084464583895e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.35 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8210782239196497, ce=5.947271657646249
Local test acc @ epoch 19: 0.9427
Global evaluate on test data...
Evaluate data in 82.27 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9183036914659203, ce=3.853370909297138
Global test acc : 0.9427
Global prompt norm: 52.33803939819336
Global epoch 20...
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.31 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9474727861378172, ce=4.271808138681115
Local test acc @ epoch 20: 0.9427
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.18 seconds!
[tester] 
SST2Metric: acc=0.9564220183486238, hinge=0.8244445419639622, ce=2.9877089710410583
Local test acc @ epoch 20: 0.9564
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.5 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.963723707636562, ce=4.833794211028913
Local test acc @ epoch 20: 0.9404
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.4 seconds!
[tester] 
SST2Metric: acc=0.9461009174311926, hinge=0.8901502369740687, ce=5.328209310496619
Local test acc @ epoch 20: 0.9461
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.53 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9506726100904133, ce=4.40042231061043
Local test acc @ epoch 20: 0.9427
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.00017591305368114263
Local loss @ local epoch 2: 0.015439004637300968
Local loss @ local epoch 3: 0.07744496315717697
Local loss @ local epoch 4: 0.0018543180776759982
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.55 seconds!
[tester] 
SST2Metric: acc=0.6697247706422018, hinge=2.3576136832937187, ce=7.936473920804645
Local test acc @ epoch 20: 0.6697
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 1.9868213740892315e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.41 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9641231325788235, ce=3.4403856566192905
Local test acc @ epoch 20: 0.9427
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.34 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=0.9645748794625658, ce=4.757885066741103
Local test acc @ epoch 20: 0.9392
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.41 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9527062281556086, ce=4.474282067850096
Local test acc @ epoch 20: 0.9415
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.36 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9490731068707388, ce=4.23517332383252
Local test acc @ epoch 20: 0.9427
Global evaluate on test data...
Evaluate data in 82.4 seconds!
[tester] 
SST2Metric: acc=0.9288990825688074, hinge=1.1472298371682472, ce=3.395096330467714
Global test acc : 0.9289
Global prompt norm: 53.83960723876953
Global epoch 21...
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.54 seconds!
[tester] 
SST2Metric: acc=0.9311926605504587, hinge=1.0898524550122952, ce=4.085702900492817
Local test acc @ epoch 21: 0.9312
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.52 seconds!
[tester] 
SST2Metric: acc=0.9346330275229358, hinge=1.0716396138208721, ce=10.250518965064932
Local test acc @ epoch 21: 0.9346
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.43 seconds!
[tester] 
SST2Metric: acc=0.930045871559633, hinge=1.1321910953302996, ce=4.303405190826556
Local test acc @ epoch 21: 0.93
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.35 seconds!
[tester] 
SST2Metric: acc=0.9311926605504587, hinge=1.0972023803159732, ce=4.904754144336105
Local test acc @ epoch 21: 0.9312
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.46 seconds!
[tester] 
SST2Metric: acc=0.930045871559633, hinge=1.137650202720537, ce=11.429290386514927
Local test acc @ epoch 21: 0.93
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.42 seconds!
[tester] 
SST2Metric: acc=0.930045871559633, hinge=1.100696221950951, ce=4.096998744054672
Local test acc @ epoch 21: 0.93
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.36 seconds!
[tester] 
SST2Metric: acc=0.930045871559633, hinge=1.104998590749338, ce=4.134002366197219
Local test acc @ epoch 21: 0.93
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.39 seconds!
[tester] 
SST2Metric: acc=0.9288990825688074, hinge=1.1053491059793246, ce=4.057176259679532
Local test acc @ epoch 21: 0.9289
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.33 seconds!
[tester] 
SST2Metric: acc=0.9311926605504587, hinge=1.0894991553157842, ce=4.543733109027968
Local test acc @ epoch 21: 0.9312
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.32 seconds!
[tester] 
SST2Metric: acc=0.930045871559633, hinge=1.1266766237009556, ce=4.541966783891031
Local test acc @ epoch 21: 0.93
Global evaluate on test data...
Evaluate data in 82.53 seconds!
[tester] 
SST2Metric: acc=0.9311926605504587, hinge=1.1244141664526879, ce=5.4142533682901925
Global test acc : 0.9312
Global prompt norm: 53.87974548339844
Global epoch 22...
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.34 seconds!
[tester] 
SST2Metric: acc=0.9323394495412844, hinge=1.0875551768945992, ce=6.248017153608689
Local test acc @ epoch 22: 0.9323
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.3 seconds!
[tester] 
SST2Metric: acc=0.9346330275229358, hinge=1.0807277844586503, ce=6.384109689555037
Local test acc @ epoch 22: 0.9346
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.7029897492193413e-08
Local loss @ local epoch 3: 1.7029897492193413e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.37 seconds!
[tester] 
SST2Metric: acc=0.9323394495412844, hinge=1.0627757753800908, ce=14.546017148079128
Local test acc @ epoch 22: 0.9323
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.43 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.0282295012692793, ce=12.05370394680478
Local test acc @ epoch 22: 0.9381
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.41 seconds!
[tester] 
SST2Metric: acc=0.9323394495412844, hinge=1.1035948040288523, ce=6.5634725640673155
Local test acc @ epoch 22: 0.9323
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.48 seconds!
[tester] 
SST2Metric: acc=0.9346330275229358, hinge=1.0701914905408108, ce=6.808929701463891
Local test acc @ epoch 22: 0.9346
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.43 seconds!
[tester] 
SST2Metric: acc=0.9323394495412844, hinge=1.0945757984294804, ce=7.069509151878707
Local test acc @ epoch 22: 0.9323
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.51 seconds!
[tester] 
SST2Metric: acc=0.9334862385321101, hinge=1.0900834030514464, ce=6.193538416416273
Local test acc @ epoch 22: 0.9335
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.37 seconds!
[tester] 
SST2Metric: acc=0.9323394495412844, hinge=1.0686936459136664, ce=7.433080100138253
Local test acc @ epoch 22: 0.9323
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.38 seconds!
[tester] 
SST2Metric: acc=0.9323394495412844, hinge=1.079957183894761, ce=6.278231126452805
Local test acc @ epoch 22: 0.9323
Global evaluate on test data...
Evaluate data in 82.46 seconds!
[tester] 
SST2Metric: acc=0.9323394495412844, hinge=1.0997909003988318, ce=7.9397065923848285
Global test acc : 0.9323
Global prompt norm: 53.899173736572266
Global epoch 23...
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.27 seconds!
[tester] 
SST2Metric: acc=0.9334862385321101, hinge=1.0609747844004849, ce=9.739496226704448
Local test acc @ epoch 23: 0.9335
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.66 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.0284906893695167, ce=9.503060686478921
Local test acc @ epoch 23: 0.9358
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.18 seconds!
[tester] 
SST2Metric: acc=0.9346330275229358, hinge=1.0445363789523414, ce=9.302195339027895
Local test acc @ epoch 23: 0.9346
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.44 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.0118365700638623, ce=9.985676494213418
Local test acc @ epoch 23: 0.9369
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.35 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.0453775341904492, ce=9.292167352973868
Local test acc @ epoch 23: 0.9358
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.4 seconds!
[tester] 
SST2Metric: acc=0.9346330275229358, hinge=1.040530638136995, ce=10.5846377381491
Local test acc @ epoch 23: 0.9346
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.7029897492193413e-08
Local loss @ local epoch 2: 1.7029897492193413e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.37 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.0427460528294974, ce=15.62893870992398
Local test acc @ epoch 23: 0.9369
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.6 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.005549789431992, ce=10.930725815099313
Local test acc @ epoch 23: 0.9358
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.024001494186734, ce=9.498793540744607
Local test acc @ epoch 23: 0.9358
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.49 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.0074383668396452, ce=13.315159220214284
Local test acc @ epoch 23: 0.9381
Global evaluate on test data...
Evaluate data in 82.48 seconds!
[tester] 
SST2Metric: acc=0.9346330275229358, hinge=1.0444291488293114, ce=10.871843075533526
Global test acc : 0.9346
Global prompt norm: 53.93290328979492
Global epoch 24...
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.54 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=0.9127219860706854, ce=14.020640206993173
Local test acc @ epoch 24: 0.9369
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.5 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=0.9293223734295696, ce=13.047785024030492
Local test acc @ epoch 24: 0.9392
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.46 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=0.9168854662037771, ce=13.122807441501443
Local test acc @ epoch 24: 0.9392
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.41 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=0.9492166162630834, ce=12.824973701337061
Local test acc @ epoch 24: 0.9381
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.9868213740892315e-08
Local loss @ local epoch 4: 1.9868213740892315e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.43 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=0.9838899860688306, ce=12.795753951466411
Local test acc @ epoch 24: 0.9381
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.45 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=0.9392980867569599, ce=12.473987421858201
Local test acc @ epoch 24: 0.9392
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.38 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.1103721386795744, ce=14.104388831952296
Local test acc @ epoch 24: 0.9358
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.52 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=0.9721510538814264, ce=13.387113571166992
Local test acc @ epoch 24: 0.9381
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.28 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.0458563030312915, ce=13.955631404841712
Local test acc @ epoch 24: 0.9381
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.33 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=0.9529717077902697, ce=12.732034919458792
Local test acc @ epoch 24: 0.9381
Global evaluate on test data...
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=0.9731537103652954, ce=13.333447473858474
Global test acc : 0.9381
Global prompt norm: 53.97414779663086
Global epoch 25...
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=0.8959284802095606, ce=14.92675112803048
Local test acc @ epoch 25: 0.9392
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.39 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.1840824490293451, ce=9.1266698399815
Local test acc @ epoch 25: 0.9358
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.26 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=0.8729217314938886, ce=15.736205660968746
Local test acc @ epoch 25: 0.9392
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.51 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=0.8955698445302631, ce=14.987051937558235
Local test acc @ epoch 25: 0.9392
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.45 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.9084803358130499, ce=15.929008405142968
Local test acc @ epoch 25: 0.9404
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.57 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.186522513628006, ce=10.8493414100157
Local test acc @ epoch 25: 0.9358
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.42 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.8820108678362785, ce=15.113762391816586
Local test acc @ epoch 25: 0.9404
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.9868213740892315e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.53 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=0.9670907450378488, ce=13.86124385168793
Local test acc @ epoch 25: 0.9392
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.55 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=0.9041101998145428, ce=14.418104792953631
Local test acc @ epoch 25: 0.9392
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.46 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.8796506070215767, ce=15.037981234559226
Local test acc @ epoch 25: 0.9404
Global evaluate on test data...
Evaluate data in 82.52 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=0.9675209740979955, ce=13.686070783422627
Global test acc : 0.9392
Global prompt norm: 54.00223922729492
Global epoch 26...
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.42 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.913201344669412, ce=15.056574707731194
Local test acc @ epoch 26: 0.9415
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.9868213740892315e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.52 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=0.9397560046353471, ce=15.703811864240453
Local test acc @ epoch 26: 0.9392
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.5 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9085911080377911, ce=14.960237739283011
Local test acc @ epoch 26: 0.9415
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.49 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.9206786751747131, ce=14.974444730566182
Local test acc @ epoch 26: 0.9404
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.62 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.9306020583581487, ce=14.468966326582322
Local test acc @ epoch 26: 0.9404
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.47 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=0.9327604196487217, ce=15.690250947934771
Local test acc @ epoch 26: 0.9392
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.26 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.9222382924972324, ce=14.885609250549876
Local test acc @ epoch 26: 0.9404
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.34 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.901089103943711, ce=15.646646105915035
Local test acc @ epoch 26: 0.9415
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.45 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9840273583700897, ce=17.209280101531142
Local test acc @ epoch 26: 0.9415
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.35 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.1020425229991249, ce=16.512937309545116
Local test acc @ epoch 26: 0.9392
Global evaluate on test data...
Evaluate data in 82.4 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=0.9534588773316199, ce=15.62753816482124
Global test acc : 0.9392
Global prompt norm: 54.02006149291992
Global epoch 27...
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.6 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9082886675082216, ce=16.694811059794294
Local test acc @ epoch 27: 0.9415
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.42 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.0430568576952732, ce=16.547867897453656
Local test acc @ epoch 27: 0.9415
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.45 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.9192993498723442, ce=17.784974448177792
Local test acc @ epoch 27: 0.9404
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.53 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9021820333025871, ce=16.724342004968484
Local test acc @ epoch 27: 0.9415
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.51 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9201338028689043, ce=16.188065756351577
Local test acc @ epoch 27: 0.9415
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.9868213740892315e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.43 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9472188708979056, ce=16.809247725600496
Local test acc @ epoch 27: 0.9415
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.4 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.8955968880872114, ce=16.606533837974617
Local test acc @ epoch 27: 0.9415
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.46 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.1270874481682385, ce=16.426421462942702
Local test acc @ epoch 27: 0.9392
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.4 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.891506916886076, ce=17.147125620360768
Local test acc @ epoch 27: 0.9415
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.56 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9098262141603942, ce=16.650548304986515
Local test acc @ epoch 27: 0.9415
Global evaluate on test data...
Evaluate data in 82.52 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9480579643074526, ce=16.841377599523703
Global test acc : 0.9415
Global prompt norm: 54.041141510009766
Global epoch 28...
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.3 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.91571145866989, ce=17.25045112294888
Local test acc @ epoch 28: 0.9415
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.44 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9837522036438688, ce=18.92618615036711
Local test acc @ epoch 28: 0.9427
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.38 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8967231205844004, ce=17.726057026364387
Local test acc @ epoch 28: 0.9438
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 1.7029897492193413e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.49 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.1362251863567108, ce=16.833666687711663
Local test acc @ epoch 28: 0.9404
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.44 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9011093542116497, ce=17.7380663495545
Local test acc @ epoch 28: 0.9415
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.4 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9151312594020039, ce=18.91694130153831
Local test acc @ epoch 28: 0.9415
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.39 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9037117088606598, ce=17.72746660949987
Local test acc @ epoch 28: 0.9415
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.61 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8871026033655219, ce=17.60563610671857
Local test acc @ epoch 28: 0.9427
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.9868213740892315e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.26 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9304778871186282, ce=18.215040521884184
Local test acc @ epoch 28: 0.9415
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.47 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.8850250555834639, ce=18.099607520147202
Local test acc @ epoch 28: 0.9415
Global evaluate on test data...
Evaluate data in 82.34 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9443489247505817, ce=18.049061906447104
Global test acc : 0.9415
Global prompt norm: 54.047698974609375
Global epoch 29...
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.56 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8912181165240226, ce=18.902135639015686
Local test acc @ epoch 29: 0.9438
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.49 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=1.0100354229638335, ce=18.736723803598945
Local test acc @ epoch 29: 0.9427
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.37 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8770741727374015, ce=19.16951412235925
Local test acc @ epoch 29: 0.9438
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.6 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9076116150672283, ce=18.444056589669042
Local test acc @ epoch 29: 0.9427
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.41 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8895674014310224, ce=18.875664684750618
Local test acc @ epoch 29: 0.9438
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.36 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8775395220572796, ce=18.76625111781129
Local test acc @ epoch 29: 0.9438
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.34 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8964064274359187, ce=18.864644689297457
Local test acc @ epoch 29: 0.9438
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.43 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9042117333193438, ce=19.82954125010639
Local test acc @ epoch 29: 0.9427
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.37 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9104723711626246, ce=20.25119732498029
Local test acc @ epoch 29: 0.9415
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.32 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.047503847594655, ce=20.77337030533257
Local test acc @ epoch 29: 0.9392
Global evaluate on test data...
Evaluate data in 82.48 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9257475542365958, ce=19.347471989622903
Global test acc : 0.9415
Global prompt norm: 54.052310943603516
Global epoch 30...
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.17 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.1754010270494935, ce=17.761061029696684
Local test acc @ epoch 30: 0.9392
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.22 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8720421769203396, ce=20.12118042062182
Local test acc @ epoch 30: 0.9438
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.9868213740892315e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.56 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9167434764564584, ce=21.145141426576387
Local test acc @ epoch 30: 0.9427
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.38 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8770142290570321, ce=20.08794445072839
Local test acc @ epoch 30: 0.9438
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.69 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.8608307007255904, ce=19.966427024351347
Local test acc @ epoch 30: 0.945
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.61 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.1653662384103198, ce=14.49131210572129
Local test acc @ epoch 30: 0.9404
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.9868213740892315e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.47 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9086763311963563, ce=20.438900028893705
Local test acc @ epoch 30: 0.9415
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.31 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8727339571769085, ce=20.07439062136029
Local test acc @ epoch 30: 0.9438
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.22 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.8576498578447814, ce=20.295925052887803
Local test acc @ epoch 30: 0.945
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.32 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8870693729558122, ce=19.684299398999695
Local test acc @ epoch 30: 0.9438
Global evaluate on test data...
Evaluate data in 82.38 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9526553285231284, ce=19.302035322976767
Global test acc : 0.9427
Global prompt norm: 54.06422424316406
Global epoch 31...
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.43 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.8829579451762208, ce=20.21901909364473
Local test acc @ epoch 31: 0.945
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.39 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8968268917241228, ce=20.296621480119338
Local test acc @ epoch 31: 0.9438
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.54 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8750747945330558, ce=20.650894987473794
Local test acc @ epoch 31: 0.9438
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.45 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.905123772971127, ce=20.854159451405938
Local test acc @ epoch 31: 0.9438
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.0824537211601888, ce=21.937844757640033
Local test acc @ epoch 31: 0.9381
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.27 seconds!
[tester] 
SST2Metric: acc=0.9461009174311926, hinge=0.9113975227425951, ce=19.871655052955
Local test acc @ epoch 31: 0.9461
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.28 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.8941883745543454, ce=20.366325238429077
Local test acc @ epoch 31: 0.945
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.26 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9168061203912857, ce=21.11067329196755
Local test acc @ epoch 31: 0.9427
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.38 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.9003887570232426, ce=20.268424147859626
Local test acc @ epoch 31: 0.945
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.36 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.0132066930105927, ce=20.89943877053917
Local test acc @ epoch 31: 0.9438
Global evaluate on test data...
Evaluate data in 82.4 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9269380821000546, ce=20.72790637585001
Global test acc : 0.9438
Global prompt norm: 54.078948974609375
Global epoch 32...
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.26 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8609510211769594, ce=21.71555039642054
Local test acc @ epoch 32: 0.9438
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.37 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8850233379853975, ce=22.150682151864427
Local test acc @ epoch 32: 0.9438
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.32 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.8787562956503772, ce=21.483191533919868
Local test acc @ epoch 32: 0.945
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.4 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.8747230604154255, ce=21.57680534222804
Local test acc @ epoch 32: 0.945
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.4 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.0482336042124196, ce=20.251762722610334
Local test acc @ epoch 32: 0.945
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.4 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8882151557764876, ce=21.145556388644998
Local test acc @ epoch 32: 0.9438
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.48 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8743192394939038, ce=21.37733538216407
Local test acc @ epoch 32: 0.9427
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.29 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8793106505630213, ce=21.520526885986328
Local test acc @ epoch 32: 0.9438
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.2 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.2124171617927901, ce=19.24641750930646
Local test acc @ epoch 32: 0.9381
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.32 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8954012197092038, ce=22.74910499852732
Local test acc @ epoch 32: 0.9427
Global evaluate on test data...
Evaluate data in 82.4 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.9329998154158986, ce=21.490398756954647
Global test acc : 0.945
Global prompt norm: 54.089969635009766
Global epoch 33...
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.38 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8901198271217696, ce=22.870345631870656
Local test acc @ epoch 33: 0.9438
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.62 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8988106075776826, ce=23.368338978618656
Local test acc @ epoch 33: 0.9438
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.52 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8953860932533894, ce=21.996627825115798
Local test acc @ epoch 33: 0.9438
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.35 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8675314581722294, ce=22.547276768115683
Local test acc @ epoch 33: 0.9427
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.37 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.8827593917146735, ce=22.40034974824398
Local test acc @ epoch 33: 0.945
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.56 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8815544974913291, ce=22.209777377067358
Local test acc @ epoch 33: 0.9427
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.27 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.1323853917078142, ce=21.829442872913607
Local test acc @ epoch 33: 0.9392
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.44 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.0595706012270867, ce=20.503615213096687
Local test acc @ epoch 33: 0.945
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.45 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.887935065348214, ce=22.29279243399244
Local test acc @ epoch 33: 0.945
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.41 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8871184937450864, ce=22.329908738442516
Local test acc @ epoch 33: 0.9438
Global evaluate on test data...
Evaluate data in 82.36 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9267303954570665, ce=22.390853444370656
Global test acc : 0.9438
Global prompt norm: 54.096248626708984
Global epoch 34...
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.49 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8725565671920776, ce=23.313552348985585
Local test acc @ epoch 34: 0.9427
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.5 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8960038467284737, ce=24.319886898775714
Local test acc @ epoch 34: 0.9438
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.29 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.1365286133704928, ce=22.504575816863174
Local test acc @ epoch 34: 0.9404
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.35 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8921398766543887, ce=23.09592950453452
Local test acc @ epoch 34: 0.9427
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.27 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9708286994094149, ce=24.26181583229555
Local test acc @ epoch 34: 0.9415
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.48 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8977690825768567, ce=22.866802968016458
Local test acc @ epoch 34: 0.9427
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.3 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.8928836266928857, ce=23.73200171584383
Local test acc @ epoch 34: 0.9415
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.48 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8873473569887493, ce=23.193875111571145
Local test acc @ epoch 34: 0.9427
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.25 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.8909932014045365, ce=23.132408807037073
Local test acc @ epoch 34: 0.9415
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.41 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8861852107791726, ce=23.03049831215395
Local test acc @ epoch 34: 0.9427
Global evaluate on test data...
Evaluate data in 82.4 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9187242437940125, ce=23.521084339246837
Global test acc : 0.9438
Global prompt norm: 54.097537994384766
Global epoch 35...
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.29 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.2323524481659636, ce=20.691566449786546
Local test acc @ epoch 35: 0.9392
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.23 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8862702343442025, ce=24.226960313429526
Local test acc @ epoch 35: 0.9427
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.42 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.888210891583644, ce=25.623569383533724
Local test acc @ epoch 35: 0.9427
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.38 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8922867720280219, ce=23.987718354671372
Local test acc @ epoch 35: 0.9427
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.46 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8870736863635001, ce=24.934050026289913
Local test acc @ epoch 35: 0.9427
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.48 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.8818726703661297, ce=24.10886859018868
Local test acc @ epoch 35: 0.9404
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.43 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8823894371680163, ce=24.27010569441209
Local test acc @ epoch 35: 0.9427
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.24 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.8673290681401524, ce=24.337130590316352
Local test acc @ epoch 35: 0.9415
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.49 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.0803883239763592, ce=21.79026836430261
Local test acc @ epoch 35: 0.9438
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.19 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.8867904593091492, ce=24.180948502426848
Local test acc @ epoch 35: 0.9415
Global evaluate on test data...
Evaluate data in 82.42 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9394556644859664, ce=24.062260321520885
Global test acc : 0.9438
Global prompt norm: 54.10877227783203
Global epoch 36...
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.41 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9031735625835734, ce=25.83396780381509
Local test acc @ epoch 36: 0.9427
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.28 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.894266772707668, ce=24.982973763702113
Local test acc @ epoch 36: 0.9427
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.24 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=0.9219944717687204, ce=28.656197994127186
Local test acc @ epoch 36: 0.9392
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.33 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.1116291317371054, ce=24.996316612313645
Local test acc @ epoch 36: 0.9404
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.26 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9056145499605651, ce=24.70314104622657
Local test acc @ epoch 36: 0.9415
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.41 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.8728952079737952, ce=25.12289260724269
Local test acc @ epoch 36: 0.9415
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.59 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8984263905691444, ce=24.88947107157576
Local test acc @ epoch 36: 0.9427
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.43 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.8990220225185429, ce=24.93237434177224
Local test acc @ epoch 36: 0.9415
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.28 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8884334082997173, ce=24.833527433762857
Local test acc @ epoch 36: 0.9427
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.4 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.8968090223609855, ce=25.4089972819757
Local test acc @ epoch 36: 0.9415
Global evaluate on test data...
Evaluate data in 82.41 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9181378358001009, ce=25.57452877289658
Global test acc : 0.9415
Global prompt norm: 54.09828567504883
Global epoch 37...
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.41 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.8707494232632699, ce=26.15742916142175
Local test acc @ epoch 37: 0.9404
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.48 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.8765642774214438, ce=27.836061670145856
Local test acc @ epoch 37: 0.9415
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.29 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.883735930154083, ce=26.115306416782765
Local test acc @ epoch 37: 0.9415
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.53 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.2426367451291565, ce=18.938978422672378
Local test acc @ epoch 37: 0.9415
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.42 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.8731373132915672, ce=27.15394307057792
Local test acc @ epoch 37: 0.9415
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.39 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.0515642483300025, ce=23.266759119996237
Local test acc @ epoch 37: 0.9404
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.47 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8541842895910281, ce=26.319617805130985
Local test acc @ epoch 37: 0.9427
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.28 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.8740538107145817, ce=26.336824119637864
Local test acc @ epoch 37: 0.9415
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.41 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.8776681959082228, ce=26.26503737913359
Local test acc @ epoch 37: 0.9415
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.39 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.8773438875828314, ce=26.32643633151273
Local test acc @ epoch 37: 0.9415
Global evaluate on test data...
Evaluate data in 82.58 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9440235993184081, ce=25.85352432180982
Global test acc : 0.9415
Global prompt norm: 54.10440444946289
Global epoch 38...
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.38 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.0500298333824227, ce=25.93826472431148
Local test acc @ epoch 38: 0.9369
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.48 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9039432991535292, ce=26.68251979022945
Local test acc @ epoch 38: 0.9415
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.3 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.1427155437819454, ce=26.1841057068711
Local test acc @ epoch 38: 0.9392
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.47 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.8937382227783903, ce=27.441612628621794
Local test acc @ epoch 38: 0.9415
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.35 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9023118751858352, ce=26.71035869843369
Local test acc @ epoch 38: 0.9427
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.49 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9120129554643543, ce=26.52900720298837
Local test acc @ epoch 38: 0.9415
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.37 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8787768576123299, ce=26.909036601355318
Local test acc @ epoch 38: 0.9427
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.36 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.906869666292033, ce=26.673144209275552
Local test acc @ epoch 38: 0.9415
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.47 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8930045235047647, ce=26.654653811673505
Local test acc @ epoch 38: 0.9427
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.4 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9014745699156315, ce=27.945865473616013
Local test acc @ epoch 38: 0.9415
Global evaluate on test data...
Evaluate data in 82.48 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9394494590409305, ce=26.988946319720068
Global test acc : 0.9415
Global prompt norm: 54.09485626220703
Global epoch 39...
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.42 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=1.0147629965335951, ce=26.67379489513712
Local test acc @ epoch 39: 0.9427
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.35 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.8924413613223154, ce=27.818852538362556
Local test acc @ epoch 39: 0.9415
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.39 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8954543553361105, ce=27.829818375613712
Local test acc @ epoch 39: 0.9427
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.42 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.8908504028932764, ce=27.839962670562464
Local test acc @ epoch 39: 0.9415
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.51 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.1493792533874512, ce=27.05886499597392
Local test acc @ epoch 39: 0.9392
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.34 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9007354963810073, ce=27.680549936557036
Local test acc @ epoch 39: 0.9415
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.33 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.8832623652361948, ce=28.540385447510886
Local test acc @ epoch 39: 0.9415
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.38 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8814531149120506, ce=27.75856350540021
Local test acc @ epoch 39: 0.9427
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.39 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.8660174028589092, ce=27.93826286945868
Local test acc @ epoch 39: 0.9415
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.61 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.8912662300494832, ce=29.066766913877714
Local test acc @ epoch 39: 0.9415
Global evaluate on test data...
Evaluate data in 82.51 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9254232065393291, ce=27.995818426849645
Global test acc : 0.9415
Global prompt norm: 54.08669662475586
Global epoch 40...
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.5 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8533748771072528, ce=28.83688277498298
Local test acc @ epoch 40: 0.9438
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.54 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.1106396990084866, ce=23.426524066050117
Local test acc @ epoch 40: 0.9358
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.39 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.262823546698334, ce=23.177194350356356
Local test acc @ epoch 40: 0.9415
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.27 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.8816013117449, ce=28.821700209871345
Local test acc @ epoch 40: 0.9415
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.55 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.8776116655507219, ce=28.81438754020481
Local test acc @ epoch 40: 0.9415
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.54 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8691512269711276, ce=28.723267581484734
Local test acc @ epoch 40: 0.9438
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.53 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.8686371724539941, ce=29.709724496263977
Local test acc @ epoch 40: 0.9404
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.25 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.8871492508354537, ce=28.682559459581288
Local test acc @ epoch 40: 0.9415
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.53 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.8737698191896491, ce=30.30642211984057
Local test acc @ epoch 40: 0.9415
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.37 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8788325458491614, ce=28.808066481844
Local test acc @ epoch 40: 0.9427
Global evaluate on test data...
Evaluate data in 82.27 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9511902091700003, ce=28.243095310456162
Global test acc : 0.9415
Global prompt norm: 54.086021423339844
Global epoch 41...
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.31 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.8730441452166356, ce=29.359145050748772
Local test acc @ epoch 41: 0.945
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.49 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.924204014856881, ce=32.640386966390345
Local test acc @ epoch 41: 0.9415
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.55 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8899191913254764, ce=29.165246701021807
Local test acc @ epoch 41: 0.9438
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.35 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9055082141806227, ce=29.175454375940724
Local test acc @ epoch 41: 0.9415
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.45 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.9012843796966272, ce=29.20027521115924
Local test acc @ epoch 41: 0.9404
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.49 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9009768087929542, ce=29.18152336680561
Local test acc @ epoch 41: 0.9415
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.44 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.8892643779789636, ce=29.86047349282361
Local test acc @ epoch 41: 0.9404
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.43 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.8999404141662317, ce=30.280904454922457
Local test acc @ epoch 41: 0.9415
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.45 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.152757563722243, ce=27.74048119291253
Local test acc @ epoch 41: 0.9404
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.34 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9103703564460125, ce=29.05681037902832
Local test acc @ epoch 41: 0.9415
Global evaluate on test data...
Evaluate data in 82.54 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9239599136037564, ce=29.701154866349807
Global test acc : 0.9415
Global prompt norm: 54.06760025024414
Global epoch 42...
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.37 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.2591458734022367, ce=19.311705038088178
Local test acc @ epoch 42: 0.9415
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.5 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8743434521036411, ce=30.607323987768332
Local test acc @ epoch 42: 0.9427
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.45 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.8644485998591152, ce=32.08384702839982
Local test acc @ epoch 42: 0.9415
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.62 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8620620736288368, ce=30.49626854362838
Local test acc @ epoch 42: 0.9438
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.38 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8448841681174182, ce=30.546775327909977
Local test acc @ epoch 42: 0.9438
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.42 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.871616111982853, ce=30.58398371005277
Local test acc @ epoch 42: 0.9427
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.22 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8708129694702429, ce=30.568630953447535
Local test acc @ epoch 42: 0.9438
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.35 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.858087377810697, ce=31.508752367912084
Local test acc @ epoch 42: 0.9427
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.38 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8800787925720215, ce=30.467302129902972
Local test acc @ epoch 42: 0.9427
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.53 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.1263011693954468, ce=23.948421093302034
Local test acc @ epoch 42: 0.9369
Global evaluate on test data...
Evaluate data in 82.36 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9659963091579052, ce=29.428933747317814
Global test acc : 0.9415
Global prompt norm: 54.0643424987793
Global epoch 43...
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.41 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.1433369369681823, ce=29.626072944851096
Local test acc @ epoch 43: 0.9404
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.55 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9242862233328163, ce=30.353772942079317
Local test acc @ epoch 43: 0.9415
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.35 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9069394999687824, ce=30.42452141998011
Local test acc @ epoch 43: 0.9427
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.39 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8897712515034807, ce=30.624545526067052
Local test acc @ epoch 43: 0.9427
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.44 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9184376034167928, ce=30.4057909589295
Local test acc @ epoch 43: 0.9415
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.49 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9729559005947288, ce=32.28228563781178
Local test acc @ epoch 43: 0.9415
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.37 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.902667533367052, ce=30.987950998708744
Local test acc @ epoch 43: 0.9427
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.4 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9155379916549823, ce=31.341105504867134
Local test acc @ epoch 43: 0.9427
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.44 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9188481689593114, ce=30.367579433896125
Local test acc @ epoch 43: 0.9415
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.36 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9282568747844171, ce=30.26183471329715
Local test acc @ epoch 43: 0.9415
Global evaluate on test data...
Evaluate data in 82.61 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9415213427412401, ce=30.76947852668412
Global test acc : 0.9415
Global prompt norm: 54.046512603759766
Global epoch 44...
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.51 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.8813998283596214, ce=32.87531222772161
Local test acc @ epoch 44: 0.9404
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.44 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8902628706135881, ce=31.672501275298792
Local test acc @ epoch 44: 0.9427
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.4 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8816000234096422, ce=31.79313439185466
Local test acc @ epoch 44: 0.9438
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.39 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8807891421361801, ce=31.762596060376648
Local test acc @ epoch 44: 0.9438
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.28 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.869401089642026, ce=31.74550705655999
Local test acc @ epoch 44: 0.9438
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.28 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8705589333805469, ce=32.419452597241886
Local test acc @ epoch 44: 0.9427
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.33 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.9208385069435889, ce=36.23144849724726
Local test acc @ epoch 44: 0.9404
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.35 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8855375631139912, ce=31.801633134894416
Local test acc @ epoch 44: 0.9427
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.52 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8520606504667789, ce=31.783230020365583
Local test acc @ epoch 44: 0.9438
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.32 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.1678796120739858, ce=29.191196861617062
Local test acc @ epoch 44: 0.9404
Global evaluate on test data...
Evaluate data in 82.26 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9103895086760915, ce=32.32701835282352
Global test acc : 0.9427
Global prompt norm: 54.01217269897461
Global epoch 45...
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.2 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.826933698916654, ce=33.1918524470898
Local test acc @ epoch 45: 0.9438
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.29 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8516111592634008, ce=33.37563999421006
Local test acc @ epoch 45: 0.9438
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.9868213740892315e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.54 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.8937309488244013, ce=33.434522716277236
Local test acc @ epoch 45: 0.9415
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.46 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.1487574041436572, ce=13.164458502323255
Local test acc @ epoch 45: 0.9392
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.51 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8541217878324177, ce=33.3819699243668
Local test acc @ epoch 45: 0.9438
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.3 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8524393379141432, ce=33.32896673569986
Local test acc @ epoch 45: 0.9427
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.9868213740892315e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.38 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9443744410068617, ce=32.63353237537069
Local test acc @ epoch 45: 0.9415
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.17 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.0317007489160661, ce=29.193756505983686
Local test acc @ epoch 45: 0.9438
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.35 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8440002104557982, ce=33.300891648738755
Local test acc @ epoch 45: 0.9427
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.23 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.859109550441077, ce=33.241490827787906
Local test acc @ epoch 45: 0.9438
Global evaluate on test data...
Evaluate data in 82.32 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9807609505609635, ce=30.901517518069767
Global test acc : 0.9415
Global prompt norm: 54.02648162841797
Global epoch 46...
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.53 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9604168988149101, ce=31.544693570618236
Local test acc @ epoch 46: 0.9427
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.43 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.961624957005912, ce=31.505737742152782
Local test acc @ epoch 46: 0.9427
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.24 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9407561765898258, ce=31.920705095343635
Local test acc @ epoch 46: 0.9415
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.48 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9376408091378868, ce=32.409422480731926
Local test acc @ epoch 46: 0.9427
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.29 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9510450866244254, ce=31.69949132586838
Local test acc @ epoch 46: 0.9427
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.47 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9576645466165805, ce=31.587600060559193
Local test acc @ epoch 46: 0.9427
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.47 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.08112774420222, ce=29.793927988874803
Local test acc @ epoch 46: 0.9392
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.49 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.94330563457734, ce=32.78007446079079
Local test acc @ epoch 46: 0.9427
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.53 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9566789723317558, ce=31.645358321863576
Local test acc @ epoch 46: 0.9427
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 1.7029897492193413e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.32 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.174206477786423, ce=30.769973632392535
Local test acc @ epoch 46: 0.9392
Global evaluate on test data...
Evaluate data in 82.38 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.989415385307522, ce=31.75541022064489
Global test acc : 0.9415
Global prompt norm: 54.0109977722168
Global epoch 47...
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.29 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9518511667164093, ce=32.702876519719396
Local test acc @ epoch 47: 0.9427
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.33 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9594534843339833, ce=32.55255926639662
Local test acc @ epoch 47: 0.9427
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 1.7029897492193413e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.54 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.16799481199422, ce=31.81573727808961
Local test acc @ epoch 47: 0.9392
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.49 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9402282522359026, ce=33.04329410168009
Local test acc @ epoch 47: 0.9427
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.43 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.953189661743444, ce=32.63590438212823
Local test acc @ epoch 47: 0.9427
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.45 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9272133363496273, ce=32.973802584026934
Local test acc @ epoch 47: 0.9427
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.32 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9898629035424749, ce=36.05527702821504
Local test acc @ epoch 47: 0.9427
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.54 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9461993252465485, ce=33.30827504779221
Local test acc @ epoch 47: 0.9427
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.29 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9578394408619731, ce=32.59550378081995
Local test acc @ epoch 47: 0.9427
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.38 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9415775614047269, ce=32.79167287284081
Local test acc @ epoch 47: 0.9438
Global evaluate on test data...
Evaluate data in 82.5 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.973375112638561, ce=33.168490086126766
Global test acc : 0.9415
Global prompt norm: 53.98392105102539
Global epoch 48...
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.39 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9014399664117656, ce=34.49796956613523
Local test acc @ epoch 48: 0.9427
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.34 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8995133299346364, ce=34.58613376442445
Local test acc @ epoch 48: 0.9427
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.32 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8640587986062426, ce=34.70097207585606
Local test acc @ epoch 48: 0.9438
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.28 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9097527845190205, ce=34.497267416857795
Local test acc @ epoch 48: 0.9438
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.43 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8947468635139115, ce=34.766725207687514
Local test acc @ epoch 48: 0.9427
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 1.7029897492193413e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.46 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.1921770747648466, ce=30.942547666917154
Local test acc @ epoch 48: 0.9392
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.36 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8851118459614045, ce=34.6631458177479
Local test acc @ epoch 48: 0.9427
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.45 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9131497658720804, ce=34.406888874298936
Local test acc @ epoch 48: 0.9427
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.44 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=0.9578753611363402, ce=37.40275976198529
Local test acc @ epoch 48: 0.9392
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.49 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9045850596296678, ce=35.06818456387301
Local test acc @ epoch 48: 0.9438
Global evaluate on test data...
Evaluate data in 82.4 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9357196890979732, ce=34.74094401368308
Global test acc : 0.9438
Global prompt norm: 53.94729995727539
Global epoch 49...
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.44 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.8451085178130263, ce=36.80852326559364
Local test acc @ epoch 49: 0.945
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.9868213740892315e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.33 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.923009568398152, ce=35.902993543432395
Local test acc @ epoch 49: 0.9415
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.27 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8477476430595468, ce=36.20441261781465
Local test acc @ epoch 49: 0.9438
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.43 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.9749437953354022, ce=37.819734730851756
Local test acc @ epoch 49: 0.9404
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.44 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8603666638015607, ce=36.18261312782218
Local test acc @ epoch 49: 0.9427
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.35 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8607536280920746, ce=36.08048353282683
Local test acc @ epoch 49: 0.9427
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.54 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.870798036592816, ce=35.99410622273017
Local test acc @ epoch 49: 0.9427
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.51 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.2201154122658826, ce=29.105820874555395
Local test acc @ epoch 49: 0.9415
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.57 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.830228011542504, ce=36.08478469148688
Local test acc @ epoch 49: 0.945
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.46 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8669394156254759, ce=36.10228067800539
Local test acc @ epoch 49: 0.9427
Global evaluate on test data...
Evaluate data in 82.64 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9197050234593382, ce=36.05611171197454
Global test acc : 0.9427
Global prompt norm: 53.90494918823242
Global epoch 50...
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.54 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.1073349336965368, ce=12.651808782455024
Local test acc @ epoch 50: 0.9392
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.9868213740892315e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.45 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9426411510607519, ce=36.29068658111292
Local test acc @ epoch 50: 0.9427
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.43 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8423689549122382, ce=37.525652229239086
Local test acc @ epoch 50: 0.9438
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.46 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8331523685280336, ce=37.74628325996049
Local test acc @ epoch 50: 0.9438
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.9868213740892315e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.42 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9589436097976265, ce=35.470637645196476
Local test acc @ epoch 50: 0.9415
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.39 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.1595957858846822, ce=21.866821114076387
Local test acc @ epoch 50: 0.9392
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.32 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.8370965817652711, ce=37.60926706856544
Local test acc @ epoch 50: 0.945
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.54 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.8246201987660259, ce=37.74939874771538
Local test acc @ epoch 50: 0.945
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8113220087978819, ce=37.57020285370153
Local test acc @ epoch 50: 0.9427
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.44 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.8391400083489374, ce=37.62262641836744
Local test acc @ epoch 50: 0.945
Global evaluate on test data...
Evaluate data in 82.5 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=1.026257926170979, ce=32.63435306024114
Global test acc : 0.9427
Global prompt norm: 53.931678771972656
Global epoch 51...
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.43 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9837112514250869, ce=34.49592390847862
Local test acc @ epoch 51: 0.9427
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.37 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.8688934418039584, ce=39.71625431305772
Local test acc @ epoch 51: 0.9404
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.42 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=1.0021419481399956, ce=33.89969652508377
Local test acc @ epoch 51: 0.9427
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.42 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.0081862922108502, ce=33.88947521874664
Local test acc @ epoch 51: 0.9415
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.27 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9988390655692564, ce=33.93445870635706
Local test acc @ epoch 51: 0.9427
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.48 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=1.0045353163272963, ce=33.75720162347916
Local test acc @ epoch 51: 0.9427
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.5 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.0088738323351658, ce=33.6031611731293
Local test acc @ epoch 51: 0.9415
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.55 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=1.0021782052626305, ce=34.01688918717411
Local test acc @ epoch 51: 0.9427
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.7029897492193413e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.43 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.0611362588514976, ce=36.098539019943374
Local test acc @ epoch 51: 0.9381
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.38 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.0085300983638938, ce=33.62288139063284
Local test acc @ epoch 51: 0.9415
Global evaluate on test data...
Evaluate data in 82.37 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=1.001040974888233, ce=34.80323298043067
Global test acc : 0.9427
Global prompt norm: 53.90506362915039
Global epoch 52...
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.4 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9409216609569865, ce=36.510801507792344
Local test acc @ epoch 52: 0.9427
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.33 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9555636261581281, ce=36.233247914445506
Local test acc @ epoch 52: 0.9427
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.7029897492193413e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.36 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.107984739706057, ce=35.547206668678776
Local test acc @ epoch 52: 0.9358
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.22 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9457788708013132, ce=36.34725759663713
Local test acc @ epoch 52: 0.9427
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.6 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9305663240065268, ce=36.58143762710991
Local test acc @ epoch 52: 0.9427
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.46 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9576281341937704, ce=36.18895392461654
Local test acc @ epoch 52: 0.9427
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.41 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9019377537823599, ce=36.912665830839664
Local test acc @ epoch 52: 0.9427
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.52 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9521509179281532, ce=36.521997819253066
Local test acc @ epoch 52: 0.9427
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.5 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9442979217669286, ce=36.45478117356607
Local test acc @ epoch 52: 0.9427
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.5 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8596590812053155, ce=41.07068578037647
Local test acc @ epoch 52: 0.9427
Global evaluate on test data...
Evaluate data in 82.51 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9524483615105305, ce=36.981648541371754
Global test acc : 0.9427
Global prompt norm: 53.86614990234375
Global epoch 53...
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.36 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.0793649089445763, ce=25.563111208994453
Local test acc @ epoch 53: 0.9392
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.41 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8372581989393322, ce=38.82955880121354
Local test acc @ epoch 53: 0.9438
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.42 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.8538204661203087, ce=38.840116973316995
Local test acc @ epoch 53: 0.945
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.64 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8790663447948771, ce=38.5340958341546
Local test acc @ epoch 53: 0.9427
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.58 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8579710711032973, ce=39.12148897363505
Local test acc @ epoch 53: 0.9427
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.45 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8822502893045407, ce=38.51483854241327
Local test acc @ epoch 53: 0.9427
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.55 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8682465947002446, ce=38.78695843197884
Local test acc @ epoch 53: 0.9438
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.5 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.870409512738569, ce=38.613791124536355
Local test acc @ epoch 53: 0.9438
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 1.7029897492193413e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.37 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.2233970515224912, ce=30.243407713163883
Local test acc @ epoch 53: 0.9392
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.38 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8576623802885003, ce=39.686154181804135
Local test acc @ epoch 53: 0.9427
Global evaluate on test data...
Evaluate data in 82.32 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.975060530758779, ce=37.01463940821657
Global test acc : 0.9415
Global prompt norm: 53.84076690673828
Global epoch 54...
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.43 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.8829626468343472, ce=39.629032904948666
Local test acc @ epoch 54: 0.9415
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.57 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8730723923499432, ce=39.124040761125194
Local test acc @ epoch 54: 0.9438
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.49 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.889161361466854, ce=38.91164608176695
Local test acc @ epoch 54: 0.9438
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 1.7029897492193413e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.46 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.2258216547309806, ce=33.98569000314135
Local test acc @ epoch 54: 0.9369
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.56 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.142408029748759, ce=31.302443023121686
Local test acc @ epoch 54: 0.9369
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.46 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.9057793070416932, ce=38.76383947669913
Local test acc @ epoch 54: 0.9404
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.56 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.884508992553851, ce=39.084697303422
Local test acc @ epoch 54: 0.9438
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.47 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8470813265634239, ce=39.33819569578958
Local test acc @ epoch 54: 0.9438
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.5 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.9003718752379811, ce=38.808212000295654
Local test acc @ epoch 54: 0.9404
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8821950811858571, ce=39.22096500921687
Local test acc @ epoch 54: 0.9427
Global evaluate on test data...
Evaluate data in 82.55 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9634233986565827, ce=37.99975582437778
Global test acc : 0.9415
Global prompt norm: 53.81953811645508
Global epoch 55...
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.57 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.034265743483097, ce=36.31693551299769
Local test acc @ epoch 55: 0.9404
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.48 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8752199903540655, ce=40.003386891216316
Local test acc @ epoch 55: 0.9438
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.47 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8919540107797045, ce=39.59394136481329
Local test acc @ epoch 55: 0.9427
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.63 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8801277864963637, ce=39.655692214265876
Local test acc @ epoch 55: 0.9427
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.43 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8673854442911411, ce=39.87147766953215
Local test acc @ epoch 55: 0.9438
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.47 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8493769015740911, ce=39.95071719108372
Local test acc @ epoch 55: 0.9438
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.47 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8775176783220484, ce=39.83567771561649
Local test acc @ epoch 55: 0.9438
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.47 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8888789251310016, ce=39.590021605885354
Local test acc @ epoch 55: 0.9438
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.49 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.8750094754980244, ce=40.4449422643819
Local test acc @ epoch 55: 0.9415
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 1.7029897492193413e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.47 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.2525245815242103, ce=31.37909939967164
Local test acc @ epoch 55: 0.9392
Global evaluate on test data...
Evaluate data in 82.59 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9454626708949377, ce=39.02368370546113
Global test acc : 0.9415
Global prompt norm: 53.7879524230957
Global epoch 56...
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.69 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8707550315681948, ce=40.56116286111534
Local test acc @ epoch 56: 0.9438
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.68 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8597849902756717, ce=40.74738357263968
Local test acc @ epoch 56: 0.9427
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.59 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8747033197945411, ce=40.50733825263627
Local test acc @ epoch 56: 0.9438
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.44 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8449457019840906, ce=40.76966353950151
Local test acc @ epoch 56: 0.9438
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.67 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.877880625768539, ce=40.498205727393476
Local test acc @ epoch 56: 0.9438
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.44 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8653627404379188, ce=40.74886986968714
Local test acc @ epoch 56: 0.9438
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.9868213740892315e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.63 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9391398736096304, ce=39.90565312236821
Local test acc @ epoch 56: 0.9415
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.66 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8523760126271379, ce=41.29995080090444
Local test acc @ epoch 56: 0.9438
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.54 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.0428805088778155, ce=37.75050385501407
Local test acc @ epoch 56: 0.9404
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.56 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.2560861001320935, ce=32.267431661623334
Local test acc @ epoch 56: 0.9404
Global evaluate on test data...
Evaluate data in 82.66 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.9400199268936017, ce=39.87825561663426
Global test acc : 0.9404
Global prompt norm: 53.75325393676758
Global epoch 57...
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.6 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.865812432875327, ce=41.400530788876594
Local test acc @ epoch 57: 0.9438
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.69 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8556384252845695, ce=41.58285553958438
Local test acc @ epoch 57: 0.9427
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.9868213740892315e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.55 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9272315502166748, ce=40.92104161113774
Local test acc @ epoch 57: 0.9415
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8689660216690204, ce=41.35927021831547
Local test acc @ epoch 57: 0.9438
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.57 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.2419914236856162, ce=31.61033633870816
Local test acc @ epoch 57: 0.9404
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.53 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.078921390235971, ce=30.945414744385886
Local test acc @ epoch 57: 0.9438
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.63 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.871930242678441, ce=41.34914436690304
Local test acc @ epoch 57: 0.9438
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.7 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8586464125082034, ce=41.62431265454774
Local test acc @ epoch 57: 0.9427
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.9 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.8411539891444215, ce=41.59988095344753
Local test acc @ epoch 57: 0.9415
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8409783249601311, ce=42.3972546988671
Local test acc @ epoch 57: 0.9438
Global evaluate on test data...
Evaluate data in 82.53 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9552372245613588, ce=40.07122925224654
Global test acc : 0.9415
Global prompt norm: 53.717227935791016
Global epoch 58...
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.49 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.886633969228202, ce=41.682262910615414
Local test acc @ epoch 58: 0.9427
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.67 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8655513470325995, ce=41.961746250817534
Local test acc @ epoch 58: 0.9438
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.59 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.889307531741781, ce=41.71747200642157
Local test acc @ epoch 58: 0.9427
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.79 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.2611746919264488, ce=31.839004814077956
Local test acc @ epoch 58: 0.9392
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.62 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8961867717427945, ce=41.50137525086009
Local test acc @ epoch 58: 0.9427
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.6 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9087515052305449, ce=41.32287223185968
Local test acc @ epoch 58: 0.9438
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8639899503200426, ce=42.59302576747509
Local test acc @ epoch 58: 0.9438
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.55 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.104013659538479, ce=24.787686111730174
Local test acc @ epoch 58: 0.9415
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.9868213740892315e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.61 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9488005791235408, ce=41.08939543557823
Local test acc @ epoch 58: 0.9415
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.52 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9024929847192327, ce=41.423467758598676
Local test acc @ epoch 58: 0.9438
Global evaluate on test data...
Evaluate data in 82.59 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.0051548087268793, ce=39.3295989780251
Global test acc : 0.9404
Global prompt norm: 53.706180572509766
Global epoch 59...
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.76 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.940216434111289, ce=41.231333286390395
Local test acc @ epoch 59: 0.9438
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.7 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.892847179272853, ce=41.94250099812079
Local test acc @ epoch 59: 0.9427
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.72 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9315939321430451, ce=41.396868119546035
Local test acc @ epoch 59: 0.9438
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.6 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9256778528930945, ce=41.39595917168013
Local test acc @ epoch 59: 0.9438
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.73 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.9547872477715168, ce=40.91674447715829
Local test acc @ epoch 59: 0.9404
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.7029897492193413e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.59 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.127068598336036, ce=37.44402050753252
Local test acc @ epoch 59: 0.9358
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.85 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9476137117508354, ce=41.036148106286284
Local test acc @ epoch 59: 0.9415
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.61 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.07614609954554, ce=31.398038899132963
Local test acc @ epoch 59: 0.9404
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.62 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9388548977878115, ce=41.153079216633365
Local test acc @ epoch 59: 0.9438
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.69 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9407749285391711, ce=41.43841097770481
Local test acc @ epoch 59: 0.9427
Global evaluate on test data...
Evaluate data in 82.62 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.9933904026626447, ce=40.240952168035946
Global test acc : 0.9404
Global prompt norm: 53.69132614135742
Global epoch 60...
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.75 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8745598268071446, ce=42.88677492054231
Local test acc @ epoch 60: 0.9438
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9164892752236182, ce=42.192783705685116
Local test acc @ epoch 60: 0.9427
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9198989386952251, ce=42.276305032432624
Local test acc @ epoch 60: 0.9415
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.82 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=1.039888985660098, ce=30.528221410348873
Local test acc @ epoch 60: 0.9427
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.64 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.1400417865963157, ce=37.059163259803704
Local test acc @ epoch 60: 0.9381
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.56 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.933235516241931, ce=41.979315591514656
Local test acc @ epoch 60: 0.9438
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.73 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9248902600839597, ce=42.10007382314139
Local test acc @ epoch 60: 0.9438
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.61 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.908321135634676, ce=42.472401365227654
Local test acc @ epoch 60: 0.9438
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.64 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9184513201407336, ce=42.56563480622178
Local test acc @ epoch 60: 0.9438
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.6 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9038740276196681, ce=42.440597394190796
Local test acc @ epoch 60: 0.9427
Global evaluate on test data...
Evaluate data in 82.73 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.981532652443702, ce=40.98331328925737
Global test acc : 0.9404
Global prompt norm: 53.67109298706055
Global epoch 61...
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8762501904723841, ce=43.41347276180162
Local test acc @ epoch 61: 0.9427
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.54 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9128582958781392, ce=42.76481302943798
Local test acc @ epoch 61: 0.9427
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.68 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=1.0817246065227264, ce=31.15341090281075
Local test acc @ epoch 61: 0.9427
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.62 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9045810765082684, ce=43.035058537754445
Local test acc @ epoch 61: 0.9427
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.76 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9114178845641809, ce=43.037923830364825
Local test acc @ epoch 61: 0.9427
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9063280350571379, ce=43.4352821560081
Local test acc @ epoch 61: 0.9415
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.92108070741006, ce=42.660765481651374
Local test acc @ epoch 61: 0.9438
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.56 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9031381497689344, ce=42.9792881186949
Local test acc @ epoch 61: 0.9427
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.62 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9288258683790854, ce=42.56105419473911
Local test acc @ epoch 61: 0.9438
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.53 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.1904036408170648, ce=31.547999775737797
Local test acc @ epoch 61: 0.9392
Global evaluate on test data...
Evaluate data in 82.62 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9936812580178637, ce=41.16920667175853
Global test acc : 0.9415
Global prompt norm: 53.653472900390625
Global epoch 62...
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.61 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9071846183286895, ce=43.34376326394737
Local test acc @ epoch 62: 0.9427
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.7 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9390857788400913, ce=43.11659100733766
Local test acc @ epoch 62: 0.9438
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.63 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9348182415743487, ce=42.78068902951862
Local test acc @ epoch 62: 0.9427
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.88 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.93781679485916, ce=42.80896381063199
Local test acc @ epoch 62: 0.9438
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.63 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9442903186203143, ce=42.56963229398115
Local test acc @ epoch 62: 0.9438
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.56 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=1.04088055103197, ce=30.663997650146484
Local test acc @ epoch 62: 0.9427
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.69 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.95035561290356, ce=42.464414824039565
Local test acc @ epoch 62: 0.9438
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.242584847529, ce=28.68675153189843
Local test acc @ epoch 62: 0.9392
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9567796812144989, ce=42.35629146470936
Local test acc @ epoch 62: 0.9438
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.85 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9411417738013311, ce=42.8293088860468
Local test acc @ epoch 62: 0.9415
Global evaluate on test data...
Evaluate data in 82.85 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.0254059625328134, ce=40.351543741488676
Global test acc : 0.9404
Global prompt norm: 53.65422821044922
Global epoch 63...
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.56 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9394661833386903, ce=42.92441180867886
Local test acc @ epoch 63: 0.9427
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.82 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.9894562576888898, ce=41.734578228871754
Local test acc @ epoch 63: 0.9404
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.64 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.9920456037608856, ce=41.88502953905578
Local test acc @ epoch 63: 0.9404
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.7029897492193413e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.1003822164798, ce=40.13486183236498
Local test acc @ epoch 63: 0.9381
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.64 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9752005196492607, ce=42.08442729984949
Local test acc @ epoch 63: 0.9415
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9882944702008448, ce=41.841044784685884
Local test acc @ epoch 63: 0.9415
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.82 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.9947520111678937, ce=41.62819566639192
Local test acc @ epoch 63: 0.9404
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8870366035251442, ce=46.00554880964647
Local test acc @ epoch 63: 0.9438
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.62 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9772981700547244, ce=42.148928791011144
Local test acc @ epoch 63: 0.9415
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.57 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.983330503516241, ce=41.885309096870074
Local test acc @ epoch 63: 0.9415
Global evaluate on test data...
Evaluate data in 82.63 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9854228080959495, ce=42.41663854056542
Global test acc : 0.9415
Global prompt norm: 53.63079071044922
Global epoch 64...
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.45 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.938600446106097, ce=43.80609102861597
Local test acc @ epoch 64: 0.9415
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.62 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9144132924736093, ce=44.25316896351106
Local test acc @ epoch 64: 0.9427
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.73 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9196087810971322, ce=44.56657980122697
Local test acc @ epoch 64: 0.9415
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9799417137006007, ce=43.623256998324614
Local test acc @ epoch 64: 0.9415
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.132076880253783, ce=28.547704959134443
Local test acc @ epoch 64: 0.9381
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.59 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8877478389565004, ce=44.731861394479736
Local test acc @ epoch 64: 0.9427
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.56 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9291943563233822, ce=43.92725214826952
Local test acc @ epoch 64: 0.9427
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.84 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9247137406550416, ce=43.99262356539385
Local test acc @ epoch 64: 0.9427
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.72 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9251323839940062, ce=44.19973908870592
Local test acc @ epoch 64: 0.9427
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9145797217657806, ce=44.338408198925336
Local test acc @ epoch 64: 0.9427
Global evaluate on test data...
Evaluate data in 82.97 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9791106368423602, ce=43.152352324319544
Global test acc : 0.9438
Global prompt norm: 53.608497619628906
Global epoch 65...
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.64 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9150020135652035, ce=44.89190187366731
Local test acc @ epoch 65: 0.9427
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.89 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9162193678934639, ce=45.08173786828277
Local test acc @ epoch 65: 0.9427
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.61 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9287452960233076, ce=44.56068374913767
Local test acc @ epoch 65: 0.9427
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.98 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9246158556106987, ce=44.64541716969341
Local test acc @ epoch 65: 0.9427
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9389854811747139, ce=44.418562897848425
Local test acc @ epoch 65: 0.9415
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.6 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.1286600860980673, ce=27.32598530480621
Local test acc @ epoch 65: 0.9381
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.92 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9045996950307024, ce=45.6139974331637
Local test acc @ epoch 65: 0.9415
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.86 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.8861701007283062, ce=45.40604806602548
Local test acc @ epoch 65: 0.9415
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 1.7029897492193413e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.72 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.2973539129309697, ce=33.37894331205875
Local test acc @ epoch 65: 0.9381
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.84 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9121289100122014, ce=45.02090881067679
Local test acc @ epoch 65: 0.9427
Global evaluate on test data...
Evaluate data in 82.61 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.0267811565224183, ce=42.18498877429087
Global test acc : 0.9404
Global prompt norm: 53.6137580871582
Global epoch 66...
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9608403236494152, ce=44.14835602646574
Local test acc @ epoch 66: 0.9427
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.7 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9574609677725976, ce=44.314540618056554
Local test acc @ epoch 66: 0.9427
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.88 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.853013392982133, ce=47.95698169393277
Local test acc @ epoch 66: 0.945
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.7029897492193413e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.69 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.1362356155290516, ce=38.113896046209774
Local test acc @ epoch 66: 0.9369
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9754955287373394, ce=43.80138862679858
Local test acc @ epoch 66: 0.9415
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.91 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9785591527956341, ce=43.788278212241075
Local test acc @ epoch 66: 0.9438
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.63 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9714754065242382, ce=43.88072915033463
Local test acc @ epoch 66: 0.9427
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.52 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9170826028246398, ce=44.99459541390795
Local test acc @ epoch 66: 0.9415
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9851136470059736, ce=43.63644311187464
Local test acc @ epoch 66: 0.9415
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9807837031303196, ce=43.881738470235
Local test acc @ epoch 66: 0.9427
Global evaluate on test data...
Evaluate data in 82.66 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9818745053142582, ce=44.203461323309384
Global test acc : 0.9438
Global prompt norm: 53.58802795410156
Global epoch 67...
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.67 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8975688798711934, ce=46.18187846612493
Local test acc @ epoch 67: 0.9427
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.57 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9225509254210585, ce=45.77060958442338
Local test acc @ epoch 67: 0.9427
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.53 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9083323019360183, ce=45.888258837778636
Local test acc @ epoch 67: 0.9427
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.62 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.2379918864013952, ce=33.65521376723543
Local test acc @ epoch 67: 0.9381
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9014904652166804, ce=46.55566794719171
Local test acc @ epoch 67: 0.9415
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.66 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8932906268933497, ce=46.35106931913883
Local test acc @ epoch 67: 0.9427
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9082095732382678, ce=46.13394616503234
Local test acc @ epoch 67: 0.9427
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.69 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9104930654578253, ce=45.825680478997185
Local test acc @ epoch 67: 0.9427
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.63 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.8727499585632884, ce=46.58376137269746
Local test acc @ epoch 67: 0.9404
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.63 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.1238010804587548, ce=32.589657774759
Local test acc @ epoch 67: 0.9404
Global evaluate on test data...
Evaluate data in 82.59 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.9999906557415603, ce=44.24482114599385
Global test acc : 0.9404
Global prompt norm: 53.565582275390625
Global epoch 68...
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.61 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9157965183258057, ce=46.559414049901
Local test acc @ epoch 68: 0.9427
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.7029897492193413e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.58 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.1985245494667542, ce=39.07499922306166
Local test acc @ epoch 68: 0.9358
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.73 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9082385225033541, ce=46.47489061268098
Local test acc @ epoch 68: 0.9427
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.81 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8926743148663722, ce=46.85574659295038
Local test acc @ epoch 68: 0.9427
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.79 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9232192542574821, ce=46.42030782437106
Local test acc @ epoch 68: 0.9427
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.66 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8865146177624343, ce=47.04589721259721
Local test acc @ epoch 68: 0.9427
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.68 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9147502872922005, ce=46.79659393730513
Local test acc @ epoch 68: 0.9415
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.72 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.1049887784030459, ce=35.11800522760514
Local test acc @ epoch 68: 0.9381
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.5 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9034601351536742, ce=46.56739310168345
Local test acc @ epoch 68: 0.9427
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.81 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8618311794525987, ce=47.34477037902272
Local test acc @ epoch 68: 0.9427
Global evaluate on test data...
Evaluate data in 82.6 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9822380324022486, ce=45.242662482305406
Global test acc : 0.9427
Global prompt norm: 53.54719543457031
Global epoch 69...
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.84 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9083142193085557, ce=46.90592764058244
Local test acc @ epoch 69: 0.9427
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.5 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8972883596332795, ce=47.25280418745968
Local test acc @ epoch 69: 0.9427
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.64 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9040044644557008, ce=47.33834604385796
Local test acc @ epoch 69: 0.9427
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8887973006712188, ce=47.48565099873674
Local test acc @ epoch 69: 0.9427
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.68 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9197324853424632, ce=46.913427125423325
Local test acc @ epoch 69: 0.9427
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.7 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9052600466876949, ce=47.00370246117268
Local test acc @ epoch 69: 0.9427
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.76 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.8973646382673071, ce=47.77537638113039
Local test acc @ epoch 69: 0.9415
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.030945817264942, ce=44.5872354069981
Local test acc @ epoch 69: 0.9415
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.7 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.8707451032936027, ce=47.69699079181076
Local test acc @ epoch 69: 0.9415
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.52 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.2305569933095108, ce=35.68879262241749
Local test acc @ epoch 69: 0.9392
Global evaluate on test data...
Evaluate data in 82.57 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9646665962464219, ce=46.510785129092156
Global test acc : 0.9415
Global prompt norm: 53.51612091064453
Global epoch 70...
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.889484458013412, ce=48.0261470199725
Local test acc @ epoch 70: 0.9427
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.61 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.859042605128857, ce=48.56016838003736
Local test acc @ epoch 70: 0.9427
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8808400827810305, ce=48.29702380819058
Local test acc @ epoch 70: 0.9438
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8750815391540527, ce=48.51213581190197
Local test acc @ epoch 70: 0.9438
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.89 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8596109250269899, ce=49.41592414226007
Local test acc @ epoch 70: 0.9427
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.59 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8995422310785416, ce=48.03055180540872
Local test acc @ epoch 70: 0.9427
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 1.7029897492193413e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.6 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.2391082387451733, ce=30.81490975126214
Local test acc @ epoch 70: 0.9369
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.66 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8896194991715457, ce=47.92137348979985
Local test acc @ epoch 70: 0.9427
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.56 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8720090761097199, ce=48.802071632595236
Local test acc @ epoch 70: 0.9427
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.58 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=1.0470770630267783, ce=25.554203050945876
Local test acc @ epoch 70: 0.9427
Global evaluate on test data...
Evaluate data in 82.69 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.0217760374786657, ce=44.31964716780077
Global test acc : 0.9404
Global prompt norm: 53.51142501831055
Global epoch 71...
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.64 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9808963416913233, ce=46.47171797446155
Local test acc @ epoch 71: 0.9415
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.82 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9544446205874102, ce=47.11190981383717
Local test acc @ epoch 71: 0.9415
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.62 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.908833363734254, ce=47.903239013951854
Local test acc @ epoch 71: 0.9427
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.69 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9866076018832145, ce=46.22387551823887
Local test acc @ epoch 71: 0.9415
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.69 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9908334312088992, ce=44.61306594708644
Local test acc @ epoch 71: 0.9427
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.63 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.9776057147104805, ce=46.35765929615825
Local test acc @ epoch 71: 0.9404
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.79 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9716393444516244, ce=46.61190197445931
Local test acc @ epoch 71: 0.9415
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.58 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9797569239905121, ce=46.68735486651779
Local test acc @ epoch 71: 0.9415
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.69 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.1615350902627368, ce=40.472973429828606
Local test acc @ epoch 71: 0.9369
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.967781213445401, ce=46.741375914407435
Local test acc @ epoch 71: 0.9415
Global evaluate on test data...
Evaluate data in 82.76 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.9982178451818063, ce=46.327221476703606
Global test acc : 0.9404
Global prompt norm: 53.49412155151367
Global epoch 72...
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.66 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9452843337977698, ce=47.93248346311237
Local test acc @ epoch 72: 0.9415
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.54 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.2919558910054898, ce=30.05130787070738
Local test acc @ epoch 72: 0.9392
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.0997321999401128, ce=36.571296866880644
Local test acc @ epoch 72: 0.9392
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.04 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9124588135185592, ce=48.59931151363828
Local test acc @ epoch 72: 0.9427
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.84 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9285252247381648, ce=48.125795801845165
Local test acc @ epoch 72: 0.9427
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.73 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.8850423305406483, ce=49.015841317833015
Local test acc @ epoch 72: 0.9415
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.64 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9340049454925257, ce=48.25054434680064
Local test acc @ epoch 72: 0.9427
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.79 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9312401780294716, ce=48.535156459983334
Local test acc @ epoch 72: 0.9415
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.64 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.922957599709887, ce=48.33174178797171
Local test acc @ epoch 72: 0.9427
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.75 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9335361030123649, ce=47.96566845955105
Local test acc @ epoch 72: 0.9427
Global evaluate on test data...
Evaluate data in 82.7 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.0327281536312278, ce=45.591056578749914
Global test acc : 0.9392
Global prompt norm: 53.496910095214844
Global epoch 73...
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.58 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9441973419364439, ce=48.08949748747939
Local test acc @ epoch 73: 0.9415
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.58 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.965830129220945, ce=47.78545820603677
Local test acc @ epoch 73: 0.9404
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.86 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9227453634279583, ce=48.66500861491632
Local test acc @ epoch 73: 0.9427
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.7029897492193413e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.69 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.0770067096850193, ce=45.009038452708396
Local test acc @ epoch 73: 0.9392
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.6 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=0.9695505002223024, ce=47.870373962122365
Local test acc @ epoch 73: 0.9392
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.68 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=0.963569977961549, ce=47.88684911465426
Local test acc @ epoch 73: 0.9392
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.57 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9399629120433003, ce=49.018885481248205
Local test acc @ epoch 73: 0.9427
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.56 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.9512253638801225, ce=47.89671486670818
Local test acc @ epoch 73: 0.9404
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.883841777066572, ce=49.24127200765347
Local test acc @ epoch 73: 0.9415
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.49 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.9380115740889803, ce=48.299029988980074
Local test acc @ epoch 73: 0.9404
Global evaluate on test data...
Evaluate data in 82.7 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.9607675228643855, ce=48.373320308300336
Global test acc : 0.9404
Global prompt norm: 53.46772766113281
Global epoch 74...
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.66 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8940292498387328, ce=49.53969140009049
Local test acc @ epoch 74: 0.9438
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.68 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8884536716916146, ce=49.78547325484249
Local test acc @ epoch 74: 0.9438
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.68 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8709054649423021, ce=49.93796850781922
Local test acc @ epoch 74: 0.9427
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.67 seconds!
[tester] 
SST2Metric: acc=0.9472477064220184, hinge=1.050444769203116, ce=29.243521156661007
Local test acc @ epoch 74: 0.9472
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.95 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8803374132978807, ce=50.00239520991614
Local test acc @ epoch 74: 0.9438
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 1.7029897492193413e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.69 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.1709415628275741, ce=24.828626702684875
Local test acc @ epoch 74: 0.9369
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.58 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8752208368493877, ce=50.40905789716528
Local test acc @ epoch 74: 0.9438
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.69 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8614214363448117, ce=51.12827801485674
Local test acc @ epoch 74: 0.9427
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.86 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9019016519599005, ce=49.64808346809597
Local test acc @ epoch 74: 0.9427
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.75 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.895098069392213, ce=49.40726015983372
Local test acc @ epoch 74: 0.9427
Global evaluate on test data...
Evaluate data in 82.7 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.024550020147901, ce=45.80542461150283
Global test acc : 0.9415
Global prompt norm: 53.454620361328125
Global epoch 75...
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.63 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9849751761200232, ce=47.874618460278995
Local test acc @ epoch 75: 0.9415
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.64 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.1069142337239117, ce=32.26320935170585
Local test acc @ epoch 75: 0.9392
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.0018457272730836, ce=47.17557462639765
Local test acc @ epoch 75: 0.9415
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.7 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9970032687580913, ce=47.709748539355914
Local test acc @ epoch 75: 0.9415
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.7 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.0080311276497098, ce=46.84763987129981
Local test acc @ epoch 75: 0.9415
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.69 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.0131535639456652, ce=46.53890091782316
Local test acc @ epoch 75: 0.9415
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.63 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.0094502562776617, ce=46.62774182240897
Local test acc @ epoch 75: 0.9415
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.67 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.2882904481450352, ce=38.72866737295728
Local test acc @ epoch 75: 0.9392
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.85 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9997396840961701, ce=47.38954621061273
Local test acc @ epoch 75: 0.9427
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.9 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.0073834931084868, ce=46.85580906299276
Local test acc @ epoch 75: 0.9415
Global evaluate on test data...
Evaluate data in 82.91 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.0669787564408888, ce=44.96677031210803
Global test acc : 0.9392
Global prompt norm: 53.46573257446289
Global epoch 76...
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8906442659710525, ce=51.05499001599233
Local test acc @ epoch 76: 0.9427
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.0474667942852056, ce=46.220362077065566
Local test acc @ epoch 76: 0.9404
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.64 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9462926715885828, ce=49.68924384160873
Local test acc @ epoch 76: 0.9427
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.66 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.048295222291159, ce=46.358046610421
Local test acc @ epoch 76: 0.9404
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.9 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.0382231987944437, ce=46.606619878646434
Local test acc @ epoch 76: 0.9404
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.7 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.9975807819891414, ce=48.05424422517829
Local test acc @ epoch 76: 0.9404
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.57 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.0427021302214456, ce=46.28326961972298
Local test acc @ epoch 76: 0.9404
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.0307211613436358, ce=46.95669776146565
Local test acc @ epoch 76: 0.9404
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.68 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.0389209121739098, ce=46.59974131452928
Local test acc @ epoch 76: 0.9404
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.63 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.0470507954238752, ce=46.1998199672874
Local test acc @ epoch 76: 0.9404
Global evaluate on test data...
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.0217249765308625, ce=47.547882185069795
Global test acc : 0.9404
Global prompt norm: 53.45396423339844
Global epoch 77...
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.73 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.9776781152147765, ce=48.73331496912405
Local test acc @ epoch 77: 0.9404
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.97 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.9747354131226146, ce=48.85450636137516
Local test acc @ epoch 77: 0.9404
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.67 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9386600835607686, ce=49.621798419077464
Local test acc @ epoch 77: 0.9427
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.86 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9664523842137888, ce=49.10242924121542
Local test acc @ epoch 77: 0.9415
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.7 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9835502729503387, ce=48.903826022366864
Local test acc @ epoch 77: 0.9415
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.141973773273853, ce=38.18276337089888
Local test acc @ epoch 77: 0.9392
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.67 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.9802042191181708, ce=48.59261997467881
Local test acc @ epoch 77: 0.9404
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.9840484496650346, ce=48.703812520438376
Local test acc @ epoch 77: 0.9404
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.69 seconds!
[tester] 
SST2Metric: acc=0.9461009174311926, hinge=0.8430796763218871, ce=52.658054036831636
Local test acc @ epoch 77: 0.9461
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.9887526844619611, ce=48.543065797298325
Local test acc @ epoch 77: 0.9404
Global evaluate on test data...
Evaluate data in 82.54 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.9965599961237076, ce=48.61372550474395
Global test acc : 0.9404
Global prompt norm: 53.437686920166016
Global epoch 78...
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9365913058639667, ce=50.48402471279879
Local test acc @ epoch 78: 0.9427
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.2477079378355533, ce=34.18048498171185
Local test acc @ epoch 78: 0.9381
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9471541675952596, ce=49.80200394796669
Local test acc @ epoch 78: 0.9427
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9592554984836403, ce=49.652018240832405
Local test acc @ epoch 78: 0.9427
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9456377073165474, ce=50.02522904282316
Local test acc @ epoch 78: 0.9427
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.73 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.1178236138930016, ce=44.3706749382369
Local test acc @ epoch 78: 0.9381
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.75 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9501190404279516, ce=49.647239125103034
Local test acc @ epoch 78: 0.9415
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.73 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9103786704737112, ce=50.58417846959665
Local test acc @ epoch 78: 0.9438
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.55 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9327011195891494, ce=50.23981790805082
Local test acc @ epoch 78: 0.9427
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.5 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9438264654317033, ce=49.95534077915577
Local test acc @ epoch 78: 0.9427
Global evaluate on test data...
Evaluate data in 82.66 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.0199699117503036, ce=48.50360390899378
Global test acc : 0.9404
Global prompt norm: 53.42287826538086
Global epoch 79...
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.73 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9150660366093347, ce=51.03674568386253
Local test acc @ epoch 79: 0.9438
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.55 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.8782461892574205, ce=51.78353286883153
Local test acc @ epoch 79: 0.945
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.57 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.8864302722685927, ce=51.358328688035314
Local test acc @ epoch 79: 0.945
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.57 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.9532191294048904, ce=50.53210988175978
Local test acc @ epoch 79: 0.9404
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.68 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9538889281246641, ce=50.28493527753638
Local test acc @ epoch 79: 0.9415
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.69 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9336184886617398, ce=50.52203558125627
Local test acc @ epoch 79: 0.9427
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.72 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9392157738361884, ce=50.30928330027729
Local test acc @ epoch 79: 0.9415
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9529646164780363, ce=50.343849847076136
Local test acc @ epoch 79: 0.9415
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.56 seconds!
[tester] 
SST2Metric: acc=0.9461009174311926, hinge=0.8271719118870726, ce=53.74081854863998
Local test acc @ epoch 79: 0.9461
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9291162097125972, ce=50.73601899453259
Local test acc @ epoch 79: 0.9415
Global evaluate on test data...
Evaluate data in 82.61 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.923902603464389, ce=51.413105605939116
Global test acc : 0.9438
Global prompt norm: 53.388858795166016
Global epoch 80...
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.79 seconds!
[tester] 
SST2Metric: acc=0.9277522935779816, hinge=1.2143496168315957, ce=12.380243467628409
Local test acc @ epoch 80: 0.9278
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.8688464995917924, ce=52.49511872737779
Local test acc @ epoch 80: 0.945
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.49 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.8769255690618393, ce=52.372962181721256
Local test acc @ epoch 80: 0.945
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 2.9802320611338473e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.56 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.101583913925591, ce=16.767268032108973
Local test acc @ epoch 80: 0.9404
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.57 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.8652273055610307, ce=52.61880097695447
Local test acc @ epoch 80: 0.945
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.9868213740892315e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.69 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.9684647945089078, ce=50.528624368370124
Local test acc @ epoch 80: 0.9404
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.69 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.8765920017837384, ce=52.19807192601195
Local test acc @ epoch 80: 0.945
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.6 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.8620864316957806, ce=52.397067568717745
Local test acc @ epoch 80: 0.945
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.68 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.8747240775222078, ce=52.038937979881915
Local test acc @ epoch 80: 0.945
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.69 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.823476738886002, ce=53.79920445013484
Local test acc @ epoch 80: 0.945
Global evaluate on test data...
Evaluate data in 82.62 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.1662307026189402, ce=36.067198832100686
Global test acc : 0.9381
Global prompt norm: 53.54512405395508
Global epoch 81...
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.62 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.1706448673108303, ce=38.41163365775292
Local test acc @ epoch 81: 0.9392
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.54 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.1694187308670183, ce=38.36131318118594
Local test acc @ epoch 81: 0.9392
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.1661819842977261, ce=37.546466092450906
Local test acc @ epoch 81: 0.9392
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.68 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.1713335404702283, ce=37.7331590914945
Local test acc @ epoch 81: 0.9392
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.66 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.1676090901051093, ce=38.39178869264935
Local test acc @ epoch 81: 0.9392
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.66 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.1681278320627475, ce=37.59950928294331
Local test acc @ epoch 81: 0.9381
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.168282716646107, ce=38.35026249316854
Local test acc @ epoch 81: 0.9392
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.67 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.1537868845353432, ce=42.41287749404207
Local test acc @ epoch 81: 0.9392
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.57 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.169744351588258, ce=37.78015633679311
Local test acc @ epoch 81: 0.9392
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.64 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.168736118789113, ce=38.79236228312921
Local test acc @ epoch 81: 0.9392
Global evaluate on test data...
Evaluate data in 82.7 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.1695440777944863, ce=38.59135895475335
Global test acc : 0.9392
Global prompt norm: 53.53507995605469
Global epoch 82...
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.81 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.1677895314102873, ce=39.83482854300683
Local test acc @ epoch 82: 0.9381
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.1640290732777447, ce=40.19324416414313
Local test acc @ epoch 82: 0.9392
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.68 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.164352255130033, ce=39.72721495322131
Local test acc @ epoch 82: 0.9392
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.1679863754762423, ce=39.63543690672708
Local test acc @ epoch 82: 0.9392
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.79 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.1627850357545626, ce=40.50807291433352
Local test acc @ epoch 82: 0.9392
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.69 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.1644241197393574, ce=40.214337935141465
Local test acc @ epoch 82: 0.9392
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.66 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.166641629070317, ce=39.747872378848015
Local test acc @ epoch 82: 0.9392
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.67 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.164486294492669, ce=40.199941337655446
Local test acc @ epoch 82: 0.9392
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.53 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.1668514636678433, ce=40.36230517746112
Local test acc @ epoch 82: 0.9392
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.9 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.1491597573691552, ce=43.20424554107386
Local test acc @ epoch 82: 0.9369
Global evaluate on test data...
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.1649624732656216, ce=40.39560989939839
Global test acc : 0.9392
Global prompt norm: 53.52965545654297
Global epoch 83...
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.62 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.1598285316327297, ce=42.00911229684812
Local test acc @ epoch 83: 0.9381
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.1615827039841118, ce=41.24052418700052
Local test acc @ epoch 83: 0.9392
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.5 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.1578623898532412, ce=41.40975465687043
Local test acc @ epoch 83: 0.9381
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.99 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.1553278844290917, ce=42.00533746141906
Local test acc @ epoch 83: 0.9381
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.56 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.1576046331213155, ce=41.69011233268528
Local test acc @ epoch 83: 0.9369
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.34 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.1387499909882153, ce=44.17980838040693
Local test acc @ epoch 83: 0.9369
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.42 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.1601496486488831, ce=41.35419051144101
Local test acc @ epoch 83: 0.9381
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.67 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.1571892488987074, ce=41.75447908453985
Local test acc @ epoch 83: 0.9369
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.156960863585866, ce=41.74415917352799
Local test acc @ epoch 83: 0.9381
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.69 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.1615167276574931, ce=41.62098676349045
Local test acc @ epoch 83: 0.9381
Global evaluate on test data...
Evaluate data in 82.64 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.1576793193817139, ce=41.92663000264299
Global test acc : 0.9381
Global prompt norm: 53.52542495727539
Global epoch 84...
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.49 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.1515408284073576, ce=43.2217256388533
Local test acc @ epoch 84: 0.9369
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.67 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.1467414711593489, ce=43.11741319708868
Local test acc @ epoch 84: 0.9369
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.57 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.1477704551241814, ce=42.86710371664905
Local test acc @ epoch 84: 0.9369
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.57 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.1527363247827653, ce=42.66652980419474
Local test acc @ epoch 84: 0.9369
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.1507691462105567, ce=42.77077183154745
Local test acc @ epoch 84: 0.9369
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.6 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.147845565725904, ce=43.01816772320949
Local test acc @ epoch 84: 0.9369
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.69 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.149115256213267, ce=43.50498510938172
Local test acc @ epoch 84: 0.9369
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.64 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.1465329577069763, ce=43.12382409331995
Local test acc @ epoch 84: 0.9369
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.61 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.1261795463911983, ce=45.13824756867295
Local test acc @ epoch 84: 0.9369
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.1446450587806352, ce=43.34741956378342
Local test acc @ epoch 84: 0.9369
Global evaluate on test data...
Evaluate data in 82.63 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.1471806688046238, ce=43.299968194524084
Global test acc : 0.9369
Global prompt norm: 53.521484375
Global epoch 85...
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.72 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.1353918871748339, ce=44.92008783182967
Local test acc @ epoch 85: 0.9369
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.67 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.1329341547204814, ce=44.386394780710205
Local test acc @ epoch 85: 0.9369
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.63 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.13854401045983, ce=44.73172854502267
Local test acc @ epoch 85: 0.9358
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.73 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.1333129777820832, ce=44.36573634016405
Local test acc @ epoch 85: 0.9369
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.56 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.1307849468441185, ce=44.58256082797269
Local test acc @ epoch 85: 0.9369
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.48 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.110391109361561, ce=46.05490962737197
Local test acc @ epoch 85: 0.9369
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.53 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.1403537474641012, ce=43.97359176075786
Local test acc @ epoch 85: 0.9369
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.134994075932634, ce=44.24528100949909
Local test acc @ epoch 85: 0.9369
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.69 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.1377761954561285, ce=44.06696064100353
Local test acc @ epoch 85: 0.9369
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.52 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.1343136139965933, ce=44.1840073121797
Local test acc @ epoch 85: 0.9369
Global evaluate on test data...
Evaluate data in 82.55 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.1338413133533722, ce=44.5727447719749
Global test acc : 0.9369
Global prompt norm: 53.517398834228516
Global epoch 86...
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.7 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.1200165114271532, ce=45.404833522411664
Local test acc @ epoch 86: 0.9358
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.59 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.1184496485858881, ce=46.219419636857616
Local test acc @ epoch 86: 0.9381
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.54 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.122778291002326, ce=45.282242626225184
Local test acc @ epoch 86: 0.9369
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.48 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.1142942839806234, ce=45.74183416804043
Local test acc @ epoch 86: 0.9369
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.58 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.116722325666235, ce=45.56446995866408
Local test acc @ epoch 86: 0.9369
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.48 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.1171884274263995, ce=45.533663548460794
Local test acc @ epoch 86: 0.9369
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.1156996652620648, ce=46.30744283133691
Local test acc @ epoch 86: 0.9369
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.4 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.118263894264851, ce=45.40263370198941
Local test acc @ epoch 86: 0.9369
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.14 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.125954518624402, ce=45.19934613989034
Local test acc @ epoch 86: 0.9358
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.81 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.0906637480499548, ce=46.927731295244406
Local test acc @ epoch 86: 0.9381
Global evaluate on test data...
Evaluate data in 82.82 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.1171777707721116, ce=45.78261583660721
Global test acc : 0.9369
Global prompt norm: 53.51233673095703
Global epoch 87...
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.82 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.097056517907239, ce=46.55112940237063
Local test acc @ epoch 87: 0.9381
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.09 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.0998533712614567, ce=46.52073900415263
Local test acc @ epoch 87: 0.9381
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.94 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.1065020364358884, ce=46.374934590190925
Local test acc @ epoch 87: 0.9369
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.62 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.0851678367054791, ce=47.72793152135446
Local test acc @ epoch 87: 0.9381
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.0952446526343669, ce=46.68170550985074
Local test acc @ epoch 87: 0.9381
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.76 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.102138401171483, ce=46.44597443746864
Local test acc @ epoch 87: 0.9381
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.61 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.0855278859444715, ce=47.766067119913366
Local test acc @ epoch 87: 0.9392
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.0959916727258525, ce=46.644454816065796
Local test acc @ epoch 87: 0.9381
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.6 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.0921981225319959, ce=46.84898299470954
Local test acc @ epoch 87: 0.9381
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.0674135597473984, ce=47.76509356717451
Local test acc @ epoch 87: 0.9392
Global evaluate on test data...
Evaluate data in 82.73 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.0939861612582424, ce=46.96501404648527
Global test acc : 0.9381
Global prompt norm: 53.506019592285156
Global epoch 88...
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.87 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.0703364118523555, ce=47.658382975727044
Local test acc @ epoch 88: 0.9381
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.9 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.04354614730275, ce=49.29133983927036
Local test acc @ epoch 88: 0.9404
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.69 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.0754726064314537, ce=47.59073642415738
Local test acc @ epoch 88: 0.9392
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.54 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.0439401875942125, ce=48.5863103604098
Local test acc @ epoch 88: 0.9392
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.08 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.0738109929845967, ce=47.62083386062482
Local test acc @ epoch 88: 0.9381
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.75 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.0689751248840893, ce=47.72298081424258
Local test acc @ epoch 88: 0.9392
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.82 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.0648346909689248, ce=47.93151673483192
Local test acc @ epoch 88: 0.9392
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.72 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.0804052046679575, ce=47.53808054792772
Local test acc @ epoch 88: 0.9381
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.84 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.0678923523754156, ce=47.76568309538955
Local test acc @ epoch 88: 0.9392
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.66 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.0384091849720807, ce=49.52876652708841
Local test acc @ epoch 88: 0.9392
Global evaluate on test data...
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.0642876821920413, ce=48.17523872305494
Global test acc : 0.9392
Global prompt norm: 53.4974250793457
Global epoch 89...
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.73 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.049233132546101, ce=48.76238467715202
Local test acc @ epoch 89: 0.9404
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.55 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.0332970662948189, ce=49.039612061386805
Local test acc @ epoch 89: 0.9404
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.69 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.0443846457595125, ce=48.7572157623571
Local test acc @ epoch 89: 0.9404
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.9 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.9751717934914685, ce=51.29699745528195
Local test acc @ epoch 89: 0.9404
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.72 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.0396423777309032, ce=48.77267207574407
Local test acc @ epoch 89: 0.9404
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.49 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.0386070789547142, ce=48.813556496156465
Local test acc @ epoch 89: 0.9404
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.59 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.044557805455059, ce=48.77626247580992
Local test acc @ epoch 89: 0.9404
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.58 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.9474173598333236, ce=51.98736799747572
Local test acc @ epoch 89: 0.9404
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.72 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.0372479399409862, ce=48.86693111034708
Local test acc @ epoch 89: 0.9404
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.63 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.0156917484528427, ce=49.42960529152406
Local test acc @ epoch 89: 0.9404
Global evaluate on test data...
Evaluate data in 82.81 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.0278184370163383, ce=49.546395363063986
Global test acc : 0.9392
Global prompt norm: 53.485198974609375
Global epoch 90...
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.87 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=0.9975816875422766, ce=50.02534351873835
Local test acc @ epoch 90: 0.9392
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.79 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.9909927648141843, ce=50.293834616284855
Local test acc @ epoch 90: 0.9404
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.76 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.0032135149754515, ce=50.06238958376263
Local test acc @ epoch 90: 0.9404
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.55 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.9956078266878741, ce=50.110373820733585
Local test acc @ epoch 90: 0.9404
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.8845239910510702, ce=53.3288956388421
Local test acc @ epoch 90: 0.945
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.62 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.0006274827029726, ce=50.155201903176966
Local test acc @ epoch 90: 0.9392
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.92 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8421601899173281, ce=54.85842734520588
Local test acc @ epoch 90: 0.9438
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.75 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.9967711299931238, ce=50.004704046686854
Local test acc @ epoch 90: 0.9404
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.9830758287272322, ce=50.38549202735271
Local test acc @ epoch 90: 0.9404
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.005475582332786, ce=50.24595264119839
Local test acc @ epoch 90: 0.9404
Global evaluate on test data...
Evaluate data in 82.88 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.9791536243683702, ce=51.14421784987143
Global test acc : 0.9404
Global prompt norm: 53.459415435791016
Global epoch 91...
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.66 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9335517839554253, ce=51.771445668071784
Local test acc @ epoch 91: 0.9427
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.55 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.258404206792149, ce=32.458194295200734
Local test acc @ epoch 91: 0.9392
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.59 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9461846832835347, ce=51.59509427831807
Local test acc @ epoch 91: 0.9427
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9435474544490149, ce=51.55336355506827
Local test acc @ epoch 91: 0.9415
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.14 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.1439549922943115, ce=35.86047279287916
Local test acc @ epoch 91: 0.9358
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.96 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9383161221075496, ce=52.084943263902574
Local test acc @ epoch 91: 0.9427
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.68 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.936178990460317, ce=51.917880556998995
Local test acc @ epoch 91: 0.9427
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.49 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9426285717465462, ce=51.75027906785318
Local test acc @ epoch 91: 0.9427
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.89 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9492657031487981, ce=51.724095510780266
Local test acc @ epoch 91: 0.9415
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.63 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9356669854680333, ce=52.48862079305386
Local test acc @ epoch 91: 0.9415
Global evaluate on test data...
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.057829926867004, ce=49.24252473323717
Global test acc : 0.9381
Global prompt norm: 53.43160629272461
Global epoch 92...
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9074070912982346, ce=53.864042194611436
Local test acc @ epoch 92: 0.9427
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.51 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.021019988103744, ce=50.55314450745189
Local test acc @ epoch 92: 0.9415
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.0229780214642166, ce=50.31841764537566
Local test acc @ epoch 92: 0.9392
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.0319953052275772, ce=50.28124818014442
Local test acc @ epoch 92: 0.9404
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.73 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8547190919928594, ce=55.06660671409117
Local test acc @ epoch 92: 0.9438
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.76 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.01133247252998, ce=50.87832732594341
Local test acc @ epoch 92: 0.9415
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.86 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.0217616011243347, ce=50.517486607262846
Local test acc @ epoch 92: 0.9404
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.82 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.9790356356069583, ce=51.64428105485548
Local test acc @ epoch 92: 0.9404
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.0306005434158745, ce=50.296305455199075
Local test acc @ epoch 92: 0.9404
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.89 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.0342004233544027, ce=50.365481595380594
Local test acc @ epoch 92: 0.9415
Global evaluate on test data...
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.9999149479997267, ce=51.54929810270257
Global test acc : 0.9404
Global prompt norm: 53.42244338989258
Global epoch 93...
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.7029897492193413e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.2128534754481883, ce=35.450509465068855
Local test acc @ epoch 93: 0.9381
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.62 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9444972921948914, ce=52.676531240480756
Local test acc @ epoch 93: 0.9427
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.87 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9565222635181672, ce=52.78912010542843
Local test acc @ epoch 93: 0.9415
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.75 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9572600443428809, ce=52.521118514034725
Local test acc @ epoch 93: 0.9427
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.75 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9565173201604721, ce=52.31319287501344
Local test acc @ epoch 93: 0.9427
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.81 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9632855117867846, ce=52.324406895068805
Local test acc @ epoch 93: 0.9415
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.931814674937397, ce=52.78430658742922
Local test acc @ epoch 93: 0.9427
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.57 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9550925919769007, ce=52.20166687571675
Local test acc @ epoch 93: 0.9427
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9534484180835409, ce=52.45438965963661
Local test acc @ epoch 93: 0.9427
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.68 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.13622305808811, ce=39.08953318464647
Local test acc @ epoch 93: 0.945
Global evaluate on test data...
Evaluate data in 82.49 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.0421963744207259, ce=50.368336668801966
Global test acc : 0.9404
Global prompt norm: 53.4078254699707
Global epoch 94...
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.69 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.0077550258111516, ce=51.615901282074255
Local test acc @ epoch 94: 0.9415
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.05 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9490540530703483, ce=52.96000111431157
Local test acc @ epoch 94: 0.9427
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.42 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.994373426524871, ce=51.90070140033687
Local test acc @ epoch 94: 0.9415
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.69 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8325575863549469, ce=56.28601210707918
Local test acc @ epoch 94: 0.9438
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.75 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.8794863595875031, ce=54.48845000660747
Local test acc @ epoch 94: 0.945
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.6 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9937691951016767, ce=51.951143422258006
Local test acc @ epoch 94: 0.9415
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.91 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.9969012671654377, ce=51.66552678379444
Local test acc @ epoch 94: 0.9404
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.6 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.0074095332294428, ce=51.82661273501335
Local test acc @ epoch 94: 0.9415
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.86 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9800292155064574, ce=52.32490809029395
Local test acc @ epoch 94: 0.9427
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.0069828864631303, ce=51.62413469367071
Local test acc @ epoch 94: 0.9415
Global evaluate on test data...
Evaluate data in 82.73 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9718792372887287, ce=52.88357088981419
Global test acc : 0.9427
Global prompt norm: 53.391815185546875
Global epoch 95...
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.64 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.175739859222272, ce=32.94506951428335
Local test acc @ epoch 95: 0.9381
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.61 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9151778308623427, ce=54.163580798227855
Local test acc @ epoch 95: 0.9427
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.66 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9170436421665576, ce=53.98281601372115
Local test acc @ epoch 95: 0.9427
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.54 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9079636565042198, ce=54.17098621053433
Local test acc @ epoch 95: 0.9427
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.57 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.8999002876631711, ce=54.1252750781698
Local test acc @ epoch 95: 0.945
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.9 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9206221912978986, ce=53.64331954116121
Local test acc @ epoch 95: 0.9427
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.6 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9214395995533794, ce=53.78275792533105
Local test acc @ epoch 95: 0.9427
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.61 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.901122893762151, ce=54.81728552022111
Local test acc @ epoch 95: 0.9427
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.06 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9274961139084003, ce=53.81412817578797
Local test acc @ epoch 95: 0.9427
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.9461009174311926, hinge=1.1827407517564406, ce=36.637824627237585
Local test acc @ epoch 95: 0.9461
Global evaluate on test data...
Evaluate data in 82.69 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=1.030917298903159, ce=51.0485593813275
Global test acc : 0.9427
Global prompt norm: 53.37287902832031
Global epoch 96...
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.64 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=1.0061476077508489, ce=52.03356412135133
Local test acc @ epoch 96: 0.9427
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.68 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=1.003310050439397, ce=52.176075786625574
Local test acc @ epoch 96: 0.9427
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.69 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9959267432536554, ce=52.37234805045872
Local test acc @ epoch 96: 0.9427
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.68 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9850072029533736, ce=52.722226659092335
Local test acc @ epoch 96: 0.9427
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.7029897492193413e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.182808512941413, ce=42.511996732939274
Local test acc @ epoch 96: 0.9369
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.51 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=1.0001548889580123, ce=52.459245314291856
Local test acc @ epoch 96: 0.9427
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9577972779580213, ce=53.41511185672305
Local test acc @ epoch 96: 0.9427
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9472477064220184, hinge=0.8570100058109389, ce=56.33500282917548
Local test acc @ epoch 96: 0.9472
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9951522065958845, ce=52.38980952971572
Local test acc @ epoch 96: 0.9427
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.82 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9973518389080642, ce=52.136219864591546
Local test acc @ epoch 96: 0.9427
Global evaluate on test data...
Evaluate data in 82.75 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=1.0086520483734411, ce=52.258132304620304
Global test acc : 0.9427
Global prompt norm: 53.36326217651367
Global epoch 97...
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.68 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9563517001790738, ce=54.0482979170773
Local test acc @ epoch 97: 0.9427
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.66 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.911811404271957, ce=54.695538407072014
Local test acc @ epoch 97: 0.9438
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.75 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9629150355627777, ce=53.6558426323287
Local test acc @ epoch 97: 0.9427
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9653061989250533, ce=53.565412888833144
Local test acc @ epoch 97: 0.9427
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.61 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.1584409355023586, ce=40.57496706061407
Local test acc @ epoch 97: 0.9415
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9491296208232914, ce=53.9471567136432
Local test acc @ epoch 97: 0.9427
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9501780282466783, ce=53.86012891016969
Local test acc @ epoch 97: 0.9427
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.67 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9531994915883476, ce=53.59098514941854
Local test acc @ epoch 97: 0.9427
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.52 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9342627219103892, ce=54.29344663707488
Local test acc @ epoch 97: 0.9427
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.59 seconds!
[tester] 
SST2Metric: acc=0.9461009174311926, hinge=0.7854828834533691, ce=58.33013688533678
Local test acc @ epoch 97: 0.9461
Global evaluate on test data...
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.974802957762272, ce=53.62932474678809
Global test acc : 0.9427
Global prompt norm: 53.335845947265625
Global epoch 98...
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9276446027493258, ce=54.8293232699053
Local test acc @ epoch 98: 0.9427
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.92 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9304437987301328, ce=54.69965562032997
Local test acc @ epoch 98: 0.9427
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9396243576609761, ce=54.54524220457864
Local test acc @ epoch 98: 0.9427
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.62 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8961633017303747, ce=55.92399327689355
Local test acc @ epoch 98: 0.9427
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.54 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.920970203679636, ce=55.11909474364114
Local test acc @ epoch 98: 0.9427
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.54 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.9449556464448982, ce=54.32823212649844
Local test acc @ epoch 98: 0.945
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.59 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9161509198879977, ce=55.1029442603435
Local test acc @ epoch 98: 0.9427
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 1.7029897492193413e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.02 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.1868183765936335, ce=29.085782899769075
Local test acc @ epoch 98: 0.9381
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.87 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9297876576764867, ce=54.50823001686586
Local test acc @ epoch 98: 0.9427
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.92 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9004940330435377, ce=55.36501063775579
Local test acc @ epoch 98: 0.9438
Global evaluate on test data...
Evaluate data in 82.45 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.0094368873386208, ce=52.90199398775713
Global test acc : 0.9415
Global prompt norm: 53.332000732421875
Global epoch 99...
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.76 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9467455400239437, ce=54.713979283604054
Local test acc @ epoch 99: 0.9427
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.6 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9262884253755622, ce=55.23381031981302
Local test acc @ epoch 99: 0.9427
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.55 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9633790681121546, ce=54.382790941710866
Local test acc @ epoch 99: 0.9427
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9508387845590573, ce=54.415101672531264
Local test acc @ epoch 99: 0.9427
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.69 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8997854049052667, ce=55.72709459777272
Local test acc @ epoch 99: 0.9438
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9619453456423698, ce=54.44102072059562
Local test acc @ epoch 99: 0.9427
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.73 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.0379192413540062, ce=50.40675679478077
Local test acc @ epoch 99: 0.9438
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.42 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9510305037192248, ce=54.92422425856284
Local test acc @ epoch 99: 0.9438
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.47 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9442900998876729, ce=54.84036286380313
Local test acc @ epoch 99: 0.9438
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.168262766041887, ce=41.083572562681425
Local test acc @ epoch 99: 0.9415
Global evaluate on test data...
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9968704083643922, ce=53.642879381092314
Global test acc : 0.9438
Global prompt norm: 53.30813980102539
Global epoch 100...
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.94 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9417565853223888, ce=55.205837704719755
Local test acc @ epoch 100: 0.9438
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.75 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9508207172428796, ce=55.061193238704575
Local test acc @ epoch 100: 0.9427
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.67 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9444139288106096, ce=55.088410788719806
Local test acc @ epoch 100: 0.9427
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.51 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9455972811497679, ce=54.81739222675289
Local test acc @ epoch 100: 0.9438
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.57 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9575135117277093, ce=54.801268656319436
Local test acc @ epoch 100: 0.9427
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.64 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.90179506791841, ce=56.09353532703645
Local test acc @ epoch 100: 0.9427
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.79 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9266834302779732, ce=55.57208097965346
Local test acc @ epoch 100: 0.9427
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.49 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9366546464622567, ce=55.63075858299885
Local test acc @ epoch 100: 0.9438
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.6 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.0130919753958325, ce=51.942120473319235
Local test acc @ epoch 100: 0.945
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.76 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=1.1347381499929166, ce=36.738254232144136
Local test acc @ epoch 100: 0.9427
Global evaluate on test data...
Evaluate data in 82.98 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9982424394800029, ce=53.847634796702536
Global test acc : 0.9438
Global prompt norm: 53.28972625732422
Global epoch 101...
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.66 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9578836554781013, ce=55.07616207577767
Local test acc @ epoch 101: 0.9438
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.63 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9698691849314839, ce=54.722828856301966
Local test acc @ epoch 101: 0.9438
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.69 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9600326424344964, ce=54.98719889089602
Local test acc @ epoch 101: 0.9438
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.68 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9602378136521086, ce=54.76420274786993
Local test acc @ epoch 101: 0.9438
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.68 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9442586855057182, ce=55.703125874930564
Local test acc @ epoch 101: 0.9438
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.18 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9184181012144876, ce=56.07865975756164
Local test acc @ epoch 101: 0.9427
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.79 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.0491297124722683, ce=20.65162175729734
Local test acc @ epoch 101: 0.9392
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.69 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9600249430455199, ce=55.12477864256692
Local test acc @ epoch 101: 0.9427
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.58 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.0984410714665684, ce=44.68608397737555
Local test acc @ epoch 101: 0.9415
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.91 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9450852980307483, ce=55.42806758355657
Local test acc @ epoch 101: 0.9438
Global evaluate on test data...
Evaluate data in 82.75 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=1.075447489362244, ce=50.776621232339004
Global test acc : 0.9427
Global prompt norm: 53.279605865478516
Global epoch 102...
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.49 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=1.0674361307686622, ce=51.302135292543184
Local test acc @ epoch 102: 0.9427
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.81 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=1.055695971217724, ce=51.90741834727996
Local test acc @ epoch 102: 0.9427
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=1.0703321290672372, ce=51.0596787688929
Local test acc @ epoch 102: 0.9427
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8831157246860889, ce=57.153060038155374
Local test acc @ epoch 102: 0.9438
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.5 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.0653672262069283, ce=51.346207504972405
Local test acc @ epoch 102: 0.9438
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.76 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.068236845348953, ce=51.17150931402084
Local test acc @ epoch 102: 0.9438
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.49 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.068775456979734, ce=51.081383591398186
Local test acc @ epoch 102: 0.9438
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.61 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.0647242966048214, ce=51.52965185182904
Local test acc @ epoch 102: 0.9438
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.0687160054478078, ce=51.15487089944542
Local test acc @ epoch 102: 0.9438
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8282990543120498, ce=58.94814048557107
Local test acc @ epoch 102: 0.9438
Global evaluate on test data...
Evaluate data in 82.62 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.0336685399396703, ce=52.9840897026412
Global test acc : 0.9438
Global prompt norm: 53.27138137817383
Global epoch 103...
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.66 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9721706022910022, ce=55.18177774411823
Local test acc @ epoch 103: 0.9438
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.72 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9991365922700375, ce=54.29021527351589
Local test acc @ epoch 103: 0.9438
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.0132755183298654, ce=53.81344387509407
Local test acc @ epoch 103: 0.9438
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.91 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.0105805397033691, ce=53.866455078125
Local test acc @ epoch 103: 0.9438
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.5 seconds!
[tester] 
SST2Metric: acc=0.9472477064220184, hinge=0.8443455652359428, ce=58.57226982466671
Local test acc @ epoch 103: 0.9472
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.61 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.0091196025183442, ce=53.91506699028365
Local test acc @ epoch 103: 0.9438
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.0044815999652268, ce=54.248287970866635
Local test acc @ epoch 103: 0.9438
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.0169330386940492, ce=53.63271380783221
Local test acc @ epoch 103: 0.9438
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.9461009174311926, hinge=0.8984403041524625, ce=55.496808603269244
Local test acc @ epoch 103: 0.9461
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.82 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.0111161503223105, ce=53.71546043605979
Local test acc @ epoch 103: 0.9438
Global evaluate on test data...
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9837541755186309, ce=54.85277777855549
Global test acc : 0.9438
Global prompt norm: 53.25662612915039
Global epoch 104...
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.59 seconds!
[tester] 
SST2Metric: acc=0.948394495412844, hinge=0.9303962375045917, ce=55.4037519682438
Local test acc @ epoch 104: 0.9484
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.190038298248151, ce=32.578495025634766
Local test acc @ epoch 104: 0.9404
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.6 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9340983005838657, ce=56.38074699891816
Local test acc @ epoch 104: 0.9438
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.81 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9382599953117721, ce=55.97577807225218
Local test acc @ epoch 104: 0.9438
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.51 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9377987800388161, ce=56.31282438925647
Local test acc @ epoch 104: 0.9438
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.72 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8861905412936429, ce=57.52851251724663
Local test acc @ epoch 104: 0.9427
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.92 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9115868927141942, ce=57.19817317297699
Local test acc @ epoch 104: 0.9438
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.5 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.949665502670708, ce=55.89446087058531
Local test acc @ epoch 104: 0.9438
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9157090843270678, ce=56.86327750529718
Local test acc @ epoch 104: 0.9438
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.92 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9367048149808831, ce=56.27812306815331
Local test acc @ epoch 104: 0.9438
Global evaluate on test data...
Evaluate data in 82.72 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.0042315360602982, ce=54.25949051183298
Global test acc : 0.9438
Global prompt norm: 53.25033950805664
Global epoch 105...
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.995899305431121, ce=54.5553846446746
Local test acc @ epoch 105: 0.9438
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.54 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9932024457039089, ce=54.65708664360396
Local test acc @ epoch 105: 0.9438
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 1.7029897492193413e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.57 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.1049330387640437, ce=26.200305851227647
Local test acc @ epoch 105: 0.9369
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.53 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.974103717628969, ce=55.30098286899952
Local test acc @ epoch 105: 0.9438
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.06 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9874284158059217, ce=54.86744945421131
Local test acc @ epoch 105: 0.9438
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.59 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9468739623323493, ce=56.141105231888794
Local test acc @ epoch 105: 0.9438
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.5 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9923862011060802, ce=54.692914455308824
Local test acc @ epoch 105: 0.9438
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.68 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9931636644065927, ce=54.614492013913775
Local test acc @ epoch 105: 0.9438
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.1378697255335817, ce=38.59265483191254
Local test acc @ epoch 105: 0.9369
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.73 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9722438339793354, ce=55.33809647866345
Local test acc @ epoch 105: 0.9438
Global evaluate on test data...
Evaluate data in 82.58 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.110992506009723, ce=50.66732756588437
Global test acc : 0.9438
Global prompt norm: 53.26508331298828
Global epoch 106...
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.0713088009335578, ce=53.35373019297189
Local test acc @ epoch 106: 0.9438
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.0729055885874896, ce=53.31806161862995
Local test acc @ epoch 106: 0.9438
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.55 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.050126351347757, ce=54.21213891965534
Local test acc @ epoch 106: 0.9438
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.96 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.086211270148601, ce=52.90901541053702
Local test acc @ epoch 106: 0.9438
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.63 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.9761251353342598, ce=55.995134616116864
Local test acc @ epoch 106: 0.945
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.82 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.0747583852995426, ce=52.726120590069975
Local test acc @ epoch 106: 0.9438
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.95 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.090229572506126, ce=52.22779618709459
Local test acc @ epoch 106: 0.9438
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.55 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.079848289489746, ce=52.71537035320877
Local test acc @ epoch 106: 0.9438
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.85 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.080329164452509, ce=52.881590117008315
Local test acc @ epoch 106: 0.9438
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.76 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.0946692764212231, ce=51.98968645848265
Local test acc @ epoch 106: 0.9438
Global evaluate on test data...
Evaluate data in 82.66 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.0705193992054791, ce=53.35699798863962
Global test acc : 0.9438
Global prompt norm: 53.26148986816406
Global epoch 107...
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.51 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=1.04104223601315, ce=54.68677310768617
Local test acc @ epoch 107: 0.9427
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.49 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.991013828767549, ce=56.001912878193984
Local test acc @ epoch 107: 0.945
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.76 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.0234901926933078, ce=55.05982344741121
Local test acc @ epoch 107: 0.9438
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.54 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.0042872428894043, ce=55.60780782437106
Local test acc @ epoch 107: 0.9438
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.81 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.0262537396282232, ce=54.64847645190878
Local test acc @ epoch 107: 0.9438
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.01 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.9495444866495395, ce=56.71487111782809
Local test acc @ epoch 107: 0.945
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.0265942188577915, ce=54.94046660956987
Local test acc @ epoch 107: 0.9438
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.0355855959271072, ce=54.58194200708232
Local test acc @ epoch 107: 0.945
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.84 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.043483489150301, ce=54.340621143306066
Local test acc @ epoch 107: 0.9438
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.977949488053628, ce=56.19485501630591
Local test acc @ epoch 107: 0.945
Global evaluate on test data...
Evaluate data in 82.85 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.0143462233587142, ce=55.379221924948034
Global test acc : 0.945
Global prompt norm: 53.25587844848633
Global epoch 108...
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.9655278275866027, ce=56.53184708761513
Local test acc @ epoch 108: 0.945
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.62 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.9613788849716887, ce=56.68428900482458
Local test acc @ epoch 108: 0.945
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.61 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.9438264566823977, ce=57.04958752973364
Local test acc @ epoch 108: 0.945
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.910154500138869, ce=57.54239423559346
Local test acc @ epoch 108: 0.9438
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.61 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.9774288037501344, ce=56.3017062965883
Local test acc @ epoch 108: 0.945
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.56 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9724472334625525, ce=56.63763207251873
Local test acc @ epoch 108: 0.9438
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.49 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9752283446285703, ce=56.31536837236597
Local test acc @ epoch 108: 0.9438
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.48 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8872136151025055, ce=57.45645316587676
Local test acc @ epoch 108: 0.9438
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.47 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.9637558000897049, ce=56.306284458265395
Local test acc @ epoch 108: 0.945
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.62 seconds!
[tester] 
SST2Metric: acc=0.9472477064220184, hinge=0.8710964797833644, ce=58.5123106930234
Local test acc @ epoch 108: 0.9472
Global evaluate on test data...
Evaluate data in 82.33 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.9481802555399204, ce=57.22875378109993
Global test acc : 0.945
Global prompt norm: 53.232521057128906
Global epoch 109...
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.5 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.886610175491473, ce=58.24516702354501
Local test acc @ epoch 109: 0.9438
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.62 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8619034399680041, ce=59.61108051964996
Local test acc @ epoch 109: 0.9427
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.41 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.8782348982784727, ce=58.85109553205858
Local test acc @ epoch 109: 0.945
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.64 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.110500154145267, ce=41.230026770075526
Local test acc @ epoch 109: 0.9392
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.61 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.8469471625231821, ce=59.05562843532737
Local test acc @ epoch 109: 0.945
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.87 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8618894235803447, ce=58.9808293963791
Local test acc @ epoch 109: 0.9438
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.69 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9191970562716143, ce=57.54939455504811
Local test acc @ epoch 109: 0.9438
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.49 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8847704283688047, ce=58.52337849468266
Local test acc @ epoch 109: 0.9438
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.67 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.8966418712510975, ce=58.332071496806016
Local test acc @ epoch 109: 0.945
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.63 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8785658145169599, ce=58.728337559131305
Local test acc @ epoch 109: 0.9438
Global evaluate on test data...
Evaluate data in 82.53 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.9494336898173761, ce=57.738787729805765
Global test acc : 0.945
Global prompt norm: 53.21543502807617
Global epoch 110...
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.6 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8407029055674141, ce=59.65503199166114
Local test acc @ epoch 110: 0.9427
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.61 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8337400375156228, ce=60.73104679912602
Local test acc @ epoch 110: 0.9427
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8394696209408822, ce=60.14604260505886
Local test acc @ epoch 110: 0.9438
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.62 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8560411558238739, ce=59.5799541998347
Local test acc @ epoch 110: 0.9427
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 1.7029897492193413e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9334862385321101, hinge=1.3049741031926707, ce=35.80760784324156
Local test acc @ epoch 110: 0.9335
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.63 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8463593491720497, ce=59.343895028490536
Local test acc @ epoch 110: 0.9427
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.57 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.7681527356488989, ce=59.1804151272555
Local test acc @ epoch 110: 0.945
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.66 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.8123450672954594, ce=60.068997444362815
Local test acc @ epoch 110: 0.945
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.6 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.8510730900895704, ce=60.24480287744365
Local test acc @ epoch 110: 0.945
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.67 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8289737526429902, ce=59.96849623513878
Local test acc @ epoch 110: 0.9427
Global evaluate on test data...
Evaluate data in 82.6 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.9320351443159471, ce=58.60641500490521
Global test acc : 0.945
Global prompt norm: 53.192962646484375
Global epoch 111...
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.7 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8612424911709007, ce=59.96156895488774
Local test acc @ epoch 111: 0.9438
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.53 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8193561921425916, ce=61.08160333895902
Local test acc @ epoch 111: 0.9438
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.48 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.8262019332395781, ce=60.39591343031017
Local test acc @ epoch 111: 0.945
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.52 seconds!
[tester] 
SST2Metric: acc=0.9461009174311926, hinge=0.8172025855528106, ce=60.319917136376056
Local test acc @ epoch 111: 0.9461
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.6 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8378766786067857, ce=60.328920836842386
Local test acc @ epoch 111: 0.9438
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.5 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.0744582469310235, ce=24.174183539294322
Local test acc @ epoch 111: 0.9381
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.67 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8463425942517202, ce=60.08197962909664
Local test acc @ epoch 111: 0.9427
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.6 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8532309269686358, ce=59.752477943350414
Local test acc @ epoch 111: 0.9438
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.7029897492193413e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.42 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.0955371812942925, ce=13.459447029533736
Local test acc @ epoch 111: 0.9369
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8135048315065716, ce=61.683446656673325
Local test acc @ epoch 111: 0.9438
Global evaluate on test data...
Evaluate data in 82.66 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.1586618904673724, ce=44.94722723304679
Global test acc : 0.9404
Global prompt norm: 53.27876281738281
Global epoch 112...
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.56 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.1575147252564038, ce=52.574962440980684
Local test acc @ epoch 112: 0.9358
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.51 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.1772595764300144, ce=49.34203748090552
Local test acc @ epoch 112: 0.9392
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.1808068205457214, ce=49.004750697984605
Local test acc @ epoch 112: 0.9392
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.67 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.1669283569405933, ce=45.98143957295549
Local test acc @ epoch 112: 0.9404
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.68 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.0230986175187138, ce=56.134711834268835
Local test acc @ epoch 112: 0.9392
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.57 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.181406823866958, ce=51.02212202439615
Local test acc @ epoch 112: 0.9358
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.54 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.1730751641299746, ce=51.9815254561398
Local test acc @ epoch 112: 0.9369
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.66 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.1861721747512117, ce=49.65093154207282
Local test acc @ epoch 112: 0.9381
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.52 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.175624934905166, ce=50.22717918605979
Local test acc @ epoch 112: 0.9381
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.41 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.1778797162782162, ce=48.85165545262328
Local test acc @ epoch 112: 0.9392
Global evaluate on test data...
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.1728581026059772, ce=50.95408773859707
Global test acc : 0.9381
Global prompt norm: 53.258602142333984
Global epoch 113...
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.75 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.0964019670398957, ce=55.21266912757804
Local test acc @ epoch 113: 0.9381
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.6 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.1535862563946926, ce=53.14323918753808
Local test acc @ epoch 113: 0.9369
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.68 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.1462395169319364, ce=52.93725095976383
Local test acc @ epoch 113: 0.9381
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.73 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.1252147079607762, ce=54.292185897127204
Local test acc @ epoch 113: 0.9381
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.57 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.125125062575034, ce=53.62868209278911
Local test acc @ epoch 113: 0.9381
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.63 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.1516033837554651, ce=53.08287828777908
Local test acc @ epoch 113: 0.9369
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.016381088746797, ce=56.75739823787584
Local test acc @ epoch 113: 0.9404
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.61 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.1159600249124229, ce=54.58692638152236
Local test acc @ epoch 113: 0.9381
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.66 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.1316486367391885, ce=53.5755137172314
Local test acc @ epoch 113: 0.9381
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.54 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.1691379940837896, ce=51.56030500919447
Local test acc @ epoch 113: 0.9381
Global evaluate on test data...
Evaluate data in 82.54 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.1287445322089238, ce=54.039236226213085
Global test acc : 0.9381
Global prompt norm: 53.25459289550781
Global epoch 114...
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.62 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.0661979421563106, ce=55.630930489356366
Local test acc @ epoch 114: 0.9381
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.63 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.0989895391901698, ce=55.32931154583572
Local test acc @ epoch 114: 0.9381
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.0890538933080272, ce=55.2748607320523
Local test acc @ epoch 114: 0.9381
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.61 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.1071091091960943, ce=55.34190435147067
Local test acc @ epoch 114: 0.9381
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.44 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.0638313205963974, ce=56.086845852913115
Local test acc @ epoch 114: 0.9381
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.62 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.0585189040647733, ce=56.07569640273348
Local test acc @ epoch 114: 0.9392
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.66 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.0401738061817414, ce=56.53776896765473
Local test acc @ epoch 114: 0.9381
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.55 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.0796021627723624, ce=56.19312097391951
Local test acc @ epoch 114: 0.9381
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.43 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9837393191976285, ce=57.30190060116829
Local test acc @ epoch 114: 0.9427
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.56 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.0764392844033897, ce=55.58408383710669
Local test acc @ epoch 114: 0.9381
Global evaluate on test data...
Evaluate data in 82.86 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.0684081873762499, ce=56.037894992653385
Global test acc : 0.9381
Global prompt norm: 53.24479293823242
Global epoch 115...
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.57 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.0301331423838205, ce=56.819350601336275
Local test acc @ epoch 115: 0.9392
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.38 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9319167268385581, ce=59.80289294741569
Local test acc @ epoch 115: 0.9415
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.46 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=0.9979043181883086, ce=57.34899405383189
Local test acc @ epoch 115: 0.9392
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.63 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.9682738934088191, ce=57.489117613626185
Local test acc @ epoch 115: 0.945
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.63 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.0131587675952036, ce=56.820093977341955
Local test acc @ epoch 115: 0.9392
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.4 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.0386474460636803, ce=56.88193266982332
Local test acc @ epoch 115: 0.9392
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.47 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.934721631741305, ce=59.83489003312697
Local test acc @ epoch 115: 0.9415
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.45 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.012865049029709, ce=57.15924600723687
Local test acc @ epoch 115: 0.9392
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.72 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.0116197953530408, ce=57.02359750730182
Local test acc @ epoch 115: 0.9404
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.38 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.022693865889803, ce=56.896241984236134
Local test acc @ epoch 115: 0.9392
Global evaluate on test data...
Evaluate data in 82.56 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.0016973215505618, ce=57.80357532326234
Global test acc : 0.9392
Global prompt norm: 53.231224060058594
Global epoch 116...
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.49 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9590405105450831, ce=58.57923269709316
Local test acc @ epoch 116: 0.9427
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.53 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9418557849499064, ce=57.890613590905424
Local test acc @ epoch 116: 0.9438
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.63 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8543425306267695, ce=61.02894081325706
Local test acc @ epoch 116: 0.9438
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9560962292032504, ce=58.371235348762724
Local test acc @ epoch 116: 0.9427
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.6 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.960048609917317, ce=58.88231931913883
Local test acc @ epoch 116: 0.9415
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.5 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.1338228413818079, ce=44.686268797708216
Local test acc @ epoch 116: 0.9438
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.56 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.962781796761609, ce=58.26236206894621
Local test acc @ epoch 116: 0.9427
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.67 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9579176115333488, ce=58.11511422953475
Local test acc @ epoch 116: 0.9427
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.56 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9478974692318418, ce=58.3481220980303
Local test acc @ epoch 116: 0.9427
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.64 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9565878089414824, ce=58.04297284467505
Local test acc @ epoch 116: 0.9427
Global evaluate on test data...
Evaluate data in 82.6 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=1.0000577147947538, ce=58.17593579773509
Global test acc : 0.9427
Global prompt norm: 53.197174072265625
Global epoch 117...
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.9461009174311926, hinge=0.9179120719979662, ce=57.25279928784852
Local test acc @ epoch 117: 0.9461
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.45 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.9317559189752701, ce=59.500380174829324
Local test acc @ epoch 117: 0.945
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.53 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9377280681505116, ce=59.90443833377383
Local test acc @ epoch 117: 0.9438
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.9324736770139922, ce=59.341047654458144
Local test acc @ epoch 117: 0.945
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.52 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.8961877166678053, ce=59.647466187083396
Local test acc @ epoch 117: 0.945
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.67 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9456281968213003, ce=59.22054000294536
Local test acc @ epoch 117: 0.9427
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.75 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.9180405030556775, ce=59.59963100328358
Local test acc @ epoch 117: 0.945
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.54 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9370790052851405, ce=59.10624113870323
Local test acc @ epoch 117: 0.9438
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.72 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9423572032823475, ce=59.492432095588896
Local test acc @ epoch 117: 0.9438
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.48 seconds!
[tester] 
SST2Metric: acc=0.9461009174311926, hinge=0.8465687419296405, ce=61.52596034478704
Local test acc @ epoch 117: 0.9461
Global evaluate on test data...
Evaluate data in 82.32 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.9333375922036827, ce=60.19811525257356
Global test acc : 0.945
Global prompt norm: 53.168880462646484
Global epoch 118...
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.44 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.0428182171025406, ce=19.051323129496442
Local test acc @ epoch 118: 0.9381
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.39 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.868341485294727, ce=60.98409365732736
Local test acc @ epoch 118: 0.945
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.91 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.871834238734814, ce=61.10991675700616
Local test acc @ epoch 118: 0.945
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.6 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.8639914836358586, ce=60.63935078612161
Local test acc @ epoch 118: 0.945
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.52 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8818926811218262, ce=60.649127645230074
Local test acc @ epoch 118: 0.9438
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.53 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8801218741530672, ce=60.82980059702462
Local test acc @ epoch 118: 0.9438
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.42 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.844584198173033, ce=62.05804649842988
Local test acc @ epoch 118: 0.945
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.53 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.8278931783973624, ce=62.913287941468965
Local test acc @ epoch 118: 0.945
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.62 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8870185055863966, ce=60.88480618678102
Local test acc @ epoch 118: 0.9438
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.43 seconds!
[tester] 
SST2Metric: acc=0.9334862385321101, hinge=1.1089175841130248, ce=29.30898816869893
Local test acc @ epoch 118: 0.9335
Global evaluate on test data...
Evaluate data in 82.6 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.1278670862180378, ce=49.35569241724977
Global test acc : 0.9404
Global prompt norm: 53.22846221923828
Global epoch 119...
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.61 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9639547418016906, ce=58.21339773475577
Local test acc @ epoch 119: 0.9415
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.45 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.0034220065545598, ce=57.28217466161885
Local test acc @ epoch 119: 0.9415
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.42 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.1461922925546628, ce=50.92949893496452
Local test acc @ epoch 119: 0.9392
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.4 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.1392459869384766, ce=55.16269582345945
Local test acc @ epoch 119: 0.9381
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.37 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.7947645362364043, ce=53.6502813986682
Local test acc @ epoch 119: 0.9438
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.57 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.1230572822990768, ce=55.19811731740969
Local test acc @ epoch 119: 0.9392
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.86 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.0621198382946329, ce=57.2412032031138
Local test acc @ epoch 119: 0.9381
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.66 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.1116364111594104, ce=55.832661724965504
Local test acc @ epoch 119: 0.9392
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.5 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.097655003223944, ce=55.992311145187514
Local test acc @ epoch 119: 0.9392
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.41 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.123901292818402, ce=55.45930935920925
Local test acc @ epoch 119: 0.9369
Global evaluate on test data...
Evaluate data in 82.4 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.0734472318526802, ce=56.79819922490951
Global test acc : 0.9392
Global prompt norm: 53.20199203491211
Global epoch 120...
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.42 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.009828235031268, ce=57.973910235483714
Local test acc @ epoch 120: 0.9404
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.5 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.0371210990695778, ce=58.044894717155245
Local test acc @ epoch 120: 0.9392
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.56 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.0192786269231673, ce=58.09514029966582
Local test acc @ epoch 120: 0.9404
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.58 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9942784965585131, ce=58.51212384285183
Local test acc @ epoch 120: 0.9427
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.43 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9597520390781787, ce=60.61166269844825
Local test acc @ epoch 120: 0.9427
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.58 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=1.005706231528466, ce=58.27510861738013
Local test acc @ epoch 120: 0.9427
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.58 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.9746079619871367, ce=58.51907541117537
Local test acc @ epoch 120: 0.945
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.53 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.01104041633256, ce=58.32602908633171
Local test acc @ epoch 120: 0.9404
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.57 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9503175140520849, ce=60.8367019443337
Local test acc @ epoch 120: 0.9427
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.37 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.0275861713864387, ce=57.9954106742089
Local test acc @ epoch 120: 0.9404
Global evaluate on test data...
Evaluate data in 82.62 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=1.0032776473859035, ce=58.93764317363774
Global test acc : 0.9427
Global prompt norm: 53.20555877685547
Global epoch 121...
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.58 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9640093549675898, ce=59.38941332615843
Local test acc @ epoch 121: 0.9427
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.48 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9584805287352396, ce=59.25881926510312
Local test acc @ epoch 121: 0.9427
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.4 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.8655130885062962, ce=61.79196555461358
Local test acc @ epoch 121: 0.945
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.35 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.967028582861664, ce=59.93088405504139
Local test acc @ epoch 121: 0.9427
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.46 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9681044018596684, ce=59.320454798707175
Local test acc @ epoch 121: 0.9427
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.41 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9639257291041383, ce=59.110455644240076
Local test acc @ epoch 121: 0.9427
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.38 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9634035267961134, ce=59.721259580839664
Local test acc @ epoch 121: 0.9427
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.5 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=1.0865014671185695, ce=52.157218688124914
Local test acc @ epoch 121: 0.9427
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.58 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9666710074888457, ce=59.07742565050037
Local test acc @ epoch 121: 0.9427
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.67 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9560979921883399, ce=58.55452234810645
Local test acc @ epoch 121: 0.9438
Global evaluate on test data...
Evaluate data in 82.64 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9871454195145073, ce=59.827835118005034
Global test acc : 0.9427
Global prompt norm: 53.17285919189453
Global epoch 122...
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.46 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9341314823255626, ce=60.40905698723749
Local test acc @ epoch 122: 0.9427
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9266096342594252, ce=61.47825101099977
Local test acc @ epoch 122: 0.9427
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.5 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.1241286479005026, ce=54.28722325596241
Local test acc @ epoch 122: 0.9392
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.56 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9314349375733542, ce=61.05199859339163
Local test acc @ epoch 122: 0.9438
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.43 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9289837845968544, ce=60.76424565446486
Local test acc @ epoch 122: 0.9427
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.9065553813899329, ce=60.35602020123683
Local test acc @ epoch 122: 0.945
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.55 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.9214585549240812, ce=60.67684068592317
Local test acc @ epoch 122: 0.945
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.52 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.9322567379802739, ce=60.53888492409242
Local test acc @ epoch 122: 0.945
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.41 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.1166919262037365, ce=53.27933474199487
Local test acc @ epoch 122: 0.945
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.69 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9403649120155825, ce=60.58083640982252
Local test acc @ epoch 122: 0.9427
Global evaluate on test data...
Evaluate data in 82.67 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9806995785564457, ce=60.52269485893599
Global test acc : 0.9427
Global prompt norm: 53.15113830566406
Global epoch 123...
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.57 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.9249902165264164, ce=61.74996311292736
Local test acc @ epoch 123: 0.945
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.51 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.9161919278836032, ce=62.21386253286939
Local test acc @ epoch 123: 0.945
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.51 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.9033306935511598, ce=61.05795592561774
Local test acc @ epoch 123: 0.945
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.67 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.9248793628237663, ce=61.44380079496891
Local test acc @ epoch 123: 0.945
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.59 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9366361679287132, ce=61.239563198264584
Local test acc @ epoch 123: 0.9438
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.41 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.9291004478384596, ce=61.21752779199443
Local test acc @ epoch 123: 0.945
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.55 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.9175634690380972, ce=61.32627672667897
Local test acc @ epoch 123: 0.945
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.41 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=1.2882263332331947, ce=36.621075551444235
Local test acc @ epoch 123: 0.9427
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.51 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9297127067495924, ce=61.1043572732068
Local test acc @ epoch 123: 0.9438
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.0593861789878356, ce=22.63053881793941
Local test acc @ epoch 123: 0.9392
Global evaluate on test data...
Evaluate data in 82.36 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.1089436373579393, ce=55.38725245764496
Global test acc : 0.9438
Global prompt norm: 53.12925720214844
Global epoch 124...
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.79 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.1045245905534937, ce=55.77794955192356
Local test acc @ epoch 124: 0.9438
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.68 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.1024497102159974, ce=55.84192762462371
Local test acc @ epoch 124: 0.9438
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.43 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.1069517879311097, ce=55.50902434882768
Local test acc @ epoch 124: 0.9438
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.69 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.0058815457405301, ce=59.98214301713016
Local test acc @ epoch 124: 0.945
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.53 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.8786049326625439, ce=62.992504084875826
Local test acc @ epoch 124: 0.945
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.56 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.1061757113955437, ce=55.586663412391594
Local test acc @ epoch 124: 0.9438
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.47 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.1052347104483788, ce=55.63742222917189
Local test acc @ epoch 124: 0.9438
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.46 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.1065397525052412, ce=55.51716442283141
Local test acc @ epoch 124: 0.9438
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.44 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.102945708353585, ce=55.94792122797135
Local test acc @ epoch 124: 0.9438
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.45 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.106376612951996, ce=55.554881874574434
Local test acc @ epoch 124: 0.9438
Global evaluate on test data...
Evaluate data in 82.35 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.0825204411777882, ce=57.10442793259927
Global test acc : 0.9438
Global prompt norm: 53.12531661987305
Global epoch 125...
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.6 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.0784951568743504, ce=57.297845857952716
Local test acc @ epoch 125: 0.9438
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.53 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.076867615411041, ce=57.40938323134676
Local test acc @ epoch 125: 0.9438
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.73 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.0718835428220417, ce=57.746012591440746
Local test acc @ epoch 125: 0.9438
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.44 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.068248897517493, ce=57.80275369346688
Local test acc @ epoch 125: 0.9438
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.54 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.0751785094584894, ce=57.51503872652666
Local test acc @ epoch 125: 0.9438
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.45 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.0772383628635231, ce=57.373791930872365
Local test acc @ epoch 125: 0.9438
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.44 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.074750484676536, ce=57.507710553090504
Local test acc @ epoch 125: 0.9438
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.69 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.0776531936925486, ce=57.32249247699703
Local test acc @ epoch 125: 0.9438
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.46 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.9172905869440201, ce=62.119255520881865
Local test acc @ epoch 125: 0.945
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.69 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8572796944084518, ce=63.7710714427703
Local test acc @ epoch 125: 0.9438
Global evaluate on test data...
Evaluate data in 82.4 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.0453054226866556, ce=58.88573791783884
Global test acc : 0.9438
Global prompt norm: 53.117618560791016
Global epoch 126...
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.64 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.020086835283752, ce=59.79801538449909
Local test acc @ epoch 126: 0.9438
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.4 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.0283003684577592, ce=59.511898600727044
Local test acc @ epoch 126: 0.9438
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.43 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.0295373059194022, ce=59.483571568760304
Local test acc @ epoch 126: 0.9438
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.44 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.0272624602011584, ce=59.560857160375754
Local test acc @ epoch 126: 0.9438
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.41 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.0230847717425144, ce=59.799307096988784
Local test acc @ epoch 126: 0.9438
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.53 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=1.0021113474434669, ce=60.30031928666141
Local test acc @ epoch 126: 0.9427
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.44 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.0329790115356445, ce=59.32813826394737
Local test acc @ epoch 126: 0.9438
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.37 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.8998332023620605, ce=61.22271959497294
Local test acc @ epoch 126: 0.945
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.57 seconds!
[tester] 
SST2Metric: acc=0.9461009174311926, hinge=0.8405087584749275, ce=64.4042739868164
Local test acc @ epoch 126: 0.9461
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.51 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.0295902917144495, ce=59.401905129808895
Local test acc @ epoch 126: 0.9438
Global evaluate on test data...
Evaluate data in 82.56 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9994170075162835, ce=60.51736544687814
Global test acc : 0.9438
Global prompt norm: 53.106109619140625
Global epoch 127...
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.54 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.9533086173031309, ce=61.76105894736194
Local test acc @ epoch 127: 0.945
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.53 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.1168537905456823, ce=50.80514774847468
Local test acc @ epoch 127: 0.945
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.44 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9113715854259806, ce=62.411876398489014
Local test acc @ epoch 127: 0.9438
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.5 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9668324059302654, ce=61.40550021950258
Local test acc @ epoch 127: 0.9438
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.6 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.9565394296558625, ce=61.47664421851482
Local test acc @ epoch 127: 0.945
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.48 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9520141006609716, ce=61.77594379110074
Local test acc @ epoch 127: 0.9438
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.52 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9623405299055467, ce=61.58099113254372
Local test acc @ epoch 127: 0.9438
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.41 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9479014151686922, ce=62.13022092066774
Local test acc @ epoch 127: 0.9438
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.67 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.9360889688544317, ce=62.1013937083953
Local test acc @ epoch 127: 0.945
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.45 seconds!
[tester] 
SST2Metric: acc=0.9461009174311926, hinge=0.8844853891145199, ce=62.815124931685425
Local test acc @ epoch 127: 0.9461
Global evaluate on test data...
Evaluate data in 82.48 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9830202662616695, ce=61.436435874449
Global test acc : 0.9438
Global prompt norm: 53.090431213378906
Global epoch 128...
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.52 seconds!
[tester] 
SST2Metric: acc=0.9461009174311926, hinge=0.9043511294443672, ce=62.99476445049321
Local test acc @ epoch 128: 0.9461
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.38 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.9053322547072664, ce=62.880654571253224
Local test acc @ epoch 128: 0.945
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.45 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.9253588860188056, ce=62.618173301766774
Local test acc @ epoch 128: 0.945
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.38 seconds!
[tester] 
SST2Metric: acc=0.9461009174311926, hinge=0.9149784298118101, ce=62.58169937133789
Local test acc @ epoch 128: 0.9461
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.63 seconds!
[tester] 
SST2Metric: acc=0.9461009174311926, hinge=0.9093108264678115, ce=61.85563369191021
Local test acc @ epoch 128: 0.9461
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.44 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.887676567112634, ce=63.11376130690268
Local test acc @ epoch 128: 0.945
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.62 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.9048301670529427, ce=63.46255958627123
Local test acc @ epoch 128: 0.945
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.46 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.9820333445837738, ce=57.113117148023136
Local test acc @ epoch 128: 0.945
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.68 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8652351755614675, ce=63.22423952435135
Local test acc @ epoch 128: 0.9438
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.42 seconds!
[tester] 
SST2Metric: acc=0.9461009174311926, hinge=0.9228419776356548, ce=62.768846494342206
Local test acc @ epoch 128: 0.9461
Global evaluate on test data...
Evaluate data in 82.46 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.9215569933620068, ce=62.96682095308916
Global test acc : 0.945
Global prompt norm: 53.06883239746094
Global epoch 129...
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.5 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8649227072339539, ce=63.82106308543354
Local test acc @ epoch 129: 0.9438
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.72 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8752699816992523, ce=63.562942574877255
Local test acc @ epoch 129: 0.9438
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.43 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.8205163981936393, ce=65.67560892367581
Local test acc @ epoch 129: 0.945
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.61 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.8592111430036913, ce=63.760201375418845
Local test acc @ epoch 129: 0.945
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.7029897492193413e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.51 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.9697913545260736, ce=9.9061973991744
Local test acc @ epoch 129: 0.9404
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.36 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8834836723607614, ce=63.65166074420334
Local test acc @ epoch 129: 0.9438
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 5.9604641222676946e-08
Local loss @ local epoch 3: 2.9802320611338473e-08
Local loss @ local epoch 4: 2.9802320611338473e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.41 seconds!
[tester] 
SST2Metric: acc=0.9346330275229358, hinge=0.9893447985069468, ce=7.793822857218051
Local test acc @ epoch 129: 0.9346
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.41 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8736276189121631, ce=63.775707804828606
Local test acc @ epoch 129: 0.9438
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.61 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.8693522357065743, ce=63.921408382030805
Local test acc @ epoch 129: 0.945
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.36 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.8384768547268089, ce=64.729775630006
Local test acc @ epoch 129: 0.945
Global evaluate on test data...
Evaluate data in 82.6 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.1680782934941283, ce=32.295724046339686
Global test acc : 0.9369
Global prompt norm: 53.421688079833984
Global epoch 130...
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.57 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.0581066017850824, ce=51.96743557431282
Local test acc @ epoch 130: 0.9358
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.4 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.2024050021390302, ce=34.85007777782755
Local test acc @ epoch 130: 0.9369
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.42 seconds!
[tester] 
SST2Metric: acc=0.9334862385321101, hinge=1.223450236364242, ce=48.520794124778256
Local test acc @ epoch 130: 0.9335
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 2.9802320611338473e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.49 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=0.9663997374543356, ce=24.792411104254768
Local test acc @ epoch 130: 0.9369
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.63 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.1093700916395275, ce=50.95554218817195
Local test acc @ epoch 130: 0.9358
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.49 seconds!
[tester] 
SST2Metric: acc=0.9346330275229358, hinge=1.2471789854382156, ce=47.44992173921078
Local test acc @ epoch 130: 0.9346
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.3 seconds!
[tester] 
SST2Metric: acc=0.9346330275229358, hinge=1.2499221464909545, ce=44.70384632775543
Local test acc @ epoch 130: 0.9346
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.53 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=0.9851025681976878, ce=46.768802642822266
Local test acc @ epoch 130: 0.9392
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.47 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.1771374645583126, ce=48.484599612174776
Local test acc @ epoch 130: 0.9358
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 2.384185648907078e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.58 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.3461197570923271, ce=17.427425463265234
Local test acc @ epoch 130: 0.9381
Global evaluate on test data...
Evaluate data in 82.52 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.1687989059938204, ce=44.44552349825518
Global test acc : 0.9381
Global prompt norm: 53.46284866333008
Global epoch 131...
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.48 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.1685654417090459, ce=44.746318397172
Local test acc @ epoch 131: 0.9381
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.55 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.1677099521007013, ce=45.052402846310116
Local test acc @ epoch 131: 0.9369
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.62 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.1745416330635001, ce=45.79746890286787
Local test acc @ epoch 131: 0.9369
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.7 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.1677582526425703, ce=44.73459016292467
Local test acc @ epoch 131: 0.9381
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.37 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.1672646430654263, ce=44.8963343069094
Local test acc @ epoch 131: 0.9369
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.1669379089950422, ce=45.41934900546293
Local test acc @ epoch 131: 0.9369
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.67 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.1679867888809343, ce=44.829399458858944
Local test acc @ epoch 131: 0.9369
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.53 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.1679789495030675, ce=45.03672885019845
Local test acc @ epoch 131: 0.9381
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.5 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.1733341588886506, ce=45.64470795097701
Local test acc @ epoch 131: 0.9369
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.57 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.167747176021611, ce=44.8064148929141
Local test acc @ epoch 131: 0.9381
Global evaluate on test data...
Evaluate data in 82.54 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.1691543181008155, ce=45.1016154158006
Global test acc : 0.9369
Global prompt norm: 53.466121673583984
Global epoch 132...
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.56 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.168441389678815, ce=45.49407119051032
Local test acc @ epoch 132: 0.9369
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.43 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.1688773763289146, ce=45.749911876993444
Local test acc @ epoch 132: 0.9369
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.45 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.173467850466387, ce=46.20626824055243
Local test acc @ epoch 132: 0.9369
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.56 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.1686100916031303, ce=45.74664229646735
Local test acc @ epoch 132: 0.9369
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.47 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.1676015832008573, ce=46.17875566395051
Local test acc @ epoch 132: 0.9369
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.61 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.1740944298035507, ce=46.30797531407907
Local test acc @ epoch 132: 0.9369
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.75 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.1683658481737889, ce=45.49706362803048
Local test acc @ epoch 132: 0.9369
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.45 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.1682656380014682, ce=45.40833131982646
Local test acc @ epoch 132: 0.9369
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.4 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.1691007526642685, ce=45.416728553422
Local test acc @ epoch 132: 0.9369
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.68 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.1676103850023463, ce=45.58173380860495
Local test acc @ epoch 132: 0.9369
Global evaluate on test data...
Evaluate data in 82.66 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.1696466393427019, ce=45.76377592174285
Global test acc : 0.9369
Global prompt norm: 53.46990203857422
Global epoch 133...
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.56 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.173903469645649, ce=46.860562525757956
Local test acc @ epoch 133: 0.9369
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.53 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.1692066214500216, ce=46.478238237013514
Local test acc @ epoch 133: 0.9369
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.56 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.1732910554343408, ce=46.806004550478875
Local test acc @ epoch 133: 0.9369
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.67 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.1691128070201349, ce=46.192827522207836
Local test acc @ epoch 133: 0.9369
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.4 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.1689444594426985, ce=46.45419290525104
Local test acc @ epoch 133: 0.9369
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.53 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.1680794702757389, ce=46.27757305180261
Local test acc @ epoch 133: 0.9369
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.58 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.1690232666260605, ce=46.17668862299088
Local test acc @ epoch 133: 0.9369
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.67 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.170033087424182, ce=46.098008497045676
Local test acc @ epoch 133: 0.9369
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.54 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.169060812083953, ce=46.09081338304992
Local test acc @ epoch 133: 0.9369
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.52 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.167299191886132, ce=46.95909909589575
Local test acc @ epoch 133: 0.9369
Global evaluate on test data...
Evaluate data in 82.86 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.1700007587397865, ce=46.44455544008027
Global test acc : 0.9369
Global prompt norm: 53.4741096496582
Global epoch 134...
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.53 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.168880687941105, ce=46.79536738964396
Local test acc @ epoch 134: 0.9369
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.51 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.1687283406563855, ce=46.91652647945859
Local test acc @ epoch 134: 0.9369
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.49 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.1700573033149089, ce=46.80320218287477
Local test acc @ epoch 134: 0.9369
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.41 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.168202275529914, ce=47.189515175075705
Local test acc @ epoch 134: 0.9369
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.55 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.1675117978262246, ce=46.99756111355003
Local test acc @ epoch 134: 0.9369
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.58 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.16569715902346, ce=47.77522823788704
Local test acc @ epoch 134: 0.9358
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.61 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.1683764129603675, ce=47.2360104902075
Local test acc @ epoch 134: 0.9369
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.57 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.1686847713015496, ce=46.881112824886216
Local test acc @ epoch 134: 0.9369
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.1731053514218113, ce=47.46139015407737
Local test acc @ epoch 134: 0.9358
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.51 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.1724341309398687, ce=47.45145370763376
Local test acc @ epoch 134: 0.9369
Global evaluate on test data...
Evaluate data in 82.56 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.169396214528915, ce=47.156634339498815
Global test acc : 0.9358
Global prompt norm: 53.4788703918457
Global epoch 135...
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.39 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.1672577595492022, ce=47.623445843337876
Local test acc @ epoch 135: 0.9358
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.37 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.1707055109356521, ce=48.15322760485728
Local test acc @ epoch 135: 0.9358
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.9 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.1657684461786113, ce=47.75469057275615
Local test acc @ epoch 135: 0.9358
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.171535605684333, ce=48.11963646565009
Local test acc @ epoch 135: 0.9369
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.53 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.1661949201461372, ce=47.96626827694954
Local test acc @ epoch 135: 0.9358
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.59 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.169048040285023, ce=47.54511390476052
Local test acc @ epoch 135: 0.9358
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.62 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.166197916783324, ce=48.0366302280251
Local test acc @ epoch 135: 0.9358
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.44 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.1624842936839532, ce=48.63901110307886
Local test acc @ epoch 135: 0.9358
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.1671788801840686, ce=47.67898108106141
Local test acc @ epoch 135: 0.9358
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.69 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.1676251100837638, ce=47.53541816921409
Local test acc @ epoch 135: 0.9358
Global evaluate on test data...
Evaluate data in 82.7 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.1676816896561089, ce=47.912442338576014
Global test acc : 0.9358
Global prompt norm: 53.48420715332031
Global epoch 136...
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.46 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.1580425796158818, ce=49.5542021585167
Local test acc @ epoch 136: 0.9358
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.7 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.164467094141409, ce=48.41651822011405
Local test acc @ epoch 136: 0.9358
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.38 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.1622692991834167, ce=48.89136764106401
Local test acc @ epoch 136: 0.9358
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.54 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.1678528851325358, ce=48.92407065575276
Local test acc @ epoch 136: 0.9358
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.42 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.164161268724214, ce=48.49345019979214
Local test acc @ epoch 136: 0.9358
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.47 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.1667880377638231, ce=48.336374055354966
Local test acc @ epoch 136: 0.9358
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.62 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.1650569504554118, ce=48.324155929985395
Local test acc @ epoch 136: 0.9358
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.57 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.1625751114766532, ce=48.56112579905659
Local test acc @ epoch 136: 0.9358
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.76 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.168950107119499, ce=48.847169613619464
Local test acc @ epoch 136: 0.9358
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.54 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.1625857156351072, ce=48.79661441068037
Local test acc @ epoch 136: 0.9358
Global evaluate on test data...
Evaluate data in 82.53 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.1645609195079278, ce=48.72403314572956
Global test acc : 0.9358
Global prompt norm: 53.49013137817383
Global epoch 137...
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.41 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.1629067189102873, ce=49.186949003727065
Local test acc @ epoch 137: 0.9358
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.53 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.158001750981042, ce=49.68702291786124
Local test acc @ epoch 137: 0.9358
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.55 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.1637463307161944, ce=49.77782748161106
Local test acc @ epoch 137: 0.9358
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.1516958442303018, ce=50.50776168403276
Local test acc @ epoch 137: 0.9358
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.160786171571924, ce=49.17338156043937
Local test acc @ epoch 137: 0.9358
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.61 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.1592700547034587, ce=49.37028937383529
Local test acc @ epoch 137: 0.9358
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.5 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.1601705791753367, ce=49.27111452435135
Local test acc @ epoch 137: 0.9358
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.51 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.1564990183629027, ce=49.80407511859859
Local test acc @ epoch 137: 0.9358
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.37 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.158048988482274, ce=49.42636132896493
Local test acc @ epoch 137: 0.9358
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.49 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.1655553962112566, ce=49.657561450923254
Local test acc @ epoch 137: 0.9358
Global evaluate on test data...
Evaluate data in 82.68 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.1600962844463663, ce=49.599966381667954
Global test acc : 0.9358
Global prompt norm: 53.49642562866211
Global epoch 138...
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.68 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.1513786031565536, ce=50.627935497038955
Local test acc @ epoch 138: 0.9358
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.1588026908559537, ce=50.72454403518537
Local test acc @ epoch 138: 0.9358
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.53 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.1545860942350614, ce=50.19003078915657
Local test acc @ epoch 138: 0.9358
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.1553940838630046, ce=50.0878457585606
Local test acc @ epoch 138: 0.9358
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.49 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.1608362700961052, ce=50.56299874541956
Local test acc @ epoch 138: 0.9358
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.7 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.1494932743387485, ce=50.759456109563146
Local test acc @ epoch 138: 0.9358
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.73 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.143361421900058, ce=51.45621385486848
Local test acc @ epoch 138: 0.9358
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.75 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.1579972297773449, ce=50.09800527730119
Local test acc @ epoch 138: 0.9358
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.53 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.153513514667476, ce=50.309117448439295
Local test acc @ epoch 138: 0.9358
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.62 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.1517939173847163, ce=50.349292860118624
Local test acc @ epoch 138: 0.9358
Global evaluate on test data...
Evaluate data in 82.53 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.1542946942355654, ce=50.537154276436624
Global test acc : 0.9358
Global prompt norm: 53.50264358520508
Global epoch 139...
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.64 seconds!
[tester] 
SST2Metric: acc=0.9346330275229358, hinge=1.1481639332727556, ce=51.054122119868566
Local test acc @ epoch 139: 0.9346
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.61 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.1516489676379282, ce=51.051233414116254
Local test acc @ epoch 139: 0.9358
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.57 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.1426073061216862, ce=51.581751202224595
Local test acc @ epoch 139: 0.9358
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.66 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.1335259774409303, ce=52.335009338658885
Local test acc @ epoch 139: 0.9358
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.1543287749684186, ce=51.566965540614696
Local test acc @ epoch 139: 0.9358
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.64 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.1433941421158818, ce=51.30762691672789
Local test acc @ epoch 139: 0.9358
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.1400115555579509, ce=51.71395618543713
Local test acc @ epoch 139: 0.9358
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.43 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.1454458389807185, ce=51.28560879908571
Local test acc @ epoch 139: 0.9358
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.45 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.1469634738537149, ce=51.15598535100254
Local test acc @ epoch 139: 0.9358
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.43 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.1516862703025887, ce=51.76017904719082
Local test acc @ epoch 139: 0.9358
Global evaluate on test data...
Evaluate data in 82.53 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.1464861686076593, ce=51.51092277316872
Global test acc : 0.9358
Global prompt norm: 53.50785827636719
Global epoch 140...
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.44 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.1418870764041165, ce=52.85499194783902
Local test acc @ epoch 140: 0.9358
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.58 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.145225743634985, ce=52.65319729726249
Local test acc @ epoch 140: 0.9358
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.42 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.1372966000793177, ce=52.126871056512954
Local test acc @ epoch 140: 0.9358
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.42 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.1432892598143412, ce=52.00545288225926
Local test acc @ epoch 140: 0.9358
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.58 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.1330244125576194, ce=52.25485876940806
Local test acc @ epoch 140: 0.9358
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.48 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.1385486235312365, ce=52.03149981017506
Local test acc @ epoch 140: 0.9358
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.47 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.135371678466097, ce=52.247831922058666
Local test acc @ epoch 140: 0.9358
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.73 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.1292114345305557, ce=52.608052559948845
Local test acc @ epoch 140: 0.9358
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.46 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.1323651829990773, ce=52.49102643214235
Local test acc @ epoch 140: 0.9358
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.1233112746422445, ce=53.099537700688074
Local test acc @ epoch 140: 0.9358
Global evaluate on test data...
Evaluate data in 82.51 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.1367488213635366, ce=52.47713774934821
Global test acc : 0.9358
Global prompt norm: 53.511383056640625
Global epoch 141...
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.1140344077294027, ce=53.757560484999914
Local test acc @ epoch 141: 0.9369
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.5 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.1335755444447928, ce=52.91758346557617
Local test acc @ epoch 141: 0.9358
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.61 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.1220772310134468, ce=53.31596084034771
Local test acc @ epoch 141: 0.9358
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.69 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.1275079687800975, ce=52.96724186468562
Local test acc @ epoch 141: 0.9358
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.53 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.1298527717590332, ce=53.96027220279799
Local test acc @ epoch 141: 0.9358
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.72 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.1217548322240147, ce=53.144028339910946
Local test acc @ epoch 141: 0.9358
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.64 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.124424695968628, ce=53.145048718933666
Local test acc @ epoch 141: 0.9358
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.62 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.118419008517484, ce=53.41073177932599
Local test acc @ epoch 141: 0.9358
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.41 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.1334817606374759, ce=53.78683930143304
Local test acc @ epoch 141: 0.9358
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.59 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.1263850303964877, ce=53.055174661338874
Local test acc @ epoch 141: 0.9358
Global evaluate on test data...
Evaluate data in 82.66 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.1259076026601529, ce=53.39574243388045
Global test acc : 0.9358
Global prompt norm: 53.51279067993164
Global epoch 142...
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.63 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.116225343231761, ce=55.04086734176776
Local test acc @ epoch 142: 0.9358
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.55 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.1047603274704119, ce=54.351284342074614
Local test acc @ epoch 142: 0.9392
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.54 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.1159400458729596, ce=53.83005880653312
Local test acc @ epoch 142: 0.9358
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.51 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.1122909204675517, ce=54.058611843564094
Local test acc @ epoch 142: 0.9369
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.52 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.119530529057214, ce=54.9334775592209
Local test acc @ epoch 142: 0.9358
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.47 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.1154159930867886, ce=53.91967150486937
Local test acc @ epoch 142: 0.9358
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.5 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.1110935648646922, ce=53.9589461580329
Local test acc @ epoch 142: 0.9358
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.51 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.1138544082641602, ce=53.961052955837424
Local test acc @ epoch 142: 0.9358
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.67 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.1086924666658453, ce=54.13400296552466
Local test acc @ epoch 142: 0.9369
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.67 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.1229251284118091, ce=53.77034399050091
Local test acc @ epoch 142: 0.9358
Global evaluate on test data...
Evaluate data in 82.47 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.115094040511945, ce=54.255276776235036
Global test acc : 0.9358
Global prompt norm: 53.51266098022461
Global epoch 143...
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.6 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.1044656596052538, ce=54.728812226461706
Local test acc @ epoch 143: 0.9369
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.46 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.1020540184930925, ce=54.74634044542225
Local test acc @ epoch 143: 0.9369
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.58 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.112371558443122, ce=54.57361455794868
Local test acc @ epoch 143: 0.9358
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.69 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.0987696253925288, ce=54.80877479063262
Local test acc @ epoch 143: 0.9369
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.7 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.1049893055487117, ce=54.6245576701033
Local test acc @ epoch 143: 0.9369
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.7 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.101443780671566, ce=56.09113378262301
Local test acc @ epoch 143: 0.9369
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.47 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.0956907141099281, ce=54.921464622567555
Local test acc @ epoch 143: 0.9404
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.52 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.1004136549223453, ce=54.71330285728524
Local test acc @ epoch 143: 0.9369
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.44 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.1037086171841404, ce=56.07454919377598
Local test acc @ epoch 143: 0.9381
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.34 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.1033116874344853, ce=54.71235835224117
Local test acc @ epoch 143: 0.9369
Global evaluate on test data...
Evaluate data in 82.54 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.1038599233014867, ce=55.07004645111364
Global test acc : 0.9369
Global prompt norm: 53.5114631652832
Global epoch 144...
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.57 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.0840698732148617, ce=57.12633129434848
Local test acc @ epoch 144: 0.9381
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.5 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.088217516557886, ce=55.465288319718944
Local test acc @ epoch 144: 0.9369
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.59 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.0912125832443937, ce=55.41097382011763
Local test acc @ epoch 144: 0.9381
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.58 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.0860464769765872, ce=55.49530309274656
Local test acc @ epoch 144: 0.9404
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.72 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.0926593290556461, ce=55.50744961379865
Local test acc @ epoch 144: 0.9369
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.59 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.09201607572923, ce=55.43013392457175
Local test acc @ epoch 144: 0.9369
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.7 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.100923153238559, ce=55.35006734865521
Local test acc @ epoch 144: 0.9369
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.64 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.0933624057594789, ce=55.37814765020248
Local test acc @ epoch 144: 0.9369
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.084716569393053, ce=57.20663151172323
Local test acc @ epoch 144: 0.9381
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.56 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.0890613695897093, ce=55.436012198071964
Local test acc @ epoch 144: 0.9369
Global evaluate on test data...
Evaluate data in 82.67 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.0914923554166742, ce=55.86621044753888
Global test acc : 0.9381
Global prompt norm: 53.50965118408203
Global epoch 145...
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.69 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.0799880027770996, ce=56.28269909499982
Local test acc @ epoch 145: 0.9381
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.57 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.080449384286863, ce=56.12150283253521
Local test acc @ epoch 145: 0.9381
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.52 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.0617885764585722, ce=58.341240174179774
Local test acc @ epoch 145: 0.9392
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.72 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.0755132928900761, ce=56.08820755984805
Local test acc @ epoch 145: 0.9404
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.69 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.063474480165254, ce=58.1734413356956
Local test acc @ epoch 145: 0.9381
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.0772782990691858, ce=56.12690381391333
Local test acc @ epoch 145: 0.9381
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.61 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.0798008070079559, ce=56.143449380857135
Local test acc @ epoch 145: 0.9381
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.59 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.0880731573892295, ce=56.12549325085561
Local test acc @ epoch 145: 0.9381
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.69 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.0773088428952278, ce=56.15570624815215
Local test acc @ epoch 145: 0.9381
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.73 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.0801984848232444, ce=56.07892174677018
Local test acc @ epoch 145: 0.9404
Global evaluate on test data...
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.0780354377326615, ce=56.67014799205535
Global test acc : 0.9381
Global prompt norm: 53.507225036621094
Global epoch 146...
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.68 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.0669678285581257, ce=56.880394051928036
Local test acc @ epoch 146: 0.9392
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.48 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.0742085833068287, ce=56.92422922816845
Local test acc @ epoch 146: 0.9381
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.59 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.0390771157150969, ce=59.27072227548022
Local test acc @ epoch 146: 0.9415
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.61 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.0647742463908065, ce=56.81090094190125
Local test acc @ epoch 146: 0.9415
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.6 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.0637415702189874, ce=56.71072223208366
Local test acc @ epoch 146: 0.9415
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.67 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.0351668585331069, ce=59.50514945633915
Local test acc @ epoch 146: 0.9415
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.66 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.0641681251175907, ce=56.89570127714664
Local test acc @ epoch 146: 0.9404
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.84 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.0661527607419075, ce=57.079230807243135
Local test acc @ epoch 146: 0.9404
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.0664163423240731, ce=56.875834368784496
Local test acc @ epoch 146: 0.9392
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.61 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.0673153816013161, ce=56.76988297208734
Local test acc @ epoch 146: 0.9415
Global evaluate on test data...
Evaluate data in 82.69 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.0628504271900983, ce=57.50714471799518
Global test acc : 0.9415
Global prompt norm: 53.50426483154297
Global epoch 147...
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.0502404204202354, ce=57.37194600236525
Local test acc @ epoch 147: 0.9404
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.62 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.049838757296221, ce=57.92099439988443
Local test acc @ epoch 147: 0.9415
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.55 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.0510167069391374, ce=57.677035970425386
Local test acc @ epoch 147: 0.9415
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.95 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.0078601093467223, ce=60.473789530062895
Local test acc @ epoch 147: 0.9415
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.63 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.0006415428371604, ce=60.74085827048766
Local test acc @ epoch 147: 0.9415
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.75 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.04890204788348, ce=57.67671329603283
Local test acc @ epoch 147: 0.9415
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.66 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.0509503303317849, ce=57.64756512423174
Local test acc @ epoch 147: 0.9415
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.58 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.0586741254964005, ce=57.7709515422856
Local test acc @ epoch 147: 0.9415
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.56 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.0529956511401255, ce=57.500069084517456
Local test acc @ epoch 147: 0.9415
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.69 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.050758851777523, ce=57.53100767923058
Local test acc @ epoch 147: 0.9415
Global evaluate on test data...
Evaluate data in 82.7 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.0454246844720403, ce=58.40344469262919
Global test acc : 0.9415
Global prompt norm: 53.500484466552734
Global epoch 148...
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.66 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9555517030418466, ce=62.11684172744051
Local test acc @ epoch 148: 0.9427
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.55 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.034474206626962, ce=58.30223244483318
Local test acc @ epoch 148: 0.9415
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.85 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.0305730006016722, ce=58.52002793058343
Local test acc @ epoch 148: 0.9415
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.63 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.030263441418289, ce=58.83671307345049
Local test acc @ epoch 148: 0.9415
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.59 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.0324715343090372, ce=58.53354956250672
Local test acc @ epoch 148: 0.9415
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.0332461147133363, ce=58.480010356378116
Local test acc @ epoch 148: 0.9415
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.63 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.0359765411516941, ce=58.28715560633108
Local test acc @ epoch 148: 0.9415
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.75 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.0400615219676166, ce=58.696379285339916
Local test acc @ epoch 148: 0.9415
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.82 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9670715507017363, ce=61.864682678782614
Local test acc @ epoch 148: 0.9415
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.0364078950444493, ce=58.08275058291374
Local test acc @ epoch 148: 0.9404
Global evaluate on test data...
Evaluate data in 82.7 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.0235488742863366, ce=59.3932899685081
Global test acc : 0.9415
Global prompt norm: 53.4952392578125
Global epoch 149...
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.94 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.0204352807561192, ce=58.8609693334737
Local test acc @ epoch 149: 0.9415
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.011771289580459, ce=59.4030323903495
Local test acc @ epoch 149: 0.9415
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.68 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.0169400425132262, ce=59.157525963739516
Local test acc @ epoch 149: 0.9415
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.66 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9156004354494427, ce=63.56575327182035
Local test acc @ epoch 149: 0.9438
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.92 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.0095030058414565, ce=59.45521167440152
Local test acc @ epoch 149: 0.9404
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.7 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9044045483300446, ce=63.70933420723731
Local test acc @ epoch 149: 0.9427
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.62 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.016396868119546, ce=59.750089417903794
Local test acc @ epoch 149: 0.9415
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.97 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.006895979610058, ce=59.87001709544331
Local test acc @ epoch 149: 0.9404
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.76 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.0099771525881707, ce=59.47862551627903
Local test acc @ epoch 149: 0.9415
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.0158287888273188, ce=59.146161735604664
Local test acc @ epoch 149: 0.9415
Global evaluate on test data...
Evaluate data in 82.76 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9980784993652904, ce=60.5180017313826
Global test acc : 0.9427
Global prompt norm: 53.486839294433594
Global epoch 150...
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.75 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.993887730694692, ce=60.16413592417306
Local test acc @ epoch 150: 0.9415
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.94 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9854667121117268, ce=60.47006943029001
Local test acc @ epoch 150: 0.9415
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.9 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9870696592768398, ce=61.02869418782925
Local test acc @ epoch 150: 0.9427
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9922607185643747, ce=60.107457992133746
Local test acc @ epoch 150: 0.9415
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.984094506010003, ce=60.53054361605863
Local test acc @ epoch 150: 0.9415
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.9993054888664036, ce=59.747216740879445
Local test acc @ epoch 150: 0.9404
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.73 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9772397487535389, ce=61.09645140061685
Local test acc @ epoch 150: 0.9415
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8394129385641955, ce=65.97687338032854
Local test acc @ epoch 150: 0.9438
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.98 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8633952884499086, ce=65.41333154800834
Local test acc @ epoch 150: 0.9427
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.88 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9832249300195537, ce=60.55332344825115
Local test acc @ epoch 150: 0.9415
Global evaluate on test data...
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9674834680119786, ce=61.84942833436738
Global test acc : 0.9415
Global prompt norm: 53.47028350830078
Global epoch 151...
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.86 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9558400801562388, ce=61.22594948864858
Local test acc @ epoch 151: 0.9438
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.94 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9368029471931107, ce=62.65853647354546
Local test acc @ epoch 151: 0.9427
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.971633289932111, ce=60.75979778744759
Local test acc @ epoch 151: 0.9415
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.86 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9516598062777738, ce=61.82479112957596
Local test acc @ epoch 151: 0.9415
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9440779336001894, ce=62.73810293915075
Local test acc @ epoch 151: 0.9438
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.95 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9626553955428098, ce=61.24162845436586
Local test acc @ epoch 151: 0.9415
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.08 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.951264136428133, ce=61.76416484587783
Local test acc @ epoch 151: 0.9427
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.8384726594347472, ce=66.14255810658867
Local test acc @ epoch 151: 0.945
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.72 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9496484327753749, ce=61.817059298174094
Local test acc @ epoch 151: 0.9427
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.66 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.9643551231524267, ce=61.388454192275304
Local test acc @ epoch 151: 0.9404
Global evaluate on test data...
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9546791566621273, ce=62.91144260791464
Global test acc : 0.9427
Global prompt norm: 53.44639587402344
Global epoch 152...
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.84 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9347610517379341, ce=63.100148752195025
Local test acc @ epoch 152: 0.9427
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.99 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9433620172903079, ce=62.86280542776125
Local test acc @ epoch 152: 0.9415
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9072877551437518, ce=64.3867507724587
Local test acc @ epoch 152: 0.9427
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.99 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9401569935159946, ce=62.77920829702955
Local test acc @ epoch 152: 0.9427
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.73 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9440683399865387, ce=62.623442903571174
Local test acc @ epoch 152: 0.9415
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.89 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9119371405435265, ce=64.07963173542548
Local test acc @ epoch 152: 0.9427
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.73 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8536981705131881, ce=65.73534333815269
Local test acc @ epoch 152: 0.9427
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.79 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9372598446837259, ce=63.090360518989215
Local test acc @ epoch 152: 0.9427
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9347827150187361, ce=63.08237838745117
Local test acc @ epoch 152: 0.9427
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.81 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9316837284543099, ce=63.09982478290523
Local test acc @ epoch 152: 0.9438
Global evaluate on test data...
Evaluate data in 82.79 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9317240496294215, ce=64.2062638658996
Global test acc : 0.9427
Global prompt norm: 53.430850982666016
Global epoch 153...
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.91 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9219216294244889, ce=63.35430565230343
Local test acc @ epoch 153: 0.9438
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.84 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9145743606287405, ce=63.71105117097907
Local test acc @ epoch 153: 0.9427
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.73 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9252343090302354, ce=64.61298723833276
Local test acc @ epoch 153: 0.9438
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9184576524507015, ce=63.99389287966107
Local test acc @ epoch 153: 0.9415
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.91 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9067039927211377, ce=64.26962742236776
Local test acc @ epoch 153: 0.9415
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.93 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.872585279132248, ce=65.7568524911863
Local test acc @ epoch 153: 0.9438
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.9 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.197343412889253, ce=31.911822467768957
Local test acc @ epoch 153: 0.9438
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.69 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9091680071769505, ce=64.3329753350774
Local test acc @ epoch 153: 0.9415
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.59 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9035427154750999, ce=64.32550720774799
Local test acc @ epoch 153: 0.9427
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.68 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8815890714662884, ce=65.31293309062993
Local test acc @ epoch 153: 0.9427
Global evaluate on test data...
Evaluate data in 82.9 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=1.0000532920207452, ce=62.372467670965634
Global test acc : 0.9427
Global prompt norm: 53.39256286621094
Global epoch 154...
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.84 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.992565303767493, ce=62.68678882143913
Local test acc @ epoch 154: 0.9427
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 1.7029897492193413e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.99 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.1445131148767034, ce=23.05162559299294
Local test acc @ epoch 154: 0.945
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9910755594935986, ce=62.732847406229844
Local test acc @ epoch 154: 0.9427
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.68 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9909134567330736, ce=62.763515157437105
Local test acc @ epoch 154: 0.9427
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.69 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9815598015391499, ce=63.1723408480303
Local test acc @ epoch 154: 0.9415
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.72 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9864565341844471, ce=62.93670297325204
Local test acc @ epoch 154: 0.9427
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.66 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8861997105659695, ce=65.72652071331619
Local test acc @ epoch 154: 0.9427
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.79 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9626920113869764, ce=63.95086592927985
Local test acc @ epoch 154: 0.9427
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.86 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9328674001431246, ce=64.69221920048425
Local test acc @ epoch 154: 0.9427
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9922955495501877, ce=62.669599900551894
Local test acc @ epoch 154: 0.9427
Global evaluate on test data...
Evaluate data in 82.79 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.0948770505572678, ce=59.681587534213286
Global test acc : 0.9438
Global prompt norm: 53.377315521240234
Global epoch 155...
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.98 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.0911345569365616, ce=59.88149124985441
Local test acc @ epoch 155: 0.9438
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.82 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.091405400442421, ce=59.85973781620691
Local test acc @ epoch 155: 0.9438
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.57 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.0886391280987942, ce=60.0064336794232
Local test acc @ epoch 155: 0.9438
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.75 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.0862686568443929, ce=60.1538861125981
Local test acc @ epoch 155: 0.9438
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.61 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.091880894582206, ce=59.840300848724645
Local test acc @ epoch 155: 0.9438
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.81 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.909937753589875, ce=65.36712153023537
Local test acc @ epoch 155: 0.9438
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.092004867868686, ce=59.82698727528983
Local test acc @ epoch 155: 0.9438
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.76 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.0853265359861042, ce=60.225069798460794
Local test acc @ epoch 155: 0.9438
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.0895961796471831, ce=59.975357230650175
Local test acc @ epoch 155: 0.9438
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.76 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.002368957624523, ce=63.27166744547153
Local test acc @ epoch 155: 0.9438
Global evaluate on test data...
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.0665666641445335, ce=61.03998324192992
Global test acc : 0.9438
Global prompt norm: 53.37651062011719
Global epoch 156...
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.7 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.0522329435436004, ce=61.68324762746828
Local test acc @ epoch 156: 0.9438
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.76 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.0599305214138206, ce=61.32981760567481
Local test acc @ epoch 156: 0.9438
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.75 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.0577578413377113, ce=61.423191980484425
Local test acc @ epoch 156: 0.9438
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.8985062345452265, ce=65.87222066056837
Local test acc @ epoch 156: 0.945
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.058105543119098, ce=61.4138242389084
Local test acc @ epoch 156: 0.9438
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.86 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.0525038351706408, ce=61.64275255115754
Local test acc @ epoch 156: 0.9438
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.73 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.0473390500479882, ce=61.891531218082534
Local test acc @ epoch 156: 0.9438
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.0585602357846882, ce=61.37954571925172
Local test acc @ epoch 156: 0.9438
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.73 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.0599148514073924, ce=61.320412207087244
Local test acc @ epoch 156: 0.9438
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.88 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.9491441752932487, ce=64.60161856555064
Local test acc @ epoch 156: 0.945
Global evaluate on test data...
Evaluate data in 82.73 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.0321056864677218, ce=62.43267290307841
Global test acc : 0.9438
Global prompt norm: 53.37464141845703
Global epoch 157...
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.81 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=1.0142371020185839, ce=63.05080343823914
Local test acc @ epoch 157: 0.9427
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9876435174854523, ce=63.88399820590238
Local test acc @ epoch 157: 0.9427
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8880733656227042, ce=66.21330716194363
Local test acc @ epoch 157: 0.9438
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=1.0080555688350572, ce=63.31977144293829
Local test acc @ epoch 157: 0.9427
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=1.0112397823858699, ce=63.141689055556554
Local test acc @ epoch 157: 0.9427
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.63 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=1.0105625686295536, ce=63.19016293866919
Local test acc @ epoch 157: 0.9427
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8939439966044295, ce=66.4053278931784
Local test acc @ epoch 157: 0.9438
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=1.0143209028681484, ce=63.02343480521386
Local test acc @ epoch 157: 0.9427
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.81 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9972654832612484, ce=63.5475155191684
Local test acc @ epoch 157: 0.9427
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.85 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=1.0152526864218057, ce=63.01989707596805
Local test acc @ epoch 157: 0.9427
Global evaluate on test data...
Evaluate data in 82.63 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9855934545534466, ce=64.03694303320088
Global test acc : 0.9427
Global prompt norm: 53.37255096435547
Global epoch 158...
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.73 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9263342104920553, ce=65.13204543087461
Local test acc @ epoch 158: 0.9427
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.87 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.93998237487373, ce=65.10061879989205
Local test acc @ epoch 158: 0.9427
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.79 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.944851135988848, ce=64.9880638822503
Local test acc @ epoch 158: 0.9427
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.9 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.8757613470794958, ce=67.48300009911213
Local test acc @ epoch 158: 0.9415
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.922389157321475, ce=65.1940836075249
Local test acc @ epoch 158: 0.9427
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.76 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.915546242250215, ce=65.1582506162311
Local test acc @ epoch 158: 0.945
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9415209665210968, ce=65.31212199499848
Local test acc @ epoch 158: 0.9438
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9351859748910326, ce=65.1567904271117
Local test acc @ epoch 158: 0.9427
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.64 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9401876685816214, ce=64.93272602886235
Local test acc @ epoch 158: 0.9427
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.87 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9453736838944461, ce=65.02807631186388
Local test acc @ epoch 158: 0.9427
Global evaluate on test data...
Evaluate data in 82.76 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9298785192157151, ce=65.62411747503718
Global test acc : 0.9427
Global prompt norm: 53.361507415771484
Global epoch 159...
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.0 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8880452497289815, ce=65.71669454312106
Local test acc @ epoch 159: 0.9427
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.73 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8802864879643152, ce=66.28445336578089
Local test acc @ epoch 159: 0.9427
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.7 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.9194490537730926, ce=64.82395760072481
Local test acc @ epoch 159: 0.945
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8888825932773975, ce=66.0663479096299
Local test acc @ epoch 159: 0.9427
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8908355826631599, ce=66.19361740952237
Local test acc @ epoch 159: 0.9427
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.0447012175113783, ce=58.799253691227065
Local test acc @ epoch 159: 0.9415
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.89 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8911583882953049, ce=66.13100181369606
Local test acc @ epoch 159: 0.9438
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.88 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8733437564394889, ce=66.772285181448
Local test acc @ epoch 159: 0.9427
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8861151004056318, ce=65.83816937787817
Local test acc @ epoch 159: 0.9438
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.88 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8596517842843991, ce=67.38990153741399
Local test acc @ epoch 159: 0.9438
Global evaluate on test data...
Evaluate data in 82.88 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9129003078565685, ce=66.25510409993863
Global test acc : 0.9438
Global prompt norm: 53.34743881225586
Global epoch 160...
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.61 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8810143295778047, ce=66.61939120511396
Local test acc @ epoch 160: 0.9427
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.8849793005427089, ce=66.4707125742501
Local test acc @ epoch 160: 0.9415
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.93 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.881999431400124, ce=66.47331839745198
Local test acc @ epoch 160: 0.9427
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.67 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.1232478274117916, ce=16.587559647516372
Local test acc @ epoch 160: 0.9392
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.7 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.878068779586652, ce=66.7812264818664
Local test acc @ epoch 160: 0.9438
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.85 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.1791008765544366, ce=26.619619876966564
Local test acc @ epoch 160: 0.9415
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.82 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.885912987070346, ce=66.65803856805924
Local test acc @ epoch 160: 0.9427
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.02 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8352685805854447, ce=68.23497884207909
Local test acc @ epoch 160: 0.9438
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.885298833934539, ce=66.69346107692894
Local test acc @ epoch 160: 0.9427
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.8494469353912073, ce=67.4893142980173
Local test acc @ epoch 160: 0.945
Global evaluate on test data...
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.231315507801301, ce=56.084926990194056
Global test acc : 0.9415
Global prompt norm: 53.3511962890625
Global epoch 161...
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.7 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.2276308995868088, ce=56.3802041569981
Local test acc @ epoch 161: 0.9415
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.225857375958644, ce=56.51261922853802
Local test acc @ epoch 161: 0.9415
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.218601926751093, ce=57.07907555956359
Local test acc @ epoch 161: 0.9415
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.2262739129022722, ce=56.47318729785604
Local test acc @ epoch 161: 0.9415
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.03 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.2279873025526695, ce=56.331368437600794
Local test acc @ epoch 161: 0.9415
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.91 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.2278496628507563, ce=56.3670352620816
Local test acc @ epoch 161: 0.9415
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.86 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.2287484527727879, ce=56.301422084143404
Local test acc @ epoch 161: 0.9415
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.81 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.2266110980182612, ce=56.42945924811407
Local test acc @ epoch 161: 0.9415
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.7 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.2266676316567517, ce=56.43475663771323
Local test acc @ epoch 161: 0.9415
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=1.2227008583348826, ce=56.783735537747724
Local test acc @ epoch 161: 0.9427
Global evaluate on test data...
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.2259225714097328, ce=56.5113904410546
Global test acc : 0.9415
Global prompt norm: 53.35215759277344
Global epoch 162...
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.72 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.2205203388809065, ce=56.91086938840534
Local test acc @ epoch 162: 0.9415
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=1.220962205064406, ce=56.87403593150847
Local test acc @ epoch 162: 0.9427
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=1.2117282359971913, ce=57.54949076241309
Local test acc @ epoch 162: 0.9427
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.96 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.2208854649045051, ce=56.865322463009335
Local test acc @ epoch 162: 0.9415
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.96 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.2224240521772192, ce=56.7657554346487
Local test acc @ epoch 162: 0.9415
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=1.220067711051451, ce=56.95278682183782
Local test acc @ epoch 162: 0.9427
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.75 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.2222990508473248, ce=56.803666106057825
Local test acc @ epoch 162: 0.9415
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.81 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.223086339618088, ce=56.73971162148572
Local test acc @ epoch 162: 0.9415
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.2219970598133332, ce=56.81846363172619
Local test acc @ epoch 162: 0.9415
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.57 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=1.216503187057075, ce=57.2326483770248
Local test acc @ epoch 162: 0.9427
Global evaluate on test data...
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=1.220109589602969, ce=56.95361356122778
Global test acc : 0.9427
Global prompt norm: 53.35321044921875
Global epoch 163...
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=1.214420204862542, ce=57.31851157792118
Local test acc @ epoch 163: 0.9427
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.6 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=1.214027842250439, ce=57.36595381290541
Local test acc @ epoch 163: 0.9427
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.79 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=1.2038353080049566, ce=58.03969556475998
Local test acc @ epoch 163: 0.9427
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.7 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=1.2144678710797512, ce=57.33095400049052
Local test acc @ epoch 163: 0.9427
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.79 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=1.2160209909491582, ce=57.25749150547413
Local test acc @ epoch 163: 0.9427
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.6 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=1.2093969266349023, ce=57.700207911500144
Local test acc @ epoch 163: 0.9427
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.67 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=1.2167876707304508, ce=57.19746262436613
Local test acc @ epoch 163: 0.9427
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=1.2161755824307783, ce=57.2171520968096
Local test acc @ epoch 163: 0.9427
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.61 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=1.213471198300703, ce=57.4107652016736
Local test acc @ epoch 163: 0.9427
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.67 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=1.2156692382392533, ce=57.27538005583877
Local test acc @ epoch 163: 0.9427
Global evaluate on test data...
Evaluate data in 82.82 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=1.2135092052844687, ce=57.41419352960149
Global test acc : 0.9427
Global prompt norm: 53.354244232177734
Global epoch 164...
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.86 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=1.2059153810553593, ce=57.888432983958396
Local test acc @ epoch 164: 0.9427
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.9 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=1.2095987162458788, ce=57.67820750245261
Local test acc @ epoch 164: 0.9427
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.82 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=1.207002512905576, ce=57.80777750977683
Local test acc @ epoch 164: 0.9427
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.53 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=1.2090028579081964, ce=57.68778137766987
Local test acc @ epoch 164: 0.9427
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.75 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=1.2065837361397, ce=57.84047212513215
Local test acc @ epoch 164: 0.9427
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=1.2012441530140168, ce=58.18834948758467
Local test acc @ epoch 164: 0.9427
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.55 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=1.2083683232648657, ce=57.75420369139505
Local test acc @ epoch 164: 0.9427
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.68 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=1.1947860980252607, ce=58.551095595053575
Local test acc @ epoch 164: 0.9427
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.59 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=1.207007963722999, ce=57.79107959992295
Local test acc @ epoch 164: 0.9427
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.53 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=1.2088224734735051, ce=57.73065612512991
Local test acc @ epoch 164: 0.9427
Global evaluate on test data...
Evaluate data in 82.73 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=1.205923080444336, ce=57.89516071004605
Global test acc : 0.9427
Global prompt norm: 53.35532760620117
Global epoch 165...
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.63 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=1.1972190830685676, ce=58.388240289250646
Local test acc @ epoch 165: 0.9427
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.92 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=1.1984634924372402, ce=58.285561797815724
Local test acc @ epoch 165: 0.9427
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=1.198025392829825, ce=58.336775193520644
Local test acc @ epoch 165: 0.9427
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.73 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=1.1844069235915438, ce=59.08358705153159
Local test acc @ epoch 165: 0.9427
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=1.20125277545474, ce=58.18626078334423
Local test acc @ epoch 165: 0.9427
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.49 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=1.1984042727619135, ce=58.30677805909323
Local test acc @ epoch 165: 0.9427
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.59 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=1.2005466146206638, ce=58.22558117787772
Local test acc @ epoch 165: 0.9427
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.191876975768203, ce=58.69829146358945
Local test acc @ epoch 165: 0.9438
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=1.2007477655323273, ce=58.18008930311291
Local test acc @ epoch 165: 0.9427
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.95 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=1.1999241890163597, ce=58.2584137172874
Local test acc @ epoch 165: 0.9427
Global evaluate on test data...
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=1.1971879836616166, ce=58.39916365737215
Global test acc : 0.9427
Global prompt norm: 53.35640335083008
Global epoch 166...
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=1.1886091538525503, ce=58.80358823723749
Local test acc @ epoch 166: 0.9427
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.67 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.1725636184762378, ce=59.63552142501971
Local test acc @ epoch 166: 0.9438
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.73 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.1910265870050554, ce=58.743776898865306
Local test acc @ epoch 166: 0.9438
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.76 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.1884882996935364, ce=58.82966515777308
Local test acc @ epoch 166: 0.9438
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.66 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.1901157536637892, ce=58.791736042827644
Local test acc @ epoch 166: 0.9438
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=1.1881712029833313, ce=58.856349700087804
Local test acc @ epoch 166: 0.9427
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.43 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=1.1914965909555417, ce=58.72664344857592
Local test acc @ epoch 166: 0.9427
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.64 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.18721973349195, ce=58.91116966457542
Local test acc @ epoch 166: 0.9438
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.1811163359825765, ce=59.230467700083324
Local test acc @ epoch 166: 0.9438
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=1.1912367497015437, ce=58.69597237263251
Local test acc @ epoch 166: 0.9427
Global evaluate on test data...
Evaluate data in 82.93 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.187124580418298, ce=58.92760523524853
Global test acc : 0.9438
Global prompt norm: 53.357425689697266
Global epoch 167...
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.68 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.1768394916429432, ce=59.400078099802
Local test acc @ epoch 167: 0.9438
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.59 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.1591981791575021, ce=60.20088717259398
Local test acc @ epoch 167: 0.9438
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.72 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.1800274630205347, ce=59.30545775387265
Local test acc @ epoch 167: 0.9438
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.54 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.1800843597552098, ce=59.28639042705571
Local test acc @ epoch 167: 0.9438
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.55 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.1770630320277782, ce=59.37730554703179
Local test acc @ epoch 167: 0.9438
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.1772431408593413, ce=59.346260385775786
Local test acc @ epoch 167: 0.9438
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.67 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.1757425168238649, ce=59.45735469433146
Local test acc @ epoch 167: 0.9438
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.9 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.1786741335457618, ce=59.35859067724385
Local test acc @ epoch 167: 0.9438
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.67 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.1688277218319953, ce=59.78274497635868
Local test acc @ epoch 167: 0.9438
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.1802742153132728, ce=59.2369160433428
Local test acc @ epoch 167: 0.9438
Global evaluate on test data...
Evaluate data in 82.63 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.1755384830159878, ce=59.48163072778544
Global test acc : 0.9438
Global prompt norm: 53.35829162597656
Global epoch 168...
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.73 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.1443477026913145, ce=60.77034374552036
Local test acc @ epoch 168: 0.9438
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.7 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.162623427329807, ce=60.02489401441102
Local test acc @ epoch 168: 0.9438
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.61 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.1641799419298084, ce=59.91222661569578
Local test acc @ epoch 168: 0.9438
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.51 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.1676718116900242, ce=59.80235993971518
Local test acc @ epoch 168: 0.9438
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.1664268204925257, ce=59.93056127565716
Local test acc @ epoch 168: 0.9438
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.95 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.1549111287528222, ce=60.3500902368388
Local test acc @ epoch 168: 0.9438
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.87 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.163854559627148, ce=59.96645855684893
Local test acc @ epoch 168: 0.9438
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.47 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.1639380498763618, ce=59.94835529852351
Local test acc @ epoch 168: 0.9438
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.1675483852351478, ce=59.852305421041784
Local test acc @ epoch 168: 0.9438
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.42 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.1652867772163602, ce=59.96314155508619
Local test acc @ epoch 168: 0.9438
Global evaluate on test data...
Evaluate data in 82.62 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.1622382478976467, ce=60.06027183182743
Global test acc : 0.9438
Global prompt norm: 53.35890197753906
Global epoch 169...
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.149277962675882, ce=60.49868112966555
Local test acc @ epoch 169: 0.9438
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.1495658060826293, ce=60.61100373574353
Local test acc @ epoch 169: 0.9438
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.1490973463845908, ce=60.55198644935538
Local test acc @ epoch 169: 0.9438
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.1477756237764971, ce=60.609181150383904
Local test acc @ epoch 169: 0.9438
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.62 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.1490057455290348, ce=60.53929663141933
Local test acc @ epoch 169: 0.9438
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.62 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.1393908404429025, ce=60.92397325848221
Local test acc @ epoch 169: 0.9438
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.44 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.153280507533922, ce=60.43895920919716
Local test acc @ epoch 169: 0.9438
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.6 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.1282057980878637, ce=61.33095113071827
Local test acc @ epoch 169: 0.9438
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.63 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.1532835697909014, ce=60.390225471706565
Local test acc @ epoch 169: 0.9438
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.85 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.1501160236673618, ce=60.613166319120914
Local test acc @ epoch 169: 0.9438
Global evaluate on test data...
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.1470920842721921, ce=60.6613302318328
Global test acc : 0.9438
Global prompt norm: 53.359107971191406
Global epoch 170...
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.56 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.1369996508327098, ce=60.99685644447257
Local test acc @ epoch 170: 0.9438
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.84 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.1324744049562228, ce=61.10001275298792
Local test acc @ epoch 170: 0.9438
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.111020438168027, ce=61.869820621035515
Local test acc @ epoch 170: 0.9438
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.57 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.1223599232664896, ce=61.49382243025194
Local test acc @ epoch 170: 0.9438
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.59 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.1322142093553456, ce=61.14439248601231
Local test acc @ epoch 170: 0.9438
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.1311854441231544, ce=61.20321781263439
Local test acc @ epoch 170: 0.9438
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.1309989045519349, ce=61.31051989214136
Local test acc @ epoch 170: 0.9438
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.1371781060455042, ce=61.04253114472836
Local test acc @ epoch 170: 0.9438
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.6 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.1302005916560462, ce=61.37079753350774
Local test acc @ epoch 170: 0.9438
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.54 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.1325354444871254, ce=61.15060991759694
Local test acc @ epoch 170: 0.9438
Global evaluate on test data...
Evaluate data in 82.62 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.1299587039772523, ce=61.28224763082802
Global test acc : 0.9438
Global prompt norm: 53.358699798583984
Global epoch 171...
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.67 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.1050737494722418, ce=62.23457990873844
Local test acc @ epoch 171: 0.9438
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.79 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.1087454130890173, ce=62.078123355130536
Local test acc @ epoch 171: 0.9438
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.1039537246074151, ce=62.05193888812984
Local test acc @ epoch 171: 0.9438
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.52 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.092969837538693, ce=62.379989449037325
Local test acc @ epoch 171: 0.9438
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.51 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.1191121110128701, ce=61.66108689614392
Local test acc @ epoch 171: 0.9438
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.85 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.1137674664138655, ce=61.711354806882525
Local test acc @ epoch 171: 0.9438
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.59 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.1135548364131822, ce=61.75857036485584
Local test acc @ epoch 171: 0.9438
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.59 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.1141687839403065, ce=61.75726041881316
Local test acc @ epoch 171: 0.9438
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.1187522301980115, ce=61.61872898766754
Local test acc @ epoch 171: 0.9438
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.1128586672861642, ce=61.80114224635133
Local test acc @ epoch 171: 0.9438
Global evaluate on test data...
Evaluate data in 82.66 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.1106332332716076, ce=61.924896905181605
Global test acc : 0.9438
Global prompt norm: 53.35750961303711
Global epoch 172...
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.59 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.0813494822300902, ce=62.94842725281322
Local test acc @ epoch 172: 0.9438
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.51 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.0840735129260142, ce=62.600061749099595
Local test acc @ epoch 172: 0.9438
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.0928987888021207, ce=62.38265196773984
Local test acc @ epoch 172: 0.9438
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.0987726963988138, ce=62.30069690669348
Local test acc @ epoch 172: 0.9438
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.73 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.0926535676378724, ce=62.403930909043055
Local test acc @ epoch 172: 0.9438
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.81 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.0938678181499517, ce=62.37277708141082
Local test acc @ epoch 172: 0.9438
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.64 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.0739469396958656, ce=62.867547096462424
Local test acc @ epoch 172: 0.9438
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.5 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.0716437418526465, ce=63.26018699156035
Local test acc @ epoch 172: 0.9438
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.67 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.0983131172460154, ce=62.25927478895275
Local test acc @ epoch 172: 0.9438
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.72 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.093023339542774, ce=62.333556253975686
Local test acc @ epoch 172: 0.9438
Global evaluate on test data...
Evaluate data in 82.49 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.0885400772094727, ce=62.604487742852726
Global test acc : 0.9438
Global prompt norm: 53.355445861816406
Global epoch 173...
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.61 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.0695932414553582, ce=62.983187474242044
Local test acc @ epoch 173: 0.9438
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.76 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.074945970412788, ce=62.93799171097782
Local test acc @ epoch 173: 0.9438
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.53 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.04440865385423, ce=63.99075744348929
Local test acc @ epoch 173: 0.9438
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.48 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.0752456560047394, ce=62.987119132225665
Local test acc @ epoch 173: 0.9438
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.53 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.070998979271005, ce=63.0145443207627
Local test acc @ epoch 173: 0.9438
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.62 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.0221257166031303, ce=64.53654297994912
Local test acc @ epoch 173: 0.9438
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.57 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.0695848858684576, ce=63.034162923830365
Local test acc @ epoch 173: 0.9438
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.57 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.0699232827632799, ce=63.02876082254112
Local test acc @ epoch 173: 0.9438
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.75 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=1.0532374250779457, ce=63.356883162752204
Local test acc @ epoch 173: 0.9427
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.75 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.0620746481309242, ce=63.157592528456945
Local test acc @ epoch 173: 0.9438
Global evaluate on test data...
Evaluate data in 82.62 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.0621479673123142, ce=63.363358488870325
Global test acc : 0.9438
Global prompt norm: 53.35215759277344
Global epoch 174...
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.43 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.0436835813959804, ce=63.731090510657076
Local test acc @ epoch 174: 0.9438
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.47 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.0462029177114505, ce=63.783007980486666
Local test acc @ epoch 174: 0.9438
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.4 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.0466029359660018, ce=63.707226394513334
Local test acc @ epoch 174: 0.9438
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.51 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.0416578284097373, ce=63.762232054264175
Local test acc @ epoch 174: 0.9438
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.73 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9482781121490198, ce=66.06965024755635
Local test acc @ epoch 174: 0.9438
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.0301181941951087, ce=63.89634795582622
Local test acc @ epoch 174: 0.9415
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.69 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.0360816246872648, ce=63.77009886995368
Local test acc @ epoch 174: 0.9438
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.56 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.0428123649107206, ce=63.72260329920218
Local test acc @ epoch 174: 0.9438
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.58 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.041525490787051, ce=63.70682434641987
Local test acc @ epoch 174: 0.9438
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.57 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9886783328625041, ce=65.33688431486077
Local test acc @ epoch 174: 0.9438
Global evaluate on test data...
Evaluate data in 82.66 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.0282821611526909, ce=64.28470363091985
Global test acc : 0.9438
Global prompt norm: 53.34673309326172
Global epoch 175...
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.55 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.0087756585637364, ce=64.67139091841672
Local test acc @ epoch 175: 0.9438
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.98 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.004406657787638, ce=64.5928016102642
Local test acc @ epoch 175: 0.9438
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.999852434210821, ce=64.55816282919787
Local test acc @ epoch 175: 0.9415
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.5 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.006787584462297, ce=64.8100438949165
Local test acc @ epoch 175: 0.9438
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.53 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.0077828092312595, ce=64.57701261327901
Local test acc @ epoch 175: 0.9438
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.58 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9038855132706668, ce=67.16567580196836
Local test acc @ epoch 175: 0.9438
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.46 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.004510818271462, ce=64.6656116520593
Local test acc @ epoch 175: 0.9438
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.68 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9024726753934807, ce=67.15734149337908
Local test acc @ epoch 175: 0.9438
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.67 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.0027508385684512, ce=64.51212961739357
Local test acc @ epoch 175: 0.9438
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.57 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.0079841220050776, ce=64.61888497028876
Local test acc @ epoch 175: 0.9438
Global evaluate on test data...
Evaluate data in 82.79 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9872441641781309, ce=65.39292988208456
Global test acc : 0.9438
Global prompt norm: 53.336692810058594
Global epoch 176...
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.54 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9408573666843799, ce=65.37954288447669
Local test acc @ epoch 176: 0.9438
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.59 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.881632664881715, ce=68.42891728112457
Local test acc @ epoch 176: 0.9438
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.56 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.961595644644641, ce=65.29178559889488
Local test acc @ epoch 176: 0.9415
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.51 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9606171572973968, ce=65.36023638664035
Local test acc @ epoch 176: 0.9427
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.4 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9584592722971504, ce=65.88496650905785
Local test acc @ epoch 176: 0.9438
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.64 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9614906661007383, ce=65.70729915373916
Local test acc @ epoch 176: 0.9427
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.68 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.956352557611028, ce=65.63595966024137
Local test acc @ epoch 176: 0.9438
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.61 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.955145376537918, ce=65.77634174451916
Local test acc @ epoch 176: 0.9438
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.56 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9528687634599318, ce=66.16630690688388
Local test acc @ epoch 176: 0.9438
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.63 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9627985954284668, ce=65.6179008833859
Local test acc @ epoch 176: 0.9427
Global evaluate on test data...
Evaluate data in 82.59 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9507943774582049, ce=66.29485205554087
Global test acc : 0.9438
Global prompt norm: 53.3194580078125
Global epoch 177...
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.48 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8906035423278809, ce=67.74184088750717
Local test acc @ epoch 177: 0.9438
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.57 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.906139828743191, ce=66.73968572354099
Local test acc @ epoch 177: 0.9427
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.66 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9251122912135693, ce=66.28218239600506
Local test acc @ epoch 177: 0.9427
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.62 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9267437217432425, ce=66.26380314958205
Local test acc @ epoch 177: 0.9415
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9178539284872352, ce=66.71538396712837
Local test acc @ epoch 177: 0.9427
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.59 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9249954442365453, ce=66.64098435148186
Local test acc @ epoch 177: 0.9427
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.56 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9106626423127061, ce=67.12907745641306
Local test acc @ epoch 177: 0.9427
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.63 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.925963848009022, ce=66.57507513203753
Local test acc @ epoch 177: 0.9427
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.920149501310576, ce=66.55351446309221
Local test acc @ epoch 177: 0.9427
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.69 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=1.0008683335890465, ce=62.82031166006666
Local test acc @ epoch 177: 0.9427
Global evaluate on test data...
Evaluate data in 82.46 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9324014689944206, ce=67.02646377983443
Global test acc : 0.9427
Global prompt norm: 53.304744720458984
Global epoch 178...
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.53 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9094128564957085, ce=67.05931532273598
Local test acc @ epoch 178: 0.9415
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.47 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9034220712994216, ce=67.40715845790479
Local test acc @ epoch 178: 0.9427
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.67 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.9098873969611772, ce=67.34117966398186
Local test acc @ epoch 178: 0.9404
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.59 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9102267737782329, ce=67.28664573179472
Local test acc @ epoch 178: 0.9415
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.56 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9045946226207489, ce=67.28018615442679
Local test acc @ epoch 178: 0.9415
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.3623913730498316e-07
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.72 seconds!
[tester] 
SST2Metric: acc=0.7660550458715596, hinge=3.9471439954337724, ce=19.09129520731235
Local test acc @ epoch 178: 0.7661
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.38 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9081948831540729, ce=67.04655120569632
Local test acc @ epoch 178: 0.9427
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.54 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.2454809486319165, ce=57.745606553663904
Local test acc @ epoch 178: 0.9369
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.42 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8845596225983506, ce=67.95685150426462
Local test acc @ epoch 178: 0.9427
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.32 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8619842835522573, ce=68.67015096681928
Local test acc @ epoch 178: 0.9438
Global evaluate on test data...
Evaluate data in 82.52 seconds!
[tester] 
SST2Metric: acc=0.9334862385321101, hinge=1.1697345523659242, ce=60.39735192115154
Global test acc : 0.9335
Global prompt norm: 53.322689056396484
Global epoch 179...
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.56 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=0.9910754063807496, ce=67.0166038723167
Local test acc @ epoch 179: 0.9358
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.73 seconds!
[tester] 
SST2Metric: acc=0.9334862385321101, hinge=1.1631541645854986, ce=61.08023743235737
Local test acc @ epoch 179: 0.9335
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.72 seconds!
[tester] 
SST2Metric: acc=0.9334862385321101, hinge=1.1626831369662503, ce=60.88618997696343
Local test acc @ epoch 179: 0.9335
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.9334862385321101, hinge=1.167429810270257, ce=60.54055698639756
Local test acc @ epoch 179: 0.9335
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.46 seconds!
[tester] 
SST2Metric: acc=0.9346330275229358, hinge=1.0257489834356746, ce=65.79362449296023
Local test acc @ epoch 179: 0.9346
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.52 seconds!
[tester] 
SST2Metric: acc=0.9334862385321101, hinge=1.1675186332212675, ce=60.535592000418845
Local test acc @ epoch 179: 0.9335
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.69 seconds!
[tester] 
SST2Metric: acc=0.9334862385321101, hinge=1.167360760750027, ce=60.54135023344547
Local test acc @ epoch 179: 0.9335
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.44 seconds!
[tester] 
SST2Metric: acc=0.9334862385321101, hinge=1.1673180028932904, ce=60.55234538087058
Local test acc @ epoch 179: 0.9335
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.53 seconds!
[tester] 
SST2Metric: acc=0.9334862385321101, hinge=1.1629933829701276, ce=60.8921034576696
Local test acc @ epoch 179: 0.9335
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.73 seconds!
[tester] 
SST2Metric: acc=0.9334862385321101, hinge=1.1647780400897385, ce=60.717280116649945
Local test acc @ epoch 179: 0.9335
Global evaluate on test data...
Evaluate data in 82.6 seconds!
[tester] 
SST2Metric: acc=0.9334862385321101, hinge=1.1404077766138478, ce=62.26843877669868
Global test acc : 0.9335
Global prompt norm: 53.31693649291992
Global epoch 180...
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.53 seconds!
[tester] 
SST2Metric: acc=0.9334862385321101, hinge=1.1340185042914994, ce=62.54236032328475
Local test acc @ epoch 180: 0.9335
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.5 seconds!
[tester] 
SST2Metric: acc=0.9334862385321101, hinge=1.1226245416413754, ce=63.125645663760125
Local test acc @ epoch 180: 0.9335
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.52 seconds!
[tester] 
SST2Metric: acc=0.9334862385321101, hinge=1.13001586756575, ce=62.76725324578241
Local test acc @ epoch 180: 0.9335
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.68 seconds!
[tester] 
SST2Metric: acc=0.9334862385321101, hinge=1.1346824890976652, ce=62.52201220311156
Local test acc @ epoch 180: 0.9335
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.48 seconds!
[tester] 
SST2Metric: acc=0.9334862385321101, hinge=1.1304508524203518, ce=62.96387740668901
Local test acc @ epoch 180: 0.9335
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.47 seconds!
[tester] 
SST2Metric: acc=0.9334862385321101, hinge=1.1345661845775918, ce=62.52971159208805
Local test acc @ epoch 180: 0.9335
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.9334862385321101, hinge=1.1267428923090663, ce=62.87221170127938
Local test acc @ epoch 180: 0.9335
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.67 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=0.9948837429011633, ce=67.2800278969861
Local test acc @ epoch 180: 0.9358
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.66 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=0.9904213782844193, ce=66.88527000497241
Local test acc @ epoch 180: 0.9358
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.63 seconds!
[tester] 
SST2Metric: acc=0.9334862385321101, hinge=1.133812353151654, ce=62.563855442432086
Local test acc @ epoch 180: 0.9335
Global evaluate on test data...
Evaluate data in 82.47 seconds!
[tester] 
SST2Metric: acc=0.9346330275229358, hinge=1.1069732237299648, ce=63.90785360773769
Global test acc : 0.9346
Global prompt norm: 53.31063461303711
Global epoch 181...
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.48 seconds!
[tester] 
SST2Metric: acc=0.9334862385321101, hinge=1.088974873954003, ce=64.52357419915155
Local test acc @ epoch 181: 0.9335
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.9334862385321101, hinge=1.0890072638835382, ce=64.44062661687168
Local test acc @ epoch 181: 0.9335
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=0.9565217648077449, ce=68.14849475545621
Local test acc @ epoch 181: 0.9358
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.63 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=0.9990579972573377, ce=67.54279551374803
Local test acc @ epoch 181: 0.9369
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.49 seconds!
[tester] 
SST2Metric: acc=0.9346330275229358, hinge=1.0909033521599727, ce=64.43235393839144
Local test acc @ epoch 181: 0.9346
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.75 seconds!
[tester] 
SST2Metric: acc=0.9334862385321101, hinge=1.0920821504855374, ce=64.38579118361167
Local test acc @ epoch 181: 0.9335
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.45 seconds!
[tester] 
SST2Metric: acc=0.9334862385321101, hinge=1.0903894966895427, ce=64.69746794394396
Local test acc @ epoch 181: 0.9335
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.45 seconds!
[tester] 
SST2Metric: acc=0.9334862385321101, hinge=1.0691657241331327, ce=65.00275477138135
Local test acc @ epoch 181: 0.9335
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.59 seconds!
[tester] 
SST2Metric: acc=0.9334862385321101, hinge=1.088339814352333, ce=64.49908111292288
Local test acc @ epoch 181: 0.9335
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.66 seconds!
[tester] 
SST2Metric: acc=0.9334862385321101, hinge=1.0604634022493975, ce=65.30794640637319
Local test acc @ epoch 181: 0.9335
Global evaluate on test data...
Evaluate data in 82.61 seconds!
[tester] 
SST2Metric: acc=0.9334862385321101, hinge=1.0648224725635773, ce=65.5128993813051
Global test acc : 0.9335
Global prompt norm: 53.30415725708008
Global epoch 182...
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.53 seconds!
[tester] 
SST2Metric: acc=0.9323394495412844, hinge=1.0201016697314902, ce=66.43583749193664
Local test acc @ epoch 182: 0.9323
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.54 seconds!
[tester] 
SST2Metric: acc=0.9346330275229358, hinge=0.9620518203175396, ce=66.87067882292861
Local test acc @ epoch 182: 0.9346
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.51 seconds!
[tester] 
SST2Metric: acc=0.9346330275229358, hinge=1.0113545164055782, ce=66.48099790800602
Local test acc @ epoch 182: 0.9346
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.57 seconds!
[tester] 
SST2Metric: acc=0.9346330275229358, hinge=0.9741863110743532, ce=66.7679333468096
Local test acc @ epoch 182: 0.9346
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.48 seconds!
[tester] 
SST2Metric: acc=0.9346330275229358, hinge=1.0297872473340515, ce=66.56686765338303
Local test acc @ epoch 182: 0.9346
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.66 seconds!
[tester] 
SST2Metric: acc=0.9334862385321101, hinge=1.0153140234291007, ce=66.31535041879077
Local test acc @ epoch 182: 0.9335
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.61 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=0.9977391750440685, ce=68.07607913236005
Local test acc @ epoch 182: 0.9358
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.7 seconds!
[tester] 
SST2Metric: acc=0.9334862385321101, hinge=1.0250494064541038, ce=66.31425427078108
Local test acc @ epoch 182: 0.9335
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.58 seconds!
[tester] 
SST2Metric: acc=0.9346330275229358, hinge=0.8892479074110679, ce=69.94871618988317
Local test acc @ epoch 182: 0.9346
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.75 seconds!
[tester] 
SST2Metric: acc=0.9346330275229358, hinge=1.0257847112253171, ce=66.39423674837165
Local test acc @ epoch 182: 0.9346
Global evaluate on test data...
Evaluate data in 82.51 seconds!
[tester] 
SST2Metric: acc=0.9346330275229358, hinge=0.9971536496363649, ce=67.26899075289386
Global test acc : 0.9346
Global prompt norm: 53.29353713989258
Global epoch 183...
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.48 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=0.905095660358394, ce=67.92257368455239
Local test acc @ epoch 183: 0.9358
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.59 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9436149684661025, ce=66.31346280859151
Local test acc @ epoch 183: 0.9438
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.63 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=0.8772525131155592, ce=67.28448220349233
Local test acc @ epoch 183: 0.9392
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.36 seconds!
[tester] 
SST2Metric: acc=0.9346330275229358, hinge=0.9165154290855477, ce=67.6968104511226
Local test acc @ epoch 183: 0.9346
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.43 seconds!
[tester] 
SST2Metric: acc=0.9346330275229358, hinge=0.9266384938441286, ce=67.90017756190869
Local test acc @ epoch 183: 0.9346
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.49 seconds!
[tester] 
SST2Metric: acc=0.9346330275229358, hinge=0.922499429195299, ce=70.07690338694721
Local test acc @ epoch 183: 0.9346
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.61 seconds!
[tester] 
SST2Metric: acc=0.9346330275229358, hinge=0.9147830446925732, ce=68.01631227545782
Local test acc @ epoch 183: 0.9346
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.49 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=0.8801144022460378, ce=67.05570339937823
Local test acc @ epoch 183: 0.9392
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.59 seconds!
[tester] 
SST2Metric: acc=0.9346330275229358, hinge=0.9313406156837394, ce=68.6816045778607
Local test acc @ epoch 183: 0.9346
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.67 seconds!
[tester] 
SST2Metric: acc=0.9346330275229358, hinge=0.9225677743964239, ce=68.33290996026555
Local test acc @ epoch 183: 0.9346
Global evaluate on test data...
Evaluate data in 82.62 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=0.9167961811800616, ce=68.59570116515553
Global test acc : 0.9369
Global prompt norm: 53.27423095703125
Global epoch 184...
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.66 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.8501521906721483, ce=67.61292763806264
Local test acc @ epoch 184: 0.9415
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.49 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.2040587193375334, ce=30.104654224640733
Local test acc @ epoch 184: 0.9392
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.43 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.8548449157574854, ce=68.89067161630054
Local test acc @ epoch 184: 0.9404
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.46 seconds!
[tester] 
SST2Metric: acc=0.9311926605504587, hinge=1.082302207246833, ce=16.339341347370674
Local test acc @ epoch 184: 0.9312
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.6 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.8574706786269441, ce=68.60286992624265
Local test acc @ epoch 184: 0.9404
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.59 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.8455098790859957, ce=69.61553213137006
Local test acc @ epoch 184: 0.9404
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.44 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.8551349902371748, ce=67.54385984928236
Local test acc @ epoch 184: 0.9404
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.52 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.8625132009523724, ce=68.85219559975721
Local test acc @ epoch 184: 0.9404
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.62 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=0.8620254621593231, ce=70.14838437421606
Local test acc @ epoch 184: 0.9369
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.8540045099520902, ce=68.73519743473157
Local test acc @ epoch 184: 0.9404
Global evaluate on test data...
Evaluate data in 82.55 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.3355418563982762, ce=55.91000551696217
Global test acc : 0.9369
Global prompt norm: 53.266326904296875
Global epoch 185...
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.46 seconds!
[tester] 
SST2Metric: acc=0.9346330275229358, hinge=1.3260246810563114, ce=57.58774724137892
Local test acc @ epoch 185: 0.9346
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.44 seconds!
[tester] 
SST2Metric: acc=0.9346330275229358, hinge=1.308850572743547, ce=59.65867033792198
Local test acc @ epoch 185: 0.9346
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.34 seconds!
[tester] 
SST2Metric: acc=0.9346330275229358, hinge=1.3265220265869702, ce=58.111805102147095
Local test acc @ epoch 185: 0.9346
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.58 seconds!
[tester] 
SST2Metric: acc=0.9346330275229358, hinge=1.322766566495283, ce=57.77447107297565
Local test acc @ epoch 185: 0.9346
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.67 seconds!
[tester] 
SST2Metric: acc=0.9334862385321101, hinge=1.2685329367261413, ce=61.438483806925085
Local test acc @ epoch 185: 0.9335
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.46 seconds!
[tester] 
SST2Metric: acc=0.9346330275229358, hinge=1.318933325076322, ce=58.51929445879175
Local test acc @ epoch 185: 0.9346
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.68 seconds!
[tester] 
SST2Metric: acc=0.9346330275229358, hinge=1.3158743053401283, ce=58.221825450932215
Local test acc @ epoch 185: 0.9346
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.55 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.335256777772116, ce=56.02121391646359
Local test acc @ epoch 185: 0.9369
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.6 seconds!
[tester] 
SST2Metric: acc=0.9346330275229358, hinge=1.3146187712293151, ce=58.63333070387534
Local test acc @ epoch 185: 0.9346
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.51 seconds!
[tester] 
SST2Metric: acc=0.9323394495412844, hinge=1.2486780149127366, ce=62.3435338571531
Local test acc @ epoch 185: 0.9323
Global evaluate on test data...
Evaluate data in 82.66 seconds!
[tester] 
SST2Metric: acc=0.9346330275229358, hinge=1.313825318572718, ce=59.070757979646736
Global test acc : 0.9346
Global prompt norm: 53.268463134765625
Global epoch 186...
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.57 seconds!
[tester] 
SST2Metric: acc=0.9346330275229358, hinge=1.2917805374215503, ce=60.4465372278056
Local test acc @ epoch 186: 0.9346
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.42 seconds!
[tester] 
SST2Metric: acc=0.9334862385321101, hinge=1.2837782606072383, ce=61.03762372918085
Local test acc @ epoch 186: 0.9335
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.32 seconds!
[tester] 
SST2Metric: acc=0.9334862385321101, hinge=1.2219316806268254, ce=62.95001969643689
Local test acc @ epoch 186: 0.9335
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.33 seconds!
[tester] 
SST2Metric: acc=0.9346330275229358, hinge=1.3127992043801404, ce=59.19198223428989
Local test acc @ epoch 186: 0.9346
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.62 seconds!
[tester] 
SST2Metric: acc=0.9334862385321101, hinge=1.1931266872161026, ce=63.67667941872133
Local test acc @ epoch 186: 0.9335
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.38 seconds!
[tester] 
SST2Metric: acc=0.9334862385321101, hinge=1.2972795328962694, ce=60.5753118182541
Local test acc @ epoch 186: 0.9335
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.66 seconds!
[tester] 
SST2Metric: acc=0.9346330275229358, hinge=1.2969565172807886, ce=60.28458821007965
Local test acc @ epoch 186: 0.9346
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.52 seconds!
[tester] 
SST2Metric: acc=0.9346330275229358, hinge=1.2814892935096671, ce=60.78038787841797
Local test acc @ epoch 186: 0.9346
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.54 seconds!
[tester] 
SST2Metric: acc=0.9346330275229358, hinge=1.2792951295135218, ce=61.036094000580114
Local test acc @ epoch 186: 0.9346
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.59 seconds!
[tester] 
SST2Metric: acc=0.9346330275229358, hinge=1.2689513766437495, ce=61.70575987089664
Local test acc @ epoch 186: 0.9346
Global evaluate on test data...
Evaluate data in 82.51 seconds!
[tester] 
SST2Metric: acc=0.9346330275229358, hinge=1.277143163418551, ce=61.310564338614086
Global test acc : 0.9346
Global prompt norm: 53.26978302001953
Global epoch 187...
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.45 seconds!
[tester] 
SST2Metric: acc=0.9346330275229358, hinge=1.2743328208223395, ce=61.50338430142184
Local test acc @ epoch 187: 0.9346
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.61 seconds!
[tester] 
SST2Metric: acc=0.9334862385321101, hinge=1.2149640879499803, ce=63.2146073437612
Local test acc @ epoch 187: 0.9335
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.56 seconds!
[tester] 
SST2Metric: acc=0.9334862385321101, hinge=1.2293649550971635, ce=62.67123941543999
Local test acc @ epoch 187: 0.9335
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.68 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.140586236201295, ce=64.40134422932196
Local test acc @ epoch 187: 0.9369
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.64 seconds!
[tester] 
SST2Metric: acc=0.9334862385321101, hinge=1.232175625792337, ce=62.850601931230734
Local test acc @ epoch 187: 0.9335
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.5 seconds!
[tester] 
SST2Metric: acc=0.9334862385321101, hinge=1.2503902365308288, ce=62.344922966913344
Local test acc @ epoch 187: 0.9335
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.42 seconds!
[tester] 
SST2Metric: acc=0.9334862385321101, hinge=1.2447753433787494, ce=62.381654546895156
Local test acc @ epoch 187: 0.9335
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.53 seconds!
[tester] 
SST2Metric: acc=0.9334862385321101, hinge=1.2519696218158127, ce=62.37889823563602
Local test acc @ epoch 187: 0.9335
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.46 seconds!
[tester] 
SST2Metric: acc=0.9334862385321101, hinge=1.170312413381874, ce=63.9216746409005
Local test acc @ epoch 187: 0.9335
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.53 seconds!
[tester] 
SST2Metric: acc=0.9334862385321101, hinge=1.229313902898666, ce=62.78976699409135
Local test acc @ epoch 187: 0.9335
Global evaluate on test data...
Evaluate data in 82.63 seconds!
[tester] 
SST2Metric: acc=0.9334862385321101, hinge=1.2269243537832837, ce=62.9474972366193
Global test acc : 0.9335
Global prompt norm: 53.27090835571289
Global epoch 188...
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.39 seconds!
[tester] 
SST2Metric: acc=0.9334862385321101, hinge=1.1750090581561448, ce=63.86850276562052
Local test acc @ epoch 188: 0.9335
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.47 seconds!
[tester] 
SST2Metric: acc=0.9334862385321101, hinge=1.1777084814299137, ce=63.91530630129193
Local test acc @ epoch 188: 0.9335
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.54 seconds!
[tester] 
SST2Metric: acc=0.9334862385321101, hinge=1.1789869824680714, ce=63.99280954063485
Local test acc @ epoch 188: 0.9335
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.63 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.107912868534753, ce=64.70571766424617
Local test acc @ epoch 188: 0.9381
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.46 seconds!
[tester] 
SST2Metric: acc=0.9334862385321101, hinge=1.1925708788250564, ce=63.9305067149871
Local test acc @ epoch 188: 0.9335
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.56 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.1318441487233573, ce=64.41242567989805
Local test acc @ epoch 188: 0.9358
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.76 seconds!
[tester] 
SST2Metric: acc=0.9334862385321101, hinge=1.2186644974104854, ce=63.3752011290384
Local test acc @ epoch 188: 0.9335
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.47 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.163908162248244, ce=64.14109774248315
Local test acc @ epoch 188: 0.9358
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.5 seconds!
[tester] 
SST2Metric: acc=0.9334862385321101, hinge=1.1921345159548138, ce=63.675640316184506
Local test acc @ epoch 188: 0.9335
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.5 seconds!
[tester] 
SST2Metric: acc=0.9334862385321101, hinge=1.2001408043257686, ce=63.60853300182097
Local test acc @ epoch 188: 0.9335
Global evaluate on test data...
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9334862385321101, hinge=1.1755572852738407, ce=64.04348831876702
Global test acc : 0.9335
Global prompt norm: 53.27098083496094
Global epoch 189...
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.48 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.0888528692612953, ce=64.88980305522954
Local test acc @ epoch 189: 0.9392
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.66 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.1250567917430072, ce=64.70329120181023
Local test acc @ epoch 189: 0.9369
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.62 seconds!
[tester] 
SST2Metric: acc=0.9346330275229358, hinge=1.135613292729089, ce=64.6204973273321
Local test acc @ epoch 189: 0.9346
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.5 seconds!
[tester] 
SST2Metric: acc=0.9346330275229358, hinge=1.1460317384212388, ce=64.50968747620189
Local test acc @ epoch 189: 0.9346
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.51 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.1053101294631258, ce=64.70670063123791
Local test acc @ epoch 189: 0.9381
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.54 seconds!
[tester] 
SST2Metric: acc=0.9334862385321101, hinge=1.135714128476764, ce=64.68687235980953
Local test acc @ epoch 189: 0.9335
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.48 seconds!
[tester] 
SST2Metric: acc=0.9346330275229358, hinge=1.1312647303310008, ce=64.59944184329531
Local test acc @ epoch 189: 0.9346
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.43 seconds!
[tester] 
SST2Metric: acc=0.9334862385321101, hinge=1.1532004557618307, ce=64.43950327602002
Local test acc @ epoch 189: 0.9335
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.5 seconds!
[tester] 
SST2Metric: acc=0.9346330275229358, hinge=1.1314376209853987, ce=65.31061266977852
Local test acc @ epoch 189: 0.9346
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.9346330275229358, hinge=1.150304094367071, ce=65.09032891649719
Local test acc @ epoch 189: 0.9346
Global evaluate on test data...
Evaluate data in 82.47 seconds!
[tester] 
SST2Metric: acc=0.9346330275229358, hinge=1.1314751336333948, ce=64.83422288107217
Global test acc : 0.9346
Global prompt norm: 53.269744873046875
Global epoch 190...
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.53 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.1123832343915188, ce=65.15387942812859
Local test acc @ epoch 190: 0.9358
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.52 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.069961228501906, ce=65.1642959664721
Local test acc @ epoch 190: 0.9392
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.51 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.0918951821983407, ce=65.18404503918569
Local test acc @ epoch 190: 0.9381
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.58 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.0997505275481338, ce=65.18925899540612
Local test acc @ epoch 190: 0.9369
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.46 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.094990922770369, ce=65.17919599900551
Local test acc @ epoch 190: 0.9369
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.6 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.0997099876403809, ce=65.24006880313978
Local test acc @ epoch 190: 0.9369
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.6 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.079964882736906, ce=65.04723620633466
Local test acc @ epoch 190: 0.9392
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.7 seconds!
[tester] 
SST2Metric: acc=0.9346330275229358, hinge=1.0609500998750738, ce=66.9807885546203
Local test acc @ epoch 190: 0.9346
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.5 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.1066207885742188, ce=65.18280421265769
Local test acc @ epoch 190: 0.9369
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.63 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=1.060089973134732, ce=66.84939351213087
Local test acc @ epoch 190: 0.9358
Global evaluate on test data...
Evaluate data in 82.67 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.0895675606683854, ce=65.64682059331771
Global test acc : 0.9381
Global prompt norm: 53.26697540283203
Global epoch 191...
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.54 seconds!
[tester] 
SST2Metric: acc=0.9346330275229358, hinge=0.9601749455163239, ce=68.85207254952248
Local test acc @ epoch 191: 0.9346
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.6 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.0609941745023115, ce=65.9115617034632
Local test acc @ epoch 191: 0.9381
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.47 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.0688593146997853, ce=66.0284046208093
Local test acc @ epoch 191: 0.9381
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.61 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.055077684034995, ce=65.80239339706002
Local test acc @ epoch 191: 0.9392
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.48 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.0484247863839526, ce=65.55170983130779
Local test acc @ epoch 191: 0.9392
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.62 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.061275919643017, ce=65.87512004047359
Local test acc @ epoch 191: 0.9392
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.37 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.0560064140809786, ce=65.86377208604725
Local test acc @ epoch 191: 0.9392
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.52 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=0.9558937090252517, ce=68.83910453866382
Local test acc @ epoch 191: 0.9381
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.37 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.0440712018844185, ce=65.61355653815313
Local test acc @ epoch 191: 0.9392
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.5 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.064848462376026, ce=65.97707209455858
Local test acc @ epoch 191: 0.9381
Global evaluate on test data...
Evaluate data in 82.63 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.0414793163264564, ce=66.71804505094475
Global test acc : 0.9392
Global prompt norm: 53.26133346557617
Global epoch 192...
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.0103304539251765, ce=66.87354555042512
Local test acc @ epoch 192: 0.9392
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.8695192818247944, ce=71.0297661177609
Local test acc @ epoch 192: 0.9404
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.68 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.0092708123933285, ce=67.11246189502401
Local test acc @ epoch 192: 0.9392
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.6 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.0082356820412732, ce=66.89868755515562
Local test acc @ epoch 192: 0.9392
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.54 seconds!
[tester] 
SST2Metric: acc=0.9346330275229358, hinge=0.9470627985963034, ce=69.86165513904817
Local test acc @ epoch 192: 0.9346
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.57 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.0035115338246756, ce=66.82891033767561
Local test acc @ epoch 192: 0.9392
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.51 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.004957089730359, ce=66.29910845275319
Local test acc @ epoch 192: 0.9404
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.4 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.0066703962623527, ce=66.74238946897174
Local test acc @ epoch 192: 0.9392
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.5 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.003394074396256, ce=66.29682365907442
Local test acc @ epoch 192: 0.9392
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.69 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.0108819095366592, ce=67.30960243995037
Local test acc @ epoch 192: 0.9392
Global evaluate on test data...
Evaluate data in 82.51 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=0.9888472950786625, ce=67.87886117357726
Global test acc : 0.9392
Global prompt norm: 53.247554779052734
Global epoch 193...
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.58 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9559770242883525, ce=66.9295300124982
Local test acc @ epoch 193: 0.9427
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.47 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=0.935669072177432, ce=69.04113552548469
Local test acc @ epoch 193: 0.9392
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.57 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.9532005108824564, ce=67.98566611753691
Local test acc @ epoch 193: 0.9404
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.49 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.0041835679920441, ce=63.91733460032612
Local test acc @ epoch 193: 0.9438
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.73 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.9524550437927246, ce=66.8305920942114
Local test acc @ epoch 193: 0.9404
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.68 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.9470197126406048, ce=67.8592999659547
Local test acc @ epoch 193: 0.9404
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=0.942066525100568, ce=68.51464059812213
Local test acc @ epoch 193: 0.9392
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.53 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.9527046702323704, ce=66.86629101114535
Local test acc @ epoch 193: 0.9404
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.44 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.9485712226377715, ce=67.83378923048667
Local test acc @ epoch 193: 0.9404
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.56 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=0.9482071334068928, ce=68.00547069584557
Local test acc @ epoch 193: 0.9392
Global evaluate on test data...
Evaluate data in 82.58 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.964835175680458, ce=68.22909447906214
Global test acc : 0.9404
Global prompt norm: 53.232479095458984
Global epoch 194...
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.45 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.9345590696422332, ce=68.37386077040927
Local test acc @ epoch 194: 0.9404
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.72 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.9417710829218593, ce=68.55265087162682
Local test acc @ epoch 194: 0.9404
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.66 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=1.060379903250878, ce=17.841955989872645
Local test acc @ epoch 194: 0.9427
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.46 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.9367805620945922, ce=68.29700861939597
Local test acc @ epoch 194: 0.9404
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.54 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.9141420005658351, ce=69.33433147745394
Local test acc @ epoch 194: 0.9404
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.46 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.8982462314290738, ce=69.93588319830938
Local test acc @ epoch 194: 0.9415
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.48 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.9447345952375219, ce=68.51114703537127
Local test acc @ epoch 194: 0.9404
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.55 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.939280750554636, ce=68.50965993338768
Local test acc @ epoch 194: 0.9404
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.85 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.2335777501447485, ce=24.682925285549338
Local test acc @ epoch 194: 0.9392
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.54 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.9406504674789009, ce=68.50134319340417
Local test acc @ epoch 194: 0.9404
Global evaluate on test data...
Evaluate data in 82.55 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.3705698678252893, ce=54.0426716935744
Global test acc : 0.9404
Global prompt norm: 53.229793548583984
Global epoch 195...
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.44 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.3307905459622724, ce=59.12111922797807
Local test acc @ epoch 195: 0.9404
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.61 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.3062372645106883, ce=60.143690966684886
Local test acc @ epoch 195: 0.9404
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.46 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.354756342161686, ce=57.58811971681927
Local test acc @ epoch 195: 0.9404
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.370501666987708, ce=54.267237742012796
Local test acc @ epoch 195: 0.9404
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.58 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.3040581405709644, ce=60.490469276358226
Local test acc @ epoch 195: 0.9404
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.37 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.3057015357761208, ce=59.92112707435538
Local test acc @ epoch 195: 0.9404
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.42 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.3394637939033158, ce=58.97413005303899
Local test acc @ epoch 195: 0.9404
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.52 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.2471979823681192, ce=61.60611091403786
Local test acc @ epoch 195: 0.9404
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.58 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.325163272542691, ce=59.629220700045245
Local test acc @ epoch 195: 0.9392
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.5 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.2106631042760447, ce=62.67709382083438
Local test acc @ epoch 195: 0.9392
Global evaluate on test data...
Evaluate data in 82.57 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.317119869617147, ce=60.02450649016494
Global test acc : 0.9404
Global prompt norm: 53.24742889404297
Global epoch 196...
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.25 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.1854691767911298, ce=63.741364085346184
Local test acc @ epoch 196: 0.9392
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.62 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.288154680794532, ce=61.44687467102611
Local test acc @ epoch 196: 0.9404
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.62 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.219667933402805, ce=63.03077830743352
Local test acc @ epoch 196: 0.9404
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.4 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.270099158680767, ce=61.99842001538758
Local test acc @ epoch 196: 0.9392
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.39 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.2554841260297582, ce=62.39761244047672
Local test acc @ epoch 196: 0.9404
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.56 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.2939476660632212, ce=61.10188772918981
Local test acc @ epoch 196: 0.9404
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.42 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.2614251626740902, ce=62.095414012943934
Local test acc @ epoch 196: 0.9404
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.58 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.2629940137950653, ce=61.91523392703555
Local test acc @ epoch 196: 0.9404
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.45 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.3157970795937635, ce=60.11176079566326
Local test acc @ epoch 196: 0.9404
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.6 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.278637081111243, ce=61.595952410216725
Local test acc @ epoch 196: 0.9404
Global evaluate on test data...
Evaluate data in 82.61 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.2657759955169958, ce=62.08442394011611
Global test acc : 0.9404
Global prompt norm: 53.250484466552734
Global epoch 197...
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.38 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.2315030579173236, ce=62.96672628560197
Local test acc @ epoch 197: 0.9404
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.56 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.1661568300439678, ce=64.05723515781787
Local test acc @ epoch 197: 0.9392
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.54 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.2224106307423444, ce=63.244240367084466
Local test acc @ epoch 197: 0.9404
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.6 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.2176337592098692, ce=63.24309357809364
Local test acc @ epoch 197: 0.9404
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.56 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.2114079107931994, ce=63.41288120374767
Local test acc @ epoch 197: 0.9404
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.5 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.2398547732501948, ce=62.83932257136074
Local test acc @ epoch 197: 0.9404
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.21 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.263432935837212, ce=62.211772393742834
Local test acc @ epoch 197: 0.9404
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.44 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.241453756979846, ce=62.829857642497494
Local test acc @ epoch 197: 0.9404
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.58 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.1861026177712537, ce=63.67386238728095
Local test acc @ epoch 197: 0.9404
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.57 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.21583193157791, ce=63.18848086715838
Local test acc @ epoch 197: 0.9404
Global evaluate on test data...
Evaluate data in 82.75 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.220379378817497, ce=63.25316234903598
Global test acc : 0.9404
Global prompt norm: 53.25135803222656
Global epoch 198...
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.64 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.1814914187160106, ce=63.90527347249722
Local test acc @ epoch 198: 0.9404
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.45 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.1810824149245516, ce=63.98793330761271
Local test acc @ epoch 198: 0.9404
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.48 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.2014258454699036, ce=63.65425120362448
Local test acc @ epoch 198: 0.9404
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.44 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.1972866233335722, ce=63.886531059895084
Local test acc @ epoch 198: 0.9404
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.53 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.1946106919454873, ce=63.76630741084387
Local test acc @ epoch 198: 0.9404
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.37 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.1851945229626577, ce=63.91432049952516
Local test acc @ epoch 198: 0.9404
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.49 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.2148812626479963, ce=63.52836342907827
Local test acc @ epoch 198: 0.9404
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.81 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.1657820579108842, ce=64.04108418455911
Local test acc @ epoch 198: 0.9404
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.68 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.1864074654535417, ce=63.93812148067929
Local test acc @ epoch 198: 0.9404
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.57 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.1534195340007818, ce=64.26717068733426
Local test acc @ epoch 198: 0.9392
Global evaluate on test data...
Evaluate data in 82.52 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.1868064119181503, ce=63.94781756619795
Global test acc : 0.9404
Global prompt norm: 53.251285552978516
Global epoch 199...
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.61 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.1589733832473055, ce=64.3793533745162
Local test acc @ epoch 199: 0.9404
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.48 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.1747865633133354, ce=64.51440734163337
Local test acc @ epoch 199: 0.9404
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.55 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.1727535571527044, ce=64.19670328962694
Local test acc @ epoch 199: 0.9404
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.35 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.162691059462521, ce=64.67432155084173
Local test acc @ epoch 199: 0.9404
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.58 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.1568184598870235, ce=64.37171820544322
Local test acc @ epoch 199: 0.9404
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.57 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.1670171055225058, ce=64.2873462362027
Local test acc @ epoch 199: 0.9404
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.57 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.160920051259732, ce=64.38985611101903
Local test acc @ epoch 199: 0.9404
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.1609973338765835, ce=64.3625666067141
Local test acc @ epoch 199: 0.9404
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.55 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.14978260950211, ce=64.33195439609912
Local test acc @ epoch 199: 0.9404
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.43 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.1412864081356504, ce=64.48169879738344
Local test acc @ epoch 199: 0.9392
Global evaluate on test data...
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.1611950681843888, ce=64.4458625163507
Global test acc : 0.9404
Global prompt norm: 53.250526428222656
Global epoch 200...
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.4 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.1374030288206327, ce=65.43853570780622
Local test acc @ epoch 200: 0.9404
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.35 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.1452035903930664, ce=64.70418755067598
Local test acc @ epoch 200: 0.9404
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.52 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.1414265720122452, ce=64.73058875547636
Local test acc @ epoch 200: 0.9392
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.6 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.1347132210337787, ce=64.61415394074326
Local test acc @ epoch 200: 0.9392
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.128346963759956, ce=64.72033558416804
Local test acc @ epoch 200: 0.9392
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.1319280851871596, ce=65.41584707837586
Local test acc @ epoch 200: 0.9404
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.45 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.1501341128568037, ce=64.64081279509658
Local test acc @ epoch 200: 0.9404
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.68 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.1403870013875699, ce=64.71369433621747
Local test acc @ epoch 200: 0.9392
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.59 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.1405155068143793, ce=64.75637838381147
Local test acc @ epoch 200: 0.9404
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.41 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.1372752320875816, ce=64.74761101958948
Local test acc @ epoch 200: 0.9392
Global evaluate on test data...
Evaluate data in 82.4 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.1395052376143429, ce=64.89584378583716
Global test acc : 0.9392
Global prompt norm: 53.24935531616211
Global epoch 201...
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.43 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.0991938835983976, ce=66.22097382851697
Local test acc @ epoch 201: 0.9404
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.5 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.1293032934906286, ce=65.0870299383041
Local test acc @ epoch 201: 0.9392
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.53 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.1188835835238116, ce=65.12384390174796
Local test acc @ epoch 201: 0.9392
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.53 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.1189993980827682, ce=64.92543796224332
Local test acc @ epoch 201: 0.9392
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.51 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.096543867653663, ce=66.4210433959961
Local test acc @ epoch 201: 0.9404
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.61 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.1224799637400775, ce=65.06144304887964
Local test acc @ epoch 201: 0.9392
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.52 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.1229550379131912, ce=65.10307990957837
Local test acc @ epoch 201: 0.9392
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.38 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.1218979686772057, ce=65.126143044288
Local test acc @ epoch 201: 0.9392
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.58 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.1253829352352598, ce=65.11738341445223
Local test acc @ epoch 201: 0.9392
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.7 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.113935059363689, ce=65.0010105798004
Local test acc @ epoch 201: 0.9392
Global evaluate on test data...
Evaluate data in 82.61 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.1180502165348158, ce=65.38340020835946
Global test acc : 0.9392
Global prompt norm: 53.24765396118164
Global epoch 202...
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.35 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.103191345109852, ce=65.53925442476886
Local test acc @ epoch 202: 0.9392
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.4 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.0587419501138389, ce=67.16959437099072
Local test acc @ epoch 202: 0.9404
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.53 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.0969412961137404, ce=65.34953220612412
Local test acc @ epoch 202: 0.9392
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.1020471371641947, ce=65.55897752954326
Local test acc @ epoch 202: 0.9392
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.44 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.0990217322603277, ce=65.56124723941907
Local test acc @ epoch 202: 0.9392
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.6 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.1044112214254678, ce=65.59326413355836
Local test acc @ epoch 202: 0.9392
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.39 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.0447411187198183, ce=67.53347211365306
Local test acc @ epoch 202: 0.9404
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.52 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.1010989574117398, ce=65.30012050243693
Local test acc @ epoch 202: 0.9392
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.61 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.1030548121951043, ce=65.47359610041347
Local test acc @ epoch 202: 0.9392
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.31 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.1072592079092602, ce=65.60417325781026
Local test acc @ epoch 202: 0.9392
Global evaluate on test data...
Evaluate data in 82.43 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.0939591915235607, ce=65.97467940444247
Global test acc : 0.9392
Global prompt norm: 53.245262145996094
Global epoch 203...
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.59 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.9784765199783745, ce=68.78534628491883
Local test acc @ epoch 203: 0.9404
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.53 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.074896965551814, ce=66.1140888459092
Local test acc @ epoch 203: 0.9392
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.64 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.0809011415604057, ce=66.25874832573287
Local test acc @ epoch 203: 0.9392
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.46 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.0023324467720243, ce=68.36669368918882
Local test acc @ epoch 203: 0.9404
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.44 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.0794812079963334, ce=66.09347254201907
Local test acc @ epoch 203: 0.9392
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.54 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.079409450566003, ce=66.19156877710185
Local test acc @ epoch 203: 0.9392
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.52 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.0788997728890235, ce=65.7749048285528
Local test acc @ epoch 203: 0.9392
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.68 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.0754943637672914, ce=65.79738165479188
Local test acc @ epoch 203: 0.9392
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.48 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.078162342036536, ce=66.1092133128315
Local test acc @ epoch 203: 0.9392
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.079573911264402, ce=65.99941180167941
Local test acc @ epoch 203: 0.9392
Global evaluate on test data...
Evaluate data in 82.79 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.0641515233101102, ce=66.73511774605568
Global test acc : 0.9392
Global prompt norm: 53.24141311645508
Global epoch 204...
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.62 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.0464913035751482, ce=66.9806400264075
Local test acc @ epoch 204: 0.9392
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.6 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.0482011103848798, ce=66.82649818910372
Local test acc @ epoch 204: 0.9392
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.59 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.04837573777645, ce=66.6967853931112
Local test acc @ epoch 204: 0.9392
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.62 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.0426298718933666, ce=66.83805413202408
Local test acc @ epoch 204: 0.9392
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.42 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=0.9423238115573148, ce=69.75989616464038
Local test acc @ epoch 204: 0.9392
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.45 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.046516825299744, ce=66.37461818030121
Local test acc @ epoch 204: 0.9404
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.52 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.0490921877939767, ce=66.38740200077721
Local test acc @ epoch 204: 0.9392
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.47 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9291001503620673, ce=69.90217576333143
Local test acc @ epoch 204: 0.9415
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.49 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.0459643635181113, ce=67.13276738858005
Local test acc @ epoch 204: 0.9392
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.51 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.0465198613088065, ce=66.83803540850998
Local test acc @ epoch 204: 0.9392
Global evaluate on test data...
Evaluate data in 82.54 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.0280732671055226, ce=67.66254992003834
Global test acc : 0.9392
Global prompt norm: 53.2341423034668
Global epoch 205...
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.67 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=0.9359494830490253, ce=70.55033391550046
Local test acc @ epoch 205: 0.9358
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.37 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.0080659192636472, ce=67.02323654594771
Local test acc @ epoch 205: 0.9404
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.62 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.0072550598634493, ce=67.7271809009237
Local test acc @ epoch 205: 0.9404
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.48 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.0097762422824124, ce=67.09272052169939
Local test acc @ epoch 205: 0.9404
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.51 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.0048262744868568, ce=67.73595946425692
Local test acc @ epoch 205: 0.9392
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.55 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.0033482674064986, ce=67.9654364629623
Local test acc @ epoch 205: 0.9392
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=1.0002679212377705, ce=67.70172147138403
Local test acc @ epoch 205: 0.9392
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.62 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.0069115752473883, ce=67.56309908245682
Local test acc @ epoch 205: 0.9404
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.43 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=0.9994401844269639, ce=68.26507743345488
Local test acc @ epoch 205: 0.9392
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.52 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.873969480532025, ce=71.5455241772013
Local test acc @ epoch 205: 0.9415
Global evaluate on test data...
Evaluate data in 82.37 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.9872719344742801, ce=68.63630221305637
Global test acc : 0.9404
Global prompt norm: 53.221134185791016
Global epoch 206...
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.43 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.9532427569048121, ce=68.57066464205401
Local test acc @ epoch 206: 0.9404
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.41 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.9565118912163131, ce=68.66724171769728
Local test acc @ epoch 206: 0.9404
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.48 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9656198396595246, ce=67.67980495067911
Local test acc @ epoch 206: 0.9415
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.51 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9582777985739052, ce=68.48583928379443
Local test acc @ epoch 206: 0.9415
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.46 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.1842634743506755, ce=61.377949285944666
Local test acc @ epoch 206: 0.9415
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.53 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.9502411851095497, ce=69.1109303465677
Local test acc @ epoch 206: 0.9404
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.58 seconds!
[tester] 
SST2Metric: acc=0.9346330275229358, hinge=0.8875968478141575, ce=71.92677216136127
Local test acc @ epoch 206: 0.9346
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.57 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9650039366625864, ce=67.55868747256218
Local test acc @ epoch 206: 0.9427
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.57 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.9597824604139416, ce=68.6610642879381
Local test acc @ epoch 206: 0.9404
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.51 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.937750357006668, ce=69.71292184252258
Local test acc @ epoch 206: 0.9404
Global evaluate on test data...
Evaluate data in 82.67 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.9780338532334074, ce=68.90254757382453
Global test acc : 0.9404
Global prompt norm: 53.199806213378906
Global epoch 207...
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.5 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=1.276561500829294, ce=43.40816616793291
Local test acc @ epoch 207: 0.9427
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.27 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9421940506051439, ce=68.75104361717854
Local test acc @ epoch 207: 0.9415
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.58 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.9295891140579083, ce=69.82640383659152
Local test acc @ epoch 207: 0.9404
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.9047096278689323, ce=70.64405633768904
Local test acc @ epoch 207: 0.9404
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.67 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9383071190720305, ce=68.77890875580114
Local test acc @ epoch 207: 0.9438
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.49 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9430246134416773, ce=69.15219004219826
Local test acc @ epoch 207: 0.9415
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9444610831934378, ce=69.22711769593965
Local test acc @ epoch 207: 0.9415
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.62 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.0744095504830737, ce=61.79871788374874
Local test acc @ epoch 207: 0.9438
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.47 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9471988721725044, ce=69.20293223529781
Local test acc @ epoch 207: 0.9415
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.54 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9399376134259985, ce=69.15393325385698
Local test acc @ epoch 207: 0.9415
Global evaluate on test data...
Evaluate data in 82.39 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.0686278824412494, ce=67.1785198526645
Global test acc : 0.9415
Global prompt norm: 53.190975189208984
Global epoch 208...
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.0454628533179606, ce=67.71560332971976
Local test acc @ epoch 208: 0.9415
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.33 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.0459244010645314, ce=67.6952154876989
Local test acc @ epoch 208: 0.9415
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.0173983355180933, ce=68.15562739940958
Local test acc @ epoch 208: 0.9415
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.61 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=0.9346389245549473, ce=70.73990022151843
Local test acc @ epoch 208: 0.9392
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.55 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.040726889164076, ce=67.81184905165927
Local test acc @ epoch 208: 0.9415
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.54 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.0467476932280655, ce=67.73205867382364
Local test acc @ epoch 208: 0.9415
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.6 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.0280431301221935, ce=67.91797980912234
Local test acc @ epoch 208: 0.9415
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.38 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.906559029850391, ce=71.00772066728784
Local test acc @ epoch 208: 0.9404
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.44 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.0404014587402344, ce=67.99532304116346
Local test acc @ epoch 208: 0.9415
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.54 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.0425072459999574, ce=67.70783625611472
Local test acc @ epoch 208: 0.9415
Global evaluate on test data...
Evaluate data in 82.79 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.017152733759049, ce=68.6911040839799
Global test acc : 0.9415
Global prompt norm: 53.18461608886719
Global epoch 209...
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.49 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9603651597959186, ce=69.91590650365987
Local test acc @ epoch 209: 0.9415
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.46 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9725185971741283, ce=69.30909407029458
Local test acc @ epoch 209: 0.9415
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.68 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9425355360048626, ce=69.16471918788525
Local test acc @ epoch 209: 0.9438
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.58 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.8410695102236686, ce=73.08013776026735
Local test acc @ epoch 209: 0.9404
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.48 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.972909144305308, ce=69.44980362358443
Local test acc @ epoch 209: 0.9415
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.42 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9632918244108147, ce=69.37351170811084
Local test acc @ epoch 209: 0.9427
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.76 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=0.9101602528073373, ce=71.84186273977298
Local test acc @ epoch 209: 0.9369
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.48 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.9526546198293704, ce=69.12763963051893
Local test acc @ epoch 209: 0.9427
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.4 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9647115742394684, ce=69.26929487875842
Local test acc @ epoch 209: 0.9415
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.52 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9701729826970932, ce=69.35012418414475
Local test acc @ epoch 209: 0.9415
Global evaluate on test data...
Evaluate data in 82.61 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9463619004695787, ce=70.25437017318306
Global test acc : 0.9415
Global prompt norm: 53.170867919921875
Global epoch 210...
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.48 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8946956625772179, ce=68.2164043461511
Local test acc @ epoch 210: 0.9427
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.55 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9981140915406953, ce=64.84300235433317
Local test acc @ epoch 210: 0.9415
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.61 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8967503407679567, ce=70.42497666385195
Local test acc @ epoch 210: 0.9427
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.6 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.0686447992237336, ce=64.74916290143214
Local test acc @ epoch 210: 0.9404
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.53 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8931306917733008, ce=70.24633411092496
Local test acc @ epoch 210: 0.9427
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.46 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8790560599860795, ce=71.18686438044277
Local test acc @ epoch 210: 0.9427
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.46 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.8979268861473153, ce=68.59488992953519
Local test acc @ epoch 210: 0.945
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.42 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8929434653815873, ce=70.465450251868
Local test acc @ epoch 210: 0.9427
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.4 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.8691682596819117, ce=71.84720828555047
Local test acc @ epoch 210: 0.9415
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.37 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8920543784395271, ce=70.35592490379963
Local test acc @ epoch 210: 0.9438
Global evaluate on test data...
Evaluate data in 82.52 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.9233014999179665, ce=70.44395894741794
Global test acc : 0.9438
Global prompt norm: 53.164649963378906
Global epoch 211...
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.84 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=1.0917757290218948, ce=18.374824173953556
Local test acc @ epoch 211: 0.9415
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.39 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.9007086010154234, ce=70.82239777451261
Local test acc @ epoch 211: 0.945
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.68 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8994797522868585, ce=70.8437484601222
Local test acc @ epoch 211: 0.9438
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.64 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.8980933723099734, ce=70.84853552022112
Local test acc @ epoch 211: 0.945
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.46 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.893963262575482, ce=70.64631064878691
Local test acc @ epoch 211: 0.945
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.58 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.8689739113553948, ce=71.5018554827489
Local test acc @ epoch 211: 0.9438
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.47 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.8966040961239317, ce=70.62379784540299
Local test acc @ epoch 211: 0.945
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.62 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.0780982654029077, ce=16.04620314956805
Local test acc @ epoch 211: 0.9381
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.64 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.895139624219422, ce=70.79029097250842
Local test acc @ epoch 211: 0.945
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.39 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.8537165746776336, ce=72.13891937535837
Local test acc @ epoch 211: 0.9427
Global evaluate on test data...
Evaluate data in 82.42 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.3461673587834069, ce=54.55867872325652
Global test acc : 0.945
Global prompt norm: 53.15110397338867
Global epoch 212...
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.54 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.3447867183510316, ce=54.746647546050745
Local test acc @ epoch 212: 0.945
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.64 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.3455617624685305, ce=54.636751927367044
Local test acc @ epoch 212: 0.945
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.46 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.345696681136385, ce=54.63035240523312
Local test acc @ epoch 212: 0.945
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.343923288747805, ce=54.902411399631326
Local test acc @ epoch 212: 0.945
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.4 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.3454050449056363, ce=54.64818013042485
Local test acc @ epoch 212: 0.945
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.63 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.3455187115100546, ce=54.65142300807008
Local test acc @ epoch 212: 0.945
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.63 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.3453680747145906, ce=54.660677708617044
Local test acc @ epoch 212: 0.945
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.53 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.3455298537508062, ce=54.657964898905625
Local test acc @ epoch 212: 0.945
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.62 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.3453125166236808, ce=54.670148517013686
Local test acc @ epoch 212: 0.945
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.53 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.3451992612366284, ce=54.69127949005967
Local test acc @ epoch 212: 0.945
Global evaluate on test data...
Evaluate data in 82.64 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.3452312180755335, ce=54.68977814420648
Global test acc : 0.945
Global prompt norm: 53.15141677856445
Global epoch 213...
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.64 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.3442440382931211, ce=54.823047777928345
Local test acc @ epoch 213: 0.945
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.49 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.3447410207275952, ce=54.761870672943395
Local test acc @ epoch 213: 0.945
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.49 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.342983792681213, ce=55.036043149615644
Local test acc @ epoch 213: 0.945
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.32 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.3443590654145687, ce=54.80218985321325
Local test acc @ epoch 213: 0.945
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.67 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.34460238797949, ce=54.768382851136934
Local test acc @ epoch 213: 0.945
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.59 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.344576966871909, ce=54.78959526271995
Local test acc @ epoch 213: 0.945
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.47 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.3444391609331883, ce=54.780173030468305
Local test acc @ epoch 213: 0.945
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.48 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.3445580377491242, ce=54.783045182534316
Local test acc @ epoch 213: 0.945
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.45 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.3444179001204464, ce=54.79249537756684
Local test acc @ epoch 213: 0.945
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.56 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.3438743976278043, ce=54.879421024147526
Local test acc @ epoch 213: 0.945
Global evaluate on test data...
Evaluate data in 82.55 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.3442763888507807, ce=54.821795332322424
Global test acc : 0.945
Global prompt norm: 53.15175247192383
Global epoch 214...
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.59 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.3420045441443766, ce=55.170788371234856
Local test acc @ epoch 214: 0.945
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.42 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.3429323817611833, ce=55.01334468596572
Local test acc @ epoch 214: 0.945
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.53 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.3435220149678921, ce=54.91308058292494
Local test acc @ epoch 214: 0.945
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.59 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.3436636268545727, ce=54.92219063995081
Local test acc @ epoch 214: 0.945
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.58 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.3436770701627119, ce=54.90109427915801
Local test acc @ epoch 214: 0.945
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.62 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.3436333673809646, ce=54.91568038660452
Local test acc @ epoch 214: 0.945
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.53 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.3437931034543098, ce=54.894458910740845
Local test acc @ epoch 214: 0.945
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.43 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.3434964582460736, ce=54.925354353878475
Local test acc @ epoch 214: 0.945
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.59 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.3433207940617833, ce=54.9557447870937
Local test acc @ epoch 214: 0.945
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.41 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.343440003351334, ce=54.93521573127956
Local test acc @ epoch 214: 0.945
Global evaluate on test data...
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.3433539539302162, ce=54.95473396231275
Global test acc : 0.945
Global prompt norm: 53.15208053588867
Global epoch 215...
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.56 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.3427346474533781, ce=55.03459198977969
Local test acc @ epoch 215: 0.945
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.46 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.342364713686322, ce=55.089406459703355
Local test acc @ epoch 215: 0.945
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.49 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.3409927525651564, ce=55.3066659979864
Local test acc @ epoch 215: 0.945
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.43 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.3424882451328664, ce=55.06919321882616
Local test acc @ epoch 215: 0.945
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.41 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.3425692112073986, ce=55.04685323172753
Local test acc @ epoch 215: 0.945
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.4 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.3427186231000707, ce=55.05570917391996
Local test acc @ epoch 215: 0.945
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.86 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.3426880049049308, ce=55.049282388949614
Local test acc @ epoch 215: 0.945
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.57 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.3425488340745277, ce=55.05903156525498
Local test acc @ epoch 215: 0.945
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.53 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.341954283758041, ce=55.148220517219755
Local test acc @ epoch 215: 0.945
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.64 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.3428557203450333, ce=55.027916724528744
Local test acc @ epoch 215: 0.945
Global evaluate on test data...
Evaluate data in 82.48 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.3423951525206959, ce=55.0887870438602
Global test acc : 0.945
Global prompt norm: 53.15241622924805
Global epoch 216...
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.4 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.3418748269387342, ce=55.162586317149874
Local test acc @ epoch 216: 0.945
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.5 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.341555324169474, ce=55.1940271220076
Local test acc @ epoch 216: 0.945
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.54 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.341748119494237, ce=55.169454487091905
Local test acc @ epoch 216: 0.945
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.61 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.3415795291235688, ce=55.18192686728381
Local test acc @ epoch 216: 0.945
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.3399383868646184, ce=55.44394085385384
Local test acc @ epoch 216: 0.945
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.49 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.3413668072551763, ce=55.224387562603034
Local test acc @ epoch 216: 0.945
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.53 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.341729903439863, ce=55.190611043107616
Local test acc @ epoch 216: 0.945
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.44 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.3414897874954643, ce=55.204444150312234
Local test acc @ epoch 216: 0.945
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.64 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.3409402873537957, ce=55.28437528697722
Local test acc @ epoch 216: 0.945
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.5 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.3417033274239356, ce=55.18409309037235
Local test acc @ epoch 216: 0.945
Global evaluate on test data...
Evaluate data in 82.58 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.3413979110367802, ce=55.224044659815796
Global test acc : 0.945
Global prompt norm: 53.15275573730469
Global epoch 217...
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.5 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.3405497270986575, ce=55.31812968822794
Local test acc @ epoch 217: 0.945
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.53 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.3403360209333788, ce=55.36038347996703
Local test acc @ epoch 217: 0.945
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.43 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.338842177609785, ce=55.582495873127506
Local test acc @ epoch 217: 0.945
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.67 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.3398856023036012, ce=55.42176528370708
Local test acc @ epoch 217: 0.945
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.62 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.3408626460154123, ce=55.29842275217039
Local test acc @ epoch 217: 0.945
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.51 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.3406778038094898, ce=55.32012729469789
Local test acc @ epoch 217: 0.945
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.43 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.3407110730442433, ce=55.32645811728381
Local test acc @ epoch 217: 0.945
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.46 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.3407260431062191, ce=55.30535738183818
Local test acc @ epoch 217: 0.945
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.72 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.3405293893376622, ce=55.330146824548
Local test acc @ epoch 217: 0.945
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.53 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.3404600685889567, ce=55.34088887205911
Local test acc @ epoch 217: 0.945
Global evaluate on test data...
Evaluate data in 82.54 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.3403651211239875, ce=55.360523293871395
Global test acc : 0.945
Global prompt norm: 53.15306854248047
Global epoch 218...
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.4 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.3398037656731563, ce=55.43562554875645
Local test acc @ epoch 218: 0.945
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.63 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.3377014431384726, ce=55.72254310397927
Local test acc @ epoch 218: 0.945
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.62 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.3392606875218382, ce=55.49780259438611
Local test acc @ epoch 218: 0.945
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.36 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.3394569825688634, ce=55.467542735808486
Local test acc @ epoch 218: 0.945
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.3394804219587133, ce=55.455663453548325
Local test acc @ epoch 218: 0.945
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.339617418586661, ce=55.45742542371838
Local test acc @ epoch 218: 0.945
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.51 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.3396469824904695, ce=55.46367323289224
Local test acc @ epoch 218: 0.945
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.3396648223247003, ce=55.442598325396894
Local test acc @ epoch 218: 0.945
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.47 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.3393871412364715, ce=55.47857326542566
Local test acc @ epoch 218: 0.945
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.69 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.3387849484014949, ce=55.56052164200249
Local test acc @ epoch 218: 0.945
Global evaluate on test data...
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.3392845381290541, ce=55.49828153137767
Global test acc : 0.945
Global prompt norm: 53.15337371826172
Global epoch 219...
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.3385597150260156, ce=55.581079815505845
Local test acc @ epoch 219: 0.945
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.51 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.3383455495221899, ce=55.606305043631735
Local test acc @ epoch 219: 0.945
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.3382683631477006, ce=55.61765054825249
Local test acc @ epoch 219: 0.945
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.36 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.3383692338925983, ce=55.59454758670352
Local test acc @ epoch 219: 0.945
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.43 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.3376434046194094, ce=55.700762862459236
Local test acc @ epoch 219: 0.945
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.44 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.3381353080819507, ce=55.636608718732084
Local test acc @ epoch 219: 0.945
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.42 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.3387058021825389, ce=55.57408849033741
Local test acc @ epoch 219: 0.945
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.52 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.3365199587760714, ce=55.86409889011208
Local test acc @ epoch 219: 0.9438
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.7 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.33854214642026, ce=55.60224137612439
Local test acc @ epoch 219: 0.945
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.64 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.3385119044452631, ce=55.59594940045558
Local test acc @ epoch 219: 0.945
Global evaluate on test data...
Evaluate data in 82.35 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.33816431640485, ce=55.63752813076754
Global test acc : 0.945
Global prompt norm: 53.15372085571289
Global epoch 220...
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.41 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.3372128294148575, ce=55.73499350591537
Local test acc @ epoch 220: 0.945
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.66 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.337109014528607, ce=55.75838267475093
Local test acc @ epoch 220: 0.945
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.53 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.3364557301232574, ce=55.84256233425315
Local test acc @ epoch 220: 0.9438
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.39 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.3369749095461785, ce=55.77702821504086
Local test acc @ epoch 220: 0.945
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.59 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.337411447402534, ce=55.72133818460167
Local test acc @ epoch 220: 0.945
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.53 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.337566550718535, ce=55.7140973992304
Local test acc @ epoch 220: 0.945
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.43 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.3373895916370078, ce=55.74251860872321
Local test acc @ epoch 220: 0.945
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.47 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.3373630112464274, ce=55.73618635125116
Local test acc @ epoch 220: 0.945
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.62 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.335287347846075, ce=56.00723833556569
Local test acc @ epoch 220: 0.9438
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.46 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.3371900199750149, ce=55.746698327020766
Local test acc @ epoch 220: 0.945
Global evaluate on test data...
Evaluate data in 82.53 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.337003786629493, ce=55.77825843741041
Global test acc : 0.945
Global prompt norm: 53.1540641784668
Global epoch 221...
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.62 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.3359052631833137, ce=55.90052774411823
Local test acc @ epoch 221: 0.9438
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.64 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.3360140564244822, ce=55.87691882772183
Local test acc @ epoch 221: 0.9438
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.53 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.3352226423561027, ce=55.985947705190114
Local test acc @ epoch 221: 0.9438
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.41 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.3340080856183254, ce=56.15203668436873
Local test acc @ epoch 221: 0.9438
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.37 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.3361968425435757, ce=55.88419562523518
Local test acc @ epoch 221: 0.9438
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.58 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.3363786137432134, ce=55.85570837598328
Local test acc @ epoch 221: 0.945
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.3359868110866722, ce=55.88855732909036
Local test acc @ epoch 221: 0.9438
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.48 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.3361707521141122, ce=55.87788538101616
Local test acc @ epoch 221: 0.9438
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.51 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.3357696620696182, ce=55.91886292903795
Local test acc @ epoch 221: 0.9438
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.57 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.3362168215830392, ce=55.8629988924079
Local test acc @ epoch 221: 0.9438
Global evaluate on test data...
Evaluate data in 82.54 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.3357944882244146, ce=55.920498244259335
Global test acc : 0.9438
Global prompt norm: 53.15443420410156
Global epoch 222...
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.46 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.334953684325612, ce=56.02737731233649
Local test acc @ epoch 222: 0.9438
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.4 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.3349286875593553, ce=56.02112040388475
Local test acc @ epoch 222: 0.9438
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.42 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.33497869859048, ce=56.00618726397873
Local test acc @ epoch 222: 0.9438
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.57 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.3326760607028225, ce=56.2987046547986
Local test acc @ epoch 222: 0.9438
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.42 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.3347644499682505, ce=56.02045164195769
Local test acc @ epoch 222: 0.9438
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.63 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.3347363165759165, ce=56.0319934110029
Local test acc @ epoch 222: 0.9438
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.66 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.3346530319353855, ce=56.044322932532076
Local test acc @ epoch 222: 0.9438
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.54 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.3345114900431503, ce=56.062238535749806
Local test acc @ epoch 222: 0.9438
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.64 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.3339397141692835, ce=56.13092782956745
Local test acc @ epoch 222: 0.9438
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.5 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.335146987110103, ce=55.99885811062034
Local test acc @ epoch 222: 0.9438
Global evaluate on test data...
Evaluate data in 82.62 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.3345325364979035, ce=56.0642858732731
Global test acc : 0.9438
Global prompt norm: 53.15478515625
Global epoch 223...
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.51 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.331293346685007, ce=56.44714239977915
Local test acc @ epoch 223: 0.9438
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.73 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.3336642291567742, ce=56.17224495564032
Local test acc @ epoch 223: 0.9438
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.85 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.3333480861208855, ce=56.18973348775041
Local test acc @ epoch 223: 0.9438
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.52 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.3336358814064515, ce=56.16610217313154
Local test acc @ epoch 223: 0.9438
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.333207839125887, ce=56.20729246926964
Local test acc @ epoch 223: 0.9438
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.66 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.3336872967011337, ce=56.150855248127506
Local test acc @ epoch 223: 0.9438
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.64 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.3334628770110803, ce=56.16556801052268
Local test acc @ epoch 223: 0.9438
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.67 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.3334404481660336, ce=56.17700590781116
Local test acc @ epoch 223: 0.9438
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.52 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.3338636652045293, ce=56.14357817063638
Local test acc @ epoch 223: 0.9438
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.64 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.3326058868968158, ce=56.27771864024871
Local test acc @ epoch 223: 0.9438
Global evaluate on test data...
Evaluate data in 82.46 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.3332263745299173, ce=56.209862595304436
Global test acc : 0.9438
Global prompt norm: 53.155155181884766
Global epoch 224...
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.54 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.3323185859470192, ce=56.318938579034366
Local test acc @ epoch 224: 0.9438
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.56 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.3318503449816224, ce=56.354251161627815
Local test acc @ epoch 224: 0.9438
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.76 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.3298503237033108, ce=56.59768841244759
Local test acc @ epoch 224: 0.9438
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.7 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.3322929329828386, ce=56.31295618879686
Local test acc @ epoch 224: 0.9438
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.46 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.3325290898664282, ce=56.290253245502434
Local test acc @ epoch 224: 0.9438
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.66 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.332344413897313, ce=56.297581733913596
Local test acc @ epoch 224: 0.9438
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.3319936323603359, ce=56.33704722693207
Local test acc @ epoch 224: 0.9438
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.73 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.3321146615054629, ce=56.31252729783365
Local test acc @ epoch 224: 0.9438
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.4 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.3312177176869244, ce=56.42640819024602
Local test acc @ epoch 224: 0.9438
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.53 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.3320841526766436, ce=56.32392270849385
Local test acc @ epoch 224: 0.9438
Global evaluate on test data...
Evaluate data in 82.51 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.3318653500408209, ce=56.357290635415175
Global test acc : 0.9438
Global prompt norm: 53.15553283691406
Global epoch 225...
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.3304380539360396, ce=56.5030557824931
Local test acc @ epoch 225: 0.9438
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.82 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.3308976943339776, ce=56.46160808178263
Local test acc @ epoch 225: 0.9438
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.56 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.330680002859973, ce=56.47271382043121
Local test acc @ epoch 225: 0.9438
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.64 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.3309527668384238, ce=56.44605027645006
Local test acc @ epoch 225: 0.9438
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.44 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.3297919089641046, ce=56.577084252593714
Local test acc @ epoch 225: 0.9438
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.45 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.3307076987870243, ce=56.461452729111414
Local test acc @ epoch 225: 0.9438
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.61 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.3305804007643953, ce=56.4862685597271
Local test acc @ epoch 225: 0.9438
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.38 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.330923841633928, ce=56.46756366414761
Local test acc @ epoch 225: 0.9438
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.73 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.3284321793722451, ce=56.75032358432035
Local test acc @ epoch 225: 0.9438
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.85 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.331141143763831, ce=56.43879083755913
Local test acc @ epoch 225: 0.9438
Global evaluate on test data...
Evaluate data in 82.64 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.33045258215808, ce=56.50660002122232
Global test acc : 0.9438
Global prompt norm: 53.15591049194336
Global epoch 226...
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.59 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.3295183881707149, ce=56.59661434768537
Local test acc @ epoch 226: 0.9438
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.49 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.3294511191341856, ce=56.612333735194774
Local test acc @ epoch 226: 0.9438
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.5 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.3296953078803666, ce=56.589260346298914
Local test acc @ epoch 226: 0.9438
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.63 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.3292681361557146, ce=56.612451045884995
Local test acc @ epoch 226: 0.9438
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.66 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.3292691991963517, ce=56.62348465525776
Local test acc @ epoch 226: 0.9438
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.75 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.329494130720786, ce=56.61824392616202
Local test acc @ epoch 226: 0.9438
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.68 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.3269788628324457, ce=56.90521733695214
Local test acc @ epoch 226: 0.9438
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.58 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.3290171535736923, ce=56.654000203543845
Local test acc @ epoch 226: 0.9438
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.7 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.32839975882014, ce=56.72987194236266
Local test acc @ epoch 226: 0.9438
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.41 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.329167164793802, ce=56.637519346464664
Local test acc @ epoch 226: 0.9438
Global evaluate on test data...
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.32902994505856, ce=56.6580733203013
Global test acc : 0.9438
Global prompt norm: 53.156288146972656
Global epoch 227...
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.91 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.3282711309030515, ce=56.74201534866193
Local test acc @ epoch 227: 0.9438
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.3278572493736898, ce=56.76543916474789
Local test acc @ epoch 227: 0.9438
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.51 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.3269376973493383, ce=56.884915483107264
Local test acc @ epoch 227: 0.9438
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.38 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.3278556613747132, ce=56.776477288762365
Local test acc @ epoch 227: 0.9438
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.55 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.3281176024620687, ce=56.74920738290209
Local test acc @ epoch 227: 0.9438
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.72 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.3277480974109894, ce=56.79086912662611
Local test acc @ epoch 227: 0.9438
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.325460709563089, ce=57.062590082851024
Local test acc @ epoch 227: 0.9438
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.61 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.3280484042036425, ce=56.765215427503676
Local test acc @ epoch 227: 0.9438
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.72 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.328095366101746, ce=56.770881057879244
Local test acc @ epoch 227: 0.9438
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.327599328592283, ce=56.80694898552851
Local test acc @ epoch 227: 0.9438
Global evaluate on test data...
Evaluate data in 82.76 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.3276060174364563, ce=56.811596476703606
Global test acc : 0.9438
Global prompt norm: 53.15666961669922
Global epoch 228...
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.72 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.3268144633791863, ce=56.89686661466546
Local test acc @ epoch 228: 0.9438
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.73 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.3262655669396077, ce=56.94663966467621
Local test acc @ epoch 228: 0.9438
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.57 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.3263776805422722, ce=56.93171618400364
Local test acc @ epoch 228: 0.9438
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.64 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.3254190234962953, ce=57.04235346382911
Local test acc @ epoch 228: 0.9438
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.88 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.3261112073145875, ce=56.962245696181554
Local test acc @ epoch 228: 0.9438
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.49 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.3266507288731566, ce=56.90415632615396
Local test acc @ epoch 228: 0.9438
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.54 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.3263789579408978, ce=56.92078823124597
Local test acc @ epoch 228: 0.9438
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.3266253077655756, ce=56.92600509223588
Local test acc @ epoch 228: 0.9438
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.56 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.3265808437942366, ce=56.920334387263026
Local test acc @ epoch 228: 0.9438
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.7 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.3238728943221065, ce=57.222276635126235
Local test acc @ epoch 228: 0.9438
Global evaluate on test data...
Evaluate data in 82.63 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.3261160106833922, ce=56.96752131750824
Global test acc : 0.9438
Global prompt norm: 53.15708541870117
Global epoch 229...
Client 0 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.64 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.3252895818937809, ce=57.05424730493388
Local test acc @ epoch 229: 0.9438
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.56 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.3250476679670702, ce=57.07784467224681
Local test acc @ epoch 229: 0.9438
Client 9 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.54 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.3248338874326933, ce=57.07852897294071
Local test acc @ epoch 229: 0.9438
Client 6 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.5 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.3251172424456394, ce=57.06140980151815
Local test acc @ epoch 229: 0.9438
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.66 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.3250961784922748, ce=57.08344258299661
Local test acc @ epoch 229: 0.9438
Client 5 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.46 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.3248330912458788, ce=57.089336710238676
Local test acc @ epoch 229: 0.9438
Client 3 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.3238265405007459, ce=57.20237360963034
Local test acc @ epoch 229: 0.9438
Client 7 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.39 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.3222135097608654, ce=57.384744066710866
Local test acc @ epoch 229: 0.9438
Client 8 execute local training on 4 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.67 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.3245613290629257, ce=57.12002321995726
Local test acc @ epoch 229: 0.9438
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.75 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.3247156274428062, ce=57.10477472007821
Local test acc @ epoch 229: 0.9438
Global evaluate on test data...
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.3245599204247152, ce=57.125901423463034
Global test acc : 0.9438
Global prompt norm: 53.15748596191406
Global epoch 230...
Client 2 execute local training on 5 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.55 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.3230921194094036, ce=57.265593782477424
Local test acc @ epoch 230: 0.9438
Client 4 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.57 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.3234439683616708, ce=57.238007221746884
Local test acc @ epoch 230: 0.9438
Client 1 execute local training on 6 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
