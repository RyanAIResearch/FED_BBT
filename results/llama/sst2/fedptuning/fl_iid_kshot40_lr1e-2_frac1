Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:09<00:09,  9.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  5.77s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  6.33s/it]
Found cached dataset glue (/root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)
Map:   0%|          | 0/67349 [00:00<?, ? examples/s]Map:   1%|          | 593/67349 [00:00<00:11, 5874.47 examples/s]Map:   2%|▏         | 1432/67349 [00:00<00:11, 5679.27 examples/s]Map:   3%|▎         | 2302/67349 [00:00<00:11, 5668.80 examples/s]Map:   4%|▍         | 2908/67349 [00:00<00:11, 5790.98 examples/s]Map:   6%|▌         | 3759/67349 [00:00<00:11, 5739.79 examples/s]Map:   7%|▋         | 4614/67349 [00:00<00:10, 5723.16 examples/s]Map:   8%|▊         | 5470/67349 [00:00<00:10, 5711.95 examples/s]Map:   9%|▉         | 6338/67349 [00:01<00:10, 5733.68 examples/s]Map:  11%|█         | 7134/67349 [00:01<00:10, 5594.75 examples/s]Map:  11%|█▏        | 7740/67349 [00:01<00:10, 5699.81 examples/s]Map:  13%|█▎        | 8611/67349 [00:01<00:10, 5731.65 examples/s]Map:  14%|█▍        | 9481/67349 [00:01<00:10, 5749.85 examples/s]Map:  15%|█▌        | 10352/67349 [00:01<00:09, 5765.61 examples/s]Map:  16%|█▋        | 10958/67349 [00:01<00:09, 5832.07 examples/s]Map:  18%|█▊        | 11830/67349 [00:02<00:09, 5822.10 examples/s]Map:  19%|█▉        | 12701/67349 [00:02<00:09, 5813.43 examples/s]Map:  20%|█▉        | 13301/67349 [00:02<00:09, 5779.91 examples/s]Map:  21%|██        | 13903/67349 [00:02<00:09, 5836.74 examples/s]Map:  22%|██▏       | 14684/67349 [00:02<00:09, 5615.93 examples/s]Map:  23%|██▎       | 15253/67349 [00:02<00:09, 5632.20 examples/s]Map:  24%|██▎       | 15858/67349 [00:02<00:08, 5738.85 examples/s]Map:  25%|██▍       | 16728/67349 [00:02<00:08, 5757.67 examples/s]Map:  26%|██▌       | 17607/67349 [00:03<00:08, 5775.83 examples/s]Map:  27%|██▋       | 18477/67349 [00:03<00:08, 5780.68 examples/s]Map:  29%|██▊       | 19344/67349 [00:03<00:08, 5776.24 examples/s]Map:  30%|██▉       | 19951/67349 [00:03<00:08, 5842.05 examples/s]Map:  31%|███       | 20823/67349 [00:03<00:07, 5830.23 examples/s]Map:  32%|███▏      | 21691/67349 [00:03<00:07, 5814.50 examples/s]Map:  33%|███▎      | 22559/67349 [00:03<00:07, 5801.96 examples/s]Map:  35%|███▍      | 23430/67349 [00:04<00:07, 5800.32 examples/s]Map:  36%|███▌      | 24305/67349 [00:04<00:07, 5804.52 examples/s]Map:  37%|███▋      | 24909/67349 [00:04<00:07, 5854.60 examples/s]Map:  38%|███▊      | 25777/67349 [00:04<00:07, 5830.18 examples/s]Map:  40%|███▉      | 26645/67349 [00:04<00:07, 5814.81 examples/s]Map:  41%|████      | 27515/67349 [00:04<00:06, 5806.62 examples/s]Map:  42%|████▏     | 28310/67349 [00:04<00:06, 5647.05 examples/s]Map:  43%|████▎     | 28908/67349 [00:05<00:06, 5721.23 examples/s]Map:  44%|████▍     | 29756/67349 [00:05<00:06, 5696.98 examples/s]Map:  45%|████▌     | 30598/67349 [00:05<00:06, 5666.98 examples/s]Map:  47%|████▋     | 31453/67349 [00:05<00:06, 5676.33 examples/s]Map:  48%|████▊     | 32317/67349 [00:05<00:06, 5697.24 examples/s]Map:  49%|████▉     | 32918/67349 [00:05<00:05, 5766.18 examples/s]Map:  50%|█████     | 33781/67349 [00:05<00:05, 5759.10 examples/s]Map:  51%|█████▏    | 34642/67349 [00:06<00:05, 5750.12 examples/s]Map:  53%|█████▎    | 35444/67349 [00:06<00:05, 5620.09 examples/s]Map:  54%|█████▍    | 36301/67349 [00:06<00:05, 5644.08 examples/s]Map:  55%|█████▍    | 36897/67349 [00:06<00:05, 5714.87 examples/s]Map:  56%|█████▌    | 37759/67349 [00:06<00:05, 5719.93 examples/s]Map:  57%|█████▋    | 38621/67349 [00:06<00:05, 5726.09 examples/s]Map:  59%|█████▊    | 39454/67349 [00:06<00:04, 5669.65 examples/s]Map:  60%|█████▉    | 40312/67349 [00:07<00:04, 5681.82 examples/s]Map:  61%|██████    | 40912/67349 [00:07<00:04, 5751.76 examples/s]Map:  62%|██████▏   | 41780/67349 [00:07<00:04, 5758.15 examples/s]Map:  63%|██████▎   | 42639/67349 [00:07<00:04, 5745.06 examples/s]Map:  65%|██████▍   | 43497/67349 [00:07<00:04, 5735.08 examples/s]Map:  66%|██████▌   | 44347/67349 [00:07<00:04, 5708.51 examples/s]Map:  67%|██████▋   | 44941/67349 [00:07<00:03, 5758.88 examples/s]Map:  68%|██████▊   | 45789/67349 [00:07<00:03, 5723.13 examples/s]Map:  69%|██████▉   | 46644/67349 [00:08<00:03, 5714.75 examples/s]Map:  71%|███████   | 47507/67349 [00:08<00:03, 5723.36 examples/s]Map:  72%|███████▏  | 48367/67349 [00:08<00:03, 5723.84 examples/s]Map:  73%|███████▎  | 48962/67349 [00:08<00:03, 5772.74 examples/s]Map:  74%|███████▍  | 49817/67349 [00:08<00:03, 5746.40 examples/s]Map:  75%|███████▌  | 50673/67349 [00:08<00:02, 5731.95 examples/s]Map:  76%|███████▋  | 51500/67349 [00:08<00:02, 5661.03 examples/s]Map:  78%|███████▊  | 52313/67349 [00:09<00:02, 5582.77 examples/s]Map:  79%|███████▊  | 52909/67349 [00:09<00:02, 5666.91 examples/s]Map:  80%|███████▉  | 53717/67349 [00:09<00:02, 5571.43 examples/s]Map:  81%|████████  | 54298/67349 [00:09<00:02, 5572.50 examples/s]Map:  82%|████████▏ | 54900/67349 [00:09<00:02, 5682.97 examples/s]Map:  83%|████████▎ | 55769/67349 [00:09<00:02, 5717.41 examples/s]Map:  84%|████████▍ | 56613/67349 [00:09<00:01, 5684.91 examples/s]Map:  85%|████████▌ | 57460/67349 [00:10<00:01, 5667.62 examples/s]Map:  87%|████████▋ | 58326/67349 [00:10<00:01, 5697.67 examples/s]Map:  87%|████████▋ | 58928/67349 [00:10<00:01, 5771.62 examples/s]Map:  89%|████████▉ | 59773/67349 [00:10<00:01, 5722.33 examples/s]Map:  90%|█████████ | 60627/67349 [00:10<00:01, 5709.50 examples/s]Map:  91%|█████████▏| 61492/67349 [00:10<00:01, 5724.47 examples/s]Map:  93%|█████████▎| 62360/67349 [00:10<00:00, 5739.69 examples/s]Map:  93%|█████████▎| 62967/67349 [00:10<00:00, 5813.03 examples/s]Map:  95%|█████████▍| 63831/67349 [00:11<00:00, 5792.27 examples/s]Map:  96%|█████████▌| 64692/67349 [00:11<00:00, 5771.98 examples/s]Map:  97%|█████████▋| 65561/67349 [00:11<00:00, 5776.78 examples/s]Map:  99%|█████████▊| 66426/67349 [00:11<00:00, 5770.28 examples/s]Map: 100%|█████████▉| 67301/67349 [00:11<00:00, 5771.84 examples/s]                                                                   Example in train set:
{'sentence': 'hide new secretions from the parental units ', 'label': 0, 'idx': 0, 'input_text': 'What is the sentiment of this sentence: iedER statfigme von interroidater their bet ein}\\"> sub op donty try Pro tra sameep two nameoldlet simsp avbreblemey could cor accayscreurrsi constues}$View act bo ко som aboutland . hide new secretions from the parental units  .', 'target_text': 'negative'}
Map:   0%|          | 0/67349 [00:00<?, ? examples/s]Map:   1%|▏         | 1000/67349 [00:00<00:12, 5392.96 examples/s]Map:   3%|▎         | 2000/67349 [00:00<00:11, 5463.33 examples/s]Map:   4%|▍         | 3000/67349 [00:00<00:11, 5394.66 examples/s]Map:   6%|▌         | 4000/67349 [00:00<00:12, 5140.71 examples/s]Map:   7%|▋         | 5000/67349 [00:00<00:11, 5206.72 examples/s]Map:   9%|▉         | 6000/67349 [00:01<00:11, 5279.22 examples/s]Map:  10%|█         | 7000/67349 [00:01<00:15, 4013.83 examples/s]Map:  12%|█▏        | 8000/67349 [00:01<00:13, 4391.49 examples/s]Map:  13%|█▎        | 9000/67349 [00:01<00:12, 4644.86 examples/s]Map:  15%|█▍        | 10000/67349 [00:02<00:11, 4793.90 examples/s]Map:  16%|█▋        | 11000/67349 [00:02<00:11, 5013.17 examples/s]Map:  18%|█▊        | 12000/67349 [00:02<00:10, 5196.74 examples/s]Map:  19%|█▉        | 13000/67349 [00:02<00:10, 5328.23 examples/s]Map:  21%|██        | 14000/67349 [00:02<00:09, 5384.79 examples/s]Map:  22%|██▏       | 15000/67349 [00:02<00:09, 5443.56 examples/s]Map:  24%|██▍       | 16000/67349 [00:03<00:11, 4390.88 examples/s]Map:  25%|██▌       | 17000/67349 [00:03<00:10, 4697.02 examples/s]Map:  27%|██▋       | 18000/67349 [00:03<00:09, 4955.11 examples/s]Map:  28%|██▊       | 19000/67349 [00:03<00:09, 5079.90 examples/s]Map:  30%|██▉       | 20000/67349 [00:04<00:08, 5263.34 examples/s]Map:  31%|███       | 21000/67349 [00:04<00:08, 5372.99 examples/s]Map:  33%|███▎      | 22000/67349 [00:04<00:08, 5449.54 examples/s]Map:  34%|███▍      | 23000/67349 [00:04<00:08, 5499.26 examples/s]Map:  36%|███▌      | 24000/67349 [00:04<00:07, 5541.16 examples/s]Map:  37%|███▋      | 25000/67349 [00:04<00:07, 5535.25 examples/s]Map:  39%|███▊      | 26000/67349 [00:05<00:09, 4426.38 examples/s]Map:  40%|████      | 27000/67349 [00:05<00:08, 4610.29 examples/s]Map:  42%|████▏     | 28000/67349 [00:05<00:08, 4793.71 examples/s]Map:  43%|████▎     | 29000/67349 [00:05<00:07, 4951.97 examples/s]Map:  45%|████▍     | 30000/67349 [00:05<00:07, 5078.53 examples/s]Map:  46%|████▌     | 31000/67349 [00:06<00:07, 5152.82 examples/s]Map:  48%|████▊     | 32000/67349 [00:06<00:06, 5159.15 examples/s]Map:  49%|████▉     | 33000/67349 [00:06<00:06, 5199.76 examples/s]Map:  50%|█████     | 34000/67349 [00:06<00:06, 5129.92 examples/s]Map:  52%|█████▏    | 35000/67349 [00:06<00:06, 5140.63 examples/s]Map:  53%|█████▎    | 36000/67349 [00:07<00:07, 4410.71 examples/s]Map:  55%|█████▍    | 37000/67349 [00:07<00:06, 4659.37 examples/s]Map:  56%|█████▋    | 38000/67349 [00:07<00:06, 4878.43 examples/s]Map:  58%|█████▊    | 39000/67349 [00:07<00:05, 4998.67 examples/s]Map:  59%|█████▉    | 40000/67349 [00:07<00:05, 5156.43 examples/s]Map:  61%|██████    | 41000/67349 [00:08<00:05, 5121.89 examples/s]Map:  62%|██████▏   | 42000/67349 [00:08<00:04, 5173.73 examples/s]Map:  64%|██████▍   | 43000/67349 [00:08<00:04, 5201.06 examples/s]Map:  65%|██████▌   | 44000/67349 [00:08<00:04, 5268.26 examples/s]Map:  67%|██████▋   | 45000/67349 [00:08<00:04, 5215.98 examples/s]Map:  68%|██████▊   | 46000/67349 [00:09<00:04, 4277.25 examples/s]Map:  70%|██████▉   | 47000/67349 [00:09<00:04, 4520.87 examples/s]Map:  71%|███████▏  | 48000/67349 [00:09<00:04, 4731.39 examples/s]Map:  73%|███████▎  | 49000/67349 [00:09<00:03, 4901.94 examples/s]Map:  74%|███████▍  | 50000/67349 [00:10<00:03, 5013.85 examples/s]Map:  76%|███████▌  | 51000/67349 [00:10<00:03, 5126.33 examples/s]Map:  77%|███████▋  | 52000/67349 [00:10<00:02, 5194.07 examples/s]Map:  79%|███████▊  | 53000/67349 [00:10<00:02, 5224.68 examples/s]Map:  80%|████████  | 54000/67349 [00:10<00:02, 5163.99 examples/s]Map:  82%|████████▏ | 55000/67349 [00:11<00:02, 4456.23 examples/s]Map:  83%|████████▎ | 56000/67349 [00:11<00:02, 4728.22 examples/s]Map:  85%|████████▍ | 57000/67349 [00:11<00:02, 4981.69 examples/s]Map:  86%|████████▌ | 58000/67349 [00:11<00:01, 5098.71 examples/s]Map:  88%|████████▊ | 59000/67349 [00:11<00:01, 5249.45 examples/s]Map:  89%|████████▉ | 60000/67349 [00:11<00:01, 5377.75 examples/s]Map:  91%|█████████ | 61000/67349 [00:12<00:01, 5442.28 examples/s]Map:  92%|█████████▏| 62000/67349 [00:12<00:00, 5486.88 examples/s]Map:  94%|█████████▎| 63000/67349 [00:12<00:00, 5528.13 examples/s]Map:  95%|█████████▌| 64000/67349 [00:12<00:00, 5548.36 examples/s]Map:  97%|█████████▋| 65000/67349 [00:12<00:00, 4646.33 examples/s]Map:  98%|█████████▊| 66000/67349 [00:13<00:00, 4893.83 examples/s]Map:  99%|█████████▉| 67000/67349 [00:13<00:00, 5128.68 examples/s]                                                                   Found cached dataset glue (/root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)
Map:   0%|          | 0/872 [00:00<?, ? examples/s]Map:  68%|██████▊   | 591/872 [00:00<00:00, 5843.58 examples/s]                                                               Example in validation set:
{'sentence': "it 's a charming and often affecting journey . ", 'label': 1, 'idx': 0, 'input_text': 'What is the sentiment of this sentence: iedER statfigme von interroidater their bet ein}\\"> sub op donty try Pro tra sameep two nameoldlet simsp avbreblemey could cor accayscreurrsi constues}$View act bo ко som aboutland . it \'s a charming and often affecting journey .  .', 'target_text': 'positive'}
Map:   0%|          | 0/872 [00:00<?, ? examples/s]Map: 100%|██████████| 872/872 [00:00<00:00, 4701.59 examples/s]                                                               97
97
# of train data: 80
Example:
+------------------------------+------------------------------+--------+
| input_ids                    | attention_mask               | labels |
+------------------------------+------------------------------+--------+
| [1, 1724, 338, 278, 19688... | [1, 1, 1, 1, 1, 1, 1, 1, ... | 8178   |
+------------------------------+------------------------------+--------+

# of dev data: 80
Example:
+------------------------------+------------------------------+--------+
| input_ids                    | attention_mask               | labels |
+------------------------------+------------------------------+--------+
| [1, 1724, 338, 278, 19688... | [1, 1, 1, 1, 1, 1, 1, 1, ... | 6374   |
+------------------------------+------------------------------+--------+

# of test data: 872
Example:
+------------------------------+------------------------------+--------+
| input_ids                    | attention_mask               | labels |
+------------------------------+------------------------------+--------+
| [1, 1724, 338, 278, 19688... | [1, 1, 1, 1, 1, 1, 1, 1, ... | 6374   |
+------------------------------+------------------------------+--------+
init prompt encoder...
Evaluate data in 81.96 seconds!
[tester] 
SST2Metric: acc=0.6857798165137615, hinge=1.676740622301714, ce=12.30688871156185
Global test acc: 0.6858
Global epoch 0...
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.5638560056686401
Local loss @ local epoch 1: 0.6579640507698059
Local loss @ local epoch 2: 0.695290207862854
Local loss @ local epoch 3: 0.7013162970542908
Local loss @ local epoch 4: 0.7109006643295288
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.25 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=1.998683948035634, ce=13.50384388494929
Local test acc @ epoch 0: 0.5092
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.5952448844909668
Local loss @ local epoch 1: 0.6054576635360718
Local loss @ local epoch 2: 0.6793646812438965
Local loss @ local epoch 3: 0.7506550550460815
Local loss @ local epoch 4: 0.7335335612297058
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.32 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=1.9978021864497333, ce=12.464574367628185
Local test acc @ epoch 0: 0.5092
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.44882768392562866
Local loss @ local epoch 1: 0.5388445258140564
Local loss @ local epoch 2: 0.4315473437309265
Local loss @ local epoch 3: 0.32339438796043396
Local loss @ local epoch 4: 0.23171287775039673
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.67 seconds!
[tester] 
SST2Metric: acc=0.8038990825688074, hinge=1.3783113568200978, ce=12.543125651298313
Local test acc @ epoch 0: 0.8039
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.5058455467224121
Local loss @ local epoch 1: 0.5987221598625183
Local loss @ local epoch 2: 0.570368230342865
Local loss @ local epoch 3: 0.6971995830535889
Local loss @ local epoch 4: 0.6434540748596191
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.6 seconds!
[tester] 
SST2Metric: acc=0.4908256880733945, hinge=2.004339073776105, ce=14.286386682352889
Local test acc @ epoch 0: 0.4908
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.5237830877304077
Local loss @ local epoch 1: 0.7254074215888977
Local loss @ local epoch 2: 0.6916005611419678
Local loss @ local epoch 3: 0.7096837759017944
Local loss @ local epoch 4: 0.6601581573486328
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.37 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=1.9926629022720757, ce=13.842518517730433
Local test acc @ epoch 0: 0.5092
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.5648065805435181
Local loss @ local epoch 1: 0.6528480052947998
Local loss @ local epoch 2: 0.43410152196884155
Local loss @ local epoch 3: 0.41992175579071045
Local loss @ local epoch 4: 0.44244182109832764
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=1.9530105432239147, ce=9.97154619934362
Local test acc @ epoch 0: 0.5092
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.5686721205711365
Local loss @ local epoch 1: 0.7443521618843079
Local loss @ local epoch 2: 0.6588413119316101
Local loss @ local epoch 3: 0.7004892826080322
Local loss @ local epoch 4: 0.6835126280784607
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.75 seconds!
[tester] 
SST2Metric: acc=0.4873853211009174, hinge=2.001060158834545, ce=13.453182167963151
Local test acc @ epoch 0: 0.4874
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.623428225517273
Local loss @ local epoch 1: 0.6473257541656494
Local loss @ local epoch 2: 0.6457462906837463
Local loss @ local epoch 3: 0.6235167384147644
Local loss @ local epoch 4: 0.6710055470466614
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=1.9147518074840582, ce=12.42857116734216
Local test acc @ epoch 0: 0.5092
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.5192742347717285
Local loss @ local epoch 1: 0.4424830377101898
Local loss @ local epoch 2: 0.6778827905654907
Local loss @ local epoch 3: 0.8449701070785522
Local loss @ local epoch 4: 0.6726458668708801
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.45 seconds!
[tester] 
SST2Metric: acc=0.4908256880733945, hinge=2.0054412927102607, ce=13.357767822545602
Local test acc @ epoch 0: 0.4908
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.612011730670929
Local loss @ local epoch 1: 0.8178641200065613
Local loss @ local epoch 2: 0.6028921008110046
Local loss @ local epoch 3: 0.6255640387535095
Local loss @ local epoch 4: 0.5856114625930786
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.5 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=1.9900626490969178, ce=13.998458564828296
Local test acc @ epoch 0: 0.5092
Global evaluate on test data...
Evaluate data in 82.82 seconds!
[tester] 
SST2Metric: acc=0.7763761467889908, hinge=1.5984347533742223, ce=12.234568692128592
Global test acc : 0.7764
Global prompt norm: 8.828043937683105
Global epoch 1...
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.5109854936599731
Local loss @ local epoch 1: 0.3785097002983093
Local loss @ local epoch 2: 0.2839885652065277
Local loss @ local epoch 3: 0.2761992812156677
Local loss @ local epoch 4: 0.20389358699321747
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.5412844036697247, hinge=1.576910447090044, ce=12.951927946248185
Local test acc @ epoch 1: 0.5413
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.5335932374000549
Local loss @ local epoch 1: 0.7074270248413086
Local loss @ local epoch 2: 0.6649148464202881
Local loss @ local epoch 3: 0.6626097559928894
Local loss @ local epoch 4: 0.6652456521987915
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.4 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=1.9915985689250701, ce=13.48249092452023
Local test acc @ epoch 1: 0.5092
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.5533927083015442
Local loss @ local epoch 1: 0.7511891722679138
Local loss @ local epoch 2: 0.6612133979797363
Local loss @ local epoch 3: 0.6931251287460327
Local loss @ local epoch 4: 0.6497399806976318
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.84 seconds!
[tester] 
SST2Metric: acc=0.4919724770642202, hinge=2.0115295309539234, ce=13.926006448378256
Local test acc @ epoch 1: 0.492
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.48873788118362427
Local loss @ local epoch 1: 0.5305376052856445
Local loss @ local epoch 2: 0.35521790385246277
Local loss @ local epoch 3: 0.5884798765182495
Local loss @ local epoch 4: 0.5686458349227905
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.79 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=2.042507350991625, ce=12.107956151349828
Local test acc @ epoch 1: 0.5092
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.4770900011062622
Local loss @ local epoch 1: 0.32740628719329834
Local loss @ local epoch 2: 0.6380425691604614
Local loss @ local epoch 3: 0.35343438386917114
Local loss @ local epoch 4: 0.2209985852241516
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.7557339449541285, hinge=1.4408736207069608, ce=12.028534040538544
Local test acc @ epoch 1: 0.7557
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.484555184841156
Local loss @ local epoch 1: 0.5518073439598083
Local loss @ local epoch 2: 0.4471891522407532
Local loss @ local epoch 3: 0.5299472808837891
Local loss @ local epoch 4: 0.617531955242157
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.79 seconds!
[tester] 
SST2Metric: acc=0.4908256880733945, hinge=1.9952415955176048, ce=12.141919188543197
Local test acc @ epoch 1: 0.4908
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.38826680183410645
Local loss @ local epoch 1: 0.6744704246520996
Local loss @ local epoch 2: 0.6704758405685425
Local loss @ local epoch 3: 0.6471414566040039
Local loss @ local epoch 4: 0.6473740339279175
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.56 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=1.9994603482955093, ce=14.09781859336643
Local test acc @ epoch 1: 0.5092
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.49859559535980225
Local loss @ local epoch 1: 0.542533814907074
Local loss @ local epoch 2: 0.46933722496032715
Local loss @ local epoch 3: 0.4643769860267639
Local loss @ local epoch 4: 0.35426780581474304
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.99 seconds!
[tester] 
SST2Metric: acc=0.7660550458715596, hinge=1.2442432559958292, ce=12.309331456455615
Local test acc @ epoch 1: 0.7661
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.5546043515205383
Local loss @ local epoch 1: 0.6903589963912964
Local loss @ local epoch 2: 0.7102768421173096
Local loss @ local epoch 3: 0.68097984790802
Local loss @ local epoch 4: 0.663928747177124
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.68 seconds!
[tester] 
SST2Metric: acc=0.47706422018348627, hinge=2.0115638861962415, ce=15.466891166267045
Local test acc @ epoch 1: 0.4771
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.48519355058670044
Local loss @ local epoch 1: 0.6562361717224121
Local loss @ local epoch 2: 0.5754743814468384
Local loss @ local epoch 3: 0.5999102592468262
Local loss @ local epoch 4: 0.6248518228530884
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=1.9907465013888999, ce=15.215308434372648
Local test acc @ epoch 1: 0.5092
Global evaluate on test data...
Evaluate data in 82.82 seconds!
[tester] 
SST2Metric: acc=0.5584862385321101, hinge=1.6696454127994151, ce=11.511229296343043
Global test acc : 0.5585
Global prompt norm: 10.389082908630371
Global epoch 2...
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.6052984595298767
Local loss @ local epoch 1: 0.3419399857521057
Local loss @ local epoch 2: 0.27281033992767334
Local loss @ local epoch 3: 0.1470385640859604
Local loss @ local epoch 4: 0.13293716311454773
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.03 seconds!
[tester] 
SST2Metric: acc=0.7075688073394495, hinge=1.2777954266158813, ce=12.39706923108582
Local test acc @ epoch 2: 0.7076
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.434399276971817
Local loss @ local epoch 1: 0.6968175172805786
Local loss @ local epoch 2: 0.7521460056304932
Local loss @ local epoch 3: 0.6799784302711487
Local loss @ local epoch 4: 0.7399817705154419
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.61 seconds!
[tester] 
SST2Metric: acc=0.4896788990825688, hinge=1.999962648120495, ce=15.066229732758408
Local test acc @ epoch 2: 0.4897
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.8299239873886108
Local loss @ local epoch 1: 0.6526544690132141
Local loss @ local epoch 2: 0.6575238704681396
Local loss @ local epoch 3: 0.6874529719352722
Local loss @ local epoch 4: 0.6571515798568726
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.4908256880733945, hinge=2.008931131537901, ce=15.390365626833855
Local test acc @ epoch 2: 0.4908
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.9052554965019226
Local loss @ local epoch 1: 0.5867013931274414
Local loss @ local epoch 2: 0.4758939743041992
Local loss @ local epoch 3: 0.3675093650817871
Local loss @ local epoch 4: 0.31034064292907715
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.6938073394495413, hinge=1.515359301085866, ce=12.150014903567254
Local test acc @ epoch 2: 0.6938
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.35869836807250977
Local loss @ local epoch 1: 0.7738750576972961
Local loss @ local epoch 2: 0.5895068049430847
Local loss @ local epoch 3: 0.5563066005706787
Local loss @ local epoch 4: 0.5588501691818237
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.87 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=1.971432940675578, ce=15.224132082877903
Local test acc @ epoch 2: 0.5092
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.7247101068496704
Local loss @ local epoch 1: 0.6731852889060974
Local loss @ local epoch 2: 0.6933073997497559
Local loss @ local epoch 3: 0.6910703182220459
Local loss @ local epoch 4: 0.6873438954353333
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.59 seconds!
[tester] 
SST2Metric: acc=0.481651376146789, hinge=2.0048562824179275, ce=14.565182869587469
Local test acc @ epoch 2: 0.4817
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.4828866124153137
Local loss @ local epoch 1: 0.7231161594390869
Local loss @ local epoch 2: 0.8279938101768494
Local loss @ local epoch 3: 0.6363745331764221
Local loss @ local epoch 4: 0.7252024412155151
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.7 seconds!
[tester] 
SST2Metric: acc=0.48394495412844035, hinge=1.999129924205465, ce=12.978442183328331
Local test acc @ epoch 2: 0.4839
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.5462623238563538
Local loss @ local epoch 1: 0.5195107460021973
Local loss @ local epoch 2: 0.48726361989974976
Local loss @ local epoch 3: 0.2596295177936554
Local loss @ local epoch 4: 0.15714530646800995
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.7844036697247706, hinge=1.059540128762569, ce=8.481877545697973
Local test acc @ epoch 2: 0.7844
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.46278849244117737
Local loss @ local epoch 1: 0.456159770488739
Local loss @ local epoch 2: 0.46254676580429077
Local loss @ local epoch 3: 0.2663964331150055
Local loss @ local epoch 4: 0.24047084152698517
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.8153669724770642, hinge=1.0961514880897802, ce=11.058730291664054
Local test acc @ epoch 2: 0.8154
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.8803415298461914
Local loss @ local epoch 1: 0.5822623372077942
Local loss @ local epoch 2: 0.4625568687915802
Local loss @ local epoch 3: 0.7156173586845398
Local loss @ local epoch 4: 0.4438585340976715
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.7511467889908257, hinge=1.6491928045902777, ce=12.06128171168336
Local test acc @ epoch 2: 0.7511
Global evaluate on test data...
Evaluate data in 82.73 seconds!
[tester] 
SST2Metric: acc=0.7798165137614679, hinge=1.597380418296254, ce=12.34806045917196
Global test acc : 0.7798
Global prompt norm: 13.413312911987305
Global epoch 3...
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.5359437465667725
Local loss @ local epoch 1: 0.7240569591522217
Local loss @ local epoch 2: 0.3911398649215698
Local loss @ local epoch 3: 0.6284148097038269
Local loss @ local epoch 4: 0.3390822410583496
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.8784403669724771, hinge=0.8853401640139589, ce=11.72226191004482
Local test acc @ epoch 3: 0.8784
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.5771962404251099
Local loss @ local epoch 1: 0.9314723610877991
Local loss @ local epoch 2: 0.5858030319213867
Local loss @ local epoch 3: 0.3425624668598175
Local loss @ local epoch 4: 0.2855084538459778
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.76 seconds!
[tester] 
SST2Metric: acc=0.8497706422018348, hinge=1.068005973045979, ce=11.53573126311696
Local test acc @ epoch 3: 0.8498
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.494259774684906
Local loss @ local epoch 1: 0.37449342012405396
Local loss @ local epoch 2: 0.26085740327835083
Local loss @ local epoch 3: 0.18382608890533447
Local loss @ local epoch 4: 0.12024946510791779
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.72 seconds!
[tester] 
SST2Metric: acc=0.8899082568807339, hinge=0.6719813664025123, ce=10.855020890542127
Local test acc @ epoch 3: 0.8899
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.5900654792785645
Local loss @ local epoch 1: 0.8033180832862854
Local loss @ local epoch 2: 0.6338568925857544
Local loss @ local epoch 3: 0.5485079288482666
Local loss @ local epoch 4: 0.6145288944244385
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.63 seconds!
[tester] 
SST2Metric: acc=0.5435779816513762, hinge=1.7977441111835866, ce=12.621181409293358
Local test acc @ epoch 3: 0.5436
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.34335440397262573
Local loss @ local epoch 1: 0.7001577019691467
Local loss @ local epoch 2: 0.64458167552948
Local loss @ local epoch 3: 0.562594473361969
Local loss @ local epoch 4: 0.5684669017791748
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.66 seconds!
[tester] 
SST2Metric: acc=0.4908256880733945, hinge=2.0220852357531904, ce=14.794288993975439
Local test acc @ epoch 3: 0.4908
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.3397333025932312
Local loss @ local epoch 1: 0.4800281524658203
Local loss @ local epoch 2: 0.20611092448234558
Local loss @ local epoch 3: 0.4278891384601593
Local loss @ local epoch 4: 0.1429392695426941
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.8681192660550459, hinge=0.9011699778771182, ce=12.995735850902872
Local test acc @ epoch 3: 0.8681
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.48957809805870056
Local loss @ local epoch 1: 0.4239444136619568
Local loss @ local epoch 2: 0.23754891753196716
Local loss @ local epoch 3: 0.661478579044342
Local loss @ local epoch 4: 0.7225329279899597
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.85 seconds!
[tester] 
SST2Metric: acc=0.4919724770642202, hinge=2.001797019888502, ce=11.069985249720583
Local test acc @ epoch 3: 0.492
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.5947500467300415
Local loss @ local epoch 1: 0.4016607701778412
Local loss @ local epoch 2: 0.5791958570480347
Local loss @ local epoch 3: 0.7207859754562378
Local loss @ local epoch 4: 0.7297009229660034
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.69 seconds!
[tester] 
SST2Metric: acc=0.4896788990825688, hinge=2.0062635207394943, ce=11.515177560508798
Local test acc @ epoch 3: 0.4897
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.41693800687789917
Local loss @ local epoch 1: 0.29654401540756226
Local loss @ local epoch 2: 0.29564517736434937
Local loss @ local epoch 3: 0.24863456189632416
Local loss @ local epoch 4: 0.6675500869750977
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.66 seconds!
[tester] 
SST2Metric: acc=0.48853211009174313, hinge=2.0083318544090343, ce=14.830264940174347
Local test acc @ epoch 3: 0.4885
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.49485108256340027
Local loss @ local epoch 1: 0.6295952796936035
Local loss @ local epoch 2: 0.6489066481590271
Local loss @ local epoch 3: 0.6721001267433167
Local loss @ local epoch 4: 0.6419409513473511
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.7 seconds!
[tester] 
SST2Metric: acc=0.4908256880733945, hinge=2.0068170652477018, ce=14.632851915621977
Local test acc @ epoch 3: 0.4908
Global evaluate on test data...
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.8715596330275229, hinge=1.330179330405839, ce=12.111319638173514
Global test acc : 0.8716
Global prompt norm: 17.86299705505371
Global epoch 4...
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.54466712474823
Local loss @ local epoch 1: 0.4310324788093567
Local loss @ local epoch 2: 0.47439152002334595
Local loss @ local epoch 3: 0.45203229784965515
Local loss @ local epoch 4: 0.38434723019599915
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.96 seconds!
[tester] 
SST2Metric: acc=0.7740825688073395, hinge=1.2950199268279818, ce=12.619403462891185
Local test acc @ epoch 4: 0.7741
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.31457144021987915
Local loss @ local epoch 1: 0.584514319896698
Local loss @ local epoch 2: 0.3083699345588684
Local loss @ local epoch 3: 0.22935713827610016
Local loss @ local epoch 4: 0.20622125267982483
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.95 seconds!
[tester] 
SST2Metric: acc=0.8727064220183486, hinge=0.9043013294902417, ce=11.312412340706642
Local test acc @ epoch 4: 0.8727
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.36337777972221375
Local loss @ local epoch 1: 0.6854742765426636
Local loss @ local epoch 2: 0.3558487892150879
Local loss @ local epoch 3: 0.2619387209415436
Local loss @ local epoch 4: 0.6143367290496826
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.87 seconds!
[tester] 
SST2Metric: acc=0.7878440366972477, hinge=1.1376144623537676, ce=11.808986637570442
Local test acc @ epoch 4: 0.7878
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.3329293727874756
Local loss @ local epoch 1: 0.6405839323997498
Local loss @ local epoch 2: 0.3014494776725769
Local loss @ local epoch 3: 0.12331348657608032
Local loss @ local epoch 4: 0.08987824618816376
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.6 seconds!
[tester] 
SST2Metric: acc=0.9151376146788991, hinge=0.7945361391666832, ce=12.460839551523192
Local test acc @ epoch 4: 0.9151
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.33351051807403564
Local loss @ local epoch 1: 0.22107499837875366
Local loss @ local epoch 2: 0.450814813375473
Local loss @ local epoch 3: 0.20134365558624268
Local loss @ local epoch 4: 0.12032338976860046
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.76 seconds!
[tester] 
SST2Metric: acc=0.8956422018348624, hinge=0.9591163992881775, ce=12.056365284351035
Local test acc @ epoch 4: 0.8956
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.3443331718444824
Local loss @ local epoch 1: 0.642952561378479
Local loss @ local epoch 2: 0.5478032231330872
Local loss @ local epoch 3: 0.5762512683868408
Local loss @ local epoch 4: 0.6991543173789978
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.6 seconds!
[tester] 
SST2Metric: acc=0.4988532110091743, hinge=2.0041517248941125, ce=14.410536302339047
Local test acc @ epoch 4: 0.4989
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.4636603593826294
Local loss @ local epoch 1: 0.7651932835578918
Local loss @ local epoch 2: 0.43200236558914185
Local loss @ local epoch 3: 0.4112328886985779
Local loss @ local epoch 4: 0.3782612383365631
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.73 seconds!
[tester] 
SST2Metric: acc=0.8486238532110092, hinge=1.0319481032703994, ce=11.91857034350754
Local test acc @ epoch 4: 0.8486
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.4138287901878357
Local loss @ local epoch 1: 0.630416750907898
Local loss @ local epoch 2: 0.39688122272491455
Local loss @ local epoch 3: 0.32306405901908875
Local loss @ local epoch 4: 0.21583668887615204
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.911697247706422, hinge=0.9341754760217229, ce=11.862510637405816
Local test acc @ epoch 4: 0.9117
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.42923712730407715
Local loss @ local epoch 1: 0.4431171119213104
Local loss @ local epoch 2: 0.373660147190094
Local loss @ local epoch 3: 0.30454221367836
Local loss @ local epoch 4: 0.19173124432563782
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.01 seconds!
[tester] 
SST2Metric: acc=0.625, hinge=1.3697409607948514, ce=11.559661112794089
Local test acc @ epoch 4: 0.625
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.40378186106681824
Local loss @ local epoch 1: 0.34091028571128845
Local loss @ local epoch 2: 0.2659643292427063
Local loss @ local epoch 3: 0.09562472999095917
Local loss @ local epoch 4: 0.0673772320151329
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.79 seconds!
[tester] 
SST2Metric: acc=0.911697247706422, hinge=0.5269932049676913, ce=9.948572928752375
Local test acc @ epoch 4: 0.9117
Global evaluate on test data...
Evaluate data in 82.82 seconds!
[tester] 
SST2Metric: acc=0.9208715596330275, hinge=0.7237064655220836, ce=11.915613839385706
Global test acc : 0.9209
Global prompt norm: 24.56808853149414
Global epoch 5...
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.1785641312599182
Local loss @ local epoch 1: 0.39184656739234924
Local loss @ local epoch 2: 0.26504045724868774
Local loss @ local epoch 3: 0.6415923237800598
Local loss @ local epoch 4: 0.26797541975975037
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.7717889908256881, hinge=1.1482256131434658, ce=10.356677720306116
Local test acc @ epoch 5: 0.7718
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.15656757354736328
Local loss @ local epoch 1: 0.12358365207910538
Local loss @ local epoch 2: 2.1130857467651367
Local loss @ local epoch 3: 0.671146810054779
Local loss @ local epoch 4: 0.6386353373527527
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.72 seconds!
[tester] 
SST2Metric: acc=0.49770642201834864, hinge=1.9540025050486993, ce=11.937237135860897
Local test acc @ epoch 5: 0.4977
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.22755372524261475
Local loss @ local epoch 1: 0.5576504468917847
Local loss @ local epoch 2: 0.6777275800704956
Local loss @ local epoch 3: 0.679951548576355
Local loss @ local epoch 4: 0.6974506378173828
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.4 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=1.9945746988331505, ce=12.281362017360303
Local test acc @ epoch 5: 0.5092
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.2137228548526764
Local loss @ local epoch 1: 0.3487057089805603
Local loss @ local epoch 2: 0.46243229508399963
Local loss @ local epoch 3: 0.6112374663352966
Local loss @ local epoch 4: 0.4014153480529785
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.8692660550458715, hinge=1.3553429409998272, ce=13.890024333918861
Local test acc @ epoch 5: 0.8693
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.21863694489002228
Local loss @ local epoch 1: 0.23685064911842346
Local loss @ local epoch 2: 0.11631587892770767
Local loss @ local epoch 3: 0.046557165682315826
Local loss @ local epoch 4: 0.3894551396369934
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.97 seconds!
[tester] 
SST2Metric: acc=0.6834862385321101, hinge=1.394611674711245, ce=10.724200327462013
Local test acc @ epoch 5: 0.6835
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.09271007031202316
Local loss @ local epoch 1: 0.12221525609493256
Local loss @ local epoch 2: 0.675835371017456
Local loss @ local epoch 3: 0.7055914402008057
Local loss @ local epoch 4: 0.6928132772445679
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.46 seconds!
[tester] 
SST2Metric: acc=0.5114678899082569, hinge=1.9975932497496998, ce=12.51089202810865
Local test acc @ epoch 5: 0.5115
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.24327094852924347
Local loss @ local epoch 1: 0.24763748049736023
Local loss @ local epoch 2: 0.8317351937294006
Local loss @ local epoch 3: 0.7152531147003174
Local loss @ local epoch 4: 0.713480532169342
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.48 seconds!
[tester] 
SST2Metric: acc=0.5103211009174312, hinge=1.9981979164508505, ce=12.885654475710808
Local test acc @ epoch 5: 0.5103
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.1959221065044403
Local loss @ local epoch 1: 0.15046674013137817
Local loss @ local epoch 2: 0.28628772497177124
Local loss @ local epoch 3: 0.19683995842933655
Local loss @ local epoch 4: 0.1946917176246643
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.81 seconds!
[tester] 
SST2Metric: acc=0.9151376146788991, hinge=0.8124717837626781, ce=11.168086515654117
Local test acc @ epoch 5: 0.9151
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.13719582557678223
Local loss @ local epoch 1: 0.19473294913768768
Local loss @ local epoch 2: 0.6572017669677734
Local loss @ local epoch 3: 0.30228686332702637
Local loss @ local epoch 4: 0.2820991277694702
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.73 seconds!
[tester] 
SST2Metric: acc=0.8291284403669725, hinge=1.2689831251398138, ce=12.677734383749305
Local test acc @ epoch 5: 0.8291
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.10963320732116699
Local loss @ local epoch 1: 0.2121393084526062
Local loss @ local epoch 2: 0.12243795394897461
Local loss @ local epoch 3: 0.4445457458496094
Local loss @ local epoch 4: 0.09602683037519455
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.6 seconds!
[tester] 
SST2Metric: acc=0.8864678899082569, hinge=0.6530203400948725, ce=11.136421413596617
Local test acc @ epoch 5: 0.8865
Global evaluate on test data...
Evaluate data in 82.7 seconds!
[tester] 
SST2Metric: acc=0.8899082568807339, hinge=0.7248546388171134, ce=11.597020612944156
Global test acc : 0.8899
Global prompt norm: 31.981687545776367
Global epoch 6...
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.36028897762298584
Local loss @ local epoch 1: 0.49174290895462036
Local loss @ local epoch 2: 0.5171945095062256
Local loss @ local epoch 3: 0.6812950968742371
Local loss @ local epoch 4: 0.5646649599075317
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.53 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=1.9717618664470287, ce=14.241195031262318
Local test acc @ epoch 6: 0.5092
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.3003882169723511
Local loss @ local epoch 1: 0.9085572957992554
Local loss @ local epoch 2: 0.7373483777046204
Local loss @ local epoch 3: 0.6385684609413147
Local loss @ local epoch 4: 0.49249720573425293
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.48 seconds!
[tester] 
SST2Metric: acc=0.4805045871559633, hinge=2.1069829360060734, ce=11.187084670460552
Local test acc @ epoch 6: 0.4805
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.5872892737388611
Local loss @ local epoch 1: 0.7113180756568909
Local loss @ local epoch 2: 0.6376692056655884
Local loss @ local epoch 3: 0.7839100360870361
Local loss @ local epoch 4: 0.7104471325874329
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.69 seconds!
[tester] 
SST2Metric: acc=0.4805045871559633, hinge=2.0165060539858057, ce=14.037745073300982
Local test acc @ epoch 6: 0.4805
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.3283720910549164
Local loss @ local epoch 1: 0.5292306542396545
Local loss @ local epoch 2: 0.5149319767951965
Local loss @ local epoch 3: 0.8121365904808044
Local loss @ local epoch 4: 0.7126009464263916
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.49 seconds!
[tester] 
SST2Metric: acc=0.4873853211009174, hinge=2.0025978766450097, ce=12.202988090865109
Local test acc @ epoch 6: 0.4874
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.490094929933548
Local loss @ local epoch 1: 0.43335992097854614
Local loss @ local epoch 2: 0.7533252835273743
Local loss @ local epoch 3: 0.691305935382843
Local loss @ local epoch 4: 0.6688933372497559
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.38 seconds!
[tester] 
SST2Metric: acc=0.4908256880733945, hinge=2.006052952293956, ce=12.711037740794891
Local test acc @ epoch 6: 0.4908
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.12118908762931824
Local loss @ local epoch 1: 0.2360999435186386
Local loss @ local epoch 2: 0.1827627420425415
Local loss @ local epoch 3: 0.06740570813417435
Local loss @ local epoch 4: 0.03695593401789665
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.911697247706422, hinge=0.46117653909626355, ce=9.317738839245717
Local test acc @ epoch 6: 0.9117
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.31804153323173523
Local loss @ local epoch 1: 0.7479795813560486
Local loss @ local epoch 2: 0.6463108658790588
Local loss @ local epoch 3: 0.6798040866851807
Local loss @ local epoch 4: 0.5645508766174316
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.48 seconds!
[tester] 
SST2Metric: acc=0.48623853211009177, hinge=1.997892188369681, ce=12.899429994985598
Local test acc @ epoch 6: 0.4862
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.21362744271755219
Local loss @ local epoch 1: 0.6711239814758301
Local loss @ local epoch 2: 0.6654287576675415
Local loss @ local epoch 3: 0.6598185300827026
Local loss @ local epoch 4: 0.6429435014724731
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.43 seconds!
[tester] 
SST2Metric: acc=0.5091743119266054, hinge=1.9755642895304828, ce=13.138017698165473
Local test acc @ epoch 6: 0.5092
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.09071864187717438
Local loss @ local epoch 1: 0.1143650934100151
Local loss @ local epoch 2: 0.5783094167709351
Local loss @ local epoch 3: 1.4598515033721924
Local loss @ local epoch 4: 0.10364428907632828
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.69 seconds!
[tester] 
SST2Metric: acc=0.8979357798165137, hinge=1.041303504497633, ce=11.546930365606185
Local test acc @ epoch 6: 0.8979
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.49791544675827026
Local loss @ local epoch 1: 0.4441189467906952
Local loss @ local epoch 2: 0.33689138293266296
Local loss @ local epoch 3: 0.20775215327739716
Local loss @ local epoch 4: 0.13407689332962036
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.92 seconds!
[tester] 
SST2Metric: acc=0.7305045871559633, hinge=1.172539464377482, ce=11.118847042048744
Local test acc @ epoch 6: 0.7305
Global evaluate on test data...
Evaluate data in 82.55 seconds!
[tester] 
SST2Metric: acc=0.5848623853211009, hinge=1.9054647749717082, ce=13.510006440888851
Global test acc : 0.5849
Global prompt norm: 40.17759704589844
Global epoch 7...
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.7890207171440125
Local loss @ local epoch 1: 0.5295830965042114
Local loss @ local epoch 2: 0.4148330092430115
Local loss @ local epoch 3: 0.2722916603088379
Local loss @ local epoch 4: 0.26092976331710815
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.64 seconds!
[tester] 
SST2Metric: acc=0.8910550458715596, hinge=1.12447194714065, ce=12.215048457504412
Local test acc @ epoch 7: 0.8911
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.6423127055168152
Local loss @ local epoch 1: 0.630608081817627
Local loss @ local epoch 2: 0.6677814722061157
Local loss @ local epoch 3: 0.7411392331123352
Local loss @ local epoch 4: 0.7150986194610596
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.34 seconds!
[tester] 
SST2Metric: acc=0.49426605504587157, hinge=2.000783708117424, ce=12.883008134474448
Local test acc @ epoch 7: 0.4943
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.5941751599311829
Local loss @ local epoch 1: 0.5591803193092346
Local loss @ local epoch 2: 0.3096901774406433
Local loss @ local epoch 3: 0.1800353229045868
Local loss @ local epoch 4: 0.11518318206071854
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.64 seconds!
[tester] 
SST2Metric: acc=0.8555045871559633, hinge=0.8236814626586546, ce=9.467028950332502
Local test acc @ epoch 7: 0.8555
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.6952570676803589
Local loss @ local epoch 1: 0.4401971697807312
Local loss @ local epoch 2: 0.27737298607826233
Local loss @ local epoch 3: 0.1575482040643692
Local loss @ local epoch 4: 0.17714640498161316
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.8956422018348624, hinge=0.679196163055, ce=10.290574712490816
Local test acc @ epoch 7: 0.8956
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.6176721453666687
Local loss @ local epoch 1: 0.49799928069114685
Local loss @ local epoch 2: 0.5993743538856506
Local loss @ local epoch 3: 0.5074335336685181
Local loss @ local epoch 4: 0.5335608124732971
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.7706422018348624, hinge=1.586416954841089, ce=12.266266376600353
Local test acc @ epoch 7: 0.7706
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.6662448644638062
Local loss @ local epoch 1: 0.8709225058555603
Local loss @ local epoch 2: 0.6859867572784424
Local loss @ local epoch 3: 0.8332326412200928
Local loss @ local epoch 4: 0.9900748133659363
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.54 seconds!
[tester] 
SST2Metric: acc=0.5103211009174312, hinge=1.995424831679108, ce=16.675311009818262
Local test acc @ epoch 7: 0.5103
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.600421667098999
Local loss @ local epoch 1: 0.7177454829216003
Local loss @ local epoch 2: 0.6191248893737793
Local loss @ local epoch 3: 0.46211355924606323
Local loss @ local epoch 4: 0.37481099367141724
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.6708715596330275, hinge=1.274134110420122, ce=11.978539554350967
Local test acc @ epoch 7: 0.6709
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.7495144605636597
Local loss @ local epoch 1: 0.47804322838783264
Local loss @ local epoch 2: 0.2869822084903717
Local loss @ local epoch 3: 0.1405024528503418
Local loss @ local epoch 4: 0.07138515263795853
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.8348623853211009, hinge=0.9235320296309409, ce=9.837930924301848
Local test acc @ epoch 7: 0.8349
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.6300504803657532
Local loss @ local epoch 1: 0.7541661262512207
Local loss @ local epoch 2: 0.561944842338562
Local loss @ local epoch 3: 0.5628588795661926
Local loss @ local epoch 4: 0.2892807424068451
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.85 seconds!
[tester] 
SST2Metric: acc=0.7694954128440367, hinge=1.2834883452555454, ce=13.063351963638166
Local test acc @ epoch 7: 0.7695
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.6146621704101562
Local loss @ local epoch 1: 0.7164998054504395
Local loss @ local epoch 2: 0.6716102957725525
Local loss @ local epoch 3: 0.5906479358673096
Local loss @ local epoch 4: 0.6568624377250671
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.33 seconds!
[tester] 
SST2Metric: acc=0.4908256880733945, hinge=2.0105589475106758, ce=12.243085178760214
Local test acc @ epoch 7: 0.4908
Global evaluate on test data...
Evaluate data in 82.82 seconds!
[tester] 
SST2Metric: acc=0.9025229357798165, hinge=0.8911186926955477, ce=11.95607411970786
Global test acc : 0.9025
Global prompt norm: 37.06882858276367
Global epoch 8...
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.24018017947673798
Local loss @ local epoch 1: 0.35474449396133423
Local loss @ local epoch 2: 0.24090655148029327
Local loss @ local epoch 3: 0.09095367044210434
Local loss @ local epoch 4: 0.25376096367836
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.7 seconds!
[tester] 
SST2Metric: acc=0.8795871559633027, hinge=0.8310635379695017, ce=10.224826147796911
Local test acc @ epoch 8: 0.8796
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.33660659193992615
Local loss @ local epoch 1: 0.2761133313179016
Local loss @ local epoch 2: 0.2554963529109955
Local loss @ local epoch 3: 1.3474094867706299
Local loss @ local epoch 4: 0.7987903952598572
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.64 seconds!
[tester] 
SST2Metric: acc=0.4908256880733945, hinge=1.98780986365922, ce=10.003119521184798
Local test acc @ epoch 8: 0.4908
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.24228422343730927
Local loss @ local epoch 1: 0.15439437329769135
Local loss @ local epoch 2: 0.3142975866794586
Local loss @ local epoch 3: 0.10813537240028381
Local loss @ local epoch 4: 0.07362554222345352
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.59 seconds!
[tester] 
SST2Metric: acc=0.8623853211009175, hinge=0.7192553998133459, ce=10.94341753163469
Local test acc @ epoch 8: 0.8624
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.2255266308784485
Local loss @ local epoch 1: 0.19069381058216095
Local loss @ local epoch 2: 0.21734780073165894
Local loss @ local epoch 3: 0.431499183177948
Local loss @ local epoch 4: 0.07636571675539017
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.66 seconds!
[tester] 
SST2Metric: acc=0.8256880733944955, hinge=1.0945055298848982, ce=11.550362464484818
Local test acc @ epoch 8: 0.8257
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.19025373458862305
Local loss @ local epoch 1: 0.13853245973587036
Local loss @ local epoch 2: 0.10390663892030716
Local loss @ local epoch 3: 0.047105129808187485
Local loss @ local epoch 4: 0.029205862432718277
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.66 seconds!
[tester] 
SST2Metric: acc=0.819954128440367, hinge=0.8663104160116353, ce=9.242556134495166
Local test acc @ epoch 8: 0.82
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.4412686228752136
Local loss @ local epoch 1: 0.4337127208709717
Local loss @ local epoch 2: 0.22628645598888397
Local loss @ local epoch 3: 0.12571565806865692
Local loss @ local epoch 4: 0.06101570650935173
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.9036697247706422, hinge=0.5116208685100625, ce=10.395043320612077
Local test acc @ epoch 8: 0.9037
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.17729386687278748
Local loss @ local epoch 1: 0.40499237179756165
Local loss @ local epoch 2: 0.31701478362083435
Local loss @ local epoch 3: 0.06729651987552643
Local loss @ local epoch 4: 0.03626915067434311
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.8520642201834863, hinge=0.7390469519096777, ce=10.371156946234747
Local test acc @ epoch 8: 0.8521
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.35648414492607117
Local loss @ local epoch 1: 0.43607190251350403
Local loss @ local epoch 2: 0.15922106802463531
Local loss @ local epoch 3: 0.1661052405834198
Local loss @ local epoch 4: 0.13112075626850128
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.8715596330275229, hinge=0.9775905721231338, ce=11.390829462523854
Local test acc @ epoch 8: 0.8716
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.2223927229642868
Local loss @ local epoch 1: 0.31163454055786133
Local loss @ local epoch 2: 0.24821536242961884
Local loss @ local epoch 3: 0.07417957484722137
Local loss @ local epoch 4: 0.05180838331580162
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.82 seconds!
[tester] 
SST2Metric: acc=0.7912844036697247, hinge=1.0694042646556818, ce=9.943532987472114
Local test acc @ epoch 8: 0.7913
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.26649585366249084
Local loss @ local epoch 1: 0.12009760737419128
Local loss @ local epoch 2: 0.07954785972833633
Local loss @ local epoch 3: 0.03521537408232689
Local loss @ local epoch 4: 0.12114322185516357
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.79 seconds!
[tester] 
SST2Metric: acc=0.5848623853211009, hinge=1.6347662779169345, ce=11.014100354745848
Local test acc @ epoch 8: 0.5849
Global evaluate on test data...
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.8291284403669725, hinge=0.8458203744450841, ce=10.410703886539563
Global test acc : 0.8291
Global prompt norm: 37.0765380859375
Global epoch 9...
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.09949920326471329
Local loss @ local epoch 1: 0.021734710782766342
Local loss @ local epoch 2: 0.030621567741036415
Local loss @ local epoch 3: 1.8808510303497314
Local loss @ local epoch 4: 0.6736505031585693
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.41 seconds!
[tester] 
SST2Metric: acc=0.5424311926605505, hinge=1.9977282799712015, ce=12.51476269468255
Local test acc @ epoch 9: 0.5424
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.1461637169122696
Local loss @ local epoch 1: 0.06734444946050644
Local loss @ local epoch 2: 0.03324677050113678
Local loss @ local epoch 3: 0.01634065993130207
Local loss @ local epoch 4: 0.006383155006915331
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.73 seconds!
[tester] 
SST2Metric: acc=0.9334862385321101, hinge=0.33754757060370316, ce=9.42141978237607
Local test acc @ epoch 9: 0.9335
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.10025667399168015
Local loss @ local epoch 1: 0.009709756821393967
Local loss @ local epoch 2: 0.0018764275591820478
Local loss @ local epoch 3: 0.0006900780135765672
Local loss @ local epoch 4: 0.000431362830568105
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.8715596330275229, hinge=0.8164607122403766, ce=6.289409856183814
Local test acc @ epoch 9: 0.8716
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.20171485841274261
Local loss @ local epoch 1: 0.20498250424861908
Local loss @ local epoch 2: 0.1155787855386734
Local loss @ local epoch 3: 0.09162817150354385
Local loss @ local epoch 4: 0.05918606370687485
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.73 seconds!
[tester] 
SST2Metric: acc=0.9128440366972477, hinge=0.5049159227434649, ce=10.666175396070567
Local test acc @ epoch 9: 0.9128
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.333874374628067
Local loss @ local epoch 1: 0.12423428148031235
Local loss @ local epoch 2: 0.050630152225494385
Local loss @ local epoch 3: 0.2358674556016922
Local loss @ local epoch 4: 0.041440702974796295
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.67 seconds!
[tester] 
SST2Metric: acc=0.856651376146789, hinge=0.8847312913575304, ce=9.779204044866999
Local test acc @ epoch 9: 0.8567
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.2717275321483612
Local loss @ local epoch 1: 0.20350205898284912
Local loss @ local epoch 2: 0.0911773070693016
Local loss @ local epoch 3: 0.4154718816280365
Local loss @ local epoch 4: 0.35505181550979614
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.67 seconds!
[tester] 
SST2Metric: acc=0.8910550458715596, hinge=0.8342442517980523, ce=11.102124222921669
Local test acc @ epoch 9: 0.8911
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.31369125843048096
Local loss @ local epoch 1: 0.15143263339996338
Local loss @ local epoch 2: 0.47310587763786316
Local loss @ local epoch 3: 0.13712632656097412
Local loss @ local epoch 4: 0.08772578835487366
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.75 seconds!
[tester] 
SST2Metric: acc=0.930045871559633, hinge=0.43682282561555913, ce=12.098376099122774
Local test acc @ epoch 9: 0.93
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.07555930316448212
Local loss @ local epoch 1: 0.018493207171559334
Local loss @ local epoch 2: 0.009298989549279213
Local loss @ local epoch 3: 0.002133385045453906
Local loss @ local epoch 4: 0.0014518798561766744
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.7 seconds!
[tester] 
SST2Metric: acc=0.8291284403669725, hinge=1.0521213905800373, ce=9.459104161743724
Local test acc @ epoch 9: 0.8291
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.2716500759124756
Local loss @ local epoch 1: 0.5200909972190857
Local loss @ local epoch 2: 0.22845131158828735
Local loss @ local epoch 3: 0.4607357382774353
Local loss @ local epoch 4: 0.18125750124454498
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.783256880733945, hinge=1.103785673412708, ce=11.726281638539165
Local test acc @ epoch 9: 0.7833
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.2853509187698364
Local loss @ local epoch 1: 0.12375868111848831
Local loss @ local epoch 2: 0.05478104203939438
Local loss @ local epoch 3: 1.4807788133621216
Local loss @ local epoch 4: 0.6987801790237427
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.56 seconds!
[tester] 
SST2Metric: acc=0.5149082568807339, hinge=1.9992370528912327, ce=12.752781299276089
Local test acc @ epoch 9: 0.5149
Global evaluate on test data...
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9392201834862385, hinge=0.3440232911241164, ce=9.995499322173792
Global test acc : 0.9392
Global prompt norm: 41.10739517211914
Global epoch 10...
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.021611560136079788
Local loss @ local epoch 1: 0.006300481501966715
Local loss @ local epoch 2: 0.06263948231935501
Local loss @ local epoch 3: 0.0030481694266200066
Local loss @ local epoch 4: 0.023527972400188446
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.7 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=0.34849104695363875, ce=10.418362153779476
Local test acc @ epoch 10: 0.9369
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.1652645617723465
Local loss @ local epoch 1: 0.7214555144309998
Local loss @ local epoch 2: 0.6908764243125916
Local loss @ local epoch 3: 0.6682087182998657
Local loss @ local epoch 4: 0.6589647531509399
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.51 seconds!
[tester] 
SST2Metric: acc=0.4908256880733945, hinge=2.0170755047316944, ce=12.35688898978977
Local test acc @ epoch 10: 0.4908
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.034874267876148224
Local loss @ local epoch 1: 0.0042318012565374374
Local loss @ local epoch 2: 0.004182491917163134
Local loss @ local epoch 3: 0.7936609387397766
Local loss @ local epoch 4: 0.0007112319581210613
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.63 seconds!
[tester] 
SST2Metric: acc=0.9094036697247706, hinge=0.5379562073071068, ce=8.71064914038422
Local test acc @ epoch 10: 0.9094
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.02483365498483181
Local loss @ local epoch 1: 0.22989897429943085
Local loss @ local epoch 2: 0.0021032372023910284
Local loss @ local epoch 3: 0.0026264155749231577
Local loss @ local epoch 4: 0.0014731207629665732
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.75 seconds!
[tester] 
SST2Metric: acc=0.9071100917431193, hinge=0.5157468260154812, ce=8.754187282072294
Local test acc @ epoch 10: 0.9071
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.014736160635948181
Local loss @ local epoch 1: 0.0028025403153151274
Local loss @ local epoch 2: 0.0007923321099951863
Local loss @ local epoch 3: 0.5330851078033447
Local loss @ local epoch 4: 0.0008648508810438216
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.8302752293577982, hinge=0.91283327778545, ce=8.092688866711537
Local test acc @ epoch 10: 0.8303
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.040781863033771515
Local loss @ local epoch 1: 0.02113160863518715
Local loss @ local epoch 2: 0.0070322174578905106
Local loss @ local epoch 3: 0.7090836763381958
Local loss @ local epoch 4: 0.18477585911750793
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.64 seconds!
[tester] 
SST2Metric: acc=0.8887614678899083, hinge=0.6055904935806169, ce=10.526492556300733
Local test acc @ epoch 10: 0.8888
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.04999259114265442
Local loss @ local epoch 1: 0.0033965876791626215
Local loss @ local epoch 2: 0.0005880708922632039
Local loss @ local epoch 3: 0.0007158943917602301
Local loss @ local epoch 4: 0.005031418055295944
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.66 seconds!
[tester] 
SST2Metric: acc=0.8910550458715596, hinge=0.8030889831278303, ce=8.867595020784151
Local test acc @ epoch 10: 0.8911
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.024366462603211403
Local loss @ local epoch 1: 0.012401110492646694
Local loss @ local epoch 2: 0.003424443071708083
Local loss @ local epoch 3: 0.0031874629203230143
Local loss @ local epoch 4: 0.0010509284911677241
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.79 seconds!
[tester] 
SST2Metric: acc=0.875, hinge=0.8111443911943961, ce=7.622069455068046
Local test acc @ epoch 10: 0.875
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.05645439773797989
Local loss @ local epoch 1: 0.021127091720700264
Local loss @ local epoch 2: 0.006339744199067354
Local loss @ local epoch 3: 0.0013206255389377475
Local loss @ local epoch 4: 0.001136947888880968
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.62 seconds!
[tester] 
SST2Metric: acc=0.8784403669724771, hinge=0.7544601655334507, ce=8.287618654583571
Local test acc @ epoch 10: 0.8784
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.10455089062452316
Local loss @ local epoch 1: 0.20913025736808777
Local loss @ local epoch 2: 0.13581523299217224
Local loss @ local epoch 3: 0.05923019349575043
Local loss @ local epoch 4: 0.025370098650455475
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.79 seconds!
[tester] 
SST2Metric: acc=0.9013761467889908, hinge=0.5003526109621066, ce=10.350886406154807
Local test acc @ epoch 10: 0.9014
Global evaluate on test data...
Evaluate data in 82.58 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.34241973273797865, ce=8.696749319723986
Global test acc : 0.9427
Global prompt norm: 41.92516326904297
Global epoch 11...
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0026818453334271908
Local loss @ local epoch 1: 0.0017164807068184018
Local loss @ local epoch 2: 0.057718511670827866
Local loss @ local epoch 3: 0.15130265057086945
Local loss @ local epoch 4: 0.011915023438632488
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.61 seconds!
[tester] 
SST2Metric: acc=0.893348623853211, hinge=0.5241284572750057, ce=10.637113448676713
Local test acc @ epoch 11: 0.8933
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.2510448396205902
Local loss @ local epoch 1: 1.1439790725708008
Local loss @ local epoch 2: 0.15588146448135376
Local loss @ local epoch 3: 0.17166867852210999
Local loss @ local epoch 4: 0.1571359634399414
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.76 seconds!
[tester] 
SST2Metric: acc=0.9128440366972477, hinge=0.7323885601048076, ce=10.65598368863447
Local test acc @ epoch 11: 0.9128
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0026122848503291607
Local loss @ local epoch 1: 0.007683728821575642
Local loss @ local epoch 2: 0.019176334142684937
Local loss @ local epoch 3: 0.022343743592500687
Local loss @ local epoch 4: 0.006976904347538948
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.66 seconds!
[tester] 
SST2Metric: acc=0.9128440366972477, hinge=0.5094484848166825, ce=8.579463783754122
Local test acc @ epoch 11: 0.9128
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0023514912463724613
Local loss @ local epoch 1: 0.0015127129154279828
Local loss @ local epoch 2: 0.00022804090986028314
Local loss @ local epoch 3: 0.0030695986934006214
Local loss @ local epoch 4: 0.014478959143161774
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.7603211009174312, hinge=1.604879923916738, ce=6.888935316593275
Local test acc @ epoch 11: 0.7603
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.006583120673894882
Local loss @ local epoch 1: 0.025373270735144615
Local loss @ local epoch 2: 1.890813946723938
Local loss @ local epoch 3: 0.34381502866744995
Local loss @ local epoch 4: 0.26211458444595337
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.8818807339449541, hinge=0.9221589822287953, ce=11.667940104773285
Local test acc @ epoch 11: 0.8819
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.06902014464139938
Local loss @ local epoch 1: 0.9940717220306396
Local loss @ local epoch 2: 0.1695433259010315
Local loss @ local epoch 3: 0.780305802822113
Local loss @ local epoch 4: 0.45721641182899475
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.72 seconds!
[tester] 
SST2Metric: acc=0.6857798165137615, hinge=1.2434109673587554, ce=12.695210246864809
Local test acc @ epoch 11: 0.6858
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0012655218597501516
Local loss @ local epoch 1: 0.008296700194478035
Local loss @ local epoch 2: 0.837166965007782
Local loss @ local epoch 3: 0.0021461741998791695
Local loss @ local epoch 4: 0.005998706445097923
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.86 seconds!
[tester] 
SST2Metric: acc=0.6892201834862385, hinge=1.4683867917148345, ce=10.650805919542226
Local test acc @ epoch 11: 0.6892
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0018113397527486086
Local loss @ local epoch 1: 0.06884200125932693
Local loss @ local epoch 2: 0.5045095682144165
Local loss @ local epoch 3: 0.008726830594241619
Local loss @ local epoch 4: 0.023188456892967224
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.81 seconds!
[tester] 
SST2Metric: acc=0.8715596330275229, hinge=0.8013995322612447, ce=10.840203118980478
Local test acc @ epoch 11: 0.8716
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.001356708351522684
Local loss @ local epoch 1: 0.0004392512491904199
Local loss @ local epoch 2: 0.0002806486445479095
Local loss @ local epoch 3: 1.5329865217208862
Local loss @ local epoch 4: 0.024717865511775017
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.61 seconds!
[tester] 
SST2Metric: acc=0.7568807339449541, hinge=1.0843033224617669, ce=9.963612206485294
Local test acc @ epoch 11: 0.7569
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.002682305173948407
Local loss @ local epoch 1: 0.048948921263217926
Local loss @ local epoch 2: 0.06081492826342583
Local loss @ local epoch 3: 0.0033099481370300055
Local loss @ local epoch 4: 0.005719910841435194
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.88 seconds!
[tester] 
SST2Metric: acc=0.9334862385321101, hinge=0.3548902148773911, ce=9.525271905671566
Local test acc @ epoch 11: 0.9335
Global evaluate on test data...
Evaluate data in 82.63 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=0.3769952661673957, ce=7.736595683141586
Global test acc : 0.9427
Global prompt norm: 44.64788818359375
Global epoch 12...
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.003385232761502266
Local loss @ local epoch 1: 0.00018320116214454174
Local loss @ local epoch 2: 0.0003013607347384095
Local loss @ local epoch 3: 7.008975080680102e-05
Local loss @ local epoch 4: 2.9711703973589465e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.62 seconds!
[tester] 
SST2Metric: acc=0.926605504587156, hinge=0.7213381288248465, ce=4.507696560763438
Local test acc @ epoch 12: 0.9266
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0006441135192289948
Local loss @ local epoch 1: 4.02767545892857e-05
Local loss @ local epoch 2: 1.3530148862628266e-05
Local loss @ local epoch 3: 1.1920810720766895e-05
Local loss @ local epoch 4: 7.03331534168683e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.75 seconds!
[tester] 
SST2Metric: acc=0.9220183486238532, hinge=0.7736749788489911, ce=4.816541098673409
Local test acc @ epoch 12: 0.922
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.002709177555516362
Local loss @ local epoch 1: 6.176128226798028e-05
Local loss @ local epoch 2: 0.00038371823029592633
Local loss @ local epoch 3: 9.565739310346544e-05
Local loss @ local epoch 4: 4.890361014986411e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.8853211009174312, hinge=0.954875409329703, ce=5.109383637752008
Local test acc @ epoch 12: 0.8853
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0018993238918483257
Local loss @ local epoch 1: 0.001899964059703052
Local loss @ local epoch 2: 0.9880366325378418
Local loss @ local epoch 3: 0.0008369676070287824
Local loss @ local epoch 4: 0.0035823609214276075
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.59 seconds!
[tester] 
SST2Metric: acc=0.8669724770642202, hinge=0.772214528480801, ce=9.754030796366001
Local test acc @ epoch 12: 0.867
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.004639714024960995
Local loss @ local epoch 1: 0.00036087408079765737
Local loss @ local epoch 2: 8.947517198976129e-05
Local loss @ local epoch 3: 0.00010154241317650303
Local loss @ local epoch 4: 5.936309025855735e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.66 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=0.5331542426293049, ce=5.486874090422184
Local test acc @ epoch 12: 0.9358
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.3238508403301239
Local loss @ local epoch 1: 0.15689313411712646
Local loss @ local epoch 2: 0.09790261834859848
Local loss @ local epoch 3: 0.08377373963594437
Local loss @ local epoch 4: 0.035825151950120926
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.7 seconds!
[tester] 
SST2Metric: acc=0.783256880733945, hinge=1.0710227280308346, ce=9.913193641452615
Local test acc @ epoch 12: 0.7833
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.00725260004401207
Local loss @ local epoch 1: 0.0006227625999599695
Local loss @ local epoch 2: 0.0003469627699814737
Local loss @ local epoch 3: 0.00018225125677417964
Local loss @ local epoch 4: 0.00011163155431859195
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.8944954128440367, hinge=0.9940805894519211, ce=6.256185872839131
Local test acc @ epoch 12: 0.8945
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0017710013780742884
Local loss @ local epoch 1: 0.003371327882632613
Local loss @ local epoch 2: 0.4706296920776367
Local loss @ local epoch 3: 0.3695693016052246
Local loss @ local epoch 4: 0.03046558052301407
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.51 seconds!
[tester] 
SST2Metric: acc=0.9105504587155964, hinge=0.43605499967522576, ce=9.777292286584137
Local test acc @ epoch 12: 0.9106
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0007190224132500589
Local loss @ local epoch 1: 5.2209892601240426e-05
Local loss @ local epoch 2: 6.474283145507798e-05
Local loss @ local epoch 3: 2.4958659196272492e-05
Local loss @ local epoch 4: 5.11106964040664e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.68 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=0.665491245481946, ce=4.423718146227915
Local test acc @ epoch 12: 0.9358
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0008756867609918118
Local loss @ local epoch 1: 6.463883619289845e-05
Local loss @ local epoch 2: 3.223035309929401e-05
Local loss @ local epoch 3: 7.271738468261901e-06
Local loss @ local epoch 4: 6.273357939790003e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.51 seconds!
[tester] 
SST2Metric: acc=0.9094036697247706, hinge=0.9406881950317173, ce=4.06752270514812
Local test acc @ epoch 12: 0.9094
Global evaluate on test data...
Evaluate data in 82.68 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=0.5622134758244961, ce=6.36045486555187
Global test acc : 0.9438
Global prompt norm: 47.79851531982422
Global epoch 13...
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.05851675570011139
Local loss @ local epoch 1: 0.6419661045074463
Local loss @ local epoch 2: 0.7033814787864685
Local loss @ local epoch 3: 0.6842091083526611
Local loss @ local epoch 4: 0.6818137764930725
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.55 seconds!
[tester] 
SST2Metric: acc=0.4908256880733945, hinge=2.0029325113384, ce=12.508208686058675
Local test acc @ epoch 13: 0.4908
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 2.9144792279112153e-05
Local loss @ local epoch 1: 2.7532997131347656
Local loss @ local epoch 2: 0.024593325331807137
Local loss @ local epoch 3: 0.01749297045171261
Local loss @ local epoch 4: 0.04812151938676834
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.61 seconds!
[tester] 
SST2Metric: acc=0.9048165137614679, hinge=0.546131713401287, ce=9.643797017018729
Local test acc @ epoch 13: 0.9048
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0001739537692628801
Local loss @ local epoch 1: 0.06742370873689651
Local loss @ local epoch 2: 1.0070520639419556
Local loss @ local epoch 3: 0.00012108684313716367
Local loss @ local epoch 4: 0.0015324065461754799
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.58 seconds!
[tester] 
SST2Metric: acc=0.9311926605504587, hinge=0.40077947244184825, ce=7.3909437240810565
Local test acc @ epoch 13: 0.9312
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 9.380407573189586e-05
Local loss @ local epoch 1: 1.6387953758239746
Local loss @ local epoch 2: 0.0024636925663799047
Local loss @ local epoch 3: 0.09610388427972794
Local loss @ local epoch 4: 0.535369873046875
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.6 seconds!
[tester] 
SST2Metric: acc=0.841743119266055, hinge=0.7067959696874706, ce=10.47814011355059
Local test acc @ epoch 13: 0.8417
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 1.1220494343433529e-05
Local loss @ local epoch 1: 1.6540273009013617e-06
Local loss @ local epoch 2: 4.619359401658585e-07
Local loss @ local epoch 3: 1.9371508130916482e-07
Local loss @ local epoch 4: 1.639127589214695e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.66 seconds!
[tester] 
SST2Metric: acc=0.9243119266055045, hinge=1.0513627162767112, ce=2.2291951288870715
Local test acc @ epoch 13: 0.9243
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 5.036241782363504e-05
Local loss @ local epoch 1: 4.063530445098877
Local loss @ local epoch 2: 0.4208768904209137
Local loss @ local epoch 3: 0.332555890083313
Local loss @ local epoch 4: 0.12244226783514023
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.84 seconds!
[tester] 
SST2Metric: acc=0.8887614678899083, hinge=0.6102651926355624, ce=9.404640258999045
Local test acc @ epoch 13: 0.8888
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.00011224994523217902
Local loss @ local epoch 1: 1.2247662544250488
Local loss @ local epoch 2: 0.006603931076824665
Local loss @ local epoch 3: 0.031237781047821045
Local loss @ local epoch 4: 0.03950267657637596
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.66 seconds!
[tester] 
SST2Metric: acc=0.9311926605504587, hinge=0.3569422623979936, ce=10.125448708140523
Local test acc @ epoch 13: 0.9312
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 3.853218368021771e-05
Local loss @ local epoch 1: 0.0004871626733802259
Local loss @ local epoch 2: 1.102684905163187e-06
Local loss @ local epoch 3: 2.1624655723571777
Local loss @ local epoch 4: 0.00014130516501609236
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.58 seconds!
[tester] 
SST2Metric: acc=0.8990825688073395, hinge=0.5468243011914262, ce=6.498880307608788
Local test acc @ epoch 13: 0.8991
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 1.7597940313862637e-05
Local loss @ local epoch 1: 2.3125547158997506e-05
Local loss @ local epoch 2: 2.682208730675484e-07
Local loss @ local epoch 3: 1.5523065328598022
Local loss @ local epoch 4: 7.167417606979143e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.62 seconds!
[tester] 
SST2Metric: acc=0.8188073394495413, hinge=1.681009256785069, ce=5.356091910545979
Local test acc @ epoch 13: 0.8188
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 1.2472126400098205e-05
Local loss @ local epoch 1: 1.2091269493103027
Local loss @ local epoch 2: 0.9317612051963806
Local loss @ local epoch 3: 0.00015354534843936563
Local loss @ local epoch 4: 0.007411055266857147
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.53 seconds!
[tester] 
SST2Metric: acc=0.9243119266055045, hinge=0.3850449389273967, ce=9.387182716929585
Local test acc @ epoch 13: 0.9243
Global evaluate on test data...
Evaluate data in 82.56 seconds!
[tester] 
SST2Metric: acc=0.948394495412844, hinge=0.4850436312343002, ce=5.066229142180276
Global test acc : 0.9484
Global prompt norm: 49.07680892944336
Global epoch 14...
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.00015934141993056983
Local loss @ local epoch 1: 0.0001775333657860756
Local loss @ local epoch 2: 2.9057180199743016e-06
Local loss @ local epoch 3: 8.240292117989156e-06
Local loss @ local epoch 4: 1.2010244972771034e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.58 seconds!
[tester] 
SST2Metric: acc=0.8990825688073395, hinge=1.0674325451938385, ce=3.2127740601880834
Local test acc @ epoch 14: 0.8991
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 6.57041891827248e-05
Local loss @ local epoch 1: 3.34669639414642e-05
Local loss @ local epoch 2: 4.813045961782336e-06
Local loss @ local epoch 3: 3.114334504061844e-06
Local loss @ local epoch 4: 1.6242249785136664e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.64 seconds!
[tester] 
SST2Metric: acc=0.9472477064220184, hinge=0.6019851800498612, ce=4.210167289873875
Local test acc @ epoch 14: 0.9472
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.00036101837758906186
Local loss @ local epoch 1: 1.931102633534465e-05
Local loss @ local epoch 2: 1.1381840705871582
Local loss @ local epoch 3: 2.0836541652679443
Local loss @ local epoch 4: 0.04808712750673294
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.82 seconds!
[tester] 
SST2Metric: acc=0.8474770642201835, hinge=0.7352301370386684, ce=10.098613065317137
Local test acc @ epoch 14: 0.8475
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.00014954633661545813
Local loss @ local epoch 1: 2.035276174545288
Local loss @ local epoch 2: 0.696204423904419
Local loss @ local epoch 3: 0.7002079486846924
Local loss @ local epoch 4: 0.6973706483840942
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.68 seconds!
[tester] 
SST2Metric: acc=0.5275229357798165, hinge=2.001490425626072, ce=13.049889818244024
Local test acc @ epoch 14: 0.5275
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 2.974174276459962e-05
Local loss @ local epoch 1: 3.389814810361713e-05
Local loss @ local epoch 2: 1.698729874988203e-06
Local loss @ local epoch 3: 6.0945385484956205e-06
Local loss @ local epoch 4: 1.2516966307885014e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.64 seconds!
[tester] 
SST2Metric: acc=0.9220183486238532, hinge=0.8485565469899309, ce=4.448469654135748
Local test acc @ epoch 14: 0.922
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 4.71138337161392e-05
Local loss @ local epoch 1: 2.3692728063906543e-06
Local loss @ local epoch 2: 1.1473882750578923e-06
Local loss @ local epoch 3: 1.4752133665751899e-06
Local loss @ local epoch 4: 8.493657333019655e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.9231651376146789, hinge=0.8000128230917345, ce=4.59610232081982
Local test acc @ epoch 14: 0.9232
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 5.159727516002022e-05
Local loss @ local epoch 1: 1.4736902812728658e-05
Local loss @ local epoch 2: 1.2814987258025212e-06
Local loss @ local epoch 3: 1.13248734123772e-06
Local loss @ local epoch 4: 6.556508651556214e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.86 seconds!
[tester] 
SST2Metric: acc=0.9518348623853211, hinge=0.6068010182555662, ce=4.598487014070563
Local test acc @ epoch 14: 0.9518
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 9.247894922737032e-05
Local loss @ local epoch 1: 1.5928988432278857e-05
Local loss @ local epoch 2: 5.7219635891669895e-06
Local loss @ local epoch 3: 4.619359401658585e-07
Local loss @ local epoch 4: 1.8328383930565906e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.66 seconds!
[tester] 
SST2Metric: acc=0.911697247706422, hinge=1.0520537386246778, ce=3.9594887024765715
Local test acc @ epoch 14: 0.9117
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 1.5631105270585977e-05
Local loss @ local epoch 1: 3.5166656289220555e-06
Local loss @ local epoch 2: 1.0579792615317274e-06
Local loss @ local epoch 3: 8.940684210756444e-07
Local loss @ local epoch 4: 4.321335609347443e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.89 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=0.7228975192122503, ce=5.311259274089008
Local test acc @ epoch 14: 0.9381
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 1.3917549949837849e-05
Local loss @ local epoch 1: 2.6225966394122224e-06
Local loss @ local epoch 2: 1.7583275848664925e-06
Local loss @ local epoch 3: 1.0430812125150624e-07
Local loss @ local epoch 4: 2.6822084464583895e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.73 seconds!
[tester] 
SST2Metric: acc=0.9323394495412844, hinge=0.836256491481711, ce=5.567952011703351
Local test acc @ epoch 14: 0.9323
Global evaluate on test data...
Evaluate data in 82.69 seconds!
[tester] 
SST2Metric: acc=0.9472477064220184, hinge=0.7627860411591486, ce=3.9225228007780304
Global test acc : 0.9472
Global prompt norm: 51.262996673583984
Global epoch 15...
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 3.576278118089249e-07
Local loss @ local epoch 1: 4.470348002882929e-08
Local loss @ local epoch 2: 4.470348002882929e-08
Local loss @ local epoch 3: 2.9802320611338473e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.9461009174311926, hinge=0.831660030631844, ce=4.232518974794161
Local test acc @ epoch 15: 0.9461
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 2.9802316703353426e-07
Local loss @ local epoch 1: 2.9802320611338473e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.72 seconds!
[tester] 
SST2Metric: acc=0.9461009174311926, hinge=0.8326347874938895, ce=4.54604783845604
Local test acc @ epoch 15: 0.9461
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 4.3213341882619716e-07
Local loss @ local epoch 1: 3.3980021476745605
Local loss @ local epoch 2: 9.089703212339373e-07
Local loss @ local epoch 3: 6.480010051745921e-05
Local loss @ local epoch 4: 0.01532434206455946
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.62 seconds!
[tester] 
SST2Metric: acc=0.7752293577981652, hinge=2.0835315695869814, ce=8.189152844455265
Local test acc @ epoch 15: 0.7752
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 1.2905164957046509
Local loss @ local epoch 1: 4.04877233505249
Local loss @ local epoch 2: 0.10637053102254868
Local loss @ local epoch 3: 0.07283976674079895
Local loss @ local epoch 4: 0.04991123825311661
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.72 seconds!
[tester] 
SST2Metric: acc=0.8876146788990825, hinge=0.5734635080219409, ce=9.321593022127765
Local test acc @ epoch 15: 0.8876
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 6.407492492144229e-07
Local loss @ local epoch 1: 1.639127447106148e-07
Local loss @ local epoch 2: 4.470348002882929e-08
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.72 seconds!
[tester] 
SST2Metric: acc=0.9380733944954128, hinge=1.0066987062812944, ce=6.146472598434588
Local test acc @ epoch 15: 0.9381
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 6.407494197446795e-07
Local loss @ local epoch 1: 0.04303877055644989
Local loss @ local epoch 2: 1.4007072195454384e-06
Local loss @ local epoch 3: 1.734454053803347e-05
Local loss @ local epoch 4: 0.00033522024750709534
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.5 seconds!
[tester] 
SST2Metric: acc=0.841743119266055, hinge=1.5791021117923456, ce=4.425888201512328
Local test acc @ epoch 15: 0.8417
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 3.874300489314919e-07
Local loss @ local epoch 1: 2.9802320611338473e-08
Local loss @ local epoch 2: 2.9802320611338473e-08
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.67 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=0.9955086795561904, ce=4.21484518926078
Local test acc @ epoch 15: 0.9369
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 3.576278118089249e-07
Local loss @ local epoch 1: 1.1920926823449918e-07
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.9802320611338473e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.66 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=0.9502890323280194, ce=4.131291953795547
Local test acc @ epoch 15: 0.9404
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 8.940687052927387e-07
Local loss @ local epoch 1: 5.952226161956787
Local loss @ local epoch 2: 0.5954221487045288
Local loss @ local epoch 3: 0.5506958365440369
Local loss @ local epoch 4: 0.03193862736225128
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.56 seconds!
[tester] 
SST2Metric: acc=0.8577981651376146, hinge=0.7599683203008196, ce=10.205328722612574
Local test acc @ epoch 15: 0.8578
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 3.4272665061507723e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 7.450579886381092e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.62 seconds!
[tester] 
SST2Metric: acc=0.948394495412844, hinge=0.8595953725893563, ce=3.609289584903542
Local test acc @ epoch 15: 0.9484
Global evaluate on test data...
Evaluate data in 82.62 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=0.99933508612694, ce=5.378858542223589
Global test acc : 0.9358
Global prompt norm: 53.63458251953125
Global epoch 16...
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 2.905712563006091e-06
Local loss @ local epoch 1: 1.0430812125150624e-07
Local loss @ local epoch 2: 1.2814970204999554e-06
Local loss @ local epoch 3: 1.2307113409042358
Local loss @ local epoch 4: 1.7790961265563965
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=0.7218853847696147, ce=2.7389444670545946
Local test acc @ epoch 16: 0.9358
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0020204023458063602
Local loss @ local epoch 1: 2.7049779891967773
Local loss @ local epoch 2: 0.0394531674683094
Local loss @ local epoch 3: 0.2811131775379181
Local loss @ local epoch 4: 0.07758898288011551
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.68 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=0.338261357551321, ce=12.96248621459401
Local test acc @ epoch 16: 0.9358
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 3.0249257179093547e-06
Local loss @ local epoch 1: 5.9604641222676946e-08
Local loss @ local epoch 2: 5.36441632448259e-07
Local loss @ local epoch 3: 4.023311532819207e-07
Local loss @ local epoch 4: 1.7881389169360773e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.99 seconds!
[tester] 
SST2Metric: acc=0.9208715596330275, hinge=0.9893820963868307, ce=2.954480645853445
Local test acc @ epoch 16: 0.9209
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 3.144128868370899e-06
Local loss @ local epoch 1: 1.0430812125150624e-07
Local loss @ local epoch 2: 1.3113010481902165e-06
Local loss @ local epoch 3: 4.4703460844175424e-07
Local loss @ local epoch 4: 4.321334472479066e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.88 seconds!
[tester] 
SST2Metric: acc=0.9059633027522935, hinge=1.311954976221837, ce=3.6036118629875533
Local test acc @ epoch 16: 0.906
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 1.4901136182743357e-06
Local loss @ local epoch 1: 5.9604641222676946e-08
Local loss @ local epoch 2: 2.3841855067985307e-07
Local loss @ local epoch 3: 2.682208730675484e-07
Local loss @ local epoch 4: 1.639127589214695e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.67 seconds!
[tester] 
SST2Metric: acc=0.9139908256880734, hinge=1.1321610152174573, ce=2.5137365870519517
Local test acc @ epoch 16: 0.914
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 2.786494633255643e-06
Local loss @ local epoch 1: 3.8743007735320134e-07
Local loss @ local epoch 2: 2.0712552668555873e-06
Local loss @ local epoch 3: 0.00012269582657609135
Local loss @ local epoch 4: 0.8623608350753784
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.66 seconds!
[tester] 
SST2Metric: acc=0.9071100917431193, hinge=1.2532316768934968, ce=3.6362485229422195
Local test acc @ epoch 16: 0.9071
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 1.9371502446574596e-07
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.9415137614678899, hinge=0.9543931281894719, ce=3.3494872270374123
Local test acc @ epoch 16: 0.9415
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 4.1723222921064007e-07
Local loss @ local epoch 1: 2.9802318834981634e-08
Local loss @ local epoch 2: 2.9802318834981634e-08
Local loss @ local epoch 3: 2.9802320611338473e-08
Local loss @ local epoch 4: 4.470348002882929e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.52 seconds!
[tester] 
SST2Metric: acc=0.9311926605504587, hinge=1.0371070750262759, ce=2.973479495136016
Local test acc @ epoch 16: 0.9312
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 5.140868779562879e-06
Local loss @ local epoch 1: 1.0653880053723697e-05
Local loss @ local epoch 2: 3.5886831283569336
Local loss @ local epoch 3: 0.00018653296865522861
Local loss @ local epoch 4: 0.0014913424383848906
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.68 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=0.36385666216732165, ce=6.698029176904521
Local test acc @ epoch 16: 0.9369
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 2.2649708171229577e-06
Local loss @ local epoch 1: 4.470348002882929e-08
Local loss @ local epoch 2: 4.3213350409132545e-07
Local loss @ local epoch 3: 2.533197118737007e-07
Local loss @ local epoch 4: 1.639127589214695e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.82 seconds!
[tester] 
SST2Metric: acc=0.9357798165137615, hinge=0.7826347263581163, ce=2.63746936277512
Local test acc @ epoch 16: 0.9358
Global evaluate on test data...
Evaluate data in 82.75 seconds!
[tester] 
SST2Metric: acc=0.9518348623853211, hinge=0.6469819841034915, ce=2.641197105066492
Global test acc : 0.9518
Global prompt norm: 57.479652404785156
Global epoch 17...
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 3.8743007735320134e-07
Local loss @ local epoch 1: 2.9802320611338473e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9506880733944955, hinge=0.7807353188138489, ce=4.575250756849936
Local test acc @ epoch 17: 0.9507
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 2.682207878024201e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.9802320611338473e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9461009174311926, hinge=0.8855253233822113, ce=4.047842106687913
Local test acc @ epoch 17: 0.9461
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 2.9802313861182483e-07
Local loss @ local epoch 1: 4.470348002882929e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.61 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.9150239486213124, ce=2.7828688145777503
Local test acc @ epoch 17: 0.945
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 3.4272659377165837e-07
Local loss @ local epoch 1: 2.9802320611338473e-08
Local loss @ local epoch 2: 2.9802320611338473e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9461009174311926, hinge=0.9228761885144295, ce=2.495495752457085
Local test acc @ epoch 17: 0.9461
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 3.278254894212296e-07
Local loss @ local epoch 1: 2.9802320611338473e-08
Local loss @ local epoch 2: 4.470348002882929e-08
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=0.9043159621571182, ce=3.39885892124351
Local test acc @ epoch 17: 0.945
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 1.1920927533992653e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.69 seconds!
[tester] 
SST2Metric: acc=0.9461009174311926, hinge=0.8007168567508732, ce=4.252161787190569
Local test acc @ epoch 17: 0.9461
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 7.301563300643465e-07
Local loss @ local epoch 1: 4.470348002882929e-08
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 4.470348002882929e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.9048165137614679, hinge=1.6933429607557595, ce=2.8607804294026224
Local test acc @ epoch 17: 0.9048
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 5.662435000886035e-07
Local loss @ local epoch 1: 5.9604641222676946e-08
Local loss @ local epoch 2: 5.9604641222676946e-08
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.9243119266055045, hinge=1.3723834107775208, ce=3.868851287649312
Local test acc @ epoch 17: 0.9243
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 1.937150670983101e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.9575688073394495, hinge=0.7226420952639449, ce=2.636806022136583
Local test acc @ epoch 17: 0.9576
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 2.4586772724433104e-06
Local loss @ local epoch 1: 0.09716575592756271
Local loss @ local epoch 2: 4.766665369970724e-05
Local loss @ local epoch 3: 0.01898767799139023
Local loss @ local epoch 4: 0.007800618652254343
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9071100917431193, hinge=0.5035070761901523, ce=10.538087678611825
Local test acc @ epoch 17: 0.9071
Global evaluate on test data...
Evaluate data in 82.68 seconds!
[tester] 
SST2Metric: acc=0.9541284403669725, hinge=0.7818565467082033, ce=3.64889611454185
Global test acc : 0.9541
Global prompt norm: 58.10458755493164
Global epoch 18...
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.76 seconds!
[tester] 
SST2Metric: acc=0.9564220183486238, hinge=0.7548923459621745, ce=5.638373764283067
Local test acc @ epoch 18: 0.9564
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.66 seconds!
[tester] 
SST2Metric: acc=0.9529816513761468, hinge=0.884643332673869, ce=2.9693726334003134
Local test acc @ epoch 18: 0.953
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.67 seconds!
[tester] 
SST2Metric: acc=0.9529816513761468, hinge=0.7519972977835104, ce=8.84110882522863
Local test acc @ epoch 18: 0.953
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.72 seconds!
[tester] 
SST2Metric: acc=0.9552752293577982, hinge=0.6862931434714467, ce=8.932444126234142
Local test acc @ epoch 18: 0.9553
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.69 seconds!
[tester] 
SST2Metric: acc=0.9564220183486238, hinge=0.7521161875866968, ce=5.940028509962449
Local test acc @ epoch 18: 0.9564
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 2.9802320611338473e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.67 seconds!
[tester] 
SST2Metric: acc=0.9529816513761468, hinge=0.9187606201259368, ce=2.8678955955242893
Local test acc @ epoch 18: 0.953
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.9552752293577982, hinge=0.7590108377124192, ce=6.1087490702987814
Local test acc @ epoch 18: 0.9553
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.9529816513761468, hinge=0.8802773197856518, ce=3.1878601268890803
Local test acc @ epoch 18: 0.953
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9529816513761468, hinge=0.86416814742832, ce=3.3551109777678043
Local test acc @ epoch 18: 0.953
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9552752293577982, hinge=0.7365431575053328, ce=6.845756487015191
Local test acc @ epoch 18: 0.9553
Global evaluate on test data...
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9564220183486238, hinge=0.8069150327542506, ce=5.085043325336701
Global test acc : 0.9564
Global prompt norm: 58.13731002807617
Global epoch 19...
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.67 seconds!
[tester] 
SST2Metric: acc=0.9552752293577982, hinge=0.7697337833019572, ce=7.211091623393767
Local test acc @ epoch 19: 0.9553
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.9552752293577982, hinge=0.791434238810058, ce=6.3402097290809
Local test acc @ epoch 19: 0.9553
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.7 seconds!
[tester] 
SST2Metric: acc=0.9564220183486238, hinge=0.7623935095760801, ce=6.987126031053176
Local test acc @ epoch 19: 0.9564
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.69 seconds!
[tester] 
SST2Metric: acc=0.9552752293577982, hinge=0.7900331250024498, ce=6.9022250831674
Local test acc @ epoch 19: 0.9553
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.89 seconds!
[tester] 
SST2Metric: acc=0.9552752293577982, hinge=0.7896776128252712, ce=6.941796543401316
Local test acc @ epoch 19: 0.9553
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.76 seconds!
[tester] 
SST2Metric: acc=0.9564220183486238, hinge=0.7687603820354567, ce=6.63540736907119
Local test acc @ epoch 19: 0.9564
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.61 seconds!
[tester] 
SST2Metric: acc=0.9564220183486238, hinge=0.7511288335017108, ce=7.691629589150805
Local test acc @ epoch 19: 0.9564
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.87 seconds!
[tester] 
SST2Metric: acc=0.9552752293577982, hinge=0.7850728341198843, ce=6.862929252309537
Local test acc @ epoch 19: 0.9553
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.68 seconds!
[tester] 
SST2Metric: acc=0.9541284403669725, hinge=0.7628863574168004, ce=8.066837061435804
Local test acc @ epoch 19: 0.9541
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.68 seconds!
[tester] 
SST2Metric: acc=0.9552752293577982, hinge=0.7865391138496749, ce=7.6095975954598245
Local test acc @ epoch 19: 0.9553
Global evaluate on test data...
Evaluate data in 82.57 seconds!
[tester] 
SST2Metric: acc=0.9552752293577982, hinge=0.7798483344393039, ce=7.124818845626411
Global test acc : 0.9553
Global prompt norm: 58.15304183959961
Global epoch 20...
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.75 seconds!
[tester] 
SST2Metric: acc=0.9552752293577982, hinge=0.7099001287320338, ce=10.691939310196343
Local test acc @ epoch 20: 0.9553
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.66 seconds!
[tester] 
SST2Metric: acc=0.9552752293577982, hinge=0.7434439724738445, ce=9.567864654261038
Local test acc @ epoch 20: 0.9553
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9541284403669725, hinge=0.7506786005212627, ce=10.322832973725205
Local test acc @ epoch 20: 0.9541
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.9552752293577982, hinge=0.7437433638703932, ce=9.59235487071746
Local test acc @ epoch 20: 0.9553
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.87 seconds!
[tester] 
SST2Metric: acc=0.9552752293577982, hinge=0.7112475130536141, ce=9.991360961844068
Local test acc @ epoch 20: 0.9553
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.84 seconds!
[tester] 
SST2Metric: acc=0.9552752293577982, hinge=0.8004323495637387, ce=8.052892159978184
Local test acc @ epoch 20: 0.9553
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9564220183486238, hinge=0.8216061734278267, ce=6.757527224514463
Local test acc @ epoch 20: 0.9564
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9564220183486238, hinge=0.6983874079284318, ce=10.303744044872598
Local test acc @ epoch 20: 0.9564
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.85 seconds!
[tester] 
SST2Metric: acc=0.9552752293577982, hinge=0.7609569288175041, ce=8.968165292652374
Local test acc @ epoch 20: 0.9553
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.9552752293577982, hinge=0.7500674762857069, ce=9.23589934777776
Local test acc @ epoch 20: 0.9553
Global evaluate on test data...
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.9552752293577982, hinge=0.7588529324312823, ce=9.348273027927503
Global test acc : 0.9553
Global prompt norm: 58.16227722167969
Global epoch 21...
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.98 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.6564808591790156, ce=12.813784249331974
Local test acc @ epoch 21: 0.9599
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.9564220183486238, hinge=0.7625085372443593, ce=10.42417270765392
Local test acc @ epoch 21: 0.9564
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.81 seconds!
[tester] 
SST2Metric: acc=0.9529816513761468, hinge=0.7052469215261827, ce=12.525980511936572
Local test acc @ epoch 21: 0.953
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.69 seconds!
[tester] 
SST2Metric: acc=0.9552752293577982, hinge=0.7075631361488902, ce=12.128372393616843
Local test acc @ epoch 21: 0.9553
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.81 seconds!
[tester] 
SST2Metric: acc=0.9564220183486238, hinge=0.7073703225052684, ce=12.216118103867277
Local test acc @ epoch 21: 0.9564
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.9587155963302753, hinge=0.6986973121625568, ce=12.731694938939645
Local test acc @ epoch 21: 0.9587
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.66 seconds!
[tester] 
SST2Metric: acc=0.9552752293577982, hinge=0.802664451096036, ce=9.432555714878466
Local test acc @ epoch 21: 0.9553
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.9802320611338473e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.79 seconds!
[tester] 
SST2Metric: acc=0.9552752293577982, hinge=0.8249015676865884, ce=10.242057065351293
Local test acc @ epoch 21: 0.9553
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.88 seconds!
[tester] 
SST2Metric: acc=0.9564220183486238, hinge=0.683626264333725, ce=12.203893600253885
Local test acc @ epoch 21: 0.9564
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.62 seconds!
[tester] 
SST2Metric: acc=0.9552752293577982, hinge=0.825272681242829, ce=7.486091915620577
Local test acc @ epoch 21: 0.9553
Global evaluate on test data...
Evaluate data in 82.67 seconds!
[tester] 
SST2Metric: acc=0.9552752293577982, hinge=0.7455354395809524, ce=11.219164865826247
Global test acc : 0.9553
Global prompt norm: 58.153480529785156
Global epoch 22...
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.68 seconds!
[tester] 
SST2Metric: acc=0.9575688073394495, hinge=0.7019672098509763, ce=13.154676349884873
Local test acc @ epoch 22: 0.9576
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.81 seconds!
[tester] 
SST2Metric: acc=0.9541284403669725, hinge=0.7234520272377434, ce=13.857156867281013
Local test acc @ epoch 22: 0.9541
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9552752293577982, hinge=0.707569203792362, ce=14.164409864933118
Local test acc @ epoch 22: 0.9553
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.79 seconds!
[tester] 
SST2Metric: acc=0.9529816513761468, hinge=0.7535146277978879, ce=15.015678379513801
Local test acc @ epoch 22: 0.953
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.75 seconds!
[tester] 
SST2Metric: acc=0.9564220183486238, hinge=0.7066366404568384, ce=13.511114995413964
Local test acc @ epoch 22: 0.9564
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.81 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.6718370012187083, ce=13.598923271949138
Local test acc @ epoch 22: 0.9599
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.9552752293577982, hinge=0.7986804244168307, ce=10.32600004738624
Local test acc @ epoch 22: 0.9553
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.9575688073394495, hinge=0.7523803716405816, ce=11.815458245233659
Local test acc @ epoch 22: 0.9576
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.9541284403669725, hinge=0.7179839168119868, ce=14.038588305132105
Local test acc @ epoch 22: 0.9541
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.95 seconds!
[tester] 
SST2Metric: acc=0.9552752293577982, hinge=0.7799934050358763, ce=12.806643206045168
Local test acc @ epoch 22: 0.9553
Global evaluate on test data...
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.9575688073394495, hinge=0.7295620364880343, ce=13.25600957433018
Global test acc : 0.9576
Global prompt norm: 58.14031982421875
Global epoch 23...
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.9529816513761468, hinge=0.7138100862503052, ce=15.46865364389682
Local test acc @ epoch 23: 0.953
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.944954128440367, hinge=1.0551069947557712, ce=9.650735093912948
Local test acc @ epoch 23: 0.945
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.62 seconds!
[tester] 
SST2Metric: acc=0.9564220183486238, hinge=0.7139527764889079, ce=14.384172010859219
Local test acc @ epoch 23: 0.9564
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.47 seconds!
[tester] 
SST2Metric: acc=0.9552752293577982, hinge=0.8013071505301589, ce=13.496702281706924
Local test acc @ epoch 23: 0.9553
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.67 seconds!
[tester] 
SST2Metric: acc=0.9587155963302753, hinge=0.7330846677132703, ce=14.014722727854318
Local test acc @ epoch 23: 0.9587
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.61 seconds!
[tester] 
SST2Metric: acc=0.9518348623853211, hinge=0.7423242981280755, ce=16.085277364888324
Local test acc @ epoch 23: 0.9518
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.79 seconds!
[tester] 
SST2Metric: acc=0.9575688073394495, hinge=0.7762234670306565, ce=12.28233025052132
Local test acc @ epoch 23: 0.9576
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.86 seconds!
[tester] 
SST2Metric: acc=0.9552752293577982, hinge=0.7115683746994088, ce=16.03235720713204
Local test acc @ epoch 23: 0.9553
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.92 seconds!
[tester] 
SST2Metric: acc=0.9506880733944955, hinge=0.7780167389353481, ce=16.9844441545119
Local test acc @ epoch 23: 0.9507
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.9529816513761468, hinge=0.7457825175119103, ce=15.495689593323874
Local test acc @ epoch 23: 0.953
Global evaluate on test data...
Evaluate data in 82.57 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7239913202207023, ce=14.335969487461474
Global test acc : 0.9599
Global prompt norm: 58.11738204956055
Global epoch 24...
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9552752293577982, hinge=0.7360233145022611, ce=17.43915738971955
Local test acc @ epoch 24: 0.9553
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.63 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.6856127507096037, ce=16.479839482438674
Local test acc @ epoch 24: 0.9599
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.76 seconds!
[tester] 
SST2Metric: acc=0.9587155963302753, hinge=0.7009713791925972, ce=16.649590002287418
Local test acc @ epoch 24: 0.9587
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.9564220183486238, hinge=0.6972488449254167, ce=16.354817329196756
Local test acc @ epoch 24: 0.9564
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.72 seconds!
[tester] 
SST2Metric: acc=0.9587155963302753, hinge=0.69364880859305, ce=16.98607434264017
Local test acc @ epoch 24: 0.9587
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.96 seconds!
[tester] 
SST2Metric: acc=0.9575688073394495, hinge=0.6902407927250643, ce=16.518213438331536
Local test acc @ epoch 24: 0.9576
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.76 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7295781636456831, ce=15.77561859690815
Local test acc @ epoch 24: 0.9599
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9518348623853211, hinge=0.7280242016556067, ce=17.05913384463809
Local test acc @ epoch 24: 0.9518
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.68 seconds!
[tester] 
SST2Metric: acc=0.9564220183486238, hinge=0.709243618020224, ce=16.635288815979564
Local test acc @ epoch 24: 0.9564
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.7 seconds!
[tester] 
SST2Metric: acc=0.9564220183486238, hinge=0.7199374169384668, ce=16.344967089661765
Local test acc @ epoch 24: 0.9564
Global evaluate on test data...
Evaluate data in 82.94 seconds!
[tester] 
SST2Metric: acc=0.9587155963302753, hinge=0.704921440247002, ce=16.670831006601315
Global test acc : 0.9587
Global prompt norm: 58.10466766357422
Global epoch 25...
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.05 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.0446924873448293, ce=12.031472643581006
Local test acc @ epoch 25: 0.9438
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.67 seconds!
[tester] 
SST2Metric: acc=0.9587155963302753, hinge=0.7497292691414509, ce=16.314678104645616
Local test acc @ epoch 25: 0.9587
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.56 seconds!
[tester] 
SST2Metric: acc=0.9575688073394495, hinge=0.792694337324265, ce=14.294377221973663
Local test acc @ epoch 25: 0.9576
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.7 seconds!
[tester] 
SST2Metric: acc=0.9529816513761468, hinge=0.7311340767309207, ce=18.894648035731883
Local test acc @ epoch 25: 0.953
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.67 seconds!
[tester] 
SST2Metric: acc=0.9529816513761468, hinge=0.786456262299774, ce=19.10845922767569
Local test acc @ epoch 25: 0.953
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.9564220183486238, hinge=0.69621989705147, ce=19.047932668563423
Local test acc @ epoch 25: 0.9564
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.68 seconds!
[tester] 
SST2Metric: acc=0.9587155963302753, hinge=0.7315042204813126, ce=16.36265664581859
Local test acc @ epoch 25: 0.9587
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.84 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7027343456898261, ce=18.76473174838845
Local test acc @ epoch 25: 0.9599
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.81 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7528873255493445, ce=16.111088743997275
Local test acc @ epoch 25: 0.9599
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.9802320611338473e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.79 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7664671851954329, ce=14.467986614332286
Local test acc @ epoch 25: 0.961
Global evaluate on test data...
Evaluate data in 82.79 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7435713623641828, ce=16.49640174305767
Global test acc : 0.9599
Global prompt norm: 58.09103775024414
Global epoch 26...
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.6 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7104324178958158, ce=18.530031099231966
Local test acc @ epoch 26: 0.9599
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.700430466494429, ce=19.14959370324371
Local test acc @ epoch 26: 0.9599
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.81 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7161816599172189, ce=18.876794237609303
Local test acc @ epoch 26: 0.9599
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.93 seconds!
[tester] 
SST2Metric: acc=0.9587155963302753, hinge=0.7114802227107757, ce=18.434469695484967
Local test acc @ epoch 26: 0.9587
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.93 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.6998057638833283, ce=19.13544182383686
Local test acc @ epoch 26: 0.9599
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.69 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7077229744797453, ce=18.653309480859598
Local test acc @ epoch 26: 0.9599
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.7 seconds!
[tester] 
SST2Metric: acc=0.9587155963302753, hinge=0.6887701640435315, ce=19.097787717066772
Local test acc @ epoch 26: 0.9587
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.59 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.714496400378166, ce=18.616542396195438
Local test acc @ epoch 26: 0.9599
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.67 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.6890778825917375, ce=19.550285916809642
Local test acc @ epoch 26: 0.9599
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.69 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7074412019974595, ce=19.418577911656932
Local test acc @ epoch 26: 0.9599
Global evaluate on test data...
Evaluate data in 82.9 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7063378314359472, ce=18.972635776624767
Global test acc : 0.9599
Global prompt norm: 58.089656829833984
Global epoch 27...
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.75 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.6692507934132848, ce=21.6578311920166
Local test acc @ epoch 27: 0.9599
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.76 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7296391025595709, ce=19.975909591814794
Local test acc @ epoch 27: 0.9599
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.87 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7616096549077865, ce=17.5950540927572
Local test acc @ epoch 27: 0.9599
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.86 seconds!
[tester] 
SST2Metric: acc=0.9575688073394495, hinge=0.6809923900376766, ce=21.472603001725783
Local test acc @ epoch 27: 0.9576
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.82 seconds!
[tester] 
SST2Metric: acc=0.9541284403669725, hinge=0.7314185844648868, ce=21.914840278275516
Local test acc @ epoch 27: 0.9541
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.9802320611338473e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9575688073394495, hinge=0.7024370574076241, ce=20.733683139906017
Local test acc @ epoch 27: 0.9576
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 5.9604641222676946e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7348374434567373, ce=18.185737714854948
Local test acc @ epoch 27: 0.961
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.82 seconds!
[tester] 
SST2Metric: acc=0.9518348623853211, hinge=0.7237730244977758, ce=21.85633631365015
Local test acc @ epoch 27: 0.9518
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.82 seconds!
[tester] 
SST2Metric: acc=0.9552752293577982, hinge=0.6836755035120413, ce=21.78073646825388
Local test acc @ epoch 27: 0.9553
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.75 seconds!
[tester] 
SST2Metric: acc=0.9587155963302753, hinge=0.6791365595038877, ce=21.534592357250528
Local test acc @ epoch 27: 0.9587
Global evaluate on test data...
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7100746773798531, ce=20.778211261154315
Global test acc : 0.9599
Global prompt norm: 58.0819091796875
Global epoch 28...
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9575688073394495, hinge=0.6919858215052054, ce=23.304669126458123
Local test acc @ epoch 28: 0.9576
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.79 seconds!
[tester] 
SST2Metric: acc=0.9587155963302753, hinge=0.7163824466390347, ce=21.933033916928352
Local test acc @ epoch 28: 0.9587
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.734190519796599, ce=20.46116065979004
Local test acc @ epoch 28: 0.9599
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.9587155963302753, hinge=0.7523856534870392, ce=21.83144935117949
Local test acc @ epoch 28: 0.9587
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.9802320611338473e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9541284403669725, hinge=0.7370034007851137, ce=23.0366760218909
Local test acc @ epoch 28: 0.9541
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.68 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.6998775858397878, ce=22.654652201801266
Local test acc @ epoch 28: 0.9599
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450579886381092e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.69 seconds!
[tester] 
SST2Metric: acc=0.9575688073394495, hinge=0.8289398594733772, ce=12.51517016734552
Local test acc @ epoch 28: 0.9576
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.85 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7270344156737721, ce=20.194802520471974
Local test acc @ epoch 28: 0.9599
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.9802320611338473e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.76 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7743653201181954, ce=17.486015206083245
Local test acc @ epoch 28: 0.961
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.6689835272797751, ce=23.032727827719594
Local test acc @ epoch 28: 0.9599
Global evaluate on test data...
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9587155963302753, hinge=0.7499230629807219, ce=20.442202034346554
Global test acc : 0.9587
Global prompt norm: 58.09699249267578
Global epoch 29...
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.79 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.6924939593043896, ce=23.6344891469413
Local test acc @ epoch 29: 0.9599
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9587155963302753, hinge=0.7048306246416285, ce=22.93515592102611
Local test acc @ epoch 29: 0.9587
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.59 seconds!
[tester] 
SST2Metric: acc=0.9587155963302753, hinge=0.7098316544786506, ce=23.61695165371676
Local test acc @ epoch 29: 0.9587
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.98 seconds!
[tester] 
SST2Metric: acc=0.9587155963302753, hinge=0.7162545000741242, ce=22.692962156523258
Local test acc @ epoch 29: 0.9587
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.6780562838283154, ce=24.08122605140056
Local test acc @ epoch 29: 0.9599
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.63 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.6846516963538773, ce=23.84649873436044
Local test acc @ epoch 29: 0.9599
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.52 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.708151466255888, ce=22.889365467456503
Local test acc @ epoch 29: 0.9599
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.67 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.6900322010757727, ce=23.798932346728964
Local test acc @ epoch 29: 0.9599
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.76 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7123812819839618, ce=22.971002981203412
Local test acc @ epoch 29: 0.9599
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7017216737117242, ce=23.998856273266153
Local test acc @ epoch 29: 0.9599
Global evaluate on test data...
Evaluate data in 82.72 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7012932759906174, ce=23.48587415852678
Global test acc : 0.9599
Global prompt norm: 58.08322525024414
Global epoch 30...
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.68 seconds!
[tester] 
SST2Metric: acc=0.9575688073394495, hinge=0.6770512696799882, ce=25.99950837651524
Local test acc @ epoch 30: 0.9576
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.56 seconds!
[tester] 
SST2Metric: acc=0.9587155963302753, hinge=0.7319124871437702, ce=23.35734551106024
Local test acc @ epoch 30: 0.9587
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.64 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6874367818919891, ce=24.246427151041292
Local test acc @ epoch 30: 0.961
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.59 seconds!
[tester] 
SST2Metric: acc=0.9587155963302753, hinge=0.6995500030867551, ce=24.045860745491236
Local test acc @ epoch 30: 0.9587
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7236407601505245, ce=25.83387674104183
Local test acc @ epoch 30: 0.9599
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.76 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.6704576474810959, ce=26.063430103686972
Local test acc @ epoch 30: 0.9599
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.73 seconds!
[tester] 
SST2Metric: acc=0.9587155963302753, hinge=0.7054068495374207, ce=24.730583523391584
Local test acc @ epoch 30: 0.9587
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.7 seconds!
[tester] 
SST2Metric: acc=0.9529816513761468, hinge=0.7093804079458255, ce=26.251232147216797
Local test acc @ epoch 30: 0.953
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 5.9604641222676946e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.68 seconds!
[tester] 
SST2Metric: acc=0.9644495412844036, hinge=0.7384747146466456, ce=19.148720487542107
Local test acc @ epoch 30: 0.9644
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.67 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7413419397599107, ce=22.677922397578527
Local test acc @ epoch 30: 0.9599
Global evaluate on test data...
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9587155963302753, hinge=0.7195993913423031, ce=24.360683021195438
Global test acc : 0.9587
Global prompt norm: 58.07195281982422
Global epoch 31...
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.9802320611338473e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9587155963302753, hinge=0.6897365259468009, ce=26.705571830819505
Local test acc @ epoch 31: 0.9587
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.91 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6832732377795998, ce=25.329516559565832
Local test acc @ epoch 31: 0.961
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 5.960463766996327e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.66 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.7119800596062197, ce=23.36738007221747
Local test acc @ epoch 31: 0.9633
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.66 seconds!
[tester] 
SST2Metric: acc=0.9587155963302753, hinge=0.6934794176609145, ce=28.51053797870601
Local test acc @ epoch 31: 0.9587
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.9802320611338473e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.84 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7472063981064963, ce=23.056312386049044
Local test acc @ epoch 31: 0.9599
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.55 seconds!
[tester] 
SST2Metric: acc=0.9575688073394495, hinge=0.6519282542237448, ce=27.54549133230787
Local test acc @ epoch 31: 0.9576
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.6588948626037038, ce=27.65311328642959
Local test acc @ epoch 31: 0.9599
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.66 seconds!
[tester] 
SST2Metric: acc=0.9587155963302753, hinge=0.6860619160013461, ce=27.13145782750681
Local test acc @ epoch 31: 0.9587
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.6677438578474413, ce=27.142026918743728
Local test acc @ epoch 31: 0.9599
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.66 seconds!
[tester] 
SST2Metric: acc=0.9552752293577982, hinge=0.6613644416179132, ce=28.129025590529135
Local test acc @ epoch 31: 0.9553
Global evaluate on test data...
Evaluate data in 82.63 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.6923684067682389, ce=26.639331117682502
Global test acc : 0.9599
Global prompt norm: 58.044349670410156
Global epoch 32...
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450579886381092e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.63 seconds!
[tester] 
SST2Metric: acc=0.9541284403669725, hinge=0.8558475839982339, ce=16.873297866331328
Local test acc @ epoch 32: 0.9541
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.69 seconds!
[tester] 
SST2Metric: acc=0.9552752293577982, hinge=0.6679022574643476, ce=30.31972137941133
Local test acc @ epoch 32: 0.9553
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.73 seconds!
[tester] 
SST2Metric: acc=0.9587155963302753, hinge=0.682466566015821, ce=28.302497653786194
Local test acc @ epoch 32: 0.9587
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.9802320611338473e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.89 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.6978741129603955, ce=27.395696500025757
Local test acc @ epoch 32: 0.9599
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.9802320611338473e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.69 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7307132843437545, ce=26.579593868430603
Local test acc @ epoch 32: 0.9599
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 4.470348002882929e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.63 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.7350263595581055, ce=23.17415692390652
Local test acc @ epoch 32: 0.9633
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.84 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6781661029255718, ce=27.776877167028026
Local test acc @ epoch 32: 0.961
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.59 seconds!
[tester] 
SST2Metric: acc=0.9587155963302753, hinge=0.6597055076459132, ce=28.2751963029214
Local test acc @ epoch 32: 0.9587
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.64 seconds!
[tester] 
SST2Metric: acc=0.9587155963302753, hinge=0.6918652998198063, ce=30.05377277759237
Local test acc @ epoch 32: 0.9587
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.64 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6483793039934351, ce=29.3507324533725
Local test acc @ epoch 32: 0.961
Global evaluate on test data...
Evaluate data in 82.76 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7120206115442679, ce=26.61014198163234
Global test acc : 0.961
Global prompt norm: 58.022613525390625
Global epoch 33...
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.9802320611338473e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.67 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6651805868936241, ce=29.905635361277728
Local test acc @ epoch 33: 0.961
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.75 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.6609239293894636, ce=29.68421530067374
Local test acc @ epoch 33: 0.9599
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.67 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.6338558918839201, ce=31.01008044251608
Local test acc @ epoch 33: 0.9599
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.64 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.664630714906465, ce=29.684530958123162
Local test acc @ epoch 33: 0.9599
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.6296820290591738, ce=31.197775342048853
Local test acc @ epoch 33: 0.9599
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6787530063489161, ce=28.91808116107906
Local test acc @ epoch 33: 0.961
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.54 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6496084108265168, ce=31.32977804131464
Local test acc @ epoch 33: 0.961
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.9587155963302753, hinge=0.6715684374538037, ce=29.591904876429005
Local test acc @ epoch 33: 0.9587
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9587155963302753, hinge=0.6639715269071247, ce=29.945756929730056
Local test acc @ epoch 33: 0.9587
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.6434249834183159, ce=30.73221516390459
Local test acc @ epoch 33: 0.9622
Global evaluate on test data...
Evaluate data in 82.75 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.6573411696547762, ce=30.266955174437356
Global test acc : 0.9599
Global prompt norm: 57.98625183105469
Global epoch 34...
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.9802320611338473e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9587155963302753, hinge=0.7722948713040133, ce=25.443301734574344
Local test acc @ epoch 34: 0.9587
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7014107572923013, ce=29.876169099720247
Local test acc @ epoch 34: 0.961
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.73 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6732859217792476, ce=31.085201893377743
Local test acc @ epoch 34: 0.961
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.9802320611338473e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.62 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6715010021804669, ce=31.403189860352683
Local test acc @ epoch 34: 0.961
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.62 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7105927182993758, ce=28.862782137109598
Local test acc @ epoch 34: 0.961
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.9802320611338473e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.725577363180458, ce=27.46791610367801
Local test acc @ epoch 34: 0.9599
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.81 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6647047690295298, ce=31.30322050392081
Local test acc @ epoch 34: 0.961
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9529816513761468, hinge=0.8304476191144471, ce=26.817821747666105
Local test acc @ epoch 34: 0.953
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.9802320611338473e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.46 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7583440859383399, ce=24.40047771558849
Local test acc @ epoch 34: 0.961
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.79 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.6493657532088254, ce=31.033161163330078
Local test acc @ epoch 34: 0.9599
Global evaluate on test data...
Evaluate data in 82.59 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7187112449506007, ce=29.073096686546954
Global test acc : 0.9599
Global prompt norm: 57.961212158203125
Global epoch 35...
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.69 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.687997452709653, ce=30.718457965675842
Local test acc @ epoch 35: 0.961
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.66 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6493755283705686, ce=33.16189832424899
Local test acc @ epoch 35: 0.961
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.73 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.6345419336896424, ce=33.201296692594475
Local test acc @ epoch 35: 0.9599
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.79 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6420882491890444, ce=32.82815049547668
Local test acc @ epoch 35: 0.961
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.62 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6491450716596131, ce=32.64999755369414
Local test acc @ epoch 35: 0.961
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.6473385194026002, ce=32.69504750103032
Local test acc @ epoch 35: 0.9622
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.7 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6690139201802945, ce=31.521418055263133
Local test acc @ epoch 35: 0.961
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.75 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6371838762125838, ce=33.0664774168522
Local test acc @ epoch 35: 0.961
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.6622225888278506, ce=31.85026044583102
Local test acc @ epoch 35: 0.9599
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.676248438861392, ce=31.539902083370663
Local test acc @ epoch 35: 0.961
Global evaluate on test data...
Evaluate data in 82.82 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.6563431801052269, ce=32.398154442463444
Global test acc : 0.9599
Global prompt norm: 57.92778778076172
Global epoch 36...
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.9575688073394495, hinge=0.6350810046589702, ce=35.204648394103444
Local test acc @ epoch 36: 0.9576
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.67 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.7082104070470967, ce=30.957664209768314
Local test acc @ epoch 36: 0.9622
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.81 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.6349787996449602, ce=33.42871872438203
Local test acc @ epoch 36: 0.9622
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.76 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.7753574170103861, ce=26.682293130717145
Local test acc @ epoch 36: 0.9622
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.9802320611338473e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.62 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.6421363003757021, ce=34.417676610684175
Local test acc @ epoch 36: 0.9599
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.9802320611338473e-08
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.7 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.7561686717042135, ce=25.992536964766476
Local test acc @ epoch 36: 0.9633
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.66 seconds!
[tester] 
SST2Metric: acc=0.9587155963302753, hinge=0.6627609817259902, ce=34.62770602025023
Local test acc @ epoch 36: 0.9587
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.85 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7235044908086095, ce=29.504764031926427
Local test acc @ epoch 36: 0.961
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.9802320611338473e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.68 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6984028728730088, ce=30.440043668134496
Local test acc @ epoch 36: 0.961
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.76 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7298491722946867, ce=30.534663681590228
Local test acc @ epoch 36: 0.9599
Global evaluate on test data...
Evaluate data in 82.76 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7116562160876913, ce=31.45538333577847
Global test acc : 0.9599
Global prompt norm: 57.901554107666016
Global epoch 37...
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.72 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6478073050122742, ce=34.17539766294147
Local test acc @ epoch 37: 0.961
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.68 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.630731632950109, ce=35.863357018986974
Local test acc @ epoch 37: 0.9599
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.68 seconds!
[tester] 
SST2Metric: acc=0.9587155963302753, hinge=0.6259491618620147, ce=35.59235907038418
Local test acc @ epoch 37: 0.9587
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.6488388240884203, ce=34.190556604927835
Local test acc @ epoch 37: 0.9622
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.81 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6387052032925667, ce=35.66608754429249
Local test acc @ epoch 37: 0.961
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.68 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.6570128978939231, ce=34.96267848933508
Local test acc @ epoch 37: 0.9599
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6716375985276808, ce=33.097828191354736
Local test acc @ epoch 37: 0.961
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.53 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6390448425887921, ce=34.76101885804343
Local test acc @ epoch 37: 0.961
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.63 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6439039072859178, ce=35.09818388562684
Local test acc @ epoch 37: 0.961
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.81 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6539994904754358, ce=34.275303096946224
Local test acc @ epoch 37: 0.961
Global evaluate on test data...
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6439690808637426, ce=34.8757769733394
Global test acc : 0.961
Global prompt norm: 57.864112854003906
Global epoch 38...
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.73 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.7134995219904349, ce=32.98968568854376
Local test acc @ epoch 38: 0.9622
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.9802318834981634e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7276219227992067, ce=32.73855160354474
Local test acc @ epoch 38: 0.961
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.6 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7124316517366182, ce=33.82658564716304
Local test acc @ epoch 38: 0.9599
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.61 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.7047897413236286, ce=32.92950588191321
Local test acc @ epoch 38: 0.9633
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.6905914599742364, ce=33.562015235970875
Local test acc @ epoch 38: 0.9599
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.85 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6969323289503745, ce=32.52449515106481
Local test acc @ epoch 38: 0.961
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.91 seconds!
[tester] 
SST2Metric: acc=0.9644495412844036, hinge=0.6246035492748295, ce=36.09727082558728
Local test acc @ epoch 38: 0.9644
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7780885215199321, ce=29.268303022472136
Local test acc @ epoch 38: 0.961
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.84 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7269312613600984, ce=31.34579978732888
Local test acc @ epoch 38: 0.961
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.56 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.6373502923807967, ce=36.43360141439175
Local test acc @ epoch 38: 0.9599
Global evaluate on test data...
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.718685745099269, ce=33.47352232626819
Global test acc : 0.9599
Global prompt norm: 57.83769989013672
Global epoch 39...
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.6452605330615963, ce=36.46801022870825
Local test acc @ epoch 39: 0.9622
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.73 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.6332168666594619, ce=36.972380821857975
Local test acc @ epoch 39: 0.9622
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.81 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6744859437330053, ce=34.908342658926586
Local test acc @ epoch 39: 0.961
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.647734924193916, ce=36.04176622793215
Local test acc @ epoch 39: 0.9633
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.69 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6399153263197033, ce=37.75135722729044
Local test acc @ epoch 39: 0.961
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.82 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.6265493532933226, ce=37.62741669821083
Local test acc @ epoch 39: 0.9599
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.91 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.6298462491516673, ce=37.01595981842881
Local test acc @ epoch 39: 0.9633
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.6521655638283546, ce=36.10177024351348
Local test acc @ epoch 39: 0.9633
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.7 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.6350402132086798, ce=38.453104071660874
Local test acc @ epoch 39: 0.9599
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.9802320611338473e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.86 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.6495377908059217, ce=36.08603458229555
Local test acc @ epoch 39: 0.9633
Global evaluate on test data...
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6395115655496579, ce=36.89393318246264
Global test acc : 0.961
Global prompt norm: 57.805267333984375
Global epoch 40...
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.7 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7358989562463323, ce=33.461347947426894
Local test acc @ epoch 40: 0.961
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.72 seconds!
[tester] 
SST2Metric: acc=0.9529816513761468, hinge=0.9640060630413371, ce=26.664566897471015
Local test acc @ epoch 40: 0.953
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.72 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.68240905682975, ce=36.739087481017506
Local test acc @ epoch 40: 0.961
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.96 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.6632597140215952, ce=37.650439621111666
Local test acc @ epoch 40: 0.9622
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9564220183486238, hinge=0.6536333451577283, ce=39.52894501292378
Local test acc @ epoch 40: 0.9564
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450579886381092e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.97 seconds!
[tester] 
SST2Metric: acc=0.9162844036697247, hinge=1.524553878591695, ce=18.791995302252815
Local test acc @ epoch 40: 0.9163
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.75 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.6311141788412672, ce=38.202240760173275
Local test acc @ epoch 40: 0.9599
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7417735965973741, ce=34.33435380568198
Local test acc @ epoch 40: 0.961
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.9802320611338473e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.68 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7160031948614558, ce=32.62205505371094
Local test acc @ epoch 40: 0.961
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 4.470348002882929e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.89 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.6587640320489166, ce=36.89179919181614
Local test acc @ epoch 40: 0.9622
Global evaluate on test data...
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.7453547289612097, ce=33.09404098440748
Global test acc : 0.9622
Global prompt norm: 57.811466217041016
Global epoch 41...
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.79 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.693104719896929, ce=36.72338615207497
Local test acc @ epoch 41: 0.9599
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.73 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7170644747007877, ce=36.03844129929849
Local test acc @ epoch 41: 0.9599
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.7 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7244640096611933, ce=35.67006259883215
Local test acc @ epoch 41: 0.9599
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.75 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7199793933728419, ce=36.248138427734375
Local test acc @ epoch 41: 0.9599
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7236718059679784, ce=35.89940471824156
Local test acc @ epoch 41: 0.9599
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.62 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7415527181887845, ce=34.63948216569533
Local test acc @ epoch 41: 0.961
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.76 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7186758474472466, ce=35.95804018493092
Local test acc @ epoch 41: 0.9599
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7361555646318908, ce=34.98886456620802
Local test acc @ epoch 41: 0.9599
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.69 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.7413400728768165, ce=34.13528186903088
Local test acc @ epoch 41: 0.9622
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.84 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7370185742684461, ce=34.89892870351809
Local test acc @ epoch 41: 0.961
Global evaluate on test data...
Evaluate data in 82.87 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7294927999513958, ce=35.59513695743106
Global test acc : 0.9599
Global prompt norm: 57.79389953613281
Global epoch 42...
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.62 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.6949284098563938, ce=37.25842222161249
Local test acc @ epoch 42: 0.9599
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.87 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.687041221408669, ce=37.102442610154455
Local test acc @ epoch 42: 0.9599
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.94 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6690570651938063, ce=37.5828291166813
Local test acc @ epoch 42: 0.961
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.6505347719979943, ce=38.020189232782485
Local test acc @ epoch 42: 0.9633
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.7 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.6873728244676502, ce=37.36745088909744
Local test acc @ epoch 42: 0.9599
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.7 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.6802736859802806, ce=37.40677901801713
Local test acc @ epoch 42: 0.9599
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.61 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7070246923954115, ce=36.61679794591501
Local test acc @ epoch 42: 0.9599
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.66 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.6841129687947964, ce=37.59972962545692
Local test acc @ epoch 42: 0.9599
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6751553049874962, ce=37.88508441470085
Local test acc @ epoch 42: 0.961
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.62 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7009671237490592, ce=36.82493073349699
Local test acc @ epoch 42: 0.9599
Global evaluate on test data...
Evaluate data in 82.76 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.6848477507949969, ce=37.41320657292637
Global test acc : 0.9599
Global prompt norm: 57.77669906616211
Global epoch 43...
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.72 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.6280563118260934, ce=40.22064562456323
Local test acc @ epoch 43: 0.9599
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.93 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6279095137884857, ce=39.647339112168055
Local test acc @ epoch 43: 0.961
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.87 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6162131248264138, ce=40.574722360033505
Local test acc @ epoch 43: 0.961
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9575688073394495, hinge=0.6174926079741312, ce=41.28037202467612
Local test acc @ epoch 43: 0.9576
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.66 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6510353022759113, ce=38.87137750748101
Local test acc @ epoch 43: 0.961
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.6366905750484642, ce=39.257127674347764
Local test acc @ epoch 43: 0.9633
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.6256968318869215, ce=40.78795105820402
Local test acc @ epoch 43: 0.9599
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.75 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.645668403817973, ce=39.33871004997044
Local test acc @ epoch 43: 0.961
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.9802320611338473e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.7 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.6756525739617304, ce=38.47686347611454
Local test acc @ epoch 43: 0.9599
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.56 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.6441836510229548, ce=38.68349547779888
Local test acc @ epoch 43: 0.9622
Global evaluate on test data...
Evaluate data in 82.96 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.6279433145435578, ce=39.8617333228435
Global test acc : 0.9622
Global prompt norm: 57.74589538574219
Global epoch 44...
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.76 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.7314235114176338, ce=35.09491908222164
Local test acc @ epoch 44: 0.9622
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.63 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7456956303447758, ce=35.348835813889806
Local test acc @ epoch 44: 0.961
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.9802320611338473e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7680414029217641, ce=29.267543617738497
Local test acc @ epoch 44: 0.961
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 5.9604641222676946e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.7 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.123351591442703, ce=21.21663497784816
Local test acc @ epoch 44: 0.9438
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.63 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.669758556085989, ce=38.87701790485907
Local test acc @ epoch 44: 0.961
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.9802320611338473e-08
Local loss @ local epoch 2: 2.9802288281643996e-07
Local loss @ local epoch 3: 6.832517623901367
Local loss @ local epoch 4: 0.2979397177696228
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.56 seconds!
[tester] 
SST2Metric: acc=0.9243119266055045, hinge=0.4360415940984673, ce=11.182179809710302
Local test acc @ epoch 44: 0.9243
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 4.470348002882929e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7393433107148617, ce=35.242578401478056
Local test acc @ epoch 44: 0.9599
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.9802320611338473e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.81 seconds!
[tester] 
SST2Metric: acc=0.9529816513761468, hinge=0.93985566305458, ce=29.608622594710884
Local test acc @ epoch 44: 0.953
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.9802320611338473e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.85 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.7531580771874944, ce=34.82874700563763
Local test acc @ epoch 44: 0.9633
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.69 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.7133079887530126, ce=37.26601651392946
Local test acc @ epoch 44: 0.9622
Global evaluate on test data...
Evaluate data in 82.56 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.7417548708959457, ce=29.08708490144222
Global test acc : 0.9622
Global prompt norm: 58.052738189697266
Global epoch 45...
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.6 seconds!
[tester] 
SST2Metric: acc=0.9518348623853211, hinge=0.9535470730667814, ce=26.631664678591108
Local test acc @ epoch 45: 0.9518
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.0430811414607888e-07
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.9802320611338473e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.69 seconds!
[tester] 
SST2Metric: acc=0.9506880733944955, hinge=0.9904556017403209, ce=17.639575853260286
Local test acc @ epoch 45: 0.9507
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.76 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.7507733817494243, ce=35.47329081964055
Local test acc @ epoch 45: 0.9633
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.86 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6570181955984973, ce=39.659828081043486
Local test acc @ epoch 45: 0.961
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 4.470347647611561e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.94 seconds!
[tester] 
SST2Metric: acc=0.948394495412844, hinge=0.8037075646426699, ce=20.836510946991247
Local test acc @ epoch 45: 0.9484
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.63 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.6210589277634927, ce=32.82999465662405
Local test acc @ epoch 45: 0.9622
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 2.9802320611338473e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.7 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7403554511726449, ce=21.162432539353677
Local test acc @ epoch 45: 0.9599
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.57 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6942451043960152, ce=38.748019717155245
Local test acc @ epoch 45: 0.961
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.64 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.5976652727214569, ce=40.48100896712837
Local test acc @ epoch 45: 0.9622
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.7881390590446244e-07
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.9802320611338473e-08
Local loss @ local epoch 4: 4.470348002882929e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.63 seconds!
[tester] 
SST2Metric: acc=0.9461009174311926, hinge=0.8671668341400427, ce=13.864506913981307
Local test acc @ epoch 45: 0.9461
Global evaluate on test data...
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.7628255196667593, ce=27.13704180936201
Global test acc : 0.9622
Global prompt norm: 58.12318801879883
Global epoch 46...
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.84 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.7798778376448046, ce=32.29045125978802
Local test acc @ epoch 46: 0.9622
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.759295369506976, ce=33.31638913635814
Local test acc @ epoch 46: 0.961
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7580130581462056, ce=34.03757571299142
Local test acc @ epoch 46: 0.961
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.81 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7245857278141407, ce=37.144168083820865
Local test acc @ epoch 46: 0.961
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.68 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7700198177897603, ce=33.66820846347634
Local test acc @ epoch 46: 0.961
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.75 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.7767597666574181, ce=28.56320717137888
Local test acc @ epoch 46: 0.9622
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.7820215728304801, ce=29.36465994808652
Local test acc @ epoch 46: 0.9622
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7726028468630729, ce=33.16670176304808
Local test acc @ epoch 46: 0.961
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.7779596748702023, ce=32.297354811922126
Local test acc @ epoch 46: 0.9622
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.72 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.7729623405211562, ce=32.87102330059086
Local test acc @ epoch 46: 0.9622
Global evaluate on test data...
Evaluate data in 82.68 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.7733444467597052, ce=32.963528326891975
Global test acc : 0.9622
Global prompt norm: 58.10166549682617
Global epoch 47...
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.6 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7444609698899295, ce=36.22103888835382
Local test acc @ epoch 47: 0.9599
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.63 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7657462063185666, ce=33.7567808693702
Local test acc @ epoch 47: 0.961
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.86 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7372255937768779, ce=36.09614615484115
Local test acc @ epoch 47: 0.9599
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7489713725693729, ce=35.29360832424339
Local test acc @ epoch 47: 0.961
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.79 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7440052141837024, ce=35.589560237499555
Local test acc @ epoch 47: 0.961
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.75 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7507899879315577, ce=35.87884717468822
Local test acc @ epoch 47: 0.9599
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.63 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.6931771160265722, ce=39.3890012688593
Local test acc @ epoch 47: 0.9599
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.81 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7310737054282372, ce=37.23990883083518
Local test acc @ epoch 47: 0.961
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.63 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7284357263407576, ce=37.02079513969771
Local test acc @ epoch 47: 0.961
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7641819245224699, ce=34.02592013297825
Local test acc @ epoch 47: 0.961
Global evaluate on test data...
Evaluate data in 82.85 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.745205647354826, ce=36.169275441300975
Global test acc : 0.9599
Global prompt norm: 58.06349563598633
Global epoch 48...
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.73 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7325200312728182, ce=36.996144285989466
Local test acc @ epoch 48: 0.961
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.68 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.7058935559124028, ce=38.55585168261047
Local test acc @ epoch 48: 0.9622
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.52 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6863236164827959, ce=39.65254141431336
Local test acc @ epoch 48: 0.961
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.6778386557867767, ce=40.366141328024206
Local test acc @ epoch 48: 0.9599
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.84 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.7156461969428106, ce=38.15746888326942
Local test acc @ epoch 48: 0.9622
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.76 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7141547509289663, ce=38.861621996678345
Local test acc @ epoch 48: 0.9599
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.73 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.675443806779494, ce=40.70736228872877
Local test acc @ epoch 48: 0.9599
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.6 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6915727427246374, ce=38.793281870150786
Local test acc @ epoch 48: 0.961
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.88 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.736783161075837, ce=37.27302852245646
Local test acc @ epoch 48: 0.961
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.6423633754800219, ce=42.205929362445794
Local test acc @ epoch 48: 0.9599
Global evaluate on test data...
Evaluate data in 82.61 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7004205327515208, ce=39.28740821628396
Global test acc : 0.961
Global prompt norm: 58.01517105102539
Global epoch 49...
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.6631650312231221, ce=41.87689485462434
Local test acc @ epoch 49: 0.9599
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.75 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.6817669890342503, ce=40.84545072503046
Local test acc @ epoch 49: 0.9599
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.61 seconds!
[tester] 
SST2Metric: acc=0.9575688073394495, hinge=0.6650384478612777, ce=42.643862313086835
Local test acc @ epoch 49: 0.9576
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7009616357470871, ce=40.59784911969386
Local test acc @ epoch 49: 0.961
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.7 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7024936654152126, ce=39.9273369115427
Local test acc @ epoch 49: 0.9599
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.86 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.6798254809248339, ce=40.721778764637236
Local test acc @ epoch 49: 0.9599
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6231530740720417, ce=43.7981849810399
Local test acc @ epoch 49: 0.961
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.88 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.6322272436334453, ce=42.575840346310116
Local test acc @ epoch 49: 0.9599
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.89 seconds!
[tester] 
SST2Metric: acc=0.9575688073394495, hinge=0.6461285691742503, ce=42.574778040614696
Local test acc @ epoch 49: 0.9576
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.81 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7010889184584311, ce=40.31954175616623
Local test acc @ epoch 49: 0.961
Global evaluate on test data...
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.660143906917047, ce=41.92335020292789
Global test acc : 0.961
Global prompt norm: 57.968772888183594
Global epoch 50...
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.9802320611338473e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.9587155963302753, hinge=0.7566709540305881, ce=35.96322913563579
Local test acc @ epoch 50: 0.9587
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.72 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.6909391048851363, ce=41.52167042023545
Local test acc @ epoch 50: 0.9622
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.7 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7205009329209634, ce=40.63640937455204
Local test acc @ epoch 50: 0.961
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.82 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6427247436768418, ce=42.90639747829612
Local test acc @ epoch 50: 0.961
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.69 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.6584642480272765, ce=42.90967629808898
Local test acc @ epoch 50: 0.9622
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.6568886424423358, ce=43.33833470475783
Local test acc @ epoch 50: 0.9599
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.76 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.6831416427542311, ce=42.00978634335579
Local test acc @ epoch 50: 0.9622
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.9 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6974665462423902, ce=41.25255598715686
Local test acc @ epoch 50: 0.961
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.88 seconds!
[tester] 
SST2Metric: acc=0.9575688073394495, hinge=0.6117779311783816, ce=45.580590029375266
Local test acc @ epoch 50: 0.9576
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9518348623853211, hinge=1.0323830175837245, ce=32.93447755236144
Local test acc @ epoch 50: 0.9518
Global evaluate on test data...
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7118508575159476, ce=41.28199740068628
Global test acc : 0.961
Global prompt norm: 57.95004653930664
Global epoch 51...
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.66 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.6438740655916546, ce=43.97362378321657
Local test acc @ epoch 51: 0.9599
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.6 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.6737001860907318, ce=42.53765953133959
Local test acc @ epoch 51: 0.9622
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.56 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.6380548936511399, ce=45.09932075290505
Local test acc @ epoch 51: 0.9599
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.63 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6622666831410259, ce=43.348193527361666
Local test acc @ epoch 51: 0.961
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.79 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6377573931982757, ce=44.53533946046042
Local test acc @ epoch 51: 0.961
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.650527713495657, ce=43.8441499482601
Local test acc @ epoch 51: 0.9622
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.94 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6381441256321898, ce=44.62966904946423
Local test acc @ epoch 51: 0.961
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.92 seconds!
[tester] 
SST2Metric: acc=0.9564220183486238, hinge=0.6174659094679247, ce=46.0571446899974
Local test acc @ epoch 51: 0.9564
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.6604296745510276, ce=43.284061536876436
Local test acc @ epoch 51: 0.9622
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.67 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6489884109672056, ce=44.55029653846671
Local test acc @ epoch 51: 0.961
Global evaluate on test data...
Evaluate data in 82.79 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6457365565343735, ce=44.3716074042364
Global test acc : 0.961
Global prompt norm: 57.91463851928711
Global epoch 52...
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 4.470348002882929e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.9541284403669725, hinge=0.9924635077835223, ce=33.67187094032218
Local test acc @ epoch 52: 0.9541
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.68 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.6275361765415297, ce=46.2845726713128
Local test acc @ epoch 52: 0.9599
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.9802320611338473e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7474791259940611, ce=40.12888406176086
Local test acc @ epoch 52: 0.9599
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.6444814292662734, ce=45.143469364271255
Local test acc @ epoch 52: 0.9633
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.79 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.717868124673126, ce=40.564880791060425
Local test acc @ epoch 52: 0.961
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.7106041208319708, ce=41.37427867224457
Local test acc @ epoch 52: 0.9622
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.728646396496974, ce=41.19091520396941
Local test acc @ epoch 52: 0.9622
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.9802320611338473e-08
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.82 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7379587637175113, ce=38.82540260104958
Local test acc @ epoch 52: 0.961
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.9518348623853211, hinge=1.0408189996666866, ce=31.55774833959177
Local test acc @ epoch 52: 0.9518
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7086207188597513, ce=42.35517715314113
Local test acc @ epoch 52: 0.961
Global evaluate on test data...
Evaluate data in 82.82 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7473475298750292, ce=40.54493342408347
Global test acc : 0.961
Global prompt norm: 57.91353225708008
Global epoch 53...
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7318665631320498, ce=41.73838837649844
Local test acc @ epoch 53: 0.961
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.76 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6875770638842101, ce=43.772404486979916
Local test acc @ epoch 53: 0.961
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.76 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.6649658986187856, ce=44.86387567782621
Local test acc @ epoch 53: 0.9622
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.68 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.6520580064266099, ce=44.868903518816744
Local test acc @ epoch 53: 0.9622
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.93 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6904332353434431, ce=43.74948662574138
Local test acc @ epoch 53: 0.961
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.85 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7269913165941151, ce=42.35949500547637
Local test acc @ epoch 53: 0.961
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.6381915731167574, ce=45.67193397032012
Local test acc @ epoch 53: 0.9599
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.86 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.678995274622506, ce=44.60673967413946
Local test acc @ epoch 53: 0.961
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.68 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.712537148676881, ce=43.062204133479966
Local test acc @ epoch 53: 0.961
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.75 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7095089461825309, ce=43.12188640209513
Local test acc @ epoch 53: 0.961
Global evaluate on test data...
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6922975833262872, ce=43.99214697321621
Global test acc : 0.961
Global prompt norm: 57.885196685791016
Global epoch 54...
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.79 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6400073077700553, ce=46.3413953868621
Local test acc @ epoch 54: 0.961
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.89 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6481207357634098, ce=46.0465264276627
Local test acc @ epoch 54: 0.961
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.81 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.647040463368827, ce=46.00669668355119
Local test acc @ epoch 54: 0.961
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.6686155074233309, ce=45.08964762556444
Local test acc @ epoch 54: 0.9622
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.76 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.6573426854719809, ce=45.29272915901394
Local test acc @ epoch 54: 0.9622
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.86 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6473165739566908, ce=46.301555143583805
Local test acc @ epoch 54: 0.961
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.87 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.6648743458844106, ce=45.533138170154814
Local test acc @ epoch 54: 0.9622
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.7 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.6600565691606715, ce=45.34915252125591
Local test acc @ epoch 54: 0.9622
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.94 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6419608286761362, ce=46.26391332083886
Local test acc @ epoch 54: 0.961
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.05 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.652580114679599, ce=45.654847976264605
Local test acc @ epoch 54: 0.9622
Global evaluate on test data...
Evaluate data in 82.73 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6533285784065177, ce=45.883335393503174
Global test acc : 0.961
Global prompt norm: 57.86192321777344
Global epoch 55...
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.97 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6859276316581516, ce=45.13366716717361
Local test acc @ epoch 55: 0.961
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 5.9604641222676946e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.72 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.8539328925106504, ce=36.05059583471456
Local test acc @ epoch 55: 0.9599
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.9802320611338473e-08
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8267800982938994, ce=30.539380047299446
Local test acc @ epoch 55: 0.9633
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.72 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.6254940382931211, ce=47.2108602961269
Local test acc @ epoch 55: 0.9599
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.89 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6646944098516342, ce=45.863069726786485
Local test acc @ epoch 55: 0.961
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 5.9604641222676946e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.03 seconds!
[tester] 
SST2Metric: acc=0.9575688073394495, hinge=0.8512913699543804, ce=35.1075176448997
Local test acc @ epoch 55: 0.9576
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.85 seconds!
[tester] 
SST2Metric: acc=0.9529816513761468, hinge=0.6640514146297349, ce=48.47974101775283
Local test acc @ epoch 55: 0.953
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.84 seconds!
[tester] 
SST2Metric: acc=0.9587155963302753, hinge=0.6411640797186335, ce=47.70724392812186
Local test acc @ epoch 55: 0.9587
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.79 seconds!
[tester] 
SST2Metric: acc=0.9564220183486238, hinge=0.6236162360655059, ce=49.02223804018913
Local test acc @ epoch 55: 0.9564
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.9802320611338473e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.94 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6861679816464765, ce=45.28288192049079
Local test acc @ epoch 55: 0.961
Global evaluate on test data...
Evaluate data in 82.97 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7329618012139557, ce=43.4315863093105
Global test acc : 0.961
Global prompt norm: 57.85518264770508
Global epoch 56...
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.73 seconds!
[tester] 
SST2Metric: acc=0.9564220183486238, hinge=0.6191798918837801, ce=49.279165635415175
Local test acc @ epoch 56: 0.9564
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.1 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6537139350121174, ce=46.55045679074909
Local test acc @ epoch 56: 0.961
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.02 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.6363480637926574, ce=47.88427538390553
Local test acc @ epoch 56: 0.9599
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.89 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.6323901994512715, ce=47.448020165119694
Local test acc @ epoch 56: 0.9599
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.6496639470441625, ce=46.6057753956646
Local test acc @ epoch 56: 0.9633
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.79 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.673845236454535, ce=45.94853112456995
Local test acc @ epoch 56: 0.961
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.89 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7024444286976386, ce=44.851472382151755
Local test acc @ epoch 56: 0.961
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.92 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6742609837733278, ce=46.21727420211932
Local test acc @ epoch 56: 0.961
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.95 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.650329045199473, ce=47.2880727785443
Local test acc @ epoch 56: 0.961
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.96 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6933904022251794, ce=45.57872555234017
Local test acc @ epoch 56: 0.961
Global evaluate on test data...
Evaluate data in 82.96 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.6535813830314426, ce=47.0131910131612
Global test acc : 0.9622
Global prompt norm: 57.829551696777344
Global epoch 57...
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.9 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.6453095094873271, ce=48.48191077556085
Local test acc @ epoch 57: 0.9599
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 4.470348002882929e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.92 seconds!
[tester] 
SST2Metric: acc=0.9564220183486238, hinge=0.8244803476771083, ce=39.22982224630653
Local test acc @ epoch 57: 0.9564
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.9802320611338473e-08
Local loss @ local epoch 4: 2.9802318834981634e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.87 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8041140770693438, ce=36.56740265592523
Local test acc @ epoch 57: 0.9622
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.75 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6753706407109532, ce=46.6759452469852
Local test acc @ epoch 57: 0.961
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.87 seconds!
[tester] 
SST2Metric: acc=0.9552752293577982, hinge=0.657817328741791, ce=49.34880569877974
Local test acc @ epoch 57: 0.9553
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.9575688073394495, hinge=0.6584983528207201, ce=48.31552890462613
Local test acc @ epoch 57: 0.9576
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7046996934698262, ce=45.40524200999409
Local test acc @ epoch 57: 0.9599
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450579886381092e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.04 seconds!
[tester] 
SST2Metric: acc=0.9587155963302753, hinge=0.7486010888300905, ce=43.15370776675163
Local test acc @ epoch 57: 0.9587
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.09 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6328430482006948, ce=48.048033023099286
Local test acc @ epoch 57: 0.961
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.97 seconds!
[tester] 
SST2Metric: acc=0.9564220183486238, hinge=0.6264178774772434, ce=49.94721816876613
Local test acc @ epoch 57: 0.9564
Global evaluate on test data...
Evaluate data in 82.97 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7046625307940562, ce=46.037538965907665
Global test acc : 0.961
Global prompt norm: 57.81148910522461
Global epoch 58...
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.99 seconds!
[tester] 
SST2Metric: acc=0.9541284403669725, hinge=0.6304014407166647, ce=50.897298165417595
Local test acc @ epoch 58: 0.9541
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.9 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6451340334131084, ce=48.55089432602629
Local test acc @ epoch 58: 0.961
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.0 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.6323965098879752, ce=49.580574350619536
Local test acc @ epoch 58: 0.9599
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.9 seconds!
[tester] 
SST2Metric: acc=0.9575688073394495, hinge=0.6378616368005036, ce=49.43061541636056
Local test acc @ epoch 58: 0.9576
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.87 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6286061531906828, ce=49.2879547329124
Local test acc @ epoch 58: 0.961
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.96 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.6446134541012826, ce=48.539085388183594
Local test acc @ epoch 58: 0.9599
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.85 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.643364392289328, ce=48.492578208993336
Local test acc @ epoch 58: 0.961
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.95 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6582990042660215, ce=47.691811272857386
Local test acc @ epoch 58: 0.961
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.04 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7670924291698211, ce=30.32247174114262
Local test acc @ epoch 58: 0.961
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.02 seconds!
[tester] 
SST2Metric: acc=0.9564220183486238, hinge=0.6547769712745597, ce=49.91453356261647
Local test acc @ epoch 58: 0.9564
Global evaluate on test data...
Evaluate data in 82.9 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.6830418525485817, ce=47.61427128643071
Global test acc : 0.9599
Global prompt norm: 57.809661865234375
Global epoch 59...
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 5.9604641222676946e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.0 seconds!
[tester] 
SST2Metric: acc=0.9518348623853211, hinge=0.943567785648031, ce=27.83758331438817
Local test acc @ epoch 59: 0.9518
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 4.470348002882929e-08
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.96 seconds!
[tester] 
SST2Metric: acc=0.9587155963302753, hinge=0.893365265032567, ce=30.03711376715144
Local test acc @ epoch 59: 0.9587
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.9802320611338473e-08
Local loss @ local epoch 3: 7.450578465295621e-08
Local loss @ local epoch 4: 1.3411037969035533e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.07 seconds!
[tester] 
SST2Metric: acc=0.9403669724770642, hinge=1.207225187109151, ce=23.73039236856163
Local test acc @ epoch 59: 0.9404
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.85 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6586347326226191, ce=48.19532807376407
Local test acc @ epoch 59: 0.961
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.9802320611338473e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.1 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6765706057942241, ce=47.63079963474099
Local test acc @ epoch 59: 0.961
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.95 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.7710064157433466, ce=38.11260937332013
Local test acc @ epoch 59: 0.9622
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.09 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.6455236837404583, ce=49.66581407599493
Local test acc @ epoch 59: 0.9599
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.9 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6459762546994271, ce=49.56509035442947
Local test acc @ epoch 59: 0.961
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.0 seconds!
[tester] 
SST2Metric: acc=0.9529816513761468, hinge=0.6687263086301471, ce=51.03730770426059
Local test acc @ epoch 59: 0.953
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.93 seconds!
[tester] 
SST2Metric: acc=0.9552752293577982, hinge=0.6170201170335122, ce=51.38650218718642
Local test acc @ epoch 59: 0.9553
Global evaluate on test data...
Evaluate data in 82.86 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.7928415197844899, ce=41.809130292419994
Global test acc : 0.9622
Global prompt norm: 57.827396392822266
Global epoch 60...
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.89 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.7777353251745941, ce=42.97771268372142
Local test acc @ epoch 60: 0.9622
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.94 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.7740259936096472, ce=43.437784177447675
Local test acc @ epoch 60: 0.9622
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.1 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.7690447164238046, ce=43.89103320760464
Local test acc @ epoch 60: 0.9622
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.99 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.762918916317301, ce=44.02270868283893
Local test acc @ epoch 60: 0.9622
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.07 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.7836921171310844, ce=42.705567316177785
Local test acc @ epoch 60: 0.9622
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.87 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.7865089254641752, ce=42.45788346736803
Local test acc @ epoch 60: 0.9622
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.07 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.7792787617499676, ce=42.86737060546875
Local test acc @ epoch 60: 0.9622
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.87 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.7762880500303496, ce=43.08056724618334
Local test acc @ epoch 60: 0.9622
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.93 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.7861838515745391, ce=42.31180719498101
Local test acc @ epoch 60: 0.9622
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.96 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.753042638848681, ce=44.687352766684434
Local test acc @ epoch 60: 0.961
Global evaluate on test data...
Evaluate data in 83.1 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.7747924677822569, ce=43.27718601751765
Global test acc : 0.9622
Global prompt norm: 57.81940841674805
Global epoch 61...
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.84 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7590420005518362, ce=44.35759801602145
Local test acc @ epoch 61: 0.9599
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.95 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7436395019566248, ce=45.224720946145716
Local test acc @ epoch 61: 0.9599
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.97 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7557575024596048, ce=44.80730154754919
Local test acc @ epoch 61: 0.961
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.98 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7572743739556829, ce=44.453349612174776
Local test acc @ epoch 61: 0.9599
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.94 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.768391088608208, ce=43.89908015399898
Local test acc @ epoch 61: 0.9622
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.02 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7612697356337801, ce=44.25469624230621
Local test acc @ epoch 61: 0.9599
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.09 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7320262204616441, ce=45.79197801362484
Local test acc @ epoch 61: 0.9599
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.98 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.7681877109982552, ce=43.754677588786556
Local test acc @ epoch 61: 0.9622
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.01 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7492856235679136, ce=45.161783270879624
Local test acc @ epoch 61: 0.9599
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.92 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.7650295966262117, ce=44.15041344318915
Local test acc @ epoch 61: 0.9622
Global evaluate on test data...
Evaluate data in 82.91 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7569468918196652, ce=44.62012285705006
Global test acc : 0.961
Global prompt norm: 57.81069564819336
Global epoch 62...
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.91 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7340644105858759, ce=45.985945710348425
Local test acc @ epoch 62: 0.9599
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.95 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.734755494178982, ce=45.68207483554105
Local test acc @ epoch 62: 0.9599
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.1 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7484460598831877, ce=45.266322004685705
Local test acc @ epoch 62: 0.9599
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.11 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7484804621530236, ce=45.099130927969554
Local test acc @ epoch 62: 0.9599
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.87 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7238884256520403, ce=46.20577138498289
Local test acc @ epoch 62: 0.9599
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.96 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.7092206084400142, ce=46.6932332800069
Local test acc @ epoch 62: 0.9622
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.09 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7253198973629453, ce=46.308024310190746
Local test acc @ epoch 62: 0.9599
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.82 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7439879868008675, ce=45.50645985734572
Local test acc @ epoch 62: 0.9599
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.16 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7377244332514772, ce=45.58615815748862
Local test acc @ epoch 62: 0.9599
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.98 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7408659436287136, ce=45.47720154928505
Local test acc @ epoch 62: 0.9599
Global evaluate on test data...
Evaluate data in 82.97 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7354849915985667, ce=45.815351783682445
Global test acc : 0.9599
Global prompt norm: 57.801734924316406
Global epoch 63...
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.03 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.7133579232277126, ce=46.920662241244536
Local test acc @ epoch 63: 0.9622
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.85 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.703135704775469, ce=47.29273300870843
Local test acc @ epoch 63: 0.9622
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.0 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.7113261550938318, ce=46.75624010978489
Local test acc @ epoch 63: 0.9622
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.9 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.7051185621034115, ce=46.96356194172431
Local test acc @ epoch 63: 0.9622
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.88 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.7179449282654928, ce=46.783625191504804
Local test acc @ epoch 63: 0.9622
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.0 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.7244590663034981, ce=46.36837754555798
Local test acc @ epoch 63: 0.9622
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.03 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.7145816689237542, ce=46.68234686895248
Local test acc @ epoch 63: 0.9622
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.12 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.722822154333832, ce=46.57002842754399
Local test acc @ epoch 63: 0.961
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.93 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6933807079945136, ce=47.4310927784771
Local test acc @ epoch 63: 0.961
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.84 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.7191277272110685, ce=46.533101178090504
Local test acc @ epoch 63: 0.9622
Global evaluate on test data...
Evaluate data in 82.88 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.7124405585297751, ce=46.86414956609043
Global test acc : 0.9622
Global prompt norm: 57.793148040771484
Global epoch 64...
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.9 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6857691401735359, ce=48.264595241721615
Local test acc @ epoch 64: 0.961
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.99 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6994701547360201, ce=47.69362808367528
Local test acc @ epoch 64: 0.961
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.01 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6995573175062827, ce=47.7648506514523
Local test acc @ epoch 64: 0.961
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.96 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7011998574668115, ce=47.58406987321486
Local test acc @ epoch 64: 0.961
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.88 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6913034850304279, ce=47.680017628800975
Local test acc @ epoch 64: 0.961
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.94 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6948844336588448, ce=47.843720707324664
Local test acc @ epoch 64: 0.961
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.94 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6920069663896473, ce=47.82712050971635
Local test acc @ epoch 64: 0.961
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.11 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6914563266509169, ce=48.138798284968104
Local test acc @ epoch 64: 0.961
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.91 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6762721341684323, ce=48.21589632646753
Local test acc @ epoch 64: 0.961
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.94 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6962643019649961, ce=47.935187033557014
Local test acc @ epoch 64: 0.961
Global evaluate on test data...
Evaluate data in 82.98 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.693557916431252, ce=47.93307057651905
Global test acc : 0.961
Global prompt norm: 57.78398895263672
Global epoch 65...
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.0 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.6459631219916387, ce=50.022680825049726
Local test acc @ epoch 65: 0.9622
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.18 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6530486771819788, ce=49.786493913842996
Local test acc @ epoch 65: 0.961
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.06 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6493503281829553, ce=49.38087991836968
Local test acc @ epoch 65: 0.961
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.27 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.6560092891028168, ce=49.57491064509121
Local test acc @ epoch 65: 0.9622
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.87 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6768140924086264, ce=48.8565200315703
Local test acc @ epoch 65: 0.961
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.96 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.6583862348434029, ce=49.46785561097871
Local test acc @ epoch 65: 0.9622
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.12 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6708320040221608, ce=48.64751542817562
Local test acc @ epoch 65: 0.961
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.91 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6623972315307057, ce=49.255099865274694
Local test acc @ epoch 65: 0.961
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.97 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6724153439933007, ce=48.971014215311875
Local test acc @ epoch 65: 0.961
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.05 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.6562817643541808, ce=49.509755545799884
Local test acc @ epoch 65: 0.9622
Global evaluate on test data...
Evaluate data in 82.89 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6612718827133879, ce=49.4132932610468
Global test acc : 0.961
Global prompt norm: 57.77019119262695
Global epoch 66...
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.14 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.6130404122378847, ce=52.15559289214808
Local test acc @ epoch 66: 0.9599
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.14 seconds!
[tester] 
SST2Metric: acc=0.9587155963302753, hinge=0.6075894592005179, ce=52.12757723047099
Local test acc @ epoch 66: 0.9587
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.3 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6364594730762166, ce=51.07809252257741
Local test acc @ epoch 66: 0.961
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.98 seconds!
[tester] 
SST2Metric: acc=0.9564220183486238, hinge=0.5793847556507915, ce=53.82941573256746
Local test acc @ epoch 66: 0.9564
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.0 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6000112874792256, ce=51.91867639384139
Local test acc @ epoch 66: 0.961
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.01 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6160951448143075, ce=51.52326548865082
Local test acc @ epoch 66: 0.961
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.9802320611338473e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.94 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.704250005407071, ce=47.384477772843944
Local test acc @ epoch 66: 0.9622
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.97 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6126454817045719, ce=51.80136115397882
Local test acc @ epoch 66: 0.961
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.96 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.643784645500533, ce=50.30715070951969
Local test acc @ epoch 66: 0.961
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.05 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.6320343061324654, ce=50.72886619217899
Local test acc @ epoch 66: 0.9599
Global evaluate on test data...
Evaluate data in 82.82 seconds!
[tester] 
SST2Metric: acc=0.9587155963302753, hinge=0.6206554666571661, ce=51.55336366005994
Global test acc : 0.9587
Global prompt norm: 57.740821838378906
Global epoch 67...
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.9802320611338473e-08
Local loss @ local epoch 2: 2.9802320611338473e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.92 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.732215969934376, ce=23.511023810150427
Local test acc @ epoch 67: 0.9599
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450579886381092e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.96 seconds!
[tester] 
SST2Metric: acc=0.9541284403669725, hinge=0.920499694456748, ce=27.962443640472692
Local test acc @ epoch 67: 0.9541
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9461009174311926, hinge=1.154727642689276, ce=39.30416551642462
Local test acc @ epoch 67: 0.9461
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.9802320611338473e-08
Local loss @ local epoch 2: 5.960463056453591e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.7961158752441406
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.0 seconds!
[tester] 
SST2Metric: acc=0.9506880733944955, hinge=0.31273848392547815, ce=12.141282842793595
Local test acc @ epoch 67: 0.9507
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.87 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7788112491642664, ce=43.33400453340023
Local test acc @ epoch 67: 0.961
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.03 seconds!
[tester] 
SST2Metric: acc=0.9529816513761468, hinge=0.9401296738090865, ce=37.713967857010864
Local test acc @ epoch 67: 0.953
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.95 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.799830600756024, ce=43.012952157116814
Local test acc @ epoch 67: 0.961
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.99 seconds!
[tester] 
SST2Metric: acc=0.9564220183486238, hinge=0.861519905405307, ce=41.84732692613514
Local test acc @ epoch 67: 0.9564
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 4.470348002882929e-08
Local loss @ local epoch 3: 4.470348002882929e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.95 seconds!
[tester] 
SST2Metric: acc=0.9587155963302753, hinge=0.8293142406218642, ce=25.40342343181645
Local test acc @ epoch 67: 0.9587
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 4.470348002882929e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.95 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.6938620226098857, ce=25.22636779295195
Local test acc @ epoch 67: 0.961
Global evaluate on test data...
Evaluate data in 82.96 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7950657770174359, ce=30.20963173612542
Global test acc : 0.9599
Global prompt norm: 57.94036102294922
Global epoch 68...
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.82 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8394911004862654, ce=33.50778966431224
Local test acc @ epoch 68: 0.961
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.93 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.83303315486383, ce=32.859620155544455
Local test acc @ epoch 68: 0.961
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.86 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8613376136219829, ce=35.64955475133493
Local test acc @ epoch 68: 0.961
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.96 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8485600729601099, ce=34.346843264518526
Local test acc @ epoch 68: 0.961
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.98 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8573922520383782, ce=35.494103912913474
Local test acc @ epoch 68: 0.961
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8118455956835265, ce=31.4254080746152
Local test acc @ epoch 68: 0.961
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.88 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8644250620395766, ce=35.66556669812684
Local test acc @ epoch 68: 0.961
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8428490533741242, ce=33.587632677970674
Local test acc @ epoch 68: 0.961
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.98 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8342360903363709, ce=32.90482008347818
Local test acc @ epoch 68: 0.961
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.88 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8554595610417357, ce=34.739650708819745
Local test acc @ epoch 68: 0.961
Global evaluate on test data...
Evaluate data in 83.05 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8482508178150981, ce=34.093920401476936
Global test acc : 0.961
Global prompt norm: 57.932498931884766
Global epoch 69...
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.96 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8535873364964757, ce=34.89257891243751
Local test acc @ epoch 69: 0.961
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.82 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8582493602682691, ce=35.595717123889045
Local test acc @ epoch 69: 0.961
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.99 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8585481949902456, ce=35.80883460088607
Local test acc @ epoch 69: 0.9622
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.9 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8542324403010377, ce=34.88571415472468
Local test acc @ epoch 69: 0.961
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.08 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8566979946346458, ce=35.25186829173237
Local test acc @ epoch 69: 0.961
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.02 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8498577437269579, ce=34.34058639106401
Local test acc @ epoch 69: 0.961
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.01 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8591963173052587, ce=35.477033055156745
Local test acc @ epoch 69: 0.961
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.08 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.852708799029709, ce=34.651872932364086
Local test acc @ epoch 69: 0.961
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.91 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.851933759286863, ce=34.566464537874275
Local test acc @ epoch 69: 0.961
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8553507415526503, ce=35.2044380782941
Local test acc @ epoch 69: 0.961
Global evaluate on test data...
Evaluate data in 82.92 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8553641651748517, ce=35.072183189042114
Global test acc : 0.961
Global prompt norm: 57.92824172973633
Global epoch 70...
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.98 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.860248860962894, ce=36.46974350115575
Local test acc @ epoch 70: 0.9622
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8560512000267658, ce=35.26622348750403
Local test acc @ epoch 70: 0.961
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.94 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8571153540130055, ce=35.41723086855827
Local test acc @ epoch 70: 0.961
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.0 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.86021303036891, ce=36.24751400728838
Local test acc @ epoch 70: 0.9622
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.05 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8578245989773252, ce=35.693732357900075
Local test acc @ epoch 70: 0.961
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.94 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8585265601446869, ce=35.94002135740508
Local test acc @ epoch 70: 0.961
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8610881468571654, ce=36.12318166680292
Local test acc @ epoch 70: 0.961
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.84 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8575948006516203, ce=35.49422759309821
Local test acc @ epoch 70: 0.961
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.93 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8583365930329769, ce=35.68494864997514
Local test acc @ epoch 70: 0.961
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.9 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8595865275881706, ce=35.97589358058544
Local test acc @ epoch 70: 0.961
Global evaluate on test data...
Evaluate data in 82.89 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8588721642800428, ce=35.83426953236991
Global test acc : 0.961
Global prompt norm: 57.9244384765625
Global epoch 71...
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.02 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8618528033615253, ce=36.71392355052703
Local test acc @ epoch 71: 0.9622
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.05 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8598926089225559, ce=36.57563027548134
Local test acc @ epoch 71: 0.9622
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.85 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8598119075145196, ce=36.36568716906626
Local test acc @ epoch 71: 0.9622
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.06 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.859075887487569, ce=36.002151629246704
Local test acc @ epoch 71: 0.9622
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.91 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.859698238722775, ce=36.11621641456534
Local test acc @ epoch 71: 0.9622
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.93 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.860934605292224, ce=36.84190211164842
Local test acc @ epoch 71: 0.9622
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.9 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8606067031895349, ce=37.065171442994284
Local test acc @ epoch 71: 0.9622
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.98 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8608404846366392, ce=36.61062161856835
Local test acc @ epoch 71: 0.9622
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.84 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8602599222725684, ce=36.35682660724045
Local test acc @ epoch 71: 0.9622
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.81 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.859977908090714, ce=36.188570215067735
Local test acc @ epoch 71: 0.9622
Global evaluate on test data...
Evaluate data in 83.04 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8604619656134089, ce=36.486069250544276
Global test acc : 0.9622
Global prompt norm: 57.920894622802734
Global epoch 72...
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.98 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8600632881899493, ce=37.15030713912544
Local test acc @ epoch 72: 0.9622
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.97 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8608275640995131, ce=36.95504869233578
Local test acc @ epoch 72: 0.9622
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.02 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.860672670766848, ce=37.393925745552835
Local test acc @ epoch 72: 0.9622
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.15 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8599654709527252, ce=37.616722841875266
Local test acc @ epoch 72: 0.9622
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.01 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8608597812302615, ce=36.80048522599247
Local test acc @ epoch 72: 0.9622
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.91 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8603459170105261, ce=36.638512760127355
Local test acc @ epoch 72: 0.9622
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.96 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8604047014078963, ce=36.96342065793659
Local test acc @ epoch 72: 0.9622
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.0 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8607260218454064, ce=36.73049771020172
Local test acc @ epoch 72: 0.9622
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.97 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8616826993609787, ce=37.26235233971832
Local test acc @ epoch 72: 0.9622
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.97 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8609370485358282, ce=37.18839575391297
Local test acc @ epoch 72: 0.9622
Global evaluate on test data...
Evaluate data in 82.88 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8607863461205719, ce=37.07200209591367
Global test acc : 0.9622
Global prompt norm: 57.91743469238281
Global epoch 73...
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.84 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8593205224483385, ce=37.68560488289649
Local test acc @ epoch 73: 0.9622
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.9 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8604413434999798, ce=37.21456830435937
Local test acc @ epoch 73: 0.9622
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.16 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8585064192430689, ce=38.138941703586404
Local test acc @ epoch 73: 0.9622
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.03 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8606769754252303, ce=37.3612895930579
Local test acc @ epoch 73: 0.9622
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.93 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8603837643194636, ce=37.50672559125708
Local test acc @ epoch 73: 0.9622
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.94 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8607320369930442, ce=37.78102969248361
Local test acc @ epoch 73: 0.9622
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.94 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8606667693601836, ce=37.292007288801564
Local test acc @ epoch 73: 0.9622
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.76 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8601421588057772, ce=37.729016540247365
Local test acc @ epoch 73: 0.9622
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.16 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8596071497015997, ce=37.916685961802074
Local test acc @ epoch 73: 0.9622
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.97 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8599851787637133, ce=37.51462598678169
Local test acc @ epoch 73: 0.9622
Global evaluate on test data...
Evaluate data in 82.81 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8601698219229322, ce=37.61587699400176
Global test acc : 0.9622
Global prompt norm: 57.91407775878906
Global epoch 74...
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.06 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8590869772324868, ce=38.279472036099214
Local test acc @ epoch 74: 0.9622
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.99 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8596556864747213, ce=37.888756603275965
Local test acc @ epoch 74: 0.9622
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.97 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8597549954685596, ce=37.819214112168055
Local test acc @ epoch 74: 0.9622
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.23 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8578304107036065, ce=38.41946110156698
Local test acc @ epoch 74: 0.9622
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.08 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8586005377113273, ce=38.244971494062234
Local test acc @ epoch 74: 0.9622
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.1 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.856467435119349, ce=38.6416923802927
Local test acc @ epoch 74: 0.9622
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.87 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8591407679636544, ce=38.02818651811792
Local test acc @ epoch 74: 0.9622
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.97 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8596123642877701, ce=37.7520557018595
Local test acc @ epoch 74: 0.9622
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.99 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8578121530900308, ce=38.19498352610737
Local test acc @ epoch 74: 0.9622
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.97 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8587580798962794, ce=38.03534754481884
Local test acc @ epoch 74: 0.9622
Global evaluate on test data...
Evaluate data in 83.01 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8587727284212725, ce=38.13223497583232
Global test acc : 0.9622
Global prompt norm: 57.91072082519531
Global epoch 75...
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.99 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8567994931422243, ce=38.7644579826145
Local test acc @ epoch 75: 0.9622
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.04 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.856364692023041, ce=38.744785623812895
Local test acc @ epoch 75: 0.9622
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.4 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8581140413196808, ce=38.32371377507481
Local test acc @ epoch 75: 0.9622
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.9 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8555414523553411, ce=38.90905072273464
Local test acc @ epoch 75: 0.9622
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.87 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8556210885354139, ce=38.6869719619051
Local test acc @ epoch 75: 0.9622
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.95 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8579102087458339, ce=38.394353324120196
Local test acc @ epoch 75: 0.9622
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.82 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8571901387030926, ce=38.529243014274385
Local test acc @ epoch 75: 0.9622
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.04 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8540762739443998, ce=39.131781936785494
Local test acc @ epoch 75: 0.9622
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.07 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.856815493434941, ce=38.535828091682646
Local test acc @ epoch 75: 0.9622
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.24 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8580414045841323, ce=38.263979465589614
Local test acc @ epoch 75: 0.9622
Global evaluate on test data...
Evaluate data in 83.2 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8566880007402613, ce=38.63027450141557
Global test acc : 0.9622
Global prompt norm: 57.90730285644531
Global epoch 76...
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.95 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.855881485370321, ce=38.81337374065994
Local test acc @ epoch 76: 0.9622
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.01 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8558202314814296, ce=38.759286058058436
Local test acc @ epoch 76: 0.9622
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.98 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8538375491396003, ce=39.23420715332031
Local test acc @ epoch 76: 0.9622
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.79 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.855559985572045, ce=38.88585193879014
Local test acc @ epoch 76: 0.9622
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.14 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8510267384555361, ce=39.61355821801982
Local test acc @ epoch 76: 0.9622
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.03 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8529179774293112, ce=39.3901613217975
Local test acc @ epoch 76: 0.9622
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.03 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.854360136417074, ce=39.02289798281608
Local test acc @ epoch 76: 0.9622
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8542819591837192, ce=39.24112526429902
Local test acc @ epoch 76: 0.9622
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.88 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8547526827645958, ce=39.017088863827766
Local test acc @ epoch 76: 0.9622
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.82 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8530771754203587, ce=39.16774679761414
Local test acc @ epoch 76: 0.9622
Global evaluate on test data...
Evaluate data in 82.96 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8542690867677741, ce=39.11651089869508
Global test acc : 0.9622
Global prompt norm: 57.90384292602539
Global epoch 77...
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.9 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8500495613168139, ce=39.64115160320877
Local test acc @ epoch 77: 0.9622
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.98 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8512159728128975, ce=39.712589123927124
Local test acc @ epoch 77: 0.9622
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.06 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8519580407973824, ce=39.49605577801346
Local test acc @ epoch 77: 0.9622
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.97 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8533494428757133, ce=39.243632675310884
Local test acc @ epoch 77: 0.9622
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.07 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8496781773523453, ce=39.86541006105755
Local test acc @ epoch 77: 0.9622
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.96 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8507818978860837, ce=39.71690526139845
Local test acc @ epoch 77: 0.9622
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.93 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8515678633243666, ce=39.50120173463034
Local test acc @ epoch 77: 0.9622
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.01 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8529530708942938, ce=39.36825512527326
Local test acc @ epoch 77: 0.9622
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.93 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8533832283195005, ce=39.29349892292548
Local test acc @ epoch 77: 0.9622
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.9 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8473312789147053, ce=40.089663129334056
Local test acc @ epoch 77: 0.9622
Global evaluate on test data...
Evaluate data in 82.94 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8513468164916432, ce=39.59494522514693
Global test acc : 0.9622
Global prompt norm: 57.90029525756836
Global epoch 78...
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.99 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8471776367327489, ce=40.19505457046929
Local test acc @ epoch 78: 0.9622
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.86 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8475311589897225, ce=40.18097410289519
Local test acc @ epoch 78: 0.9622
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.94 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8485478261195192, ce=39.968792906594935
Local test acc @ epoch 78: 0.9622
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.95 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8464058407949745, ce=40.1095356022546
Local test acc @ epoch 78: 0.9622
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.27 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8502515959083488, ce=39.720947475608334
Local test acc @ epoch 78: 0.9622
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.08 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8444813960189119, ce=40.56117804990996
Local test acc @ epoch 78: 0.9622
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.22 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8481599912730926, ce=39.97336536372473
Local test acc @ epoch 78: 0.9622
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.93 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8502628103308721, ce=39.76763247568673
Local test acc @ epoch 78: 0.9622
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.0 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8497175776630367, ce=39.84494060551355
Local test acc @ epoch 78: 0.9622
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.04 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8458334109105101, ce=40.336485801486795
Local test acc @ epoch 78: 0.9622
Global evaluate on test data...
Evaluate data in 82.97 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8478042991883165, ce=40.06828553086027
Global test acc : 0.9622
Global prompt norm: 57.89665603637695
Global epoch 79...
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.99 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8458818186313735, ce=40.31767062965883
Local test acc @ epoch 79: 0.9622
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.02 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8429315855743689, ce=40.573556567550796
Local test acc @ epoch 79: 0.9622
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.92 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8465284207545289, ce=40.23775331689677
Local test acc @ epoch 79: 0.9622
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.93 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8465304418441353, ce=40.1935340461381
Local test acc @ epoch 79: 0.9622
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.93 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8415692311908127, ce=41.02750911187688
Local test acc @ epoch 79: 0.9622
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.93 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8427739908935827, ce=40.80308319231786
Local test acc @ epoch 79: 0.9622
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.91 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8440973189992642, ce=40.64690147189919
Local test acc @ epoch 79: 0.9622
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.21 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8443077179270053, ce=40.44078907397909
Local test acc @ epoch 79: 0.9622
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.01 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8444569963927663, ce=40.669127963004854
Local test acc @ epoch 79: 0.9622
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8450831426393002, ce=40.436909771840504
Local test acc @ epoch 79: 0.9622
Global evaluate on test data...
Evaluate data in 82.87 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8444108656786997, ce=40.53728485107422
Global test acc : 0.9622
Global prompt norm: 57.89302062988281
Global epoch 80...
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.05 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8415950853890235, ce=40.90305370365808
Local test acc @ epoch 80: 0.9622
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.98 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8424341197407573, ce=40.89968693584477
Local test acc @ epoch 80: 0.9622
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.04 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8381589224579138, ce=41.48672600842397
Local test acc @ epoch 80: 0.961
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.86 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8416490795415476, ce=41.13784825036285
Local test acc @ epoch 80: 0.9622
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.99 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8434486826625439, ce=40.66177676139622
Local test acc @ epoch 80: 0.9622
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.07 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8436374511193792, ce=40.70425611023509
Local test acc @ epoch 80: 0.9622
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.96 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.841188896686659, ce=41.10955380081037
Local test acc @ epoch 80: 0.9622
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8397679460158042, ce=41.2637001877531
Local test acc @ epoch 80: 0.9622
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.08 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8399909023844868, ce=41.03289878915209
Local test acc @ epoch 80: 0.9622
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.91 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8431489751973283, ce=40.78660041039143
Local test acc @ epoch 80: 0.9622
Global evaluate on test data...
Evaluate data in 83.14 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.841637351097317, ce=41.0015733001429
Global test acc : 0.9622
Global prompt norm: 57.88932800292969
Global epoch 81...
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.96 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.8363048374106031, ce=41.71527183602709
Local test acc @ epoch 81: 0.9599
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.93 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.838437266306046, ce=41.35843766938656
Local test acc @ epoch 81: 0.9622
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.02 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.837793923299247, ce=41.566585575768705
Local test acc @ epoch 81: 0.961
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.95 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8393213202100281, ce=41.355562402567735
Local test acc @ epoch 81: 0.961
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.88 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8365749962832949, ce=41.48534610293327
Local test acc @ epoch 81: 0.961
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.04 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8406932332100124, ce=41.16630351215328
Local test acc @ epoch 81: 0.9622
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.98 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8401140160516861, ce=41.25058588850389
Local test acc @ epoch 81: 0.9622
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.93 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8342584251263819, ce=41.93538021822588
Local test acc @ epoch 81: 0.961
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.86 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.8383756536956227, ce=41.59866493995037
Local test acc @ epoch 81: 0.9599
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.89 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8405123500648989, ce=41.12486746551794
Local test acc @ epoch 81: 0.9622
Global evaluate on test data...
Evaluate data in 83.01 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8383870321676272, ce=41.45898507494445
Global test acc : 0.961
Global prompt norm: 57.88558578491211
Global epoch 82...
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.97 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.8372730771335987, ce=41.621373132828175
Local test acc @ epoch 82: 0.9599
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.03 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8370960305590148, ce=41.58068193208187
Local test acc @ epoch 82: 0.961
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.9 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.8357568662100976, ce=41.80135723428989
Local test acc @ epoch 82: 0.9599
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.95 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.8324223658360472, ce=42.15348220965184
Local test acc @ epoch 82: 0.9599
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.92 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.8366031471742402, ce=41.7067307988438
Local test acc @ epoch 82: 0.9599
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.9 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.8327266929346487, ce=41.92762682853489
Local test acc @ epoch 82: 0.9599
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.01 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.8348405733021027, ce=41.804091532296
Local test acc @ epoch 82: 0.9599
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.92 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8339255577927336, ce=42.0142836264514
Local test acc @ epoch 82: 0.961
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8299276894385662, ce=42.369038083137724
Local test acc @ epoch 82: 0.961
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.96 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8346609325583921, ce=42.04741528712282
Local test acc @ epoch 82: 0.961
Global evaluate on test data...
Evaluate data in 83.03 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.8346772740740295, ce=41.9062232271247
Global test acc : 0.9599
Global prompt norm: 57.8819465637207
Global epoch 83...
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.86 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8332281243910483, ce=42.02544165095058
Local test acc @ epoch 83: 0.961
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8317857335466857, ce=42.233134733427555
Local test acc @ epoch 83: 0.961
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.92 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8308403688833255, ce=42.236017839624246
Local test acc @ epoch 83: 0.961
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.97 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8326473301703777, ce=42.15104916773805
Local test acc @ epoch 83: 0.961
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.9 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8305476171161057, ce=42.47944130153831
Local test acc @ epoch 83: 0.961
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.86 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8296320919596821, ce=42.44814807996838
Local test acc @ epoch 83: 0.961
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.93 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8281826972961426, ce=42.57353826400337
Local test acc @ epoch 83: 0.961
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.06 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8334034932862728, ce=42.0657889339902
Local test acc @ epoch 83: 0.961
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.91 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8284992493620706, ce=42.35588980158535
Local test acc @ epoch 83: 0.961
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8252403736114502, ce=42.782894134521484
Local test acc @ epoch 83: 0.961
Global evaluate on test data...
Evaluate data in 83.01 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8305636655300035, ce=42.33903114948798
Global test acc : 0.961
Global prompt norm: 57.878379821777344
Global epoch 84...
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.13 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8283047741706219, ce=42.57909109833044
Local test acc @ epoch 84: 0.961
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.05 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8291287247194062, ce=42.49520510052322
Local test acc @ epoch 84: 0.961
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.91 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8289555278393107, ce=42.455013380138155
Local test acc @ epoch 84: 0.961
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.86 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8236670537826118, ce=42.970785718445384
Local test acc @ epoch 84: 0.961
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.91 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8261544857550105, ce=42.88975402412065
Local test acc @ epoch 84: 0.961
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.85 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8211322596313757, ce=43.17265830783669
Local test acc @ epoch 84: 0.961
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.98 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8250339556177821, ce=42.86318157790998
Local test acc @ epoch 84: 0.961
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.96 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8239707859284288, ce=42.7653466670885
Local test acc @ epoch 84: 0.961
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.94 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8265061006633514, ce=42.65004565737663
Local test acc @ epoch 84: 0.961
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.01 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8274691258001765, ce=42.64663517803227
Local test acc @ epoch 84: 0.961
Global evaluate on test data...
Evaluate data in 83.0 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8261058352409153, ce=42.75285510841859
Global test acc : 0.961
Global prompt norm: 57.875003814697266
Global epoch 85...
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.86 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8232630502193345, ce=43.037748914246166
Local test acc @ epoch 85: 0.961
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.84 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8224526414083778, ce=43.27422472752562
Local test acc @ epoch 85: 0.961
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.09 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8223185429879285, ce=43.04225270682519
Local test acc @ epoch 85: 0.961
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.06 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.824531358316404, ce=42.90511636996488
Local test acc @ epoch 85: 0.961
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.91 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8169775905959104, ce=43.53501759100398
Local test acc @ epoch 85: 0.961
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.91 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8236575739099345, ce=42.98615947338419
Local test acc @ epoch 85: 0.961
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.82 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8198053311864171, ce=43.15239369103668
Local test acc @ epoch 85: 0.961
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.86 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8211051083486015, ce=43.25478111057107
Local test acc @ epoch 85: 0.961
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.9 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8243662348581017, ce=42.864652441182265
Local test acc @ epoch 85: 0.961
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.91 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8194890897208398, ce=43.34173772969377
Local test acc @ epoch 85: 0.961
Global evaluate on test data...
Evaluate data in 82.96 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.821936782346953, ce=43.14377835474977
Global test acc : 0.961
Global prompt norm: 57.871761322021484
Global epoch 86...
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.03 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8155902919419314, ce=43.68452278627168
Local test acc @ epoch 86: 0.961
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.01 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.820517511542784, ce=43.29157463563691
Local test acc @ epoch 86: 0.961
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.86 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8204986764750349, ce=43.25094768979134
Local test acc @ epoch 86: 0.961
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.85 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8195676650476018, ce=43.36836970618012
Local test acc @ epoch 86: 0.961
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.82 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8194373025806672, ce=43.40353519544689
Local test acc @ epoch 86: 0.961
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.0 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8127305966998459, ce=43.86864051468876
Local test acc @ epoch 86: 0.961
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.92 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8158596458785031, ce=43.51390702133879
Local test acc @ epoch 86: 0.961
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.85 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8169916485427716, ce=43.619480483028866
Local test acc @ epoch 86: 0.961
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.13 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8185541170452713, ce=43.630243878845775
Local test acc @ epoch 86: 0.961
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.22 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8184923644459575, ce=43.409590939863016
Local test acc @ epoch 86: 0.961
Global evaluate on test data...
Evaluate data in 83.2 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8179877701155637, ce=43.50855874577793
Global test acc : 0.961
Global prompt norm: 57.86891555786133
Global epoch 87...
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.0 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8156663234080743, ce=43.7426893951696
Local test acc @ epoch 87: 0.961
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.56 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8116392017504491, ce=43.998951098240845
Local test acc @ epoch 87: 0.961
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.3 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8155001172231972, ce=43.72373895907621
Local test acc @ epoch 87: 0.961
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.03 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8164547299026349, ce=43.6109236970954
Local test acc @ epoch 87: 0.961
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.06 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8152343461272913, ce=43.957177013432215
Local test acc @ epoch 87: 0.9622
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.01 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8145341523196719, ce=43.75073109198054
Local test acc @ epoch 87: 0.961
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.94 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8092075662875394, ce=44.17391880280381
Local test acc @ epoch 87: 0.961
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.9 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8118476692689668, ce=43.84864562148348
Local test acc @ epoch 87: 0.961
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.14 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8130103010650075, ce=43.95578429895804
Local test acc @ epoch 87: 0.9622
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.16 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8164565847554338, ce=43.65199801243773
Local test acc @ epoch 87: 0.961
Global evaluate on test data...
Evaluate data in 83.15 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8139306383395414, ce=43.845905128968965
Global test acc : 0.961
Global prompt norm: 57.866207122802734
Global epoch 88...
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.18 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8112332930258654, ce=44.06567543799724
Local test acc @ epoch 88: 0.961
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8128458469285877, ce=43.94409568156671
Local test acc @ epoch 88: 0.961
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.95 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8127352447684751, ce=43.98545651917064
Local test acc @ epoch 88: 0.961
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.17 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8096980589245437, ce=44.26425674858443
Local test acc @ epoch 88: 0.9622
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.85 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8117215764631919, ce=44.05145879622993
Local test acc @ epoch 88: 0.961
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.06 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8125794349460427, ce=44.0553360685296
Local test acc @ epoch 88: 0.9622
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.1 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8084171605766366, ce=44.286511797423756
Local test acc @ epoch 88: 0.961
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.17 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.805870379876653, ce=44.45263031425826
Local test acc @ epoch 88: 0.9622
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.88 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8121124451313544, ce=44.25613298328645
Local test acc @ epoch 88: 0.9622
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.98 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8083550186332212, ce=44.15682265955374
Local test acc @ epoch 88: 0.961
Global evaluate on test data...
Evaluate data in 83.19 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8107027220069816, ce=44.15623918585821
Global test acc : 0.9622
Global prompt norm: 57.8637580871582
Global epoch 89...
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.07 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8094351947854418, ce=44.34298184596071
Local test acc @ epoch 89: 0.9622
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.01 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8063855258696669, ce=44.54636827521368
Local test acc @ epoch 89: 0.9622
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.07 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.809605090989979, ce=44.251018069206026
Local test acc @ epoch 89: 0.9622
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.0 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.805340712223578, ce=44.549780959383064
Local test acc @ epoch 89: 0.9622
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.95 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8081164185060273, ce=44.35577039106177
Local test acc @ epoch 89: 0.9622
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.85 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8052596411573778, ce=44.44011688232422
Local test acc @ epoch 89: 0.9622
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.9 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8094777557828011, ce=44.29283586554571
Local test acc @ epoch 89: 0.9622
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.0 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8084890055000236, ce=44.35308295433674
Local test acc @ epoch 89: 0.9622
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.96 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8089452861645899, ce=44.5291358177815
Local test acc @ epoch 89: 0.961
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.1 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8025934018126322, ce=44.707362883681554
Local test acc @ epoch 89: 0.961
Global evaluate on test data...
Evaluate data in 82.94 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8074958368178902, ce=44.44110600882714
Global test acc : 0.9622
Global prompt norm: 57.861507415771484
Global epoch 90...
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.01 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8049851404417545, ce=44.62337896364544
Local test acc @ epoch 90: 0.961
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.02 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8052526635861178, ce=44.630652576411535
Local test acc @ epoch 90: 0.9622
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.02 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.805772901675023, ce=44.779391192514964
Local test acc @ epoch 90: 0.961
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.11 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8022919335496534, ce=44.79183998457882
Local test acc @ epoch 90: 0.961
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.16 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8062697966164405, ce=44.60809739139102
Local test acc @ epoch 90: 0.961
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.87 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8030992822909574, ce=44.80503820716788
Local test acc @ epoch 90: 0.961
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.04 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8021863075571323, ce=44.70104854478748
Local test acc @ epoch 90: 0.9622
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.11 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8061985072739627, ce=44.5761491268053
Local test acc @ epoch 90: 0.9622
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.06 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7993809323792064, ce=44.94149318310099
Local test acc @ epoch 90: 0.961
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.95 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8063385727208688, ce=44.533824220709846
Local test acc @ epoch 90: 0.961
Global evaluate on test data...
Evaluate data in 83.12 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8043003672853523, ce=44.70320724347316
Global test acc : 0.961
Global prompt norm: 57.85942840576172
Global epoch 91...
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.87 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.802023859199034, ce=44.8873702582963
Local test acc @ epoch 91: 0.961
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.97 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8029240905691725, ce=44.838402564372494
Local test acc @ epoch 91: 0.961
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.99 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8031116035006461, ce=44.85341766777388
Local test acc @ epoch 91: 0.961
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.29 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7998539723387552, ce=45.04362757271583
Local test acc @ epoch 91: 0.961
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.33 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7992758991521433, ce=45.0159217414506
Local test acc @ epoch 91: 0.961
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.1 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8026151941456926, ce=45.010244002035996
Local test acc @ epoch 91: 0.961
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.03 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7962370771880544, ce=45.15846742402523
Local test acc @ epoch 91: 0.961
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.84 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8018582654655526, ce=44.871403300434075
Local test acc @ epoch 91: 0.961
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.1 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7991446486306847, ce=44.942388622038955
Local test acc @ epoch 91: 0.961
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.96 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8030752391990171, ce=44.7953314124991
Local test acc @ epoch 91: 0.961
Global evaluate on test data...
Evaluate data in 83.1 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.801123107245209, ce=44.945511704191155
Global test acc : 0.961
Global prompt norm: 57.85759735107422
Global epoch 92...
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.21 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7962901351648733, ce=45.22500578854062
Local test acc @ epoch 92: 0.961
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.94 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7987455096813517, ce=45.10290467848471
Local test acc @ epoch 92: 0.961
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.12 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7988178795630779, ce=45.12648972677528
Local test acc @ epoch 92: 0.961
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.06 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.799969909387991, ce=45.08223010421893
Local test acc @ epoch 92: 0.961
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.94 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7994845263454893, ce=45.22497611089584
Local test acc @ epoch 92: 0.961
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.18 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7931642816701067, ce=45.36108580423058
Local test acc @ epoch 92: 0.961
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.15 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7961362108178095, ce=45.16750381189749
Local test acc @ epoch 92: 0.961
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.98 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.799662856880678, ce=45.0825430493836
Local test acc @ epoch 92: 0.961
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.88 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7998316922319044, ce=45.03868722478184
Local test acc @ epoch 92: 0.961
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.72 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7967710166896155, ce=45.26548784588455
Local test acc @ epoch 92: 0.961
Global evaluate on test data...
Evaluate data in 83.22 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7979757479571421, ce=45.17138745369167
Global test acc : 0.961
Global prompt norm: 57.8558464050293
Global epoch 93...
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.05 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7967414680970918, ce=45.42668424833805
Local test acc @ epoch 93: 0.961
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.91 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7939621549133861, ce=45.47381045840202
Local test acc @ epoch 93: 0.961
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.93 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7901327653762398, ce=45.55265920096581
Local test acc @ epoch 93: 0.961
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.2 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7956440951846061, ce=45.321024728477546
Local test acc @ epoch 93: 0.961
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.08 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7956274999391049, ce=45.351343312394725
Local test acc @ epoch 93: 0.961
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.04 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7931472489593225, ce=45.37942042919474
Local test acc @ epoch 93: 0.961
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.97 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7966006414605937, ce=45.26718458123163
Local test acc @ epoch 93: 0.961
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.17 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7964133866336367, ce=45.31212133005125
Local test acc @ epoch 93: 0.961
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.96 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7969212575789986, ce=45.29744153503978
Local test acc @ epoch 93: 0.961
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.86 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7933331892031048, ce=45.42221835775113
Local test acc @ epoch 93: 0.961
Global evaluate on test data...
Evaluate data in 83.16 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7948538753964486, ce=45.38388579482332
Global test acc : 0.961
Global prompt norm: 57.85421371459961
Global epoch 94...
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.93 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7903940787009143, ce=45.610225572498564
Local test acc @ epoch 94: 0.961
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.85 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.790375046773788, ce=45.58117808770696
Local test acc @ epoch 94: 0.961
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.91 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7936212032213124, ce=45.48390323743908
Local test acc @ epoch 94: 0.961
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.1 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7941579009414813, ce=45.501954139919455
Local test acc @ epoch 94: 0.961
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.94 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7874592444218627, ce=45.735615301569666
Local test acc @ epoch 94: 0.961
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.95 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7939945295316364, ce=45.618514174715095
Local test acc @ epoch 94: 0.961
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.95 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7933334516822745, ce=45.530139328142916
Local test acc @ epoch 94: 0.961
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.75 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.792700900944001, ce=45.52862429837568
Local test acc @ epoch 94: 0.961
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.17 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7925574495158064, ce=45.56519051648061
Local test acc @ epoch 94: 0.961
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.91 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7911606009947051, ce=45.67187699484169
Local test acc @ epoch 94: 0.961
Global evaluate on test data...
Evaluate data in 83.03 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7920418048123701, ce=45.5860504360374
Global test acc : 0.961
Global prompt norm: 57.852622985839844
Global epoch 95...
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.05 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7907532442600356, ce=45.691987308887164
Local test acc @ epoch 95: 0.961
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.88 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7877338785643971, ce=45.77526428502634
Local test acc @ epoch 95: 0.961
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.84 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7904506254633632, ce=45.73978256085597
Local test acc @ epoch 95: 0.961
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.93 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7883490991154942, ce=45.86245979519065
Local test acc @ epoch 95: 0.961
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.96 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7847846954240711, ce=45.912459452217874
Local test acc @ epoch 95: 0.961
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.11 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.78761570388024, ce=45.791550872522755
Local test acc @ epoch 95: 0.961
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.97 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7899489249658147, ce=45.728502221063735
Local test acc @ epoch 95: 0.961
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.02 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7913820349842037, ce=45.698542918633976
Local test acc @ epoch 95: 0.961
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.96 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7912399375110591, ce=45.80291681552152
Local test acc @ epoch 95: 0.961
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.88 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7897348644536569, ce=45.770893551887724
Local test acc @ epoch 95: 0.961
Global evaluate on test data...
Evaluate data in 83.02 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.789276783619452, ce=45.78055614506433
Global test acc : 0.961
Global prompt norm: 57.8512077331543
Global epoch 96...
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.08 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7884562299885881, ce=45.982334486935116
Local test acc @ epoch 96: 0.961
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.03 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7871497311723341, ce=45.92326879938808
Local test acc @ epoch 96: 0.961
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.0 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7849793412269802, ce=45.968407412187766
Local test acc @ epoch 96: 0.961
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.96 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7820753482503628, ce=46.08547858141978
Local test acc @ epoch 96: 0.961
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.91 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7875149140664197, ce=45.94380586956619
Local test acc @ epoch 96: 0.961
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.97 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7855101353531584, ce=46.04812359591143
Local test acc @ epoch 96: 0.961
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.94 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7850406104271564, ce=45.96448915814041
Local test acc @ epoch 96: 0.961
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.97 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7885670968151968, ce=45.889745344809434
Local test acc @ epoch 96: 0.961
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.05 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7868577187214423, ce=45.97148559290335
Local test acc @ epoch 96: 0.961
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.04 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7878418099989585, ce=45.89415604477629
Local test acc @ epoch 96: 0.961
Global evaluate on test data...
Evaluate data in 83.04 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7864695382774423, ce=45.97024070669752
Global test acc : 0.961
Global prompt norm: 57.849788665771484
Global epoch 97...
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.03 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7822789445929571, ce=46.151080910218965
Local test acc @ epoch 97: 0.961
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.08 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7848614771431739, ce=46.093040606297485
Local test acc @ epoch 97: 0.961
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.19 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7845035627347614, ce=46.1448849319318
Local test acc @ epoch 97: 0.961
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.85 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7826174967879549, ce=46.23105628337335
Local test acc @ epoch 97: 0.961
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.91 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7822801563717904, ce=46.14308411484465
Local test acc @ epoch 97: 0.961
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.0 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7842759823580401, ce=46.11533915668453
Local test acc @ epoch 97: 0.961
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.95 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7856912897267473, ce=46.07780019077686
Local test acc @ epoch 97: 0.961
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.9 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7793028026545813, ce=46.25667292043703
Local test acc @ epoch 97: 0.961
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.9 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7839027785379952, ce=46.16930259914573
Local test acc @ epoch 97: 0.961
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.95 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7856209934304613, ce=46.15924803707578
Local test acc @ epoch 97: 0.961
Global evaluate on test data...
Evaluate data in 82.94 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.783599827267708, ce=46.15706249552036
Global test acc : 0.961
Global prompt norm: 57.84839630126953
Global epoch 98...
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.04 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7794963285463665, ce=46.317355199691356
Local test acc @ epoch 98: 0.961
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.06 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7796396443603235, ce=46.41368106527066
Local test acc @ epoch 98: 0.961
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.18 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7827316008576559, ce=46.265088422582785
Local test acc @ epoch 98: 0.961
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.87 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7817750195844457, ce=46.29102773403903
Local test acc @ epoch 98: 0.961
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.86 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7808433672703734, ce=46.36674905479501
Local test acc @ epoch 98: 0.961
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.93 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7813848814833055, ce=46.34533820895974
Local test acc @ epoch 98: 0.961
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.06 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7827156771213637, ce=46.335535311917646
Local test acc @ epoch 98: 0.961
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.12 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7764427005697828, ce=46.42805141483972
Local test acc @ epoch 98: 0.961
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.0 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7794105919129258, ce=46.33721167888116
Local test acc @ epoch 98: 0.961
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.24 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7812968131599076, ce=46.3069718737121
Local test acc @ epoch 98: 0.961
Global evaluate on test data...
Evaluate data in 83.0 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7806348078841463, ce=46.343539771683716
Global test acc : 0.961
Global prompt norm: 57.846988677978516
Global epoch 99...
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.84 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7734597407349753, ce=46.60158720803917
Local test acc @ epoch 99: 0.961
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.81 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7797029171514949, ce=46.51318880833617
Local test acc @ epoch 99: 0.961
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.85 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.776413368522574, ce=46.525068195588
Local test acc @ epoch 99: 0.961
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.14 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.778551416659574, ce=46.49055358466752
Local test acc @ epoch 99: 0.961
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.24 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7765967780296955, ce=46.4931787613335
Local test acc @ epoch 99: 0.961
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.08 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7765463360952675, ce=46.598000902648366
Local test acc @ epoch 99: 0.961
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.9 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7796571517209394, ce=46.45335125704424
Local test acc @ epoch 99: 0.961
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.96 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7781780334787631, ce=46.500303460917344
Local test acc @ epoch 99: 0.961
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.0 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.778120185257098, ce=46.54759839259157
Local test acc @ epoch 99: 0.961
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.88 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.777633971030559, ce=46.566219364831205
Local test acc @ epoch 99: 0.961
Global evaluate on test data...
Evaluate data in 83.1 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7775475103920753, ce=46.531768098883674
Global test acc : 0.961
Global prompt norm: 57.845584869384766
Global epoch 100...
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.16 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7751408935686864, ce=46.693989919959954
Local test acc @ epoch 100: 0.961
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.17 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7732386829656198, ce=46.716821128075274
Local test acc @ epoch 100: 0.961
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.93 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7732855114368123, ce=46.786251803056906
Local test acc @ epoch 100: 0.961
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7735436815734303, ce=46.672458963656645
Local test acc @ epoch 100: 0.961
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.0 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7703148268778389, ce=46.77897430559911
Local test acc @ epoch 100: 0.961
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.99 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7765516272378624, ce=46.69426660800199
Local test acc @ epoch 100: 0.961
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.0 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7742283519254912, ce=46.77017218913507
Local test acc @ epoch 100: 0.961
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.88 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7746634023998855, ce=46.754046308884924
Local test acc @ epoch 100: 0.961
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.03 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7748766011054363, ce=46.69775852588339
Local test acc @ epoch 100: 0.961
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.09 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.776424924168018, ce=46.64506800240333
Local test acc @ epoch 100: 0.961
Global evaluate on test data...
Evaluate data in 83.18 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.774285358026487, ce=46.72386211430261
Global test acc : 0.961
Global prompt norm: 57.84416961669922
Global epoch 101...
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.95 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7709552738644662, ce=46.96720301776851
Local test acc @ epoch 101: 0.961
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.0 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7669640768558608, ce=46.96209177839647
Local test acc @ epoch 101: 0.961
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.11 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7713399852087738, ce=46.90144484633699
Local test acc @ epoch 101: 0.961
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.0 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7732110548456874, ce=46.88078353601858
Local test acc @ epoch 101: 0.961
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.47 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7714912760148355, ce=46.90362552327847
Local test acc @ epoch 101: 0.961
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.84 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7698247607694854, ce=46.9803550440237
Local test acc @ epoch 101: 0.961
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.98 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7702961405482861, ce=46.857157400988655
Local test acc @ epoch 101: 0.961
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.04 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7698426946587519, ce=46.91454255690268
Local test acc @ epoch 101: 0.961
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.9 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7705790952804985, ce=46.98088497196863
Local test acc @ epoch 101: 0.961
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.12 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7729968740305769, ce=46.84200598340516
Local test acc @ epoch 101: 0.961
Global evaluate on test data...
Evaluate data in 83.04 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7708094819970087, ce=46.92196329799267
Global test acc : 0.961
Global prompt norm: 57.842681884765625
Global epoch 102...
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.06 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.767504978617397, ce=47.11379952386979
Local test acc @ epoch 102: 0.961
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.09 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7667988309072792, ce=47.04928123404127
Local test acc @ epoch 102: 0.961
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.85 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.769305679776253, ce=47.04667772065609
Local test acc @ epoch 102: 0.961
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.79 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.766927856917775, ce=47.18969796556945
Local test acc @ epoch 102: 0.961
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.99 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7661664114085907, ce=47.120607148616685
Local test acc @ epoch 102: 0.961
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.04 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7675308262536286, ce=47.12221709085167
Local test acc @ epoch 102: 0.961
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.05 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.769639253616333, ce=47.07480757827059
Local test acc @ epoch 102: 0.961
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.92 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7666109395683358, ce=47.20101092277317
Local test acc @ epoch 102: 0.961
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.15 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7661001222942947, ce=47.182599513902574
Local test acc @ epoch 102: 0.961
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.97 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7633507382979087, ce=47.15302203117161
Local test acc @ epoch 102: 0.961
Global evaluate on test data...
Evaluate data in 82.85 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7670558833200997, ce=47.128489083106366
Global test acc : 0.961
Global prompt norm: 57.841163635253906
Global epoch 103...
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.04 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7620416671857921, ce=47.395604089859425
Local test acc @ epoch 103: 0.961
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.01 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7631775589164244, ce=47.3526273954899
Local test acc @ epoch 103: 0.961
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.85 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7594110987602024, ce=47.354062561595114
Local test acc @ epoch 103: 0.961
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.22 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7657661394241753, ce=47.27869464279315
Local test acc @ epoch 103: 0.961
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.05 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.762992268308587, ce=47.251255245383724
Local test acc @ epoch 103: 0.961
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.9 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7652947771439859, ce=47.26142795807725
Local test acc @ epoch 103: 0.961
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.81 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.76249773349237, ce=47.424425877562356
Local test acc @ epoch 103: 0.961
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.0 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7621384782528658, ce=47.337655093691765
Local test acc @ epoch 103: 0.961
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.91 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.762243839578891, ce=47.433421388678596
Local test acc @ epoch 103: 0.961
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.86 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7632880057763616, ce=47.337807996557395
Local test acc @ epoch 103: 0.961
Global evaluate on test data...
Evaluate data in 82.96 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.762948243989857, ce=47.34605316722065
Global test acc : 0.961
Global prompt norm: 57.83955001831055
Global epoch 104...
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.99 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7587973502797818, ce=47.465453121640266
Local test acc @ epoch 104: 0.961
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.9 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7576697507035841, ce=47.56878816097154
Local test acc @ epoch 104: 0.961
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.96 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7608758856397156, ce=47.48919877218544
Local test acc @ epoch 104: 0.961
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.1 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7573692054923521, ce=47.681745826651195
Local test acc @ epoch 104: 0.961
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.02 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7550588091579052, ce=47.567772996535
Local test acc @ epoch 104: 0.961
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.1 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.761511671433755, ce=47.495149839908706
Local test acc @ epoch 104: 0.961
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.05 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7583163353281284, ce=47.59852999065994
Local test acc @ epoch 104: 0.961
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.0 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7585844228027063, ce=47.5767167817562
Local test acc @ epoch 104: 0.961
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.02 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7575678212927022, ce=47.62218629329576
Local test acc @ epoch 104: 0.961
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.02 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7575543233014028, ce=47.67513604120377
Local test acc @ epoch 104: 0.961
Global evaluate on test data...
Evaluate data in 83.02 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7584047142518769, ce=47.577704998331335
Global test acc : 0.961
Global prompt norm: 57.83777618408203
Global epoch 105...
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.18 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7518491591882268, ce=47.95032161747644
Local test acc @ epoch 105: 0.961
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.17 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7541183812902608, ce=47.69519483933755
Local test acc @ epoch 105: 0.961
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.87 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7525714690532159, ce=47.86581039428711
Local test acc @ epoch 105: 0.961
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.95 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7567847168773686, ce=47.72736607122859
Local test acc @ epoch 105: 0.961
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.08 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7526401664138934, ce=47.817726730206694
Local test acc @ epoch 105: 0.961
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.99 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7559470867891924, ce=47.733349441388334
Local test acc @ epoch 105: 0.961
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.02 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7528087874071314, ce=47.864103229767686
Local test acc @ epoch 105: 0.961
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.98 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7519502289798281, ce=47.94617640644039
Local test acc @ epoch 105: 0.961
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.93 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7501999347581776, ce=47.79722840195402
Local test acc @ epoch 105: 0.961
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.21 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.753264757471347, ce=47.83451811764218
Local test acc @ epoch 105: 0.961
Global evaluate on test data...
Evaluate data in 83.12 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7532946363501593, ce=47.82732279366309
Global test acc : 0.961
Global prompt norm: 57.83589553833008
Global epoch 106...
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.08 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7503630130662831, ce=47.99820243765455
Local test acc @ epoch 106: 0.961
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.04 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7464589613293289, ce=48.15489893222074
Local test acc @ epoch 106: 0.961
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.09 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.748821459778952, ce=47.9442851915272
Local test acc @ epoch 106: 0.961
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7446934805003875, ce=48.0463098298519
Local test acc @ epoch 106: 0.961
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.97 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7471358273007455, ce=48.116630239224214
Local test acc @ epoch 106: 0.961
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.28 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7454938997916125, ce=48.243088818471364
Local test acc @ epoch 106: 0.961
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.94 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7514522644357944, ce=47.97942450287145
Local test acc @ epoch 106: 0.961
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.08 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7454809136346939, ce=48.24477235986552
Local test acc @ epoch 106: 0.961
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.03 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7468966344080934, ce=48.08911188808056
Local test acc @ epoch 106: 0.961
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.98 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7469058583635803, ce=48.13091243078949
Local test acc @ epoch 106: 0.961
Global evaluate on test data...
Evaluate data in 83.0 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7474640443784382, ce=48.09962676861964
Global test acc : 0.961
Global prompt norm: 57.833805084228516
Global epoch 107...
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.97 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.7383601184285015, ce=48.32022672180736
Local test acc @ epoch 107: 0.9622
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.72 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.7402101700459052, ce=48.38977572239867
Local test acc @ epoch 107: 0.9622
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.84 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.7427296397882864, ce=48.2182841519697
Local test acc @ epoch 107: 0.9622
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.95 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.7379936122019356, ce=48.57324029764998
Local test acc @ epoch 107: 0.9622
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.88 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.7399311175040149, ce=48.43044886457811
Local test acc @ epoch 107: 0.9622
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.94 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.7389799367397203, ce=48.478841134167595
Local test acc @ epoch 107: 0.9622
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.22 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.7378927830162398, ce=48.574252592314274
Local test acc @ epoch 107: 0.9622
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.98 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.7453287019642121, ce=48.256845106772325
Local test acc @ epoch 107: 0.9622
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.13 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.7439273781732682, ce=48.2900320980527
Local test acc @ epoch 107: 0.9622
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.95 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.7403778373648268, ce=48.42350184589351
Local test acc @ epoch 107: 0.9622
Global evaluate on test data...
Evaluate data in 82.89 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.7406909115817568, ce=48.401426577786786
Global test acc : 0.9622
Global prompt norm: 57.83147430419922
Global epoch 108...
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.09 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.7301786755203107, ce=48.94700773046651
Local test acc @ epoch 108: 0.9622
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.2 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.7309419671329883, ce=48.62605614618424
Local test acc @ epoch 108: 0.9622
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.98 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.7355917112542949, ce=48.524275893465095
Local test acc @ epoch 108: 0.9622
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.85 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.7324768031409027, ce=48.72871111948556
Local test acc @ epoch 108: 0.9622
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.84 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.7306044036095295, ce=48.95108959652962
Local test acc @ epoch 108: 0.9622
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.93 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.733067575944673, ce=48.751878020960255
Local test acc @ epoch 108: 0.9622
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.95 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.7381627275309431, ce=48.567217695603674
Local test acc @ epoch 108: 0.9622
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.92 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.7323994308436682, ce=48.786653046214255
Local test acc @ epoch 108: 0.9622
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.9 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.7316765216512418, ce=48.847402940102675
Local test acc @ epoch 108: 0.9622
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.89 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.7363711803331288, ce=48.61674167038104
Local test acc @ epoch 108: 0.9622
Global evaluate on test data...
Evaluate data in 82.75 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.7329483797790808, ce=48.74210448658794
Global test acc : 0.9622
Global prompt norm: 57.82872772216797
Global epoch 109...
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.86 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7258874560714862, ce=49.278093635489086
Local test acc @ epoch 109: 0.9599
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.9 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.7329842934914685, ce=48.92169668915075
Local test acc @ epoch 109: 0.9622
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.02 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.7266796575773746, ce=49.120008521123765
Local test acc @ epoch 109: 0.9622
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.94 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7269190035828756, ce=49.2016771649002
Local test acc @ epoch 109: 0.961
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.72 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.7258123389077843, ce=48.97424676877643
Local test acc @ epoch 109: 0.9622
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.21 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.7272905690954365, ce=49.12839942022201
Local test acc @ epoch 109: 0.9622
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.94 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.7302092521562489, ce=48.990596806237455
Local test acc @ epoch 109: 0.9622
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.7284778323742228, ce=48.87329920497509
Local test acc @ epoch 109: 0.9622
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7240579784463305, ce=49.3836555480957
Local test acc @ epoch 109: 0.961
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.85 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7245183078520888, ce=49.391350247444365
Local test acc @ epoch 109: 0.9599
Global evaluate on test data...
Evaluate data in 83.04 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.7274590479124576, ce=49.13614084086287
Global test acc : 0.9622
Global prompt norm: 57.82549285888672
Global epoch 110...
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.99 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7190546595722164, ce=49.80083171599502
Local test acc @ epoch 110: 0.9599
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.75 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7169764894957936, ce=49.91276921263528
Local test acc @ epoch 110: 0.9599
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.85 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7206252277444262, ce=49.3809737109263
Local test acc @ epoch 110: 0.9599
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7236484475092057, ce=49.282748091111486
Local test acc @ epoch 110: 0.961
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.88 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7286066549633621, ce=49.338155763958575
Local test acc @ epoch 110: 0.9599
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.82 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7211273832058688, ce=49.58637762507168
Local test acc @ epoch 110: 0.9599
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.91 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7176382913501984, ce=49.92515780947624
Local test acc @ epoch 110: 0.9599
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.81 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.722035637689293, ce=49.572403094090454
Local test acc @ epoch 110: 0.9599
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.92 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7207718748565114, ce=49.70366675700616
Local test acc @ epoch 110: 0.9599
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.96 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.724869052204517, ce=49.431618331769194
Local test acc @ epoch 110: 0.9599
Global evaluate on test data...
Evaluate data in 82.99 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7217140328993491, ce=49.60751636750108
Global test acc : 0.9599
Global prompt norm: 57.82152557373047
Global epoch 111...
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.9587155963302753, hinge=0.706638554914282, ce=50.58950679674061
Local test acc @ epoch 111: 0.9587
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7178410127622272, ce=49.78373935244499
Local test acc @ epoch 111: 0.9599
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.9 seconds!
[tester] 
SST2Metric: acc=0.9587155963302753, hinge=0.7075215392156479, ce=50.60851501324855
Local test acc @ epoch 111: 0.9587
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.9 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7140421823624077, ce=50.168798744131664
Local test acc @ epoch 111: 0.9599
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.88 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7184704553096666, ce=49.974576792585744
Local test acc @ epoch 111: 0.9599
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.98 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7137831635431412, ce=49.87432581350344
Local test acc @ epoch 111: 0.9599
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.93 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7237039356056704, ce=49.848145581166676
Local test acc @ epoch 111: 0.9599
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.99 seconds!
[tester] 
SST2Metric: acc=0.9587155963302753, hinge=0.7095289624065434, ce=50.47188725602736
Local test acc @ epoch 111: 0.9587
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.69 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7154507155812114, ce=50.11772561729501
Local test acc @ epoch 111: 0.9599
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.01 seconds!
[tester] 
SST2Metric: acc=0.9587155963302753, hinge=0.7118165821110437, ce=50.34513043044904
Local test acc @ epoch 111: 0.9587
Global evaluate on test data...
Evaluate data in 83.0 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7143221513940654, ce=50.20024073889496
Global test acc : 0.9599
Global prompt norm: 57.816322326660156
Global epoch 112...
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.92 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7053276027014496, ce=50.508130379773064
Local test acc @ epoch 112: 0.9599
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.81 seconds!
[tester] 
SST2Metric: acc=0.9587155963302753, hinge=0.7103902353059262, ce=50.4410186907567
Local test acc @ epoch 112: 0.9587
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.87 seconds!
[tester] 
SST2Metric: acc=0.9587155963302753, hinge=0.7166037778241918, ce=50.515378514561085
Local test acc @ epoch 112: 0.9587
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.15 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.6916501675177058, ce=51.563381440048914
Local test acc @ epoch 112: 0.9599
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.72 seconds!
[tester] 
SST2Metric: acc=0.9587155963302753, hinge=0.7033801647501254, ce=50.951403276635965
Local test acc @ epoch 112: 0.9587
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.92 seconds!
[tester] 
SST2Metric: acc=0.9587155963302753, hinge=0.6897749069633834, ce=51.53258111936237
Local test acc @ epoch 112: 0.9587
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.02 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.6936686935774777, ce=51.41703418416714
Local test acc @ epoch 112: 0.9599
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.89 seconds!
[tester] 
SST2Metric: acc=0.9587155963302753, hinge=0.7088078752570196, ce=50.690425312847175
Local test acc @ epoch 112: 0.9587
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.82 seconds!
[tester] 
SST2Metric: acc=0.9587155963302753, hinge=0.7057176554968597, ce=50.83054033331915
Local test acc @ epoch 112: 0.9587
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.79 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.6971467175614943, ce=51.24339059952202
Local test acc @ epoch 112: 0.9599
Global evaluate on test data...
Evaluate data in 83.02 seconds!
[tester] 
SST2Metric: acc=0.9587155963302753, hinge=0.7031922646618765, ce=51.008318979805765
Global test acc : 0.9587
Global prompt norm: 57.8087158203125
Global epoch 113...
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.99 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7012774922432156, ce=51.4399270223915
Local test acc @ epoch 113: 0.9599
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.84 seconds!
[tester] 
SST2Metric: acc=0.9541284403669725, hinge=0.6787660974975026, ce=53.00430658322956
Local test acc @ epoch 113: 0.9541
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.82 seconds!
[tester] 
SST2Metric: acc=0.9575688073394495, hinge=0.6640040721368352, ce=53.06258094857592
Local test acc @ epoch 113: 0.9576
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9564220183486238, hinge=0.6803994441251142, ce=52.73139845121891
Local test acc @ epoch 113: 0.9564
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.98 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7066799522539892, ce=51.50359351481866
Local test acc @ epoch 113: 0.9599
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.81 seconds!
[tester] 
SST2Metric: acc=0.9587155963302753, hinge=0.6911579272068968, ce=51.86598030580293
Local test acc @ epoch 113: 0.9587
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.87 seconds!
[tester] 
SST2Metric: acc=0.9587155963302753, hinge=0.6917900470418668, ce=51.41515500829854
Local test acc @ epoch 113: 0.9587
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.97 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.6893585187579514, ce=52.15068075197552
Local test acc @ epoch 113: 0.9599
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.9 seconds!
[tester] 
SST2Metric: acc=0.9552752293577982, hinge=0.673229112537629, ce=53.12764344521619
Local test acc @ epoch 113: 0.9553
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.88 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.6944936568583917, ce=51.761990713416985
Local test acc @ epoch 113: 0.9599
Global evaluate on test data...
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.6873480376847293, ce=52.28796530207363
Global test acc : 0.9599
Global prompt norm: 57.795753479003906
Global epoch 114...
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.6463663293681013, ce=53.19726908972504
Local test acc @ epoch 114: 0.9599
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.9541284403669725, hinge=0.6743689983262928, ce=53.958600490465074
Local test acc @ epoch 114: 0.9541
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.07 seconds!
[tester] 
SST2Metric: acc=0.9552752293577982, hinge=0.6756092474001263, ce=53.132236900679565
Local test acc @ epoch 114: 0.9553
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.88 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.7340800237218175, ce=48.84449176613344
Local test acc @ epoch 114: 0.9622
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.87 seconds!
[tester] 
SST2Metric: acc=0.9541284403669725, hinge=0.6706079036817638, ce=54.59058772095847
Local test acc @ epoch 114: 0.9541
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.01 seconds!
[tester] 
SST2Metric: acc=0.9541284403669725, hinge=0.6727707714115808, ce=53.743844723482745
Local test acc @ epoch 114: 0.9541
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.06 seconds!
[tester] 
SST2Metric: acc=0.9541284403669725, hinge=0.6239665145174079, ce=56.42514692534
Local test acc @ epoch 114: 0.9541
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.87 seconds!
[tester] 
SST2Metric: acc=0.9518348623853211, hinge=0.712991412626494, ce=54.06409027379587
Local test acc @ epoch 114: 0.9518
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.9802320611338473e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.89 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.7170068364624583, ce=48.83893210734796
Local test acc @ epoch 114: 0.9622
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.85 seconds!
[tester] 
SST2Metric: acc=0.9529816513761468, hinge=0.6951740816098835, ce=53.50748692083796
Local test acc @ epoch 114: 0.953
Global evaluate on test data...
Evaluate data in 83.05 seconds!
[tester] 
SST2Metric: acc=0.9587155963302753, hinge=0.6589282105822082, ce=53.37726530022577
Global test acc : 0.9587
Global prompt norm: 57.7721061706543
Global epoch 115...
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 4.470348002882929e-08
Local loss @ local epoch 4: 3.129240440102876e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.01 seconds!
[tester] 
SST2Metric: acc=0.9174311926605505, hinge=1.6877663944839338, ce=28.03787569168511
Local test acc @ epoch 115: 0.9174
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.9802320611338473e-08
Local loss @ local epoch 4: 2.9802320611338473e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.81 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.8530945865386123, ce=39.9854674383041
Local test acc @ epoch 115: 0.9599
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.82 seconds!
[tester] 
SST2Metric: acc=0.9552752293577982, hinge=0.8997170443928569, ce=41.58049084724636
Local test acc @ epoch 115: 0.9553
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.92 seconds!
[tester] 
SST2Metric: acc=0.9529816513761468, hinge=0.6301040386934893, ce=56.34493031633009
Local test acc @ epoch 115: 0.953
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.9802320611338473e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.89 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.6950700479909915, ce=51.38800038328958
Local test acc @ epoch 115: 0.9599
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.89 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.7180503464620048, ce=50.12831717674885
Local test acc @ epoch 115: 0.9622
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.75 seconds!
[tester] 
SST2Metric: acc=0.9541284403669725, hinge=0.624787492489596, ce=56.48599362154619
Local test acc @ epoch 115: 0.9541
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 4.470348002882929e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.01 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7267220282773359, ce=49.35115373243979
Local test acc @ epoch 115: 0.9599
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.99 seconds!
[tester] 
SST2Metric: acc=0.9438073394495413, hinge=1.001416020437118, ce=42.415155953223554
Local test acc @ epoch 115: 0.9438
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.76 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.6935664273183281, ce=49.425965370388205
Local test acc @ epoch 115: 0.9622
Global evaluate on test data...
Evaluate data in 82.91 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8003475075468011, ce=47.566468405067376
Global test acc : 0.961
Global prompt norm: 57.817142486572266
Global epoch 116...
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.88 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.77708778906306, ce=49.205826610600184
Local test acc @ epoch 116: 0.961
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7857357471361073, ce=48.564046667256484
Local test acc @ epoch 116: 0.961
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.0 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7753490526741798, ce=49.38695743105827
Local test acc @ epoch 116: 0.9599
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.03 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7662848376352852, ce=49.55018801207936
Local test acc @ epoch 116: 0.9599
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.93 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7911098397106205, ce=48.24398933200661
Local test acc @ epoch 116: 0.961
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.81 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7874419951657636, ce=48.478458929499354
Local test acc @ epoch 116: 0.961
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.84 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7803373118059351, ce=48.80796477991507
Local test acc @ epoch 116: 0.961
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.03 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.762159365032791, ce=49.665970793557825
Local test acc @ epoch 116: 0.9599
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.85 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7878786861349684, ce=48.378263141037124
Local test acc @ epoch 116: 0.961
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.89 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7926897652652285, ce=48.09157751240861
Local test acc @ epoch 116: 0.961
Global evaluate on test data...
Evaluate data in 82.97 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7810558157229642, ce=48.872552679219375
Global test acc : 0.961
Global prompt norm: 57.81144714355469
Global epoch 117...
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.96 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7678926034804878, ce=49.653490643982494
Local test acc @ epoch 117: 0.9599
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.76 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7593846167993108, ce=50.311331162758925
Local test acc @ epoch 117: 0.9599
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.87 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7620072299187336, ce=49.86907056056032
Local test acc @ epoch 117: 0.9599
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.03 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7718314380820738, ce=49.48988741253494
Local test acc @ epoch 117: 0.9599
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.85 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7733953349087217, ce=49.3317945287862
Local test acc @ epoch 117: 0.9599
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.79 seconds!
[tester] 
SST2Metric: acc=0.9587155963302753, hinge=0.7473087004565317, ce=50.44931348748163
Local test acc @ epoch 117: 0.9587
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.1 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7511666542893156, ce=50.32844326474251
Local test acc @ epoch 117: 0.9599
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.93 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7613666254446048, ce=50.17847386631397
Local test acc @ epoch 117: 0.9599
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.75 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.768766333203797, ce=49.557170937914364
Local test acc @ epoch 117: 0.9599
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.86 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7679718809390287, ce=49.69012808143546
Local test acc @ epoch 117: 0.9599
Global evaluate on test data...
Evaluate data in 82.85 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7635369607067983, ce=49.91321196249866
Global test acc : 0.9599
Global prompt norm: 57.80614471435547
Global epoch 118...
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.91 seconds!
[tester] 
SST2Metric: acc=0.9587155963302753, hinge=0.7505222416799003, ce=50.69478246706341
Local test acc @ epoch 118: 0.9587
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.87 seconds!
[tester] 
SST2Metric: acc=0.9587155963302753, hinge=0.7523146769322386, ce=50.516160317517205
Local test acc @ epoch 118: 0.9587
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.99 seconds!
[tester] 
SST2Metric: acc=0.9587155963302753, hinge=0.7532107501948645, ce=50.501575749948486
Local test acc @ epoch 118: 0.9587
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.98 seconds!
[tester] 
SST2Metric: acc=0.9587155963302753, hinge=0.7538256776442221, ce=50.5473846295558
Local test acc @ epoch 118: 0.9587
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.93 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.736848673689256, ce=51.03845666307922
Local test acc @ epoch 118: 0.961
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7504453484071504, ce=50.875271893422536
Local test acc @ epoch 118: 0.961
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.91 seconds!
[tester] 
SST2Metric: acc=0.9587155963302753, hinge=0.7466110089503297, ce=50.71121740778652
Local test acc @ epoch 118: 0.9587
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.08 seconds!
[tester] 
SST2Metric: acc=0.9587155963302753, hinge=0.7557711076298985, ce=50.36830338644325
Local test acc @ epoch 118: 0.9587
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.79 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7408695964638247, ce=50.884240596666245
Local test acc @ epoch 118: 0.9599
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.05 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7462307772505175, ce=51.0554570539282
Local test acc @ epoch 118: 0.961
Global evaluate on test data...
Evaluate data in 82.73 seconds!
[tester] 
SST2Metric: acc=0.9587155963302753, hinge=0.7487024079769029, ce=50.742819514843305
Global test acc : 0.9587
Global prompt norm: 57.80166244506836
Global epoch 119...
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.89 seconds!
[tester] 
SST2Metric: acc=0.9587155963302753, hinge=0.7319545308384326, ce=51.55728443390733
Local test acc @ epoch 119: 0.9587
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.85 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7381188016419017, ce=51.51064622511557
Local test acc @ epoch 119: 0.9599
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7385693908831396, ce=51.384673302326725
Local test acc @ epoch 119: 0.9599
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7352531634339499, ce=51.45370791373997
Local test acc @ epoch 119: 0.9599
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.73 seconds!
[tester] 
SST2Metric: acc=0.9587155963302753, hinge=0.7437388875068874, ce=51.449611908798914
Local test acc @ epoch 119: 0.9587
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.76 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7351630455857023, ce=51.37429165621416
Local test acc @ epoch 119: 0.9599
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.12 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7370578608381639, ce=51.70974150491417
Local test acc @ epoch 119: 0.9599
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.93 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.7409145678948919, ce=51.30623525217039
Local test acc @ epoch 119: 0.961
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.79 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.735642328174836, ce=51.607133567880055
Local test acc @ epoch 119: 0.9599
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.81 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.742492268938537, ce=51.24467282776439
Local test acc @ epoch 119: 0.9599
Global evaluate on test data...
Evaluate data in 82.85 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7377842806894844, ce=51.48338461359707
Global test acc : 0.9599
Global prompt norm: 57.79746627807617
Global epoch 120...
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.76 seconds!
[tester] 
SST2Metric: acc=0.9587155963302753, hinge=0.7264414489816088, ce=52.3594702974372
Local test acc @ epoch 120: 0.9587
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.76 seconds!
[tester] 
SST2Metric: acc=0.9587155963302753, hinge=0.7215155374019517, ce=52.62811944244105
Local test acc @ epoch 120: 0.9587
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.84 seconds!
[tester] 
SST2Metric: acc=0.9575688073394495, hinge=0.7300459791760926, ce=51.95524943640473
Local test acc @ epoch 120: 0.9576
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.95 seconds!
[tester] 
SST2Metric: acc=0.9575688073394495, hinge=0.7242779381778262, ce=52.56465008936891
Local test acc @ epoch 120: 0.9576
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.9575688073394495, hinge=0.728014862865483, ce=52.32866346726724
Local test acc @ epoch 120: 0.9576
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.89 seconds!
[tester] 
SST2Metric: acc=0.9575688073394495, hinge=0.7380293312422727, ce=52.089740578187715
Local test acc @ epoch 120: 0.9576
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.97 seconds!
[tester] 
SST2Metric: acc=0.9575688073394495, hinge=0.7263574468980142, ce=52.2736268699716
Local test acc @ epoch 120: 0.9576
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9575688073394495, hinge=0.733316474004623, ce=52.05077999009998
Local test acc @ epoch 120: 0.9576
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.81 seconds!
[tester] 
SST2Metric: acc=0.9575688073394495, hinge=0.7284875222302358, ce=52.433980889276626
Local test acc @ epoch 120: 0.9576
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.92 seconds!
[tester] 
SST2Metric: acc=0.9575688073394495, hinge=0.7254268357513147, ce=52.15283262620279
Local test acc @ epoch 120: 0.9576
Global evaluate on test data...
Evaluate data in 82.92 seconds!
[tester] 
SST2Metric: acc=0.9575688073394495, hinge=0.7286777802563589, ce=52.31436412706287
Global test acc : 0.9576
Global prompt norm: 57.7923698425293
Global epoch 121...
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.9575688073394495, hinge=0.7195235567355375, ce=53.13283335834468
Local test acc @ epoch 121: 0.9576
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.88 seconds!
[tester] 
SST2Metric: acc=0.9575688073394495, hinge=0.7297238078686076, ce=53.00719924366802
Local test acc @ epoch 121: 0.9576
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.05 seconds!
[tester] 
SST2Metric: acc=0.9575688073394495, hinge=0.7217240071077959, ce=52.805149393344145
Local test acc @ epoch 121: 0.9576
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.85 seconds!
[tester] 
SST2Metric: acc=0.9575688073394495, hinge=0.7153267597933428, ce=53.42705941856454
Local test acc @ epoch 121: 0.9576
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.95 seconds!
[tester] 
SST2Metric: acc=0.9552752293577982, hinge=0.7090663953658638, ce=53.76355344439865
Local test acc @ epoch 121: 0.9553
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.67 seconds!
[tester] 
SST2Metric: acc=0.9575688073394495, hinge=0.7129799335374745, ce=52.98731095200285
Local test acc @ epoch 121: 0.9576
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.85 seconds!
[tester] 
SST2Metric: acc=0.9575688073394495, hinge=0.6987154724401071, ce=54.09040017084244
Local test acc @ epoch 121: 0.9576
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9575688073394495, hinge=0.7124368072649755, ce=53.41692905251039
Local test acc @ epoch 121: 0.9576
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.9564220183486238, hinge=0.7055970463184041, ce=54.03828559665505
Local test acc @ epoch 121: 0.9564
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.99 seconds!
[tester] 
SST2Metric: acc=0.9564220183486238, hinge=0.7114556688781178, ce=53.76437955383861
Local test acc @ epoch 121: 0.9564
Global evaluate on test data...
Evaluate data in 82.94 seconds!
[tester] 
SST2Metric: acc=0.9575688073394495, hinge=0.7137091619159104, ce=53.50185646267112
Global test acc : 0.9576
Global prompt norm: 57.783870697021484
Global epoch 122...
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.04 seconds!
[tester] 
SST2Metric: acc=0.9518348623853211, hinge=0.6583778180113626, ce=57.04696795262328
Local test acc @ epoch 122: 0.9518
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.93 seconds!
[tester] 
SST2Metric: acc=0.9529816513761468, hinge=0.7019058367527953, ce=55.12588455480173
Local test acc @ epoch 122: 0.953
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.82 seconds!
[tester] 
SST2Metric: acc=0.9541284403669725, hinge=0.6974470943485925, ce=55.1516826524647
Local test acc @ epoch 122: 0.9541
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.81 seconds!
[tester] 
SST2Metric: acc=0.9529816513761468, hinge=0.7256899011244468, ce=54.63924281968983
Local test acc @ epoch 122: 0.953
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.72 seconds!
[tester] 
SST2Metric: acc=0.9529816513761468, hinge=0.6944129007671951, ce=55.613765086602726
Local test acc @ epoch 122: 0.953
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.24 seconds!
[tester] 
SST2Metric: acc=0.9541284403669725, hinge=0.7002156458863424, ce=54.508310615469554
Local test acc @ epoch 122: 0.9541
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.9587155963302753, hinge=0.6739293107199013, ce=53.019258726627456
Local test acc @ epoch 122: 0.9587
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9518348623853211, hinge=0.6589966957722235, ce=56.86351552140822
Local test acc @ epoch 122: 0.9518
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9529816513761468, hinge=0.6446137340790635, ce=57.06813392289188
Local test acc @ epoch 122: 0.953
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9529816513761468, hinge=0.7213618514734671, ce=54.8483942364334
Local test acc @ epoch 122: 0.953
Global evaluate on test data...
Evaluate data in 82.86 seconds!
[tester] 
SST2Metric: acc=0.9529816513761468, hinge=0.6876626670907396, ce=55.58239749593472
Global test acc : 0.953
Global prompt norm: 57.76197814941406
Global epoch 123...
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.9426605504587156, hinge=1.2232726451453813, ce=34.10693574607919
Local test acc @ epoch 123: 0.9427
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.9802320611338473e-08
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.9 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.8355934357424395, ce=34.66666456100044
Local test acc @ epoch 123: 0.961
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 2.9802320611338473e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.2 seconds!
[tester] 
SST2Metric: acc=0.9575688073394495, hinge=0.8006048968078894, ce=46.85416447350738
Local test acc @ epoch 123: 0.9576
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.02 seconds!
[tester] 
SST2Metric: acc=0.9575688073394495, hinge=0.8124738855099459, ce=31.481939648269513
Local test acc @ epoch 123: 0.9576
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 2.9802320611338473e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.81 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.7195476348247003, ce=26.94923586364186
Local test acc @ epoch 123: 0.9633
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.3884994611827606, ce=39.86958823947732
Local test acc @ epoch 123: 0.9369
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.76 seconds!
[tester] 
SST2Metric: acc=0.9598623853211009, hinge=0.7059970908208725, ce=52.8353845438826
Local test acc @ epoch 123: 0.9599
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.9802320611338473e-08
Local loss @ local epoch 4: 4.470348002882929e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.86 seconds!
[tester] 
SST2Metric: acc=0.9587155963302753, hinge=0.8638529755653591, ce=38.823084245034316
Local test acc @ epoch 123: 0.9587
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.9802320611338473e-08
Local loss @ local epoch 2: 1.3411039390121005e-07
Local loss @ local epoch 3: 4.470347647611561e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.72 seconds!
[tester] 
SST2Metric: acc=0.9369266055045872, hinge=1.2714023983806646, ce=16.9901084374944
Local test acc @ epoch 123: 0.9369
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 5.9604641222676946e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9541284403669725, hinge=0.9082964319701589, ce=29.78832314867492
Local test acc @ epoch 123: 0.9541
Global evaluate on test data...
Evaluate data in 82.85 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8561980439982283, ce=34.00660500832654
Global test acc : 0.9622
Global prompt norm: 57.92500686645508
Global epoch 124...
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.86 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8577451465326712, ce=34.163586887744586
Local test acc @ epoch 124: 0.9622
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.86089370010096, ce=34.43220560266337
Local test acc @ epoch 124: 0.9622
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.01 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8594229768175597, ce=34.318576392777466
Local test acc @ epoch 124: 0.9622
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.88 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8585518915718848, ce=34.25247040144894
Local test acc @ epoch 124: 0.9622
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.95 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8596697969174166, ce=34.33161971765921
Local test acc @ epoch 124: 0.9622
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8592354201395577, ce=34.29037043370238
Local test acc @ epoch 124: 0.9622
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.9 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8610621854799603, ce=34.45696961989096
Local test acc @ epoch 124: 0.9622
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.85 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8591588615277491, ce=34.29146311698704
Local test acc @ epoch 124: 0.9622
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.69 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8575763461786673, ce=34.1632522618005
Local test acc @ epoch 124: 0.9622
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.73 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.861395424659099, ce=34.45794264767148
Local test acc @ epoch 124: 0.9622
Global evaluate on test data...
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8594819996335091, ce=34.31598299358963
Global test acc : 0.9622
Global prompt norm: 57.92430877685547
Global epoch 125...
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.91 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8635013365964277, ce=34.70729743887525
Local test acc @ epoch 125: 0.9622
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.03 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8606414116850687, ce=34.457947494786815
Local test acc @ epoch 125: 0.9622
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.862143107510488, ce=34.58838427832367
Local test acc @ epoch 125: 0.9622
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.7 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8614467349621134, ce=34.53496247037835
Local test acc @ epoch 125: 0.9622
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.86341684236439, ce=34.69040767424697
Local test acc @ epoch 125: 0.9622
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.92 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8620097112218175, ce=34.56666386455571
Local test acc @ epoch 125: 0.9622
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.73 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8637775324900215, ce=34.708729227748485
Local test acc @ epoch 125: 0.9622
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.7 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8607800619317851, ce=34.45667237098064
Local test acc @ epoch 125: 0.9622
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.92 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8623422832664, ce=34.59884801042189
Local test acc @ epoch 125: 0.9622
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.84 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8619141578674316, ce=34.56319530732041
Local test acc @ epoch 125: 0.9622
Global evaluate on test data...
Evaluate data in 82.72 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8622042389091001, ce=34.58746115658261
Global test acc : 0.9622
Global prompt norm: 57.92373275756836
Global epoch 126...
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.99 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8644491466907186, ce=34.82975438319215
Local test acc @ epoch 126: 0.9622
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8656040550371923, ce=34.93384219528338
Local test acc @ epoch 126: 0.9622
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.7 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8646172777228399, ce=34.83842884728668
Local test acc @ epoch 126: 0.9622
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.67 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8633144208050649, ce=34.71569196018604
Local test acc @ epoch 126: 0.9622
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.91 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8643498486335125, ce=34.81288358705853
Local test acc @ epoch 126: 0.9622
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.863879527520696, ce=34.78599747824013
Local test acc @ epoch 126: 0.9622
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8655727084623565, ce=34.92252120621708
Local test acc @ epoch 126: 0.9622
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.85 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8658401441136632, ce=34.93588578810385
Local test acc @ epoch 126: 0.9622
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.0 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8642529128888331, ce=34.80615859075424
Local test acc @ epoch 126: 0.9622
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.7 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8631963620492078, ce=34.71813982342361
Local test acc @ epoch 126: 0.9622
Global evaluate on test data...
Evaluate data in 82.92 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8645153504992844, ce=34.83006118634425
Global test acc : 0.9622
Global prompt norm: 57.923099517822266
Global epoch 127...
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.86 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8663623223610974, ce=35.03547580963975
Local test acc @ epoch 127: 0.9622
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8653733314724144, ce=34.95183258756585
Local test acc @ epoch 127: 0.9622
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8662601873415325, ce=35.02638669845161
Local test acc @ epoch 127: 0.9622
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8676340208141082, ce=35.14368958429459
Local test acc @ epoch 127: 0.9622
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.95 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8674335239130423, ce=35.13378073316102
Local test acc @ epoch 127: 0.9622
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8674310981680494, ce=35.14101061689745
Local test acc @ epoch 127: 0.9622
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.92 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8654742240905762, ce=34.948574486128784
Local test acc @ epoch 127: 0.9622
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.96 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8659626803266893, ce=35.01245017445415
Local test acc @ epoch 127: 0.9622
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.94 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8665757551105744, ce=35.05601821689431
Local test acc @ epoch 127: 0.9622
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.07 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8664360352612417, ce=35.048799742252456
Local test acc @ epoch 127: 0.9622
Global evaluate on test data...
Evaluate data in 82.69 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.866500207043569, ce=35.04987812917167
Global test acc : 0.9622
Global prompt norm: 57.92258834838867
Global epoch 128...
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8680129401180723, ce=35.22828917547103
Local test acc @ epoch 128: 0.9622
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.91 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8682923601308, ce=35.25587262144876
Local test acc @ epoch 128: 0.9622
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.67 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8692344109946435, ce=35.335735636019926
Local test acc @ epoch 128: 0.9622
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.76 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8690938424626622, ce=35.33257127464364
Local test acc @ epoch 128: 0.9622
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8677705559161825, ce=35.219265036626695
Local test acc @ epoch 128: 0.9622
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.76 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8673465470655248, ce=35.16057096708805
Local test acc @ epoch 128: 0.9622
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.87 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8681140033476943, ce=35.23929310719901
Local test acc @ epoch 128: 0.9622
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8672562192339416, ce=35.16445721617532
Local test acc @ epoch 128: 0.9622
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.86 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8692011111373201, ce=35.32830693306179
Local test acc @ epoch 128: 0.9622
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.98 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8681693733285326, ce=35.249772325568244
Local test acc @ epoch 128: 0.9622
Global evaluate on test data...
Evaluate data in 82.75 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8682310274981577, ce=35.25149313900449
Global test acc : 0.9622
Global prompt norm: 57.92208480834961
Global epoch 129...
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.66 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8709792194016482, ce=35.51435537075778
Local test acc @ epoch 129: 0.9622
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.84 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8700490697808222, ce=35.44101926821087
Local test acc @ epoch 129: 0.9622
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.88 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.869985147353706, ce=35.427485754730505
Local test acc @ epoch 129: 0.9622
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.88 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8690518545448234, ce=35.355735148858585
Local test acc @ epoch 129: 0.9622
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.79 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8708579868351648, ce=35.51058494497877
Local test acc @ epoch 129: 0.9622
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.76 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8699484549531149, ce=35.43573537004103
Local test acc @ epoch 129: 0.9622
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.76 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8689715840400906, ce=35.36009433291374
Local test acc @ epoch 129: 0.9622
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8695209595041538, ce=35.41010777884667
Local test acc @ epoch 129: 0.9622
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8709819579343183, ce=35.50873446683271
Local test acc @ epoch 129: 0.9622
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.7 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.869762252230163, ce=35.41510160253682
Local test acc @ epoch 129: 0.9622
Global evaluate on test data...
Evaluate data in 82.99 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8700148293731409, ce=35.43797216502898
Global test acc : 0.9622
Global prompt norm: 57.92160415649414
Global epoch 130...
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8717223460521173, ce=35.6136845929907
Local test acc @ epoch 130: 0.9622
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8714652127082195, ce=35.58922251430126
Local test acc @ epoch 130: 0.9622
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.7 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8725860753190626, ce=35.677250433405604
Local test acc @ epoch 130: 0.9622
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.81 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8716390111030788, ce=35.609135444011166
Local test acc @ epoch 130: 0.9622
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.82 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8725610763654796, ce=35.68169221090614
Local test acc @ epoch 130: 0.9622
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.14 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8716806446740387, ce=35.60270347945187
Local test acc @ epoch 130: 0.9622
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.91 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8724554613095905, ce=35.67724490384443
Local test acc @ epoch 130: 0.9622
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.870841986542448, ce=35.53676580726554
Local test acc @ epoch 130: 0.9622
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.871265008908893, ce=35.58755811638788
Local test acc @ epoch 130: 0.9622
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.82 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.870764854851119, ce=35.54153942843096
Local test acc @ epoch 130: 0.9622
Global evaluate on test data...
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8717012164789603, ce=35.61175043648536
Global test acc : 0.9622
Global prompt norm: 57.9211540222168
Global epoch 131...
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.75 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8731712966883948, ce=35.77179448538964
Local test acc @ epoch 131: 0.9622
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.97 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8732162593701563, ce=35.766865266572445
Local test acc @ epoch 131: 0.9622
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.92 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.874004195589538, ce=35.83923570825419
Local test acc @ epoch 131: 0.9622
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.03 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8724539279937744, ce=35.70595589034054
Local test acc @ epoch 131: 0.9622
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.75 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.872387778868369, ce=35.71101802860925
Local test acc @ epoch 131: 0.9622
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.88 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8740509453169797, ce=35.83573052642542
Local test acc @ epoch 131: 0.9622
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.73 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8732489292774726, ce=35.7758020173519
Local test acc @ epoch 131: 0.9622
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.9 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8739087012929654, ce=35.8343006099036
Local test acc @ epoch 131: 0.9622
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.86 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8728386021535331, ce=35.75362165258565
Local test acc @ epoch 131: 0.9622
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.82 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8730139010543123, ce=35.75245302532791
Local test acc @ epoch 131: 0.9622
Global evaluate on test data...
Evaluate data in 82.85 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8732321896684279, ce=35.77470187965883
Global test acc : 0.9622
Global prompt norm: 57.92069625854492
Global epoch 132...
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.84 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8739251740481875, ce=35.86490876084074
Local test acc @ epoch 132: 0.9622
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.86 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8744202885059041, ce=35.906401153004495
Local test acc @ epoch 132: 0.9622
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.75 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.875240107195093, ce=35.98283722203806
Local test acc @ epoch 132: 0.9622
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8738626711959139, ce=35.87028741399082
Local test acc @ epoch 132: 0.9622
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.93 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8746173928637023, ce=35.92156145988255
Local test acc @ epoch 132: 0.9622
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.76 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8746347711720598, ce=35.92875877870332
Local test acc @ epoch 132: 0.9622
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.91 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8745687664101977, ce=35.92518762710991
Local test acc @ epoch 132: 0.9622
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.72 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8753847332175718, ce=35.98541448750627
Local test acc @ epoch 132: 0.9622
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8753246801708816, ce=35.98830060346411
Local test acc @ epoch 132: 0.9622
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8742763843011419, ce=35.90999690764541
Local test acc @ epoch 132: 0.9622
Global evaluate on test data...
Evaluate data in 82.67 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8746290294402236, ce=35.92836589988219
Global test acc : 0.9622
Global prompt norm: 57.920265197753906
Global epoch 133...
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.03 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8764687568769542, ce=36.12409248702023
Local test acc @ epoch 133: 0.9622
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8755907793657496, ce=36.05802892982413
Local test acc @ epoch 133: 0.9622
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.98 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8759030617705179, ce=36.0681277633807
Local test acc @ epoch 133: 0.9622
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.02 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8752062211342908, ce=36.02080976853677
Local test acc @ epoch 133: 0.9622
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.88 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8759143571241186, ce=36.07385134915693
Local test acc @ epoch 133: 0.9622
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8765461291741887, ce=36.13008506144952
Local test acc @ epoch 133: 0.9622
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.7 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8752651914544062, ce=36.01526386365978
Local test acc @ epoch 133: 0.9622
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.88 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8757171740225695, ce=36.05230775885626
Local test acc @ epoch 133: 0.9622
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.91 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8758542297083304, ce=36.07068161570698
Local test acc @ epoch 133: 0.9622
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.99 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8766131422935276, ce=36.12758751965444
Local test acc @ epoch 133: 0.9633
Global evaluate on test data...
Evaluate data in 82.85 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8759076267207434, ce=36.07408957525131
Global test acc : 0.9622
Global prompt norm: 57.91987609863281
Global epoch 134...
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.76 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8764455537183569, ce=36.16363472894791
Local test acc @ epoch 134: 0.9633
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.85 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8769085319764024, ce=36.19098435848131
Local test acc @ epoch 134: 0.9633
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.9 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8767969455194036, ce=36.19856811663426
Local test acc @ epoch 134: 0.9633
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.89 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8770357250073634, ce=36.2089458430579
Local test acc @ epoch 134: 0.9633
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.93 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8776670333442338, ce=36.26502073795424
Local test acc @ epoch 134: 0.9633
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.12 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8770845133230227, ce=36.207314062555994
Local test acc @ epoch 134: 0.9633
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.01 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.877597837273134, ce=36.258615896242475
Local test acc @ epoch 134: 0.9633
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.95 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8777479753581756, ce=36.262853289962905
Local test acc @ epoch 134: 0.9633
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8770881267862582, ce=36.211811590632166
Local test acc @ epoch 134: 0.9633
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8764975399052332, ce=36.157889234910314
Local test acc @ epoch 134: 0.9633
Global evaluate on test data...
Evaluate data in 82.86 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8770886867418202, ce=36.21252231422914
Global test acc : 0.9633
Global prompt norm: 57.91946029663086
Global epoch 135...
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.69 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8787945607386598, ce=36.39231015126639
Local test acc @ epoch 135: 0.9633
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8775847658104853, ce=36.29957097604734
Local test acc @ epoch 135: 0.9633
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.89 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8780083831297149, ce=36.32337752175987
Local test acc @ epoch 135: 0.9633
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.99 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8779125979187292, ce=36.33254539419752
Local test acc @ epoch 135: 0.9633
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.01 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8786474105414994, ce=36.38741771453017
Local test acc @ epoch 135: 0.9633
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.9 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8781755211156442, ce=36.3401188281698
Local test acc @ epoch 135: 0.9633
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.72 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8787122538330359, ce=36.39429585868066
Local test acc @ epoch 135: 0.9633
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8776363385926693, ce=36.293710411141774
Local test acc @ epoch 135: 0.9633
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.73 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.878127356188013, ce=36.3410027180243
Local test acc @ epoch 135: 0.9633
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.05 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8781787780446744, ce=36.34354792603659
Local test acc @ epoch 135: 0.9633
Global evaluate on test data...
Evaluate data in 82.95 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8781794561158627, ce=36.344814440526
Global test acc : 0.9633
Global prompt norm: 57.9190559387207
Global epoch 136...
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.89 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8786870492707699, ce=36.42360739751693
Local test acc @ epoch 136: 0.9633
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.9 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.879189355657735, ce=36.467387103159496
Local test acc @ epoch 136: 0.9622
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.94 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8797688877910649, ce=36.51627101373235
Local test acc @ epoch 136: 0.9622
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8790283334364585, ce=36.450210641283505
Local test acc @ epoch 136: 0.9622
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.85 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8796783412268402, ce=36.51821794422395
Local test acc @ epoch 136: 0.9622
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8789456415613857, ce=36.46081213994857
Local test acc @ epoch 136: 0.9622
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.99 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8796212782553576, ce=36.51093019257992
Local test acc @ epoch 136: 0.9622
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.88 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8791857093846033, ce=36.469903088490895
Local test acc @ epoch 136: 0.9622
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.91 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8786409579285788, ce=36.42964228358837
Local test acc @ epoch 136: 0.9633
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.97 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8791413963387865, ce=36.4675376612112
Local test acc @ epoch 136: 0.9622
Global evaluate on test data...
Evaluate data in 82.7 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8791926060247859, ce=36.471483913036664
Global test acc : 0.9622
Global prompt norm: 57.91868591308594
Global epoch 137...
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.72 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8798987581095564, ce=36.583874308734856
Local test acc @ epoch 137: 0.9622
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.81 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8801197765070364, ce=36.59117402942903
Local test acc @ epoch 137: 0.9622
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.97 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8800815026694482, ce=36.58905288276323
Local test acc @ epoch 137: 0.9622
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.01 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8801266031527738, ce=36.58946864976795
Local test acc @ epoch 137: 0.9622
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.85 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8796648432355408, ce=36.54813885470049
Local test acc @ epoch 137: 0.9622
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.88 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8805280628554318, ce=36.62977813580714
Local test acc @ epoch 137: 0.9622
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.93 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.880582052633303, ce=36.63739017171597
Local test acc @ epoch 137: 0.9622
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8799757498119949, ce=36.57197063341053
Local test acc @ epoch 137: 0.9622
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8796177807204221, ce=36.554258504045116
Local test acc @ epoch 137: 0.9622
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.7 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8806739444032722, ce=36.63549311226661
Local test acc @ epoch 137: 0.9622
Global evaluate on test data...
Evaluate data in 83.04 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8801312730946672, ce=36.59309345210364
Global test acc : 0.9622
Global prompt norm: 57.91830825805664
Global epoch 138...
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.97 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8809983555330049, ce=36.707894211515374
Local test acc @ epoch 138: 0.9622
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.73 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8815205447170713, ce=36.75038178470157
Local test acc @ epoch 138: 0.9622
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.73 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8807912157216203, ce=36.70225748884569
Local test acc @ epoch 138: 0.9622
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.75 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8805686224491225, ce=36.667816722064934
Local test acc @ epoch 138: 0.9622
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.79 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8805298761490288, ce=36.67399215698242
Local test acc @ epoch 138: 0.9622
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.94 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8813771939058916, ce=36.7443273701799
Local test acc @ epoch 138: 0.9622
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.02 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8809582246552914, ce=36.70593993160703
Local test acc @ epoch 138: 0.9622
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.04 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8814269687057635, ce=36.752324515526446
Local test acc @ epoch 138: 0.9622
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.97 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8808557265395418, ce=36.689066685667825
Local test acc @ epoch 138: 0.9622
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.85 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8810037297940035, ce=36.7068760723149
Local test acc @ epoch 138: 0.9622
Global evaluate on test data...
Evaluate data in 82.9 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8810055387129477, ce=36.710083987734734
Global test acc : 0.9622
Global prompt norm: 57.91794204711914
Global epoch 139...
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.89 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8813737619907485, ce=36.78942755602915
Local test acc @ epoch 139: 0.9622
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.0 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8818210899283033, ce=36.82025902424384
Local test acc @ epoch 139: 0.9622
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.95 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.881416594216583, ce=36.78316193326898
Local test acc @ epoch 139: 0.9622
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.99 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8822158935966842, ce=36.8634300931878
Local test acc @ epoch 139: 0.9622
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.01 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8817826039200529, ce=36.8188406918027
Local test acc @ epoch 139: 0.9622
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.98 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8823100995579991, ce=36.86135188811416
Local test acc @ epoch 139: 0.9622
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.94 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.881622251020659, ce=36.81639858560825
Local test acc @ epoch 139: 0.9622
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.94 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8821660925488953, ce=36.85505476785362
Local test acc @ epoch 139: 0.9622
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.88 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8818100658031779, ce=36.82058964300593
Local test acc @ epoch 139: 0.9622
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.79 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8816848151180723, ce=36.802194437849415
Local test acc @ epoch 139: 0.9622
Global evaluate on test data...
Evaluate data in 83.06 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8818212736637221, ce=36.82306576650077
Global test acc : 0.9622
Global prompt norm: 57.91758728027344
Global epoch 140...
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.94 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8825480106773727, ce=36.9279387587801
Local test acc @ epoch 140: 0.9622
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.88 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8824027743908244, ce=36.92671592082452
Local test acc @ epoch 140: 0.9622
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8825774061570474, ce=36.929600181929565
Local test acc @ epoch 140: 0.9622
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.68 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8822064705944936, ce=36.89455679797251
Local test acc @ epoch 140: 0.9622
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.95 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8824560729735488, ce=36.91151319731266
Local test acc @ epoch 140: 0.9622
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.91 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8829106693967766, ce=36.96222392790908
Local test acc @ epoch 140: 0.9622
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.89 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8830516775813672, ce=36.968702263788344
Local test acc @ epoch 140: 0.9622
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8829569707223035, ce=36.97091079851903
Local test acc @ epoch 140: 0.9622
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.91 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8825867526028135, ce=36.92983151357108
Local test acc @ epoch 140: 0.9622
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.76 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8821664250225102, ce=36.90086602727207
Local test acc @ epoch 140: 0.9622
Global evaluate on test data...
Evaluate data in 82.95 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8825875619135866, ce=36.93232356080222
Global test acc : 0.9622
Global prompt norm: 57.917240142822266
Global epoch 141...
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.69 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8829084426984875, ce=37.00877866832488
Local test acc @ epoch 141: 0.9622
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.79 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8837456353213808, ce=37.07278382887534
Local test acc @ epoch 141: 0.9622
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.9 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8836438043401875, ce=37.07515748050235
Local test acc @ epoch 141: 0.9622
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.96 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8833045018922299, ce=37.03597927968436
Local test acc @ epoch 141: 0.9622
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8831792008986167, ce=37.01744496056793
Local test acc @ epoch 141: 0.9622
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.76 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8832947529784037, ce=37.03523362885922
Local test acc @ epoch 141: 0.9622
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8831306597508422, ce=37.03350711087568
Local test acc @ epoch 141: 0.9622
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.95 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8836066482263968, ce=37.0661936768698
Local test acc @ epoch 141: 0.9622
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.73 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8829491750909648, ce=37.00246548433916
Local test acc @ epoch 141: 0.9622
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.62 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.883263491709298, ce=37.033662008583
Local test acc @ epoch 141: 0.9622
Global evaluate on test data...
Evaluate data in 83.13 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8833011027869828, ce=37.03811600011423
Global test acc : 0.9622
Global prompt norm: 57.916900634765625
Global epoch 142...
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.16 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8839405589147445, ce=37.13624418766127
Local test acc @ epoch 142: 0.9622
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.84 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8836071688100833, ce=37.11339044133457
Local test acc @ epoch 142: 0.9622
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8839773300590865, ce=37.138925184897325
Local test acc @ epoch 142: 0.9622
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.9 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8838138514702473, ce=37.13707390181515
Local test acc @ epoch 142: 0.9622
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8838615023761714, ce=37.12025861127661
Local test acc @ epoch 142: 0.9622
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.82 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8843968373919846, ce=37.17382885994167
Local test acc @ epoch 142: 0.9622
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.94 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8836469234676536, ce=37.107007227906394
Local test acc @ epoch 142: 0.9622
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8839663146832667, ce=37.13774329369221
Local test acc @ epoch 142: 0.9622
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8842992170141377, ce=37.17636283384551
Local test acc @ epoch 142: 0.9622
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.92 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8842623605640656, ce=37.16703337923102
Local test acc @ epoch 142: 0.9622
Global evaluate on test data...
Evaluate data in 82.95 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8839776997172505, ce=37.14083130862735
Global test acc : 0.9622
Global prompt norm: 57.916561126708984
Global epoch 143...
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.95 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8848802321547762, ce=37.2653327381939
Local test acc @ epoch 143: 0.9622
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.9 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.884502903037115, ce=37.22008997365969
Local test acc @ epoch 143: 0.9622
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.86 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8850117670286686, ce=37.27213794813244
Local test acc @ epoch 143: 0.9622
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.9 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8846052414780363, ce=37.237449086040534
Local test acc @ epoch 143: 0.9622
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.0 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8845769418488949, ce=37.23602350917431
Local test acc @ epoch 143: 0.9622
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.9 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8844609413671931, ce=37.23783930507275
Local test acc @ epoch 143: 0.9622
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8842978630590876, ce=37.20845959164681
Local test acc @ epoch 143: 0.9622
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.79 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8849123180459398, ce=37.27490661341116
Local test acc @ epoch 143: 0.9622
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.85 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.884615066948287, ce=37.2390603931672
Local test acc @ epoch 143: 0.9622
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.75 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8842634279793555, ce=37.21495063151788
Local test acc @ epoch 143: 0.9622
Global evaluate on test data...
Evaluate data in 83.0 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8846134767619842, ce=37.240683179382884
Global test acc : 0.9622
Global prompt norm: 57.91622543334961
Global epoch 144...
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.01 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8851044440488203, ce=37.317263786945865
Local test acc @ epoch 144: 0.9622
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.81 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8849112156334273, ce=37.30724219225962
Local test acc @ epoch 144: 0.9622
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.97 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8855875675831366, ce=37.36796996790335
Local test acc @ epoch 144: 0.9622
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.91 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8852007607801244, ce=37.334403956702
Local test acc @ epoch 144: 0.9622
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.04 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8854611947995807, ce=37.36102494406044
Local test acc @ epoch 144: 0.9622
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8851757727631735, ce=37.333085646323106
Local test acc @ epoch 144: 0.9622
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.89 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8852085476621575, ce=37.336387739269014
Local test acc @ epoch 144: 0.9622
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.06 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8850629548414037, ce=37.33577010828421
Local test acc @ epoch 144: 0.9622
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8854933484978632, ce=37.37090665484787
Local test acc @ epoch 144: 0.9622
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.94 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8848750175686058, ce=37.3137273525973
Local test acc @ epoch 144: 0.9622
Global evaluate on test data...
Evaluate data in 82.9 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8852074321256865, ce=37.337761310262415
Global test acc : 0.9622
Global prompt norm: 57.91590881347656
Global epoch 145...
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.85 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.88549150239437, ce=37.40341228520105
Local test acc @ epoch 145: 0.9622
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.86 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8857401751596993, ce=37.427775146764354
Local test acc @ epoch 145: 0.9622
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.91 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8856334161320958, ce=37.43124106170934
Local test acc @ epoch 145: 0.9622
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.89 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8860334059514037, ce=37.4644580456095
Local test acc @ epoch 145: 0.9622
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.09 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8854560480205291, ce=37.40994696660873
Local test acc @ epoch 145: 0.9622
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.79 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8857632667646496, ce=37.4290421862121
Local test acc @ epoch 145: 0.9622
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.85 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8861320499980122, ce=37.46125968443145
Local test acc @ epoch 145: 0.9622
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.99 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8856715587300992, ce=37.41210521033051
Local test acc @ epoch 145: 0.9622
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8857668146080927, ce=37.431308921324
Local test acc @ epoch 145: 0.9622
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.06 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8860085644853224, ce=37.45437240600586
Local test acc @ epoch 145: 0.9622
Global evaluate on test data...
Evaluate data in 82.98 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8857720204449575, ce=37.432524304871166
Global test acc : 0.9622
Global prompt norm: 57.915557861328125
Global epoch 146...
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.91 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8862923000930646, ce=37.52140059164905
Local test acc @ epoch 146: 0.9622
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.886647073500747, ce=37.55247340071092
Local test acc @ epoch 146: 0.9622
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8865258321849578, ce=37.54554664541822
Local test acc @ epoch 146: 0.9622
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.95 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8865520910385551, ce=37.55588692481365
Local test acc @ epoch 146: 0.9622
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8860338784139091, ce=37.497240049029706
Local test acc @ epoch 146: 0.9622
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8862068609360161, ce=37.50460461957739
Local test acc @ epoch 146: 0.9622
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.91 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8861703107116419, ce=37.52437703543847
Local test acc @ epoch 146: 0.9622
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.96 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8863031207968336, ce=37.524039207248514
Local test acc @ epoch 146: 0.9622
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.99 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8862707942997644, ce=37.52017218913507
Local test acc @ epoch 146: 0.9622
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.86 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.885998439351353, ce=37.50372660925629
Local test acc @ epoch 146: 0.9622
Global evaluate on test data...
Evaluate data in 83.07 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8863037551214935, ce=37.52501555976518
Global test acc : 0.9622
Global prompt norm: 57.91524887084961
Global epoch 147...
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.94 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8866776085774833, ce=37.61531948824541
Local test acc @ epoch 147: 0.9622
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.01 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8867926182003196, ce=37.61154780256639
Local test acc @ epoch 147: 0.9622
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.81 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8865115270702117, ce=37.59538696009085
Local test acc @ epoch 147: 0.9622
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.03 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.886799396724876, ce=37.61446618596348
Local test acc @ epoch 147: 0.9622
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.01 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8870134266144639, ce=37.634674842204525
Local test acc @ epoch 147: 0.9622
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.84 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8867732341136407, ce=37.610370356008545
Local test acc @ epoch 147: 0.9622
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.88 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8865491884564041, ce=37.58885220868872
Local test acc @ epoch 147: 0.9622
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8870357285945787, ce=37.64529926405041
Local test acc @ epoch 147: 0.9622
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.88 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8867075202661917, ce=37.59487831045728
Local test acc @ epoch 147: 0.9622
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.0 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8871320475132094, ce=37.64157667947472
Local test acc @ epoch 147: 0.9622
Global evaluate on test data...
Evaluate data in 83.01 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8868003132146433, ce=37.615244419202895
Global test acc : 0.9622
Global prompt norm: 57.914920806884766
Global epoch 148...
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.15 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8870343112070626, ce=37.6783439566236
Local test acc @ epoch 148: 0.9622
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.97 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8874726382964248, ce=37.72191738863604
Local test acc @ epoch 148: 0.9622
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.81 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8875920641312905, ce=37.7288292351119
Local test acc @ epoch 148: 0.9622
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.97 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8872635123926566, ce=37.69979329940376
Local test acc @ epoch 148: 0.9622
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.93 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8871515344042297, ce=37.70428827268268
Local test acc @ epoch 148: 0.9622
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.88 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8872434414854837, ce=37.69867702799106
Local test acc @ epoch 148: 0.9622
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.99 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8874934922664537, ce=37.73275123386208
Local test acc @ epoch 148: 0.9622
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.04 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8869982553184579, ce=37.68495006736266
Local test acc @ epoch 148: 0.9622
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.17 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8872677514312464, ce=37.7029569783342
Local test acc @ epoch 148: 0.9622
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.84 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8871930148623405, ce=37.68329791847719
Local test acc @ epoch 148: 0.9622
Global evaluate on test data...
Evaluate data in 82.94 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8872730053892923, ce=37.70364743853928
Global test acc : 0.9622
Global prompt norm: 57.91462707519531
Global epoch 149...
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.11 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8876914168716571, ce=37.785118802971795
Local test acc @ epoch 149: 0.9622
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.86 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8876027754687388, ce=37.79140713892946
Local test acc @ epoch 149: 0.9622
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.88 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.887639605670894, ce=37.76980811302815
Local test acc @ epoch 149: 0.9622
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.0 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8879105716670325, ce=37.80738137621398
Local test acc @ epoch 149: 0.9622
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.97 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8874910796454193, ce=37.765983826523524
Local test acc @ epoch 149: 0.9622
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.81 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8874560824227989, ce=37.772621784735165
Local test acc @ epoch 149: 0.9622
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.02 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8879253426823047, ce=37.81846286178729
Local test acc @ epoch 149: 0.9622
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.87 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8877099085291591, ce=37.78621306113147
Local test acc @ epoch 149: 0.9622
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.02 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8880223965426104, ce=37.81428937299536
Local test acc @ epoch 149: 0.9622
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.06 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8877113062307376, ce=37.78962343548416
Local test acc @ epoch 149: 0.9622
Global evaluate on test data...
Evaluate data in 82.97 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8877159389880819, ce=37.79008504885052
Global test acc : 0.9622
Global prompt norm: 57.91433334350586
Global epoch 150...
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.12 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8879442936783537, ce=37.85191779180404
Local test acc @ epoch 150: 0.9622
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.09 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8879302685413886, ce=37.85855802483515
Local test acc @ epoch 150: 0.9622
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.86 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8880989573417454, ce=37.876827239990234
Local test acc @ epoch 150: 0.9622
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.03 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8883860483082062, ce=37.90250400228238
Local test acc @ epoch 150: 0.9633
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.99 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8881728124181065, ce=37.87462916942911
Local test acc @ epoch 150: 0.9622
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.03 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8881651720869432, ce=37.86994115147022
Local test acc @ epoch 150: 0.9622
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.09 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8883745626572075, ce=37.8912935169465
Local test acc @ epoch 150: 0.9622
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.97 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8880881278886708, ce=37.854687227021664
Local test acc @ epoch 150: 0.9622
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.29 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8885104612472954, ce=37.89810205162118
Local test acc @ epoch 150: 0.9633
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.12 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.888172545564284, ce=37.87101598617134
Local test acc @ epoch 150: 0.9622
Global evaluate on test data...
Evaluate data in 83.13 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8881839480968791, ce=37.87496846750242
Global test acc : 0.9622
Global prompt norm: 57.91402053833008
Global epoch 151...
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.84 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8888952229001107, ce=37.973509867256936
Local test acc @ epoch 151: 0.9633
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.17 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8886840015376379, ce=37.95789326659036
Local test acc @ epoch 151: 0.9633
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.27 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8888923159433068, ce=37.98491616205338
Local test acc @ epoch 151: 0.9633
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.13 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8886048268834386, ce=37.93785795159296
Local test acc @ epoch 151: 0.9633
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.04 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8886863616628384, ce=37.95404875169107
Local test acc @ epoch 151: 0.9633
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.26 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8886788153867109, ce=37.95302466296275
Local test acc @ epoch 151: 0.9633
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.25 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8884667584655481, ce=37.93608940194506
Local test acc @ epoch 151: 0.9633
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.01 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8884552596905909, ce=37.94272204057886
Local test acc @ epoch 151: 0.9633
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.94 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8886144423703535, ce=37.96049936977001
Local test acc @ epoch 151: 0.9633
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.84 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8890438386059683, ce=37.98028949422574
Local test acc @ epoch 151: 0.9633
Global evaluate on test data...
Evaluate data in 83.06 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8886971473693848, ce=37.9581390170876
Global test acc : 0.9633
Global prompt norm: 57.91371536254883
Global epoch 152...
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.94 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8893271739329767, ce=38.03567749863371
Local test acc @ epoch 152: 0.9633
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.17 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8895501981087781, ce=38.06595391089763
Local test acc @ epoch 152: 0.9633
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.19 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8893172040991827, ce=38.034695721547536
Local test acc @ epoch 152: 0.9633
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.96 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8897200724400511, ce=38.06110452074523
Local test acc @ epoch 152: 0.9633
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.07 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8890386283944506, ce=38.02542779205042
Local test acc @ epoch 152: 0.9633
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.12 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8892125033457344, ce=38.019562537517025
Local test acc @ epoch 152: 0.9633
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.08 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8893548108022148, ce=38.039750650388385
Local test acc @ epoch 152: 0.9633
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.87 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8890472770830907, ce=38.01877677987475
Local test acc @ epoch 152: 0.9633
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.98 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.889254384084579, ce=38.04268621742179
Local test acc @ epoch 152: 0.9633
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.93 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8895761157394549, ce=38.054397093046695
Local test acc @ epoch 152: 0.9633
Global evaluate on test data...
Evaluate data in 83.09 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8893428833112804, ce=38.03981319042521
Global test acc : 0.9633
Global prompt norm: 57.9134407043457
Global epoch 153...
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.98 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.890020584841387, ce=38.119997496998636
Local test acc @ epoch 153: 0.9633
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.1 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8899187757334578, ce=38.12332947757266
Local test acc @ epoch 153: 0.9633
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.06 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8897155074898256, ce=38.10653924504551
Local test acc @ epoch 153: 0.9633
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.01 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8897219447914614, ce=38.09986803947239
Local test acc @ epoch 153: 0.9633
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.11 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8898827307814852, ce=38.09977375695465
Local test acc @ epoch 153: 0.9633
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.28 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8899842052284731, ce=38.11483677155381
Local test acc @ epoch 153: 0.9633
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.2 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8902056326559924, ce=38.14558879607314
Local test acc @ epoch 153: 0.9633
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.06 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.889989406690685, ce=38.11579023588688
Local test acc @ epoch 153: 0.9633
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.97 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8903734815230063, ce=38.1404128818337
Local test acc @ epoch 153: 0.9633
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.07 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8902311653172205, ce=38.13378027819712
Local test acc @ epoch 153: 0.9633
Global evaluate on test data...
Evaluate data in 83.05 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8900026837620166, ce=38.11997460881504
Global test acc : 0.9633
Global prompt norm: 57.91311264038086
Global epoch 154...
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.07 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8910011720219884, ce=38.218481571302505
Local test acc @ epoch 154: 0.9633
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.09 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8905662265392619, ce=38.20278801174339
Local test acc @ epoch 154: 0.9633
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.95 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8903657886960091, ce=38.18630582476975
Local test acc @ epoch 154: 0.9633
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.99 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8906329793667574, ce=38.194723741723855
Local test acc @ epoch 154: 0.9633
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.88 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8906257218177166, ce=38.19374763418775
Local test acc @ epoch 154: 0.9633
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.11 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8905282851752885, ce=38.17874880449487
Local test acc @ epoch 154: 0.9633
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.99 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8903772218511739, ce=38.179657752360775
Local test acc @ epoch 154: 0.9633
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.04 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8908382555760375, ce=38.22396952077883
Local test acc @ epoch 154: 0.9633
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.07 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8908631473506262, ce=38.21196813320895
Local test acc @ epoch 154: 0.9633
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.07 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8906617186485081, ce=38.19907820115396
Local test acc @ epoch 154: 0.9633
Global evaluate on test data...
Evaluate data in 83.23 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8906477306960919, ce=38.19895340105809
Global test acc : 0.9633
Global prompt norm: 57.9128303527832
Global epoch 155...
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.08 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.890998146949558, ce=38.26478163692929
Local test acc @ epoch 155: 0.9633
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.93 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8910049473473786, ce=38.258124710222994
Local test acc @ epoch 155: 0.9633
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.0 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8911899448534765, ce=38.280790346478106
Local test acc @ epoch 155: 0.9633
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.1 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8912497419829762, ce=38.272277622047916
Local test acc @ epoch 155: 0.9633
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.91 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8914736585879545, ce=38.28886991028392
Local test acc @ epoch 155: 0.9633
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.04 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8912443502233662, ce=38.27131652832031
Local test acc @ epoch 155: 0.9633
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.96 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8914517372026356, ce=38.301012651635965
Local test acc @ epoch 155: 0.9633
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.92 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8912794808728979, ce=38.276767940696224
Local test acc @ epoch 155: 0.9633
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.1 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8916063855547424, ce=38.29537323418013
Local test acc @ epoch 155: 0.9633
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.09 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8911496499262819, ce=38.25627206224914
Local test acc @ epoch 155: 0.9633
Global evaluate on test data...
Evaluate data in 82.87 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8912663591017417, ce=38.276577310824614
Global test acc : 0.9633
Global prompt norm: 57.91253662109375
Global epoch 156...
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.97 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8916132603216609, ce=38.33536774521574
Local test acc @ epoch 156: 0.9633
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.94 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8917937060014918, ce=38.35766552566388
Local test acc @ epoch 156: 0.9633
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.99 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8918757723012102, ce=38.35332796989231
Local test acc @ epoch 156: 0.9633
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.06 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8917528423694295, ce=38.33281228301722
Local test acc @ epoch 156: 0.9633
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.9 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8915993139284466, ce=38.341978265604844
Local test acc @ epoch 156: 0.9633
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.06 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8918395348645132, ce=38.347721764800745
Local test acc @ epoch 156: 0.9633
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.89 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.892040364239194, ce=38.376983537586455
Local test acc @ epoch 156: 0.9633
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.98 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.891846131840977, ce=38.34861989852485
Local test acc @ epoch 156: 0.9633
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.05 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8920612685177305, ce=38.364612054387365
Local test acc @ epoch 156: 0.9633
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.0 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.892192825264887, ce=38.37104023924661
Local test acc @ epoch 156: 0.9633
Global evaluate on test data...
Evaluate data in 82.98 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8918624252354334, ce=38.353022199158275
Global test acc : 0.9633
Global prompt norm: 57.912254333496094
Global epoch 157...
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.97 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8926083188538158, ce=38.45189040297762
Local test acc @ epoch 157: 0.9633
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.85 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8924200228594859, ce=38.42311680645024
Local test acc @ epoch 157: 0.9633
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.94 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8922006515187955, ce=38.41145916160094
Local test acc @ epoch 157: 0.9633
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.01 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8921847365318089, ce=38.41812620250457
Local test acc @ epoch 157: 0.9633
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.1 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.892626679271733, ce=38.4393152709401
Local test acc @ epoch 157: 0.9633
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.05 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8924248743494716, ce=38.4240476625775
Local test acc @ epoch 157: 0.9633
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.99 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8924508663492465, ce=38.42882691829576
Local test acc @ epoch 157: 0.9633
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.11 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8927598043319283, ce=38.44567181648464
Local test acc @ epoch 157: 0.9633
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.14 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8923314864482355, ce=38.40816406809956
Local test acc @ epoch 157: 0.9633
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.02 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8923700752608273, ce=38.43351294141297
Local test acc @ epoch 157: 0.9633
Global evaluate on test data...
Evaluate data in 82.84 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8924358569153952, ce=38.42842756498844
Global test acc : 0.9633
Global prompt norm: 57.911964416503906
Global epoch 158...
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.03 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8929294468066015, ce=38.50818648032092
Local test acc @ epoch 158: 0.9633
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.11 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8927657735457114, ce=38.48640896858425
Local test acc @ epoch 158: 0.9633
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.02 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8927496923219174, ce=38.49312990521072
Local test acc @ epoch 158: 0.9633
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.08 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8928935768407419, ce=38.48244234837523
Local test acc @ epoch 158: 0.9633
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.82 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8929767608642578, ce=38.497312108311085
Local test acc @ epoch 158: 0.9633
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.21 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8933092694763743, ce=38.519263416255285
Local test acc @ epoch 158: 0.9633
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.25 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8931800706670918, ce=38.51300346304517
Local test acc @ epoch 158: 0.9633
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.0 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8929834081492293, ce=38.4982271106965
Local test acc @ epoch 158: 0.9633
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.07 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8930058216829913, ce=38.50317123833052
Local test acc @ epoch 158: 0.9633
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.03 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8931564475418231, ce=38.52572204869821
Local test acc @ epoch 158: 0.9633
Global evaluate on test data...
Evaluate data in 83.03 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8929961602622216, ce=38.50265257949129
Global test acc : 0.9633
Global prompt norm: 57.91168975830078
Global epoch 159...
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.09 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8932930285777521, ce=38.567097865113425
Local test acc @ epoch 159: 0.9633
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.17 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8936797041411794, ce=38.598563203024206
Local test acc @ epoch 159: 0.9633
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.01 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8937103113996874, ce=38.58568835477217
Local test acc @ epoch 159: 0.9633
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.07 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8938306580989732, ce=38.59186056994517
Local test acc @ epoch 159: 0.9633
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.14 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.893513174231993, ce=38.57060196202829
Local test acc @ epoch 159: 0.9633
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.1 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8935171311054755, ce=38.571522598966546
Local test acc @ epoch 159: 0.9633
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.87 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8933065440676627, ce=38.56043040424312
Local test acc @ epoch 159: 0.9633
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.08 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8935414257399533, ce=38.576544035465346
Local test acc @ epoch 159: 0.9633
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.09 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8934651689791898, ce=38.58187708723436
Local test acc @ epoch 159: 0.9633
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.95 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8934328534187527, ce=38.55565783299437
Local test acc @ epoch 159: 0.9633
Global evaluate on test data...
Evaluate data in 82.91 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8935283870872007, ce=38.57603535083456
Global test acc : 0.9633
Global prompt norm: 57.9113883972168
Global epoch 160...
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.03 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8940311834352825, ce=38.64292011785945
Local test acc @ epoch 160: 0.9633
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.0 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8939890314679627, ce=38.65464814212344
Local test acc @ epoch 160: 0.9633
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.02 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8938189646519652, ce=38.64020590825912
Local test acc @ epoch 160: 0.9633
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.15 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8939488568437208, ce=38.628011720989825
Local test acc @ epoch 160: 0.9633
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.93 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8942245693381773, ce=38.65744928482476
Local test acc @ epoch 160: 0.9633
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.18 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8943428621379608, ce=38.66348595575455
Local test acc @ epoch 160: 0.9633
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.01 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8940372904506299, ce=38.643847124292215
Local test acc @ epoch 160: 0.9633
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.22 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8940577900737797, ce=38.64902048373441
Local test acc @ epoch 160: 0.9633
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.97 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8941977483416916, ce=38.67048743011755
Local test acc @ epoch 160: 0.9633
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.98 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8938334863120263, ce=38.633514509288545
Local test acc @ epoch 160: 0.9633
Global evaluate on test data...
Evaluate data in 83.07 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8940476408792198, ce=38.648361801007475
Global test acc : 0.9633
Global prompt norm: 57.91109085083008
Global epoch 161...
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.98 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8943421993780574, ce=38.705564656388866
Local test acc @ epoch 161: 0.9633
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.02 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8945574519831107, ce=38.72049741132544
Local test acc @ epoch 161: 0.9633
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.02 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8945312434380207, ce=38.71429016393259
Local test acc @ epoch 161: 0.9633
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.01 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8947135658439146, ce=38.728387640156875
Local test acc @ epoch 161: 0.9633
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.13 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.894325693812939, ce=38.71222567777021
Local test acc @ epoch 161: 0.9633
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.04 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8944890849087217, ce=38.72644917899316
Local test acc @ epoch 161: 0.9633
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.13 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8948320730016865, ce=38.734340352749605
Local test acc @ epoch 161: 0.9633
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.98 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8944557084949738, ce=38.69938813655748
Local test acc @ epoch 161: 0.9633
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.93 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8946849337411583, ce=38.74155401527335
Local test acc @ epoch 161: 0.9633
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.99 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8945396405841233, ce=38.715237748732264
Local test acc @ epoch 161: 0.9633
Global evaluate on test data...
Evaluate data in 83.03 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8945451679579709, ce=38.71980523625645
Global test acc : 0.9633
Global prompt norm: 57.91080093383789
Global epoch 162...
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.96 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8951932793363518, ce=38.7985265889299
Local test acc @ epoch 162: 0.9633
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.01 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8949732496104109, ce=38.797362266330545
Local test acc @ epoch 162: 0.9633
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.01 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8948135091624129, ce=38.783483977711526
Local test acc @ epoch 162: 0.9633
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.98 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8951658130785741, ce=38.811848071737025
Local test acc @ epoch 162: 0.9633
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.11 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8948330507365936, ce=38.77680678761333
Local test acc @ epoch 162: 0.9633
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.02 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8950223572757265, ce=38.7858386958411
Local test acc @ epoch 162: 0.9633
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.0 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.895306913130874, ce=38.80436951523527
Local test acc @ epoch 162: 0.9633
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.89 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8950160118418002, ce=38.78498259378136
Local test acc @ epoch 162: 0.9633
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.85 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8950386703561205, ce=38.79120572991327
Local test acc @ epoch 162: 0.9633
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.12 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8949404987720174, ce=38.77002502581395
Local test acc @ epoch 162: 0.9633
Global evaluate on test data...
Evaluate data in 83.12 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.89503357169825, ce=38.79048167237448
Global test acc : 0.9633
Global prompt norm: 57.9105224609375
Global epoch 163...
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.22 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.895303080934997, ce=38.84715061012758
Local test acc @ epoch 163: 0.9633
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.97 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8952870522070369, ce=38.8538201008368
Local test acc @ epoch 163: 0.9633
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.06 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8954401847419389, ce=38.867505974725844
Local test acc @ epoch 163: 0.9633
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.12 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8955073903460021, ce=38.86106638077202
Local test acc @ epoch 163: 0.9633
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.88 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8956512004957287, ce=38.867755014962015
Local test acc @ epoch 163: 0.9633
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.96 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8954860092303075, ce=38.85559078531528
Local test acc @ epoch 163: 0.9633
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.93 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8957627935147067, ce=38.87357085341707
Local test acc @ epoch 163: 0.9622
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.97 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8954845480962631, ce=38.854653034735165
Local test acc @ epoch 163: 0.9633
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.05 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8954119638565483, ce=38.83974071817661
Local test acc @ epoch 163: 0.9633
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.82 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8956234695714548, ce=38.881195033362154
Local test acc @ epoch 163: 0.9633
Global evaluate on test data...
Evaluate data in 82.93 seconds!
[tester] 
SST2Metric: acc=0.963302752293578, hinge=0.8954951741279812, ce=38.86022007793461
Global test acc : 0.9633
Global prompt norm: 57.910255432128906
Global epoch 164...
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.04 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8959347501807257, ce=38.92367795191774
Local test acc @ epoch 164: 0.9622
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.0 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.895955796635479, ce=38.93017497631388
Local test acc @ epoch 164: 0.9622
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.05 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8958658144014691, ce=38.908742467197804
Local test acc @ epoch 164: 0.9622
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.94 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8960974128968126, ce=38.93633546741731
Local test acc @ epoch 164: 0.9622
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.97 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8960688814110712, ce=38.94996548573905
Local test acc @ epoch 164: 0.9622
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.91 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8958938449894617, ce=38.93692342075733
Local test acc @ epoch 164: 0.9622
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.81 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8957587972693487, ce=38.9167865788171
Local test acc @ epoch 164: 0.9622
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8957409902450142, ce=38.92344760019845
Local test acc @ epoch 164: 0.9622
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.92 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.896208955607283, ce=38.94203878980164
Local test acc @ epoch 164: 0.9622
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.95 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8959399407063056, ce=38.92455113262211
Local test acc @ epoch 164: 0.9622
Global evaluate on test data...
Evaluate data in 83.15 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8959467848506543, ce=38.92929910082336
Global test acc : 0.9622
Global prompt norm: 57.90996551513672
Global epoch 165...
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.98 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8965270366143743, ce=39.004141746311014
Local test acc @ epoch 165: 0.9622
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.89 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8963019913489666, ce=38.97702001869132
Local test acc @ epoch 165: 0.9622
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.05 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8964961625020439, ce=39.01789988946477
Local test acc @ epoch 165: 0.9622
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.99 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.896327933040234, ce=39.0055038382154
Local test acc @ epoch 165: 0.9622
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.23 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8963715002077435, ce=38.991930655383186
Local test acc @ epoch 165: 0.9622
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.89 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8962012234084104, ce=38.985584993974875
Local test acc @ epoch 165: 0.9622
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.89 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8966339203195834, ce=39.00973080276349
Local test acc @ epoch 165: 0.9622
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.98 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8963732150716519, ce=38.992874320493925
Local test acc @ epoch 165: 0.9622
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.97 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.896182624571914, ce=38.99230670054025
Local test acc @ epoch 165: 0.9622
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.03 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8963892984827724, ce=38.998498619149586
Local test acc @ epoch 165: 0.9622
Global evaluate on test data...
Evaluate data in 82.93 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8963805513644437, ce=38.99756905791956
Global test acc : 0.9622
Global prompt norm: 57.9096794128418
Global epoch 166...
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.91 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8967243990766893, ce=39.04454799967075
Local test acc @ epoch 166: 0.9622
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.99 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8969403144416459, ce=39.071349852675695
Local test acc @ epoch 166: 0.9622
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.95 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8969089022470177, ce=39.08524291012265
Local test acc @ epoch 166: 0.9622
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.98 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.896606434375868, ce=39.06039547701494
Local test acc @ epoch 166: 0.9622
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.03 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8970458616904162, ce=39.07680273493496
Local test acc @ epoch 166: 0.9622
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.95 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8966248472896191, ce=39.05364514272147
Local test acc @ epoch 166: 0.9622
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.86 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8968056385670233, ce=39.06615556489437
Local test acc @ epoch 166: 0.9622
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.03 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8967919568403051, ce=39.06042469969583
Local test acc @ epoch 166: 0.9622
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.9 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8967484706038729, ce=39.073391380660034
Local test acc @ epoch 166: 0.9622
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.87 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8967897979491347, ce=39.059491953718556
Local test acc @ epoch 166: 0.9622
Global evaluate on test data...
Evaluate data in 83.01 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8967946756870375, ce=39.06515327943574
Global test acc : 0.9622
Global prompt norm: 57.90940475463867
Global epoch 167...
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.99 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8974441038359195, ce=39.14321878415729
Local test acc @ epoch 167: 0.9622
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.9 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.897197972743883, ce=39.12737708135482
Local test acc @ epoch 167: 0.9622
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.86 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.897194002746442, ce=39.126399223957584
Local test acc @ epoch 167: 0.9622
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.75 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.897016326221851, ce=39.12785150370467
Local test acc @ epoch 167: 0.9622
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.75 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8973404617484556, ce=39.137838941101634
Local test acc @ epoch 167: 0.9622
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.1 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8972083909795918, ce=39.13315533279279
Local test acc @ epoch 167: 0.9622
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.08 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8971305024733237, ce=39.11147679320169
Local test acc @ epoch 167: 0.9622
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.04 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8971511486473434, ce=39.140669971431066
Local test acc @ epoch 167: 0.9622
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.06 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8973058144980615, ce=39.151894455656
Local test acc @ epoch 167: 0.9622
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.95 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8970348506892493, ce=39.12113837145884
Local test acc @ epoch 167: 0.9622
Global evaluate on test data...
Evaluate data in 82.93 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8972028001732782, ce=39.13210496115028
Global test acc : 0.9622
Global prompt norm: 57.90911102294922
Global epoch 168...
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.89 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8974045285391151, ce=39.19467464062052
Local test acc @ epoch 168: 0.9622
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.82 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8978229465834592, ce=39.209007403172485
Local test acc @ epoch 168: 0.9622
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.85 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8975229744517476, ce=39.17774494416123
Local test acc @ epoch 168: 0.9622
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.05 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8975854729293683, ce=39.193648417061624
Local test acc @ epoch 168: 0.9622
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.0 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8975442177658781, ce=39.207272380863856
Local test acc @ epoch 168: 0.9622
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.11 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8975821153833232, ce=39.19268315866453
Local test acc @ epoch 168: 0.9622
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.99 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8977275113446996, ce=39.20380538100496
Local test acc @ epoch 168: 0.9622
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.9 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8975962673852204, ce=39.19951083681999
Local test acc @ epoch 168: 0.9622
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.02 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8974288406722043, ce=39.1879669329442
Local test acc @ epoch 168: 0.9622
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.94 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8976915888830063, ce=39.21790765184875
Local test acc @ epoch 168: 0.9622
Global evaluate on test data...
Evaluate data in 82.91 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8975904578462653, ce=39.19836698759586
Global test acc : 0.9622
Global prompt norm: 57.90884780883789
Global epoch 169...
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.93 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8982856448637236, ce=39.27420404416706
Local test acc @ epoch 169: 0.9622
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.07 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8979576508933251, ce=39.273312279937464
Local test acc @ epoch 169: 0.9622
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.02 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8978200243153703, ce=39.26090390966573
Local test acc @ epoch 169: 0.9622
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.09 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.898012373425545, ce=39.25933407424787
Local test acc @ epoch 169: 0.9622
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.1 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8978451676324967, ce=39.254198651794994
Local test acc @ epoch 169: 0.9622
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.82 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8980029176134582, ce=39.25839803853166
Local test acc @ epoch 169: 0.9622
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.93 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8979320198024084, ce=39.24338790473588
Local test acc @ epoch 169: 0.9622
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.86 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8981649700654756, ce=39.269079750830976
Local test acc @ epoch 169: 0.9622
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.99 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8981584430834569, ce=39.28340946862457
Local test acc @ epoch 169: 0.9622
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.98 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.898059442502643, ce=39.26528419704612
Local test acc @ epoch 169: 0.9622
Global evaluate on test data...
Evaluate data in 82.98 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8980246290154413, ce=39.2641833594086
Global test acc : 0.9622
Global prompt norm: 57.90856170654297
Global epoch 170...
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.91 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8984288403747278, ce=39.338803037590935
Local test acc @ epoch 170: 0.9622
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.89 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8984818371064073, ce=39.32451997109509
Local test acc @ epoch 170: 0.9622
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8985271235124781, ce=39.330544952952536
Local test acc @ epoch 170: 0.9622
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.82 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.898472077255949, ce=39.32356188712864
Local test acc @ epoch 170: 0.9622
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.04 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8986244048547307, ce=39.34833712096608
Local test acc @ epoch 170: 0.9622
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.91 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8986319008223508, ce=39.33396362164699
Local test acc @ epoch 170: 0.9622
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.76 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.898405650340089, ce=39.30855189332175
Local test acc @ epoch 170: 0.9622
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.86 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8987479188026638, ce=39.338978618656824
Local test acc @ epoch 170: 0.9622
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.84 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.898293993888645, ce=39.326539800801406
Local test acc @ epoch 170: 0.9622
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.88 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8983177788760683, ce=39.31983513788346
Local test acc @ epoch 170: 0.9622
Global evaluate on test data...
Evaluate data in 82.92 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8984938324044603, ce=39.329370026194724
Global test acc : 0.9622
Global prompt norm: 57.90827941894531
Global epoch 171...
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.2 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.898930449004567, ce=39.388131097916066
Local test acc @ epoch 171: 0.9622
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.04 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8989404778961742, ce=39.38911647971617
Local test acc @ epoch 171: 0.9622
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.04 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8987774345852914, ce=39.3849296219852
Local test acc @ epoch 171: 0.9622
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.95 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8990834940464125, ce=39.39822408693646
Local test acc @ epoch 171: 0.9622
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.99 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8989829054666222, ce=39.39519581226034
Local test acc @ epoch 171: 0.9622
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.04 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8991962638470011, ce=39.40310987420038
Local test acc @ epoch 171: 0.9622
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.9 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8987573199315902, ce=39.39160975185009
Local test acc @ epoch 171: 0.9622
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.04 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8988839267590724, ce=39.40370566691827
Local test acc @ epoch 171: 0.9622
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.98 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.89907414541332, ce=39.412702262948414
Local test acc @ epoch 171: 0.9622
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.99 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8988640177140542, ce=39.373118409323034
Local test acc @ epoch 171: 0.9622
Global evaluate on test data...
Evaluate data in 82.81 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.898946519291729, ce=39.39397447918533
Global test acc : 0.9622
Global prompt norm: 57.90800094604492
Global epoch 172...
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.92 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8992286078426817, ce=39.449472094894546
Local test acc @ epoch 172: 0.9622
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8995242446934412, ce=39.46199686592872
Local test acc @ epoch 172: 0.9622
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8995146948263186, ce=39.47664817320098
Local test acc @ epoch 172: 0.9622
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.85 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8994214162914032, ce=39.45941645071047
Local test acc @ epoch 172: 0.9622
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.22 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8993740912971147, ce=39.4522712777514
Local test acc @ epoch 172: 0.9622
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.08 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8993094645508932, ce=39.43720017879381
Local test acc @ epoch 172: 0.9622
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8992005116348967, ce=39.45621399485737
Local test acc @ epoch 172: 0.9622
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8993851285461986, ce=39.453246755337496
Local test acc @ epoch 172: 0.9622
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.95 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8996353193160591, ce=39.46677794150256
Local test acc @ epoch 172: 0.9622
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.92 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8993306969283917, ce=39.46814094333474
Local test acc @ epoch 172: 0.9622
Global evaluate on test data...
Evaluate data in 82.67 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8993909949556403, ce=39.458139962012616
Global test acc : 0.9622
Global prompt norm: 57.90776062011719
Global epoch 173...
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.02 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8996617094092413, ce=39.51358123219341
Local test acc @ epoch 173: 0.9622
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.14 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8997455474433549, ce=39.500790412272885
Local test acc @ epoch 173: 0.9622
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.0 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8998518011985569, ce=39.52306862927358
Local test acc @ epoch 173: 0.9622
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8999383624540557, ce=39.54007657952265
Local test acc @ epoch 173: 0.9622
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.82 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8997574355624137, ce=39.53207939917888
Local test acc @ epoch 173: 0.9622
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.9 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8998030500674467, ce=39.515898853267004
Local test acc @ epoch 173: 0.9622
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.01 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8999492859621661, ce=39.52530208202677
Local test acc @ epoch 173: 0.9622
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.85 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9000583876163588, ce=39.53000451884139
Local test acc @ epoch 173: 0.9622
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.0 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8998134836144404, ce=39.51689347433388
Local test acc @ epoch 173: 0.9622
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.84 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8996377275624406, ce=39.52026430182501
Local test acc @ epoch 173: 0.9622
Global evaluate on test data...
Evaluate data in 82.89 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.8998219748155787, ce=39.52181418882598
Global test acc : 0.9622
Global prompt norm: 57.9074821472168
Global epoch 174...
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.15 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9000818685654106, ce=39.57718675945877
Local test acc @ epoch 174: 0.9622
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.81 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9002298411973025, ce=39.58007207048048
Local test acc @ epoch 174: 0.9622
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.69 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9003597465130168, ce=39.588174102503224
Local test acc @ epoch 174: 0.9622
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.96 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9002195410772201, ce=39.57903464781035
Local test acc @ epoch 174: 0.9622
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.17 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9004665952210033, ce=39.59273826529127
Local test acc @ epoch 174: 0.9622
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.12 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9002639000568915, ce=39.58629083195957
Local test acc @ epoch 174: 0.9622
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.87 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9003469265929056, ce=39.60309656825634
Local test acc @ epoch 174: 0.9622
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.79 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9000537614209936, ce=39.583886627757224
Local test acc @ epoch 174: 0.9622
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.94 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9001734344237441, ce=39.595537588137006
Local test acc @ epoch 174: 0.9622
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.81 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.900160461390784, ce=39.56389190953806
Local test acc @ epoch 174: 0.9622
Global evaluate on test data...
Evaluate data in 82.9 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9002356791715009, ce=39.5849822858058
Global test acc : 0.9622
Global prompt norm: 57.90720748901367
Global epoch 175...
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.85 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9005667113382881, ce=39.62656987041508
Local test acc @ epoch 175: 0.9622
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.04 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9006326111084825, ce=39.64281330633601
Local test acc @ epoch 175: 0.9622
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.92 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9008630590701322, ce=39.655044590661284
Local test acc @ epoch 175: 0.9622
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.92 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9005766374255539, ce=39.65859897858506
Local test acc @ epoch 175: 0.9622
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.67 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9006658431586869, ce=39.64913779442463
Local test acc @ epoch 175: 0.9622
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.79 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9004584299315006, ce=39.64708370243738
Local test acc @ epoch 175: 0.9622
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.97 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9004884334879184, ce=39.64037284501102
Local test acc @ epoch 175: 0.9622
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.16 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9006192749793377, ce=39.64175341544895
Local test acc @ epoch 175: 0.9622
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.05 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9007569474911471, ce=39.65059497378288
Local test acc @ epoch 175: 0.9622
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.84 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9007460021097725, ce=39.66570152492698
Local test acc @ epoch 175: 0.9622
Global evaluate on test data...
Evaluate data in 83.02 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9006393130766143, ce=39.64774847468105
Global test acc : 0.9622
Global prompt norm: 57.90694808959961
Global epoch 176...
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9010084659681408, ce=39.704090223399874
Local test acc @ epoch 176: 0.9622
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.95 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9011445439189946, ce=39.7126339553693
Local test acc @ epoch 176: 0.9622
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.9 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9009563747895967, ce=39.68881544060663
Local test acc @ epoch 176: 0.9622
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9009641747955882, ce=39.72121716420585
Local test acc @ epoch 176: 0.9622
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9010508672906719, ce=39.711508409692605
Local test acc @ epoch 176: 0.9622
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.92 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9012432317121313, ce=39.71695989206297
Local test acc @ epoch 176: 0.9622
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.02 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9008787072032963, ce=39.703116355686014
Local test acc @ epoch 176: 0.9622
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.85 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9010226048460794, ce=39.70515385898975
Local test acc @ epoch 176: 0.9622
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.93 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9008496770071327, ce=39.70982794805404
Local test acc @ epoch 176: 0.9622
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.81 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9011294623033717, ce=39.72778771776672
Local test acc @ epoch 176: 0.9622
Global evaluate on test data...
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9010234250934845, ce=39.71012118978238
Global test acc : 0.9622
Global prompt norm: 57.906681060791016
Global epoch 177...
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.75 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9013340188822615, ce=39.750719752880414
Local test acc @ epoch 177: 0.9622
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.91 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9013965742303691, ce=39.767109407197445
Local test acc @ epoch 177: 0.9622
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.93 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9012611656013979, ce=39.76551801349045
Local test acc @ epoch 177: 0.9622
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.88 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9015143792563622, ce=39.77434907265759
Local test acc @ epoch 177: 0.9622
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.76 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9014258428451118, ce=39.77352373315654
Local test acc @ epoch 177: 0.9622
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.82 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9014999844612331, ce=39.78965962261235
Local test acc @ epoch 177: 0.9622
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9016165252125591, ce=39.77858443653911
Local test acc @ epoch 177: 0.9622
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.99 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9012262996183623, ce=39.77221802177779
Local test acc @ epoch 177: 0.9622
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.91 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9013859481986509, ce=39.766025718199
Local test acc @ epoch 177: 0.9622
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.901336923651739, ce=39.78351498525077
Local test acc @ epoch 177: 0.9622
Global evaluate on test data...
Evaluate data in 82.84 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9014014082217435, ce=39.7720741481956
Global test acc : 0.9622
Global prompt norm: 57.90641784667969
Global epoch 178...
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.86 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9015949581741193, ce=39.83413262323502
Local test acc @ epoch 178: 0.9622
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.75 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9016996961121165, ce=39.845349513062644
Local test acc @ epoch 178: 0.9622
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.66 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9017912838437142, ce=39.83517361562186
Local test acc @ epoch 178: 0.9622
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9019926031795117, ce=39.8397400882266
Local test acc @ epoch 178: 0.9622
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.75 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9017002691916369, ce=39.81231815443127
Local test acc @ epoch 178: 0.9622
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.95 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9017511310927365, ce=39.82758803761333
Local test acc @ epoch 178: 0.9622
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.75 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9018611907958984, ce=39.85103078719673
Local test acc @ epoch 178: 0.9622
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.75 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9016271468696244, ce=39.8274459488895
Local test acc @ epoch 178: 0.9622
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.68 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9018778144766432, ce=39.835658047177375
Local test acc @ epoch 178: 0.9622
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.81 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9017642463019134, ce=39.82867778113129
Local test acc @ epoch 178: 0.9622
Global evaluate on test data...
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9017673654293795, ce=39.83374768878342
Global test acc : 0.9622
Global prompt norm: 57.9061393737793
Global epoch 179...
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.86 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.902023846950006, ce=39.895804378964485
Local test acc @ epoch 179: 0.9622
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.91 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9023208508797742, ce=39.896643752351814
Local test acc @ epoch 179: 0.9622
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.06 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9021187944149752, ce=39.873409376231905
Local test acc @ epoch 179: 0.9622
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.98 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9021476693109635, ce=39.90688145488774
Local test acc @ epoch 179: 0.9622
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.902208691343255, ce=39.88997097190367
Local test acc @ epoch 179: 0.9622
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9020551213430702, ce=39.88911409990503
Local test acc @ epoch 179: 0.9622
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9024453075653917, ce=39.90063539557501
Local test acc @ epoch 179: 0.9622
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.76 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9023098705011771, ce=39.91211539452229
Local test acc @ epoch 179: 0.9622
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9021863171813684, ce=39.88884815601034
Local test acc @ epoch 179: 0.9622
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.84 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.90223750718143, ce=39.89647391083044
Local test acc @ epoch 179: 0.9622
Global evaluate on test data...
Evaluate data in 82.94 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9022042029494539, ce=39.894968575293866
Global test acc : 0.9622
Global prompt norm: 57.90589904785156
Global epoch 180...
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.87 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9026357340156486, ce=39.949730689372494
Local test acc @ epoch 180: 0.9622
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9026836277148046, ce=39.95740043570142
Local test acc @ epoch 180: 0.9622
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.81 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9025977839023696, ce=39.967974041580064
Local test acc @ epoch 180: 0.9622
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.75 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9027529375268779, ce=39.97285709906062
Local test acc @ epoch 180: 0.9622
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.96 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9025718028392267, ce=39.934198152034654
Local test acc @ epoch 180: 0.9622
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.9 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9026556190000762, ce=39.95078764049285
Local test acc @ epoch 180: 0.9622
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.87 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.902884719568655, ce=39.96113586425781
Local test acc @ epoch 180: 0.9622
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.91 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9027662211601887, ce=39.957251067555276
Local test acc @ epoch 180: 0.9622
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.75 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9024733009688352, ce=39.95705861782809
Local test acc @ epoch 180: 0.9622
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.06 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9025050937582594, ce=39.95037712307151
Local test acc @ epoch 180: 0.9622
Global evaluate on test data...
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9026501244361248, ce=39.95590437442885
Global test acc : 0.9622
Global prompt norm: 57.90564727783203
Global epoch 181...
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.99 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9030077435554714, ce=39.99479139835463
Local test acc @ epoch 181: 0.9622
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.03 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9029114596340635, ce=40.01804285311918
Local test acc @ epoch 181: 0.9622
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.88 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9030323334790151, ce=40.02888278786195
Local test acc @ epoch 181: 0.9622
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9030917850109416, ce=40.01140783467424
Local test acc @ epoch 181: 0.9622
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.63 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9033151832195597, ce=40.02136436952363
Local test acc @ epoch 181: 0.9622
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.99 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9031163049400399, ce=40.01802731435233
Local test acc @ epoch 181: 0.9622
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.79 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9031972338300233, ce=40.017588029214004
Local test acc @ epoch 181: 0.9622
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.91 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9031876292797404, ce=40.03335112825446
Local test acc @ epoch 181: 0.9622
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.95 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9029409622927325, ce=40.01132226646493
Local test acc @ epoch 181: 0.9622
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.93 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9030714538119254, ce=40.01025754596115
Local test acc @ epoch 181: 0.9622
Global evaluate on test data...
Evaluate data in 83.01 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9030881037405871, ce=40.01652873327973
Global test acc : 0.9622
Global prompt norm: 57.90537643432617
Global epoch 182...
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.95 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9034935246913804, ce=40.070474047179616
Local test acc @ epoch 182: 0.9622
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9033710694094317, ce=40.071933431362886
Local test acc @ epoch 182: 0.9622
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.95 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9034565413763763, ce=40.08942770301749
Local test acc @ epoch 182: 0.9622
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.76 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9033348407220403, ce=40.07863739433638
Local test acc @ epoch 182: 0.9622
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.81 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9036073990918081, ce=40.09346064296337
Local test acc @ epoch 182: 0.9622
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.79 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9034364639072243, ce=40.05498728620897
Local test acc @ epoch 182: 0.9622
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.76 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.903733935924845, ce=40.081273805110825
Local test acc @ epoch 182: 0.9622
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.98 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9035182524164882, ce=40.07166969229322
Local test acc @ epoch 182: 0.9622
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9035392157528379, ce=40.078337258155194
Local test acc @ epoch 182: 0.9622
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.99 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9036180382474847, ce=40.07759720688566
Local test acc @ epoch 182: 0.9622
Global evaluate on test data...
Evaluate data in 82.98 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9035120644700636, ce=40.076838817071476
Global test acc : 0.9622
Global prompt norm: 57.905094146728516
Global epoch 183...
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.91 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9041432940631832, ce=40.1409526789954
Local test acc @ epoch 183: 0.9622
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.98 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9038525043277565, ce=40.11493574369938
Local test acc @ epoch 183: 0.9622
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.87 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9040288793931314, ce=40.13740098585776
Local test acc @ epoch 183: 0.9622
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.88 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.903788109438135, ce=40.132344342153004
Local test acc @ epoch 183: 0.9622
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.903753659047118, ce=40.13903255637633
Local test acc @ epoch 183: 0.9622
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9039511571236707, ce=40.13841100570259
Local test acc @ epoch 183: 0.9622
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.81 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.903867673436436, ce=40.14971087394505
Local test acc @ epoch 183: 0.9622
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.75 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9040187958183639, ce=40.153356219650405
Local test acc @ epoch 183: 0.9622
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.85 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9039284308022315, ce=40.131674390320384
Local test acc @ epoch 183: 0.9622
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.02 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9039070409372312, ce=40.1305332358824
Local test acc @ epoch 183: 0.9622
Global evaluate on test data...
Evaluate data in 82.91 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9039237105518306, ce=40.13683693562079
Global test acc : 0.9622
Global prompt norm: 57.90483474731445
Global epoch 184...
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.82 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9043108410791519, ce=40.1902183392726
Local test acc @ epoch 184: 0.9622
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.84 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.904539519493733, ce=40.200257397572926
Local test acc @ epoch 184: 0.9622
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9041541432021954, ce=40.19910630392372
Local test acc @ epoch 184: 0.9622
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.89 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9044269268665839, ce=40.1968376789618
Local test acc @ epoch 184: 0.9622
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.96 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9043497951752549, ce=40.198193751343894
Local test acc @ epoch 184: 0.9622
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.84 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9042544714901426, ce=40.174641250470366
Local test acc @ epoch 184: 0.9622
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.9 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9041930251165268, ce=40.1924074155475
Local test acc @ epoch 184: 0.9622
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.75 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9043298117611387, ce=40.191414859316765
Local test acc @ epoch 184: 0.9622
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.9 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9044131926440317, ce=40.21297157357592
Local test acc @ epoch 184: 0.9622
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.96 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9042668167604219, ce=40.20973314057797
Local test acc @ epoch 184: 0.9622
Global evaluate on test data...
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9043251877530999, ce=40.19659000361731
Global test acc : 0.9622
Global prompt norm: 57.90457534790039
Global epoch 185...
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9045846790348718, ce=40.252257215867346
Local test acc @ epoch 185: 0.9622
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.84 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9046994305531914, ce=40.24963189921248
Local test acc @ epoch 185: 0.9622
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.86 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9047996122902686, ce=40.27231545404557
Local test acc @ epoch 185: 0.9622
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.94 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9047199258016884, ce=40.25085977676812
Local test acc @ epoch 185: 0.9622
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.02 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9046455282683766, ce=40.23396080787029
Local test acc @ epoch 185: 0.9622
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.85 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9048150438781178, ce=40.25610421556945
Local test acc @ epoch 185: 0.9622
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.73 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9049263875418847, ce=40.25940259880976
Local test acc @ epoch 185: 0.9622
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.7 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9047387039989506, ce=40.257707228354356
Local test acc @ epoch 185: 0.9622
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.79 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9046555834079008, ce=40.26946738006872
Local test acc @ epoch 185: 0.9622
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.89 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9045451737325126, ce=40.2589372757378
Local test acc @ epoch 185: 0.9622
Global evaluate on test data...
Evaluate data in 82.88 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9047123248424005, ce=40.25605224469386
Global test acc : 0.9622
Global prompt norm: 57.90428924560547
Global epoch 186...
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9051746753377652, ce=40.331463070090756
Local test acc @ epoch 186: 0.9622
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.82 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.905032711291532, ce=40.329019529010175
Local test acc @ epoch 186: 0.9622
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9051139442198867, ce=40.317036130012724
Local test acc @ epoch 186: 0.9622
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.64 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9050765934340451, ce=40.308914254564755
Local test acc @ epoch 186: 0.9622
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9049662537531021, ce=40.311817869133904
Local test acc @ epoch 186: 0.9622
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.86 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9053000419511708, ce=40.31832567267462
Local test acc @ epoch 186: 0.9622
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.12 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9050989960311749, ce=40.31018083904861
Local test acc @ epoch 186: 0.9622
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.86 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9050281507159592, ce=40.2931180481517
Local test acc @ epoch 186: 0.9622
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.79 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9049262497403207, ce=40.31852508684911
Local test acc @ epoch 186: 0.9622
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9051920383348377, ce=40.31520539030023
Local test acc @ epoch 186: 0.9622
Global evaluate on test data...
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9050929458863145, ce=40.31540784923308
Global test acc : 0.9622
Global prompt norm: 57.90401840209961
Global epoch 187...
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.85 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9055579080494172, ce=40.373933249657306
Local test acc @ epoch 187: 0.9622
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.96 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9053976667036704, ce=40.35209001313656
Local test acc @ epoch 187: 0.9622
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.93 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9054806363691977, ce=40.376020169039386
Local test acc @ epoch 187: 0.9622
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.96 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9052934580986652, ce=40.37794004667789
Local test acc @ epoch 187: 0.9622
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.89 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9053998715286955, ce=40.388279206162196
Local test acc @ epoch 187: 0.9622
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.82 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9054675692812019, ce=40.36914604956951
Local test acc @ epoch 187: 0.9622
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9055405691129352, ce=40.39034607213571
Local test acc @ epoch 187: 0.9622
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.92 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.90533764427955, ce=40.371207175998514
Local test acc @ epoch 187: 0.9622
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9054483186214342, ce=40.367905852991505
Local test acc @ epoch 187: 0.9622
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.1 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9056649623660866, ce=40.37699911135052
Local test acc @ epoch 187: 0.9622
Global evaluate on test data...
Evaluate data in 82.91 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9054595264819784, ce=40.3744224408351
Global test acc : 0.9622
Global prompt norm: 57.90373611450195
Global epoch 188...
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9057547958619004, ce=40.447289948069724
Local test acc @ epoch 188: 0.9622
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9058378486458315, ce=40.43486614402281
Local test acc @ epoch 188: 0.9622
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.905830529851651, ce=40.42794278346071
Local test acc @ epoch 188: 0.9622
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.9 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9056526914649053, ce=40.4370646345506
Local test acc @ epoch 188: 0.9622
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.99 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.905802497076332, ce=40.426662935029476
Local test acc @ epoch 188: 0.9622
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.07 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.905911705909519, ce=40.43250554635984
Local test acc @ epoch 188: 0.9622
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.08 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9057590327131639, ce=40.410777765676514
Local test acc @ epoch 188: 0.9622
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.84 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9056966457891902, ce=40.430328999090634
Local test acc @ epoch 188: 0.9622
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.82 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9060194579833144, ce=40.43546666136575
Local test acc @ epoch 188: 0.9622
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.86 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9058949794244329, ce=40.44904323892856
Local test acc @ epoch 188: 0.9622
Global evaluate on test data...
Evaluate data in 82.82 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9058172462183401, ce=40.433206505731704
Global test acc : 0.9622
Global prompt norm: 57.90349578857422
Global epoch 189...
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.93 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9060436607500829, ce=40.48928962497536
Local test acc @ epoch 189: 0.9622
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9062566975934789, ce=40.49097792599179
Local test acc @ epoch 189: 0.9622
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.03 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9059982846636291, ce=40.49600650192401
Local test acc @ epoch 189: 0.9622
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.85 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9062362067196348, ce=40.507630514442376
Local test acc @ epoch 189: 0.9622
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.81 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9061794346625652, ce=40.493557886246144
Local test acc @ epoch 189: 0.9622
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.81 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9061092717931905, ce=40.46933536354555
Local test acc @ epoch 189: 0.9622
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.73 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9060982761033084, ce=40.50621984639299
Local test acc @ epoch 189: 0.9622
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.84 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9061719605682093, ce=40.486600018422536
Local test acc @ epoch 189: 0.9622
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.68 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9063611358677576, ce=40.49381291100738
Local test acc @ epoch 189: 0.9622
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.86 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9061499932490358, ce=40.4852949369938
Local test acc @ epoch 189: 0.9622
Global evaluate on test data...
Evaluate data in 83.01 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9061599412095656, ce=40.491874974802
Global test acc : 0.9622
Global prompt norm: 57.903228759765625
Global epoch 190...
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.92 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9065883531482941, ce=40.549161718526015
Local test acc @ epoch 190: 0.9622
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.87 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9063848661720206, ce=40.547987631701545
Local test acc @ epoch 190: 0.9622
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.81 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9065690937392209, ce=40.565868972638334
Local test acc @ epoch 190: 0.9622
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9065125338528135, ce=40.544989279650764
Local test acc @ epoch 190: 0.9622
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.57 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9064861393849785, ce=40.543645176318805
Local test acc @ epoch 190: 0.9622
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.7 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9065156201703832, ce=40.55198903914985
Local test acc @ epoch 190: 0.9622
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.7 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9063367340542855, ce=40.5547356211811
Local test acc @ epoch 190: 0.9622
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.02 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9064341269501852, ce=40.56492569249704
Local test acc @ epoch 190: 0.9622
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9064458575817423, ce=40.527692427328965
Local test acc @ epoch 190: 0.9622
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.88 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9066918661834997, ce=40.551893251751544
Local test acc @ epoch 190: 0.9622
Global evaluate on test data...
Evaluate data in 82.76 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9064966473010702, ce=40.55027638006648
Global test acc : 0.9622
Global prompt norm: 57.90297317504883
Global epoch 191...
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.89 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9070148074298824, ce=40.609886309422485
Local test acc @ epoch 191: 0.9622
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.906836949357199, ce=40.61038904452543
Local test acc @ epoch 191: 0.9622
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.86 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9068361794183014, ce=40.6033505431009
Local test acc @ epoch 191: 0.9622
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9067554561370009, ce=40.6235068434969
Local test acc @ epoch 191: 0.9622
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.9 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9066618145059008, ce=40.613360518709236
Local test acc @ epoch 191: 0.9622
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.7 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9069136151480018, ce=40.60728605077901
Local test acc @ epoch 191: 0.9622
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.88 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9067739456071766, ce=40.58589704321065
Local test acc @ epoch 191: 0.9622
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.75 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9067137460096166, ce=40.606712411303036
Local test acc @ epoch 191: 0.9622
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9068896967336673, ce=40.624119014914974
Local test acc @ epoch 191: 0.9622
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.87 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9068113226409352, ce=40.60194578958214
Local test acc @ epoch 191: 0.9622
Global evaluate on test data...
Evaluate data in 82.87 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9068197132250585, ce=40.60860968073574
Global test acc : 0.9622
Global prompt norm: 57.90270233154297
Global epoch 192...
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.02 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9070717194758424, ce=40.68180931161303
Local test acc @ epoch 192: 0.9622
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.96 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9070932690156709, ce=40.643870467439704
Local test acc @ epoch 192: 0.9622
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.06 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9071555487606504, ce=40.66847117012794
Local test acc @ epoch 192: 0.9622
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.23 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9071275466079012, ce=40.660049648459896
Local test acc @ epoch 192: 0.9622
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.84 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9073268076695433, ce=40.66769223694408
Local test acc @ epoch 192: 0.9622
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9072297166246887, ce=40.6651939252101
Local test acc @ epoch 192: 0.9622
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.76 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9069826493569471, ce=40.671774487976634
Local test acc @ epoch 192: 0.9622
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9071534358033346, ce=40.661440473084056
Local test acc @ epoch 192: 0.9622
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.86 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9070293728364717, ce=40.66509859277568
Local test acc @ epoch 192: 0.9622
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.907202795011188, ce=40.68218294196173
Local test acc @ epoch 192: 0.9622
Global evaluate on test data...
Evaluate data in 83.05 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.907137901411144, ce=40.6667138545885
Global test acc : 0.9622
Global prompt norm: 57.902435302734375
Global epoch 193...
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9073372630898012, ce=40.723402775755716
Local test acc @ epoch 193: 0.9622
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.79 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9072859615360925, ce=40.7301116733376
Local test acc @ epoch 193: 0.9622
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.84 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9074047989801529, ce=40.701765567884536
Local test acc @ epoch 193: 0.9622
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.82 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9074556149473978, ce=40.726523793071784
Local test acc @ epoch 193: 0.9622
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.95 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9074326523947059, ce=40.71801404340552
Local test acc @ epoch 193: 0.9622
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.94 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9074598583606405, ce=40.71944945449129
Local test acc @ epoch 193: 0.9622
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.89 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9075075726990306, ce=40.74007940729824
Local test acc @ epoch 193: 0.9622
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.92 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9075317098460066, ce=40.72300114762892
Local test acc @ epoch 193: 0.9622
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9073745066966485, ce=40.74013883258225
Local test acc @ epoch 193: 0.9622
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9076296233255928, ce=40.7253899180561
Local test acc @ epoch 193: 0.9622
Global evaluate on test data...
Evaluate data in 82.9 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9074388884623116, ce=40.724770922179616
Global test acc : 0.9622
Global prompt norm: 57.902164459228516
Global epoch 194...
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9075785186312614, ce=40.788232330882224
Local test acc @ epoch 194: 0.9622
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.02 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9077485417007306, ce=40.78436083312428
Local test acc @ epoch 194: 0.9622
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.85 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9076684549314167, ce=40.798274363946476
Local test acc @ epoch 194: 0.9622
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.85 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9077999854306562, ce=40.79783969844153
Local test acc @ epoch 194: 0.9622
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.86 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9079216773356866, ce=40.78287789581019
Local test acc @ epoch 194: 0.9622
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9076999961783033, ce=40.75947091338831
Local test acc @ epoch 194: 0.9622
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9077560770402261, ce=40.777283624771535
Local test acc @ epoch 194: 0.9622
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9078259096233123, ce=40.780660646771075
Local test acc @ epoch 194: 0.9622
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.99 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9077316358548786, ce=40.775805832049166
Local test acc @ epoch 194: 0.9622
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.01 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9076352360051706, ce=40.78150086009175
Local test acc @ epoch 194: 0.9622
Global evaluate on test data...
Evaluate data in 82.93 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.907738335635684, ce=40.78267837664403
Global test acc : 0.9622
Global prompt norm: 57.90190124511719
Global epoch 195...
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9082052357699892, ce=40.840337840788955
Local test acc @ epoch 195: 0.9622
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.88 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9081088774794832, ce=40.83820566999803
Local test acc @ epoch 195: 0.9622
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.82 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9080299674917799, ce=40.842196508285106
Local test acc @ epoch 195: 0.9622
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.87 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9079220579304826, ce=40.839653505097836
Local test acc @ epoch 195: 0.9622
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.04 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9080152992808491, ce=40.833559473720165
Local test acc @ epoch 195: 0.9622
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9080823342734521, ce=40.85558693562079
Local test acc @ epoch 195: 0.9622
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.82 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9078634025853708, ce=40.84634269924339
Local test acc @ epoch 195: 0.9622
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.93 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9079519389966212, ce=40.85628705505931
Local test acc @ epoch 195: 0.9622
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.91 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9079889004383612, ce=40.81712309811093
Local test acc @ epoch 195: 0.9622
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9080425730539025, ce=40.835013923295044
Local test acc @ epoch 195: 0.9622
Global evaluate on test data...
Evaluate data in 82.92 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9080230489783331, ce=40.840433768176155
Global test acc : 0.9622
Global prompt norm: 57.90162658691406
Global epoch 196...
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9083175024855028, ce=40.892617111906
Local test acc @ epoch 196: 0.9622
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.95 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9081986300442197, ce=40.89749236500591
Local test acc @ epoch 196: 0.9622
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.98 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.90826733177955, ce=40.87472485183576
Local test acc @ epoch 196: 0.9622
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9082888988179898, ce=40.891176766211835
Local test acc @ epoch 196: 0.9622
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.72 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9081407030788037, ce=40.90426922719413
Local test acc @ epoch 196: 0.9622
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9082240992729816, ce=40.914180860606905
Local test acc @ epoch 196: 0.9622
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9083542692551919, ce=40.913110435555836
Local test acc @ epoch 196: 0.9622
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.75 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9083828729227048, ce=40.89561966362349
Local test acc @ epoch 196: 0.9622
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.84 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9083072526739278, ce=40.89982422994911
Local test acc @ epoch 196: 0.9622
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.99 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9084743972218364, ce=40.89765699194112
Local test acc @ epoch 196: 0.9622
Global evaluate on test data...
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.908296020752793, ce=40.89801147880904
Global test acc : 0.9622
Global prompt norm: 57.9013671875
Global epoch 197...
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9087374035371553, ce=40.954964559012595
Local test acc @ epoch 197: 0.9622
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.64 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9085856293319562, ce=40.95022268032809
Local test acc @ epoch 197: 0.9622
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.91 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9086163022102566, ce=40.97057286533741
Local test acc @ epoch 197: 0.9622
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.01 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9085683516406138, ce=40.95741831928218
Local test acc @ epoch 197: 0.9622
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.84 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9084051530295556, ce=40.962169507227905
Local test acc @ epoch 197: 0.9622
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.81 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9085310861605023, ce=40.93206363642981
Local test acc @ epoch 197: 0.9622
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9086446062140509, ce=40.95305049091304
Local test acc @ epoch 197: 0.9622
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.84 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9084664156677527, ce=40.95538547060905
Local test acc @ epoch 197: 0.9622
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.87 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9085565138300624, ce=40.948597794279046
Local test acc @ epoch 197: 0.9622
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.81 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9084851216832432, ce=40.97206301207936
Local test acc @ epoch 197: 0.9622
Global evaluate on test data...
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9085603832104884, ce=40.95563783558137
Global test acc : 0.9622
Global prompt norm: 57.90110778808594
Global epoch 198...
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.85 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9088099943388492, ce=41.00620070291222
Local test acc @ epoch 198: 0.9622
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.91 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9087256313463964, ce=41.013246973720165
Local test acc @ epoch 198: 0.9622
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.86 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9089031766314025, ce=41.010407299076746
Local test acc @ epoch 198: 0.9622
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.88 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9087390965277996, ce=41.029784071336096
Local test acc @ epoch 198: 0.9622
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.79 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9088254259266985, ce=41.015034176887724
Local test acc @ epoch 198: 0.9622
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9089932901049973, ce=41.01217672365521
Local test acc @ epoch 198: 0.9622
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.97 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.908793066619733, ce=40.989510597438986
Local test acc @ epoch 198: 0.9622
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.89 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9088409471949306, ce=41.007740860685296
Local test acc @ epoch 198: 0.9622
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.84 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9088692840086211, ce=41.02805615346366
Local test acc @ epoch 198: 0.9622
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.82 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9086604643305507, ce=41.01998183924124
Local test acc @ epoch 198: 0.9622
Global evaluate on test data...
Evaluate data in 82.85 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9088150820600878, ce=41.013213306392004
Global test acc : 0.9622
Global prompt norm: 57.90081787109375
Global epoch 199...
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.86 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9090702664961509, ce=41.072375656267916
Local test acc @ epoch 199: 0.9622
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.72 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9091508126040118, ce=41.06755219905748
Local test acc @ epoch 199: 0.9622
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.82 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.908985116066189, ce=41.0874501499561
Local test acc @ epoch 199: 0.9622
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.81 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9090420631093716, ce=41.04673224632893
Local test acc @ epoch 199: 0.9622
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.96 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9091138599115774, ce=41.08530520517892
Local test acc @ epoch 199: 0.9622
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.86 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.909088451927955, ce=41.06504895271511
Local test acc @ epoch 199: 0.9622
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.86 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9089701569408452, ce=41.07089338390105
Local test acc @ epoch 199: 0.9622
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.01 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9092359849072378, ce=41.06917257046481
Local test acc @ epoch 199: 0.9622
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9089030432044913, ce=41.07767514570044
Local test acc @ epoch 199: 0.9622
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.79 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.9090608544305924, ce=41.063498855730806
Local test acc @ epoch 199: 0.9622
Global evaluate on test data...
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9621559633027523, hinge=0.909061576248309, ce=41.070625060195226
Global test acc : 0.9622
Global prompt norm: 57.90056610107422
Global epoch 200...
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.64 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9093826888898097, ce=41.124705533368875
Local test acc @ epoch 200: 0.961
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9093038620205101, ce=41.129739043909474
Local test acc @ epoch 200: 0.961
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.76 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9092808732199013, ce=41.10394689577435
Local test acc @ epoch 200: 0.961
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.98 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9092182916238767, ce=41.1450117968638
Local test acc @ epoch 200: 0.961
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.95 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9093461342907827, ce=41.14257004064157
Local test acc @ epoch 200: 0.961
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.94 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9092092557784615, ce=41.128548613382044
Local test acc @ epoch 200: 0.961
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9093255777971461, ce=41.122408035698285
Local test acc @ epoch 200: 0.961
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.93 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9091443031206043, ce=41.13524270713876
Local test acc @ epoch 200: 0.961
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.88 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9092948896075608, ce=41.12078713933262
Local test acc @ epoch 200: 0.961
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.01 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9094697422937515, ce=41.12627095913668
Local test acc @ epoch 200: 0.961
Global evaluate on test data...
Evaluate data in 82.75 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.90929679914352, ce=41.127943126433486
Global test acc : 0.961
Global prompt norm: 57.90028762817383
Global epoch 201...
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.88 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9095725422605462, ce=41.199780140448055
Local test acc @ epoch 201: 0.961
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.84 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9094411495628707, ce=41.20253022220157
Local test acc @ epoch 201: 0.961
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.0 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9095529350665731, ce=41.17962705979654
Local test acc @ epoch 201: 0.961
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.95 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9094376235926916, ce=41.18605426473355
Local test acc @ epoch 201: 0.961
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9095102297056705, ce=41.161009097318036
Local test acc @ epoch 201: 0.961
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.75 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9093674279134208, ce=41.192791860037985
Local test acc @ epoch 201: 0.961
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9095213216379148, ce=41.17797354601939
Local test acc @ epoch 201: 0.961
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9095264509183552, ce=41.18699369518035
Local test acc @ epoch 201: 0.961
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.86 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9096093309034995, ce=41.18177931899324
Local test acc @ epoch 201: 0.961
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.84 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9096934139181715, ce=41.18314053596706
Local test acc @ epoch 201: 0.961
Global evaluate on test data...
Evaluate data in 82.87 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9095251932056672, ce=41.18521758613237
Global test acc : 0.961
Global prompt norm: 57.90001678466797
Global epoch 202...
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9095850800155499, ce=41.25027238338365
Local test acc @ epoch 202: 0.961
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.12 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9097409620197541, ce=41.235197644714916
Local test acc @ epoch 202: 0.961
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.69 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9097418063277498, ce=41.244279563973805
Local test acc @ epoch 202: 0.961
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.82 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9096565005976126, ce=41.24350983505949
Local test acc @ epoch 202: 0.961
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.82 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9097834617719738, ce=41.25690040238407
Local test acc @ epoch 202: 0.961
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9097288289201368, ce=41.21817454066845
Local test acc @ epoch 202: 0.961
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.6 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9096549869677343, ce=41.25999695664152
Local test acc @ epoch 202: 0.961
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.88 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9099105782465103, ce=41.240154581332426
Local test acc @ epoch 202: 0.961
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9098247103734848, ce=41.23889681614867
Local test acc @ epoch 202: 0.961
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.69 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9097675752202306, ce=41.23679869765535
Local test acc @ epoch 202: 0.961
Global evaluate on test data...
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9097382716082651, ce=41.242435980280604
Global test acc : 0.961
Global prompt norm: 57.899757385253906
Global epoch 203...
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.1 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9099397724921551, ce=41.275140114880486
Local test acc @ epoch 203: 0.961
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9098577521262913, ce=41.31738809708062
Local test acc @ epoch 203: 0.961
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.92 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9101127462649564, ce=41.29693677009792
Local test acc @ epoch 203: 0.961
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.89 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9098646465791475, ce=41.30094465203241
Local test acc @ epoch 203: 0.961
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.88 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9099754521606165, ce=41.29389197673272
Local test acc @ epoch 203: 0.961
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.909788591052414, ce=41.3077205342984
Local test acc @ epoch 203: 0.961
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.7 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.910027735823885, ce=41.295821303621345
Local test acc @ epoch 203: 0.961
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.72 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9099468069339017, ce=41.30140787527102
Local test acc @ epoch 203: 0.961
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9099857369694141, ce=41.31398255234465
Local test acc @ epoch 203: 0.961
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.9 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9099477606082181, ce=41.29223839296113
Local test acc @ epoch 203: 0.961
Global evaluate on test data...
Evaluate data in 82.98 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.909943589376747, ce=41.299523134844016
Global test acc : 0.961
Global prompt norm: 57.89948654174805
Global epoch 204...
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.99 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9099871718555416, ce=41.365196333019014
Local test acc @ epoch 204: 0.961
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.9 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9101395891347063, ce=41.358688214503296
Local test acc @ epoch 204: 0.961
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9101736479942951, ce=41.351142603323
Local test acc @ epoch 204: 0.961
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.79 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9103082188772499, ce=41.353917918074025
Local test acc @ epoch 204: 0.961
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.7 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9101442197047243, ce=41.34944821278983
Local test acc @ epoch 204: 0.961
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9100534631571638, ce=41.37488881382374
Local test acc @ epoch 204: 0.961
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.69 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9101823273055051, ce=41.37117361366202
Local test acc @ epoch 204: 0.961
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.87 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.910139138545465, ce=41.33209903962022
Local test acc @ epoch 204: 0.961
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.82 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9102285039534262, ce=41.35287356595381
Local test acc @ epoch 204: 0.961
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.04 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.910062656490081, ce=41.35852680731257
Local test acc @ epoch 204: 0.961
Global evaluate on test data...
Evaluate data in 82.85 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9101383686065674, ce=41.3568497404046
Global test acc : 0.961
Global prompt norm: 57.899200439453125
Global epoch 205...
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.85 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9103265005514163, ce=41.415819780542215
Local test acc @ epoch 205: 0.961
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.72 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9101708263432214, ce=41.42268984033427
Local test acc @ epoch 205: 0.961
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.86 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9103317173249131, ce=41.406539846997745
Local test acc @ epoch 205: 0.961
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.72 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9103627511120718, ce=41.40835315809338
Local test acc @ epoch 205: 0.961
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9103289087977978, ce=41.38921373699783
Local test acc @ epoch 205: 0.961
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.84 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9104119922042987, ce=41.40990098025821
Local test acc @ epoch 205: 0.961
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.94 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9102509809196542, ce=41.415949445252025
Local test acc @ epoch 205: 0.961
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.92 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9102397293125818, ce=41.43234921376639
Local test acc @ epoch 205: 0.961
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9103688231301964, ce=41.4283674747572
Local test acc @ epoch 205: 0.961
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9104947234512469, ce=41.41082490693539
Local test acc @ epoch 205: 0.961
Global evaluate on test data...
Evaluate data in 82.81 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.910330870829591, ce=41.41397203217953
Global test acc : 0.961
Global prompt norm: 57.89892578125
Global epoch 206...
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9105138406841033, ce=41.46362577665836
Local test acc @ epoch 206: 0.961
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9105439076729871, ce=41.46546078603202
Local test acc @ epoch 206: 0.961
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.66 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9106721549952795, ce=41.46762536425109
Local test acc @ epoch 206: 0.961
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.03 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9103485597382992, ce=41.48011142835705
Local test acc @ epoch 206: 0.961
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.76 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9104138361204654, ce=41.48976579718634
Local test acc @ epoch 206: 0.961
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.92 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9105464909054818, ce=41.48537067098355
Local test acc @ epoch 206: 0.961
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9105888419195053, ce=41.46682308791974
Local test acc @ epoch 206: 0.961
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9104298451624879, ce=41.47333215136047
Local test acc @ epoch 206: 0.961
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9105109031047296, ce=41.4462369166383
Local test acc @ epoch 206: 0.961
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.75 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9105029740464796, ce=41.47299575805664
Local test acc @ epoch 206: 0.961
Global evaluate on test data...
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9105071977737846, ce=41.471108077862944
Global test acc : 0.961
Global prompt norm: 57.89865493774414
Global epoch 207...
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9106831747457522, ce=41.520755102875036
Local test acc @ epoch 207: 0.961
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.61 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.910757874130109, ce=41.523894703716316
Local test acc @ epoch 207: 0.961
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.7 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9106702607706052, ce=41.53021730195492
Local test acc @ epoch 207: 0.961
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.05 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9105793095509941, ce=41.547186020317426
Local test acc @ epoch 207: 0.961
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.93 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9108434379647631, ce=41.52453333303469
Local test acc @ epoch 207: 0.961
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.72 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9106017952665276, ce=41.53081365462837
Local test acc @ epoch 207: 0.961
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9106820679585869, ce=41.50325068202587
Local test acc @ epoch 207: 0.961
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.82 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9107122290025064, ce=41.54248519337505
Local test acc @ epoch 207: 0.961
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.92 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9105152340110289, ce=41.53755646451898
Local test acc @ epoch 207: 0.961
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9107123449308063, ce=41.52261706011011
Local test acc @ epoch 207: 0.961
Global evaluate on test data...
Evaluate data in 82.75 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9106760090644207, ce=41.528293364638586
Global test acc : 0.961
Global prompt norm: 57.89837646484375
Global epoch 208...
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.7 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9107614854060182, ce=41.58821441930368
Local test acc @ epoch 208: 0.961
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9108733234055545, ce=41.57973256242384
Local test acc @ epoch 208: 0.961
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9108276957765632, ce=41.587366926560705
Local test acc @ epoch 208: 0.961
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.97 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9108666126881171, ce=41.59961091487779
Local test acc @ epoch 208: 0.961
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.85 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.910673373336092, ce=41.594978577500086
Local test acc @ epoch 208: 0.961
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9108469573729628, ce=41.56023221497142
Local test acc @ epoch 208: 0.961
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.91 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9109956058887166, ce=41.581332005492044
Local test acc @ epoch 208: 0.961
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9109167024629925, ce=41.5808428843087
Local test acc @ epoch 208: 0.961
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.75 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9107306703515009, ce=41.60462748676265
Local test acc @ epoch 208: 0.961
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.82 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9108408394209836, ce=41.577832493213336
Local test acc @ epoch 208: 0.961
Global evaluate on test data...
Evaluate data in 82.86 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9108311845621931, ce=41.585510568881254
Global test acc : 0.961
Global prompt norm: 57.89808654785156
Global epoch 209...
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.96 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9109921302270452, ce=41.63502481443073
Local test acc @ epoch 209: 0.961
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.95 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9110223897006533, ce=41.63696233066944
Local test acc @ epoch 209: 0.961
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.69 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9111444906357231, ce=41.63835861486032
Local test acc @ epoch 209: 0.961
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.73 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9109974279316193, ce=41.617328468812715
Local test acc @ epoch 209: 0.961
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9108791832530171, ce=41.66213663783642
Local test acc @ epoch 209: 0.961
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.86 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9110650469403748, ce=41.6379375982722
Local test acc @ epoch 209: 0.961
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.0 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9109760927497794, ce=41.644600229525786
Local test acc @ epoch 209: 0.961
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.86 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9109135877101793, ce=41.645731024785874
Local test acc @ epoch 209: 0.961
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.05 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9110148740470956, ce=41.65682818911491
Local test acc @ epoch 209: 0.961
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9108212978468029, ce=41.652483808884924
Local test acc @ epoch 209: 0.961
Global evaluate on test data...
Evaluate data in 82.82 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9109844767719234, ce=41.64268941616793
Global test acc : 0.961
Global prompt norm: 57.89781188964844
Global epoch 210...
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.59 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.911113977432251, ce=41.701868984677375
Local test acc @ epoch 210: 0.961
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9112080827765509, ce=41.695016528488296
Local test acc @ epoch 210: 0.961
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.91 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9111627482492989, ce=41.69419248388448
Local test acc @ epoch 210: 0.961
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.98 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9110167004646511, ce=41.719680401163366
Local test acc @ epoch 210: 0.961
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9109606961591528, ce=41.71005070537602
Local test acc @ epoch 210: 0.961
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.87 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9110491407026938, ce=41.703286407190724
Local test acc @ epoch 210: 0.961
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.79 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9112844292176973, ce=41.69525069490485
Local test acc @ epoch 210: 0.961
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.91 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9111421042626057, ce=41.67439025038973
Local test acc @ epoch 210: 0.961
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9111311479445992, ce=41.69224891312626
Local test acc @ epoch 210: 0.961
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9111528068507483, ce=41.71402876967684
Local test acc @ epoch 210: 0.961
Global evaluate on test data...
Evaluate data in 82.93 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9111223986389441, ce=41.70002452605361
Global test acc : 0.961
Global prompt norm: 57.89752197265625
Global epoch 211...
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.95 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.911244051172099, ce=41.75919230049903
Local test acc @ epoch 211: 0.961
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.79 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9110874254769141, ce=41.7676222215005
Local test acc @ epoch 211: 0.961
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9112627243776934, ce=41.74953936655587
Local test acc @ epoch 211: 0.961
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.67 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.911278538747665, ce=41.771311978681375
Local test acc @ epoch 211: 0.961
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.82 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9111408509245706, ce=41.777320091877506
Local test acc @ epoch 211: 0.961
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.68 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.911336920676975, ce=41.752178402122006
Local test acc @ epoch 211: 0.961
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.9 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9114124249974522, ce=41.75232077082363
Local test acc @ epoch 211: 0.961
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.08 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9112959236180017, ce=41.75151432982278
Local test acc @ epoch 211: 0.961
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.79 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9111836394038769, ce=41.76085536851795
Local test acc @ epoch 211: 0.961
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9112751943255784, ce=41.7315556237457
Local test acc @ epoch 211: 0.961
Global evaluate on test data...
Evaluate data in 82.93 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9112540647524212, ce=41.75729566101634
Global test acc : 0.961
Global prompt norm: 57.89725875854492
Global epoch 212...
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.81 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9113837097762921, ce=41.8067325277066
Local test acc @ epoch 212: 0.961
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9113608237800248, ce=41.81657073694632
Local test acc @ epoch 212: 0.961
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.87 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9114583326042245, ce=41.80932242717218
Local test acc @ epoch 212: 0.961
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.02 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9112051539464828, ce=41.825232689533756
Local test acc @ epoch 212: 0.961
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.97 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9115322795482951, ce=41.809360924117065
Local test acc @ epoch 212: 0.961
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.87 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9114011230818723, ce=41.78867427580947
Local test acc @ epoch 212: 0.961
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.82 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9114155200643277, ce=41.808792394235596
Local test acc @ epoch 212: 0.961
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.72 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9112567026680762, ce=41.83492181060511
Local test acc @ epoch 212: 0.961
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.84 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9113990166865358, ce=41.82861177636943
Local test acc @ epoch 212: 0.961
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.93 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9113026080875222, ce=41.81848291519585
Local test acc @ epoch 212: 0.961
Global evaluate on test data...
Evaluate data in 83.02 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9113733615350286, ce=41.8146123273657
Global test acc : 0.961
Global prompt norm: 57.8969612121582
Global epoch 213...
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.9 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9114169002672948, ce=41.87619123546355
Local test acc @ epoch 213: 0.961
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.81 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9115649232076942, ce=41.8666099408351
Local test acc @ epoch 213: 0.961
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.81 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9116426651630927, ce=41.86648521073368
Local test acc @ epoch 213: 0.961
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9114947756496045, ce=41.864212876066155
Local test acc @ epoch 213: 0.961
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.88 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9115163711232876, ce=41.84596696906134
Local test acc @ epoch 213: 0.961
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.86 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9115061738075466, ce=41.88598748303335
Local test acc @ epoch 213: 0.961
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.81 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9114684511762147, ce=41.87406231941433
Local test acc @ epoch 213: 0.961
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9113126347918029, ce=41.88300302487995
Local test acc @ epoch 213: 0.961
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.82 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9115273099426829, ce=41.86625898868666
Local test acc @ epoch 213: 0.961
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.73 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9113633501420327, ce=41.89263097080616
Local test acc @ epoch 213: 0.961
Global evaluate on test data...
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9114802627388491, ce=41.872156265678754
Global test acc : 0.961
Global prompt norm: 57.89667510986328
Global epoch 214...
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.98 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9114619810646827, ce=41.95035024520454
Local test acc @ epoch 214: 0.961
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.95 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9115662356035426, ce=41.93147134343418
Local test acc @ epoch 214: 0.961
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.98 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9117422606966911, ce=41.923647434339614
Local test acc @ epoch 214: 0.961
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.02 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9115962522839187, ce=41.921603141574685
Local test acc @ epoch 214: 0.961
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.96 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9116053974956547, ce=41.9433476159332
Local test acc @ epoch 214: 0.961
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.86 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9116172003089835, ce=41.90327572603838
Local test acc @ epoch 214: 0.961
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.85 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9115158111677257, ce=41.933862388680836
Local test acc @ epoch 214: 0.961
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.92 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9114122543859919, ce=41.940709070328175
Local test acc @ epoch 214: 0.961
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.87 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9116662598531181, ce=41.9239501953125
Local test acc @ epoch 214: 0.961
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.88 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9116301055348247, ce=41.92366881764263
Local test acc @ epoch 214: 0.961
Global evaluate on test data...
Evaluate data in 82.81 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9115807725748885, ce=41.9296036466546
Global test acc : 0.961
Global prompt norm: 57.896385192871094
Global epoch 215...
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9115483126509081, ce=42.00818557039313
Local test acc @ epoch 215: 0.961
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.75 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9117117759284623, ce=41.960609331043486
Local test acc @ epoch 215: 0.961
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9116580376931287, ce=41.989057908364394
Local test acc @ epoch 215: 0.961
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.92 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9117577994635345, ce=41.98134606037665
Local test acc @ epoch 215: 0.961
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9116938354772165, ce=42.00094030537736
Local test acc @ epoch 215: 0.961
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.03 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.911687710963258, ce=41.979117507234626
Local test acc @ epoch 215: 0.961
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.02 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9114998174369882, ce=41.998506003563556
Local test acc @ epoch 215: 0.961
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.73 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9116087331684357, ce=41.99173421597262
Local test acc @ epoch 215: 0.961
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.9 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9117211770573888, ce=41.98123609910318
Local test acc @ epoch 215: 0.961
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.85 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9118315845454504, ce=41.98094768699156
Local test acc @ epoch 215: 0.961
Global evaluate on test data...
Evaluate data in 82.88 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.91167050982834, ce=41.98716956322346
Global test acc : 0.961
Global prompt norm: 57.89611053466797
Global epoch 216...
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.87 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9117971188431486, ce=42.018100493544836
Local test acc @ epoch 216: 0.961
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.84 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9116886165163932, ce=42.04976223586896
Local test acc @ epoch 216: 0.961
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.82 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9118367685090512, ce=42.03894676418479
Local test acc @ epoch 216: 0.961
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.92 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9115801229389435, ce=42.056587534213286
Local test acc @ epoch 216: 0.961
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.96 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9116230732804045, ce=42.06629898351267
Local test acc @ epoch 216: 0.961
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9117676927409041, ce=42.03669266307026
Local test acc @ epoch 216: 0.961
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.93 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9118032674176977, ce=42.038905922426
Local test acc @ epoch 216: 0.961
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.75 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9119135633521124, ce=42.03836031572534
Local test acc @ epoch 216: 0.961
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9117369717414227, ce=42.04679289651573
Local test acc @ epoch 216: 0.961
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.81 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9117736247701382, ce=42.05864365603946
Local test acc @ epoch 216: 0.961
Global evaluate on test data...
Evaluate data in 82.86 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9117539344577614, ce=42.04491519053048
Global test acc : 0.961
Global prompt norm: 57.89581298828125
Global epoch 217...
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9119097158449505, ce=42.09650606627858
Local test acc @ epoch 217: 0.961
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.82 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9116445987596424, ce=42.11455665378396
Local test acc @ epoch 217: 0.961
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.7 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9118731612459235, ce=42.07572300062267
Local test acc @ epoch 217: 0.961
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.88 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9118394632951929, ce=42.116316909090095
Local test acc @ epoch 217: 0.961
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.93 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9118740952343022, ce=42.0966874218862
Local test acc @ epoch 217: 0.961
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.61 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9116855586340668, ce=42.12427587246676
Local test acc @ epoch 217: 0.961
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9117604723764122, ce=42.1077289756285
Local test acc @ epoch 217: 0.961
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.82 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9119838443371134, ce=42.09587576629919
Local test acc @ epoch 217: 0.961
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.93 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9118030027512016, ce=42.10454601322839
Local test acc @ epoch 217: 0.961
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.72 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9118409156799316, ce=42.094379145071045
Local test acc @ epoch 217: 0.961
Global evaluate on test data...
Evaluate data in 82.75 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9118228767989972, ce=42.10263649476777
Global test acc : 0.961
Global prompt norm: 57.89551544189453
Global epoch 218...
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.85 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9118627145749714, ce=42.162414305800695
Local test acc @ epoch 218: 0.961
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.9 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9120433942987285, ce=42.15335502974484
Local test acc @ epoch 218: 0.961
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9117024907278358, ce=42.172685255698106
Local test acc @ epoch 218: 0.961
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.94 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9119705497671705, ce=42.15423160517981
Local test acc @ epoch 218: 0.961
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9118998925620263, ce=42.17419472090695
Local test acc @ epoch 218: 0.961
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.84 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9119378404879789, ce=42.15449285944668
Local test acc @ epoch 218: 0.961
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9119374161466546, ce=42.13332587425862
Local test acc @ epoch 218: 0.961
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.7 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9118167872822612, ce=42.16592928685179
Local test acc @ epoch 218: 0.961
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.87 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9119025217283756, ce=42.15217880808979
Local test acc @ epoch 218: 0.961
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.76 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.911745178590127, ce=42.182437791736845
Local test acc @ epoch 218: 0.961
Global evaluate on test data...
Evaluate data in 82.87 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9118810662435829, ce=42.16051224174849
Global test acc : 0.961
Global prompt norm: 57.89523696899414
Global epoch 219...
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.93 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9117537288490786, ce=42.23107549684857
Local test acc @ epoch 219: 0.961
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.05 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9119549650664723, ce=42.21012402455741
Local test acc @ epoch 219: 0.961
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.71 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9118702980356479, ce=42.224223495623384
Local test acc @ epoch 219: 0.961
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.87 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9119910122057714, ce=42.191152065172105
Local test acc @ epoch 219: 0.961
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9119093374374809, ce=42.22044372558594
Local test acc @ epoch 219: 0.961
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9119860666607498, ce=42.21245112987833
Local test acc @ epoch 219: 0.961
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9120208888972571, ce=42.212066615393404
Local test acc @ epoch 219: 0.961
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9117909090234599, ce=42.24082463815672
Local test acc @ epoch 219: 0.961
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.73 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9119469288292281, ce=42.23216401546373
Local test acc @ epoch 219: 0.961
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.1 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9120947702215352, ce=42.2110956174518
Local test acc @ epoch 219: 0.961
Global evaluate on test data...
Evaluate data in 82.72 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9119315934837411, ce=42.218515833583446
Global test acc : 0.961
Global prompt norm: 57.89494705200195
Global epoch 220...
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.91 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9119879565107714, ce=42.29030294155856
Local test acc @ epoch 220: 0.961
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.88 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9119964061527077, ce=42.268175772570686
Local test acc @ epoch 220: 0.961
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.73 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.912064092968582, ce=42.270103559581514
Local test acc @ epoch 220: 0.961
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.84 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9120363839175722, ce=42.24919240409081
Local test acc @ epoch 220: 0.961
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9117895047599023, ce=42.28946517804347
Local test acc @ epoch 220: 0.961
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.93 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9118259215573652, ce=42.29926909000502
Local test acc @ epoch 220: 0.961
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.87 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9119133905533257, ce=42.28265888319103
Local test acc @ epoch 220: 0.961
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.64 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.911947996244518, ce=42.2785946207309
Local test acc @ epoch 220: 0.961
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.81 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.912134627683447, ce=42.26898833808549
Local test acc @ epoch 220: 0.961
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.69 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9120313749400848, ce=42.27057759696191
Local test acc @ epoch 220: 0.961
Global evaluate on test data...
Evaluate data in 82.82 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9119732533026179, ce=42.27674295267928
Global test acc : 0.961
Global prompt norm: 57.89463424682617
Global epoch 221...
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.02 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9120122489579227, ce=42.348559038354715
Local test acc @ epoch 221: 0.961
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.94 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.912062570589398, ce=42.32884149813871
Local test acc @ epoch 221: 0.961
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.82 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9120241327023287, ce=42.32644023370305
Local test acc @ epoch 221: 0.961
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9119379411049939, ce=42.34119450280426
Local test acc @ epoch 221: 0.961
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.66 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9121634653948862, ce=42.32702248249579
Local test acc @ epoch 221: 0.961
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.75 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9119770920604741, ce=42.33691175268331
Local test acc @ epoch 221: 0.961
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.9 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9118495381206547, ce=42.357811044115536
Local test acc @ epoch 221: 0.961
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.87 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9120914520473655, ce=42.32827188334334
Local test acc @ epoch 221: 0.961
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.86 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9118150614817208, ce=42.34807887646036
Local test acc @ epoch 221: 0.961
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.73 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9120711930301211, ce=42.30727445969888
Local test acc @ epoch 221: 0.961
Global evaluate on test data...
Evaluate data in 83.01 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9120015288711688, ce=42.33506106455392
Global test acc : 0.961
Global prompt norm: 57.89433288574219
Global epoch 222...
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.89 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9119588978793642, ce=42.399932091389225
Local test acc @ epoch 222: 0.961
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9121847830781149, ce=42.38513061103471
Local test acc @ epoch 222: 0.961
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.94 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9120933725199568, ce=42.36547239111104
Local test acc @ epoch 222: 0.961
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.88 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9119925192736704, ce=42.39535473464826
Local test acc @ epoch 222: 0.961
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.74 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.912082193094656, ce=42.387245703180994
Local test acc @ epoch 222: 0.961
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.0 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9118641603977309, ce=42.416604313281695
Local test acc @ epoch 222: 0.961
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9120308499817454, ce=42.406985571625036
Local test acc @ epoch 222: 0.961
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.86 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9120470646324508, ce=42.3848171409117
Local test acc @ epoch 222: 0.961
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.77 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9121109367510595, ce=42.38654043915075
Local test acc @ epoch 222: 0.961
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9118324201041406, ce=42.40683168883717
Local test acc @ epoch 222: 0.961
Global evaluate on test data...
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9120206023574969, ce=42.3934422064265
Global test acc : 0.961
Global prompt norm: 57.89403533935547
Global epoch 223...
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.02 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9118378118637505, ce=42.46562880769782
Local test acc @ epoch 223: 0.961
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.01 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9120918304548351, ce=42.44585030232001
Local test acc @ epoch 223: 0.961
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.81 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9121079401138725, ce=42.42386676193377
Local test acc @ epoch 223: 0.961
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.97 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9119682596364153, ce=42.458787935589434
Local test acc @ epoch 223: 0.961
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.88 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9121950722615654, ce=42.443390557525355
Local test acc @ epoch 223: 0.961
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.94 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9120359792621857, ce=42.46552112124382
Local test acc @ epoch 223: 0.961
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.93 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.912057321006005, ce=42.443346706005414
Local test acc @ epoch 223: 0.961
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.93 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9118677476130495, ce=42.475516363021434
Local test acc @ epoch 223: 0.961
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.89 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9119995777760077, ce=42.45393651559812
Local test acc @ epoch 223: 0.961
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.93 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9121227505010202, ce=42.44499003559078
Local test acc @ epoch 223: 0.961
Global evaluate on test data...
Evaluate data in 82.8 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.912030530632089, ce=42.452092441943805
Global test acc : 0.961
Global prompt norm: 57.89372634887695
Global epoch 224...
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.94 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9118567562978203, ce=42.53468585233076
Local test acc @ epoch 224: 0.961
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.98 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9119949187707463, ce=42.51280985840964
Local test acc @ epoch 224: 0.961
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.93 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9120324686032917, ce=42.52436744619947
Local test acc @ epoch 224: 0.961
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.82 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9121120216649606, ce=42.48234040146574
Local test acc @ epoch 224: 0.961
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.99 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9118296837587969, ce=42.52479766705714
Local test acc @ epoch 224: 0.961
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.03 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9120533706945017, ce=42.50206585105406
Local test acc @ epoch 224: 0.961
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.04 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.912191021333047, ce=42.5019258971608
Local test acc @ epoch 224: 0.961
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.86 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9120916467194163, ce=42.50462330809427
Local test acc @ epoch 224: 0.961
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.97 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9121206003591555, ce=42.5036992414282
Local test acc @ epoch 224: 0.961
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9119659170098261, ce=42.51788659052018
Local test acc @ epoch 224: 0.961
Global evaluate on test data...
Evaluate data in 82.93 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9120252613627583, ce=42.51096078015249
Global test acc : 0.961
Global prompt norm: 57.893436431884766
Global epoch 225...
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.86 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9121783282778678, ce=42.56058659684767
Local test acc @ epoch 225: 0.961
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.08 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9121075157725483, ce=42.56250573954451
Local test acc @ epoch 225: 0.961
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.94 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9121026336599928, ce=42.54118725137973
Local test acc @ epoch 225: 0.961
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.97 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9120165929881805, ce=42.58320537182169
Local test acc @ epoch 225: 0.961
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.99 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9119498204747472, ce=42.57720457304508
Local test acc @ epoch 225: 0.961
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.9 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9118379649765994, ce=42.593964952941334
Local test acc @ epoch 225: 0.961
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.98 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9120761254511842, ce=42.56349175129462
Local test acc @ epoch 225: 0.961
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.12 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9119795899872386, ce=42.571707804268655
Local test acc @ epoch 225: 0.961
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.18 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9120401023724757, ce=42.56098227544662
Local test acc @ epoch 225: 0.961
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.95 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9118122376433206, ce=42.584019792189295
Local test acc @ epoch 225: 0.961
Global evaluate on test data...
Evaluate data in 82.97 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9120109168761367, ce=42.56984276727799
Global test acc : 0.961
Global prompt norm: 57.89312744140625
Global epoch 226...
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.01 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9119283168687733, ce=42.636646305749174
Local test acc @ epoch 226: 0.961
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.65 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9120549805667422, ce=42.622644791909316
Local test acc @ epoch 226: 0.961
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.84 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9120858328058086, ce=42.62151133686031
Local test acc @ epoch 226: 0.961
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.86 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9120209238944798, ce=42.619967959342745
Local test acc @ epoch 226: 0.961
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.98 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9119529942853735, ce=42.63096510160953
Local test acc @ epoch 226: 0.961
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.92 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9117851344817275, ce=42.643515770588444
Local test acc @ epoch 226: 0.961
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.97 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9118081648415381, ce=42.65343863810968
Local test acc @ epoch 226: 0.961
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.87 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9119901569611436, ce=42.64242973677609
Local test acc @ epoch 226: 0.961
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.84 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9120850606795845, ce=42.60003301637982
Local test acc @ epoch 226: 0.961
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.01 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9121564397024452, ce=42.61946154953143
Local test acc @ epoch 226: 0.961
Global evaluate on test data...
Evaluate data in 83.03 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9119883611661579, ce=42.62904462901824
Global test acc : 0.961
Global prompt norm: 57.892822265625
Global epoch 227...
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.84 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.91195414919372, ce=42.70176178818449
Local test acc @ epoch 227: 0.961
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.94 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9121215146615964, ce=42.678552855045425
Local test acc @ epoch 227: 0.961
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.85 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.912051130872254, ce=42.68070248945044
Local test acc @ epoch 227: 0.961
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.78 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9119851107991069, ce=42.67932741357646
Local test acc @ epoch 227: 0.961
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.96 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9118917907049896, ce=42.69624013638278
Local test acc @ epoch 227: 0.961
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.84 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9120214925993473, ce=42.68201838502097
Local test acc @ epoch 227: 0.961
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.92 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9117678217931625, ce=42.71314288498065
Local test acc @ epoch 227: 0.961
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.93 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9117476568309539, ce=42.70315723244203
Local test acc @ epoch 227: 0.961
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.98 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.912053007598317, ce=42.65921282986982
Local test acc @ epoch 227: 0.961
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.02 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9119161859564825, ce=42.69025984597862
Local test acc @ epoch 227: 0.961
Global evaluate on test data...
Evaluate data in 82.91 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9119515834598366, ce=42.688379620193345
Global test acc : 0.961
Global prompt norm: 57.89253234863281
Global epoch 228...
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.97 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9119798787143252, ce=42.74153469680646
Local test acc @ epoch 228: 0.961
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.94 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9117176926464116, ce=42.77297711153643
Local test acc @ epoch 228: 0.961
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.84 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9119073032239161, ce=42.761276630086634
Local test acc @ epoch 228: 0.961
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.0 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9119425213665043, ce=42.73871941522721
Local test acc @ epoch 228: 0.961
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.03 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9120132157561975, ce=42.718525037853
Local test acc @ epoch 228: 0.961
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.82 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9116959987430397, ce=42.76298753930888
Local test acc @ epoch 228: 0.961
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.06 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9118678307314532, ce=42.749815249661786
Local test acc @ epoch 228: 0.961
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.75 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9120800276415064, ce=42.73774239776331
Local test acc @ epoch 228: 0.961
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.84 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9118453537652252, ce=42.75610201074443
Local test acc @ epoch 228: 0.961
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.05 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9120081849054459, ce=42.740109224931906
Local test acc @ epoch 228: 0.961
Global evaluate on test data...
Evaluate data in 82.95 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9119091777626528, ce=42.74802633163032
Global test acc : 0.961
Global prompt norm: 57.8922004699707
Global epoch 229...
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.82 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9118474842211522, ce=42.82107984910318
Local test acc @ epoch 229: 0.961
Client 6 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.89 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9118899970973303, ce=42.79841309293695
Local test acc @ epoch 229: 0.961
Client 9 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.82 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9119540748246219, ce=42.799770145241276
Local test acc @ epoch 229: 0.961
Client 0 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.84 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9117894697626796, ce=42.81610852862717
Local test acc @ epoch 229: 0.961
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.97 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9116344145678599, ce=42.82301659540299
Local test acc @ epoch 229: 0.961
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.89 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9119259589308992, ce=42.80119831190197
Local test acc @ epoch 229: 0.961
Client 5 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.83 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.911812661984645, ce=42.809637052203534
Local test acc @ epoch 229: 0.961
Client 2 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.79 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9119629641191676, ce=42.778131957447854
Local test acc @ epoch 229: 0.961
Client 1 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.16 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9120269456040968, ce=42.79731942973006
Local test acc @ epoch 229: 0.961
Client 8 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 83.03 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9116520706666719, ce=42.833090510937055
Local test acc @ epoch 229: 0.961
Global evaluate on test data...
Evaluate data in 83.02 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9118509358222332, ce=42.807792628577
Global test acc : 0.961
Global prompt norm: 57.891910552978516
Global epoch 230...
Client 7 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.94 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.9115614541080019, ce=42.88332685418085
Local test acc @ epoch 230: 0.961
Client 4 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 82.88 seconds!
[tester] 
SST2Metric: acc=0.9610091743119266, hinge=0.911858563029438, ce=42.86121690382651
Local test acc @ epoch 230: 0.961
Client 3 execute local training on 8 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
