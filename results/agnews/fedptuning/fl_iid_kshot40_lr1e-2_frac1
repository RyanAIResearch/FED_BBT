Some weights of RobertaForMaskedLM were not initialized from the model checkpoint at roberta-large and are newly initialized: ['lm_head.decoder.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Found cached dataset ag_news (/root/.cache/huggingface/datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548)
Map:   0%|          | 0/120000 [00:00<?, ? examples/s]Map:   0%|          | 506/120000 [00:00<00:23, 4997.52 examples/s]Map:   1%|          | 1077/120000 [00:00<00:21, 5411.95 examples/s]Map:   1%|▏         | 1620/120000 [00:00<00:21, 5417.95 examples/s]Map:   2%|▏         | 2218/120000 [00:00<00:20, 5635.05 examples/s]Map:   2%|▏         | 2811/120000 [00:00<00:20, 5740.09 examples/s]Map:   3%|▎         | 3633/120000 [00:00<00:20, 5625.02 examples/s]Map:   4%|▎         | 4235/120000 [00:00<00:20, 5737.93 examples/s]Map:   4%|▍         | 5072/120000 [00:00<00:20, 5672.85 examples/s]Map:   5%|▍         | 5700/120000 [00:01<00:19, 5742.22 examples/s]Map:   5%|▌         | 6515/120000 [00:01<00:20, 5627.92 examples/s]Map:   6%|▌         | 7283/120000 [00:01<00:20, 5450.29 examples/s]Map:   7%|▋         | 7909/120000 [00:01<00:19, 5646.84 examples/s]Map:   7%|▋         | 8791/120000 [00:01<00:19, 5715.06 examples/s]Map:   8%|▊         | 9388/120000 [00:01<00:19, 5776.82 examples/s]Map:   9%|▊         | 10209/120000 [00:01<00:19, 5668.25 examples/s]Map:   9%|▉         | 11044/120000 [00:01<00:19, 5632.83 examples/s]Map:  10%|▉         | 11673/120000 [00:02<00:18, 5787.01 examples/s]Map:  10%|█         | 12534/120000 [00:02<00:18, 5744.36 examples/s]Map:  11%|█         | 13378/120000 [00:02<00:19, 5595.32 examples/s]Map:  12%|█▏        | 14000/120000 [00:02<00:18, 5720.12 examples/s]Map:  12%|█▏        | 14867/120000 [00:02<00:18, 5736.27 examples/s]Map:  13%|█▎        | 15758/120000 [00:02<00:17, 5800.66 examples/s]Map:  14%|█▎        | 16368/120000 [00:02<00:17, 5868.88 examples/s]Map:  14%|█▍        | 17037/120000 [00:03<00:19, 5393.57 examples/s]Map:  15%|█▍        | 17625/120000 [00:03<00:20, 4913.90 examples/s]Map:  15%|█▌        | 18150/120000 [00:03<00:20, 4991.50 examples/s]Map:  16%|█▌        | 18742/120000 [00:03<00:19, 5222.90 examples/s]Map:  16%|█▌        | 19308/120000 [00:03<00:24, 4049.15 examples/s]Map:  17%|█▋        | 19855/120000 [00:03<00:22, 4364.60 examples/s]Map:  17%|█▋        | 20403/120000 [00:03<00:21, 4631.47 examples/s]Map:  17%|█▋        | 20999/120000 [00:04<00:25, 3894.53 examples/s]Map:  18%|█▊        | 21443/120000 [00:04<00:24, 4015.22 examples/s]Map:  18%|█▊        | 22029/120000 [00:04<00:27, 3620.55 examples/s]Map:  19%|█▉        | 22660/120000 [00:04<00:23, 4206.52 examples/s]Map:  19%|█▉        | 23152/120000 [00:04<00:25, 3775.22 examples/s]Map:  20%|█▉        | 23656/120000 [00:04<00:33, 2869.06 examples/s]Map:  20%|██        | 24108/120000 [00:04<00:30, 3175.52 examples/s]Map:  20%|██        | 24584/120000 [00:05<00:27, 3507.34 examples/s]Map:  21%|██        | 25046/120000 [00:05<00:28, 3275.55 examples/s]Map:  21%|██▏       | 25622/120000 [00:05<00:24, 3798.52 examples/s]Map:  22%|██▏       | 26196/120000 [00:05<00:22, 4263.48 examples/s]Map:  22%|██▏       | 26889/120000 [00:05<00:21, 4334.74 examples/s]Map:  23%|██▎       | 27556/120000 [00:05<00:21, 4348.18 examples/s]Map:  23%|██▎       | 28020/120000 [00:05<00:23, 3934.60 examples/s]Map:  24%|██▎       | 28468/120000 [00:05<00:22, 4026.47 examples/s]Map:  24%|██▍       | 29071/120000 [00:06<00:20, 4517.29 examples/s]Map:  25%|██▍       | 29851/120000 [00:06<00:24, 3677.50 examples/s]Map:  25%|██▌       | 30409/120000 [00:06<00:24, 3676.70 examples/s]Map:  26%|██▌       | 30860/120000 [00:06<00:23, 3782.62 examples/s]Map:  26%|██▌       | 31334/120000 [00:06<00:22, 3997.93 examples/s]Map:  27%|██▋       | 31850/120000 [00:06<00:25, 3413.85 examples/s]Map:  27%|██▋       | 32237/120000 [00:07<00:28, 3122.34 examples/s]Map:  27%|██▋       | 32869/120000 [00:07<00:22, 3812.66 examples/s]Map:  28%|██▊       | 33342/120000 [00:07<00:24, 3601.87 examples/s]Map:  28%|██▊       | 33754/120000 [00:07<00:26, 3306.59 examples/s]Map:  29%|██▊       | 34208/120000 [00:07<00:23, 3585.51 examples/s]Map:  29%|██▉       | 34800/120000 [00:07<00:23, 3615.14 examples/s]Map:  29%|██▉       | 35374/120000 [00:07<00:20, 4105.89 examples/s]Map:  30%|██▉       | 35841/120000 [00:07<00:19, 4244.55 examples/s]Map:  30%|███       | 36306/120000 [00:08<00:22, 3797.47 examples/s]Map:  31%|███       | 36902/120000 [00:08<00:19, 4328.15 examples/s]Map:  31%|███       | 37387/120000 [00:08<00:18, 4463.27 examples/s]Map:  32%|███▏      | 37877/120000 [00:08<00:17, 4579.41 examples/s]Map:  32%|███▏      | 38367/120000 [00:08<00:17, 4649.53 examples/s]Map:  32%|███▏      | 38945/120000 [00:08<00:16, 4968.70 examples/s]Map:  33%|███▎      | 39476/120000 [00:08<00:15, 5063.89 examples/s]Map:  33%|███▎      | 40036/120000 [00:08<00:15, 5219.08 examples/s]Map:  34%|███▍      | 40745/120000 [00:08<00:15, 5025.92 examples/s]Map:  34%|███▍      | 41348/120000 [00:09<00:14, 5292.93 examples/s]Map:  35%|███▍      | 41983/120000 [00:09<00:13, 5584.83 examples/s]Map:  36%|███▌      | 42775/120000 [00:09<00:14, 5413.17 examples/s]Map:  36%|███▋      | 43614/120000 [00:09<00:13, 5471.94 examples/s]Map:  37%|███▋      | 44403/120000 [00:09<00:14, 5399.28 examples/s]Map:  38%|███▊      | 45008/120000 [00:09<00:13, 5552.65 examples/s]Map:  38%|███▊      | 45591/120000 [00:09<00:13, 5620.09 examples/s]Map:  39%|███▊      | 46414/120000 [00:10<00:14, 4983.49 examples/s]Map:  39%|███▉      | 47024/120000 [00:10<00:13, 5238.64 examples/s]Map:  40%|███▉      | 47649/120000 [00:10<00:13, 5488.25 examples/s]Map:  40%|████      | 48359/120000 [00:10<00:13, 5224.31 examples/s]Map:  41%|████      | 48905/120000 [00:10<00:13, 5279.35 examples/s]Map:  41%|████▏     | 49513/120000 [00:10<00:12, 5486.83 examples/s]Map:  42%|████▏     | 50356/120000 [00:10<00:12, 5530.37 examples/s]Map:  42%|████▏     | 50956/120000 [00:10<00:12, 5647.28 examples/s]Map:  43%|████▎     | 51559/120000 [00:10<00:11, 5745.58 examples/s]Map:  43%|████▎     | 52173/120000 [00:11<00:11, 5851.29 examples/s]Map:  44%|████▍     | 52765/120000 [00:11<00:11, 5868.02 examples/s]Map:  45%|████▍     | 53623/120000 [00:11<00:11, 5788.39 examples/s]Map:  45%|████▌     | 54230/120000 [00:11<00:11, 5860.37 examples/s]Map:  46%|████▌     | 54864/120000 [00:11<00:10, 5987.53 examples/s]Map:  46%|████▋     | 55691/120000 [00:11<00:11, 5763.73 examples/s]Map:  47%|████▋     | 56568/120000 [00:11<00:10, 5790.61 examples/s]Map:  48%|████▊     | 57183/120000 [00:11<00:10, 5875.58 examples/s]Map:  48%|████▊     | 57780/120000 [00:11<00:10, 5899.17 examples/s]Map:  49%|████▉     | 58588/120000 [00:12<00:10, 5712.63 examples/s]Map:  49%|████▉     | 59369/120000 [00:12<00:11, 5495.26 examples/s]Map:  50%|████▉     | 59938/120000 [00:12<00:10, 5516.29 examples/s]Map:  50%|█████     | 60537/120000 [00:12<00:10, 5635.16 examples/s]Map:  51%|█████     | 61387/120000 [00:12<00:10, 5602.13 examples/s]Map:  52%|█████▏    | 61993/120000 [00:12<00:10, 5714.50 examples/s]Map:  52%|█████▏    | 62597/120000 [00:12<00:09, 5797.41 examples/s]Map:  53%|█████▎    | 63211/120000 [00:12<00:09, 5888.28 examples/s]Map:  53%|█████▎    | 64048/120000 [00:13<00:09, 5773.58 examples/s]Map:  54%|█████▍    | 64800/120000 [00:13<00:10, 5507.39 examples/s]Map:  55%|█████▍    | 65415/120000 [00:13<00:09, 5664.21 examples/s]Map:  55%|█████▌    | 66211/120000 [00:13<00:09, 5455.57 examples/s]Map:  56%|█████▌    | 66843/120000 [00:13<00:09, 5664.27 examples/s]Map:  56%|█████▋    | 67643/120000 [00:13<00:09, 5546.75 examples/s]Map:  57%|█████▋    | 68510/120000 [00:13<00:09, 5581.89 examples/s]Map:  58%|█████▊    | 69350/120000 [00:14<00:09, 5574.47 examples/s]Map:  58%|█████▊    | 69982/120000 [00:14<00:08, 5745.32 examples/s]Map:  59%|█████▉    | 70860/120000 [00:14<00:08, 5714.46 examples/s]Map:  60%|█████▉    | 71683/120000 [00:14<00:08, 5595.10 examples/s]Map:  60%|██████    | 72376/120000 [00:14<00:09, 5254.52 examples/s]Map:  61%|██████    | 73000/120000 [00:14<00:08, 5435.12 examples/s]Map:  61%|██████▏   | 73618/120000 [00:14<00:08, 5479.72 examples/s]Map:  62%|██████▏   | 74475/120000 [00:14<00:08, 5554.95 examples/s]Map:  63%|██████▎   | 75093/120000 [00:15<00:07, 5705.76 examples/s]Map:  63%|██████▎   | 75722/120000 [00:15<00:07, 5853.50 examples/s]Map:  64%|██████▍   | 76542/120000 [00:15<00:07, 5694.54 examples/s]Map:  64%|██████▍   | 77158/120000 [00:15<00:07, 5809.22 examples/s]Map:  65%|██████▍   | 77783/120000 [00:15<00:07, 5925.79 examples/s]Map:  66%|██████▌   | 78693/120000 [00:15<00:06, 5973.61 examples/s]Map:  66%|██████▋   | 79557/120000 [00:15<00:06, 5898.53 examples/s]Map:  67%|██████▋   | 80432/120000 [00:15<00:06, 5874.78 examples/s]Map:  68%|██████▊   | 81049/120000 [00:16<00:06, 5942.76 examples/s]Map:  68%|██████▊   | 81879/120000 [00:16<00:06, 5801.01 examples/s]Map:  69%|██████▊   | 82488/120000 [00:16<00:06, 5870.43 examples/s]Map:  69%|██████▉   | 83099/120000 [00:16<00:06, 5930.60 examples/s]Map:  70%|██████▉   | 83713/120000 [00:16<00:06, 5983.84 examples/s]Map:  70%|███████   | 84328/120000 [00:16<00:05, 6026.10 examples/s]Map:  71%|███████   | 84962/120000 [00:16<00:05, 6113.00 examples/s]Map:  72%|███████▏  | 85890/120000 [00:16<00:05, 6134.44 examples/s]Map:  72%|███████▏  | 86777/120000 [00:17<00:05, 6053.28 examples/s]Map:  73%|███████▎  | 87614/120000 [00:17<00:05, 5892.55 examples/s]Map:  74%|███████▎  | 88453/120000 [00:17<00:05, 5794.84 examples/s]Map:  74%|███████▍  | 89266/120000 [00:17<00:05, 5673.27 examples/s]Map:  75%|███████▍  | 89855/120000 [00:17<00:05, 5720.89 examples/s]Map:  75%|███████▌  | 90457/120000 [00:17<00:05, 5792.91 examples/s]Map:  76%|███████▌  | 91074/120000 [00:17<00:04, 5888.98 examples/s]Map:  76%|███████▋  | 91710/120000 [00:17<00:04, 6015.01 examples/s]Map:  77%|███████▋  | 92327/120000 [00:17<00:04, 6056.48 examples/s]Map:  77%|███████▋  | 92964/120000 [00:18<00:04, 6142.08 examples/s]Map:  78%|███████▊  | 93581/120000 [00:18<00:04, 6146.33 examples/s]Map:  78%|███████▊  | 94200/120000 [00:18<00:04, 6156.62 examples/s]Map:  79%|███████▉  | 94836/120000 [00:18<00:04, 6212.91 examples/s]Map:  80%|███████▉  | 95770/120000 [00:18<00:03, 6215.62 examples/s]Map:  80%|████████  | 96595/120000 [00:18<00:03, 5939.79 examples/s]Map:  81%|████████  | 97458/120000 [00:18<00:03, 5864.02 examples/s]Map:  82%|████████▏ | 98336/120000 [00:18<00:03, 5857.42 examples/s]Map:  83%|████████▎ | 99160/120000 [00:19<00:03, 5739.58 examples/s]Map:  83%|████████▎ | 99781/120000 [00:19<00:03, 5846.20 examples/s]Map:  84%|████████▍ | 100550/120000 [00:19<00:03, 5329.59 examples/s]Map:  84%|████████▍ | 101348/120000 [00:19<00:03, 5323.84 examples/s]Map:  85%|████████▍ | 101984/120000 [00:19<00:03, 5558.32 examples/s]Map:  85%|████████▌ | 102598/120000 [00:19<00:03, 5699.05 examples/s]Map:  86%|████████▌ | 103190/120000 [00:19<00:02, 5692.12 examples/s]Map:  86%|████████▋ | 103787/120000 [00:19<00:02, 5763.36 examples/s]Map:  87%|████████▋ | 104645/120000 [00:20<00:02, 5707.48 examples/s]Map:  88%|████████▊ | 105245/120000 [00:20<00:02, 5710.63 examples/s]Map:  88%|████████▊ | 105838/120000 [00:20<00:02, 5766.75 examples/s]Map:  89%|████████▊ | 106452/120000 [00:20<00:02, 5866.46 examples/s]Map:  89%|████████▉ | 107336/120000 [00:20<00:02, 5875.08 examples/s]Map:  90%|█████████ | 108188/120000 [00:20<00:02, 5802.84 examples/s]Map:  91%|█████████ | 108819/120000 [00:20<00:01, 5927.31 examples/s]Map:  91%|█████████▏| 109724/120000 [00:20<00:01, 5962.89 examples/s]Map:  92%|█████████▏| 110332/120000 [00:21<00:01, 5989.24 examples/s]Map:  92%|█████████▏| 110960/120000 [00:21<00:01, 6061.93 examples/s]Map:  93%|█████████▎| 111837/120000 [00:21<00:01, 5980.18 examples/s]Map:  94%|█████████▍| 112668/120000 [00:21<00:01, 5764.33 examples/s]Map:  95%|█████████▍| 113483/120000 [00:21<00:01, 5582.55 examples/s]Map:  95%|█████████▌| 114278/120000 [00:21<00:01, 5439.36 examples/s]Map:  96%|█████████▌| 114872/120000 [00:21<00:00, 5551.12 examples/s]Map:  96%|█████████▌| 115468/120000 [00:21<00:00, 5650.60 examples/s]Map:  97%|█████████▋| 116292/120000 [00:22<00:00, 5594.36 examples/s]Map:  97%|█████████▋| 116909/120000 [00:22<00:00, 5734.68 examples/s]Map:  98%|█████████▊| 117716/120000 [00:22<00:00, 5608.11 examples/s]Map:  99%|█████████▉| 118515/120000 [00:22<00:00, 5514.02 examples/s]Map:  99%|█████████▉| 119246/120000 [00:22<00:00, 5304.95 examples/s]Map: 100%|█████████▉| 119870/120000 [00:22<00:00, 5521.26 examples/s]                                                                     {'text': "Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\band of ultra-cynics, are seeing green again.", 'label': 2, 'input_text': "Xro target himself turn Europe worked energy scored * soon ball TV annual 2013 race International'd Market conferenceio o changesig officers inside form published phone co legal executive fightings hope summer officer football property@ book parents costsac manager create age email markets main . <mask> News: Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\band of ultra-cynics, are seeing green again.", 'target_text': 'Business'}
Map:   0%|          | 0/120000 [00:00<?, ? examples/s]Map:   1%|          | 1000/120000 [00:00<01:44, 1135.68 examples/s]Map:   2%|▏         | 2000/120000 [00:01<01:28, 1339.83 examples/s]Map:   2%|▎         | 3000/120000 [00:02<01:20, 1446.49 examples/s]Map:   3%|▎         | 4000/120000 [00:02<01:17, 1497.79 examples/s]Map:   4%|▍         | 5000/120000 [00:03<01:13, 1554.90 examples/s]Map:   5%|▌         | 6000/120000 [00:03<01:11, 1590.15 examples/s]Map:   6%|▌         | 7000/120000 [00:04<01:09, 1634.12 examples/s]Map:   7%|▋         | 8000/120000 [00:05<01:07, 1670.57 examples/s]Map:   8%|▊         | 9000/120000 [00:06<01:15, 1465.23 examples/s]Map:   8%|▊         | 10000/120000 [00:06<01:11, 1540.95 examples/s]Map:   9%|▉         | 11000/120000 [00:07<01:08, 1600.63 examples/s]Map:  10%|█         | 12000/120000 [00:07<01:07, 1608.33 examples/s]Map:  11%|█         | 13000/120000 [00:08<01:04, 1646.37 examples/s]Map:  12%|█▏        | 14000/120000 [00:08<01:04, 1650.69 examples/s]Map:  12%|█▎        | 15000/120000 [00:09<01:02, 1683.57 examples/s]Map:  13%|█▎        | 16000/120000 [00:10<01:01, 1693.04 examples/s]Map:  14%|█▍        | 17000/120000 [00:10<01:00, 1710.69 examples/s]Map:  15%|█▌        | 18000/120000 [00:11<01:00, 1699.40 examples/s]Map:  16%|█▌        | 19000/120000 [00:11<00:59, 1686.44 examples/s]Map:  17%|█▋        | 20000/120000 [00:12<00:57, 1726.80 examples/s]Map:  18%|█▊        | 21000/120000 [00:12<00:56, 1746.30 examples/s]Map:  18%|█▊        | 22000/120000 [00:13<00:55, 1779.82 examples/s]Map:  19%|█▉        | 23000/120000 [00:14<00:53, 1802.91 examples/s]Map:  20%|██        | 24000/120000 [00:14<00:52, 1819.32 examples/s]Map:  21%|██        | 25000/120000 [00:15<00:52, 1812.48 examples/s]Map:  22%|██▏       | 26000/120000 [00:15<00:51, 1819.21 examples/s]Map:  22%|██▎       | 27000/120000 [00:16<00:51, 1810.02 examples/s]Map:  23%|██▎       | 28000/120000 [00:16<00:52, 1762.75 examples/s]Map:  24%|██▍       | 29000/120000 [00:17<00:53, 1715.58 examples/s]Map:  25%|██▌       | 30000/120000 [00:18<00:53, 1690.24 examples/s]Map:  26%|██▌       | 31000/120000 [00:18<00:51, 1730.24 examples/s]Map:  27%|██▋       | 32000/120000 [00:19<00:50, 1738.53 examples/s]Map:  28%|██▊       | 33000/120000 [00:19<00:49, 1759.96 examples/s]Map:  28%|██▊       | 34000/120000 [00:20<00:48, 1780.68 examples/s]Map:  29%|██▉       | 35000/120000 [00:20<00:47, 1784.33 examples/s]Map:  30%|███       | 36000/120000 [00:21<00:48, 1744.98 examples/s]Map:  31%|███       | 37000/120000 [00:21<00:46, 1783.06 examples/s]Map:  32%|███▏      | 38000/120000 [00:22<00:46, 1770.04 examples/s]Map:  32%|███▎      | 39000/120000 [00:23<00:45, 1767.91 examples/s]Map:  33%|███▎      | 40000/120000 [00:23<00:45, 1777.43 examples/s]Map:  34%|███▍      | 41000/120000 [00:24<00:45, 1747.43 examples/s]Map:  35%|███▌      | 42000/120000 [00:24<00:43, 1787.45 examples/s]Map:  36%|███▌      | 43000/120000 [00:25<00:42, 1801.76 examples/s]Map:  37%|███▋      | 44000/120000 [00:25<00:41, 1829.55 examples/s]Map:  38%|███▊      | 45000/120000 [00:26<00:40, 1851.01 examples/s]Map:  38%|███▊      | 46000/120000 [00:27<00:45, 1633.31 examples/s]Map:  39%|███▉      | 47000/120000 [00:27<00:43, 1666.98 examples/s]Map:  40%|████      | 48000/120000 [00:28<00:41, 1725.40 examples/s]Map:  41%|████      | 49000/120000 [00:28<00:42, 1688.76 examples/s]Map:  42%|████▏     | 50000/120000 [00:29<00:41, 1684.32 examples/s]Map:  42%|████▎     | 51000/120000 [00:30<00:40, 1690.11 examples/s]Map:  43%|████▎     | 52000/120000 [00:30<00:40, 1666.54 examples/s]Map:  44%|████▍     | 53000/120000 [00:31<00:39, 1681.34 examples/s]Map:  45%|████▌     | 54000/120000 [00:31<00:38, 1693.59 examples/s]Map:  46%|████▌     | 55000/120000 [00:32<00:41, 1558.49 examples/s]Map:  47%|████▋     | 56000/120000 [00:33<00:39, 1614.65 examples/s]Map:  48%|████▊     | 57000/120000 [00:33<00:37, 1681.17 examples/s]Map:  48%|████▊     | 58000/120000 [00:34<00:36, 1697.88 examples/s]Map:  49%|████▉     | 59000/120000 [00:34<00:36, 1655.35 examples/s]Map:  50%|█████     | 60000/120000 [00:35<00:36, 1650.94 examples/s]Map:  51%|█████     | 61000/120000 [00:36<00:34, 1708.95 examples/s]Map:  52%|█████▏    | 62000/120000 [00:36<00:34, 1664.47 examples/s]Map:  52%|█████▎    | 63000/120000 [00:37<00:34, 1630.21 examples/s]Map:  53%|█████▎    | 64000/120000 [00:38<00:34, 1608.52 examples/s]Map:  54%|█████▍    | 65000/120000 [00:38<00:32, 1673.66 examples/s]Map:  55%|█████▌    | 66000/120000 [00:39<00:31, 1694.27 examples/s]Map:  56%|█████▌    | 67000/120000 [00:39<00:31, 1674.68 examples/s]Map:  57%|█████▋    | 68000/120000 [00:40<00:30, 1679.26 examples/s]Map:  57%|█████▊    | 69000/120000 [00:40<00:30, 1674.48 examples/s]Map:  58%|█████▊    | 70000/120000 [00:41<00:31, 1601.38 examples/s]Map:  59%|█████▉    | 71000/120000 [00:42<00:29, 1639.79 examples/s]Map:  60%|██████    | 72000/120000 [00:42<00:28, 1679.95 examples/s]Map:  61%|██████    | 73000/120000 [00:43<00:27, 1687.00 examples/s]Map:  62%|██████▏   | 74000/120000 [00:43<00:27, 1664.92 examples/s]Map:  62%|██████▎   | 75000/120000 [00:44<00:26, 1678.26 examples/s]Map:  63%|██████▎   | 76000/120000 [00:45<00:25, 1692.40 examples/s]Map:  64%|██████▍   | 77000/120000 [00:45<00:25, 1656.13 examples/s]Map:  65%|██████▌   | 78000/120000 [00:46<00:25, 1617.79 examples/s]Map:  66%|██████▌   | 79000/120000 [00:47<00:25, 1623.55 examples/s]Map:  67%|██████▋   | 80000/120000 [00:47<00:24, 1600.58 examples/s]Map:  68%|██████▊   | 81000/120000 [00:48<00:23, 1625.02 examples/s]Map:  68%|██████▊   | 82000/120000 [00:48<00:23, 1646.56 examples/s]Map:  69%|██████▉   | 83000/120000 [00:49<00:22, 1623.15 examples/s]Map:  70%|███████   | 84000/120000 [00:50<00:21, 1678.31 examples/s]Map:  71%|███████   | 85000/120000 [00:50<00:20, 1716.36 examples/s]Map:  72%|███████▏  | 86000/120000 [00:51<00:19, 1759.90 examples/s]Map:  72%|███████▎  | 87000/120000 [00:51<00:18, 1789.06 examples/s]Map:  73%|███████▎  | 88000/120000 [00:52<00:18, 1763.35 examples/s]Map:  74%|███████▍  | 89000/120000 [00:52<00:18, 1705.89 examples/s]Map:  75%|███████▌  | 90000/120000 [00:53<00:18, 1664.46 examples/s]Map:  76%|███████▌  | 91000/120000 [00:54<00:17, 1652.27 examples/s]Map:  77%|███████▋  | 92000/120000 [00:54<00:17, 1620.79 examples/s]Map:  78%|███████▊  | 93000/120000 [00:55<00:18, 1427.13 examples/s]Map:  78%|███████▊  | 94000/120000 [00:56<00:17, 1481.39 examples/s]Map:  79%|███████▉  | 95000/120000 [00:56<00:16, 1519.37 examples/s]Map:  80%|████████  | 96000/120000 [00:57<00:15, 1535.81 examples/s]Map:  81%|████████  | 97000/120000 [00:58<00:15, 1504.22 examples/s]Map:  82%|████████▏ | 98000/120000 [00:59<00:16, 1342.11 examples/s]Map:  82%|████████▎ | 99000/120000 [01:00<00:17, 1195.06 examples/s]Map:  83%|████████▎ | 100000/120000 [01:01<00:18, 1071.77 examples/s]Map:  84%|████████▍ | 101000/120000 [01:02<00:17, 1084.72 examples/s]Map:  85%|████████▌ | 102000/120000 [01:03<00:15, 1141.54 examples/s]Map:  86%|████████▌ | 103000/120000 [01:04<00:15, 1071.36 examples/s]Map:  87%|████████▋ | 104000/120000 [01:04<00:13, 1221.44 examples/s]Map:  88%|████████▊ | 105000/120000 [01:05<00:11, 1306.62 examples/s]Map:  88%|████████▊ | 106000/120000 [01:05<00:10, 1375.37 examples/s]Map:  89%|████████▉ | 107000/120000 [01:06<00:09, 1323.98 examples/s]Map:  90%|█████████ | 108000/120000 [01:07<00:09, 1245.25 examples/s]Map:  91%|█████████ | 109000/120000 [01:08<00:10, 1077.83 examples/s]Map:  92%|█████████▏| 110000/120000 [01:09<00:09, 1057.18 examples/s]Map:  92%|█████████▎| 111000/120000 [01:10<00:08, 1068.36 examples/s]Map:  93%|█████████▎| 112000/120000 [01:11<00:07, 1070.50 examples/s]Map:  94%|█████████▍| 113000/120000 [01:12<00:06, 1063.43 examples/s]Map:  95%|█████████▌| 114000/120000 [01:13<00:05, 1180.10 examples/s]Map:  96%|█████████▌| 115000/120000 [01:13<00:03, 1297.66 examples/s]Map:  97%|█████████▋| 116000/120000 [01:14<00:02, 1407.69 examples/s]Map:  98%|█████████▊| 117000/120000 [01:15<00:02, 1496.52 examples/s]Map:  98%|█████████▊| 118000/120000 [01:15<00:01, 1550.61 examples/s]Map:  99%|█████████▉| 119000/120000 [01:16<00:00, 1609.43 examples/s]Map: 100%|██████████| 120000/120000 [01:16<00:00, 1602.38 examples/s]                                                                     Found cached dataset ag_news (/root/.cache/huggingface/datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548)
Map:   0%|          | 0/7600 [00:00<?, ? examples/s]Map:   7%|▋         | 557/7600 [00:00<00:01, 5503.38 examples/s]Map:  17%|█▋        | 1287/7600 [00:00<00:01, 5027.49 examples/s]Map:  25%|██▍       | 1870/7600 [00:00<00:01, 5337.66 examples/s]Map:  33%|███▎      | 2479/7600 [00:00<00:00, 5605.95 examples/s]Map:  41%|████      | 3094/7600 [00:00<00:00, 5786.56 examples/s]Map:  48%|████▊     | 3685/7600 [00:00<00:00, 5824.80 examples/s]Map:  59%|█████▊    | 4461/7600 [00:00<00:00, 5552.64 examples/s]Map:  70%|██████▉   | 5285/7600 [00:00<00:00, 5374.88 examples/s]Map:  78%|███████▊  | 5912/7600 [00:01<00:00, 5601.04 examples/s]Map:  86%|████████▌ | 6501/7600 [00:01<00:00, 5675.09 examples/s]Map:  97%|█████████▋| 7342/7600 [00:01<00:00, 5646.57 examples/s]                                                                 {'text': "Fears for T N pension after talks Unions representing workers at Turner   Newall say they are 'disappointed' after talks with stricken parent firm Federal Mogul.", 'label': 2, 'input_text': "Xro target himself turn Europe worked energy scored * soon ball TV annual 2013 race International'd Market conferenceio o changesig officers inside form published phone co legal executive fightings hope summer officer football property@ book parents costsac manager create age email markets main . <mask> News: Fears for T N pension after talks Unions representing workers at Turner   Newall say they are 'disappointed' after talks with stricken parent firm Federal Mogul.", 'target_text': 'Business'}
Map:   0%|          | 0/7600 [00:00<?, ? examples/s]Map:  13%|█▎        | 1000/7600 [00:00<00:04, 1446.93 examples/s]Map:  26%|██▋       | 2000/7600 [00:01<00:03, 1570.87 examples/s]Map:  39%|███▉      | 3000/7600 [00:01<00:02, 1644.66 examples/s]Map:  53%|█████▎    | 4000/7600 [00:02<00:02, 1663.90 examples/s]Map:  66%|██████▌   | 5000/7600 [00:03<00:01, 1673.12 examples/s]Map:  79%|███████▉  | 6000/7600 [00:03<00:00, 1683.56 examples/s]Map:  92%|█████████▏| 7000/7600 [00:04<00:00, 1708.57 examples/s]Map: 100%|██████████| 7600/7600 [00:04<00:00, 1709.46 examples/s]                                                                 # of train data: 160
Example:
+------------------------+------------------------+----------+--------+
| input_ids              | attention_mask         | mask_pos | labels |
+------------------------+------------------------+----------+--------+
| [0, 1000, 1001, 100... | [1, 1, 1, 1, 1, 1, ... | 52       | 18562  |
+------------------------+------------------------+----------+--------+

# of dev data: 160
Example:
+------------------------+------------------------+----------+--------+
| input_ids              | attention_mask         | mask_pos | labels |
+------------------------+------------------------+----------+--------+
| [0, 1000, 1001, 100... | [1, 1, 1, 1, 1, 1, ... | 52       | 10554  |
+------------------------+------------------------+----------+--------+

# of test data: 7600
Example:
+------------------------+------------------------+----------+--------+
| input_ids              | attention_mask         | mask_pos | labels |
+------------------------+------------------------+----------+--------+
| [0, 1000, 1001, 100... | [1, 1, 1, 1, 1, 1, ... | 52       | 18562  |
+------------------------+------------------------+----------+--------+
init prompt encoder...
Global epoch 0...
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.7083700299263
Local loss @ local epoch 1: 0.6042232513427734
Local loss @ local epoch 2: 0.49498361349105835
Local loss @ local epoch 3: 0.4615515470504761
Local loss @ local epoch 4: 0.42826658487319946
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 128.41 seconds!
[tester] 
AGNewsMetric: acc=0.8089473684210526, hinge=1.5045385656858745, ce=6.797440868176912
Local test acc @ epoch 0: 0.8089
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.9582577347755432
Local loss @ local epoch 1: 0.9455682635307312
Local loss @ local epoch 2: 0.7823156714439392
Local loss @ local epoch 3: 1.1795599460601807
Local loss @ local epoch 4: 0.865312397480011
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.61 seconds!
[tester] 
AGNewsMetric: acc=0.7723684210526316, hinge=1.6722967318484658, ce=7.5473505471882065
Local test acc @ epoch 0: 0.7724
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.7719470858573914
Local loss @ local epoch 1: 0.7295281291007996
Local loss @ local epoch 2: 0.6906866431236267
Local loss @ local epoch 3: 0.8402449488639832
Local loss @ local epoch 4: 0.5129102468490601
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.59 seconds!
[tester] 
AGNewsMetric: acc=0.7864473684210527, hinge=1.6761369163111637, ce=6.112259521484375
Local test acc @ epoch 0: 0.7864
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.6112694144248962
Local loss @ local epoch 1: 0.6591858267784119
Local loss @ local epoch 2: 0.5479392409324646
Local loss @ local epoch 3: 0.3660855293273926
Local loss @ local epoch 4: 0.49637264013290405
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.94 seconds!
[tester] 
AGNewsMetric: acc=0.8211842105263157, hinge=1.30864417879205, ce=6.140233232598556
Local test acc @ epoch 0: 0.8212
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.6804854273796082
Local loss @ local epoch 1: 0.742684006690979
Local loss @ local epoch 2: 1.0584537982940674
Local loss @ local epoch 3: 0.7297120094299316
Local loss @ local epoch 4: 0.8482423424720764
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.65 seconds!
[tester] 
AGNewsMetric: acc=0.7893421052631578, hinge=1.6568921445545397, ce=6.6946263704801865
Local test acc @ epoch 0: 0.7893
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.7946459650993347
Local loss @ local epoch 1: 0.7874202728271484
Local loss @ local epoch 2: 0.8450049161911011
Local loss @ local epoch 3: 0.8108083009719849
Local loss @ local epoch 4: 1.4948344230651855
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 128.82 seconds!
[tester] 
AGNewsMetric: acc=0.28289473684210525, hinge=5.790654082047312, ce=14.418999798423366
Local test acc @ epoch 0: 0.2829
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.44825345277786255
Local loss @ local epoch 1: 0.46793830394744873
Local loss @ local epoch 2: 0.45686042308807373
Local loss @ local epoch 3: 0.32855910062789917
Local loss @ local epoch 4: 0.2874351143836975
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.56 seconds!
[tester] 
AGNewsMetric: acc=0.8061842105263158, hinge=1.487681322599712, ce=5.876352011028089
Local test acc @ epoch 0: 0.8062
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.9113634824752808
Local loss @ local epoch 1: 1.1745809316635132
Local loss @ local epoch 2: 1.121715784072876
Local loss @ local epoch 3: 1.042808175086975
Local loss @ local epoch 4: 0.8216750025749207
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.81 seconds!
[tester] 
AGNewsMetric: acc=0.8073684210526316, hinge=1.6127615241000526, ce=6.497604991511294
Local test acc @ epoch 0: 0.8074
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 1.0360029935836792
Local loss @ local epoch 1: 0.5849697589874268
Local loss @ local epoch 2: 0.6513833403587341
Local loss @ local epoch 3: 0.5805928111076355
Local loss @ local epoch 4: 0.6219540238380432
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.59 seconds!
[tester] 
AGNewsMetric: acc=0.8123684210526316, hinge=1.3938304158260948, ce=7.093359578785144
Local test acc @ epoch 0: 0.8124
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 1.0419915914535522
Local loss @ local epoch 1: 0.9185133576393127
Local loss @ local epoch 2: 0.8175373673439026
Local loss @ local epoch 3: 0.9354292154312134
Local loss @ local epoch 4: 1.2583547830581665
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.2 seconds!
[tester] 
AGNewsMetric: acc=0.7796052631578947, hinge=1.609970605247899, ce=7.816169735757928
Local test acc @ epoch 0: 0.7796
Global evaluate on test data...
Evaluate data in 130.5 seconds!
[tester] 
AGNewsMetric: acc=0.8060526315789474, hinge=1.5426334079943205, ce=6.72911122773823
Global test acc @ epoch 0: 0.8061
Global epoch 1...
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.7794671654701233
Local loss @ local epoch 1: 0.8532896637916565
Local loss @ local epoch 2: 0.8342087268829346
Local loss @ local epoch 3: 1.000234842300415
Local loss @ local epoch 4: 0.751621663570404
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.96 seconds!
[tester] 
AGNewsMetric: acc=0.8075, hinge=1.50654962037739, ce=7.383580785048635
Local test acc @ epoch 1: 0.8075
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.8063796758651733
Local loss @ local epoch 1: 0.5176594257354736
Local loss @ local epoch 2: 1.8919219970703125
Local loss @ local epoch 3: 1.98431396484375
Local loss @ local epoch 4: 1.2309781312942505
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.24 seconds!
[tester] 
AGNewsMetric: acc=0.7986842105263158, hinge=1.4414572025600232, ce=8.665348757693643
Local test acc @ epoch 1: 0.7987
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.5727496147155762
Local loss @ local epoch 1: 0.4024779200553894
Local loss @ local epoch 2: 1.381442666053772
Local loss @ local epoch 3: 1.2739070653915405
Local loss @ local epoch 4: 0.8097122311592102
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.78 seconds!
[tester] 
AGNewsMetric: acc=0.7619736842105264, hinge=1.6818772320998343, ce=6.887802080857126
Local test acc @ epoch 1: 0.762
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.9009485840797424
Local loss @ local epoch 1: 0.7561577558517456
Local loss @ local epoch 2: 0.8398258686065674
Local loss @ local epoch 3: 1.1846040487289429
Local loss @ local epoch 4: 0.9173457622528076
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.87 seconds!
[tester] 
AGNewsMetric: acc=0.7984210526315789, hinge=1.4402342128753662, ce=7.738404457694606
Local test acc @ epoch 1: 0.7984
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 1.031643033027649
Local loss @ local epoch 1: 0.851111114025116
Local loss @ local epoch 2: 0.8149192929267883
Local loss @ local epoch 3: 0.8771976828575134
Local loss @ local epoch 4: 1.0299896001815796
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.63 seconds!
[tester] 
AGNewsMetric: acc=0.25026315789473685, hinge=6.72803879988821, ce=16.566216948659797
Local test acc @ epoch 1: 0.2503
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.0000331401824951
Local loss @ local epoch 1: 1.0354405641555786
Local loss @ local epoch 2: 0.894849419593811
Local loss @ local epoch 3: 1.0342262983322144
Local loss @ local epoch 4: 0.9222381114959717
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.8 seconds!
[tester] 
AGNewsMetric: acc=0.8111842105263158, hinge=1.4428566566266512, ce=6.70508575941387
Local test acc @ epoch 1: 0.8112
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.5098414421081543
Local loss @ local epoch 1: 0.6316233277320862
Local loss @ local epoch 2: 0.7260051369667053
Local loss @ local epoch 3: 0.39568203687667847
Local loss @ local epoch 4: 0.4913116693496704
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.72 seconds!
[tester] 
AGNewsMetric: acc=0.7907894736842105, hinge=1.3162241514105546, ce=7.3971750520405015
Local test acc @ epoch 1: 0.7908
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.7705103158950806
Local loss @ local epoch 1: 0.7613924145698547
Local loss @ local epoch 2: 0.6895961165428162
Local loss @ local epoch 3: 0.7571394443511963
Local loss @ local epoch 4: 0.6740766167640686
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.25 seconds!
[tester] 
AGNewsMetric: acc=0.7861842105263158, hinge=1.5828702113502904, ce=6.159183804361444
Local test acc @ epoch 1: 0.7862
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.48600396513938904
Local loss @ local epoch 1: 0.3493356704711914
Local loss @ local epoch 2: 0.36449238657951355
Local loss @ local epoch 3: 0.31328296661376953
Local loss @ local epoch 4: 0.2836625277996063
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.6 seconds!
[tester] 
AGNewsMetric: acc=0.8235526315789473, hinge=1.2732946285448576, ce=7.240841360594097
Local test acc @ epoch 1: 0.8236
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.7155145406723022
Local loss @ local epoch 1: 0.605443000793457
Local loss @ local epoch 2: 0.7307043671607971
Local loss @ local epoch 3: 0.5800508856773376
Local loss @ local epoch 4: 0.848712682723999
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.0 seconds!
[tester] 
AGNewsMetric: acc=0.7735526315789474, hinge=1.5926456315893875, ce=7.462538934004934
Local test acc @ epoch 1: 0.7736
Global evaluate on test data...
Evaluate data in 129.8 seconds!
[tester] 
AGNewsMetric: acc=0.815921052631579, hinge=1.3693788769370632, ce=7.153789797331157
Global test acc @ epoch 1: 0.8159
Global epoch 2...
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.5027881264686584
Local loss @ local epoch 1: 0.5654497146606445
Local loss @ local epoch 2: 1.1052056550979614
Local loss @ local epoch 3: 0.5458329319953918
Local loss @ local epoch 4: 0.6699050664901733
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.09 seconds!
[tester] 
AGNewsMetric: acc=0.8102631578947368, hinge=1.3673081754383287, ce=7.153789700959858
Local test acc @ epoch 2: 0.8103
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.8121097683906555
Local loss @ local epoch 1: 0.6959853768348694
Local loss @ local epoch 2: 0.6779129505157471
Local loss @ local epoch 3: 0.5759861469268799
Local loss @ local epoch 4: 0.6164444088935852
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.66 seconds!
[tester] 
AGNewsMetric: acc=0.8252631578947368, hinge=1.3240623363695647, ce=6.902304892289011
Local test acc @ epoch 2: 0.8253
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.8861432671546936
Local loss @ local epoch 1: 0.6601288318634033
Local loss @ local epoch 2: 0.9997477531433105
Local loss @ local epoch 3: 0.7556318640708923
Local loss @ local epoch 4: 0.8124595284461975
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.63 seconds!
[tester] 
AGNewsMetric: acc=0.8021052631578948, hinge=1.5599644926974647, ce=7.019486861981844
Local test acc @ epoch 2: 0.8021
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.4136839509010315
Local loss @ local epoch 1: 0.400987446308136
Local loss @ local epoch 2: 0.3207695484161377
Local loss @ local epoch 3: 0.3483763635158539
Local loss @ local epoch 4: 0.30588585138320923
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.31 seconds!
[tester] 
AGNewsMetric: acc=0.8196052631578947, hinge=1.3557136992404335, ce=6.799994703594007
Local test acc @ epoch 2: 0.8196
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.5690782070159912
Local loss @ local epoch 1: 0.574149489402771
Local loss @ local epoch 2: 0.5679848790168762
Local loss @ local epoch 3: 0.7407846450805664
Local loss @ local epoch 4: 0.731762170791626
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.05 seconds!
[tester] 
AGNewsMetric: acc=0.8131578947368421, hinge=1.3529228381106728, ce=7.596335718255294
Local test acc @ epoch 2: 0.8132
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.8874717354774475
Local loss @ local epoch 1: 0.9186230897903442
Local loss @ local epoch 2: 0.8585387468338013
Local loss @ local epoch 3: 0.7427064776420593
Local loss @ local epoch 4: 0.6509531140327454
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.41 seconds!
[tester] 
AGNewsMetric: acc=0.8060526315789474, hinge=1.4545988785593134, ce=7.256246777584678
Local test acc @ epoch 2: 0.8061
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.5251604318618774
Local loss @ local epoch 1: 0.4162582457065582
Local loss @ local epoch 2: 0.3944699764251709
Local loss @ local epoch 3: 0.42774608731269836
Local loss @ local epoch 4: 0.34885722398757935
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.51 seconds!
[tester] 
AGNewsMetric: acc=0.8323684210526315, hinge=1.219718848278648, ce=6.6781715493453175
Local test acc @ epoch 2: 0.8324
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.8257508277893066
Local loss @ local epoch 1: 0.7473692893981934
Local loss @ local epoch 2: 0.7814991474151611
Local loss @ local epoch 3: 0.6773867607116699
Local loss @ local epoch 4: 0.6772011518478394
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.86 seconds!
[tester] 
AGNewsMetric: acc=0.790921052631579, hinge=1.450575852645071, ce=7.06336851621929
Local test acc @ epoch 2: 0.7909
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 1.114077091217041
Local loss @ local epoch 1: 0.8717613816261292
Local loss @ local epoch 2: 0.9474170207977295
Local loss @ local epoch 3: 0.9296786189079285
Local loss @ local epoch 4: 0.866925060749054
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.13 seconds!
[tester] 
AGNewsMetric: acc=0.42210526315789476, hinge=4.118809209120901, ce=10.8940203977886
Local test acc @ epoch 2: 0.4221
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.6950992941856384
Local loss @ local epoch 1: 0.6171718239784241
Local loss @ local epoch 2: 0.5451226830482483
Local loss @ local epoch 3: 0.6141874194145203
Local loss @ local epoch 4: 0.49120232462882996
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.9 seconds!
[tester] 
AGNewsMetric: acc=0.8134210526315789, hinge=1.2517144062644556, ce=7.576790036653217
Local test acc @ epoch 2: 0.8134
Global evaluate on test data...
Evaluate data in 129.94 seconds!
[tester] 
AGNewsMetric: acc=0.825921052631579, hinge=1.2793870012383712, ce=7.111460266113281
Global test acc @ epoch 2: 0.8259
Global epoch 3...
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.363211452960968
Local loss @ local epoch 1: 0.42960962653160095
Local loss @ local epoch 2: 0.2418994903564453
Local loss @ local epoch 3: 0.3606637120246887
Local loss @ local epoch 4: 0.283089816570282
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.15 seconds!
[tester] 
AGNewsMetric: acc=0.8255263157894737, hinge=1.2978442874707674, ce=6.7765669310720344
Local test acc @ epoch 3: 0.8255
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.6669992208480835
Local loss @ local epoch 1: 0.5149739384651184
Local loss @ local epoch 2: 0.46171998977661133
Local loss @ local epoch 3: 0.7689387798309326
Local loss @ local epoch 4: 0.6505048871040344
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.15 seconds!
[tester] 
AGNewsMetric: acc=0.8231578947368421, hinge=1.1846173532385575, ce=5.548772464551424
Local test acc @ epoch 3: 0.8232
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.41380831599235535
Local loss @ local epoch 1: 0.48366278409957886
Local loss @ local epoch 2: 0.6852556467056274
Local loss @ local epoch 3: 0.38469377160072327
Local loss @ local epoch 4: 0.35319140553474426
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.45 seconds!
[tester] 
AGNewsMetric: acc=0.8075, hinge=1.3111648750305176, ce=7.302381830717388
Local test acc @ epoch 3: 0.8075
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.944664716720581
Local loss @ local epoch 1: 0.7152625918388367
Local loss @ local epoch 2: 0.7042937278747559
Local loss @ local epoch 3: 0.5214443802833557
Local loss @ local epoch 4: 0.8708212971687317
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 128.93 seconds!
[tester] 
AGNewsMetric: acc=0.8061842105263158, hinge=1.325565205624229, ce=5.184159353155839
Local test acc @ epoch 3: 0.8062
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.6626852750778198
Local loss @ local epoch 1: 0.4950742721557617
Local loss @ local epoch 2: 0.5575129389762878
Local loss @ local epoch 3: 0.9241324067115784
Local loss @ local epoch 4: 0.5244414806365967
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.57 seconds!
[tester] 
AGNewsMetric: acc=0.8173684210526316, hinge=1.355214517492997, ce=6.939749197708933
Local test acc @ epoch 3: 0.8174
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.6123641133308411
Local loss @ local epoch 1: 0.4158479869365692
Local loss @ local epoch 2: 0.46027103066444397
Local loss @ local epoch 3: 0.384166419506073
Local loss @ local epoch 4: 0.5496702194213867
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.79 seconds!
[tester] 
AGNewsMetric: acc=0.8123684210526316, hinge=1.235274809787148, ce=7.194889183044434
Local test acc @ epoch 3: 0.8124
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.9101678729057312
Local loss @ local epoch 1: 0.9355512261390686
Local loss @ local epoch 2: 0.8826868534088135
Local loss @ local epoch 3: 0.8636063933372498
Local loss @ local epoch 4: 0.6839371919631958
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.51 seconds!
[tester] 
AGNewsMetric: acc=0.8207894736842105, hinge=1.4700183953736958, ce=5.991463650151303
Local test acc @ epoch 3: 0.8208
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.5413597822189331
Local loss @ local epoch 1: 0.5210740566253662
Local loss @ local epoch 2: 0.5813565850257874
Local loss @ local epoch 3: 0.5698109865188599
Local loss @ local epoch 4: 0.5176312923431396
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.43 seconds!
[tester] 
AGNewsMetric: acc=0.8271052631578948, hinge=1.3148870824512682, ce=7.440452521474738
Local test acc @ epoch 3: 0.8271
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.0867385864257812
Local loss @ local epoch 1: 0.7758166193962097
Local loss @ local epoch 2: 1.1579469442367554
Local loss @ local epoch 3: 0.6906846761703491
Local loss @ local epoch 4: 0.7991999387741089
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.94 seconds!
[tester] 
AGNewsMetric: acc=0.8125, hinge=1.304871661537572, ce=7.569630278537148
Local test acc @ epoch 3: 0.8125
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.9144133925437927
Local loss @ local epoch 1: 0.8347052335739136
Local loss @ local epoch 2: 0.7951438426971436
Local loss @ local epoch 3: 0.5446511507034302
Local loss @ local epoch 4: 0.6703578233718872
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.81 seconds!
[tester] 
AGNewsMetric: acc=0.8069736842105263, hinge=1.2549802147714715, ce=7.583333373822664
Local test acc @ epoch 3: 0.807
Global evaluate on test data...
Evaluate data in 130.29 seconds!
[tester] 
AGNewsMetric: acc=0.8347368421052631, hinge=1.1574161599811754, ce=7.005669846785696
Global test acc @ epoch 3: 0.8347
Global epoch 4...
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.7812730073928833
Local loss @ local epoch 1: 0.661899209022522
Local loss @ local epoch 2: 1.0902009010314941
Local loss @ local epoch 3: 0.6196073889732361
Local loss @ local epoch 4: 0.6064238548278809
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.45 seconds!
[tester] 
AGNewsMetric: acc=0.7856578947368421, hinge=1.4267752195659438, ce=7.461199394025301
Local test acc @ epoch 4: 0.7857
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.6556865572929382
Local loss @ local epoch 1: 0.5132027864456177
Local loss @ local epoch 2: 0.5895172953605652
Local loss @ local epoch 3: 0.5586399435997009
Local loss @ local epoch 4: 0.41502609848976135
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.24 seconds!
[tester] 
AGNewsMetric: acc=0.6811842105263158, hinge=2.1569045975333765, ce=7.849865991692794
Local test acc @ epoch 4: 0.6812
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.398528516292572
Local loss @ local epoch 1: 0.5668399333953857
Local loss @ local epoch 2: 0.535061776638031
Local loss @ local epoch 3: 0.4351387917995453
Local loss @ local epoch 4: 0.36514320969581604
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.43 seconds!
[tester] 
AGNewsMetric: acc=0.8011842105263158, hinge=1.2943329188698216, ce=8.3337176634136
Local test acc @ epoch 4: 0.8012
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.7546440958976746
Local loss @ local epoch 1: 0.6079710721969604
Local loss @ local epoch 2: 0.5494580268859863
Local loss @ local epoch 3: 0.47344669699668884
Local loss @ local epoch 4: 0.7012081146240234
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.35 seconds!
[tester] 
AGNewsMetric: acc=0.8315789473684211, hinge=1.11548078235827, ce=7.078268815090782
Local test acc @ epoch 4: 0.8316
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.7705176472663879
Local loss @ local epoch 1: 0.8226498365402222
Local loss @ local epoch 2: 0.9790683388710022
Local loss @ local epoch 3: 0.600643515586853
Local loss @ local epoch 4: 0.8545310497283936
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.03 seconds!
[tester] 
AGNewsMetric: acc=0.8138157894736842, hinge=1.297838053954275, ce=7.045472712265818
Local test acc @ epoch 4: 0.8138
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.4852694869041443
Local loss @ local epoch 1: 0.5553728938102722
Local loss @ local epoch 2: 0.6166483163833618
Local loss @ local epoch 3: 0.6068353652954102
Local loss @ local epoch 4: 0.42404842376708984
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.64 seconds!
[tester] 
AGNewsMetric: acc=0.805, hinge=1.4065567568728798, ce=7.146636699877287
Local test acc @ epoch 4: 0.805
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.4062857925891876
Local loss @ local epoch 1: 0.2911509871482849
Local loss @ local epoch 2: 0.25412261486053467
Local loss @ local epoch 3: 0.3781699240207672
Local loss @ local epoch 4: 0.27931907773017883
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.96 seconds!
[tester] 
AGNewsMetric: acc=0.8080263157894737, hinge=1.316036616375572, ce=4.89060115814209
Local test acc @ epoch 4: 0.808
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.8925963044166565
Local loss @ local epoch 1: 0.7207778096199036
Local loss @ local epoch 2: 0.582554817199707
Local loss @ local epoch 3: 0.8024144172668457
Local loss @ local epoch 4: 0.6801544427871704
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.67 seconds!
[tester] 
AGNewsMetric: acc=0.809078947368421, hinge=1.2540719985961915, ce=5.76299664045635
Local test acc @ epoch 4: 0.8091
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.3621284067630768
Local loss @ local epoch 1: 0.35075315833091736
Local loss @ local epoch 2: 0.3590409755706787
Local loss @ local epoch 3: 0.2837865948677063
Local loss @ local epoch 4: 0.3014070987701416
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.19 seconds!
[tester] 
AGNewsMetric: acc=0.8255263157894737, hinge=1.2652240361665426, ce=6.745685354533949
Local test acc @ epoch 4: 0.8255
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.9682959318161011
Local loss @ local epoch 1: 0.9390609264373779
Local loss @ local epoch 2: 0.8072990775108337
Local loss @ local epoch 3: 0.946567952632904
Local loss @ local epoch 4: 0.8047720193862915
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.98 seconds!
[tester] 
AGNewsMetric: acc=0.8172368421052632, hinge=1.4379197783219186, ce=7.014363514749627
Local test acc @ epoch 4: 0.8172
Global evaluate on test data...
Evaluate data in 129.45 seconds!
[tester] 
AGNewsMetric: acc=0.8377631578947369, hinge=1.1542506233014558, ce=6.729303860915334
Global test acc @ epoch 4: 0.8378
Global epoch 5...
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.8447263836860657
Local loss @ local epoch 1: 0.6797739267349243
Local loss @ local epoch 2: 0.7564843893051147
Local loss @ local epoch 3: 0.6055929064750671
Local loss @ local epoch 4: 0.5736287832260132
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.9 seconds!
[tester] 
AGNewsMetric: acc=0.7848684210526315, hinge=1.4073502294640792, ce=9.473685648064864
Local test acc @ epoch 5: 0.7849
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.8862946629524231
Local loss @ local epoch 1: 0.5583989024162292
Local loss @ local epoch 2: 0.6639400124549866
Local loss @ local epoch 3: 0.509410560131073
Local loss @ local epoch 4: 0.5853538513183594
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.34 seconds!
[tester] 
AGNewsMetric: acc=0.7997368421052632, hinge=1.2742626190185546, ce=6.623082834544935
Local test acc @ epoch 5: 0.7997
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.593690812587738
Local loss @ local epoch 1: 0.5241563320159912
Local loss @ local epoch 2: 0.3313385546207428
Local loss @ local epoch 3: 0.41240179538726807
Local loss @ local epoch 4: 0.45899447798728943
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.47 seconds!
[tester] 
AGNewsMetric: acc=0.7444736842105263, hinge=1.6569286562267103, ce=8.524067655864515
Local test acc @ epoch 5: 0.7445
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.6612006425857544
Local loss @ local epoch 1: 0.7289233207702637
Local loss @ local epoch 2: 0.6016653776168823
Local loss @ local epoch 3: 0.574989378452301
Local loss @ local epoch 4: 0.6008104085922241
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.43 seconds!
[tester] 
AGNewsMetric: acc=0.8232894736842106, hinge=1.3289197625611957, ce=6.2453092705576045
Local test acc @ epoch 5: 0.8233
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.8601571321487427
Local loss @ local epoch 1: 0.8942611217498779
Local loss @ local epoch 2: 0.8105292320251465
Local loss @ local epoch 3: 1.3272435665130615
Local loss @ local epoch 4: 2.086282730102539
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.94 seconds!
[tester] 
AGNewsMetric: acc=0.26302631578947366, hinge=6.097445844349108, ce=12.37700311961927
Local test acc @ epoch 5: 0.263
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.4733026921749115
Local loss @ local epoch 1: 0.3930552899837494
Local loss @ local epoch 2: 0.8987109065055847
Local loss @ local epoch 3: 0.34491100907325745
Local loss @ local epoch 4: 0.2967907786369324
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.87 seconds!
[tester] 
AGNewsMetric: acc=0.8253947368421053, hinge=1.0919052425183748, ce=8.181729726289449
Local test acc @ epoch 5: 0.8254
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.7526033520698547
Local loss @ local epoch 1: 0.6893198490142822
Local loss @ local epoch 2: 0.7602308392524719
Local loss @ local epoch 3: 0.8902557492256165
Local loss @ local epoch 4: 0.9463701248168945
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.7 seconds!
[tester] 
AGNewsMetric: acc=0.7681578947368422, hinge=1.4948695308283755, ce=8.663903874849018
Local test acc @ epoch 5: 0.7682
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.29493096470832825
Local loss @ local epoch 1: 0.37011364102363586
Local loss @ local epoch 2: 0.9594419002532959
Local loss @ local epoch 3: 0.5518083572387695
Local loss @ local epoch 4: 0.41375815868377686
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.53 seconds!
[tester] 
AGNewsMetric: acc=0.8309210526315789, hinge=1.1579280245931525, ce=7.18813966148778
Local test acc @ epoch 5: 0.8309
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.35921573638916016
Local loss @ local epoch 1: 0.329159677028656
Local loss @ local epoch 2: 0.3255302309989929
Local loss @ local epoch 3: 0.2669166326522827
Local loss @ local epoch 4: 0.2590729296207428
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.12 seconds!
[tester] 
AGNewsMetric: acc=0.8086842105263158, hinge=1.3666878770527087, ce=6.981076255597566
Local test acc @ epoch 5: 0.8087
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.44450855255126953
Local loss @ local epoch 1: 0.4836667776107788
Local loss @ local epoch 2: 0.23624245822429657
Local loss @ local epoch 3: 0.2866652011871338
Local loss @ local epoch 4: 0.26885852217674255
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.61 seconds!
[tester] 
AGNewsMetric: acc=0.8167105263157894, hinge=1.1432889722522936, ce=8.826782118144788
Local test acc @ epoch 5: 0.8167
Global evaluate on test data...
Evaluate data in 129.81 seconds!
[tester] 
AGNewsMetric: acc=0.8402631578947368, hinge=1.092280663440102, ce=7.05900025518317
Global test acc @ epoch 5: 0.8403
Global epoch 6...
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.7797505855560303
Local loss @ local epoch 1: 0.6742375493049622
Local loss @ local epoch 2: 0.8282706141471863
Local loss @ local epoch 3: 0.7433366179466248
Local loss @ local epoch 4: 0.5198975205421448
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.71 seconds!
[tester] 
AGNewsMetric: acc=0.7805263157894737, hinge=1.3310955639889366, ce=6.858485585262901
Local test acc @ epoch 6: 0.7805
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.41455405950546265
Local loss @ local epoch 1: 0.3516128361225128
Local loss @ local epoch 2: 0.27601152658462524
Local loss @ local epoch 3: 0.3575921654701233
Local loss @ local epoch 4: 0.3910510838031769
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.2 seconds!
[tester] 
AGNewsMetric: acc=0.8348684210526316, hinge=1.2247603802931937, ce=6.390258140563965
Local test acc @ epoch 6: 0.8349
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.619087815284729
Local loss @ local epoch 1: 0.6910350918769836
Local loss @ local epoch 2: 0.7208923101425171
Local loss @ local epoch 3: 1.661474347114563
Local loss @ local epoch 4: 1.569006323814392
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.02 seconds!
[tester] 
AGNewsMetric: acc=0.25894736842105265, hinge=5.99909434770283, ce=14.226195491991545
Local test acc @ epoch 6: 0.2589
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.6761711835861206
Local loss @ local epoch 1: 0.6688742637634277
Local loss @ local epoch 2: 0.5503401160240173
Local loss @ local epoch 3: 0.6438317894935608
Local loss @ local epoch 4: 1.116929292678833
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.33 seconds!
[tester] 
AGNewsMetric: acc=0.8038157894736843, hinge=1.3632296672620272, ce=7.486089799780594
Local test acc @ epoch 6: 0.8038
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.5330678820610046
Local loss @ local epoch 1: 0.4513932466506958
Local loss @ local epoch 2: 0.5475807785987854
Local loss @ local epoch 3: 0.6813476085662842
Local loss @ local epoch 4: 0.5404932498931885
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 128.96 seconds!
[tester] 
AGNewsMetric: acc=0.8115789473684211, hinge=1.3001157233589573, ce=7.983675095407587
Local test acc @ epoch 6: 0.8116
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.49908536672592163
Local loss @ local epoch 1: 0.3114452362060547
Local loss @ local epoch 2: 0.312877893447876
Local loss @ local epoch 3: 0.2136889547109604
Local loss @ local epoch 4: 0.16557477414608002
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.27 seconds!
[tester] 
AGNewsMetric: acc=0.8228947368421052, hinge=1.1791381170875148, ce=6.808494788721988
Local test acc @ epoch 6: 0.8229
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.6028769612312317
Local loss @ local epoch 1: 0.4737315773963928
Local loss @ local epoch 2: 0.3226366639137268
Local loss @ local epoch 3: 0.9992386698722839
Local loss @ local epoch 4: 0.5803123712539673
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.1 seconds!
[tester] 
AGNewsMetric: acc=0.49315789473684213, hinge=3.941888346923025, ce=9.743046463414242
Local test acc @ epoch 6: 0.4932
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.4123864769935608
Local loss @ local epoch 1: 0.4090970754623413
Local loss @ local epoch 2: 0.2882521152496338
Local loss @ local epoch 3: 0.4287503659725189
Local loss @ local epoch 4: 0.2845807373523712
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.64 seconds!
[tester] 
AGNewsMetric: acc=0.8253947368421053, hinge=1.1068210114930805, ce=9.211992478621633
Local test acc @ epoch 6: 0.8254
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.7528620958328247
Local loss @ local epoch 1: 1.1846414804458618
Local loss @ local epoch 2: 0.8942238092422485
Local loss @ local epoch 3: 0.7892019748687744
Local loss @ local epoch 4: 0.7255276441574097
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.27 seconds!
[tester] 
AGNewsMetric: acc=0.8302631578947368, hinge=1.1482444020321494, ce=7.186168989884226
Local test acc @ epoch 6: 0.8303
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.4433325231075287
Local loss @ local epoch 1: 0.4724278450012207
Local loss @ local epoch 2: 0.4038601517677307
Local loss @ local epoch 3: 0.4632721245288849
Local loss @ local epoch 4: 0.4051695764064789
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.04 seconds!
[tester] 
AGNewsMetric: acc=0.8025, hinge=1.222893399188393, ce=6.8531082123204285
Local test acc @ epoch 6: 0.8025
Global evaluate on test data...
Evaluate data in 129.68 seconds!
[tester] 
AGNewsMetric: acc=0.844078947368421, hinge=0.9697501804954127, ce=7.207766238764712
Global test acc @ epoch 6: 0.8441
Global epoch 7...
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.3509539067745209
Local loss @ local epoch 1: 0.41757693886756897
Local loss @ local epoch 2: 0.184420645236969
Local loss @ local epoch 3: 1.0041618347167969
Local loss @ local epoch 4: 0.28729578852653503
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.17 seconds!
[tester] 
AGNewsMetric: acc=0.8072368421052631, hinge=1.3137383832429586, ce=9.019354113528603
Local test acc @ epoch 7: 0.8072
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.6667941808700562
Local loss @ local epoch 1: 0.6094686985015869
Local loss @ local epoch 2: 0.4962654709815979
Local loss @ local epoch 3: 0.9786258339881897
Local loss @ local epoch 4: 0.3801805078983307
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.34 seconds!
[tester] 
AGNewsMetric: acc=0.8115789473684211, hinge=1.166925799219232, ce=5.489524975826866
Local test acc @ epoch 7: 0.8116
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.8683963418006897
Local loss @ local epoch 1: 0.8409218192100525
Local loss @ local epoch 2: 0.7698193788528442
Local loss @ local epoch 3: 0.7040114998817444
Local loss @ local epoch 4: 0.861182689666748
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.95 seconds!
[tester] 
AGNewsMetric: acc=0.8082894736842106, hinge=1.2745850387372468, ce=7.0150856520000255
Local test acc @ epoch 7: 0.8083
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.5140393972396851
Local loss @ local epoch 1: 0.5913265943527222
Local loss @ local epoch 2: 0.65079665184021
Local loss @ local epoch 3: 0.6009160280227661
Local loss @ local epoch 4: 0.6654792428016663
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.06 seconds!
[tester] 
AGNewsMetric: acc=0.8069736842105263, hinge=1.2597954960873252, ce=7.748754571613513
Local test acc @ epoch 7: 0.807
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.3265856206417084
Local loss @ local epoch 1: 0.37134236097335815
Local loss @ local epoch 2: 0.2557846009731293
Local loss @ local epoch 3: 0.24834302067756653
Local loss @ local epoch 4: 0.3133324384689331
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.83 seconds!
[tester] 
AGNewsMetric: acc=0.8128947368421052, hinge=1.3026808663418419, ce=6.83174256575735
Local test acc @ epoch 7: 0.8129
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.45013517141342163
Local loss @ local epoch 1: 0.4663183391094208
Local loss @ local epoch 2: 0.5270358324050903
Local loss @ local epoch 3: 0.4767391085624695
Local loss @ local epoch 4: 1.6350321769714355
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.07 seconds!
[tester] 
AGNewsMetric: acc=0.7117105263157895, hinge=2.090060285267077, ce=6.1414047180978875
Local test acc @ epoch 7: 0.7117
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.6525385975837708
Local loss @ local epoch 1: 0.7025467753410339
Local loss @ local epoch 2: 0.7372199892997742
Local loss @ local epoch 3: 0.6741902232170105
Local loss @ local epoch 4: 0.524606466293335
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.81 seconds!
[tester] 
AGNewsMetric: acc=0.8164473684210526, hinge=1.2439916093725907, ce=8.54356649699964
Local test acc @ epoch 7: 0.8164
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.21380621194839478
Local loss @ local epoch 1: 0.4720049798488617
Local loss @ local epoch 2: 0.6292440891265869
Local loss @ local epoch 3: 1.3534127473831177
Local loss @ local epoch 4: 2.232668876647949
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.55 seconds!
[tester] 
AGNewsMetric: acc=0.2905263157894737, hinge=5.913790533166183, ce=12.434808686908923
Local test acc @ epoch 7: 0.2905
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.4237431287765503
Local loss @ local epoch 1: 0.6335787177085876
Local loss @ local epoch 2: 0.458172470331192
Local loss @ local epoch 3: 0.38190340995788574
Local loss @ local epoch 4: 0.40627530217170715
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.32 seconds!
[tester] 
AGNewsMetric: acc=0.8168421052631579, hinge=1.207489646108527, ce=8.277056979129188
Local test acc @ epoch 7: 0.8168
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.30647143721580505
Local loss @ local epoch 1: 0.538425087928772
Local loss @ local epoch 2: 0.41022059321403503
Local loss @ local epoch 3: 0.3815280497074127
Local loss @ local epoch 4: 0.5244453549385071
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 128.98 seconds!
[tester] 
AGNewsMetric: acc=0.8303947368421053, hinge=1.087986711200915, ce=6.211059532165527
Local test acc @ epoch 7: 0.8304
Global evaluate on test data...
Evaluate data in 130.21 seconds!
[tester] 
AGNewsMetric: acc=0.8556578947368421, hinge=0.9214496446910657, ce=6.565067858445017
Global test acc @ epoch 7: 0.8557
Global epoch 8...
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.7433524131774902
Local loss @ local epoch 1: 0.5196403861045837
Local loss @ local epoch 2: 0.6379442811012268
Local loss @ local epoch 3: 0.6689642071723938
Local loss @ local epoch 4: 0.4869808852672577
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.99 seconds!
[tester] 
AGNewsMetric: acc=0.8256578947368421, hinge=1.1738296062067934, ce=7.904154305709036
Local test acc @ epoch 8: 0.8257
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.8310806751251221
Local loss @ local epoch 1: 0.6837243437767029
Local loss @ local epoch 2: 0.629375696182251
Local loss @ local epoch 3: 0.5120902061462402
Local loss @ local epoch 4: 0.6936395764350891
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.75 seconds!
[tester] 
AGNewsMetric: acc=0.7467105263157895, hinge=1.5387380248621891, ce=7.844762513010125
Local test acc @ epoch 8: 0.7467
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.6328737139701843
Local loss @ local epoch 1: 0.7103790044784546
Local loss @ local epoch 2: 0.48794591426849365
Local loss @ local epoch 3: 0.5198734402656555
Local loss @ local epoch 4: 0.5167437791824341
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.39 seconds!
[tester] 
AGNewsMetric: acc=0.8167105263157894, hinge=1.1620852008618807, ce=7.478006320752596
Local test acc @ epoch 8: 0.8167
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.2724616229534149
Local loss @ local epoch 1: 0.25460124015808105
Local loss @ local epoch 2: 0.32453083992004395
Local loss @ local epoch 3: 0.31119096279144287
Local loss @ local epoch 4: 0.2016337513923645
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.79 seconds!
[tester] 
AGNewsMetric: acc=0.8413157894736842, hinge=1.1158240132582815, ce=6.827821610099391
Local test acc @ epoch 8: 0.8413
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.5367785692214966
Local loss @ local epoch 1: 0.7064247131347656
Local loss @ local epoch 2: 0.6371700763702393
Local loss @ local epoch 3: 0.6706845164299011
Local loss @ local epoch 4: 0.5669834613800049
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.13 seconds!
[tester] 
AGNewsMetric: acc=0.8238157894736842, hinge=1.2489317311738666, ce=6.179597218162135
Local test acc @ epoch 8: 0.8238
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.27952611446380615
Local loss @ local epoch 1: 0.19334827363491058
Local loss @ local epoch 2: 0.1938561499118805
Local loss @ local epoch 3: 0.2879287004470825
Local loss @ local epoch 4: 0.24506624042987823
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.58 seconds!
[tester] 
AGNewsMetric: acc=0.8410526315789474, hinge=1.057537360944246, ce=7.8802047609028065
Local test acc @ epoch 8: 0.8411
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.7040019631385803
Local loss @ local epoch 1: 0.6306309103965759
Local loss @ local epoch 2: 0.41017946600914
Local loss @ local epoch 3: 0.41903743147850037
Local loss @ local epoch 4: 0.5005539655685425
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.81 seconds!
[tester] 
AGNewsMetric: acc=0.8139473684210526, hinge=1.270126391461021, ce=7.016423314747057
Local test acc @ epoch 8: 0.8139
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.40952643752098083
Local loss @ local epoch 1: 0.6392853856086731
Local loss @ local epoch 2: 0.3896543085575104
Local loss @ local epoch 3: 0.43209347128868103
Local loss @ local epoch 4: 0.28551265597343445
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.28 seconds!
[tester] 
AGNewsMetric: acc=0.8388157894736842, hinge=1.033599248685335, ce=9.130544034054404
Local test acc @ epoch 8: 0.8388
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.29789215326309204
Local loss @ local epoch 1: 0.3886915445327759
Local loss @ local epoch 2: 0.2579881250858307
Local loss @ local epoch 3: 0.3718682825565338
Local loss @ local epoch 4: 0.44870319962501526
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.58 seconds!
[tester] 
AGNewsMetric: acc=0.8331578947368421, hinge=1.096812179465043, ce=6.9202045932569005
Local test acc @ epoch 8: 0.8332
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.7486781477928162
Local loss @ local epoch 1: 0.5214038491249084
Local loss @ local epoch 2: 0.8118801712989807
Local loss @ local epoch 3: 0.651291012763977
Local loss @ local epoch 4: 0.8132408261299133
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.58 seconds!
[tester] 
AGNewsMetric: acc=0.8097368421052632, hinge=1.2148238332648027, ce=7.701649079573782
Local test acc @ epoch 8: 0.8097
Global evaluate on test data...
Evaluate data in 129.64 seconds!
[tester] 
AGNewsMetric: acc=0.8582894736842105, hinge=0.9514068558341578, ce=6.752264530784205
Global test acc @ epoch 8: 0.8583
Global epoch 9...
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.4535443186759949
Local loss @ local epoch 1: 0.20687714219093323
Local loss @ local epoch 2: 0.10816916078329086
Local loss @ local epoch 3: 0.27112236618995667
Local loss @ local epoch 4: 0.1881730705499649
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.48 seconds!
[tester] 
AGNewsMetric: acc=0.7901315789473684, hinge=1.325109039356834, ce=9.324205934624922
Local test acc @ epoch 9: 0.7901
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.5444117784500122
Local loss @ local epoch 1: 0.43515974283218384
Local loss @ local epoch 2: 0.5686640739440918
Local loss @ local epoch 3: 0.4318445026874542
Local loss @ local epoch 4: 0.7172035574913025
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.79 seconds!
[tester] 
AGNewsMetric: acc=0.8206578947368421, hinge=1.1519872093200683, ce=6.117600212097168
Local test acc @ epoch 9: 0.8207
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.4976278841495514
Local loss @ local epoch 1: 0.41367676854133606
Local loss @ local epoch 2: 0.43765416741371155
Local loss @ local epoch 3: 0.8039069771766663
Local loss @ local epoch 4: 0.48017269372940063
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.55 seconds!
[tester] 
AGNewsMetric: acc=0.8175, hinge=1.156324012154027, ce=8.474297898945055
Local test acc @ epoch 9: 0.8175
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.31141194701194763
Local loss @ local epoch 1: 0.2823029160499573
Local loss @ local epoch 2: 0.2719816267490387
Local loss @ local epoch 3: 0.17247383296489716
Local loss @ local epoch 4: 0.17390461266040802
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.64 seconds!
[tester] 
AGNewsMetric: acc=0.8084210526315789, hinge=1.2550735262820596, ce=8.057634349622225
Local test acc @ epoch 9: 0.8084
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.6427921652793884
Local loss @ local epoch 1: 0.3898104429244995
Local loss @ local epoch 2: 0.42782825231552124
Local loss @ local epoch 3: 0.4852694869041443
Local loss @ local epoch 4: 0.5375885963439941
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.54 seconds!
[tester] 
AGNewsMetric: acc=0.7569736842105264, hinge=1.7750958081295616, ce=7.558979281375283
Local test acc @ epoch 9: 0.757
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.8258427381515503
Local loss @ local epoch 1: 0.7052602767944336
Local loss @ local epoch 2: 0.7213039994239807
Local loss @ local epoch 3: 0.766552746295929
Local loss @ local epoch 4: 0.7968651652336121
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.78 seconds!
[tester] 
AGNewsMetric: acc=0.8015789473684211, hinge=1.2789697908100328, ce=8.10713478088379
Local test acc @ epoch 9: 0.8016
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.2778177261352539
Local loss @ local epoch 1: 0.35924774408340454
Local loss @ local epoch 2: 0.2923615574836731
Local loss @ local epoch 3: 0.28882792592048645
Local loss @ local epoch 4: 0.3016423285007477
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.58 seconds!
[tester] 
AGNewsMetric: acc=0.8471052631578947, hinge=1.1287688978094803, ce=6.53428813131232
Local test acc @ epoch 9: 0.8471
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.6823834180831909
Local loss @ local epoch 1: 0.6417905688285828
Local loss @ local epoch 2: 0.5250748991966248
Local loss @ local epoch 3: 1.018908977508545
Local loss @ local epoch 4: 0.7457374334335327
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.2 seconds!
[tester] 
AGNewsMetric: acc=0.7973684210526316, hinge=1.2925342660201222, ce=8.018915585969625
Local test acc @ epoch 9: 0.7974
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.37512707710266113
Local loss @ local epoch 1: 0.5273793339729309
Local loss @ local epoch 2: 0.6540448069572449
Local loss @ local epoch 3: 0.6888599991798401
Local loss @ local epoch 4: 0.7767795920372009
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.54 seconds!
[tester] 
AGNewsMetric: acc=0.8328947368421052, hinge=1.1338115406036378, ce=8.174940010873895
Local test acc @ epoch 9: 0.8329
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.703026533126831
Local loss @ local epoch 1: 0.6364957690238953
Local loss @ local epoch 2: 0.52565598487854
Local loss @ local epoch 3: 0.718492329120636
Local loss @ local epoch 4: 0.5695010423660278
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.05 seconds!
[tester] 
AGNewsMetric: acc=0.7807894736842105, hinge=1.4834203770286158, ce=7.64198726553666
Local test acc @ epoch 9: 0.7808
Global evaluate on test data...
Evaluate data in 129.63 seconds!
[tester] 
AGNewsMetric: acc=0.8555263157894737, hinge=0.8993608901375219, ce=7.504457479778089
Global test acc @ epoch 9: 0.8555
Global epoch 10...
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.6362197995185852
Local loss @ local epoch 1: 0.6517080664634705
Local loss @ local epoch 2: 0.4605039954185486
Local loss @ local epoch 3: 0.6185448169708252
Local loss @ local epoch 4: 0.7085985541343689
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.9 seconds!
[tester] 
AGNewsMetric: acc=0.8425, hinge=1.027167811142771, ce=8.030360559162341
Local test acc @ epoch 10: 0.8425
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.28007712960243225
Local loss @ local epoch 1: 0.2276320457458496
Local loss @ local epoch 2: 0.14847661554813385
Local loss @ local epoch 3: 0.19590680301189423
Local loss @ local epoch 4: 0.1900603324174881
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.79 seconds!
[tester] 
AGNewsMetric: acc=0.8385526315789473, hinge=1.0077655862507067, ce=8.863102820547004
Local test acc @ epoch 10: 0.8386
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.45648109912872314
Local loss @ local epoch 1: 0.36988481879234314
Local loss @ local epoch 2: 0.3284889757633209
Local loss @ local epoch 3: 0.26681962609291077
Local loss @ local epoch 4: 0.32262980937957764
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.48 seconds!
[tester] 
AGNewsMetric: acc=0.8263157894736842, hinge=1.0392602564159192, ce=9.76188152112459
Local test acc @ epoch 10: 0.8263
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.5158693790435791
Local loss @ local epoch 1: 0.6019817590713501
Local loss @ local epoch 2: 0.47074687480926514
Local loss @ local epoch 3: 0.32593217492103577
Local loss @ local epoch 4: 0.3378039300441742
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 128.81 seconds!
[tester] 
AGNewsMetric: acc=0.8230263157894737, hinge=1.20485300465634, ce=5.308457091482062
Local test acc @ epoch 10: 0.823
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.9553319811820984
Local loss @ local epoch 1: 0.7370590567588806
Local loss @ local epoch 2: 0.7230706214904785
Local loss @ local epoch 3: 0.7610426545143127
Local loss @ local epoch 4: 1.0185664892196655
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.69 seconds!
[tester] 
AGNewsMetric: acc=0.8161842105263157, hinge=1.3679918344397295, ce=6.551444457204719
Local test acc @ epoch 10: 0.8162
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.6013895869255066
Local loss @ local epoch 1: 0.5639195442199707
Local loss @ local epoch 2: 0.4182533919811249
Local loss @ local epoch 3: 0.5170947909355164
Local loss @ local epoch 4: 0.3885954022407532
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.86 seconds!
[tester] 
AGNewsMetric: acc=0.7513157894736842, hinge=2.2315685854460066, ce=9.904234283848814
Local test acc @ epoch 10: 0.7513
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.4039748013019562
Local loss @ local epoch 1: 0.5058164596557617
Local loss @ local epoch 2: 0.46664613485336304
Local loss @ local epoch 3: 0.5996662974357605
Local loss @ local epoch 4: 0.6216669678688049
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.7 seconds!
[tester] 
AGNewsMetric: acc=0.810921052631579, hinge=1.3544171107442755, ce=7.442832895580091
Local test acc @ epoch 10: 0.8109
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.6374526023864746
Local loss @ local epoch 1: 0.4349050223827362
Local loss @ local epoch 2: 0.4702836871147156
Local loss @ local epoch 3: 0.6004056930541992
Local loss @ local epoch 4: 0.539101243019104
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.09 seconds!
[tester] 
AGNewsMetric: acc=0.8194736842105264, hinge=1.11748941321122, ce=8.004249759473298
Local test acc @ epoch 10: 0.8195
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.4428035318851471
Local loss @ local epoch 1: 0.21655069291591644
Local loss @ local epoch 2: 0.4096938371658325
Local loss @ local epoch 3: 0.1999301314353943
Local loss @ local epoch 4: 0.34625956416130066
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.05 seconds!
[tester] 
AGNewsMetric: acc=0.7756578947368421, hinge=1.5373147241692795, ce=6.680091126090602
Local test acc @ epoch 10: 0.7757
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.2824057638645172
Local loss @ local epoch 1: 0.2681012451648712
Local loss @ local epoch 2: 0.16069753468036652
Local loss @ local epoch 3: 0.14639513194561005
Local loss @ local epoch 4: 0.2894076108932495
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.16 seconds!
[tester] 
AGNewsMetric: acc=0.8060526315789474, hinge=1.3162276870325993, ce=7.321090425190173
Local test acc @ epoch 10: 0.8061
Global evaluate on test data...
Evaluate data in 130.06 seconds!
[tester] 
AGNewsMetric: acc=0.8478947368421053, hinge=0.9357791117617958, ce=8.802243710568076
Global test acc @ epoch 10: 0.8479
Global epoch 11...
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.3311220109462738
Local loss @ local epoch 1: 0.2088131606578827
Local loss @ local epoch 2: 0.2916823923587799
Local loss @ local epoch 3: 0.2811310291290283
Local loss @ local epoch 4: 0.2958814203739166
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.82 seconds!
[tester] 
AGNewsMetric: acc=0.8356578947368422, hinge=1.1691769966326262, ce=4.464603276503714
Local test acc @ epoch 11: 0.8357
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.7328270673751831
Local loss @ local epoch 1: 0.7229094505310059
Local loss @ local epoch 2: 0.7841916084289551
Local loss @ local epoch 3: 0.6333724856376648
Local loss @ local epoch 4: 0.8993116021156311
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.57 seconds!
[tester] 
AGNewsMetric: acc=0.8217105263157894, hinge=1.11965449734738, ce=7.888424893429405
Local test acc @ epoch 11: 0.8217
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.5982142686843872
Local loss @ local epoch 1: 0.5365571975708008
Local loss @ local epoch 2: 0.3961936831474304
Local loss @ local epoch 3: 0.39288759231567383
Local loss @ local epoch 4: 0.5205065011978149
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.23 seconds!
[tester] 
AGNewsMetric: acc=0.6194736842105263, hinge=2.7288691872044613, ce=7.269965918691534
Local test acc @ epoch 11: 0.6195
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.6238313317298889
Local loss @ local epoch 1: 0.4322385787963867
Local loss @ local epoch 2: 0.41751131415367126
Local loss @ local epoch 3: 0.5289631485939026
Local loss @ local epoch 4: 0.6389390826225281
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.51 seconds!
[tester] 
AGNewsMetric: acc=0.7957894736842105, hinge=1.263160074133622, ce=7.296663166849236
Local test acc @ epoch 11: 0.7958
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.4651702046394348
Local loss @ local epoch 1: 0.45993053913116455
Local loss @ local epoch 2: 0.3222413659095764
Local loss @ local epoch 3: 0.39933449029922485
Local loss @ local epoch 4: 0.3618300259113312
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.36 seconds!
[tester] 
AGNewsMetric: acc=0.8309210526315789, hinge=1.0869219624368769, ce=9.33891685887387
Local test acc @ epoch 11: 0.8309
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.287751704454422
Local loss @ local epoch 1: 0.4207327365875244
Local loss @ local epoch 2: 0.33270058035850525
Local loss @ local epoch 3: 0.37018436193466187
Local loss @ local epoch 4: 0.3512088656425476
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.15 seconds!
[tester] 
AGNewsMetric: acc=0.805921052631579, hinge=1.2139075725956967, ce=7.5403570456253854
Local test acc @ epoch 11: 0.8059
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.20639453828334808
Local loss @ local epoch 1: 0.5682488083839417
Local loss @ local epoch 2: 0.29409515857696533
Local loss @ local epoch 3: 0.322463721036911
Local loss @ local epoch 4: 0.3643045723438263
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.38 seconds!
[tester] 
AGNewsMetric: acc=0.8452631578947368, hinge=1.123111612922267, ce=6.16069891477886
Local test acc @ epoch 11: 0.8453
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.7332926988601685
Local loss @ local epoch 1: 0.7860863208770752
Local loss @ local epoch 2: 0.6877619028091431
Local loss @ local epoch 3: 0.39543044567108154
Local loss @ local epoch 4: 0.7075436115264893
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.04 seconds!
[tester] 
AGNewsMetric: acc=0.7767105263157895, hinge=1.3603647337461773, ce=9.213579904656662
Local test acc @ epoch 11: 0.7767
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.6046662926673889
Local loss @ local epoch 1: 0.5717818737030029
Local loss @ local epoch 2: 0.49637216329574585
Local loss @ local epoch 3: 0.3925747871398926
Local loss @ local epoch 4: 0.544108510017395
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.47 seconds!
[tester] 
AGNewsMetric: acc=0.8118421052631579, hinge=1.2743069603568629, ce=8.696229772065815
Local test acc @ epoch 11: 0.8118
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.5341737866401672
Local loss @ local epoch 1: 0.3132455050945282
Local loss @ local epoch 2: 0.32190069556236267
Local loss @ local epoch 3: 0.2313276082277298
Local loss @ local epoch 4: 0.2802793085575104
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.97 seconds!
[tester] 
AGNewsMetric: acc=0.8021052631578948, hinge=1.289561535182752, ce=6.344968823884662
Local test acc @ epoch 11: 0.8021
Global evaluate on test data...
Evaluate data in 129.54 seconds!
[tester] 
AGNewsMetric: acc=0.8610526315789474, hinge=0.8697607356623599, ce=6.6801856422424315
Global test acc @ epoch 11: 0.8611
Global epoch 12...
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.9694613814353943
Local loss @ local epoch 1: 0.6795459389686584
Local loss @ local epoch 2: 0.5297729969024658
Local loss @ local epoch 3: 0.5543439388275146
Local loss @ local epoch 4: 0.5779480338096619
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.61 seconds!
[tester] 
AGNewsMetric: acc=0.8075, hinge=1.2523183747341757, ce=7.308596507624576
Local test acc @ epoch 12: 0.8075
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.2613465189933777
Local loss @ local epoch 1: 0.1736430674791336
Local loss @ local epoch 2: 0.19222454726696014
Local loss @ local epoch 3: 0.23212701082229614
Local loss @ local epoch 4: 0.9749203324317932
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.55 seconds!
[tester] 
AGNewsMetric: acc=0.8547368421052631, hinge=0.9511126714003714, ce=5.943951151998419
Local test acc @ epoch 12: 0.8547
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.3126707077026367
Local loss @ local epoch 1: 0.2670087218284607
Local loss @ local epoch 2: 0.2300574630498886
Local loss @ local epoch 3: 0.3580126166343689
Local loss @ local epoch 4: 0.3042142987251282
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.96 seconds!
[tester] 
AGNewsMetric: acc=0.8047368421052632, hinge=1.1885208275443628, ce=6.497101622129741
Local test acc @ epoch 12: 0.8047
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.4797525107860565
Local loss @ local epoch 1: 0.43548116087913513
Local loss @ local epoch 2: 0.5441699028015137
Local loss @ local epoch 3: 0.6099570393562317
Local loss @ local epoch 4: 0.49255651235580444
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.65 seconds!
[tester] 
AGNewsMetric: acc=0.845, hinge=1.1504310105976305, ce=6.94449952476903
Local test acc @ epoch 12: 0.845
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.38950011134147644
Local loss @ local epoch 1: 0.5305911302566528
Local loss @ local epoch 2: 0.32413041591644287
Local loss @ local epoch 3: 0.6726755499839783
Local loss @ local epoch 4: 0.3738631308078766
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.05 seconds!
[tester] 
AGNewsMetric: acc=0.7922368421052631, hinge=1.3038847592002467, ce=6.201124119005705
Local test acc @ epoch 12: 0.7922
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.1962406188249588
Local loss @ local epoch 1: 0.3754628300666809
Local loss @ local epoch 2: 0.18476735055446625
Local loss @ local epoch 3: 0.25112441182136536
Local loss @ local epoch 4: 0.20621220767498016
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.67 seconds!
[tester] 
AGNewsMetric: acc=0.8465789473684211, hinge=1.1298229553824977, ce=5.369810585222746
Local test acc @ epoch 12: 0.8466
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.6907731294631958
Local loss @ local epoch 1: 0.7849560976028442
Local loss @ local epoch 2: 0.6941201686859131
Local loss @ local epoch 3: 0.6763847470283508
Local loss @ local epoch 4: 0.615241527557373
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.32 seconds!
[tester] 
AGNewsMetric: acc=0.8082894736842106, hinge=1.26554806508516, ce=7.296288850683915
Local test acc @ epoch 12: 0.8083
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.36740419268608093
Local loss @ local epoch 1: 0.45551544427871704
Local loss @ local epoch 2: 0.4177994728088379
Local loss @ local epoch 3: 0.3402663469314575
Local loss @ local epoch 4: 0.24319201707839966
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.04 seconds!
[tester] 
AGNewsMetric: acc=0.8201315789473684, hinge=1.1338689021060342, ce=7.008951589684737
Local test acc @ epoch 12: 0.8201
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.29232698678970337
Local loss @ local epoch 1: 0.5431262850761414
Local loss @ local epoch 2: 0.36212533712387085
Local loss @ local epoch 3: 0.7490089535713196
Local loss @ local epoch 4: 0.43246573209762573
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 128.97 seconds!
[tester] 
AGNewsMetric: acc=0.8596052631578948, hinge=1.0189264222195273, ce=6.033938611683093
Local test acc @ epoch 12: 0.8596
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.593171238899231
Local loss @ local epoch 1: 0.5552926659584045
Local loss @ local epoch 2: 0.4963917136192322
Local loss @ local epoch 3: 0.4559471905231476
Local loss @ local epoch 4: 0.4816811680793762
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.97 seconds!
[tester] 
AGNewsMetric: acc=0.7301315789473685, hinge=1.896012231927169, ce=7.629517554232948
Local test acc @ epoch 12: 0.7301
Global evaluate on test data...
Evaluate data in 129.48 seconds!
[tester] 
AGNewsMetric: acc=0.8601315789473685, hinge=0.8645098083897641, ce=6.524270826640882
Global test acc @ epoch 12: 0.8601
Global epoch 13...
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.7409577965736389
Local loss @ local epoch 1: 0.8798354864120483
Local loss @ local epoch 2: 0.6914133429527283
Local loss @ local epoch 3: 0.8461175560951233
Local loss @ local epoch 4: 0.9195675253868103
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.95 seconds!
[tester] 
AGNewsMetric: acc=0.8188157894736842, hinge=1.221991988734195, ce=6.125846247422068
Local test acc @ epoch 13: 0.8188
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.6253133416175842
Local loss @ local epoch 1: 0.33761560916900635
Local loss @ local epoch 2: 0.26915591955184937
Local loss @ local epoch 3: 0.2774766683578491
Local loss @ local epoch 4: 0.17349284887313843
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.28 seconds!
[tester] 
AGNewsMetric: acc=0.8457894736842105, hinge=1.0610350904966654, ce=4.802000180294639
Local test acc @ epoch 13: 0.8458
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.14170458912849426
Local loss @ local epoch 1: 0.21263112127780914
Local loss @ local epoch 2: 0.20781821012496948
Local loss @ local epoch 3: 0.20054323971271515
Local loss @ local epoch 4: 0.3663172721862793
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.04 seconds!
[tester] 
AGNewsMetric: acc=0.8486842105263158, hinge=1.030793985567595, ce=6.446423794595819
Local test acc @ epoch 13: 0.8487
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.5589211583137512
Local loss @ local epoch 1: 0.45640820264816284
Local loss @ local epoch 2: 0.4156486988067627
Local loss @ local epoch 3: 0.29051530361175537
Local loss @ local epoch 4: 0.3902536928653717
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.22 seconds!
[tester] 
AGNewsMetric: acc=0.8155263157894737, hinge=1.1973768073634097, ce=7.529446307734439
Local test acc @ epoch 13: 0.8155
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.5813227295875549
Local loss @ local epoch 1: 0.8746970891952515
Local loss @ local epoch 2: 0.6808907389640808
Local loss @ local epoch 3: 0.7294198870658875
Local loss @ local epoch 4: 0.5804690718650818
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.04 seconds!
[tester] 
AGNewsMetric: acc=0.8410526315789474, hinge=1.1593211821505898, ce=5.708341536270945
Local test acc @ epoch 13: 0.8411
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.384573757648468
Local loss @ local epoch 1: 0.27960720658302307
Local loss @ local epoch 2: 0.2989296317100525
Local loss @ local epoch 3: 2.1816956996917725
Local loss @ local epoch 4: 2.196293830871582
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.59 seconds!
[tester] 
AGNewsMetric: acc=0.2525, hinge=6.142843867854068, ce=10.147657587151778
Local test acc @ epoch 13: 0.2525
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.2136516571044922
Local loss @ local epoch 1: 0.11257155984640121
Local loss @ local epoch 2: 0.17378661036491394
Local loss @ local epoch 3: 0.10307326912879944
Local loss @ local epoch 4: 0.09934621304273605
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.09 seconds!
[tester] 
AGNewsMetric: acc=0.8375, hinge=1.1477878854149266, ce=7.392554600364283
Local test acc @ epoch 13: 0.8375
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.4081163704395294
Local loss @ local epoch 1: 0.21935242414474487
Local loss @ local epoch 2: 0.2902739644050598
Local loss @ local epoch 3: 0.31480854749679565
Local loss @ local epoch 4: 0.29120129346847534
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.09 seconds!
[tester] 
AGNewsMetric: acc=0.8411842105263158, hinge=1.02884007654692, ce=6.4808127302872505
Local test acc @ epoch 13: 0.8412
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.36926543712615967
Local loss @ local epoch 1: 0.5294923186302185
Local loss @ local epoch 2: 0.4453910291194916
Local loss @ local epoch 3: 0.7285764217376709
Local loss @ local epoch 4: 0.3557054400444031
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.94 seconds!
[tester] 
AGNewsMetric: acc=0.8019736842105263, hinge=1.2705571340259754, ce=6.80055114645707
Local test acc @ epoch 13: 0.802
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.7720688581466675
Local loss @ local epoch 1: 0.525173008441925
Local loss @ local epoch 2: 0.7818307876586914
Local loss @ local epoch 3: 0.8969789147377014
Local loss @ local epoch 4: 0.9028207063674927
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.99 seconds!
[tester] 
AGNewsMetric: acc=0.7890789473684211, hinge=1.311857547258076, ce=7.146588812376324
Local test acc @ epoch 13: 0.7891
Global evaluate on test data...
Evaluate data in 129.38 seconds!
[tester] 
AGNewsMetric: acc=0.8739473684210526, hinge=0.8481208791230854, ce=5.774711039693732
Global test acc @ epoch 13: 0.8739
Global epoch 14...
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.37923917174339294
Local loss @ local epoch 1: 0.34143105149269104
Local loss @ local epoch 2: 0.2584032416343689
Local loss @ local epoch 3: 0.4959595799446106
Local loss @ local epoch 4: 0.44947338104248047
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.35 seconds!
[tester] 
AGNewsMetric: acc=0.8594736842105263, hinge=0.9072543204458137, ce=7.598428278471294
Local test acc @ epoch 14: 0.8595
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.2471604198217392
Local loss @ local epoch 1: 0.2962793707847595
Local loss @ local epoch 2: 0.26861271262168884
Local loss @ local epoch 3: 0.2007763683795929
Local loss @ local epoch 4: 0.2274210900068283
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.15 seconds!
[tester] 
AGNewsMetric: acc=0.8219736842105263, hinge=1.155116504869963, ce=7.353980374587209
Local test acc @ epoch 14: 0.822
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.7770692706108093
Local loss @ local epoch 1: 0.6115114688873291
Local loss @ local epoch 2: 0.7804101705551147
Local loss @ local epoch 3: 0.531216025352478
Local loss @ local epoch 4: 0.6494359374046326
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.89 seconds!
[tester] 
AGNewsMetric: acc=0.6835526315789474, hinge=2.2064441871643066, ce=5.795683904948987
Local test acc @ epoch 14: 0.6836
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.2605578899383545
Local loss @ local epoch 1: 0.10453388839960098
Local loss @ local epoch 2: 0.17326119542121887
Local loss @ local epoch 3: 0.35721465945243835
Local loss @ local epoch 4: 0.3215638995170593
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.99 seconds!
[tester] 
AGNewsMetric: acc=0.854078947368421, hinge=0.9770094738508526, ce=5.2889206575092516
Local test acc @ epoch 14: 0.8541
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.4355771541595459
Local loss @ local epoch 1: 0.5412582755088806
Local loss @ local epoch 2: 0.5135529637336731
Local loss @ local epoch 3: 0.40744784474372864
Local loss @ local epoch 4: 0.28436708450317383
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.78 seconds!
[tester] 
AGNewsMetric: acc=0.8313157894736842, hinge=1.0749158595737658, ce=7.56533661691766
Local test acc @ epoch 14: 0.8313
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.3472590744495392
Local loss @ local epoch 1: 0.4220898747444153
Local loss @ local epoch 2: 0.3417780101299286
Local loss @ local epoch 3: 0.4001712501049042
Local loss @ local epoch 4: 0.4020737111568451
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.45 seconds!
[tester] 
AGNewsMetric: acc=0.7906578947368421, hinge=1.2761578374159963, ce=7.2863970666182665
Local test acc @ epoch 14: 0.7907
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.5472390055656433
Local loss @ local epoch 1: 0.6516025066375732
Local loss @ local epoch 2: 0.683243989944458
Local loss @ local epoch 3: 0.44698768854141235
Local loss @ local epoch 4: 0.9770808815956116
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.61 seconds!
[tester] 
AGNewsMetric: acc=0.8509210526315789, hinge=1.045599782341405, ce=5.643957371962698
Local test acc @ epoch 14: 0.8509
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.3530556559562683
Local loss @ local epoch 1: 0.2927817106246948
Local loss @ local epoch 2: 0.3407782316207886
Local loss @ local epoch 3: 0.47302424907684326
Local loss @ local epoch 4: 0.41924354434013367
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.25 seconds!
[tester] 
AGNewsMetric: acc=0.8268421052631579, hinge=1.0712229357267682, ce=8.866497517635947
Local test acc @ epoch 14: 0.8268
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.2714546322822571
Local loss @ local epoch 1: 0.24836957454681396
Local loss @ local epoch 2: 0.23875901103019714
Local loss @ local epoch 3: 0.21360048651695251
Local loss @ local epoch 4: 0.18232670426368713
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.39 seconds!
[tester] 
AGNewsMetric: acc=0.8510526315789474, hinge=1.0477012047014738, ce=6.009253848226447
Local test acc @ epoch 14: 0.8511
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.8344554305076599
Local loss @ local epoch 1: 0.7667494416236877
Local loss @ local epoch 2: 0.7960242629051208
Local loss @ local epoch 3: 0.8145952820777893
Local loss @ local epoch 4: 0.9723275303840637
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.27 seconds!
[tester] 
AGNewsMetric: acc=0.7847368421052632, hinge=1.450366745497051, ce=6.702292306799638
Local test acc @ epoch 14: 0.7847
Global evaluate on test data...
Evaluate data in 129.95 seconds!
[tester] 
AGNewsMetric: acc=0.8575, hinge=0.86359315169485, ce=8.05621163619192
Global test acc @ epoch 14: 0.8575
Global epoch 15...
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.5932314991950989
Local loss @ local epoch 1: 0.3058966398239136
Local loss @ local epoch 2: 0.45573049783706665
Local loss @ local epoch 3: 0.34242886304855347
Local loss @ local epoch 4: 0.4369659721851349
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.9 seconds!
[tester] 
AGNewsMetric: acc=0.848421052631579, hinge=1.011874394667776, ce=5.963365010713276
Local test acc @ epoch 15: 0.8484
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.3645261228084564
Local loss @ local epoch 1: 0.408699095249176
Local loss @ local epoch 2: 0.44959044456481934
Local loss @ local epoch 3: 0.44069159030914307
Local loss @ local epoch 4: 0.3379386365413666
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.02 seconds!
[tester] 
AGNewsMetric: acc=0.8151315789473684, hinge=1.156067401986373, ce=5.680919735557155
Local test acc @ epoch 15: 0.8151
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.48145297169685364
Local loss @ local epoch 1: 0.3619425892829895
Local loss @ local epoch 2: 0.5832528471946716
Local loss @ local epoch 3: 0.5815925002098083
Local loss @ local epoch 4: 0.5132163166999817
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.66 seconds!
[tester] 
AGNewsMetric: acc=0.6711842105263158, hinge=1.8721724976991352, ce=6.86044458489669
Local test acc @ epoch 15: 0.6712
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.3262869715690613
Local loss @ local epoch 1: 0.9557040929794312
Local loss @ local epoch 2: 0.26976582407951355
Local loss @ local epoch 3: 0.3396734893321991
Local loss @ local epoch 4: 0.3125622570514679
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.9 seconds!
[tester] 
AGNewsMetric: acc=0.8519736842105263, hinge=1.0009131200690018, ce=6.553604739339728
Local test acc @ epoch 15: 0.852
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.25833019614219666
Local loss @ local epoch 1: 0.17625692486763
Local loss @ local epoch 2: 0.11138078570365906
Local loss @ local epoch 3: 0.10048169642686844
Local loss @ local epoch 4: 0.22845181822776794
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.85 seconds!
[tester] 
AGNewsMetric: acc=0.6376315789473684, hinge=3.131709182638871, ce=8.900360085336786
Local test acc @ epoch 15: 0.6376
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.5471432209014893
Local loss @ local epoch 1: 0.4225756525993347
Local loss @ local epoch 2: 0.85774827003479
Local loss @ local epoch 3: 0.522149920463562
Local loss @ local epoch 4: 0.5032705664634705
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 128.95 seconds!
[tester] 
AGNewsMetric: acc=0.526578947368421, hinge=3.5327354466287715, ce=9.627543477510152
Local test acc @ epoch 15: 0.5266
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.8425546288490295
Local loss @ local epoch 1: 0.9342200756072998
Local loss @ local epoch 2: 0.8380714654922485
Local loss @ local epoch 3: 0.7054738402366638
Local loss @ local epoch 4: 0.7737699747085571
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.54 seconds!
[tester] 
AGNewsMetric: acc=0.8164473684210526, hinge=1.2922449618891665, ce=7.29145334444548
Local test acc @ epoch 15: 0.8164
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.3899751901626587
Local loss @ local epoch 1: 0.42107486724853516
Local loss @ local epoch 2: 0.3681180775165558
Local loss @ local epoch 3: 0.33654919266700745
Local loss @ local epoch 4: 0.4912743866443634
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 128.84 seconds!
[tester] 
AGNewsMetric: acc=0.8186842105263158, hinge=1.1240693428641872, ce=9.093492618360017
Local test acc @ epoch 15: 0.8187
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.211204394698143
Local loss @ local epoch 1: 0.20832189917564392
Local loss @ local epoch 2: 0.1389857679605484
Local loss @ local epoch 3: 0.4191892743110657
Local loss @ local epoch 4: 0.1767134815454483
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.41 seconds!
[tester] 
AGNewsMetric: acc=0.8553947368421052, hinge=1.050430871561954, ce=5.214053328664679
Local test acc @ epoch 15: 0.8554
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.6332244277000427
Local loss @ local epoch 1: 0.44810950756073
Local loss @ local epoch 2: 0.4361094534397125
Local loss @ local epoch 3: 0.5457260608673096
Local loss @ local epoch 4: 0.5287132859230042
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.94 seconds!
[tester] 
AGNewsMetric: acc=0.8369736842105263, hinge=0.9765158969477603, ce=5.992908765893233
Local test acc @ epoch 15: 0.837
Global evaluate on test data...
Evaluate data in 130.05 seconds!
[tester] 
AGNewsMetric: acc=0.8601315789473685, hinge=0.864652190459402, ce=6.60642184608861
Global test acc @ epoch 15: 0.8601
Global epoch 16...
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.24814175069332123
Local loss @ local epoch 1: 0.23968051373958588
Local loss @ local epoch 2: 0.2087312787771225
Local loss @ local epoch 3: 0.23614390194416046
Local loss @ local epoch 4: 0.19240593910217285
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.11 seconds!
[tester] 
AGNewsMetric: acc=0.8498684210526316, hinge=1.0162077376717016, ce=5.726382236480713
Local test acc @ epoch 16: 0.8499
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.7905929088592529
Local loss @ local epoch 1: 0.7852669954299927
Local loss @ local epoch 2: 0.714045524597168
Local loss @ local epoch 3: 1.3196016550064087
Local loss @ local epoch 4: 1.077196478843689
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.43 seconds!
[tester] 
AGNewsMetric: acc=0.8096052631578947, hinge=1.225427323391563, ce=7.8372597242656505
Local test acc @ epoch 16: 0.8096
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.1181628629565239
Local loss @ local epoch 1: 0.1733940839767456
Local loss @ local epoch 2: 0.22760795056819916
Local loss @ local epoch 3: 0.8815232515335083
Local loss @ local epoch 4: 1.0300952196121216
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.23 seconds!
[tester] 
AGNewsMetric: acc=0.7065789473684211, hinge=2.2061677541230855, ce=8.649054436934621
Local test acc @ epoch 16: 0.7066
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.6856990456581116
Local loss @ local epoch 1: 0.45530176162719727
Local loss @ local epoch 2: 0.4250747859477997
Local loss @ local epoch 3: 0.33205729722976685
Local loss @ local epoch 4: 0.5654181838035583
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.44 seconds!
[tester] 
AGNewsMetric: acc=0.8497368421052631, hinge=0.9724302803842645, ce=5.911393557096782
Local test acc @ epoch 16: 0.8497
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.3885955810546875
Local loss @ local epoch 1: 0.24198606610298157
Local loss @ local epoch 2: 0.3202267289161682
Local loss @ local epoch 3: 0.29849427938461304
Local loss @ local epoch 4: 0.12183970212936401
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.64 seconds!
[tester] 
AGNewsMetric: acc=0.8313157894736842, hinge=1.0582808173330207, ce=8.377098591453151
Local test acc @ epoch 16: 0.8313
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.5052022337913513
Local loss @ local epoch 1: 0.3679542541503906
Local loss @ local epoch 2: 0.44239017367362976
Local loss @ local epoch 3: 0.48362284898757935
Local loss @ local epoch 4: 0.6594215035438538
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.6 seconds!
[tester] 
AGNewsMetric: acc=0.7903947368421053, hinge=1.4965799572593288, ce=6.885866877907201
Local test acc @ epoch 16: 0.7904
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.5478790402412415
Local loss @ local epoch 1: 0.3424162268638611
Local loss @ local epoch 2: 0.6079913973808289
Local loss @ local epoch 3: 0.5149522423744202
Local loss @ local epoch 4: 0.356106162071228
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.31 seconds!
[tester] 
AGNewsMetric: acc=0.8425, hinge=1.111919466319837, ce=5.595635567715293
Local test acc @ epoch 16: 0.8425
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.3822903037071228
Local loss @ local epoch 1: 0.33688122034072876
Local loss @ local epoch 2: 0.30439579486846924
Local loss @ local epoch 3: 0.5189484357833862
Local loss @ local epoch 4: 0.42373737692832947
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.28 seconds!
[tester] 
AGNewsMetric: acc=0.8322368421052632, hinge=1.0939411805805408, ce=6.88203004033942
Local test acc @ epoch 16: 0.8322
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.31087589263916016
Local loss @ local epoch 1: 0.5489314198493958
Local loss @ local epoch 2: 0.34687066078186035
Local loss @ local epoch 3: 0.26879382133483887
Local loss @ local epoch 4: 0.3806712031364441
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.54 seconds!
[tester] 
AGNewsMetric: acc=0.8309210526315789, hinge=1.070928608743768, ce=8.108498225964999
Local test acc @ epoch 16: 0.8309
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.4241724908351898
Local loss @ local epoch 1: 0.38029995560646057
Local loss @ local epoch 2: 0.24896377325057983
Local loss @ local epoch 3: 0.2897093594074249
Local loss @ local epoch 4: 0.45715275406837463
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.92 seconds!
[tester] 
AGNewsMetric: acc=0.795921052631579, hinge=1.225557928587261, ce=8.29822554337351
Local test acc @ epoch 16: 0.7959
Global evaluate on test data...
Evaluate data in 129.87 seconds!
[tester] 
AGNewsMetric: acc=0.8614473684210526, hinge=0.8493021056526585, ce=8.429335909391705
Global test acc @ epoch 16: 0.8614
Global epoch 17...
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.2231670320034027
Local loss @ local epoch 1: 0.17826515436172485
Local loss @ local epoch 2: 0.28435951471328735
Local loss @ local epoch 3: 0.23215582966804504
Local loss @ local epoch 4: 0.19477230310440063
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.62 seconds!
[tester] 
AGNewsMetric: acc=0.8038157894736843, hinge=1.512604745563708, ce=6.756863380231356
Local test acc @ epoch 17: 0.8038
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.5523800849914551
Local loss @ local epoch 1: 0.2756074368953705
Local loss @ local epoch 2: 0.42016565799713135
Local loss @ local epoch 3: 0.5749421119689941
Local loss @ local epoch 4: 0.41707539558410645
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.53 seconds!
[tester] 
AGNewsMetric: acc=0.8184210526315789, hinge=1.1328535933243602, ce=6.216328256506669
Local test acc @ epoch 17: 0.8184
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.6952813863754272
Local loss @ local epoch 1: 0.80208420753479
Local loss @ local epoch 2: 0.6500471830368042
Local loss @ local epoch 3: 0.5385945439338684
Local loss @ local epoch 4: 0.6503404974937439
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.24 seconds!
[tester] 
AGNewsMetric: acc=0.8348684210526316, hinge=1.008113977030704, ce=9.028089131807025
Local test acc @ epoch 17: 0.8349
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.5549562573432922
Local loss @ local epoch 1: 0.44587773084640503
Local loss @ local epoch 2: 0.76669842004776
Local loss @ local epoch 3: 0.7976715564727783
Local loss @ local epoch 4: 0.5745033621788025
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.45 seconds!
[tester] 
AGNewsMetric: acc=0.8039473684210526, hinge=1.346695341311003, ce=7.169648216649105
Local test acc @ epoch 17: 0.8039
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.6426853537559509
Local loss @ local epoch 1: 0.34551429748535156
Local loss @ local epoch 2: 0.25021564960479736
Local loss @ local epoch 3: 0.21868860721588135
Local loss @ local epoch 4: 0.9687370657920837
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.56 seconds!
[tester] 
AGNewsMetric: acc=0.7971052631578948, hinge=1.496334622031764, ce=7.983951879802503
Local test acc @ epoch 17: 0.7971
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.5789534449577332
Local loss @ local epoch 1: 0.6268933415412903
Local loss @ local epoch 2: 0.38160082697868347
Local loss @ local epoch 3: 0.38663461804389954
Local loss @ local epoch 4: 0.4775981903076172
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.56 seconds!
[tester] 
AGNewsMetric: acc=0.8476315789473684, hinge=1.0448511736016524, ce=5.203377393421374
Local test acc @ epoch 17: 0.8476
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.21502578258514404
Local loss @ local epoch 1: 0.10223102569580078
Local loss @ local epoch 2: 0.09609229862689972
Local loss @ local epoch 3: 0.17393803596496582
Local loss @ local epoch 4: 0.17706990242004395
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.16 seconds!
[tester] 
AGNewsMetric: acc=0.8606578947368421, hinge=0.9069283103942871, ce=5.257087126280132
Local test acc @ epoch 17: 0.8607
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.5751950740814209
Local loss @ local epoch 1: 0.30108293890953064
Local loss @ local epoch 2: 0.276690810918808
Local loss @ local epoch 3: 0.22050708532333374
Local loss @ local epoch 4: 0.6657004952430725
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.92 seconds!
[tester] 
AGNewsMetric: acc=0.84, hinge=1.139285541835584, ce=5.283379742471795
Local test acc @ epoch 17: 0.84
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.2315986603498459
Local loss @ local epoch 1: 0.325690358877182
Local loss @ local epoch 2: 0.34027785062789917
Local loss @ local epoch 3: 0.33642444014549255
Local loss @ local epoch 4: 0.3473789095878601
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 128.99 seconds!
[tester] 
AGNewsMetric: acc=0.6843421052631579, hinge=2.465277297873246, ce=7.158282631321957
Local test acc @ epoch 17: 0.6843
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.48170262575149536
Local loss @ local epoch 1: 0.17544886469841003
Local loss @ local epoch 2: 0.25501760840415955
Local loss @ local epoch 3: 0.23966185748577118
Local loss @ local epoch 4: 0.27047738432884216
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.37 seconds!
[tester] 
AGNewsMetric: acc=0.8523684210526316, hinge=0.9451623374537418, ce=10.018292031539113
Local test acc @ epoch 17: 0.8524
Global evaluate on test data...
Evaluate data in 130.24 seconds!
[tester] 
AGNewsMetric: acc=0.8647368421052631, hinge=0.8668377168555009, ce=7.524233099284925
Global test acc @ epoch 17: 0.8647
Global epoch 18...
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.5927382111549377
Local loss @ local epoch 1: 0.5484955906867981
Local loss @ local epoch 2: 0.43975237011909485
Local loss @ local epoch 3: 0.7858361601829529
Local loss @ local epoch 4: 0.6547303199768066
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.97 seconds!
[tester] 
AGNewsMetric: acc=0.7661842105263158, hinge=1.6076731159812525, ce=5.938087660136976
Local test acc @ epoch 18: 0.7662
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.7481744885444641
Local loss @ local epoch 1: 0.42606300115585327
Local loss @ local epoch 2: 0.4600248336791992
Local loss @ local epoch 3: 0.49568405747413635
Local loss @ local epoch 4: 0.6522836089134216
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.97 seconds!
[tester] 
AGNewsMetric: acc=0.7711842105263158, hinge=1.386805816449617, ce=8.083571128845215
Local test acc @ epoch 18: 0.7712
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.1274828314781189
Local loss @ local epoch 1: 0.15050660073757172
Local loss @ local epoch 2: 0.17475028336048126
Local loss @ local epoch 3: 0.15158599615097046
Local loss @ local epoch 4: 0.3136614263057709
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.29 seconds!
[tester] 
AGNewsMetric: acc=0.8572368421052632, hinge=0.9125930023193359, ce=6.851400983710038
Local test acc @ epoch 18: 0.8572
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.7589374780654907
Local loss @ local epoch 1: 0.8003443479537964
Local loss @ local epoch 2: 0.8055394887924194
Local loss @ local epoch 3: 0.8190197944641113
Local loss @ local epoch 4: 0.6433709859848022
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.48 seconds!
[tester] 
AGNewsMetric: acc=0.8373684210526315, hinge=0.9949223663932398, ce=8.079077977632222
Local test acc @ epoch 18: 0.8374
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.334608256816864
Local loss @ local epoch 1: 0.18785296380519867
Local loss @ local epoch 2: 0.24667911231517792
Local loss @ local epoch 3: 0.11250527203083038
Local loss @ local epoch 4: 0.14019550383090973
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.19 seconds!
[tester] 
AGNewsMetric: acc=0.8606578947368421, hinge=0.868524832223591, ce=6.160267957386218
Local test acc @ epoch 18: 0.8607
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.5185220837593079
Local loss @ local epoch 1: 0.5084301829338074
Local loss @ local epoch 2: 0.5170769095420837
Local loss @ local epoch 3: 0.38357460498809814
Local loss @ local epoch 4: 0.5562502145767212
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.42 seconds!
[tester] 
AGNewsMetric: acc=0.8260526315789474, hinge=1.2034778625086735, ce=7.244519693475021
Local test acc @ epoch 18: 0.8261
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.2289808690547943
Local loss @ local epoch 1: 0.26197877526283264
Local loss @ local epoch 2: 0.15522661805152893
Local loss @ local epoch 3: 0.28061413764953613
Local loss @ local epoch 4: 0.3304422199726105
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.75 seconds!
[tester] 
AGNewsMetric: acc=0.8507894736842105, hinge=1.1069965809269955, ce=7.100951034144352
Local test acc @ epoch 18: 0.8508
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.45772385597229004
Local loss @ local epoch 1: 0.30883580446243286
Local loss @ local epoch 2: 0.2817304730415344
Local loss @ local epoch 3: 0.24848629534244537
Local loss @ local epoch 4: 0.13598841428756714
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.88 seconds!
[tester] 
AGNewsMetric: acc=0.8531578947368421, hinge=0.9688950538635254, ce=7.636334411219547
Local test acc @ epoch 18: 0.8532
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.39336055517196655
Local loss @ local epoch 1: 0.31820836663246155
Local loss @ local epoch 2: 0.30724236369132996
Local loss @ local epoch 3: 0.24573248624801636
Local loss @ local epoch 4: 0.17921069264411926
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.66 seconds!
[tester] 
AGNewsMetric: acc=0.8498684210526316, hinge=0.9829221123143246, ce=8.00759324927079
Local test acc @ epoch 18: 0.8499
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.3049331605434418
Local loss @ local epoch 1: 0.7470785975456238
Local loss @ local epoch 2: 0.3966357707977295
Local loss @ local epoch 3: 0.43469682335853577
Local loss @ local epoch 4: 0.5515571236610413
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.69 seconds!
[tester] 
AGNewsMetric: acc=0.8322368421052632, hinge=1.0553302413538883, ce=4.2716387547944725
Local test acc @ epoch 18: 0.8322
Global evaluate on test data...
Evaluate data in 129.88 seconds!
[tester] 
AGNewsMetric: acc=0.8661842105263158, hinge=0.8456332824104711, ce=7.949746449119166
Global test acc @ epoch 18: 0.8662
Global epoch 19...
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.5172612071037292
Local loss @ local epoch 1: 0.573566734790802
Local loss @ local epoch 2: 0.40296754240989685
Local loss @ local epoch 3: 0.3718075454235077
Local loss @ local epoch 4: 0.3310396075248718
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.14 seconds!
[tester] 
AGNewsMetric: acc=0.8251315789473684, hinge=1.0798805066158896, ce=5.952393233650609
Local test acc @ epoch 19: 0.8251
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.3473905026912689
Local loss @ local epoch 1: 0.35311397910118103
Local loss @ local epoch 2: 0.1651538610458374
Local loss @ local epoch 3: 0.10582511872053146
Local loss @ local epoch 4: 0.2217465043067932
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.9 seconds!
[tester] 
AGNewsMetric: acc=0.8157894736842105, hinge=1.2803377487784937, ce=7.724453628941586
Local test acc @ epoch 19: 0.8158
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.3169465959072113
Local loss @ local epoch 1: 0.18265216052532196
Local loss @ local epoch 2: 0.3120141923427582
Local loss @ local epoch 3: 0.3155367076396942
Local loss @ local epoch 4: 0.2544979453086853
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 128.33 seconds!
[tester] 
AGNewsMetric: acc=0.8042105263157895, hinge=1.365167569110268, ce=10.453760636982166
Local test acc @ epoch 19: 0.8042
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.15874497592449188
Local loss @ local epoch 1: 0.10675499588251114
Local loss @ local epoch 2: 1.6665997505187988
Local loss @ local epoch 3: 0.1619912087917328
Local loss @ local epoch 4: 0.3518839180469513
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.08 seconds!
[tester] 
AGNewsMetric: acc=0.2893421052631579, hinge=5.900612527947676, ce=18.324433168110094
Local test acc @ epoch 19: 0.2893
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.5637251138687134
Local loss @ local epoch 1: 0.4020014703273773
Local loss @ local epoch 2: 0.4934057593345642
Local loss @ local epoch 3: 0.4006274938583374
Local loss @ local epoch 4: 0.38975656032562256
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.6 seconds!
[tester] 
AGNewsMetric: acc=0.8497368421052631, hinge=0.9927230865076968, ce=5.955395578083239
Local test acc @ epoch 19: 0.8497
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.14624914526939392
Local loss @ local epoch 1: 0.25215888023376465
Local loss @ local epoch 2: 0.12234846502542496
Local loss @ local epoch 3: 0.16411936283111572
Local loss @ local epoch 4: 0.09694927930831909
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.01 seconds!
[tester] 
AGNewsMetric: acc=0.8373684210526315, hinge=1.1931363572572407, ce=7.731481654518529
Local test acc @ epoch 19: 0.8374
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.2912021279335022
Local loss @ local epoch 1: 0.22388334572315216
Local loss @ local epoch 2: 0.16978541016578674
Local loss @ local epoch 3: 0.1477736085653305
Local loss @ local epoch 4: 0.18770654499530792
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.44 seconds!
[tester] 
AGNewsMetric: acc=0.8219736842105263, hinge=1.3051821924510756, ce=5.994020809374358
Local test acc @ epoch 19: 0.822
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.7109836339950562
Local loss @ local epoch 1: 0.7957730293273926
Local loss @ local epoch 2: 0.8320061564445496
Local loss @ local epoch 3: 0.9565083384513855
Local loss @ local epoch 4: 0.6316832900047302
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.15 seconds!
[tester] 
AGNewsMetric: acc=0.829078947368421, hinge=1.289573292481272, ce=6.680424841830605
Local test acc @ epoch 19: 0.8291
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.6204724907875061
Local loss @ local epoch 1: 0.45748767256736755
Local loss @ local epoch 2: 0.4054233729839325
Local loss @ local epoch 3: 0.33651024103164673
Local loss @ local epoch 4: 0.4644298255443573
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.31 seconds!
[tester] 
AGNewsMetric: acc=0.8306578947368422, hinge=1.1041078396847372, ce=7.950176265114232
Local test acc @ epoch 19: 0.8307
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.8023556470870972
Local loss @ local epoch 1: 0.3710630238056183
Local loss @ local epoch 2: 0.44656461477279663
Local loss @ local epoch 3: 0.6446927785873413
Local loss @ local epoch 4: 0.5995224118232727
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.78 seconds!
[tester] 
AGNewsMetric: acc=0.3798684210526316, hinge=6.158418978640908, ce=7.375859917088559
Local test acc @ epoch 19: 0.3799
Global evaluate on test data...
Evaluate data in 131.43 seconds!
[tester] 
AGNewsMetric: acc=0.861578947368421, hinge=0.8401154297276547, ce=7.68377924868935
Global test acc @ epoch 19: 0.8616
Global epoch 20...
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.22917720675468445
Local loss @ local epoch 1: 0.27795013785362244
Local loss @ local epoch 2: 0.1869707554578781
Local loss @ local epoch 3: 0.3579859137535095
Local loss @ local epoch 4: 1.430216908454895
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.27 seconds!
[tester] 
AGNewsMetric: acc=0.7767105263157895, hinge=1.586115080180921, ce=5.134319002251876
Local test acc @ epoch 20: 0.7767
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.30131280422210693
Local loss @ local epoch 1: 0.05528152361512184
Local loss @ local epoch 2: 0.19607461988925934
Local loss @ local epoch 3: 0.2395060658454895
Local loss @ local epoch 4: 0.12126953899860382
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.53 seconds!
[tester] 
AGNewsMetric: acc=0.8443421052631579, hinge=1.0635347928498922, ce=7.049348673569528
Local test acc @ epoch 20: 0.8443
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.40600138902664185
Local loss @ local epoch 1: 0.22031909227371216
Local loss @ local epoch 2: 0.8561562299728394
Local loss @ local epoch 3: 0.39211735129356384
Local loss @ local epoch 4: 0.3386756181716919
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.67 seconds!
[tester] 
AGNewsMetric: acc=0.8431578947368421, hinge=0.9839911706824052, ce=5.7670010195280375
Local test acc @ epoch 20: 0.8432
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.7570695877075195
Local loss @ local epoch 1: 0.4407649636268616
Local loss @ local epoch 2: 0.5429204106330872
Local loss @ local epoch 3: 0.36574846506118774
Local loss @ local epoch 4: 0.5021889805793762
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.94 seconds!
[tester] 
AGNewsMetric: acc=0.8022368421052631, hinge=1.192966274964182, ce=6.305912967481111
Local test acc @ epoch 20: 0.8022
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.36095598340034485
Local loss @ local epoch 1: 0.49943217635154724
Local loss @ local epoch 2: 0.4927424192428589
Local loss @ local epoch 3: 0.30081722140312195
Local loss @ local epoch 4: 0.33715158700942993
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.54 seconds!
[tester] 
AGNewsMetric: acc=0.8210526315789474, hinge=1.095114460493389, ce=7.225602226257324
Local test acc @ epoch 20: 0.8211
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.7996979355812073
Local loss @ local epoch 1: 0.6789158582687378
Local loss @ local epoch 2: 0.6817600727081299
Local loss @ local epoch 3: 0.5950777530670166
Local loss @ local epoch 4: 0.7895545959472656
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.27 seconds!
[tester] 
AGNewsMetric: acc=0.84, hinge=1.0018694862566495, ce=8.468610378064607
Local test acc @ epoch 20: 0.84
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.3342789113521576
Local loss @ local epoch 1: 0.3084723651409149
Local loss @ local epoch 2: 0.36636194586753845
Local loss @ local epoch 3: 0.5857861042022705
Local loss @ local epoch 4: 0.36576607823371887
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.45 seconds!
[tester] 
AGNewsMetric: acc=0.8296052631578947, hinge=1.124482529288844, ce=5.485741323169909
Local test acc @ epoch 20: 0.8296
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.49230116605758667
Local loss @ local epoch 1: 0.3129516541957855
Local loss @ local epoch 2: 0.21021553874015808
Local loss @ local epoch 3: 0.44851154088974
Local loss @ local epoch 4: 0.29757431149482727
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.28 seconds!
[tester] 
AGNewsMetric: acc=0.7856578947368421, hinge=1.4575149280146549, ce=8.04752000306782
Local test acc @ epoch 20: 0.7857
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.4088241159915924
Local loss @ local epoch 1: 0.19816076755523682
Local loss @ local epoch 2: 0.3016095757484436
Local loss @ local epoch 3: 0.3118066191673279
Local loss @ local epoch 4: 0.12811440229415894
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.92 seconds!
[tester] 
AGNewsMetric: acc=0.7897368421052632, hinge=1.3432094413355777, ce=7.685001845108835
Local test acc @ epoch 20: 0.7897
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.15338192880153656
Local loss @ local epoch 1: 0.17858515679836273
Local loss @ local epoch 2: 0.16143082082271576
Local loss @ local epoch 3: 0.09719214588403702
Local loss @ local epoch 4: 0.11415461450815201
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.25 seconds!
[tester] 
AGNewsMetric: acc=0.8525, hinge=1.008422632719341, ce=4.739358201277883
Local test acc @ epoch 20: 0.8525
Global evaluate on test data...
Evaluate data in 131.29 seconds!
[tester] 
AGNewsMetric: acc=0.8696052631578948, hinge=0.8396776174244128, ce=6.768825141505191
Global test acc @ epoch 20: 0.8696
Global epoch 21...
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.17580877244472504
Local loss @ local epoch 1: 0.35542505979537964
Local loss @ local epoch 2: 0.31417497992515564
Local loss @ local epoch 3: 0.17264093458652496
Local loss @ local epoch 4: 0.16808336973190308
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.8 seconds!
[tester] 
AGNewsMetric: acc=0.8556578947368421, hinge=0.9338597915047093, ce=4.840498140234696
Local test acc @ epoch 21: 0.8557
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.3225341737270355
Local loss @ local epoch 1: 0.3600461483001709
Local loss @ local epoch 2: 0.6136232018470764
Local loss @ local epoch 3: 0.440246045589447
Local loss @ local epoch 4: 0.45282143354415894
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.39 seconds!
[tester] 
AGNewsMetric: acc=0.8526315789473684, hinge=1.0411166748247649, ce=7.938894583049573
Local test acc @ epoch 21: 0.8526
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.36293649673461914
Local loss @ local epoch 1: 0.4584047198295593
Local loss @ local epoch 2: 0.25467297434806824
Local loss @ local epoch 3: 0.38508129119873047
Local loss @ local epoch 4: 0.2377106249332428
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.28 seconds!
[tester] 
AGNewsMetric: acc=0.7951315789473684, hinge=1.2651745229018363, ce=6.9248776737012365
Local test acc @ epoch 21: 0.7951
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 1.0568450689315796
Local loss @ local epoch 1: 0.8285308480262756
Local loss @ local epoch 2: 0.6697335243225098
Local loss @ local epoch 3: 0.859487771987915
Local loss @ local epoch 4: 0.610377848148346
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.59 seconds!
[tester] 
AGNewsMetric: acc=0.8173684210526316, hinge=1.172435493971172, ce=7.595600106088739
Local test acc @ epoch 21: 0.8174
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.19343911111354828
Local loss @ local epoch 1: 0.25802284479141235
Local loss @ local epoch 2: 0.25291186571121216
Local loss @ local epoch 3: 0.12126924842596054
Local loss @ local epoch 4: 0.12538546323776245
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.7 seconds!
[tester] 
AGNewsMetric: acc=0.8597368421052631, hinge=0.9395021659449527, ce=8.242388000488281
Local test acc @ epoch 21: 0.8597
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.1354687213897705
Local loss @ local epoch 1: 0.10904881358146667
Local loss @ local epoch 2: 0.14477550983428955
Local loss @ local epoch 3: 0.14943763613700867
Local loss @ local epoch 4: 0.11753208190202713
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.28 seconds!
[tester] 
AGNewsMetric: acc=0.8419736842105263, hinge=1.1715198481710334, ce=8.769894794664886
Local test acc @ epoch 21: 0.842
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.13201558589935303
Local loss @ local epoch 1: 0.12237147241830826
Local loss @ local epoch 2: 0.09530191123485565
Local loss @ local epoch 3: 0.12906406819820404
Local loss @ local epoch 4: 0.19773799180984497
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.94 seconds!
[tester] 
AGNewsMetric: acc=0.8368421052631579, hinge=1.080670495284231, ce=6.986286911211516
Local test acc @ epoch 21: 0.8368
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.4806935787200928
Local loss @ local epoch 1: 0.6148164868354797
Local loss @ local epoch 2: 0.32485949993133545
Local loss @ local epoch 3: 0.3566265404224396
Local loss @ local epoch 4: 0.44230467081069946
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.0 seconds!
[tester] 
AGNewsMetric: acc=0.8157894736842105, hinge=1.135968270050852, ce=7.272764322381271
Local test acc @ epoch 21: 0.8158
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.35152310132980347
Local loss @ local epoch 1: 0.35600900650024414
Local loss @ local epoch 2: 0.22643662989139557
Local loss @ local epoch 3: 0.2031976580619812
Local loss @ local epoch 4: 0.2769964933395386
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.22 seconds!
[tester] 
AGNewsMetric: acc=0.8463157894736842, hinge=0.9652319958335475, ce=9.564490015130295
Local test acc @ epoch 21: 0.8463
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.6418127417564392
Local loss @ local epoch 1: 0.5175265073776245
Local loss @ local epoch 2: 0.6026888489723206
Local loss @ local epoch 3: 0.563798725605011
Local loss @ local epoch 4: 0.32233572006225586
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.34 seconds!
[tester] 
AGNewsMetric: acc=0.8336842105263158, hinge=0.9942426104294626, ce=5.451912845812346
Local test acc @ epoch 21: 0.8337
Global evaluate on test data...
Evaluate data in 129.51 seconds!
[tester] 
AGNewsMetric: acc=0.8777631578947368, hinge=0.7800009526704487, ce=8.795994041844418
Global test acc @ epoch 21: 0.8778
Global epoch 22...
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.04561242088675499
Local loss @ local epoch 1: 0.11568548530340195
Local loss @ local epoch 2: 0.09629969298839569
Local loss @ local epoch 3: 0.3176474869251251
Local loss @ local epoch 4: 0.8437667489051819
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.01 seconds!
[tester] 
AGNewsMetric: acc=0.8078947368421052, hinge=1.2583378008792274, ce=7.373052516736482
Local test acc @ epoch 22: 0.8079
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.727721095085144
Local loss @ local epoch 1: 0.8027507662773132
Local loss @ local epoch 2: 0.8972105383872986
Local loss @ local epoch 3: 0.8988058567047119
Local loss @ local epoch 4: 0.6015176177024841
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.5 seconds!
[tester] 
AGNewsMetric: acc=0.845657894736842, hinge=1.027961294274581, ce=7.0088048774317695
Local test acc @ epoch 22: 0.8457
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.3254314661026001
Local loss @ local epoch 1: 0.3536534607410431
Local loss @ local epoch 2: 0.20258140563964844
Local loss @ local epoch 3: 0.4187930226325989
Local loss @ local epoch 4: 0.33917737007141113
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.23 seconds!
[tester] 
AGNewsMetric: acc=0.8452631578947368, hinge=0.9640687791924728, ce=8.543227547093442
Local test acc @ epoch 22: 0.8453
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.06680064648389816
Local loss @ local epoch 1: 0.17106550931930542
Local loss @ local epoch 2: 0.06796349585056305
Local loss @ local epoch 3: 0.23514750599861145
Local loss @ local epoch 4: 0.2535433769226074
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.24 seconds!
[tester] 
AGNewsMetric: acc=0.8186842105263158, hinge=1.2432853334828426, ce=9.61509556017424
Local test acc @ epoch 22: 0.8187
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.4658498466014862
Local loss @ local epoch 1: 0.5322520136833191
Local loss @ local epoch 2: 0.5476240515708923
Local loss @ local epoch 3: 0.41605696082115173
Local loss @ local epoch 4: 0.5691303610801697
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.49 seconds!
[tester] 
AGNewsMetric: acc=0.8011842105263158, hinge=1.2976904828924882, ce=7.0937473778975635
Local test acc @ epoch 22: 0.8012
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.4049566686153412
Local loss @ local epoch 1: 0.32996436953544617
Local loss @ local epoch 2: 0.362496554851532
Local loss @ local epoch 3: 0.3609514534473419
Local loss @ local epoch 4: 0.6062772274017334
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.28 seconds!
[tester] 
AGNewsMetric: acc=0.799078947368421, hinge=1.2613936499545448, ce=6.832081985473633
Local test acc @ epoch 22: 0.7991
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.28624865412712097
Local loss @ local epoch 1: 0.203769713640213
Local loss @ local epoch 2: 0.22024844586849213
Local loss @ local epoch 3: 0.1089177131652832
Local loss @ local epoch 4: 0.17094771564006805
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 128.96 seconds!
[tester] 
AGNewsMetric: acc=0.8423684210526315, hinge=0.9552430087641666, ce=9.082198307639674
Local test acc @ epoch 22: 0.8424
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.12058436125516891
Local loss @ local epoch 1: 0.07720862329006195
Local loss @ local epoch 2: 0.1345643252134323
Local loss @ local epoch 3: 0.16416122019290924
Local loss @ local epoch 4: 0.28544187545776367
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.29 seconds!
[tester] 
AGNewsMetric: acc=0.8202631578947368, hinge=1.2952205045599687, ce=5.830765263406854
Local test acc @ epoch 22: 0.8203
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.2841377854347229
Local loss @ local epoch 1: 0.3793289363384247
Local loss @ local epoch 2: 0.23205672204494476
Local loss @ local epoch 3: 0.493865966796875
Local loss @ local epoch 4: 0.3359878957271576
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.01 seconds!
[tester] 
AGNewsMetric: acc=0.810921052631579, hinge=1.149609973807084, ce=7.878945097672312
Local test acc @ epoch 22: 0.8109
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.5437774658203125
Local loss @ local epoch 1: 0.2975635826587677
Local loss @ local epoch 2: 0.3585180938243866
Local loss @ local epoch 3: 0.8217414617538452
Local loss @ local epoch 4: 0.4556059241294861
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.99 seconds!
[tester] 
AGNewsMetric: acc=0.8125, hinge=1.1470219275825901, ce=5.651127220956902
Local test acc @ epoch 22: 0.8125
Global evaluate on test data...
Evaluate data in 130.36 seconds!
[tester] 
AGNewsMetric: acc=0.8678947368421053, hinge=0.8133865542160837, ce=9.002766836065994
Global test acc @ epoch 22: 0.8679
Global epoch 23...
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.36596229672431946
Local loss @ local epoch 1: 0.4193992614746094
Local loss @ local epoch 2: 0.28820306062698364
Local loss @ local epoch 3: 0.2664245069026947
Local loss @ local epoch 4: 0.2587132155895233
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.87 seconds!
[tester] 
AGNewsMetric: acc=0.7880263157894737, hinge=1.2878819495753238, ce=8.594274811995657
Local test acc @ epoch 23: 0.788
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.5044534206390381
Local loss @ local epoch 1: 0.3713304400444031
Local loss @ local epoch 2: 0.32309117913246155
Local loss @ local epoch 3: 0.6339495182037354
Local loss @ local epoch 4: 0.3779855966567993
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.85 seconds!
[tester] 
AGNewsMetric: acc=0.8207894736842105, hinge=1.1598484089500025, ce=6.57190027437712
Local test acc @ epoch 23: 0.8208
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.1806265264749527
Local loss @ local epoch 1: 0.14993196725845337
Local loss @ local epoch 2: 0.235763281583786
Local loss @ local epoch 3: 0.16021625697612762
Local loss @ local epoch 4: 0.2636599838733673
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.4 seconds!
[tester] 
AGNewsMetric: acc=0.8563157894736843, hinge=0.9405933932254189, ce=5.982114394338508
Local test acc @ epoch 23: 0.8563
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.45893171429634094
Local loss @ local epoch 1: 0.3673539161682129
Local loss @ local epoch 2: 0.4398610293865204
Local loss @ local epoch 3: 0.7824959754943848
Local loss @ local epoch 4: 0.47173598408699036
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.23 seconds!
[tester] 
AGNewsMetric: acc=0.7422368421052632, hinge=1.8049761460956775, ce=7.6776141096416275
Local test acc @ epoch 23: 0.7422
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.8030094504356384
Local loss @ local epoch 1: 0.6571405529975891
Local loss @ local epoch 2: 0.7752867341041565
Local loss @ local epoch 3: 0.6209119558334351
Local loss @ local epoch 4: 0.7040730714797974
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 128.74 seconds!
[tester] 
AGNewsMetric: acc=0.824078947368421, hinge=1.1266171234532407, ce=7.799571195903577
Local test acc @ epoch 23: 0.8241
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.2550279498100281
Local loss @ local epoch 1: 0.15606634318828583
Local loss @ local epoch 2: 0.2666340470314026
Local loss @ local epoch 3: 0.2728519141674042
Local loss @ local epoch 4: 0.30166205763816833
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.77 seconds!
[tester] 
AGNewsMetric: acc=0.8206578947368421, hinge=1.0668378026861893, ce=7.317410771219354
Local test acc @ epoch 23: 0.8207
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.5650801658630371
Local loss @ local epoch 1: 0.36035996675491333
Local loss @ local epoch 2: 0.35912713408470154
Local loss @ local epoch 3: 0.5049575567245483
Local loss @ local epoch 4: 0.40986618399620056
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.36 seconds!
[tester] 
AGNewsMetric: acc=0.8014473684210527, hinge=1.1877405452728271, ce=7.644910880640934
Local test acc @ epoch 23: 0.8014
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.1863745152950287
Local loss @ local epoch 1: 0.1499689668416977
Local loss @ local epoch 2: 0.1164269745349884
Local loss @ local epoch 3: 0.11941870301961899
Local loss @ local epoch 4: 0.08262136578559875
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.25 seconds!
[tester] 
AGNewsMetric: acc=0.8226315789473684, hinge=1.2062339614567004, ce=9.2834772089908
Local test acc @ epoch 23: 0.8226
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.1280742883682251
Local loss @ local epoch 1: 0.15668900310993195
Local loss @ local epoch 2: 0.1435014307498932
Local loss @ local epoch 3: 0.15640707314014435
Local loss @ local epoch 4: 0.1886349767446518
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.07 seconds!
[tester] 
AGNewsMetric: acc=0.8635526315789473, hinge=0.9013466558958355, ce=7.073056602478028
Local test acc @ epoch 23: 0.8636
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.28992846608161926
Local loss @ local epoch 1: 0.25942546129226685
Local loss @ local epoch 2: 0.328687459230423
Local loss @ local epoch 3: 0.2809971272945404
Local loss @ local epoch 4: 0.1511860191822052
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.77 seconds!
[tester] 
AGNewsMetric: acc=0.8622368421052632, hinge=0.9435750635046708, ce=5.7584678308587325
Local test acc @ epoch 23: 0.8622
Global evaluate on test data...
Evaluate data in 129.7 seconds!
[tester] 
AGNewsMetric: acc=0.8759210526315789, hinge=0.7954881547626697, ce=8.587105144701505
Global test acc @ epoch 23: 0.8759
Global epoch 24...
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.1464633196592331
Local loss @ local epoch 1: 0.12251108884811401
Local loss @ local epoch 2: 0.17779165506362915
Local loss @ local epoch 3: 0.2578754127025604
Local loss @ local epoch 4: 0.3820796012878418
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.31 seconds!
[tester] 
AGNewsMetric: acc=0.8388157894736842, hinge=0.9769953918457032, ce=6.964654362327174
Local test acc @ epoch 24: 0.8388
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.7900695204734802
Local loss @ local epoch 1: 0.769366979598999
Local loss @ local epoch 2: 0.6778702735900879
Local loss @ local epoch 3: 0.5768845081329346
Local loss @ local epoch 4: 0.6819972395896912
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.93 seconds!
[tester] 
AGNewsMetric: acc=0.8278947368421052, hinge=1.1118559701819168, ce=8.048732430307489
Local test acc @ epoch 24: 0.8279
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.34694284200668335
Local loss @ local epoch 1: 0.4210536777973175
Local loss @ local epoch 2: 0.44819825887680054
Local loss @ local epoch 3: 0.22121259570121765
Local loss @ local epoch 4: 0.20855063199996948
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.61 seconds!
[tester] 
AGNewsMetric: acc=0.8155263157894737, hinge=1.2086356941022371, ce=8.321220741271972
Local test acc @ epoch 24: 0.8155
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.28082138299942017
Local loss @ local epoch 1: 0.44483157992362976
Local loss @ local epoch 2: 0.22744350135326385
Local loss @ local epoch 3: 0.3548917770385742
Local loss @ local epoch 4: 0.5359632968902588
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 128.84 seconds!
[tester] 
AGNewsMetric: acc=0.8610526315789474, hinge=0.953027811050415, ce=5.580887682061446
Local test acc @ epoch 24: 0.8611
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.39770448207855225
Local loss @ local epoch 1: 0.19187259674072266
Local loss @ local epoch 2: 0.277479350566864
Local loss @ local epoch 3: 0.3881193697452545
Local loss @ local epoch 4: 0.2365933507680893
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.49 seconds!
[tester] 
AGNewsMetric: acc=0.8013157894736842, hinge=1.2077671502765857, ce=9.557956653394196
Local test acc @ epoch 24: 0.8013
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.23230737447738647
Local loss @ local epoch 1: 0.0995943695306778
Local loss @ local epoch 2: 0.041516948491334915
Local loss @ local epoch 3: 0.14671239256858826
Local loss @ local epoch 4: 0.2410782277584076
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.83 seconds!
[tester] 
AGNewsMetric: acc=0.8230263157894737, hinge=1.21261937342192, ce=6.4638215185466565
Local test acc @ epoch 24: 0.823
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.07939877361059189
Local loss @ local epoch 1: 0.45494985580444336
Local loss @ local epoch 2: 0.12982311844825745
Local loss @ local epoch 3: 0.4715062975883484
Local loss @ local epoch 4: 0.21855731308460236
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 139.34 seconds!
[tester] 
AGNewsMetric: acc=0.8375, hinge=1.013245877215737, ce=7.169257131877698
Local test acc @ epoch 24: 0.8375
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.47170865535736084
Local loss @ local epoch 1: 0.33660414814949036
Local loss @ local epoch 2: 0.3652331531047821
Local loss @ local epoch 3: 0.48913508653640747
Local loss @ local epoch 4: 0.5715143084526062
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.39 seconds!
[tester] 
AGNewsMetric: acc=0.8182894736842106, hinge=1.168630205957513, ce=7.2186140973944415
Local test acc @ epoch 24: 0.8183
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.4496438801288605
Local loss @ local epoch 1: 0.771288275718689
Local loss @ local epoch 2: 0.7989565134048462
Local loss @ local epoch 3: 0.7197496891021729
Local loss @ local epoch 4: 0.6529061794281006
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.8 seconds!
[tester] 
AGNewsMetric: acc=0.8593421052631579, hinge=0.9630770648153205, ce=6.396157134206671
Local test acc @ epoch 24: 0.8593
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.07215449959039688
Local loss @ local epoch 1: 0.04663481190800667
Local loss @ local epoch 2: 0.12944969534873962
Local loss @ local epoch 3: 0.12253852933645248
Local loss @ local epoch 4: 0.06219622492790222
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.04 seconds!
[tester] 
AGNewsMetric: acc=0.8668421052631579, hinge=0.9307269874371981, ce=9.502282716851486
Local test acc @ epoch 24: 0.8668
Global evaluate on test data...
Evaluate data in 130.27 seconds!
[tester] 
AGNewsMetric: acc=0.8631578947368421, hinge=0.8369604467090808, ce=8.221597314131888
Global test acc @ epoch 24: 0.8632
Global epoch 25...
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.18324419856071472
Local loss @ local epoch 1: 0.17459990084171295
Local loss @ local epoch 2: 0.14700742065906525
Local loss @ local epoch 3: 0.127772256731987
Local loss @ local epoch 4: 0.08708561211824417
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.66 seconds!
[tester] 
AGNewsMetric: acc=0.8375, hinge=1.152933074549625, ce=7.553531361630088
Local test acc @ epoch 25: 0.8375
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.37423717975616455
Local loss @ local epoch 1: 0.37477073073387146
Local loss @ local epoch 2: 0.36593133211135864
Local loss @ local epoch 3: 0.3429257273674011
Local loss @ local epoch 4: 0.4968642294406891
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.31 seconds!
[tester] 
AGNewsMetric: acc=0.6177631578947368, hinge=2.8614290106923956, ce=6.946863347103721
Local test acc @ epoch 25: 0.6178
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.628627359867096
Local loss @ local epoch 1: 0.5814425945281982
Local loss @ local epoch 2: 0.7587460279464722
Local loss @ local epoch 3: 0.5455448031425476
Local loss @ local epoch 4: 0.5630269646644592
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.41 seconds!
[tester] 
AGNewsMetric: acc=0.8448684210526316, hinge=0.9451966757523386, ce=9.855584371466385
Local test acc @ epoch 25: 0.8449
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.6168612837791443
Local loss @ local epoch 1: 0.4664387106895447
Local loss @ local epoch 2: 0.7308403849601746
Local loss @ local epoch 3: 0.681393563747406
Local loss @ local epoch 4: 0.5743191242218018
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.79 seconds!
[tester] 
AGNewsMetric: acc=0.8143421052631579, hinge=1.22108481858906, ce=8.696661391007273
Local test acc @ epoch 25: 0.8143
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.14993134140968323
Local loss @ local epoch 1: 0.10428335517644882
Local loss @ local epoch 2: 0.10726489871740341
Local loss @ local epoch 3: 0.09466146677732468
Local loss @ local epoch 4: 0.09358368813991547
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.45 seconds!
[tester] 
AGNewsMetric: acc=0.8421052631578947, hinge=1.1025374460220336, ce=6.83899919811048
Local test acc @ epoch 25: 0.8421
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.27790573239326477
Local loss @ local epoch 1: 0.17895054817199707
Local loss @ local epoch 2: 0.41443100571632385
Local loss @ local epoch 3: 0.09187661856412888
Local loss @ local epoch 4: 0.16397696733474731
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.96 seconds!
[tester] 
AGNewsMetric: acc=0.8467105263157895, hinge=0.997496485961111, ce=7.608048378793817
Local test acc @ epoch 25: 0.8467
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.3512622117996216
Local loss @ local epoch 1: 0.12082347273826599
Local loss @ local epoch 2: 0.3150479197502136
Local loss @ local epoch 3: 0.3322630226612091
Local loss @ local epoch 4: 0.23390406370162964
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.47 seconds!
[tester] 
AGNewsMetric: acc=0.835, hinge=1.0261950703671103, ce=8.386488866304097
Local test acc @ epoch 25: 0.835
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.408296674489975
Local loss @ local epoch 1: 0.29241928458213806
Local loss @ local epoch 2: 0.26149502396583557
Local loss @ local epoch 3: 0.4179779291152954
Local loss @ local epoch 4: 0.3050718307495117
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.18 seconds!
[tester] 
AGNewsMetric: acc=0.7998684210526316, hinge=1.3148042452962776, ce=8.544919281005859
Local test acc @ epoch 25: 0.7999
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.33524343371391296
Local loss @ local epoch 1: 0.224427729845047
Local loss @ local epoch 2: 0.14987339079380035
Local loss @ local epoch 3: 0.10441555827856064
Local loss @ local epoch 4: 0.11947905272245407
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.72 seconds!
[tester] 
AGNewsMetric: acc=0.8675, hinge=0.8274690221485339, ce=6.253668345401161
Local test acc @ epoch 25: 0.8675
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.4490932822227478
Local loss @ local epoch 1: 0.3215009272098541
Local loss @ local epoch 2: 0.2933301329612732
Local loss @ local epoch 3: 0.2823553681373596
Local loss @ local epoch 4: 0.31874701380729675
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.83 seconds!
[tester] 
AGNewsMetric: acc=0.8309210526315789, hinge=1.002956505825645, ce=6.262693566774067
Local test acc @ epoch 25: 0.8309
Global evaluate on test data...
Evaluate data in 129.52 seconds!
[tester] 
AGNewsMetric: acc=0.8761842105263158, hinge=0.8578272518358733, ce=9.184202758387515
Global test acc @ epoch 25: 0.8762
Global epoch 26...
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.23764601349830627
Local loss @ local epoch 1: 0.4440883696079254
Local loss @ local epoch 2: 1.304142713546753
Local loss @ local epoch 3: 2.0313148498535156
Local loss @ local epoch 4: 1.2658880949020386
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.74 seconds!
[tester] 
AGNewsMetric: acc=0.2493421052631579, hinge=6.946877969440661, ce=16.164043386358962
Local test acc @ epoch 26: 0.2493
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.2088097780942917
Local loss @ local epoch 1: 0.25845375657081604
Local loss @ local epoch 2: 0.32441261410713196
Local loss @ local epoch 3: 0.1469573825597763
Local loss @ local epoch 4: 0.1957143098115921
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 128.9 seconds!
[tester] 
AGNewsMetric: acc=0.8526315789473684, hinge=0.9458033606880589, ce=7.033062874643426
Local test acc @ epoch 26: 0.8526
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.4374081790447235
Local loss @ local epoch 1: 0.5862874984741211
Local loss @ local epoch 2: 0.36842080950737
Local loss @ local epoch 3: 0.5236803293228149
Local loss @ local epoch 4: 0.48459720611572266
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.01 seconds!
[tester] 
AGNewsMetric: acc=0.8036842105263158, hinge=1.204656733462685, ce=6.655644866541812
Local test acc @ epoch 26: 0.8037
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.7219972610473633
Local loss @ local epoch 1: 0.6355909109115601
Local loss @ local epoch 2: 0.7634800672531128
Local loss @ local epoch 3: 0.5775648951530457
Local loss @ local epoch 4: 0.6436325907707214
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.04 seconds!
[tester] 
AGNewsMetric: acc=0.8471052631578947, hinge=1.0125629660957738, ce=6.508075229243229
Local test acc @ epoch 26: 0.8471
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.14324378967285156
Local loss @ local epoch 1: 0.8954647779464722
Local loss @ local epoch 2: 0.07298588752746582
Local loss @ local epoch 3: 0.21508760750293732
Local loss @ local epoch 4: 0.12137304991483688
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.62 seconds!
[tester] 
AGNewsMetric: acc=0.8697368421052631, hinge=0.8263868658166182, ce=6.454511620370965
Local test acc @ epoch 26: 0.8697
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.23934713006019592
Local loss @ local epoch 1: 0.0691436380147934
Local loss @ local epoch 2: 0.08975573629140854
Local loss @ local epoch 3: 0.260256826877594
Local loss @ local epoch 4: 0.1011904701590538
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 128.86 seconds!
[tester] 
AGNewsMetric: acc=0.8507894736842105, hinge=1.0028135108947753, ce=8.421291353326096
Local test acc @ epoch 26: 0.8508
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.6021018028259277
Local loss @ local epoch 1: 0.3763491213321686
Local loss @ local epoch 2: 0.30602899193763733
Local loss @ local epoch 3: 0.9093973636627197
Local loss @ local epoch 4: 1.8073451519012451
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.71 seconds!
[tester] 
AGNewsMetric: acc=0.6051315789473685, hinge=3.0771097614890652, ce=12.982640176070364
Local test acc @ epoch 26: 0.6051
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.500860869884491
Local loss @ local epoch 1: 0.44159626960754395
Local loss @ local epoch 2: 0.30210018157958984
Local loss @ local epoch 3: 0.45825961232185364
Local loss @ local epoch 4: 0.2556912899017334
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.42 seconds!
[tester] 
AGNewsMetric: acc=0.8130263157894737, hinge=1.1030643227225856, ce=8.84556072837428
Local test acc @ epoch 26: 0.813
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.1075412929058075
Local loss @ local epoch 1: 0.08539345115423203
Local loss @ local epoch 2: 0.07496502995491028
Local loss @ local epoch 3: 0.09681448340415955
Local loss @ local epoch 4: 0.12231855094432831
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.59 seconds!
[tester] 
AGNewsMetric: acc=0.8607894736842105, hinge=0.9620899622063888, ce=5.584239293148643
Local test acc @ epoch 26: 0.8608
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.16670548915863037
Local loss @ local epoch 1: 0.21459831297397614
Local loss @ local epoch 2: 0.10116465389728546
Local loss @ local epoch 3: 0.48569902777671814
Local loss @ local epoch 4: 0.6011263728141785
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.67 seconds!
[tester] 
AGNewsMetric: acc=0.8222368421052632, hinge=1.2342027844880756, ce=6.100600824858013
Local test acc @ epoch 26: 0.8222
Global evaluate on test data...
Evaluate data in 129.84 seconds!
[tester] 
AGNewsMetric: acc=0.8618421052631579, hinge=0.8483041517358078, ce=8.132927609493859
Global test acc @ epoch 26: 0.8618
Global epoch 27...
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.21814581751823425
Local loss @ local epoch 1: 0.7527905702590942
Local loss @ local epoch 2: 0.15293830633163452
Local loss @ local epoch 3: 0.09927263855934143
Local loss @ local epoch 4: 0.1391780525445938
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.93 seconds!
[tester] 
AGNewsMetric: acc=0.845657894736842, hinge=1.0235616478167082, ce=8.530677175019918
Local test acc @ epoch 27: 0.8457
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.3299574851989746
Local loss @ local epoch 1: 0.18123434484004974
Local loss @ local epoch 2: 0.36826297640800476
Local loss @ local epoch 3: 0.551315426826477
Local loss @ local epoch 4: 0.15169857442378998
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 128.82 seconds!
[tester] 
AGNewsMetric: acc=0.8677631578947368, hinge=0.8932623988703677, ce=8.730431145115903
Local test acc @ epoch 27: 0.8678
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.3832925260066986
Local loss @ local epoch 1: 0.6046133637428284
Local loss @ local epoch 2: 0.5569639801979065
Local loss @ local epoch 3: 0.5543058514595032
Local loss @ local epoch 4: 0.5372353792190552
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.83 seconds!
[tester] 
AGNewsMetric: acc=0.8457894736842105, hinge=1.0222949976670115, ce=5.872457109752454
Local test acc @ epoch 27: 0.8458
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.7951816320419312
Local loss @ local epoch 1: 0.6567846536636353
Local loss @ local epoch 2: 0.5698767304420471
Local loss @ local epoch 3: 0.5968062281608582
Local loss @ local epoch 4: 0.5574382543563843
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.64 seconds!
[tester] 
AGNewsMetric: acc=0.8286842105263158, hinge=1.126308832168579, ce=6.800346306248715
Local test acc @ epoch 27: 0.8287
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.3215331733226776
Local loss @ local epoch 1: 0.24192692339420319
Local loss @ local epoch 2: 0.2724016308784485
Local loss @ local epoch 3: 0.23833101987838745
Local loss @ local epoch 4: 0.10246642678976059
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.25 seconds!
[tester] 
AGNewsMetric: acc=0.8122368421052631, hinge=1.3468738719036704, ce=7.448417436700118
Local test acc @ epoch 27: 0.8122
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.17861178517341614
Local loss @ local epoch 1: 0.06910818815231323
Local loss @ local epoch 2: 0.08126334846019745
Local loss @ local epoch 3: 0.10319378226995468
Local loss @ local epoch 4: 0.03632701560854912
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.16 seconds!
[tester] 
AGNewsMetric: acc=0.845657894736842, hinge=1.0599953332700227, ce=7.837480002955386
Local test acc @ epoch 27: 0.8457
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.4377012550830841
Local loss @ local epoch 1: 0.3188127279281616
Local loss @ local epoch 2: 0.34844741225242615
Local loss @ local epoch 3: 0.39806878566741943
Local loss @ local epoch 4: 0.45677056908607483
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.09 seconds!
[tester] 
AGNewsMetric: acc=0.8267105263157895, hinge=1.1152794597023412, ce=7.80526573783473
Local test acc @ epoch 27: 0.8267
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.11459819972515106
Local loss @ local epoch 1: 0.08095547556877136
Local loss @ local epoch 2: 0.09135528653860092
Local loss @ local epoch 3: 0.30675625801086426
Local loss @ local epoch 4: 0.5026068687438965
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.82 seconds!
[tester] 
AGNewsMetric: acc=0.7436842105263158, hinge=2.1800826293543767, ce=5.127900222979094
Local test acc @ epoch 27: 0.7437
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.5943088531494141
Local loss @ local epoch 1: 0.45955178141593933
Local loss @ local epoch 2: 0.49750953912734985
Local loss @ local epoch 3: 0.38957518339157104
Local loss @ local epoch 4: 0.45982006192207336
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.25 seconds!
[tester] 
AGNewsMetric: acc=0.8492105263157895, hinge=0.9672004393527383, ce=9.096794220773797
Local test acc @ epoch 27: 0.8492
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.3110954165458679
Local loss @ local epoch 1: 0.19757060706615448
Local loss @ local epoch 2: 0.5665650367736816
Local loss @ local epoch 3: 0.322464257478714
Local loss @ local epoch 4: 0.17348964512348175
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.5 seconds!
[tester] 
AGNewsMetric: acc=0.8443421052631579, hinge=1.0006901736008493, ce=6.709273530056602
Local test acc @ epoch 27: 0.8443
Global evaluate on test data...
Evaluate data in 129.34 seconds!
[tester] 
AGNewsMetric: acc=0.8738157894736842, hinge=0.7871516794907419, ce=8.644252365513852
Global test acc @ epoch 27: 0.8738
Global epoch 28...
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.47055724263191223
Local loss @ local epoch 1: 0.5590891242027283
Local loss @ local epoch 2: 0.43504124879837036
Local loss @ local epoch 3: 0.658285915851593
Local loss @ local epoch 4: 0.3778865337371826
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.21 seconds!
[tester] 
AGNewsMetric: acc=0.8467105263157895, hinge=0.9384548965253328, ce=5.762376109675357
Local test acc @ epoch 28: 0.8467
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.6766456365585327
Local loss @ local epoch 1: 0.815273642539978
Local loss @ local epoch 2: 0.6180607676506042
Local loss @ local epoch 3: 0.7450853586196899
Local loss @ local epoch 4: 0.6406805515289307
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.52 seconds!
[tester] 
AGNewsMetric: acc=0.8492105263157895, hinge=0.9362216502741764, ce=8.515163261012027
Local test acc @ epoch 28: 0.8492
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.07568413019180298
Local loss @ local epoch 1: 0.17147359251976013
Local loss @ local epoch 2: 0.045086570084095
Local loss @ local epoch 3: 0.12685449421405792
Local loss @ local epoch 4: 0.12051418423652649
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.66 seconds!
[tester] 
AGNewsMetric: acc=0.8536842105263158, hinge=1.0256671719802053, ce=9.464971184981497
Local test acc @ epoch 28: 0.8537
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.11900676786899567
Local loss @ local epoch 1: 0.6296043395996094
Local loss @ local epoch 2: 0.14919313788414001
Local loss @ local epoch 3: 0.11330903321504593
Local loss @ local epoch 4: 0.22983543574810028
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 128.75 seconds!
[tester] 
AGNewsMetric: acc=0.8672368421052632, hinge=0.8359695263912803, ce=8.220451666179455
Local test acc @ epoch 28: 0.8672
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.5472193360328674
Local loss @ local epoch 1: 0.19142213463783264
Local loss @ local epoch 2: 0.131755992770195
Local loss @ local epoch 3: 0.390674352645874
Local loss @ local epoch 4: 0.39155110716819763
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.11 seconds!
[tester] 
AGNewsMetric: acc=0.7876315789473685, hinge=1.6215238581205669, ce=10.425261720356188
Local test acc @ epoch 28: 0.7876
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.5249618887901306
Local loss @ local epoch 1: 0.3129202723503113
Local loss @ local epoch 2: 0.20817063748836517
Local loss @ local epoch 3: 0.19693127274513245
Local loss @ local epoch 4: 0.3125072419643402
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.33 seconds!
[tester] 
AGNewsMetric: acc=0.8363157894736842, hinge=1.059160425286544, ce=6.659886374222605
Local test acc @ epoch 28: 0.8363
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.3457435965538025
Local loss @ local epoch 1: 0.389656662940979
Local loss @ local epoch 2: 0.3189519941806793
Local loss @ local epoch 3: 0.29409775137901306
Local loss @ local epoch 4: 0.19857721030712128
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.16 seconds!
[tester] 
AGNewsMetric: acc=0.8757894736842106, hinge=0.848864463504992, ce=6.747559539393375
Local test acc @ epoch 28: 0.8758
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.4217996597290039
Local loss @ local epoch 1: 0.3673974275588989
Local loss @ local epoch 2: 0.24615059792995453
Local loss @ local epoch 3: 0.25867369771003723
Local loss @ local epoch 4: 0.3340286314487457
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.76 seconds!
[tester] 
AGNewsMetric: acc=0.8003947368421053, hinge=1.5179112047898142, ce=5.906668610823782
Local test acc @ epoch 28: 0.8004
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.13325877487659454
Local loss @ local epoch 1: 0.1847003996372223
Local loss @ local epoch 2: 0.15907397866249084
Local loss @ local epoch 3: 0.1133977621793747
Local loss @ local epoch 4: 0.16114476323127747
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.57 seconds!
[tester] 
AGNewsMetric: acc=0.8518421052631578, hinge=1.0462674482245193, ce=9.181467985855905
Local test acc @ epoch 28: 0.8518
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.36281993985176086
Local loss @ local epoch 1: 0.23601438105106354
Local loss @ local epoch 2: 0.1762605905532837
Local loss @ local epoch 3: 0.20492170751094818
Local loss @ local epoch 4: 0.16424454748630524
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 128.7 seconds!
[tester] 
AGNewsMetric: acc=0.8506578947368421, hinge=0.9759112282803184, ce=6.09593000110827
Local test acc @ epoch 28: 0.8507
Global evaluate on test data...
Evaluate data in 129.91 seconds!
[tester] 
AGNewsMetric: acc=0.8696052631578948, hinge=0.8029593156513415, ce=8.355916432832418
Global test acc @ epoch 28: 0.8696
Global epoch 29...
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.14947547018527985
Local loss @ local epoch 1: 0.10698039829730988
Local loss @ local epoch 2: 0.12987996637821198
Local loss @ local epoch 3: 0.18886111676692963
Local loss @ local epoch 4: 0.23509494960308075
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.9 seconds!
[tester] 
AGNewsMetric: acc=0.8413157894736842, hinge=1.022095412706074, ce=5.782416352723774
Local test acc @ epoch 29: 0.8413
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.28041529655456543
Local loss @ local epoch 1: 0.29592612385749817
Local loss @ local epoch 2: 0.11123958975076675
Local loss @ local epoch 3: 0.5218778252601624
Local loss @ local epoch 4: 0.5332044363021851
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.2 seconds!
[tester] 
AGNewsMetric: acc=0.854078947368421, hinge=1.003470448945698, ce=5.423411656429893
Local test acc @ epoch 29: 0.8541
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.38256099820137024
Local loss @ local epoch 1: 0.3900417685508728
Local loss @ local epoch 2: 0.42911264300346375
Local loss @ local epoch 3: 0.34450796246528625
Local loss @ local epoch 4: 0.29985013604164124
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.15 seconds!
[tester] 
AGNewsMetric: acc=0.8360526315789474, hinge=1.0201758670806884, ce=5.48065099515413
Local test acc @ epoch 29: 0.8361
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.18654018640518188
Local loss @ local epoch 1: 0.18850132822990417
Local loss @ local epoch 2: 0.20476722717285156
Local loss @ local epoch 3: 0.060901325196027756
Local loss @ local epoch 4: 0.08265932649374008
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.88 seconds!
[tester] 
AGNewsMetric: acc=0.8611842105263158, hinge=0.9115578320151881, ce=9.053051791944002
Local test acc @ epoch 29: 0.8612
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.7895220518112183
Local loss @ local epoch 1: 0.7085274457931519
Local loss @ local epoch 2: 0.6694408655166626
Local loss @ local epoch 3: 0.50022292137146
Local loss @ local epoch 4: 0.5437084436416626
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.34 seconds!
[tester] 
AGNewsMetric: acc=0.8309210526315789, hinge=1.018331651687622, ce=7.696065360621402
Local test acc @ epoch 29: 0.8309
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.2915828227996826
Local loss @ local epoch 1: 0.4633534252643585
Local loss @ local epoch 2: 0.3845016360282898
Local loss @ local epoch 3: 0.33346858620643616
Local loss @ local epoch 4: 0.2691012918949127
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.34 seconds!
[tester] 
AGNewsMetric: acc=0.7846052631578947, hinge=1.2714669583973133, ce=6.77058342180754
Local test acc @ epoch 29: 0.7846
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.11153747141361237
Local loss @ local epoch 1: 0.11306586116552353
Local loss @ local epoch 2: 0.055081985890865326
Local loss @ local epoch 3: 0.04276750236749649
Local loss @ local epoch 4: 0.054538775235414505
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.38 seconds!
[tester] 
AGNewsMetric: acc=0.8042105263157895, hinge=1.615451538939225, ce=6.657543843921862
Local test acc @ epoch 29: 0.8042
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.44837966561317444
Local loss @ local epoch 1: 0.3000274896621704
Local loss @ local epoch 2: 0.28114140033721924
Local loss @ local epoch 3: 0.17410458624362946
Local loss @ local epoch 4: 0.17049704492092133
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.93 seconds!
[tester] 
AGNewsMetric: acc=0.7853947368421053, hinge=1.4598608850177965, ce=7.9484573544954
Local test acc @ epoch 29: 0.7854
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.12195530533790588
Local loss @ local epoch 1: 0.038032252341508865
Local loss @ local epoch 2: 0.10206915438175201
Local loss @ local epoch 3: 0.03868386149406433
Local loss @ local epoch 4: 0.20518390834331512
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.94 seconds!
[tester] 
AGNewsMetric: acc=0.8493421052631579, hinge=1.0216384521283601, ce=8.909490910580283
Local test acc @ epoch 29: 0.8493
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.4470859169960022
Local loss @ local epoch 1: 0.32982951402664185
Local loss @ local epoch 2: 0.38764286041259766
Local loss @ local epoch 3: 0.547816276550293
Local loss @ local epoch 4: 0.26377439498901367
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.05 seconds!
[tester] 
AGNewsMetric: acc=0.8610526315789474, hinge=0.8678742509139211, ce=9.191333814922132
Local test acc @ epoch 29: 0.8611
Global evaluate on test data...
Evaluate data in 130.59 seconds!
[tester] 
AGNewsMetric: acc=0.8814473684210526, hinge=0.7729893383226897, ce=8.416617493880423
Global test acc @ epoch 29: 0.8814
Global epoch 30...
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.5293725728988647
Local loss @ local epoch 1: 0.31108832359313965
Local loss @ local epoch 2: 0.3256639242172241
Local loss @ local epoch 3: 0.4174957573413849
Local loss @ local epoch 4: 0.3568156361579895
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.63 seconds!
[tester] 
AGNewsMetric: acc=0.849078947368421, hinge=0.949495311536287, ce=5.145489723807887
Local test acc @ epoch 30: 0.8491
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.17170450091362
Local loss @ local epoch 1: 0.181666299700737
Local loss @ local epoch 2: 0.22003912925720215
Local loss @ local epoch 3: 0.12073064595460892
Local loss @ local epoch 4: 0.09620894491672516
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.6 seconds!
[tester] 
AGNewsMetric: acc=0.8597368421052631, hinge=0.8791235020286159, ce=8.54849970566599
Local test acc @ epoch 30: 0.8597
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.22772280871868134
Local loss @ local epoch 1: 0.14106296002864838
Local loss @ local epoch 2: 0.16586090624332428
Local loss @ local epoch 3: 0.17946168780326843
Local loss @ local epoch 4: 0.2409965991973877
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.46 seconds!
[tester] 
AGNewsMetric: acc=0.8632894736842105, hinge=0.9003692295676784, ce=7.528400435196726
Local test acc @ epoch 30: 0.8633
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.265451043844223
Local loss @ local epoch 1: 0.4180105924606323
Local loss @ local epoch 2: 0.11561819165945053
Local loss @ local epoch 3: 0.1275951862335205
Local loss @ local epoch 4: 0.04502736032009125
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.3 seconds!
[tester] 
AGNewsMetric: acc=0.8607894736842105, hinge=0.9216505341780813, ce=7.111433842307643
Local test acc @ epoch 30: 0.8608
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.7514483332633972
Local loss @ local epoch 1: 0.6934558749198914
Local loss @ local epoch 2: 0.5327670574188232
Local loss @ local epoch 3: 0.7795500755310059
Local loss @ local epoch 4: 0.7021092176437378
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.37 seconds!
[tester] 
AGNewsMetric: acc=0.8282894736842106, hinge=1.0397023918754176, ce=8.598567219784385
Local test acc @ epoch 30: 0.8283
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.6040883660316467
Local loss @ local epoch 1: 0.42751947045326233
Local loss @ local epoch 2: 0.18365658819675446
Local loss @ local epoch 3: 0.27382463216781616
Local loss @ local epoch 4: 0.4135969579219818
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.8 seconds!
[tester] 
AGNewsMetric: acc=0.8378947368421052, hinge=1.0507812861392372, ce=9.24982296993858
Local test acc @ epoch 30: 0.8379
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.12506520748138428
Local loss @ local epoch 1: 0.1301472932100296
Local loss @ local epoch 2: 0.08721698820590973
Local loss @ local epoch 3: 0.07080525159835815
Local loss @ local epoch 4: 0.041131164878606796
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.81 seconds!
[tester] 
AGNewsMetric: acc=0.8543421052631579, hinge=1.014930174476222, ce=4.950785849721808
Local test acc @ epoch 30: 0.8543
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.163357675075531
Local loss @ local epoch 1: 0.033213842660188675
Local loss @ local epoch 2: 0.05396657809615135
Local loss @ local epoch 3: 0.03959959000349045
Local loss @ local epoch 4: 0.05992812290787697
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.31 seconds!
[tester] 
AGNewsMetric: acc=0.8451315789473685, hinge=1.1742208229868036, ce=7.140243493130333
Local test acc @ epoch 30: 0.8451
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.5515052676200867
Local loss @ local epoch 1: 0.348854660987854
Local loss @ local epoch 2: 0.21792493760585785
Local loss @ local epoch 3: 0.15810295939445496
Local loss @ local epoch 4: 0.21421383321285248
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.23 seconds!
[tester] 
AGNewsMetric: acc=0.8348684210526316, hinge=1.0362658646232203, ce=8.093964496411775
Local test acc @ epoch 30: 0.8349
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.3722827732563019
Local loss @ local epoch 1: 0.3282582759857178
Local loss @ local epoch 2: 0.37859317660331726
Local loss @ local epoch 3: 0.3267580568790436
Local loss @ local epoch 4: 0.2810426354408264
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.72 seconds!
[tester] 
AGNewsMetric: acc=0.8010526315789473, hinge=1.190423940357409, ce=6.216631193662945
Local test acc @ epoch 30: 0.8011
Global evaluate on test data...
Evaluate data in 129.81 seconds!
[tester] 
AGNewsMetric: acc=0.8748684210526316, hinge=0.7940818535654168, ce=8.132583128276623
Global test acc @ epoch 30: 0.8749
Global epoch 31...
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.6106728911399841
Local loss @ local epoch 1: 0.3830338716506958
Local loss @ local epoch 2: 0.17400629818439484
Local loss @ local epoch 3: 0.20649632811546326
Local loss @ local epoch 4: 0.23375220596790314
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.53 seconds!
[tester] 
AGNewsMetric: acc=0.7636842105263157, hinge=1.6665703201293944, ce=9.018372969376413
Local test acc @ epoch 31: 0.7637
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.43474525213241577
Local loss @ local epoch 1: 0.32071611285209656
Local loss @ local epoch 2: 0.3569248616695404
Local loss @ local epoch 3: 0.36107146739959717
Local loss @ local epoch 4: 0.1843959242105484
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.89 seconds!
[tester] 
AGNewsMetric: acc=0.8201315789473684, hinge=1.0962645284753096, ce=7.851154614498741
Local test acc @ epoch 31: 0.8201
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.2389266937971115
Local loss @ local epoch 1: 0.11212572455406189
Local loss @ local epoch 2: 0.06471673399209976
Local loss @ local epoch 3: 0.044866740703582764
Local loss @ local epoch 4: 0.04813186451792717
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.39 seconds!
[tester] 
AGNewsMetric: acc=0.8492105263157895, hinge=1.0352990175548353, ce=5.306543888292815
Local test acc @ epoch 31: 0.8492
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.20271557569503784
Local loss @ local epoch 1: 0.19899408519268036
Local loss @ local epoch 2: 0.42920413613319397
Local loss @ local epoch 3: 0.13845767080783844
Local loss @ local epoch 4: 0.21261152625083923
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.87 seconds!
[tester] 
AGNewsMetric: acc=0.865, hinge=0.8583835641961348, ce=7.682832051327354
Local test acc @ epoch 31: 0.865
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.07202659547328949
Local loss @ local epoch 1: 0.11375286430120468
Local loss @ local epoch 2: 0.2027893364429474
Local loss @ local epoch 3: 0.2988218069076538
Local loss @ local epoch 4: 0.20019468665122986
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.46 seconds!
[tester] 
AGNewsMetric: acc=0.8521052631578947, hinge=0.9739150107534308, ce=5.833724680448833
Local test acc @ epoch 31: 0.8521
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.5331994891166687
Local loss @ local epoch 1: 0.4223887026309967
Local loss @ local epoch 2: 0.27174103260040283
Local loss @ local epoch 3: 0.26984891295433044
Local loss @ local epoch 4: 0.30362626910209656
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.92 seconds!
[tester] 
AGNewsMetric: acc=0.8330263157894737, hinge=1.1680166410145008, ce=10.146590022036904
Local test acc @ epoch 31: 0.833
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.2612195611000061
Local loss @ local epoch 1: 0.15990984439849854
Local loss @ local epoch 2: 0.1968427151441574
Local loss @ local epoch 3: 0.32336029410362244
Local loss @ local epoch 4: 0.07499589025974274
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.81 seconds!
[tester] 
AGNewsMetric: acc=0.8319736842105263, hinge=1.0831436985417415, ce=7.529455250187924
Local test acc @ epoch 31: 0.832
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.4180189371109009
Local loss @ local epoch 1: 0.2638745605945587
Local loss @ local epoch 2: 0.24479658901691437
Local loss @ local epoch 3: 0.2059558480978012
Local loss @ local epoch 4: 0.14277848601341248
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.65 seconds!
[tester] 
AGNewsMetric: acc=0.791578947368421, hinge=1.234266767501831, ce=6.048436155821148
Local test acc @ epoch 31: 0.7916
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.18305926024913788
Local loss @ local epoch 1: 0.44648540019989014
Local loss @ local epoch 2: 0.10314710438251495
Local loss @ local epoch 3: 0.2073911726474762
Local loss @ local epoch 4: 0.20012353360652924
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.35 seconds!
[tester] 
AGNewsMetric: acc=0.8605263157894737, hinge=0.885822050947892, ce=8.531155901457135
Local test acc @ epoch 31: 0.8605
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.7138296365737915
Local loss @ local epoch 1: 0.7169603109359741
Local loss @ local epoch 2: 0.6898868680000305
Local loss @ local epoch 3: 0.4886675179004669
Local loss @ local epoch 4: 0.5919553637504578
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 128.95 seconds!
[tester] 
AGNewsMetric: acc=0.8414473684210526, hinge=0.9753063919669703, ce=7.633185360557155
Local test acc @ epoch 31: 0.8414
Global evaluate on test data...
Evaluate data in 130.06 seconds!
[tester] 
AGNewsMetric: acc=0.8742105263157894, hinge=0.7931136397311562, ce=8.17739020698949
Global test acc @ epoch 31: 0.8742
Global epoch 32...
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.13943389058113098
Local loss @ local epoch 1: 0.29221975803375244
Local loss @ local epoch 2: 0.09441773593425751
Local loss @ local epoch 3: 0.2189263105392456
Local loss @ local epoch 4: 0.08423621952533722
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.2 seconds!
[tester] 
AGNewsMetric: acc=0.8603947368421052, hinge=0.8922793779875102, ce=8.541090850830079
Local test acc @ epoch 32: 0.8604
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.07058154791593552
Local loss @ local epoch 1: 0.2960352599620819
Local loss @ local epoch 2: 0.06994209438562393
Local loss @ local epoch 3: 0.19015033543109894
Local loss @ local epoch 4: 0.08419004082679749
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.2 seconds!
[tester] 
AGNewsMetric: acc=0.8564473684210526, hinge=0.9124883149799548, ce=7.337844370791786
Local test acc @ epoch 32: 0.8564
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.26265308260917664
Local loss @ local epoch 1: 0.2551000118255615
Local loss @ local epoch 2: 0.3151896595954895
Local loss @ local epoch 3: 0.374275267124176
Local loss @ local epoch 4: 0.3658377230167389
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.25 seconds!
[tester] 
AGNewsMetric: acc=0.8068421052631579, hinge=1.266588424381457, ce=6.626572716361598
Local test acc @ epoch 32: 0.8068
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.12721505761146545
Local loss @ local epoch 1: 0.060260169208049774
Local loss @ local epoch 2: 0.039889901876449585
Local loss @ local epoch 3: 0.09192651510238647
Local loss @ local epoch 4: 0.035044677555561066
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.18 seconds!
[tester] 
AGNewsMetric: acc=0.7293421052631579, hinge=2.384014640607332, ce=6.6257562657406455
Local test acc @ epoch 32: 0.7293
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0825556069612503
Local loss @ local epoch 1: 0.08728795498609543
Local loss @ local epoch 2: 0.027128778398036957
Local loss @ local epoch 3: 0.06837295740842819
Local loss @ local epoch 4: 0.09891201555728912
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 131.52 seconds!
[tester] 
AGNewsMetric: acc=0.8630263157894736, hinge=0.911663697393317, ce=5.529971503207558
Local test acc @ epoch 32: 0.863
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.42626023292541504
Local loss @ local epoch 1: 0.6395289301872253
Local loss @ local epoch 2: 0.31312304735183716
Local loss @ local epoch 3: 0.48889464139938354
Local loss @ local epoch 4: 0.40882378816604614
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.11 seconds!
[tester] 
AGNewsMetric: acc=0.8532894736842105, hinge=0.9634945623498213, ce=6.82781744404843
Local test acc @ epoch 32: 0.8533
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.3692144751548767
Local loss @ local epoch 1: 0.42250141501426697
Local loss @ local epoch 2: 0.46779078245162964
Local loss @ local epoch 3: 0.3982451856136322
Local loss @ local epoch 4: 0.2755264639854431
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.46 seconds!
[tester] 
AGNewsMetric: acc=0.8476315789473684, hinge=0.9690767657129388, ce=8.58051211909244
Local test acc @ epoch 32: 0.8476
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.579698383808136
Local loss @ local epoch 1: 0.6289389133453369
Local loss @ local epoch 2: 0.4398197829723358
Local loss @ local epoch 3: 0.5053234100341797
Local loss @ local epoch 4: 0.5811649560928345
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.31 seconds!
[tester] 
AGNewsMetric: acc=0.839078947368421, hinge=0.9601568031311035, ce=6.506987426155492
Local test acc @ epoch 32: 0.8391
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.2963475286960602
Local loss @ local epoch 1: 0.21310335397720337
Local loss @ local epoch 2: 0.16123439371585846
Local loss @ local epoch 3: 0.11876625567674637
Local loss @ local epoch 4: 0.326142281293869
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.7 seconds!
[tester] 
AGNewsMetric: acc=0.8585526315789473, hinge=0.9051179464239824, ce=4.986061170477616
Local test acc @ epoch 32: 0.8586
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.3441866636276245
Local loss @ local epoch 1: 0.38060057163238525
Local loss @ local epoch 2: 0.314993292093277
Local loss @ local epoch 3: 0.0990564301609993
Local loss @ local epoch 4: 0.22405309975147247
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.15 seconds!
[tester] 
AGNewsMetric: acc=0.8594736842105263, hinge=0.9450209702943501, ce=6.2206308756376565
Local test acc @ epoch 32: 0.8595
Global evaluate on test data...
Evaluate data in 130.65 seconds!
[tester] 
AGNewsMetric: acc=0.8817105263157895, hinge=0.7868673550455194, ce=7.237220314427426
Global test acc @ epoch 32: 0.8817
Global epoch 33...
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.15233655273914337
Local loss @ local epoch 1: 0.05610593035817146
Local loss @ local epoch 2: 0.07311854511499405
Local loss @ local epoch 3: 0.05719795823097229
Local loss @ local epoch 4: 0.08270593732595444
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.64 seconds!
[tester] 
AGNewsMetric: acc=0.8206578947368421, hinge=1.3355934158124423, ce=7.2279293923628956
Local test acc @ epoch 33: 0.8207
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.4982233941555023
Local loss @ local epoch 1: 0.17947086691856384
Local loss @ local epoch 2: 0.18051128089427948
Local loss @ local epoch 3: 0.20373395085334778
Local loss @ local epoch 4: 0.1884479969739914
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.71 seconds!
[tester] 
AGNewsMetric: acc=0.8126315789473684, hinge=1.0996705466822574, ce=7.259184887534694
Local test acc @ epoch 33: 0.8126
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.26826030015945435
Local loss @ local epoch 1: 0.24947211146354675
Local loss @ local epoch 2: 0.3452303111553192
Local loss @ local epoch 3: 0.28977060317993164
Local loss @ local epoch 4: 0.35846230387687683
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.5 seconds!
[tester] 
AGNewsMetric: acc=0.8273684210526315, hinge=1.132859041314376, ce=6.380004147981342
Local test acc @ epoch 33: 0.8274
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.2289239764213562
Local loss @ local epoch 1: 0.08945821225643158
Local loss @ local epoch 2: 0.17851290106773376
Local loss @ local epoch 3: 0.1179991066455841
Local loss @ local epoch 4: 0.1923503279685974
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.83 seconds!
[tester] 
AGNewsMetric: acc=0.8638157894736842, hinge=0.8605078767475329, ce=7.8951013163516395
Local test acc @ epoch 33: 0.8638
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.04665791988372803
Local loss @ local epoch 1: 0.04176955297589302
Local loss @ local epoch 2: 0.12707602977752686
Local loss @ local epoch 3: 0.052709683775901794
Local loss @ local epoch 4: 0.05123842507600784
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.34 seconds!
[tester] 
AGNewsMetric: acc=0.8425, hinge=1.1466575587423224, ce=7.369532792944657
Local test acc @ epoch 33: 0.8425
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.7211324572563171
Local loss @ local epoch 1: 0.5225197672843933
Local loss @ local epoch 2: 0.576741099357605
Local loss @ local epoch 3: 0.5095450282096863
Local loss @ local epoch 4: 0.5510286688804626
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.55 seconds!
[tester] 
AGNewsMetric: acc=0.8223684210526315, hinge=1.0439200938375373, ce=9.940342937268708
Local test acc @ epoch 33: 0.8224
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.5640376210212708
Local loss @ local epoch 1: 0.39316970109939575
Local loss @ local epoch 2: 0.3604758679866791
Local loss @ local epoch 3: 0.25748100876808167
Local loss @ local epoch 4: 0.3451235890388489
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.81 seconds!
[tester] 
AGNewsMetric: acc=0.8213157894736842, hinge=1.104732464238217, ce=7.477917771590383
Local test acc @ epoch 33: 0.8213
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.3845309317111969
Local loss @ local epoch 1: 0.3844892382621765
Local loss @ local epoch 2: 0.5519916415214539
Local loss @ local epoch 3: 0.26670849323272705
Local loss @ local epoch 4: 0.4673934280872345
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.4 seconds!
[tester] 
AGNewsMetric: acc=0.8617105263157895, hinge=0.8612563379187334, ce=7.8381687626085785
Local test acc @ epoch 33: 0.8617
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.2085006982088089
Local loss @ local epoch 1: 0.15980862081050873
Local loss @ local epoch 2: 0.11036521941423416
Local loss @ local epoch 3: 0.1015484556555748
Local loss @ local epoch 4: 0.12467153370380402
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 131.0 seconds!
[tester] 
AGNewsMetric: acc=0.6807894736842105, hinge=2.6339700879548724, ce=7.7602911376953125
Local test acc @ epoch 33: 0.6808
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.07423640042543411
Local loss @ local epoch 1: 0.07543887943029404
Local loss @ local epoch 2: 0.12831707298755646
Local loss @ local epoch 3: 0.04939154163002968
Local loss @ local epoch 4: 0.03229298070073128
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.79 seconds!
[tester] 
AGNewsMetric: acc=0.8486842105263158, hinge=1.0940486534018266, ce=9.022010459899903
Local test acc @ epoch 33: 0.8487
Global evaluate on test data...
Evaluate data in 130.47 seconds!
[tester] 
AGNewsMetric: acc=0.8775, hinge=0.8156449237622713, ce=8.271122416446083
Global test acc @ epoch 33: 0.8775
Global epoch 34...
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.09742142260074615
Local loss @ local epoch 1: 0.3785272538661957
Local loss @ local epoch 2: 0.180349200963974
Local loss @ local epoch 3: 0.06131765618920326
Local loss @ local epoch 4: 0.05694583058357239
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.89 seconds!
[tester] 
AGNewsMetric: acc=0.8507894736842105, hinge=1.0663713721225136, ce=8.466476771706029
Local test acc @ epoch 34: 0.8508
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.20084813237190247
Local loss @ local epoch 1: 0.2364732325077057
Local loss @ local epoch 2: 0.2427678257226944
Local loss @ local epoch 3: 0.20016229152679443
Local loss @ local epoch 4: 0.1590418666601181
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.31 seconds!
[tester] 
AGNewsMetric: acc=0.8675, hinge=0.8630991057345742, ce=8.26545367793033
Local test acc @ epoch 34: 0.8675
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.3016173839569092
Local loss @ local epoch 1: 0.1681186854839325
Local loss @ local epoch 2: 0.14774566888809204
Local loss @ local epoch 3: 0.17199017107486725
Local loss @ local epoch 4: 0.1430983692407608
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.78 seconds!
[tester] 
AGNewsMetric: acc=0.8338157894736842, hinge=1.2681356791446083, ce=8.374559795981959
Local test acc @ epoch 34: 0.8338
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.4183448851108551
Local loss @ local epoch 1: 0.38537201285362244
Local loss @ local epoch 2: 0.3179989159107208
Local loss @ local epoch 3: 0.34424567222595215
Local loss @ local epoch 4: 0.1851891577243805
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.38 seconds!
[tester] 
AGNewsMetric: acc=0.8551315789473685, hinge=1.0457502761640047, ce=6.894311369845742
Local test acc @ epoch 34: 0.8551
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.14329750835895538
Local loss @ local epoch 1: 0.07881979644298553
Local loss @ local epoch 2: 0.04818141832947731
Local loss @ local epoch 3: 0.20798416435718536
Local loss @ local epoch 4: 0.12054360657930374
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.98 seconds!
[tester] 
AGNewsMetric: acc=0.8455263157894737, hinge=0.990870035071122, ce=8.924737611067922
Local test acc @ epoch 34: 0.8455
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.060647401958703995
Local loss @ local epoch 1: 0.05657457187771797
Local loss @ local epoch 2: 0.047735657542943954
Local loss @ local epoch 3: 0.03510211408138275
Local loss @ local epoch 4: 0.1534128487110138
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.96 seconds!
[tester] 
AGNewsMetric: acc=0.868421052631579, hinge=0.9556536195152684, ce=7.1628851619519684
Local test acc @ epoch 34: 0.8684
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.42087939381599426
Local loss @ local epoch 1: 0.2940368056297302
Local loss @ local epoch 2: 0.23607203364372253
Local loss @ local epoch 3: 0.25452104210853577
Local loss @ local epoch 4: 0.23306725919246674
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.2 seconds!
[tester] 
AGNewsMetric: acc=0.7526315789473684, hinge=1.584927121212608, ce=8.141046632465564
Local test acc @ epoch 34: 0.7526
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.11897486448287964
Local loss @ local epoch 1: 0.12468314170837402
Local loss @ local epoch 2: 0.10674037039279938
Local loss @ local epoch 3: 0.06871034950017929
Local loss @ local epoch 4: 0.0361323356628418
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.47 seconds!
[tester] 
AGNewsMetric: acc=0.8417105263157895, hinge=1.0829938692795602, ce=8.409664035596345
Local test acc @ epoch 34: 0.8417
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.47573035955429077
Local loss @ local epoch 1: 0.4253652095794678
Local loss @ local epoch 2: 0.17535820603370667
Local loss @ local epoch 3: 0.18739613890647888
Local loss @ local epoch 4: 0.12304982542991638
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.95 seconds!
[tester] 
AGNewsMetric: acc=0.8218421052631579, hinge=1.1635078681142708, ce=7.695546393143503
Local test acc @ epoch 34: 0.8218
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.5953377485275269
Local loss @ local epoch 1: 0.5749807357788086
Local loss @ local epoch 2: 0.8586052060127258
Local loss @ local epoch 3: 0.4592478275299072
Local loss @ local epoch 4: 0.6798474788665771
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.4 seconds!
[tester] 
AGNewsMetric: acc=0.8438157894736842, hinge=0.9552712139330413, ce=8.572313071803043
Local test acc @ epoch 34: 0.8438
Global evaluate on test data...
Evaluate data in 130.66 seconds!
[tester] 
AGNewsMetric: acc=0.8796052631578948, hinge=0.8104061367637233, ce=8.048466796875
Global test acc @ epoch 34: 0.8796
Global epoch 35...
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.3690859079360962
Local loss @ local epoch 1: 0.12939150631427765
Local loss @ local epoch 2: 0.26420918107032776
Local loss @ local epoch 3: 0.16308632493019104
Local loss @ local epoch 4: 0.27052679657936096
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.68 seconds!
[tester] 
AGNewsMetric: acc=0.8113157894736842, hinge=1.2904821787382428, ce=8.325692777131733
Local test acc @ epoch 35: 0.8113
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.8308267593383789
Local loss @ local epoch 1: 0.4062511920928955
Local loss @ local epoch 2: 0.6445187330245972
Local loss @ local epoch 3: 0.6437335014343262
Local loss @ local epoch 4: 0.48788484930992126
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.21 seconds!
[tester] 
AGNewsMetric: acc=0.8530263157894736, hinge=0.9057415174183092, ce=6.835867010417737
Local test acc @ epoch 35: 0.853
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.05064116045832634
Local loss @ local epoch 1: 0.1311669796705246
Local loss @ local epoch 2: 0.36250853538513184
Local loss @ local epoch 3: 0.12696608901023865
Local loss @ local epoch 4: 0.05498531088232994
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.12 seconds!
[tester] 
AGNewsMetric: acc=0.8526315789473684, hinge=0.984278238447089, ce=5.700809165553043
Local test acc @ epoch 35: 0.8526
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.04237142577767372
Local loss @ local epoch 1: 0.04581989347934723
Local loss @ local epoch 2: 0.04863407090306282
Local loss @ local epoch 3: 0.10560465604066849
Local loss @ local epoch 4: 0.04713849723339081
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.55 seconds!
[tester] 
AGNewsMetric: acc=0.8234210526315789, hinge=1.3613154356103194, ce=5.230995148106625
Local test acc @ epoch 35: 0.8234
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.04565844312310219
Local loss @ local epoch 1: 0.026293858885765076
Local loss @ local epoch 2: 0.029542159289121628
Local loss @ local epoch 3: 0.022165492177009583
Local loss @ local epoch 4: 0.11836987733840942
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.61 seconds!
[tester] 
AGNewsMetric: acc=0.8551315789473685, hinge=0.9931496685429623, ce=6.398852751882453
Local test acc @ epoch 35: 0.8551
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.4742550551891327
Local loss @ local epoch 1: 0.239484503865242
Local loss @ local epoch 2: 0.31550025939941406
Local loss @ local epoch 3: 0.18780048191547394
Local loss @ local epoch 4: 0.2669631242752075
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.16 seconds!
[tester] 
AGNewsMetric: acc=0.8111842105263158, hinge=1.2259549868734259, ce=7.314428321436832
Local test acc @ epoch 35: 0.8112
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.4217451214790344
Local loss @ local epoch 1: 0.37371590733528137
Local loss @ local epoch 2: 0.2403983473777771
Local loss @ local epoch 3: 0.24596495926380157
Local loss @ local epoch 4: 0.26457056403160095
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.06 seconds!
[tester] 
AGNewsMetric: acc=0.8127631578947369, hinge=1.0833003355327406, ce=7.7633945083618165
Local test acc @ epoch 35: 0.8128
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.18034705519676208
Local loss @ local epoch 1: 0.22728808224201202
Local loss @ local epoch 2: 0.09323985129594803
Local loss @ local epoch 3: 0.11441666632890701
Local loss @ local epoch 4: 0.19826972484588623
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.35 seconds!
[tester] 
AGNewsMetric: acc=0.8609210526315789, hinge=0.8928116170983565, ce=9.75960091038754
Local test acc @ epoch 35: 0.8609
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.36282944679260254
Local loss @ local epoch 1: 0.4190118908882141
Local loss @ local epoch 2: 0.34583261609077454
Local loss @ local epoch 3: 0.367019385099411
Local loss @ local epoch 4: 0.3661947250366211
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.03 seconds!
[tester] 
AGNewsMetric: acc=0.8631578947368421, hinge=0.9258121204376221, ce=6.368307802300704
Local test acc @ epoch 35: 0.8632
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.18146958947181702
Local loss @ local epoch 1: 0.82594233751297
Local loss @ local epoch 2: 0.21080096065998077
Local loss @ local epoch 3: 0.12804293632507324
Local loss @ local epoch 4: 0.18678294122219086
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.93 seconds!
[tester] 
AGNewsMetric: acc=0.8382894736842105, hinge=1.035803212617573, ce=9.151281716196161
Local test acc @ epoch 35: 0.8383
Global evaluate on test data...
Evaluate data in 128.62 seconds!
[tester] 
AGNewsMetric: acc=0.8811842105263158, hinge=0.8029598572379665, ce=7.717976258930407
Global test acc @ epoch 35: 0.8812
Global epoch 36...
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.19838957488536835
Local loss @ local epoch 1: 0.5620256662368774
Local loss @ local epoch 2: 0.4706598222255707
Local loss @ local epoch 3: 0.15353824198246002
Local loss @ local epoch 4: 0.25672638416290283
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.67 seconds!
[tester] 
AGNewsMetric: acc=0.8761842105263158, hinge=0.8403979672883686, ce=6.944863595460591
Local test acc @ epoch 36: 0.8762
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.26792576909065247
Local loss @ local epoch 1: 0.18282291293144226
Local loss @ local epoch 2: 0.20005935430526733
Local loss @ local epoch 3: 0.9248477816581726
Local loss @ local epoch 4: 0.19576551020145416
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.76 seconds!
[tester] 
AGNewsMetric: acc=0.7863157894736842, hinge=1.3379428411784926, ce=8.010385118785658
Local test acc @ epoch 36: 0.7863
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0703655555844307
Local loss @ local epoch 1: 0.06235765665769577
Local loss @ local epoch 2: 0.04588150233030319
Local loss @ local epoch 3: 0.04882044717669487
Local loss @ local epoch 4: 0.022339124232530594
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.24 seconds!
[tester] 
AGNewsMetric: acc=0.8078947368421052, hinge=1.6335797362578544, ce=7.441590495862459
Local test acc @ epoch 36: 0.8079
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.3958226144313812
Local loss @ local epoch 1: 0.3753058910369873
Local loss @ local epoch 2: 0.3192104995250702
Local loss @ local epoch 3: 0.3261067569255829
Local loss @ local epoch 4: 0.2517072260379791
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.2 seconds!
[tester] 
AGNewsMetric: acc=0.8230263157894737, hinge=1.1451799217023348, ce=7.028360770376105
Local test acc @ epoch 36: 0.823
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.09057750552892685
Local loss @ local epoch 1: 0.3864900767803192
Local loss @ local epoch 2: 0.14845095574855804
Local loss @ local epoch 3: 0.2315341681241989
Local loss @ local epoch 4: 0.26422956585884094
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.4 seconds!
[tester] 
AGNewsMetric: acc=0.8653947368421052, hinge=0.875797875554938, ce=9.670443902266653
Local test acc @ epoch 36: 0.8654
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.20614643394947052
Local loss @ local epoch 1: 0.1087416559457779
Local loss @ local epoch 2: 0.22761322557926178
Local loss @ local epoch 3: 0.16801831126213074
Local loss @ local epoch 4: 0.1988837569952011
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.45 seconds!
[tester] 
AGNewsMetric: acc=0.8556578947368421, hinge=1.124018655827171, ce=8.934856167843467
Local test acc @ epoch 36: 0.8557
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.2922336757183075
Local loss @ local epoch 1: 0.2550194561481476
Local loss @ local epoch 2: 0.22996392846107483
Local loss @ local epoch 3: 0.09002078324556351
Local loss @ local epoch 4: 0.1866230070590973
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.76 seconds!
[tester] 
AGNewsMetric: acc=0.7572368421052632, hinge=1.4675757970308003, ce=5.927882205561588
Local test acc @ epoch 36: 0.7572
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.053238917142152786
Local loss @ local epoch 1: 0.024015896022319794
Local loss @ local epoch 2: 0.0190159622579813
Local loss @ local epoch 3: 0.02240953966975212
Local loss @ local epoch 4: 0.040633752942085266
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.17 seconds!
[tester] 
AGNewsMetric: acc=0.8631578947368421, hinge=0.8999218569303814, ce=7.246311539097836
Local test acc @ epoch 36: 0.8632
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.4272257685661316
Local loss @ local epoch 1: 0.5656721591949463
Local loss @ local epoch 2: 0.691676914691925
Local loss @ local epoch 3: 0.379408061504364
Local loss @ local epoch 4: 0.52541184425354
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.99 seconds!
[tester] 
AGNewsMetric: acc=0.8135526315789474, hinge=1.1180989405983373, ce=7.327576737654836
Local test acc @ epoch 36: 0.8136
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.10488031804561615
Local loss @ local epoch 1: 0.609343945980072
Local loss @ local epoch 2: 0.4072825312614441
Local loss @ local epoch 3: 0.07361534237861633
Local loss @ local epoch 4: 0.07931038737297058
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.47 seconds!
[tester] 
AGNewsMetric: acc=0.859078947368421, hinge=0.891858703713668, ce=8.415534553527833
Local test acc @ epoch 36: 0.8591
Global evaluate on test data...
Evaluate data in 129.7 seconds!
[tester] 
AGNewsMetric: acc=0.8798684210526316, hinge=0.7962120221790514, ce=7.888746319821006
Global test acc @ epoch 36: 0.8799
Global epoch 37...
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.3309340178966522
Local loss @ local epoch 1: 0.15883170068264008
Local loss @ local epoch 2: 0.2747540771961212
Local loss @ local epoch 3: 0.8242571353912354
Local loss @ local epoch 4: 0.1721286028623581
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.47 seconds!
[tester] 
AGNewsMetric: acc=0.8168421052631579, hinge=1.2197165604641562, ce=7.498310914290578
Local test acc @ epoch 37: 0.8168
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.292815238237381
Local loss @ local epoch 1: 0.37446534633636475
Local loss @ local epoch 2: 0.35507211089134216
Local loss @ local epoch 3: 0.900501549243927
Local loss @ local epoch 4: 0.38869187235832214
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.37 seconds!
[tester] 
AGNewsMetric: acc=0.8535526315789473, hinge=0.9740843316128379, ce=6.55164722844174
Local test acc @ epoch 37: 0.8536
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.1832498461008072
Local loss @ local epoch 1: 0.18771235644817352
Local loss @ local epoch 2: 0.16556555032730103
Local loss @ local epoch 3: 0.15782903134822845
Local loss @ local epoch 4: 0.22409702837467194
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.17 seconds!
[tester] 
AGNewsMetric: acc=0.825, hinge=1.256699188633969, ce=4.96923622432508
Local test acc @ epoch 37: 0.825
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.47633153200149536
Local loss @ local epoch 1: 0.4387095272541046
Local loss @ local epoch 2: 0.49145767092704773
Local loss @ local epoch 3: 0.26639047265052795
Local loss @ local epoch 4: 0.35288143157958984
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.87 seconds!
[tester] 
AGNewsMetric: acc=0.83, hinge=1.0720152235031128, ce=8.151551204480622
Local test acc @ epoch 37: 0.83
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.05109415203332901
Local loss @ local epoch 1: 0.12992694973945618
Local loss @ local epoch 2: 0.03602595627307892
Local loss @ local epoch 3: 0.09173411875963211
Local loss @ local epoch 4: 0.03331758826971054
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.25 seconds!
[tester] 
AGNewsMetric: acc=0.8742105263157894, hinge=0.9186256270659597, ce=7.0754563723112405
Local test acc @ epoch 37: 0.8742
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.11754870414733887
Local loss @ local epoch 1: 0.09404554218053818
Local loss @ local epoch 2: 0.07624038308858871
Local loss @ local epoch 3: 0.10920140147209167
Local loss @ local epoch 4: 0.0826154425740242
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.48 seconds!
[tester] 
AGNewsMetric: acc=0.8647368421052631, hinge=0.9023206331855372, ce=7.68409184907612
Local test acc @ epoch 37: 0.8647
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.6827579140663147
Local loss @ local epoch 1: 0.7342028021812439
Local loss @ local epoch 2: 0.6120372414588928
Local loss @ local epoch 3: 0.6001291275024414
Local loss @ local epoch 4: 0.5487200617790222
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.48 seconds!
[tester] 
AGNewsMetric: acc=0.8443421052631579, hinge=0.9414605883548134, ce=8.54251198015715
Local test acc @ epoch 37: 0.8443
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.2894894778728485
Local loss @ local epoch 1: 0.10380401462316513
Local loss @ local epoch 2: 0.19703924655914307
Local loss @ local epoch 3: 0.15167716145515442
Local loss @ local epoch 4: 0.2640771269798279
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.3 seconds!
[tester] 
AGNewsMetric: acc=0.8189473684210526, hinge=1.0866814307162636, ce=7.469482218089857
Local test acc @ epoch 37: 0.8189
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.03398943319916725
Local loss @ local epoch 1: 0.04729261249303818
Local loss @ local epoch 2: 0.03750481456518173
Local loss @ local epoch 3: 0.048170462250709534
Local loss @ local epoch 4: 0.09955655783414841
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.62 seconds!
[tester] 
AGNewsMetric: acc=0.8513157894736842, hinge=0.9591509819030761, ce=7.56566520690918
Local test acc @ epoch 37: 0.8513
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.25161218643188477
Local loss @ local epoch 1: 0.162554070353508
Local loss @ local epoch 2: 0.0440581776201725
Local loss @ local epoch 3: 0.20422013103961945
Local loss @ local epoch 4: 1.9876042604446411
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.33 seconds!
[tester] 
AGNewsMetric: acc=0.6948684210526316, hinge=2.532280432048597, ce=8.723702747947291
Local test acc @ epoch 37: 0.6949
Global evaluate on test data...
Evaluate data in 129.51 seconds!
[tester] 
AGNewsMetric: acc=0.8814473684210526, hinge=0.8097825015218635, ce=7.497625905087119
Global test acc @ epoch 37: 0.8814
Global epoch 38...
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.048782266676425934
Local loss @ local epoch 1: 0.028693152591586113
Local loss @ local epoch 2: 0.04091760143637657
Local loss @ local epoch 3: 0.1116693839430809
Local loss @ local epoch 4: 0.031323567032814026
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.92 seconds!
[tester] 
AGNewsMetric: acc=0.8673684210526316, hinge=0.9179593793969405, ce=6.143085212707519
Local test acc @ epoch 38: 0.8674
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.3964366018772125
Local loss @ local epoch 1: 0.28678688406944275
Local loss @ local epoch 2: 0.5238139033317566
Local loss @ local epoch 3: 0.3762620687484741
Local loss @ local epoch 4: 0.5378808379173279
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.54 seconds!
[tester] 
AGNewsMetric: acc=0.8398684210526316, hinge=0.972852225052683, ce=6.5530271851389035
Local test acc @ epoch 38: 0.8399
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.2743574380874634
Local loss @ local epoch 1: 0.13158336281776428
Local loss @ local epoch 2: 0.04937942698597908
Local loss @ local epoch 3: 0.15528184175491333
Local loss @ local epoch 4: 0.11426545679569244
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.62 seconds!
[tester] 
AGNewsMetric: acc=0.8669736842105263, hinge=0.9578832508388319, ce=8.689293226944773
Local test acc @ epoch 38: 0.867
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.29125335812568665
Local loss @ local epoch 1: 0.2631348967552185
Local loss @ local epoch 2: 0.26474419236183167
Local loss @ local epoch 3: 0.43284979462623596
Local loss @ local epoch 4: 0.19686603546142578
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.16 seconds!
[tester] 
AGNewsMetric: acc=0.7473684210526316, hinge=2.2495239975577905, ce=8.5030728089182
Local test acc @ epoch 38: 0.7474
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.20690825581550598
Local loss @ local epoch 1: 0.20821461081504822
Local loss @ local epoch 2: 0.3097655177116394
Local loss @ local epoch 3: 0.3375060260295868
Local loss @ local epoch 4: 0.18917696177959442
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.26 seconds!
[tester] 
AGNewsMetric: acc=0.7926315789473685, hinge=1.3917255190799112, ce=7.894191784105803
Local test acc @ epoch 38: 0.7926
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.11701230704784393
Local loss @ local epoch 1: 0.3206399977207184
Local loss @ local epoch 2: 0.22809681296348572
Local loss @ local epoch 3: 0.05510159581899643
Local loss @ local epoch 4: 0.07635609805583954
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.51 seconds!
[tester] 
AGNewsMetric: acc=0.8415789473684211, hinge=1.0533624061785247, ce=7.039302523763556
Local test acc @ epoch 38: 0.8416
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.05603644251823425
Local loss @ local epoch 1: 0.08676151186227798
Local loss @ local epoch 2: 0.3335079252719879
Local loss @ local epoch 3: 0.21384337544441223
Local loss @ local epoch 4: 0.15449854731559753
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.63 seconds!
[tester] 
AGNewsMetric: acc=0.843421052631579, hinge=0.9799126434326172, ce=9.221788177490234
Local test acc @ epoch 38: 0.8434
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.31455209851264954
Local loss @ local epoch 1: 0.20440180599689484
Local loss @ local epoch 2: 0.11460445821285248
Local loss @ local epoch 3: 0.17781412601470947
Local loss @ local epoch 4: 0.32399094104766846
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.49 seconds!
[tester] 
AGNewsMetric: acc=0.8459210526315789, hinge=0.9167191324735943, ce=6.287351495843184
Local test acc @ epoch 38: 0.8459
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.19786739349365234
Local loss @ local epoch 1: 0.06521181762218475
Local loss @ local epoch 2: 0.04829282686114311
Local loss @ local epoch 3: 0.024382520467042923
Local loss @ local epoch 4: 0.020725363865494728
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.71 seconds!
[tester] 
AGNewsMetric: acc=0.8532894736842105, hinge=1.0890940962339701, ce=8.562191852770354
Local test acc @ epoch 38: 0.8533
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.5939953923225403
Local loss @ local epoch 1: 0.40313073992729187
Local loss @ local epoch 2: 0.5601867437362671
Local loss @ local epoch 3: 0.37860479950904846
Local loss @ local epoch 4: 0.395433634519577
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.36 seconds!
[tester] 
AGNewsMetric: acc=0.8694736842105263, hinge=0.8417826215844405, ce=7.761845098796644
Local test acc @ epoch 38: 0.8695
Global evaluate on test data...
Evaluate data in 129.68 seconds!
[tester] 
AGNewsMetric: acc=0.8809210526315789, hinge=0.8146055565382305, ce=7.140814124659488
Global test acc @ epoch 38: 0.8809
Global epoch 39...
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.035670213401317596
Local loss @ local epoch 1: 0.2090848833322525
Local loss @ local epoch 2: 0.028065189719200134
Local loss @ local epoch 3: 0.07485496252775192
Local loss @ local epoch 4: 0.04805086925625801
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.98 seconds!
[tester] 
AGNewsMetric: acc=0.863421052631579, hinge=1.016056728363037, ce=7.65172024777061
Local test acc @ epoch 39: 0.8634
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.452915757894516
Local loss @ local epoch 1: 0.33153703808784485
Local loss @ local epoch 2: 0.06840722262859344
Local loss @ local epoch 3: 0.13029012084007263
Local loss @ local epoch 4: 0.318722128868103
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.53 seconds!
[tester] 
AGNewsMetric: acc=0.8048684210526316, hinge=1.2787719447989212, ce=5.956808790909617
Local test acc @ epoch 39: 0.8049
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.6160228848457336
Local loss @ local epoch 1: 0.4794517755508423
Local loss @ local epoch 2: 0.3645147979259491
Local loss @ local epoch 3: 0.5140066146850586
Local loss @ local epoch 4: 0.34382858872413635
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.53 seconds!
[tester] 
AGNewsMetric: acc=0.8442105263157895, hinge=0.9917815725426925, ce=9.287979477330259
Local test acc @ epoch 39: 0.8442
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.1135527491569519
Local loss @ local epoch 1: 0.08693397045135498
Local loss @ local epoch 2: 0.052718985825777054
Local loss @ local epoch 3: 0.09917926043272018
Local loss @ local epoch 4: 0.16353322565555573
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.27 seconds!
[tester] 
AGNewsMetric: acc=0.8494736842105263, hinge=1.198015550312243, ce=6.790372021323756
Local test acc @ epoch 39: 0.8495
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.13859324157238007
Local loss @ local epoch 1: 0.11354920268058777
Local loss @ local epoch 2: 0.13123269379138947
Local loss @ local epoch 3: 0.05773511901497841
Local loss @ local epoch 4: 0.06601109355688095
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.91 seconds!
[tester] 
AGNewsMetric: acc=0.8706578947368421, hinge=0.8927630595157021, ce=7.013476129833021
Local test acc @ epoch 39: 0.8707
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.032260820269584656
Local loss @ local epoch 1: 0.09922723472118378
Local loss @ local epoch 2: 0.015304045751690865
Local loss @ local epoch 3: 0.03848002478480339
Local loss @ local epoch 4: 0.08246330916881561
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.98 seconds!
[tester] 
AGNewsMetric: acc=0.8646052631578948, hinge=1.1357511181580393, ce=7.798728850515265
Local test acc @ epoch 39: 0.8646
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.2800915539264679
Local loss @ local epoch 1: 0.18519888818264008
Local loss @ local epoch 2: 0.0820467621088028
Local loss @ local epoch 3: 0.31310904026031494
Local loss @ local epoch 4: 0.365820050239563
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.03 seconds!
[tester] 
AGNewsMetric: acc=0.8477631578947369, hinge=1.053953494021767, ce=6.110616173995169
Local test acc @ epoch 39: 0.8478
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.26990392804145813
Local loss @ local epoch 1: 0.2527623176574707
Local loss @ local epoch 2: 0.17697358131408691
Local loss @ local epoch 3: 0.29103896021842957
Local loss @ local epoch 4: 0.37822282314300537
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.85 seconds!
[tester] 
AGNewsMetric: acc=0.7640789473684211, hinge=1.5837636739329288, ce=7.8377473489861735
Local test acc @ epoch 39: 0.7641
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.16237115859985352
Local loss @ local epoch 1: 0.046878647059202194
Local loss @ local epoch 2: 0.6298955678939819
Local loss @ local epoch 3: 0.2061309516429901
Local loss @ local epoch 4: 0.11315451562404633
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.94 seconds!
[tester] 
AGNewsMetric: acc=0.8367105263157895, hinge=1.1282365919414319, ce=8.114552455701325
Local test acc @ epoch 39: 0.8367
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.3011651933193207
Local loss @ local epoch 1: 0.3352232873439789
Local loss @ local epoch 2: 0.17485056817531586
Local loss @ local epoch 3: 0.12283250689506531
Local loss @ local epoch 4: 0.3085162937641144
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.38 seconds!
[tester] 
AGNewsMetric: acc=0.8631578947368421, hinge=0.89381684278187, ce=6.975691857588918
Local test acc @ epoch 39: 0.8632
Global evaluate on test data...
Evaluate data in 129.87 seconds!
[tester] 
AGNewsMetric: acc=0.8759210526315789, hinge=0.8794934061953896, ce=7.356475337179083
Global test acc @ epoch 39: 0.8759
Global epoch 40...
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.2642185688018799
Local loss @ local epoch 1: 0.1380995512008667
Local loss @ local epoch 2: 0.07476229220628738
Local loss @ local epoch 3: 0.48475492000579834
Local loss @ local epoch 4: 0.20883819460868835
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.8 seconds!
[tester] 
AGNewsMetric: acc=0.8553947368421052, hinge=0.9820502313814665, ce=10.368805244847348
Local test acc @ epoch 40: 0.8554
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.1922227293252945
Local loss @ local epoch 1: 0.05170072987675667
Local loss @ local epoch 2: 0.051593441516160965
Local loss @ local epoch 3: 0.11802821606397629
Local loss @ local epoch 4: 0.1368899643421173
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.73 seconds!
[tester] 
AGNewsMetric: acc=0.8477631578947369, hinge=1.0720886009617856, ce=6.686722677130448
Local test acc @ epoch 40: 0.8478
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.41485023498535156
Local loss @ local epoch 1: 0.2019125521183014
Local loss @ local epoch 2: 0.17959368228912354
Local loss @ local epoch 3: 0.2556430697441101
Local loss @ local epoch 4: 0.24416285753250122
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.25 seconds!
[tester] 
AGNewsMetric: acc=0.8705263157894737, hinge=0.8840085606825979, ce=7.001441766839278
Local test acc @ epoch 40: 0.8705
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.1473991572856903
Local loss @ local epoch 1: 0.13555051386356354
Local loss @ local epoch 2: 0.10725650191307068
Local loss @ local epoch 3: 0.10786186158657074
Local loss @ local epoch 4: 0.2584173381328583
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.96 seconds!
[tester] 
AGNewsMetric: acc=0.7867105263157895, hinge=1.3576838325199327, ce=7.565495400679739
Local test acc @ epoch 40: 0.7867
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.059388667345047
Local loss @ local epoch 1: 0.031084353104233742
Local loss @ local epoch 2: 0.10800331830978394
Local loss @ local epoch 3: 0.05595274642109871
Local loss @ local epoch 4: 0.14321322739124298
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.23 seconds!
[tester] 
AGNewsMetric: acc=0.815921052631579, hinge=1.284433472783942, ce=9.386888243022717
Local test acc @ epoch 40: 0.8159
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.10561446845531464
Local loss @ local epoch 1: 0.07841497659683228
Local loss @ local epoch 2: 0.04103389009833336
Local loss @ local epoch 3: 0.018885988742113113
Local loss @ local epoch 4: 0.18240542709827423
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.63 seconds!
[tester] 
AGNewsMetric: acc=0.8657894736842106, hinge=1.0063690833041543, ce=8.546742126063297
Local test acc @ epoch 40: 0.8658
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.07896789163351059
Local loss @ local epoch 1: 0.3893056809902191
Local loss @ local epoch 2: 0.03374918922781944
Local loss @ local epoch 3: 0.1742677241563797
Local loss @ local epoch 4: 0.055203989148139954
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.3 seconds!
[tester] 
AGNewsMetric: acc=0.8697368421052631, hinge=0.8530159332877711, ce=5.789461144899067
Local test acc @ epoch 40: 0.8697
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.2574344575405121
Local loss @ local epoch 1: 0.3071938753128052
Local loss @ local epoch 2: 0.28032734990119934
Local loss @ local epoch 3: 0.23605097830295563
Local loss @ local epoch 4: 0.09816444665193558
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.14 seconds!
[tester] 
AGNewsMetric: acc=0.8464473684210526, hinge=1.0627237028824656, ce=4.259521355879934
Local test acc @ epoch 40: 0.8464
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.16962142288684845
Local loss @ local epoch 1: 0.08701514452695847
Local loss @ local epoch 2: 0.11024342477321625
Local loss @ local epoch 3: 0.09791100025177002
Local loss @ local epoch 4: 0.48124080896377563
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.84 seconds!
[tester] 
AGNewsMetric: acc=0.8210526315789474, hinge=1.3197446469256753, ce=5.63371307774594
Local test acc @ epoch 40: 0.8211
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.5766946077346802
Local loss @ local epoch 1: 0.4712371826171875
Local loss @ local epoch 2: 0.806132435798645
Local loss @ local epoch 3: 0.3575778603553772
Local loss @ local epoch 4: 0.37547528743743896
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.92 seconds!
[tester] 
AGNewsMetric: acc=0.8598684210526316, hinge=0.8592241638585141, ce=7.025171675431101
Local test acc @ epoch 40: 0.8599
Global evaluate on test data...
Evaluate data in 129.99 seconds!
[tester] 
AGNewsMetric: acc=0.8856578947368421, hinge=0.8095511993608977, ce=7.466303070469906
Global test acc @ epoch 40: 0.8857
Global epoch 41...
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.8141718506813049
Local loss @ local epoch 1: 0.44814643263816833
Local loss @ local epoch 2: 0.5629067420959473
Local loss @ local epoch 3: 0.4939749538898468
Local loss @ local epoch 4: 0.3092781603336334
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 131.27 seconds!
[tester] 
AGNewsMetric: acc=0.8453947368421053, hinge=0.9918482213271291, ce=7.453881516707571
Local test acc @ epoch 41: 0.8454
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.02432943694293499
Local loss @ local epoch 1: 0.1710180640220642
Local loss @ local epoch 2: 0.10150031745433807
Local loss @ local epoch 3: 0.02738545462489128
Local loss @ local epoch 4: 0.09374392032623291
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.96 seconds!
[tester] 
AGNewsMetric: acc=0.8397368421052631, hinge=1.0180009701377468, ce=5.59996441389385
Local test acc @ epoch 41: 0.8397
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.14381906390190125
Local loss @ local epoch 1: 0.24369826912879944
Local loss @ local epoch 2: 0.07993393391370773
Local loss @ local epoch 3: 0.1042211651802063
Local loss @ local epoch 4: 0.12004044651985168
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.77 seconds!
[tester] 
AGNewsMetric: acc=0.8692105263157894, hinge=0.8430078145077354, ce=5.209599389527973
Local test acc @ epoch 41: 0.8692
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.06143365800380707
Local loss @ local epoch 1: 0.06045956909656525
Local loss @ local epoch 2: 0.01703263260424137
Local loss @ local epoch 3: 0.0651780515909195
Local loss @ local epoch 4: 0.032915208488702774
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.86 seconds!
[tester] 
AGNewsMetric: acc=0.8461842105263158, hinge=1.1422467723645662, ce=4.730549534245541
Local test acc @ epoch 41: 0.8462
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.26560771465301514
Local loss @ local epoch 1: 0.2970874309539795
Local loss @ local epoch 2: 0.2762621343135834
Local loss @ local epoch 3: 0.1576516330242157
Local loss @ local epoch 4: 0.44589048624038696
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.53 seconds!
[tester] 
AGNewsMetric: acc=0.809078947368421, hinge=1.2267912663911518, ce=7.15693187312076
Local test acc @ epoch 41: 0.8091
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.10598568618297577
Local loss @ local epoch 1: 0.06515045464038849
Local loss @ local epoch 2: 0.09888671338558197
Local loss @ local epoch 3: 0.26217979192733765
Local loss @ local epoch 4: 0.21282115578651428
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.86 seconds!
[tester] 
AGNewsMetric: acc=0.8648684210526316, hinge=0.9409810086300499, ce=5.4393065944470855
Local test acc @ epoch 41: 0.8649
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.2728883624076843
Local loss @ local epoch 1: 0.32486188411712646
Local loss @ local epoch 2: 0.15459756553173065
Local loss @ local epoch 3: 0.08937687426805496
Local loss @ local epoch 4: 0.12255243957042694
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.69 seconds!
[tester] 
AGNewsMetric: acc=0.8622368421052632, hinge=0.9460047405644467, ce=8.342328190050628
Local test acc @ epoch 41: 0.8622
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.05949122831225395
Local loss @ local epoch 1: 0.1319408267736435
Local loss @ local epoch 2: 0.05878671258687973
Local loss @ local epoch 3: 0.15724602341651917
Local loss @ local epoch 4: 0.026440957561135292
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.25 seconds!
[tester] 
AGNewsMetric: acc=0.8146052631578947, hinge=1.3785904969667133, ce=6.689385411111932
Local test acc @ epoch 41: 0.8146
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.20027685165405273
Local loss @ local epoch 1: 0.1929367631673813
Local loss @ local epoch 2: 0.14283885061740875
Local loss @ local epoch 3: 0.11728911846876144
Local loss @ local epoch 4: 0.20951686799526215
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.43 seconds!
[tester] 
AGNewsMetric: acc=0.8352631578947368, hinge=1.1660597482480501, ce=8.47714614868164
Local test acc @ epoch 41: 0.8353
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.24445374310016632
Local loss @ local epoch 1: 0.3091716468334198
Local loss @ local epoch 2: 0.3381519615650177
Local loss @ local epoch 3: 0.39893922209739685
Local loss @ local epoch 4: 0.32820454239845276
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.86 seconds!
[tester] 
AGNewsMetric: acc=0.8505263157894737, hinge=1.1653406356510363, ce=7.319209936041581
Local test acc @ epoch 41: 0.8505
Global evaluate on test data...
Evaluate data in 129.79 seconds!
[tester] 
AGNewsMetric: acc=0.8794736842105263, hinge=0.839373029407702, ce=6.36051342010498
Global test acc @ epoch 41: 0.8795
Global epoch 42...
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0809369906783104
Local loss @ local epoch 1: 0.055660031735897064
Local loss @ local epoch 2: 0.21063698828220367
Local loss @ local epoch 3: 0.17256499826908112
Local loss @ local epoch 4: 0.35674312710762024
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.17 seconds!
[tester] 
AGNewsMetric: acc=0.85, hinge=1.0317180593390214, ce=6.415438558678878
Local test acc @ epoch 42: 0.85
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.2976526916027069
Local loss @ local epoch 1: 0.13182397186756134
Local loss @ local epoch 2: 0.14943617582321167
Local loss @ local epoch 3: 0.08978288620710373
Local loss @ local epoch 4: 0.08262220025062561
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.94 seconds!
[tester] 
AGNewsMetric: acc=0.8143421052631579, hinge=1.209331777974179, ce=6.231437540556255
Local test acc @ epoch 42: 0.8143
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0614202544093132
Local loss @ local epoch 1: 0.01444181613624096
Local loss @ local epoch 2: 0.0703670009970665
Local loss @ local epoch 3: 0.020032411441206932
Local loss @ local epoch 4: 0.09499624371528625
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.58 seconds!
[tester] 
AGNewsMetric: acc=0.8569736842105263, hinge=1.0435995536101492, ce=7.184801856593082
Local test acc @ epoch 42: 0.857
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.042374882847070694
Local loss @ local epoch 1: 0.0681927427649498
Local loss @ local epoch 2: 0.0543706975877285
Local loss @ local epoch 3: 0.11307575553655624
Local loss @ local epoch 4: 0.09195400029420853
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.94 seconds!
[tester] 
AGNewsMetric: acc=0.8661842105263158, hinge=0.9067141989657753, ce=5.685216497120105
Local test acc @ epoch 42: 0.8662
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.02519180253148079
Local loss @ local epoch 1: 0.6852638125419617
Local loss @ local epoch 2: 0.023503990843892097
Local loss @ local epoch 3: 0.04519953206181526
Local loss @ local epoch 4: 0.037895798683166504
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.61 seconds!
[tester] 
AGNewsMetric: acc=0.8425, hinge=1.0744942378997804, ce=6.968257723356548
Local test acc @ epoch 42: 0.8425
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.32639822363853455
Local loss @ local epoch 1: 0.4605928659439087
Local loss @ local epoch 2: 0.16878817975521088
Local loss @ local epoch 3: 0.24788308143615723
Local loss @ local epoch 4: 0.26537594199180603
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.58 seconds!
[tester] 
AGNewsMetric: acc=0.7867105263157895, hinge=1.398524314478824, ce=6.308504186931409
Local test acc @ epoch 42: 0.7867
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.29105836153030396
Local loss @ local epoch 1: 0.5102273225784302
Local loss @ local epoch 2: 0.09233790636062622
Local loss @ local epoch 3: 0.5637513995170593
Local loss @ local epoch 4: 0.2674940526485443
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.56 seconds!
[tester] 
AGNewsMetric: acc=0.799078947368421, hinge=1.5540117168426513, ce=9.918948948508815
Local test acc @ epoch 42: 0.7991
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.40345999598503113
Local loss @ local epoch 1: 0.4593478739261627
Local loss @ local epoch 2: 0.33614280819892883
Local loss @ local epoch 3: 0.3497191071510315
Local loss @ local epoch 4: 0.28348156809806824
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.18 seconds!
[tester] 
AGNewsMetric: acc=0.8492105263157895, hinge=0.9458087409170051, ce=8.86049194536711
Local test acc @ epoch 42: 0.8492
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.15940138697624207
Local loss @ local epoch 1: 0.20111511647701263
Local loss @ local epoch 2: 0.0668167769908905
Local loss @ local epoch 3: 0.17828324437141418
Local loss @ local epoch 4: 0.4870750904083252
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.71 seconds!
[tester] 
AGNewsMetric: acc=0.7548684210526316, hinge=1.5739323480505691, ce=8.008576063858836
Local test acc @ epoch 42: 0.7549
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.06707937270402908
Local loss @ local epoch 1: 0.024384845048189163
Local loss @ local epoch 2: 0.050782106816768646
Local loss @ local epoch 3: 0.046476587653160095
Local loss @ local epoch 4: 0.02810525707900524
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.29 seconds!
[tester] 
AGNewsMetric: acc=0.8728947368421053, hinge=0.9795913859417564, ce=6.213180232800935
Local test acc @ epoch 42: 0.8729
Global evaluate on test data...
Evaluate data in 130.95 seconds!
[tester] 
AGNewsMetric: acc=0.875, hinge=0.8604080912941381, ce=7.712514186658358
Global test acc @ epoch 42: 0.875
Global epoch 43...
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.10276667773723602
Local loss @ local epoch 1: 0.028265561908483505
Local loss @ local epoch 2: 0.0577290877699852
Local loss @ local epoch 3: 0.14955949783325195
Local loss @ local epoch 4: 0.083350270986557
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.86 seconds!
[tester] 
AGNewsMetric: acc=0.8693421052631579, hinge=0.869634128871717, ce=9.418928927371377
Local test acc @ epoch 43: 0.8693
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.09370338916778564
Local loss @ local epoch 1: 0.04470308870077133
Local loss @ local epoch 2: 0.03275073319673538
Local loss @ local epoch 3: 0.05797174200415611
Local loss @ local epoch 4: 0.04694477096199989
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.48 seconds!
[tester] 
AGNewsMetric: acc=0.8503947368421053, hinge=1.1325091999455503, ce=8.633809736151445
Local test acc @ epoch 43: 0.8504
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.30936214327812195
Local loss @ local epoch 1: 0.14231298863887787
Local loss @ local epoch 2: 0.23677586019039154
Local loss @ local epoch 3: 0.06590652465820312
Local loss @ local epoch 4: 0.08025890588760376
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.52 seconds!
[tester] 
AGNewsMetric: acc=0.7232894736842105, hinge=1.9699343596006695, ce=6.358227795048764
Local test acc @ epoch 43: 0.7233
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.26821115612983704
Local loss @ local epoch 1: 0.1985393613576889
Local loss @ local epoch 2: 0.27399492263793945
Local loss @ local epoch 3: 0.1633744239807129
Local loss @ local epoch 4: 0.11069198697805405
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.07 seconds!
[tester] 
AGNewsMetric: acc=0.814078947368421, hinge=1.2182311755732487, ce=5.553171113666735
Local test acc @ epoch 43: 0.8141
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.05277761071920395
Local loss @ local epoch 1: 0.05933758616447449
Local loss @ local epoch 2: 0.017324045300483704
Local loss @ local epoch 3: 0.020070787519216537
Local loss @ local epoch 4: 0.6488571166992188
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.46 seconds!
[tester] 
AGNewsMetric: acc=0.8471052631578947, hinge=1.0470572295941805, ce=7.828588446566933
Local test acc @ epoch 43: 0.8471
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.14887264370918274
Local loss @ local epoch 1: 0.44440212845802307
Local loss @ local epoch 2: 0.18438878655433655
Local loss @ local epoch 3: 0.16277244687080383
Local loss @ local epoch 4: 0.25365328788757324
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.83 seconds!
[tester] 
AGNewsMetric: acc=0.859078947368421, hinge=0.8883907629314222, ce=6.80865976835552
Local test acc @ epoch 43: 0.8591
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.6203484535217285
Local loss @ local epoch 1: 0.7296816110610962
Local loss @ local epoch 2: 0.4243485629558563
Local loss @ local epoch 3: 0.4125029444694519
Local loss @ local epoch 4: 0.40216296911239624
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.56 seconds!
[tester] 
AGNewsMetric: acc=0.8518421052631578, hinge=0.9483166278036017, ce=7.204271198071932
Local test acc @ epoch 43: 0.8518
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.2258092164993286
Local loss @ local epoch 1: 0.05840607360005379
Local loss @ local epoch 2: 0.18155498802661896
Local loss @ local epoch 3: 0.2574916183948517
Local loss @ local epoch 4: 0.6135819554328918
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.02 seconds!
[tester] 
AGNewsMetric: acc=0.8098684210526316, hinge=1.325033541227642, ce=6.365369108099687
Local test acc @ epoch 43: 0.8099
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.04143653064966202
Local loss @ local epoch 1: 0.05504994839429855
Local loss @ local epoch 2: 0.09392866492271423
Local loss @ local epoch 3: 0.17352831363677979
Local loss @ local epoch 4: 0.290068656206131
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.79 seconds!
[tester] 
AGNewsMetric: acc=0.8002631578947368, hinge=1.2887028764423571, ce=7.918365848942807
Local test acc @ epoch 43: 0.8003
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.05218447744846344
Local loss @ local epoch 1: 0.1021498292684555
Local loss @ local epoch 2: 0.04899586737155914
Local loss @ local epoch 3: 0.11071319878101349
Local loss @ local epoch 4: 0.006784259807318449
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.23 seconds!
[tester] 
AGNewsMetric: acc=0.8623684210526316, hinge=1.0403198395277324, ce=8.22408514123214
Local test acc @ epoch 43: 0.8624
Global evaluate on test data...
Evaluate data in 129.82 seconds!
[tester] 
AGNewsMetric: acc=0.8827631578947368, hinge=0.8843099935431229, ce=7.414025601838764
Global test acc @ epoch 43: 0.8828
Global epoch 44...
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.13233859837055206
Local loss @ local epoch 1: 0.24092920124530792
Local loss @ local epoch 2: 0.24924199283123016
Local loss @ local epoch 3: 0.0911792740225792
Local loss @ local epoch 4: 0.2667580842971802
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.92 seconds!
[tester] 
AGNewsMetric: acc=0.8294736842105264, hinge=1.012587349038375, ce=6.6817647682993035
Local test acc @ epoch 44: 0.8295
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.11458360403776169
Local loss @ local epoch 1: 0.4869830906391144
Local loss @ local epoch 2: 0.31312617659568787
Local loss @ local epoch 3: 0.30754050612449646
Local loss @ local epoch 4: 0.48194146156311035
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.03 seconds!
[tester] 
AGNewsMetric: acc=0.8430263157894737, hinge=1.0032357958743447, ce=6.543512145594547
Local test acc @ epoch 44: 0.843
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.021755166351795197
Local loss @ local epoch 1: 0.013415854424238205
Local loss @ local epoch 2: 0.05612386763095856
Local loss @ local epoch 3: 0.02174421399831772
Local loss @ local epoch 4: 0.007673698477447033
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.35 seconds!
[tester] 
AGNewsMetric: acc=0.8247368421052632, hinge=1.485548099467629, ce=6.284337412181653
Local test acc @ epoch 44: 0.8247
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.21877360343933105
Local loss @ local epoch 1: 0.27229955792427063
Local loss @ local epoch 2: 0.1280522346496582
Local loss @ local epoch 3: 0.1310955286026001
Local loss @ local epoch 4: 0.1553596705198288
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.58 seconds!
[tester] 
AGNewsMetric: acc=0.7893421052631578, hinge=1.6942862033843995, ce=7.270844184473941
Local test acc @ epoch 44: 0.7893
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.04109668731689453
Local loss @ local epoch 1: 0.03914805129170418
Local loss @ local epoch 2: 0.02935732528567314
Local loss @ local epoch 3: 0.06250344216823578
Local loss @ local epoch 4: 0.2716262936592102
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.04 seconds!
[tester] 
AGNewsMetric: acc=0.8517105263157895, hinge=1.0256050792493319, ce=7.842957446449681
Local test acc @ epoch 44: 0.8517
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.3239266276359558
Local loss @ local epoch 1: 0.18838058412075043
Local loss @ local epoch 2: 0.16216601431369781
Local loss @ local epoch 3: 0.09818801283836365
Local loss @ local epoch 4: 0.1612565964460373
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.73 seconds!
[tester] 
AGNewsMetric: acc=0.8459210526315789, hinge=1.0505443643268786, ce=6.279665872674239
Local test acc @ epoch 44: 0.8459
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.032391633838415146
Local loss @ local epoch 1: 0.14905983209609985
Local loss @ local epoch 2: 0.02370670810341835
Local loss @ local epoch 3: 0.15949709713459015
Local loss @ local epoch 4: 0.28468120098114014
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.3 seconds!
[tester] 
AGNewsMetric: acc=0.8701315789473684, hinge=0.9046943205281308, ce=6.4641986445376745
Local test acc @ epoch 44: 0.8701
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.027168504893779755
Local loss @ local epoch 1: 0.19034190475940704
Local loss @ local epoch 2: 0.2445768415927887
Local loss @ local epoch 3: 0.16076649725437164
Local loss @ local epoch 4: 0.2504967749118805
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.65 seconds!
[tester] 
AGNewsMetric: acc=0.834078947368421, hinge=1.1017949189637837, ce=6.922842938272576
Local test acc @ epoch 44: 0.8341
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.2045423686504364
Local loss @ local epoch 1: 0.29488760232925415
Local loss @ local epoch 2: 0.2808118462562561
Local loss @ local epoch 3: 0.2595655620098114
Local loss @ local epoch 4: 0.2624801695346832
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.99 seconds!
[tester] 
AGNewsMetric: acc=0.8486842105263158, hinge=0.9564356432462994, ce=8.757274623670076
Local test acc @ epoch 44: 0.8487
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.4877347946166992
Local loss @ local epoch 1: 0.5216281414031982
Local loss @ local epoch 2: 0.45131754875183105
Local loss @ local epoch 3: 0.4855881929397583
Local loss @ local epoch 4: 0.3521713316440582
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.59 seconds!
[tester] 
AGNewsMetric: acc=0.834078947368421, hinge=1.1234052050741095, ce=6.215007193715949
Local test acc @ epoch 44: 0.8341
Global evaluate on test data...
Evaluate data in 130.55 seconds!
[tester] 
AGNewsMetric: acc=0.881578947368421, hinge=0.8143304295288889, ce=7.5895692624543845
Global test acc @ epoch 44: 0.8816
Global epoch 45...
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.030426843091845512
Local loss @ local epoch 1: 0.054907042533159256
Local loss @ local epoch 2: 0.019907446578145027
Local loss @ local epoch 3: 0.01840752735733986
Local loss @ local epoch 4: 0.29130709171295166
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.01 seconds!
[tester] 
AGNewsMetric: acc=0.8607894736842105, hinge=1.0616211971483733, ce=7.100788350356253
Local test acc @ epoch 45: 0.8608
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.3370639383792877
Local loss @ local epoch 1: 0.4318265914916992
Local loss @ local epoch 2: 0.1537216752767563
Local loss @ local epoch 3: 0.30416956543922424
Local loss @ local epoch 4: 0.25273406505584717
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.76 seconds!
[tester] 
AGNewsMetric: acc=0.8409210526315789, hinge=1.007528402428878, ce=8.74692871896844
Local test acc @ epoch 45: 0.8409
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.05258234217762947
Local loss @ local epoch 1: 0.05269688740372658
Local loss @ local epoch 2: 0.03969281539320946
Local loss @ local epoch 3: 0.040499426424503326
Local loss @ local epoch 4: 0.309015154838562
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.13 seconds!
[tester] 
AGNewsMetric: acc=0.8436842105263158, hinge=1.3394335485759534, ce=6.808416957855225
Local test acc @ epoch 45: 0.8437
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.19511884450912476
Local loss @ local epoch 1: 0.1392463743686676
Local loss @ local epoch 2: 0.11298681795597076
Local loss @ local epoch 3: 0.06817163527011871
Local loss @ local epoch 4: 0.3804747462272644
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.19 seconds!
[tester] 
AGNewsMetric: acc=0.7742105263157895, hinge=1.5574286581340588, ce=6.858117886593467
Local test acc @ epoch 45: 0.7742
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.14045612514019012
Local loss @ local epoch 1: 0.23814868927001953
Local loss @ local epoch 2: 0.1545012891292572
Local loss @ local epoch 3: 0.19541147351264954
Local loss @ local epoch 4: 0.1687532663345337
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.97 seconds!
[tester] 
AGNewsMetric: acc=0.8559210526315789, hinge=1.0849785162273207, ce=7.071086889568128
Local test acc @ epoch 45: 0.8559
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.09500622749328613
Local loss @ local epoch 1: 0.3434648811817169
Local loss @ local epoch 2: 0.17257797718048096
Local loss @ local epoch 3: 0.058283958584070206
Local loss @ local epoch 4: 0.14291074872016907
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.9 seconds!
[tester] 
AGNewsMetric: acc=0.8697368421052631, hinge=0.9692385063673321, ce=4.827232286553634
Local test acc @ epoch 45: 0.8697
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.016788970679044724
Local loss @ local epoch 1: 0.20646625757217407
Local loss @ local epoch 2: 0.2039635181427002
Local loss @ local epoch 3: 0.013768980279564857
Local loss @ local epoch 4: 0.02083551324903965
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.36 seconds!
[tester] 
AGNewsMetric: acc=0.8748684210526316, hinge=0.9022039724651136, ce=8.452399840103952
Local test acc @ epoch 45: 0.8749
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.14478813111782074
Local loss @ local epoch 1: 0.09333672374486923
Local loss @ local epoch 2: 0.07328571379184723
Local loss @ local epoch 3: 0.16227202117443085
Local loss @ local epoch 4: 0.07200143486261368
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.26 seconds!
[tester] 
AGNewsMetric: acc=0.8743421052631579, hinge=0.8774310895016318, ce=6.887922474710565
Local test acc @ epoch 45: 0.8743
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.2489360272884369
Local loss @ local epoch 1: 0.4573945999145508
Local loss @ local epoch 2: 0.5469542741775513
Local loss @ local epoch 3: 0.5192345976829529
Local loss @ local epoch 4: 0.34681448340415955
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.7 seconds!
[tester] 
AGNewsMetric: acc=0.8764473684210526, hinge=0.8120980689400121, ce=7.386478701139751
Local test acc @ epoch 45: 0.8764
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.10869860649108887
Local loss @ local epoch 1: 0.2411658763885498
Local loss @ local epoch 2: 0.5633728504180908
Local loss @ local epoch 3: 0.4814755618572235
Local loss @ local epoch 4: 0.23824192583560944
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.43 seconds!
[tester] 
AGNewsMetric: acc=0.8528947368421053, hinge=0.9509245378092716, ce=6.695988593854402
Local test acc @ epoch 45: 0.8529
Global evaluate on test data...
Evaluate data in 129.9 seconds!
[tester] 
AGNewsMetric: acc=0.8806578947368421, hinge=0.8740509040732133, ce=7.246795092130962
Global test acc @ epoch 45: 0.8807
Global epoch 46...
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.26958638429641724
Local loss @ local epoch 1: 0.3051881790161133
Local loss @ local epoch 2: 0.21473243832588196
Local loss @ local epoch 3: 0.19963963329792023
Local loss @ local epoch 4: 0.12161661684513092
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.07 seconds!
[tester] 
AGNewsMetric: acc=0.8467105263157895, hinge=0.9556523197575619, ce=7.103099346160889
Local test acc @ epoch 46: 0.8467
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.3982003927230835
Local loss @ local epoch 1: 0.07815109938383102
Local loss @ local epoch 2: 0.17912980914115906
Local loss @ local epoch 3: 0.11520101875066757
Local loss @ local epoch 4: 0.37020108103752136
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.84 seconds!
[tester] 
AGNewsMetric: acc=0.6907894736842105, hinge=2.362762767139234, ce=8.917333173249897
Local test acc @ epoch 46: 0.6908
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.06281435489654541
Local loss @ local epoch 1: 0.2869352400302887
Local loss @ local epoch 2: 0.3523491322994232
Local loss @ local epoch 3: 0.07949839532375336
Local loss @ local epoch 4: 0.17218048870563507
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.01 seconds!
[tester] 
AGNewsMetric: acc=0.8372368421052632, hinge=1.022848118480883, ce=7.80810955248381
Local test acc @ epoch 46: 0.8372
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.009457808919250965
Local loss @ local epoch 1: 0.0444965697824955
Local loss @ local epoch 2: 0.02618214301764965
Local loss @ local epoch 3: 0.014201268553733826
Local loss @ local epoch 4: 0.6372391581535339
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.61 seconds!
[tester] 
AGNewsMetric: acc=0.8219736842105263, hinge=1.549026326380278, ce=8.478447771574322
Local test acc @ epoch 46: 0.822
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.040705617517232895
Local loss @ local epoch 1: 0.029173055663704872
Local loss @ local epoch 2: 0.0432194247841835
Local loss @ local epoch 3: 0.21967270970344543
Local loss @ local epoch 4: 0.06981459259986877
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.45 seconds!
[tester] 
AGNewsMetric: acc=0.8528947368421053, hinge=1.0022990753776149, ce=8.177641119706003
Local test acc @ epoch 46: 0.8529
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.3324575424194336
Local loss @ local epoch 1: 0.5255029797554016
Local loss @ local epoch 2: 0.6319110989570618
Local loss @ local epoch 3: 0.48254019021987915
Local loss @ local epoch 4: 0.30645373463630676
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.91 seconds!
[tester] 
AGNewsMetric: acc=0.8417105263157895, hinge=0.9641886339689556, ce=7.964374148720189
Local test acc @ epoch 46: 0.8417
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.2559140622615814
Local loss @ local epoch 1: 0.20573945343494415
Local loss @ local epoch 2: 0.22744090855121613
Local loss @ local epoch 3: 0.2930765748023987
Local loss @ local epoch 4: 0.24759747087955475
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.19 seconds!
[tester] 
AGNewsMetric: acc=0.81, hinge=1.149329450004979, ce=7.804122631675319
Local test acc @ epoch 46: 0.81
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.38665130734443665
Local loss @ local epoch 1: 0.20396021008491516
Local loss @ local epoch 2: 0.0711311548948288
Local loss @ local epoch 3: 0.21327437460422516
Local loss @ local epoch 4: 0.23494069278240204
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.13 seconds!
[tester] 
AGNewsMetric: acc=0.8203947368421053, hinge=1.194010641700343, ce=5.272393988559121
Local test acc @ epoch 46: 0.8204
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.11097008734941483
Local loss @ local epoch 1: 0.11624498665332794
Local loss @ local epoch 2: 0.06580900400876999
Local loss @ local epoch 3: 0.4331548810005188
Local loss @ local epoch 4: 0.12817656993865967
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.38 seconds!
[tester] 
AGNewsMetric: acc=0.8576315789473684, hinge=1.0628879117965697, ce=4.840502488989579
Local test acc @ epoch 46: 0.8576
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.012640105560421944
Local loss @ local epoch 1: 0.02481616660952568
Local loss @ local epoch 2: 0.059526361525058746
Local loss @ local epoch 3: 0.6151439547538757
Local loss @ local epoch 4: 0.00907860603183508
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.18 seconds!
[tester] 
AGNewsMetric: acc=0.8465789473684211, hinge=1.115847830521433, ce=7.558917786447625
Local test acc @ epoch 46: 0.8466
Global evaluate on test data...
Evaluate data in 130.18 seconds!
[tester] 
AGNewsMetric: acc=0.8828947368421053, hinge=0.8503762099617406, ce=7.299846759595369
Global test acc @ epoch 46: 0.8829
Global epoch 47...
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0366956889629364
Local loss @ local epoch 1: 0.032363615930080414
Local loss @ local epoch 2: 0.030881909653544426
Local loss @ local epoch 3: 0.008589173667132854
Local loss @ local epoch 4: 0.06853504478931427
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.63 seconds!
[tester] 
AGNewsMetric: acc=0.8723684210526316, hinge=0.9318251353815982, ce=6.596662896808825
Local test acc @ epoch 47: 0.8724
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.3738565146923065
Local loss @ local epoch 1: 0.4865572154521942
Local loss @ local epoch 2: 0.29317811131477356
Local loss @ local epoch 3: 0.28692740201950073
Local loss @ local epoch 4: 0.42577871680259705
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.83 seconds!
[tester] 
AGNewsMetric: acc=0.8372368421052632, hinge=1.0847375596197029, ce=7.878583096955952
Local test acc @ epoch 47: 0.8372
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.027137812227010727
Local loss @ local epoch 1: 0.02158971130847931
Local loss @ local epoch 2: 0.07366345077753067
Local loss @ local epoch 3: 0.1871214658021927
Local loss @ local epoch 4: 0.20165929198265076
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.98 seconds!
[tester] 
AGNewsMetric: acc=0.8601315789473685, hinge=0.9093281226409109, ce=9.019277554562217
Local test acc @ epoch 47: 0.8601
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.26169291138648987
Local loss @ local epoch 1: 0.5019763708114624
Local loss @ local epoch 2: 0.30841147899627686
Local loss @ local epoch 3: 0.06031756475567818
Local loss @ local epoch 4: 0.07982438057661057
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.59 seconds!
[tester] 
AGNewsMetric: acc=0.8631578947368421, hinge=0.9965502344934564, ce=9.201823146217748
Local test acc @ epoch 47: 0.8632
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.03194710239768028
Local loss @ local epoch 1: 0.018299998715519905
Local loss @ local epoch 2: 0.007106025703251362
Local loss @ local epoch 3: 0.08391508460044861
Local loss @ local epoch 4: 0.049052149057388306
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.81 seconds!
[tester] 
AGNewsMetric: acc=0.8468421052631578, hinge=1.2885839690660175, ce=7.413181744625694
Local test acc @ epoch 47: 0.8468
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.07294395565986633
Local loss @ local epoch 1: 1.5277349948883057
Local loss @ local epoch 2: 0.09736252576112747
Local loss @ local epoch 3: 0.1532944142818451
Local loss @ local epoch 4: 0.12574797868728638
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.91 seconds!
[tester] 
AGNewsMetric: acc=0.8573684210526316, hinge=0.9183132959667005, ce=6.788506113353528
Local test acc @ epoch 47: 0.8574
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.2475583255290985
Local loss @ local epoch 1: 0.14484605193138123
Local loss @ local epoch 2: 0.07607832551002502
Local loss @ local epoch 3: 0.17109529674053192
Local loss @ local epoch 4: 0.14836503565311432
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.37 seconds!
[tester] 
AGNewsMetric: acc=0.855, hinge=1.00260701129311, ce=6.605212608136629
Local test acc @ epoch 47: 0.855
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.3166047930717468
Local loss @ local epoch 1: 0.29139354825019836
Local loss @ local epoch 2: 0.12366577237844467
Local loss @ local epoch 3: 0.2360946089029312
Local loss @ local epoch 4: 0.12861795723438263
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 131.0 seconds!
[tester] 
AGNewsMetric: acc=0.8336842105263158, hinge=1.1203149966189736, ce=5.99403458745856
Local test acc @ epoch 47: 0.8337
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.48582786321640015
Local loss @ local epoch 1: 0.23550744354724884
Local loss @ local epoch 2: 0.40859469771385193
Local loss @ local epoch 3: 0.3740224838256836
Local loss @ local epoch 4: 0.5197442173957825
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.55 seconds!
[tester] 
AGNewsMetric: acc=0.8663157894736843, hinge=0.9632170511546888, ce=8.10532008622822
Local test acc @ epoch 47: 0.8663
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.018989713862538338
Local loss @ local epoch 1: 0.021843338385224342
Local loss @ local epoch 2: 0.019916780292987823
Local loss @ local epoch 3: 0.008343202993273735
Local loss @ local epoch 4: 0.00505124730989337
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.77 seconds!
[tester] 
AGNewsMetric: acc=0.8519736842105263, hinge=1.1805149823740908, ce=9.08903460050884
Local test acc @ epoch 47: 0.852
Global evaluate on test data...
Evaluate data in 129.67 seconds!
[tester] 
AGNewsMetric: acc=0.8789473684210526, hinge=0.9183206221931859, ce=7.692353963349995
Global test acc @ epoch 47: 0.8789
Global epoch 48...
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.32854634523391724
Local loss @ local epoch 1: 0.24470588564872742
Local loss @ local epoch 2: 0.3248876929283142
Local loss @ local epoch 3: 0.10258043557405472
Local loss @ local epoch 4: 0.19736924767494202
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.37 seconds!
[tester] 
AGNewsMetric: acc=0.7436842105263158, hinge=1.883812591904088, ce=7.1006568607531095
Local test acc @ epoch 48: 0.7437
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.011497149243950844
Local loss @ local epoch 1: 0.010226895101368427
Local loss @ local epoch 2: 0.023991893976926804
Local loss @ local epoch 3: 0.2598951756954193
Local loss @ local epoch 4: 0.04642055183649063
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.24 seconds!
[tester] 
AGNewsMetric: acc=0.8115789473684211, hinge=1.4064631778315493, ce=5.084600614246569
Local test acc @ epoch 48: 0.8116
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.4068574905395508
Local loss @ local epoch 1: 0.4362928569316864
Local loss @ local epoch 2: 0.6817751526832581
Local loss @ local epoch 3: 0.29536139965057373
Local loss @ local epoch 4: 0.44436222314834595
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.39 seconds!
[tester] 
AGNewsMetric: acc=0.8494736842105263, hinge=0.9382631010758249, ce=7.847357918588739
Local test acc @ epoch 48: 0.8495
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.032227031886577606
Local loss @ local epoch 1: 0.4176231324672699
Local loss @ local epoch 2: 0.10235647857189178
Local loss @ local epoch 3: 0.08075504004955292
Local loss @ local epoch 4: 0.04738544300198555
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.43 seconds!
[tester] 
AGNewsMetric: acc=0.7648684210526315, hinge=1.707519187927246, ce=7.229826233512477
Local test acc @ epoch 48: 0.7649
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.02613103948533535
Local loss @ local epoch 1: 0.006241514813154936
Local loss @ local epoch 2: 0.010009611025452614
Local loss @ local epoch 3: 0.005625368095934391
Local loss @ local epoch 4: 0.02415146678686142
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.18 seconds!
[tester] 
AGNewsMetric: acc=0.8309210526315789, hinge=1.3403641507500097, ce=6.0034420003389055
Local test acc @ epoch 48: 0.8309
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.1398574411869049
Local loss @ local epoch 1: 0.038126781582832336
Local loss @ local epoch 2: 0.034081220626831055
Local loss @ local epoch 3: 0.013853169046342373
Local loss @ local epoch 4: 0.020989900454878807
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.64 seconds!
[tester] 
AGNewsMetric: acc=0.8525, hinge=1.1487806633899087, ce=6.473011370207134
Local test acc @ epoch 48: 0.8525
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.2189473658800125
Local loss @ local epoch 1: 0.31707245111465454
Local loss @ local epoch 2: 0.14147049188613892
Local loss @ local epoch 3: 0.07138344645500183
Local loss @ local epoch 4: 0.07244578003883362
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.58 seconds!
[tester] 
AGNewsMetric: acc=0.7919736842105263, hinge=1.573245627754613, ce=6.322838715001156
Local test acc @ epoch 48: 0.792
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.35133880376815796
Local loss @ local epoch 1: 0.30668342113494873
Local loss @ local epoch 2: 0.14719326794147491
Local loss @ local epoch 3: 0.5334272384643555
Local loss @ local epoch 4: 0.49720990657806396
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 131.42 seconds!
[tester] 
AGNewsMetric: acc=0.8225, hinge=1.1675600418291594, ce=6.706997726841977
Local test acc @ epoch 48: 0.8225
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.16590076684951782
Local loss @ local epoch 1: 0.14798466861248016
Local loss @ local epoch 2: 0.13208194077014923
Local loss @ local epoch 3: 0.2856862545013428
Local loss @ local epoch 4: 0.42176783084869385
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.97 seconds!
[tester] 
AGNewsMetric: acc=0.8628947368421053, hinge=0.982974547586943, ce=7.637286194249203
Local test acc @ epoch 48: 0.8629
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.24252033233642578
Local loss @ local epoch 1: 0.07823314517736435
Local loss @ local epoch 2: 0.1955615133047104
Local loss @ local epoch 3: 0.2752649784088135
Local loss @ local epoch 4: 0.24313916265964508
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.29 seconds!
[tester] 
AGNewsMetric: acc=0.8142105263157895, hinge=1.3169026364778218, ce=6.560471272719534
Local test acc @ epoch 48: 0.8142
Global evaluate on test data...
Evaluate data in 129.89 seconds!
[tester] 
AGNewsMetric: acc=0.8792105263157894, hinge=0.9027213294882523, ce=7.098811899486341
Global test acc @ epoch 48: 0.8792
Global epoch 49...
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.09640540927648544
Local loss @ local epoch 1: 1.2427536249160767
Local loss @ local epoch 2: 0.12009264528751373
Local loss @ local epoch 3: 0.05379003658890724
Local loss @ local epoch 4: 0.08175519108772278
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.38 seconds!
[tester] 
AGNewsMetric: acc=0.86, hinge=0.8845154270372892, ce=7.665487301475124
Local test acc @ epoch 49: 0.86
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.12908706068992615
Local loss @ local epoch 1: 0.23779132962226868
Local loss @ local epoch 2: 0.23762471973896027
Local loss @ local epoch 3: 0.15638339519500732
Local loss @ local epoch 4: 0.18712462484836578
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.89 seconds!
[tester] 
AGNewsMetric: acc=0.8365789473684211, hinge=1.2035406521746987, ce=7.266156102230674
Local test acc @ epoch 49: 0.8366
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0926911011338234
Local loss @ local epoch 1: 0.022851157933473587
Local loss @ local epoch 2: 0.024261850863695145
Local loss @ local epoch 3: 0.23955032229423523
Local loss @ local epoch 4: 0.0722510814666748
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.6 seconds!
[tester] 
AGNewsMetric: acc=0.8432894736842105, hinge=1.091887909989608, ce=7.332220912732576
Local test acc @ epoch 49: 0.8433
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.026321060955524445
Local loss @ local epoch 1: 0.022962914779782295
Local loss @ local epoch 2: 0.17711478471755981
Local loss @ local epoch 3: 0.03708991780877113
Local loss @ local epoch 4: 0.027977291494607925
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.18 seconds!
[tester] 
AGNewsMetric: acc=0.8528947368421053, hinge=1.1606833954861289, ce=8.564170343499434
Local test acc @ epoch 49: 0.8529
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.248503178358078
Local loss @ local epoch 1: 0.17158152163028717
Local loss @ local epoch 2: 0.22673313319683075
Local loss @ local epoch 3: 0.0862017497420311
Local loss @ local epoch 4: 0.10165011882781982
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.48 seconds!
[tester] 
AGNewsMetric: acc=0.8323684210526315, hinge=1.112846894766155, ce=5.382834420455129
Local test acc @ epoch 49: 0.8324
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.15520931780338287
Local loss @ local epoch 1: 0.17472651600837708
Local loss @ local epoch 2: 0.38269931077957153
Local loss @ local epoch 3: 0.4703274071216583
Local loss @ local epoch 4: 0.4071390628814697
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.44 seconds!
[tester] 
AGNewsMetric: acc=0.8403947368421053, hinge=1.1201398149289583, ce=7.704046414023951
Local test acc @ epoch 49: 0.8404
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.01365263294428587
Local loss @ local epoch 1: 0.06431366503238678
Local loss @ local epoch 2: 0.009950892999768257
Local loss @ local epoch 3: 0.029178105294704437
Local loss @ local epoch 4: 0.07211549580097198
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.66 seconds!
[tester] 
AGNewsMetric: acc=0.8465789473684211, hinge=1.206754349407397, ce=6.913420732397782
Local test acc @ epoch 49: 0.8466
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.02500384859740734
Local loss @ local epoch 1: 0.014515639282763004
Local loss @ local epoch 2: 0.024716315791010857
Local loss @ local epoch 3: 0.07927913218736649
Local loss @ local epoch 4: 0.018830308690667152
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.06 seconds!
[tester] 
AGNewsMetric: acc=0.7825, hinge=1.6691309996655113, ce=6.6890154687981855
Local test acc @ epoch 49: 0.7825
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.48947691917419434
Local loss @ local epoch 1: 1.205153465270996
Local loss @ local epoch 2: 0.3689052164554596
Local loss @ local epoch 3: 0.4188378155231476
Local loss @ local epoch 4: 1.0830401182174683
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.53 seconds!
[tester] 
AGNewsMetric: acc=0.8571052631578947, hinge=0.9721889455694901, ce=6.655291516153436
Local test acc @ epoch 49: 0.8571
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.3496144711971283
Local loss @ local epoch 1: 0.07760854810476303
Local loss @ local epoch 2: 0.08760786801576614
Local loss @ local epoch 3: 0.12718291580677032
Local loss @ local epoch 4: 0.20187482237815857
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.59 seconds!
[tester] 
AGNewsMetric: acc=0.8596052631578948, hinge=0.9120359435834383, ce=5.57072294436003
Local test acc @ epoch 49: 0.8596
Global evaluate on test data...
Evaluate data in 130.09 seconds!
[tester] 
AGNewsMetric: acc=0.8863157894736842, hinge=0.9116816084008468, ce=8.042410473070646
Global test acc @ epoch 49: 0.8863
Global epoch 50...
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.421173632144928
Local loss @ local epoch 1: 0.32705986499786377
Local loss @ local epoch 2: 0.4324454665184021
Local loss @ local epoch 3: 0.38240817189216614
Local loss @ local epoch 4: 0.37611743807792664
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.86 seconds!
[tester] 
AGNewsMetric: acc=0.8532894736842105, hinge=1.003742366589998, ce=8.547216714557848
Local test acc @ epoch 50: 0.8533
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.007272067479789257
Local loss @ local epoch 1: 0.0259171724319458
Local loss @ local epoch 2: 0.011966862715780735
Local loss @ local epoch 3: 0.012151255272328854
Local loss @ local epoch 4: 0.021936656907200813
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.32 seconds!
[tester] 
AGNewsMetric: acc=0.8577631578947369, hinge=1.199041061903301, ce=10.470036655225252
Local test acc @ epoch 50: 0.8578
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.14665678143501282
Local loss @ local epoch 1: 0.23524965345859528
Local loss @ local epoch 2: 0.04797946661710739
Local loss @ local epoch 3: 0.17929348349571228
Local loss @ local epoch 4: 0.020110754296183586
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.57 seconds!
[tester] 
AGNewsMetric: acc=0.8569736842105263, hinge=1.1129457599238346, ce=7.810857664409436
Local test acc @ epoch 50: 0.857
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.057142000645399094
Local loss @ local epoch 1: 0.37166333198547363
Local loss @ local epoch 2: 0.15724240243434906
Local loss @ local epoch 3: 0.18673452734947205
Local loss @ local epoch 4: 0.19126376509666443
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.86 seconds!
[tester] 
AGNewsMetric: acc=0.8443421052631579, hinge=0.9636526850650186, ce=6.205186267652009
Local test acc @ epoch 50: 0.8443
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.114133819937706
Local loss @ local epoch 1: 0.17998117208480835
Local loss @ local epoch 2: 0.12487620115280151
Local loss @ local epoch 3: 0.2800441086292267
Local loss @ local epoch 4: 0.5224341154098511
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.62 seconds!
[tester] 
AGNewsMetric: acc=0.8605263157894737, hinge=0.9451349421551353, ce=7.097620501267283
Local test acc @ epoch 50: 0.8605
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.05675537884235382
Local loss @ local epoch 1: 0.5751160979270935
Local loss @ local epoch 2: 0.18384380638599396
Local loss @ local epoch 3: 0.16677284240722656
Local loss @ local epoch 4: 0.26025739312171936
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.9 seconds!
[tester] 
AGNewsMetric: acc=0.8688157894736842, hinge=0.8556281378394679, ce=6.524704533627158
Local test acc @ epoch 50: 0.8688
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.10349377989768982
Local loss @ local epoch 1: 0.10550593584775925
Local loss @ local epoch 2: 0.15438543260097504
Local loss @ local epoch 3: 0.11881225556135178
Local loss @ local epoch 4: 0.16989846527576447
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 131.31 seconds!
[tester] 
AGNewsMetric: acc=0.8135526315789474, hinge=1.3193774853254618, ce=7.8183235570004115
Local test acc @ epoch 50: 0.8136
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.008872236125171185
Local loss @ local epoch 1: 0.014032172970473766
Local loss @ local epoch 2: 0.015711955726146698
Local loss @ local epoch 3: 0.003828256856650114
Local loss @ local epoch 4: 0.029715176671743393
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.98 seconds!
[tester] 
AGNewsMetric: acc=0.8276315789473684, hinge=1.4320132378527992, ce=7.291271199678119
Local test acc @ epoch 50: 0.8276
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.017678920179605484
Local loss @ local epoch 1: 0.016345862299203873
Local loss @ local epoch 2: 0.014677206054329872
Local loss @ local epoch 3: 0.04906158149242401
Local loss @ local epoch 4: 0.0231041107326746
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.92 seconds!
[tester] 
AGNewsMetric: acc=0.829078947368421, hinge=1.4947087240219117, ce=5.67657648889642
Local test acc @ epoch 50: 0.8291
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.4077111482620239
Local loss @ local epoch 1: 0.1811491698026657
Local loss @ local epoch 2: 0.14488139748573303
Local loss @ local epoch 3: 0.1956268846988678
Local loss @ local epoch 4: 0.09539608657360077
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.26 seconds!
[tester] 
AGNewsMetric: acc=0.8247368421052632, hinge=1.2969867415177194, ce=7.196184997558594
Local test acc @ epoch 50: 0.8247
Global evaluate on test data...
Evaluate data in 130.2 seconds!
[tester] 
AGNewsMetric: acc=0.8756578947368421, hinge=0.9024848057094373, ce=8.14193251961156
Global test acc @ epoch 50: 0.8757
Global epoch 51...
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.2490757405757904
Local loss @ local epoch 1: 0.16642382740974426
Local loss @ local epoch 2: 0.1524922102689743
Local loss @ local epoch 3: 0.055425696074962616
Local loss @ local epoch 4: 0.2962009608745575
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.47 seconds!
[tester] 
AGNewsMetric: acc=0.781578947368421, hinge=1.461672867222836, ce=7.2155045589647795
Local test acc @ epoch 51: 0.7816
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.02992193028330803
Local loss @ local epoch 1: 0.01040593907237053
Local loss @ local epoch 2: 0.021645642817020416
Local loss @ local epoch 3: 0.024699000641703606
Local loss @ local epoch 4: 0.013172149658203125
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.72 seconds!
[tester] 
AGNewsMetric: acc=0.8521052631578947, hinge=1.212080458088925, ce=7.854466257597271
Local test acc @ epoch 51: 0.8521
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.2018093466758728
Local loss @ local epoch 1: 0.15575237572193146
Local loss @ local epoch 2: 0.129612535238266
Local loss @ local epoch 3: 0.32771867513656616
Local loss @ local epoch 4: 0.27695703506469727
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 128.98 seconds!
[tester] 
AGNewsMetric: acc=0.8593421052631579, hinge=0.9637240392283389, ce=10.54231570193642
Local test acc @ epoch 51: 0.8593
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.013449594378471375
Local loss @ local epoch 1: 0.03779798373579979
Local loss @ local epoch 2: 0.007986526004970074
Local loss @ local epoch 3: 0.056027255952358246
Local loss @ local epoch 4: 0.009986386634409428
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.65 seconds!
[tester] 
AGNewsMetric: acc=0.8061842105263158, hinge=1.5139416727266815, ce=9.830352465980932
Local test acc @ epoch 51: 0.8062
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.01397891715168953
Local loss @ local epoch 1: 0.2806452214717865
Local loss @ local epoch 2: 0.08801495283842087
Local loss @ local epoch 3: 0.280311644077301
Local loss @ local epoch 4: 0.0947142168879509
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.74 seconds!
[tester] 
AGNewsMetric: acc=0.8642105263157894, hinge=0.9253674338993273, ce=8.20926623294228
Local test acc @ epoch 51: 0.8642
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.010342493653297424
Local loss @ local epoch 1: 0.006485022138804197
Local loss @ local epoch 2: 0.006729650776833296
Local loss @ local epoch 3: 0.008945521898567677
Local loss @ local epoch 4: 0.004137990064918995
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.95 seconds!
[tester] 
AGNewsMetric: acc=0.8476315789473684, hinge=1.160365269058629, ce=7.300845840855649
Local test acc @ epoch 51: 0.8476
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.4058510661125183
Local loss @ local epoch 1: 0.2590844929218292
Local loss @ local epoch 2: 0.5293475389480591
Local loss @ local epoch 3: 0.37074947357177734
Local loss @ local epoch 4: 0.25451207160949707
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.15 seconds!
[tester] 
AGNewsMetric: acc=0.853421052631579, hinge=0.9394113570765446, ce=7.490037547663638
Local test acc @ epoch 51: 0.8534
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.1728837639093399
Local loss @ local epoch 1: 0.603016197681427
Local loss @ local epoch 2: 0.1849546730518341
Local loss @ local epoch 3: 0.1358122080564499
Local loss @ local epoch 4: 0.2985542118549347
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.3 seconds!
[tester] 
AGNewsMetric: acc=0.8717105263157895, hinge=0.998835032362687, ce=6.3424572512978
Local test acc @ epoch 51: 0.8717
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.16804297268390656
Local loss @ local epoch 1: 0.19026246666908264
Local loss @ local epoch 2: 0.06502087414264679
Local loss @ local epoch 3: 0.07296321541070938
Local loss @ local epoch 4: 0.15921002626419067
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.56 seconds!
[tester] 
AGNewsMetric: acc=0.8198684210526316, hinge=1.3696150455976788, ce=6.531223752875077
Local test acc @ epoch 51: 0.8199
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.15943436324596405
Local loss @ local epoch 1: 0.0345693901181221
Local loss @ local epoch 2: 0.13455407321453094
Local loss @ local epoch 3: 0.07168424874544144
Local loss @ local epoch 4: 0.07081764936447144
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.26 seconds!
[tester] 
AGNewsMetric: acc=0.8523684210526316, hinge=1.0231038131211934, ce=8.331962780199554
Local test acc @ epoch 51: 0.8524
Global evaluate on test data...
Evaluate data in 129.66 seconds!
[tester] 
AGNewsMetric: acc=0.8848684210526315, hinge=0.9663593392623099, ce=7.874118899295205
Global test acc @ epoch 51: 0.8849
Global epoch 52...
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.24751366674900055
Local loss @ local epoch 1: 0.22354526817798615
Local loss @ local epoch 2: 0.4678964912891388
Local loss @ local epoch 3: 0.47444185614585876
Local loss @ local epoch 4: 0.4984825551509857
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.51 seconds!
[tester] 
AGNewsMetric: acc=0.8338157894736842, hinge=1.1643882543162296, ce=7.6144474511397515
Local test acc @ epoch 52: 0.8338
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.21785540878772736
Local loss @ local epoch 1: 0.03653058037161827
Local loss @ local epoch 2: 0.15998771786689758
Local loss @ local epoch 3: 0.2715241611003876
Local loss @ local epoch 4: 0.7699483036994934
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.14 seconds!
[tester] 
AGNewsMetric: acc=0.7835526315789474, hinge=1.6640563568316007, ce=7.088420928151984
Local test acc @ epoch 52: 0.7836
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.02522810734808445
Local loss @ local epoch 1: 0.01057165116071701
Local loss @ local epoch 2: 0.0462004654109478
Local loss @ local epoch 3: 0.06794678419828415
Local loss @ local epoch 4: 0.022015267983078957
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.52 seconds!
[tester] 
AGNewsMetric: acc=0.8555263157894737, hinge=1.3024479271236218, ce=9.076886867723967
Local test acc @ epoch 52: 0.8555
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.006463652476668358
Local loss @ local epoch 1: 0.3027104437351227
Local loss @ local epoch 2: 0.06403695046901703
Local loss @ local epoch 3: 0.17221179604530334
Local loss @ local epoch 4: 0.012699171900749207
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.55 seconds!
[tester] 
AGNewsMetric: acc=0.8630263157894736, hinge=0.8987484761288291, ce=7.567721465261359
Local test acc @ epoch 52: 0.863
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.028979960829019547
Local loss @ local epoch 1: 0.03936807066202164
Local loss @ local epoch 2: 0.22388345003128052
Local loss @ local epoch 3: 0.10447845607995987
Local loss @ local epoch 4: 0.06887715309858322
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.79 seconds!
[tester] 
AGNewsMetric: acc=0.8461842105263158, hinge=1.158836006867258, ce=7.926430933099044
Local test acc @ epoch 52: 0.8462
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.03959079831838608
Local loss @ local epoch 1: 0.14930714666843414
Local loss @ local epoch 2: 0.048176366835832596
Local loss @ local epoch 3: 0.06803839653730392
Local loss @ local epoch 4: 0.2635090947151184
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 131.44 seconds!
[tester] 
AGNewsMetric: acc=0.8778947368421053, hinge=0.9187895298004151, ce=6.44068489074707
Local test acc @ epoch 52: 0.8779
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.02041269838809967
Local loss @ local epoch 1: 0.9017980098724365
Local loss @ local epoch 2: 0.10709705948829651
Local loss @ local epoch 3: 0.1188143789768219
Local loss @ local epoch 4: 0.2939288020133972
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.4 seconds!
[tester] 
AGNewsMetric: acc=0.8776315789473684, hinge=0.8380778769442909, ce=6.307030174857692
Local test acc @ epoch 52: 0.8776
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.3633643388748169
Local loss @ local epoch 1: 0.159934863448143
Local loss @ local epoch 2: 0.10166959464550018
Local loss @ local epoch 3: 0.16943931579589844
Local loss @ local epoch 4: 0.22618648409843445
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.21 seconds!
[tester] 
AGNewsMetric: acc=0.8598684210526316, hinge=1.1298260470440513, ce=9.625139310736404
Local test acc @ epoch 52: 0.8599
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.007052487228065729
Local loss @ local epoch 1: 0.029823649674654007
Local loss @ local epoch 2: 0.009576966986060143
Local loss @ local epoch 3: 0.02193707972764969
Local loss @ local epoch 4: 0.16215606033802032
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.73 seconds!
[tester] 
AGNewsMetric: acc=0.8347368421052631, hinge=1.6408671338934648, ce=8.047355155944825
Local test acc @ epoch 52: 0.8347
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.45267096161842346
Local loss @ local epoch 1: 0.39284470677375793
Local loss @ local epoch 2: 0.6988349556922913
Local loss @ local epoch 3: 0.6100603342056274
Local loss @ local epoch 4: 0.49060556292533875
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.74 seconds!
[tester] 
AGNewsMetric: acc=0.8573684210526316, hinge=0.903488655090332, ce=5.641068360178094
Local test acc @ epoch 52: 0.8574
Global evaluate on test data...
Evaluate data in 129.15 seconds!
[tester] 
AGNewsMetric: acc=0.8817105263157895, hinge=0.9773100197942634, ce=7.234808480112176
Global test acc @ epoch 52: 0.8817
Global epoch 53...
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.10811015218496323
Local loss @ local epoch 1: 0.3601970374584198
Local loss @ local epoch 2: 0.10814525187015533
Local loss @ local epoch 3: 0.15985621511936188
Local loss @ local epoch 4: 0.08945124596357346
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.68 seconds!
[tester] 
AGNewsMetric: acc=0.8106578947368421, hinge=1.3464651288484273, ce=8.3832593596609
Local test acc @ epoch 53: 0.8107
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.3067741394042969
Local loss @ local epoch 1: 0.1500280797481537
Local loss @ local epoch 2: 0.44975894689559937
Local loss @ local epoch 3: 0.2093358188867569
Local loss @ local epoch 4: 0.19952592253684998
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.12 seconds!
[tester] 
AGNewsMetric: acc=0.8089473684210526, hinge=1.1984040993138363, ce=9.570301383169074
Local test acc @ epoch 53: 0.8089
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.11917581409215927
Local loss @ local epoch 1: 0.4493168890476227
Local loss @ local epoch 2: 0.05373912304639816
Local loss @ local epoch 3: 0.04369857907295227
Local loss @ local epoch 4: 0.17674118280410767
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.82 seconds!
[tester] 
AGNewsMetric: acc=0.8489473684210527, hinge=1.0404599485899273, ce=6.076323230141088
Local test acc @ epoch 53: 0.8489
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.3640952408313751
Local loss @ local epoch 1: 0.2752315402030945
Local loss @ local epoch 2: 0.23799104988574982
Local loss @ local epoch 3: 0.23426218330860138
Local loss @ local epoch 4: 0.7052780985832214
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.46 seconds!
[tester] 
AGNewsMetric: acc=0.7253947368421053, hinge=1.7760433703974674, ce=10.459980723732397
Local test acc @ epoch 53: 0.7254
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.07026215642690659
Local loss @ local epoch 1: 0.2467668354511261
Local loss @ local epoch 2: 0.041737645864486694
Local loss @ local epoch 3: 0.14479468762874603
Local loss @ local epoch 4: 0.4349612891674042
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.95 seconds!
[tester] 
AGNewsMetric: acc=0.8298684210526316, hinge=1.065627424842433, ce=5.879305427952817
Local test acc @ epoch 53: 0.8299
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.027132295072078705
Local loss @ local epoch 1: 0.04375498741865158
Local loss @ local epoch 2: 0.12968522310256958
Local loss @ local epoch 3: 0.13313543796539307
Local loss @ local epoch 4: 0.18394888937473297
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.08 seconds!
[tester] 
AGNewsMetric: acc=0.8398684210526316, hinge=1.2734750672390587, ce=9.658121267619887
Local test acc @ epoch 53: 0.8399
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.08458428829908371
Local loss @ local epoch 1: 0.06703902781009674
Local loss @ local epoch 2: 0.065747931599617
Local loss @ local epoch 3: 0.15097108483314514
Local loss @ local epoch 4: 0.22150471806526184
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.71 seconds!
[tester] 
AGNewsMetric: acc=0.8489473684210527, hinge=1.2052127893347488, ce=9.943854175366853
Local test acc @ epoch 53: 0.8489
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.01360374502837658
Local loss @ local epoch 1: 0.05740327388048172
Local loss @ local epoch 2: 0.02312501333653927
Local loss @ local epoch 3: 0.0185024943202734
Local loss @ local epoch 4: 0.014081116765737534
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.52 seconds!
[tester] 
AGNewsMetric: acc=0.8581578947368421, hinge=0.9626991909428647, ce=9.169143941778886
Local test acc @ epoch 53: 0.8582
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.16527263820171356
Local loss @ local epoch 1: 0.12723194062709808
Local loss @ local epoch 2: 0.22751076519489288
Local loss @ local epoch 3: 0.1439083218574524
Local loss @ local epoch 4: 0.13398578763008118
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.04 seconds!
[tester] 
AGNewsMetric: acc=0.8396052631578947, hinge=1.1428426805295442, ce=5.672069196199116
Local test acc @ epoch 53: 0.8396
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.004542396869510412
Local loss @ local epoch 1: 0.007767096161842346
Local loss @ local epoch 2: 0.0030474585946649313
Local loss @ local epoch 3: 0.04876882955431938
Local loss @ local epoch 4: 0.06045151501893997
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.81 seconds!
[tester] 
AGNewsMetric: acc=0.8461842105263158, hinge=1.1882265582837557, ce=6.181905005605597
Local test acc @ epoch 53: 0.8462
Global evaluate on test data...
Evaluate data in 130.23 seconds!
[tester] 
AGNewsMetric: acc=0.8743421052631579, hinge=1.0131291788502743, ce=8.702949084231728
Global test acc @ epoch 53: 0.8743
Global epoch 54...
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.06844500452280045
Local loss @ local epoch 1: 0.1615251749753952
Local loss @ local epoch 2: 0.24964603781700134
Local loss @ local epoch 3: 0.29511505365371704
Local loss @ local epoch 4: 0.10567895323038101
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.07 seconds!
[tester] 
AGNewsMetric: acc=0.8089473684210526, hinge=1.4534052457307514, ce=6.956755053871556
Local test acc @ epoch 54: 0.8089
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.016665924340486526
Local loss @ local epoch 1: 0.007621584925800562
Local loss @ local epoch 2: 0.05900206044316292
Local loss @ local epoch 3: 0.05681275576353073
Local loss @ local epoch 4: 0.06215615198016167
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.32 seconds!
[tester] 
AGNewsMetric: acc=0.8690789473684211, hinge=0.9286292537889983, ce=7.552084075526187
Local test acc @ epoch 54: 0.8691
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.11736919730901718
Local loss @ local epoch 1: 0.048202186822891235
Local loss @ local epoch 2: 0.025028355419635773
Local loss @ local epoch 3: 0.10798181593418121
Local loss @ local epoch 4: 0.13191565871238708
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.53 seconds!
[tester] 
AGNewsMetric: acc=0.8119736842105263, hinge=1.220243508188348, ce=8.19254349557977
Local test acc @ epoch 54: 0.812
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.22433824837207794
Local loss @ local epoch 1: 0.10643886774778366
Local loss @ local epoch 2: 0.02725590579211712
Local loss @ local epoch 3: 0.07196468114852905
Local loss @ local epoch 4: 0.09415728598833084
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.13 seconds!
[tester] 
AGNewsMetric: acc=0.8365789473684211, hinge=1.2653102084210044, ce=7.590819816589356
Local test acc @ epoch 54: 0.8366
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.3433571755886078
Local loss @ local epoch 1: 0.4491073191165924
Local loss @ local epoch 2: 0.5252584218978882
Local loss @ local epoch 3: 0.24108457565307617
Local loss @ local epoch 4: 0.23283611238002777
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 131.13 seconds!
[tester] 
AGNewsMetric: acc=0.8168421052631579, hinge=1.1734037007783589, ce=8.809776097347862
Local test acc @ epoch 54: 0.8168
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.6880060434341431
Local loss @ local epoch 1: 0.30798226594924927
Local loss @ local epoch 2: 0.26977333426475525
Local loss @ local epoch 3: 0.5861459374427795
Local loss @ local epoch 4: 0.3381763994693756
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.72 seconds!
[tester] 
AGNewsMetric: acc=0.8517105263157895, hinge=0.9182545687022962, ce=8.622248199864437
Local test acc @ epoch 54: 0.8517
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.006042603403329849
Local loss @ local epoch 1: 0.12647567689418793
Local loss @ local epoch 2: 0.0249495692551136
Local loss @ local epoch 3: 0.10071489959955215
Local loss @ local epoch 4: 0.025792013853788376
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.31 seconds!
[tester] 
AGNewsMetric: acc=0.844078947368421, hinge=1.3066747800927414, ce=7.591418095638877
Local test acc @ epoch 54: 0.8441
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.07012622058391571
Local loss @ local epoch 1: 0.019815143197774887
Local loss @ local epoch 2: 0.025548666715621948
Local loss @ local epoch 3: 0.02642321027815342
Local loss @ local epoch 4: 0.021792471408843994
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.6 seconds!
[tester] 
AGNewsMetric: acc=0.8632894736842105, hinge=0.9936388128682186, ce=7.4652518262361225
Local test acc @ epoch 54: 0.8633
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.307298481464386
Local loss @ local epoch 1: 0.17009560763835907
Local loss @ local epoch 2: 0.14206568896770477
Local loss @ local epoch 3: 0.13707812130451202
Local loss @ local epoch 4: 0.11743326485157013
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.03 seconds!
[tester] 
AGNewsMetric: acc=0.8568421052631578, hinge=0.952489322863127, ce=6.867266980221397
Local test acc @ epoch 54: 0.8568
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.006251173559576273
Local loss @ local epoch 1: 0.035673391073942184
Local loss @ local epoch 2: 0.0017707542283460498
Local loss @ local epoch 3: 0.18302825093269348
Local loss @ local epoch 4: 0.0617377907037735
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.92 seconds!
[tester] 
AGNewsMetric: acc=0.8097368421052632, hinge=1.4316424422515066, ce=8.710570345426861
Local test acc @ epoch 54: 0.8097
Global evaluate on test data...
Evaluate data in 129.4 seconds!
[tester] 
AGNewsMetric: acc=0.876578947368421, hinge=0.9186685938584177, ce=7.501471812599584
Global test acc @ epoch 54: 0.8766
Global epoch 55...
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.02187754586338997
Local loss @ local epoch 1: 0.010988591238856316
Local loss @ local epoch 2: 0.017225198447704315
Local loss @ local epoch 3: 0.05824854224920273
Local loss @ local epoch 4: 0.005307886749505997
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.74 seconds!
[tester] 
AGNewsMetric: acc=0.8377631578947369, hinge=1.1749400891755757, ce=9.38013144242136
Local test acc @ epoch 55: 0.8378
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.20507775247097015
Local loss @ local epoch 1: 0.1286969929933548
Local loss @ local epoch 2: 0.13366317749023438
Local loss @ local epoch 3: 0.3294074237346649
Local loss @ local epoch 4: 0.09008128941059113
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.04 seconds!
[tester] 
AGNewsMetric: acc=0.8044736842105263, hinge=1.4152994497198808, ce=6.992448370080245
Local test acc @ epoch 55: 0.8045
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.21058595180511475
Local loss @ local epoch 1: 0.18435777723789215
Local loss @ local epoch 2: 0.20418252050876617
Local loss @ local epoch 3: 0.10701858252286911
Local loss @ local epoch 4: 0.013566442765295506
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.67 seconds!
[tester] 
AGNewsMetric: acc=0.8467105263157895, hinge=1.29340256038465, ce=6.909000573409231
Local test acc @ epoch 55: 0.8467
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.05657432973384857
Local loss @ local epoch 1: 0.011820598505437374
Local loss @ local epoch 2: 0.14610494673252106
Local loss @ local epoch 3: 0.06096351891756058
Local loss @ local epoch 4: 0.015332474373281002
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.53 seconds!
[tester] 
AGNewsMetric: acc=0.8792105263157894, hinge=0.9305204604801379, ce=9.759043555008738
Local test acc @ epoch 55: 0.8792
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.007367866113781929
Local loss @ local epoch 1: 0.03342708572745323
Local loss @ local epoch 2: 0.2730976939201355
Local loss @ local epoch 3: 0.04864759370684624
Local loss @ local epoch 4: 0.04286288842558861
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.87 seconds!
[tester] 
AGNewsMetric: acc=0.844078947368421, hinge=1.0893838307732029, ce=5.624883197985198
Local test acc @ epoch 55: 0.8441
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.19725070893764496
Local loss @ local epoch 1: 0.07620524615049362
Local loss @ local epoch 2: 0.23647178709506989
Local loss @ local epoch 3: 0.018174272030591965
Local loss @ local epoch 4: 0.19964033365249634
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.67 seconds!
[tester] 
AGNewsMetric: acc=0.8326315789473684, hinge=1.3097524743331106, ce=9.323999103746916
Local test acc @ epoch 55: 0.8326
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.4981427490711212
Local loss @ local epoch 1: 0.20217208564281464
Local loss @ local epoch 2: 0.392972469329834
Local loss @ local epoch 3: 0.21749183535575867
Local loss @ local epoch 4: 1.2102164030075073
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.28 seconds!
[tester] 
AGNewsMetric: acc=0.8622368421052632, hinge=0.9273847371653506, ce=8.576807118466025
Local test acc @ epoch 55: 0.8622
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.27076515555381775
Local loss @ local epoch 1: 0.16258662939071655
Local loss @ local epoch 2: 0.03659345954656601
Local loss @ local epoch 3: 0.1444932520389557
Local loss @ local epoch 4: 0.02994772419333458
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.6 seconds!
[tester] 
AGNewsMetric: acc=0.8592105263157894, hinge=1.1441887817884746, ce=7.405223653692948
Local test acc @ epoch 55: 0.8592
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.09402953833341599
Local loss @ local epoch 1: 0.07386098802089691
Local loss @ local epoch 2: 0.09483254700899124
Local loss @ local epoch 3: 0.17001138627529144
Local loss @ local epoch 4: 0.10627628117799759
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.33 seconds!
[tester] 
AGNewsMetric: acc=0.7389473684210527, hinge=2.3287903690338134, ce=9.081554099635074
Local test acc @ epoch 55: 0.7389
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0634443461894989
Local loss @ local epoch 1: 0.32415053248405457
Local loss @ local epoch 2: 0.011078729294240475
Local loss @ local epoch 3: 0.008126691915094852
Local loss @ local epoch 4: 0.04987959563732147
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.88 seconds!
[tester] 
AGNewsMetric: acc=0.8403947368421053, hinge=1.2275907305667275, ce=7.714605421768992
Local test acc @ epoch 55: 0.8404
Global evaluate on test data...
Evaluate data in 129.61 seconds!
[tester] 
AGNewsMetric: acc=0.8607894736842105, hinge=1.23127264198504, ce=7.900922966003418
Global test acc @ epoch 55: 0.8608
Global epoch 56...
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.5808001160621643
Local loss @ local epoch 1: 0.1227409839630127
Local loss @ local epoch 2: 0.04714936017990112
Local loss @ local epoch 3: 0.07905300706624985
Local loss @ local epoch 4: 0.07500562071800232
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.53 seconds!
[tester] 
AGNewsMetric: acc=0.7921052631578948, hinge=1.3962156140176873, ce=6.746914771230597
Local test acc @ epoch 56: 0.7921
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.01814565807580948
Local loss @ local epoch 1: 0.04796045646071434
Local loss @ local epoch 2: 0.019811734557151794
Local loss @ local epoch 3: 1.3500889539718628
Local loss @ local epoch 4: 0.01905681937932968
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.16 seconds!
[tester] 
AGNewsMetric: acc=0.8688157894736842, hinge=0.960543606406764, ce=8.738684005737305
Local test acc @ epoch 56: 0.8688
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.004815202672034502
Local loss @ local epoch 1: 0.1812659651041031
Local loss @ local epoch 2: 0.009742017835378647
Local loss @ local epoch 3: 0.07140085846185684
Local loss @ local epoch 4: 0.010496634989976883
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.43 seconds!
[tester] 
AGNewsMetric: acc=0.8522368421052632, hinge=1.1486027275888544, ce=8.360862203899183
Local test acc @ epoch 56: 0.8522
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.4427942931652069
Local loss @ local epoch 1: 0.4171082377433777
Local loss @ local epoch 2: 0.29306232929229736
Local loss @ local epoch 3: 0.6041834354400635
Local loss @ local epoch 4: 0.5224097371101379
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 131.19 seconds!
[tester] 
AGNewsMetric: acc=0.8551315789473685, hinge=0.9402501216687654, ce=8.232573055468107
Local test acc @ epoch 56: 0.8551
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.014175741001963615
Local loss @ local epoch 1: 0.011295996606349945
Local loss @ local epoch 2: 0.186578631401062
Local loss @ local epoch 3: 0.012854192405939102
Local loss @ local epoch 4: 0.012285356409847736
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.64 seconds!
[tester] 
AGNewsMetric: acc=0.8567105263157895, hinge=1.1087893742009214, ce=6.390390710328755
Local test acc @ epoch 56: 0.8567
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.26777398586273193
Local loss @ local epoch 1: 0.16766142845153809
Local loss @ local epoch 2: 0.4185652732849121
Local loss @ local epoch 3: 0.13215745985507965
Local loss @ local epoch 4: 0.14398063719272614
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.95 seconds!
[tester] 
AGNewsMetric: acc=0.8510526315789474, hinge=1.1120924821652864, ce=8.99707523948268
Local test acc @ epoch 56: 0.8511
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.03146512061357498
Local loss @ local epoch 1: 0.022506024688482285
Local loss @ local epoch 2: 0.11246983706951141
Local loss @ local epoch 3: 0.11432643234729767
Local loss @ local epoch 4: 0.22724054753780365
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.23 seconds!
[tester] 
AGNewsMetric: acc=0.8563157894736843, hinge=1.111926488625376, ce=7.40145624863474
Local test acc @ epoch 56: 0.8563
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0162290520966053
Local loss @ local epoch 1: 0.010946070775389671
Local loss @ local epoch 2: 0.3527619242668152
Local loss @ local epoch 3: 0.047820083796978
Local loss @ local epoch 4: 0.01118425466120243
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.69 seconds!
[tester] 
AGNewsMetric: acc=0.8336842105263158, hinge=1.366737477402938, ce=9.910297949941535
Local test acc @ epoch 56: 0.8337
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.014037606306374073
Local loss @ local epoch 1: 0.019068244844675064
Local loss @ local epoch 2: 0.23130393028259277
Local loss @ local epoch 3: 0.009047387167811394
Local loss @ local epoch 4: 0.1258379966020584
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.17 seconds!
[tester] 
AGNewsMetric: acc=0.8644736842105263, hinge=0.9428004937422902, ce=9.690607010690789
Local test acc @ epoch 56: 0.8645
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.07869848608970642
Local loss @ local epoch 1: 0.03185899928212166
Local loss @ local epoch 2: 0.0716848373413086
Local loss @ local epoch 3: 0.051962122321128845
Local loss @ local epoch 4: 0.045779723674058914
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.29 seconds!
[tester] 
AGNewsMetric: acc=0.8476315789473684, hinge=1.1987663821170205, ce=6.584693449923867
Local test acc @ epoch 56: 0.8476
Global evaluate on test data...
Evaluate data in 129.74 seconds!
[tester] 
AGNewsMetric: acc=0.8728947368421053, hinge=0.9438574068169845, ce=8.238188368144788
Global test acc @ epoch 56: 0.8729
Global epoch 57...
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.15820911526679993
Local loss @ local epoch 1: 0.021515673026442528
Local loss @ local epoch 2: 0.24195222556591034
Local loss @ local epoch 3: 0.40108954906463623
Local loss @ local epoch 4: 0.1190565824508667
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.05 seconds!
[tester] 
AGNewsMetric: acc=0.8686842105263158, hinge=1.0228196380012913, ce=7.036771751203035
Local test acc @ epoch 57: 0.8687
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.013027805835008621
Local loss @ local epoch 1: 0.21905125677585602
Local loss @ local epoch 2: 0.22872167825698853
Local loss @ local epoch 3: 0.31949374079704285
Local loss @ local epoch 4: 0.254689484834671
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.76 seconds!
[tester] 
AGNewsMetric: acc=0.8125, hinge=1.3592760821392662, ce=7.373909170251143
Local test acc @ epoch 57: 0.8125
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.023182382807135582
Local loss @ local epoch 1: 0.008518257178366184
Local loss @ local epoch 2: 0.05951739847660065
Local loss @ local epoch 3: 0.012504098936915398
Local loss @ local epoch 4: 0.09941630065441132
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.55 seconds!
[tester] 
AGNewsMetric: acc=0.8160526315789474, hinge=1.6961823036796169, ce=7.443910940069902
Local test acc @ epoch 57: 0.8161
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.2760010063648224
Local loss @ local epoch 1: 0.005882661789655685
Local loss @ local epoch 2: 0.06742198020219803
Local loss @ local epoch 3: 0.07221931219100952
Local loss @ local epoch 4: 0.08965006470680237
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.28 seconds!
[tester] 
AGNewsMetric: acc=0.8738157894736842, hinge=0.8851499999196906, ce=7.674425044812654
Local test acc @ epoch 57: 0.8738
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.028085287660360336
Local loss @ local epoch 1: 0.003866553073748946
Local loss @ local epoch 2: 0.013745450414717197
Local loss @ local epoch 3: 0.02772274985909462
Local loss @ local epoch 4: 0.03511489927768707
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.24 seconds!
[tester] 
AGNewsMetric: acc=0.8411842105263158, hinge=1.2477021109430413, ce=6.431075045936986
Local test acc @ epoch 57: 0.8412
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.21252849698066711
Local loss @ local epoch 1: 0.07042296975851059
Local loss @ local epoch 2: 0.12592612206935883
Local loss @ local epoch 3: 0.0798833891749382
Local loss @ local epoch 4: 0.1610446274280548
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.76 seconds!
[tester] 
AGNewsMetric: acc=0.8021052631578948, hinge=1.440755117817929, ce=8.47135428177683
Local test acc @ epoch 57: 0.8021
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.04671378433704376
Local loss @ local epoch 1: 0.07387036085128784
Local loss @ local epoch 2: 0.11337125301361084
Local loss @ local epoch 3: 0.03808265179395676
Local loss @ local epoch 4: 0.12317594885826111
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.9 seconds!
[tester] 
AGNewsMetric: acc=0.8422368421052632, hinge=1.0469855988653083, ce=9.538069369667454
Local test acc @ epoch 57: 0.8422
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.28480154275894165
Local loss @ local epoch 1: 0.31107422709465027
Local loss @ local epoch 2: 0.17554402351379395
Local loss @ local epoch 3: 0.25903934240341187
Local loss @ local epoch 4: 0.5646036267280579
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.13 seconds!
[tester] 
AGNewsMetric: acc=0.8668421052631579, hinge=0.9866166107278121, ce=7.7044550524259865
Local test acc @ epoch 57: 0.8668
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.18623949587345123
Local loss @ local epoch 1: 0.13946107029914856
Local loss @ local epoch 2: 0.22337400913238525
Local loss @ local epoch 3: 0.1554422527551651
Local loss @ local epoch 4: 0.031226573511958122
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.05 seconds!
[tester] 
AGNewsMetric: acc=0.8510526315789474, hinge=1.0132870920080888, ce=7.4367194105449475
Local test acc @ epoch 57: 0.8511
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.3482905328273773
Local loss @ local epoch 1: 0.2544814348220825
Local loss @ local epoch 2: 0.07581435889005661
Local loss @ local epoch 3: 0.07454897463321686
Local loss @ local epoch 4: 0.16057908535003662
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.94 seconds!
[tester] 
AGNewsMetric: acc=0.8302631578947368, hinge=1.345421297173751, ce=6.906561001225522
Local test acc @ epoch 57: 0.8303
Global evaluate on test data...
Evaluate data in 129.81 seconds!
[tester] 
AGNewsMetric: acc=0.8732894736842105, hinge=1.0599650744387978, ce=7.644882926940918
Global test acc @ epoch 57: 0.8733
Global epoch 58...
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.02400936931371689
Local loss @ local epoch 1: 0.17062896490097046
Local loss @ local epoch 2: 0.12371049076318741
Local loss @ local epoch 3: 0.0351736843585968
Local loss @ local epoch 4: 0.13003851473331451
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.69 seconds!
[tester] 
AGNewsMetric: acc=0.8086842105263158, hinge=1.408835855785169, ce=9.683781513414885
Local test acc @ epoch 58: 0.8087
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.19806255400180817
Local loss @ local epoch 1: 0.10196773707866669
Local loss @ local epoch 2: 0.09384600073099136
Local loss @ local epoch 3: 0.054853975772857666
Local loss @ local epoch 4: 0.12177237868309021
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.46 seconds!
[tester] 
AGNewsMetric: acc=0.783157894736842, hinge=1.4780188013377942, ce=7.308582557878996
Local test acc @ epoch 58: 0.7832
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.8048582077026367
Local loss @ local epoch 1: 0.33571675419807434
Local loss @ local epoch 2: 0.2966758608818054
Local loss @ local epoch 3: 0.15640047192573547
Local loss @ local epoch 4: 0.398802787065506
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.84 seconds!
[tester] 
AGNewsMetric: acc=0.8386842105263158, hinge=1.1016203182622006, ce=8.683312614842466
Local test acc @ epoch 58: 0.8387
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.007810024078935385
Local loss @ local epoch 1: 0.050714876502752304
Local loss @ local epoch 2: 0.004193968139588833
Local loss @ local epoch 3: 0.005801028106361628
Local loss @ local epoch 4: 0.02007514238357544
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.97 seconds!
[tester] 
AGNewsMetric: acc=0.8382894736842105, hinge=1.5868212140233893, ce=7.710812058699759
Local test acc @ epoch 58: 0.8383
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0946115106344223
Local loss @ local epoch 1: 0.04094468429684639
Local loss @ local epoch 2: 0.022209234535694122
Local loss @ local epoch 3: 0.022718584164977074
Local loss @ local epoch 4: 0.018731506541371346
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.0 seconds!
[tester] 
AGNewsMetric: acc=0.7363157894736843, hinge=2.1976205978895487, ce=7.434516254224275
Local test acc @ epoch 58: 0.7363
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.041358087211847305
Local loss @ local epoch 1: 0.03389742597937584
Local loss @ local epoch 2: 0.15750287473201752
Local loss @ local epoch 3: 0.03646532818675041
Local loss @ local epoch 4: 0.055721431970596313
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.48 seconds!
[tester] 
AGNewsMetric: acc=0.8552631578947368, hinge=1.0594111864190352, ce=8.810140503331235
Local test acc @ epoch 58: 0.8553
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.06033143401145935
Local loss @ local epoch 1: 0.3514312207698822
Local loss @ local epoch 2: 0.13390833139419556
Local loss @ local epoch 3: 0.1722583919763565
Local loss @ local epoch 4: 0.12768685817718506
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.53 seconds!
[tester] 
AGNewsMetric: acc=0.8135526315789474, hinge=1.400620332517122, ce=7.248533714695981
Local test acc @ epoch 58: 0.8136
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.02979421615600586
Local loss @ local epoch 1: 0.3827859163284302
Local loss @ local epoch 2: 0.008920122869312763
Local loss @ local epoch 3: 0.018420401960611343
Local loss @ local epoch 4: 0.14479991793632507
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.13 seconds!
[tester] 
AGNewsMetric: acc=0.8571052631578947, hinge=1.0629063345256604, ce=6.866468572114643
Local test acc @ epoch 58: 0.8571
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.01607213355600834
Local loss @ local epoch 1: 0.015861714258790016
Local loss @ local epoch 2: 0.03637489676475525
Local loss @ local epoch 3: 0.03012489341199398
Local loss @ local epoch 4: 0.053815439343452454
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.47 seconds!
[tester] 
AGNewsMetric: acc=0.8651315789473685, hinge=1.248256781728644, ce=8.525940527664988
Local test acc @ epoch 58: 0.8651
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.023466207087039948
Local loss @ local epoch 1: 0.0037578060291707516
Local loss @ local epoch 2: 0.025206562131643295
Local loss @ local epoch 3: 0.056320879608392715
Local loss @ local epoch 4: 0.03121788427233696
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.24 seconds!
[tester] 
AGNewsMetric: acc=0.8578947368421053, hinge=0.9855904217770225, ce=9.460984551279168
Local test acc @ epoch 58: 0.8579
Global evaluate on test data...
Evaluate data in 129.43 seconds!
[tester] 
AGNewsMetric: acc=0.8752631578947369, hinge=1.0253091086839374, ce=8.295624738994398
Global test acc @ epoch 58: 0.8753
Global epoch 59...
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.007463244255632162
Local loss @ local epoch 1: 0.08613213151693344
Local loss @ local epoch 2: 0.0012406738242134452
Local loss @ local epoch 3: 0.035479556769132614
Local loss @ local epoch 4: 0.027558667585253716
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.83 seconds!
[tester] 
AGNewsMetric: acc=0.8594736842105263, hinge=1.129434999415749, ce=7.752691146449039
Local test acc @ epoch 59: 0.8595
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.5975185632705688
Local loss @ local epoch 1: 0.4954107999801636
Local loss @ local epoch 2: 0.3705504834651947
Local loss @ local epoch 3: 0.24054193496704102
Local loss @ local epoch 4: 0.24403078854084015
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.21 seconds!
[tester] 
AGNewsMetric: acc=0.865, hinge=0.9239479393708079, ce=8.159496678804096
Local test acc @ epoch 59: 0.865
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.1047128215432167
Local loss @ local epoch 1: 0.10490862280130386
Local loss @ local epoch 2: 0.04074039310216904
Local loss @ local epoch 3: 0.12214305251836777
Local loss @ local epoch 4: 0.06731852889060974
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 131.07 seconds!
[tester] 
AGNewsMetric: acc=0.8475, hinge=1.121863922570881, ce=7.84533432408383
Local test acc @ epoch 59: 0.8475
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.1205805093050003
Local loss @ local epoch 1: 0.018008960410952568
Local loss @ local epoch 2: 0.016201265156269073
Local loss @ local epoch 3: 0.017353082075715065
Local loss @ local epoch 4: 0.10173335671424866
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.82 seconds!
[tester] 
AGNewsMetric: acc=0.8522368421052632, hinge=1.2656616737968043, ce=8.01977663542095
Local test acc @ epoch 59: 0.8522
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0858708843588829
Local loss @ local epoch 1: 0.027495529502630234
Local loss @ local epoch 2: 0.025048740208148956
Local loss @ local epoch 3: 0.04078824818134308
Local loss @ local epoch 4: 0.056733351200819016
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.32 seconds!
[tester] 
AGNewsMetric: acc=0.8453947368421053, hinge=1.1375957890560753, ce=8.0668393968281
Local test acc @ epoch 59: 0.8454
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.24405354261398315
Local loss @ local epoch 1: 0.17059050500392914
Local loss @ local epoch 2: 0.04932655021548271
Local loss @ local epoch 3: 0.2188366949558258
Local loss @ local epoch 4: 0.0683777704834938
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.54 seconds!
[tester] 
AGNewsMetric: acc=0.785, hinge=1.669538261513961, ce=6.88128732882048
Local test acc @ epoch 59: 0.785
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00577226746827364
Local loss @ local epoch 1: 0.03006586618721485
Local loss @ local epoch 2: 0.020931104198098183
Local loss @ local epoch 3: 0.00630911672487855
Local loss @ local epoch 4: 0.003659349400550127
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.08 seconds!
[tester] 
AGNewsMetric: acc=0.8698684210526316, hinge=1.0218155062826055, ce=8.313854113127055
Local test acc @ epoch 59: 0.8699
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.19256970286369324
Local loss @ local epoch 1: 0.06728456169366837
Local loss @ local epoch 2: 0.11561073362827301
Local loss @ local epoch 3: 0.061107780784368515
Local loss @ local epoch 4: 0.023495150730013847
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.33 seconds!
[tester] 
AGNewsMetric: acc=0.8052631578947368, hinge=1.5927700266085172, ce=9.048225288391114
Local test acc @ epoch 59: 0.8053
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0075706783682107925
Local loss @ local epoch 1: 0.01959460787475109
Local loss @ local epoch 2: 0.022366628050804138
Local loss @ local epoch 3: 0.005227310582995415
Local loss @ local epoch 4: 0.011417636647820473
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.16 seconds!
[tester] 
AGNewsMetric: acc=0.8468421052631578, hinge=1.3330324524327328, ce=6.779394153795744
Local test acc @ epoch 59: 0.8468
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.03583570942282677
Local loss @ local epoch 1: 0.08904482424259186
Local loss @ local epoch 2: 0.11170355975627899
Local loss @ local epoch 3: 0.011977638117969036
Local loss @ local epoch 4: 0.04750808700919151
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.84 seconds!
[tester] 
AGNewsMetric: acc=0.8280263157894737, hinge=1.2294639175816586, ce=7.8511784322638265
Local test acc @ epoch 59: 0.828
Global evaluate on test data...
Evaluate data in 129.66 seconds!
[tester] 
AGNewsMetric: acc=0.8663157894736843, hinge=1.2265373511063424, ce=8.299993547138415
Global test acc @ epoch 59: 0.8663
Global epoch 60...
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.09577883780002594
Local loss @ local epoch 1: 0.29268068075180054
Local loss @ local epoch 2: 0.08942907303571701
Local loss @ local epoch 3: 0.23648707568645477
Local loss @ local epoch 4: 0.0849103257060051
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.97 seconds!
[tester] 
AGNewsMetric: acc=0.8356578947368422, hinge=1.4199252926675896, ce=6.289934059946161
Local test acc @ epoch 60: 0.8357
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.011052526533603668
Local loss @ local epoch 1: 0.049417171627283096
Local loss @ local epoch 2: 0.06472034007310867
Local loss @ local epoch 3: 0.030338061973452568
Local loss @ local epoch 4: 0.029294656589627266
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.41 seconds!
[tester] 
AGNewsMetric: acc=0.8542105263157894, hinge=1.2826625964516087, ce=6.6486686184531765
Local test acc @ epoch 60: 0.8542
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.5848954319953918
Local loss @ local epoch 1: 0.07280336320400238
Local loss @ local epoch 2: 0.031729985028505325
Local loss @ local epoch 3: 0.043681513518095016
Local loss @ local epoch 4: 0.2660551965236664
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.49 seconds!
[tester] 
AGNewsMetric: acc=0.8438157894736842, hinge=0.9904674146049901, ce=6.386672221735904
Local test acc @ epoch 60: 0.8438
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.006885873153805733
Local loss @ local epoch 1: 0.04055244103074074
Local loss @ local epoch 2: 0.010717351920902729
Local loss @ local epoch 3: 0.03131787106394768
Local loss @ local epoch 4: 0.14331838488578796
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.97 seconds!
[tester] 
AGNewsMetric: acc=0.8771052631578947, hinge=0.9322630382839002, ce=9.329085787722939
Local test acc @ epoch 60: 0.8771
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.10767371207475662
Local loss @ local epoch 1: 0.10304152965545654
Local loss @ local epoch 2: 0.14271433651447296
Local loss @ local epoch 3: 0.20735102891921997
Local loss @ local epoch 4: 0.10661362111568451
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.24 seconds!
[tester] 
AGNewsMetric: acc=0.866578947368421, hinge=1.01586258612181, ce=10.189024178354364
Local test acc @ epoch 60: 0.8666
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.12819263339042664
Local loss @ local epoch 1: 0.07089685648679733
Local loss @ local epoch 2: 0.08083566278219223
Local loss @ local epoch 3: 0.09242410957813263
Local loss @ local epoch 4: 0.05064551532268524
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.93 seconds!
[tester] 
AGNewsMetric: acc=0.8236842105263158, hinge=1.450635314238699, ce=10.11929948304829
Local test acc @ epoch 60: 0.8237
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.012004471383988857
Local loss @ local epoch 1: 0.008114428259432316
Local loss @ local epoch 2: 0.03145413473248482
Local loss @ local epoch 3: 0.006226325407624245
Local loss @ local epoch 4: 0.011042040772736073
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.87 seconds!
[tester] 
AGNewsMetric: acc=0.8552631578947368, hinge=1.1947394950766312, ce=9.889671893872713
Local test acc @ epoch 60: 0.8553
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.33631935715675354
Local loss @ local epoch 1: 0.5004620552062988
Local loss @ local epoch 2: 0.36047229170799255
Local loss @ local epoch 3: 0.44872087240219116
Local loss @ local epoch 4: 0.17643596231937408
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.25 seconds!
[tester] 
AGNewsMetric: acc=0.8518421052631578, hinge=1.0955833169033653, ce=9.140225251850328
Local test acc @ epoch 60: 0.8518
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.009431910701096058
Local loss @ local epoch 1: 0.23605412244796753
Local loss @ local epoch 2: 0.1435183733701706
Local loss @ local epoch 3: 0.2655504047870636
Local loss @ local epoch 4: 0.18928134441375732
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.71 seconds!
[tester] 
AGNewsMetric: acc=0.8034210526315789, hinge=1.5949635259728683, ce=7.547975789120323
Local test acc @ epoch 60: 0.8034
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.24788787961006165
Local loss @ local epoch 1: 0.10311605036258698
Local loss @ local epoch 2: 0.03606878221035004
Local loss @ local epoch 3: 0.1965039074420929
Local loss @ local epoch 4: 0.10336697101593018
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 131.35 seconds!
[tester] 
AGNewsMetric: acc=0.7588157894736842, hinge=1.9832654501262463, ce=6.250060009203459
Local test acc @ epoch 60: 0.7588
Global evaluate on test data...
Evaluate data in 129.18 seconds!
[tester] 
AGNewsMetric: acc=0.8747368421052631, hinge=1.022377990170529, ce=8.843809340627569
Global test acc @ epoch 60: 0.8747
Global epoch 61...
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0736374631524086
Local loss @ local epoch 1: 0.08451973646879196
Local loss @ local epoch 2: 0.06080745905637741
Local loss @ local epoch 3: 0.03705580532550812
Local loss @ local epoch 4: 0.2869036793708801
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.4 seconds!
[tester] 
AGNewsMetric: acc=0.8113157894736842, hinge=1.5045186040275975, ce=8.993961492839613
Local test acc @ epoch 61: 0.8113
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.18230216205120087
Local loss @ local epoch 1: 0.011943545192480087
Local loss @ local epoch 2: 0.13395600020885468
Local loss @ local epoch 3: 0.021605808287858963
Local loss @ local epoch 4: 0.07543838024139404
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 131.03 seconds!
[tester] 
AGNewsMetric: acc=0.824078947368421, hinge=1.1746531885548641, ce=8.39821478592722
Local test acc @ epoch 61: 0.8241
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.14452499151229858
Local loss @ local epoch 1: 0.21263082325458527
Local loss @ local epoch 2: 0.1263091266155243
Local loss @ local epoch 3: 0.13427254557609558
Local loss @ local epoch 4: 0.21831046044826508
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.62 seconds!
[tester] 
AGNewsMetric: acc=0.8575, hinge=1.1967380011709112, ce=9.015046294362921
Local test acc @ epoch 61: 0.8575
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.009030497632920742
Local loss @ local epoch 1: 0.6224681735038757
Local loss @ local epoch 2: 0.017712276428937912
Local loss @ local epoch 3: 0.07774554193019867
Local loss @ local epoch 4: 0.10154752433300018
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.09 seconds!
[tester] 
AGNewsMetric: acc=0.8539473684210527, hinge=1.0200638311787655, ce=7.243190670013428
Local test acc @ epoch 61: 0.8539
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.01147516444325447
Local loss @ local epoch 1: 0.006276422645896673
Local loss @ local epoch 2: 0.026224898174405098
Local loss @ local epoch 3: 0.029173720628023148
Local loss @ local epoch 4: 0.0017288880189880729
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.65 seconds!
[tester] 
AGNewsMetric: acc=0.8703947368421052, hinge=1.205966524575886, ce=7.021460159703305
Local test acc @ epoch 61: 0.8704
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.11195681989192963
Local loss @ local epoch 1: 0.018356094136834145
Local loss @ local epoch 2: 0.074729323387146
Local loss @ local epoch 3: 0.0707005187869072
Local loss @ local epoch 4: 0.07262725383043289
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.13 seconds!
[tester] 
AGNewsMetric: acc=0.8497368421052631, hinge=1.1643515672181781, ce=9.327666176243833
Local test acc @ epoch 61: 0.8497
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.32423603534698486
Local loss @ local epoch 1: 0.06334319710731506
Local loss @ local epoch 2: 0.3131329119205475
Local loss @ local epoch 3: 0.2117839902639389
Local loss @ local epoch 4: 0.08043331652879715
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.26 seconds!
[tester] 
AGNewsMetric: acc=0.8731578947368421, hinge=0.895677500273052, ce=6.4808313399867
Local test acc @ epoch 61: 0.8732
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.03353143855929375
Local loss @ local epoch 1: 0.01818806864321232
Local loss @ local epoch 2: 0.008963534608483315
Local loss @ local epoch 3: 0.013693963177502155
Local loss @ local epoch 4: 0.024096224457025528
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.44 seconds!
[tester] 
AGNewsMetric: acc=0.861578947368421, hinge=1.1785813303997643, ce=7.174227961490029
Local test acc @ epoch 61: 0.8616
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.09492544084787369
Local loss @ local epoch 1: 0.2335667610168457
Local loss @ local epoch 2: 0.07115031033754349
Local loss @ local epoch 3: 0.24125845730304718
Local loss @ local epoch 4: 0.07034843415021896
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.34 seconds!
[tester] 
AGNewsMetric: acc=0.8510526315789474, hinge=1.1195037141599153, ce=7.974256684152704
Local test acc @ epoch 61: 0.8511
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.010610658675432205
Local loss @ local epoch 1: 0.08611202239990234
Local loss @ local epoch 2: 0.00996504444628954
Local loss @ local epoch 3: 0.4307737946510315
Local loss @ local epoch 4: 0.05772215873003006
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.38 seconds!
[tester] 
AGNewsMetric: acc=0.8457894736842105, hinge=1.1091542798594425, ce=9.176242495085063
Local test acc @ epoch 61: 0.8458
Global evaluate on test data...
Evaluate data in 129.64 seconds!
[tester] 
AGNewsMetric: acc=0.8830263157894737, hinge=1.0105339579833181, ce=8.390916982951918
Global test acc @ epoch 61: 0.883
Global epoch 62...
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.2663954794406891
Local loss @ local epoch 1: 0.12150448560714722
Local loss @ local epoch 2: 0.10713700950145721
Local loss @ local epoch 3: 0.08824364840984344
Local loss @ local epoch 4: 0.08430105447769165
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.02 seconds!
[tester] 
AGNewsMetric: acc=0.7934210526315789, hinge=1.5529132704985769, ce=8.95050460213109
Local test acc @ epoch 62: 0.7934
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.042791787534952164
Local loss @ local epoch 1: 0.006727945990860462
Local loss @ local epoch 2: 0.010003352537751198
Local loss @ local epoch 3: 0.01878207176923752
Local loss @ local epoch 4: 0.049141667783260345
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.85 seconds!
[tester] 
AGNewsMetric: acc=0.8503947368421053, hinge=1.0600219673859446, ce=9.318291260568719
Local test acc @ epoch 62: 0.8504
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.09360124170780182
Local loss @ local epoch 1: 0.06653234362602234
Local loss @ local epoch 2: 0.10884318500757217
Local loss @ local epoch 3: 0.11401576548814774
Local loss @ local epoch 4: 0.036239635199308395
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.05 seconds!
[tester] 
AGNewsMetric: acc=0.83, hinge=1.4602126630983854, ce=7.136031088578074
Local test acc @ epoch 62: 0.83
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.009146912023425102
Local loss @ local epoch 1: 0.012622215785086155
Local loss @ local epoch 2: 0.04182198643684387
Local loss @ local epoch 3: 0.05063493922352791
Local loss @ local epoch 4: 0.03573356568813324
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.59 seconds!
[tester] 
AGNewsMetric: acc=0.8644736842105263, hinge=1.038483362448843, ce=8.815326987818668
Local test acc @ epoch 62: 0.8645
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.05983026325702667
Local loss @ local epoch 1: 0.009223331697285175
Local loss @ local epoch 2: 0.11823438853025436
Local loss @ local epoch 3: 0.10771085321903229
Local loss @ local epoch 4: 0.07638285309076309
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.73 seconds!
[tester] 
AGNewsMetric: acc=0.8252631578947368, hinge=1.4141790194260446, ce=8.00257179260254
Local test acc @ epoch 62: 0.8253
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.011045819148421288
Local loss @ local epoch 1: 0.08167580515146255
Local loss @ local epoch 2: 0.004379268269985914
Local loss @ local epoch 3: 0.006609652191400528
Local loss @ local epoch 4: 0.062359802424907684
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.67 seconds!
[tester] 
AGNewsMetric: acc=0.8301315789473684, hinge=1.3093736387553967, ce=5.956727664345189
Local test acc @ epoch 62: 0.8301
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.31454598903656006
Local loss @ local epoch 1: 0.21505539119243622
Local loss @ local epoch 2: 0.061645809561014175
Local loss @ local epoch 3: 0.16914379596710205
Local loss @ local epoch 4: 0.7169792652130127
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.97 seconds!
[tester] 
AGNewsMetric: acc=0.7496052631578948, hinge=2.1185731586657073, ce=7.556412490041632
Local test acc @ epoch 62: 0.7496
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.010571117512881756
Local loss @ local epoch 1: 0.006446953397244215
Local loss @ local epoch 2: 0.017960920929908752
Local loss @ local epoch 3: 0.01707138493657112
Local loss @ local epoch 4: 0.00971589982509613
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.79 seconds!
[tester] 
AGNewsMetric: acc=0.8475, hinge=1.1522963930431165, ce=8.798008238139905
Local test acc @ epoch 62: 0.8475
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00511992909014225
Local loss @ local epoch 1: 0.002006158232688904
Local loss @ local epoch 2: 0.00239606318064034
Local loss @ local epoch 3: 0.004087247885763645
Local loss @ local epoch 4: 0.05501807853579521
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.2 seconds!
[tester] 
AGNewsMetric: acc=0.8486842105263158, hinge=1.3857642326856914, ce=9.54030350333766
Local test acc @ epoch 62: 0.8487
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.2948440611362457
Local loss @ local epoch 1: 0.3096306622028351
Local loss @ local epoch 2: 0.5070559978485107
Local loss @ local epoch 3: 0.2710489332675934
Local loss @ local epoch 4: 0.29084357619285583
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.98 seconds!
[tester] 
AGNewsMetric: acc=0.8551315789473685, hinge=1.0090877128902234, ce=7.068212828385202
Local test acc @ epoch 62: 0.8551
Global evaluate on test data...
Evaluate data in 129.43 seconds!
[tester] 
AGNewsMetric: acc=0.8764473684210526, hinge=1.0294360951373451, ce=8.02578715876529
Global test acc @ epoch 62: 0.8764
Global epoch 63...
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.04645654559135437
Local loss @ local epoch 1: 0.044454656541347504
Local loss @ local epoch 2: 0.08822202682495117
Local loss @ local epoch 3: 0.1228237897157669
Local loss @ local epoch 4: 0.09424495697021484
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.22 seconds!
[tester] 
AGNewsMetric: acc=0.8219736842105263, hinge=1.5149534205386512, ce=7.293258223282663
Local test acc @ epoch 63: 0.822
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0451950840651989
Local loss @ local epoch 1: 0.008274386636912823
Local loss @ local epoch 2: 0.38492703437805176
Local loss @ local epoch 3: 0.11105334013700485
Local loss @ local epoch 4: 0.06893007457256317
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 128.83 seconds!
[tester] 
AGNewsMetric: acc=0.8339473684210527, hinge=1.298083782447012, ce=10.017344450699655
Local test acc @ epoch 63: 0.8339
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.062108688056468964
Local loss @ local epoch 1: 0.005153881385922432
Local loss @ local epoch 2: 0.025203179568052292
Local loss @ local epoch 3: 0.03514550253748894
Local loss @ local epoch 4: 0.07265382260084152
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.08 seconds!
[tester] 
AGNewsMetric: acc=0.8696052631578948, hinge=0.9611619359568546, ce=6.963072276868318
Local test acc @ epoch 63: 0.8696
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.07677151262760162
Local loss @ local epoch 1: 0.0915222018957138
Local loss @ local epoch 2: 0.26005563139915466
Local loss @ local epoch 3: 0.13867580890655518
Local loss @ local epoch 4: 0.1959977000951767
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.44 seconds!
[tester] 
AGNewsMetric: acc=0.8101315789473684, hinge=1.435426852577611, ce=5.790264345470228
Local test acc @ epoch 63: 0.8101
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.043905988335609436
Local loss @ local epoch 1: 0.018554018810391426
Local loss @ local epoch 2: 0.15131115913391113
Local loss @ local epoch 3: 0.047056518495082855
Local loss @ local epoch 4: 0.09517379105091095
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.36 seconds!
[tester] 
AGNewsMetric: acc=0.8313157894736842, hinge=1.2549838176526522, ce=10.038025044892963
Local test acc @ epoch 63: 0.8313
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.07284132391214371
Local loss @ local epoch 1: 0.05964167043566704
Local loss @ local epoch 2: 0.01585282012820244
Local loss @ local epoch 3: 0.1760886311531067
Local loss @ local epoch 4: 0.028787940740585327
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.02 seconds!
[tester] 
AGNewsMetric: acc=0.8403947368421053, hinge=1.2848258952090614, ce=8.53811197180497
Local test acc @ epoch 63: 0.8404
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.003748394316062331
Local loss @ local epoch 1: 0.0010095374891534448
Local loss @ local epoch 2: 0.00342713319696486
Local loss @ local epoch 3: 0.09976903349161148
Local loss @ local epoch 4: 0.378690242767334
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.35 seconds!
[tester] 
AGNewsMetric: acc=0.8525, hinge=1.3234946424082705, ce=9.15668095438104
Local test acc @ epoch 63: 0.8525
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.012175572104752064
Local loss @ local epoch 1: 0.0045461575500667095
Local loss @ local epoch 2: 0.011094572953879833
Local loss @ local epoch 3: 0.0397905632853508
Local loss @ local epoch 4: 0.009710926562547684
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.21 seconds!
[tester] 
AGNewsMetric: acc=0.8657894736842106, hinge=1.1566297317806042, ce=7.235580514606677
Local test acc @ epoch 63: 0.8658
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.003995424136519432
Local loss @ local epoch 1: 0.04656103998422623
Local loss @ local epoch 2: 0.014264405705034733
Local loss @ local epoch 3: 0.34052637219429016
Local loss @ local epoch 4: 0.001594026223756373
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.68 seconds!
[tester] 
AGNewsMetric: acc=0.8269736842105263, hinge=1.3960106869747764, ce=6.769672118739078
Local test acc @ epoch 63: 0.827
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.09450208395719528
Local loss @ local epoch 1: 0.5163472890853882
Local loss @ local epoch 2: 0.014986991882324219
Local loss @ local epoch 3: 0.4778990149497986
Local loss @ local epoch 4: 0.08403157442808151
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.27 seconds!
[tester] 
AGNewsMetric: acc=0.8630263157894736, hinge=1.1055136018050344, ce=10.086391820405659
Local test acc @ epoch 63: 0.863
Global evaluate on test data...
Evaluate data in 130.59 seconds!
[tester] 
AGNewsMetric: acc=0.8760526315789474, hinge=1.1135447093060142, ce=8.280801891527679
Global test acc @ epoch 63: 0.8761
Global epoch 64...
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.005430095829069614
Local loss @ local epoch 1: 0.03974000737071037
Local loss @ local epoch 2: 0.01661982201039791
Local loss @ local epoch 3: 0.2368546426296234
Local loss @ local epoch 4: 0.014310525730252266
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.74 seconds!
[tester] 
AGNewsMetric: acc=0.7960526315789473, hinge=1.5756414832566914, ce=11.048617527610377
Local test acc @ epoch 64: 0.7961
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0030933928210288286
Local loss @ local epoch 1: 0.11383220553398132
Local loss @ local epoch 2: 0.006325911730527878
Local loss @ local epoch 3: 0.002975810319185257
Local loss @ local epoch 4: 0.006071974523365498
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 128.7 seconds!
[tester] 
AGNewsMetric: acc=0.845657894736842, hinge=1.2787715362247667, ce=8.052764725936086
Local test acc @ epoch 64: 0.8457
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.3076511323451996
Local loss @ local epoch 1: 0.05790749937295914
Local loss @ local epoch 2: 0.01910518668591976
Local loss @ local epoch 3: 0.19268283247947693
Local loss @ local epoch 4: 0.04928694665431976
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.08 seconds!
[tester] 
AGNewsMetric: acc=0.8310526315789474, hinge=1.2461622388739335, ce=8.06989290538587
Local test acc @ epoch 64: 0.8311
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.007348916959017515
Local loss @ local epoch 1: 0.004109881818294525
Local loss @ local epoch 2: 0.016654931008815765
Local loss @ local epoch 3: 0.0250590480864048
Local loss @ local epoch 4: 0.023546213284134865
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.38 seconds!
[tester] 
AGNewsMetric: acc=0.8147368421052632, hinge=1.8210971541153758, ce=7.510511914303429
Local test acc @ epoch 64: 0.8147
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.03057551570236683
Local loss @ local epoch 1: 0.04212639480829239
Local loss @ local epoch 2: 0.07184771448373795
Local loss @ local epoch 3: 0.03557094931602478
Local loss @ local epoch 4: 0.21168453991413116
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.89 seconds!
[tester] 
AGNewsMetric: acc=0.8410526315789474, hinge=1.3180897486837286, ce=8.769166675366854
Local test acc @ epoch 64: 0.8411
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.16353437304496765
Local loss @ local epoch 1: 0.0754454955458641
Local loss @ local epoch 2: 0.05191421881318092
Local loss @ local epoch 3: 0.14350496232509613
Local loss @ local epoch 4: 0.0618751123547554
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.41 seconds!
[tester] 
AGNewsMetric: acc=0.8317105263157895, hinge=1.3292594222018592, ce=6.847966982188978
Local test acc @ epoch 64: 0.8317
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.03563122823834419
Local loss @ local epoch 1: 0.13960528373718262
Local loss @ local epoch 2: 0.12213429063558578
Local loss @ local epoch 3: 0.07354326546192169
Local loss @ local epoch 4: 0.29475483298301697
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.49 seconds!
[tester] 
AGNewsMetric: acc=0.7571052631578947, hinge=1.983206514559294, ce=9.359747043408845
Local test acc @ epoch 64: 0.7571
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.025410480797290802
Local loss @ local epoch 1: 0.012033656239509583
Local loss @ local epoch 2: 0.036267317831516266
Local loss @ local epoch 3: 0.16391383111476898
Local loss @ local epoch 4: 0.5374618768692017
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.85 seconds!
[tester] 
AGNewsMetric: acc=0.7685526315789474, hinge=2.6600926165831718, ce=10.486953239440918
Local test acc @ epoch 64: 0.7686
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.013301474042236805
Local loss @ local epoch 1: 0.02675829455256462
Local loss @ local epoch 2: 0.03418095409870148
Local loss @ local epoch 3: 0.026760417968034744
Local loss @ local epoch 4: 0.028583457693457603
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.62 seconds!
[tester] 
AGNewsMetric: acc=0.858421052631579, hinge=1.092436937030993, ce=8.475959117287085
Local test acc @ epoch 64: 0.8584
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.557019054889679
Local loss @ local epoch 1: 0.5926578044891357
Local loss @ local epoch 2: 0.2622612416744232
Local loss @ local epoch 3: 0.2251482605934143
Local loss @ local epoch 4: 0.240152508020401
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.5 seconds!
[tester] 
AGNewsMetric: acc=0.8557894736842105, hinge=0.9955773730027048, ce=8.869272049351743
Local test acc @ epoch 64: 0.8558
Global evaluate on test data...
Evaluate data in 129.58 seconds!
[tester] 
AGNewsMetric: acc=0.8764473684210526, hinge=1.0790338205036365, ce=8.559204344498484
Global test acc @ epoch 64: 0.8764
Global epoch 65...
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.004878091160207987
Local loss @ local epoch 1: 0.11646173149347305
Local loss @ local epoch 2: 0.009007643908262253
Local loss @ local epoch 3: 0.37542709708213806
Local loss @ local epoch 4: 0.06976015865802765
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.21 seconds!
[tester] 
AGNewsMetric: acc=0.8786842105263157, hinge=1.024790475995917, ce=8.632475007709704
Local test acc @ epoch 65: 0.8787
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.006077629514038563
Local loss @ local epoch 1: 0.011751554906368256
Local loss @ local epoch 2: 0.017241070047020912
Local loss @ local epoch 3: 0.013196113519370556
Local loss @ local epoch 4: 0.002638578414916992
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.62 seconds!
[tester] 
AGNewsMetric: acc=0.8631578947368421, hinge=1.0739269954279849, ce=8.629940040989926
Local test acc @ epoch 65: 0.8632
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.02447688579559326
Local loss @ local epoch 1: 0.004926543682813644
Local loss @ local epoch 2: 0.0039017770905047655
Local loss @ local epoch 3: 0.005540961865335703
Local loss @ local epoch 4: 0.12056780606508255
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 128.92 seconds!
[tester] 
AGNewsMetric: acc=0.8357894736842105, hinge=1.4497004411095067, ce=9.074137268066407
Local test acc @ epoch 65: 0.8358
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.020842295140028
Local loss @ local epoch 1: 0.01882268115878105
Local loss @ local epoch 2: 0.16812022030353546
Local loss @ local epoch 3: 0.5242338180541992
Local loss @ local epoch 4: 0.12687988579273224
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.34 seconds!
[tester] 
AGNewsMetric: acc=0.8423684210526315, hinge=1.2930410982433118, ce=7.024050007870323
Local test acc @ epoch 65: 0.8424
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.060230955481529236
Local loss @ local epoch 1: 0.051382072269916534
Local loss @ local epoch 2: 0.20742976665496826
Local loss @ local epoch 3: 0.051489099860191345
Local loss @ local epoch 4: 0.04661630466580391
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 128.97 seconds!
[tester] 
AGNewsMetric: acc=0.8128947368421052, hinge=2.0239132755681086, ce=8.940378401906866
Local test acc @ epoch 65: 0.8129
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.2571010887622833
Local loss @ local epoch 1: 0.21787719428539276
Local loss @ local epoch 2: 0.1321127563714981
Local loss @ local epoch 3: 0.023945318534970284
Local loss @ local epoch 4: 0.14353224635124207
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.49 seconds!
[tester] 
AGNewsMetric: acc=0.8398684210526316, hinge=1.2282488009804173, ce=7.484010505676269
Local test acc @ epoch 65: 0.8399
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.18664440512657166
Local loss @ local epoch 1: 0.3438508212566376
Local loss @ local epoch 2: 0.04389216750860214
Local loss @ local epoch 3: 0.07094438374042511
Local loss @ local epoch 4: 0.2802664637565613
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.89 seconds!
[tester] 
AGNewsMetric: acc=0.8544736842105263, hinge=1.1382693268123425, ce=9.646274721246016
Local test acc @ epoch 65: 0.8545
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.4442451596260071
Local loss @ local epoch 1: 0.02037873864173889
Local loss @ local epoch 2: 0.5099707841873169
Local loss @ local epoch 3: 0.22146952152252197
Local loss @ local epoch 4: 0.19047556817531586
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.21 seconds!
[tester] 
AGNewsMetric: acc=0.7622368421052632, hinge=1.8124748275154516, ce=6.489408438833136
Local test acc @ epoch 65: 0.7622
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.008142612874507904
Local loss @ local epoch 1: 0.01109326258301735
Local loss @ local epoch 2: 0.018544083461165428
Local loss @ local epoch 3: 0.0035655731335282326
Local loss @ local epoch 4: 0.004588945768773556
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.81 seconds!
[tester] 
AGNewsMetric: acc=0.8569736842105263, hinge=1.2049429471869217, ce=5.617166058389764
Local test acc @ epoch 65: 0.857
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0878181979060173
Local loss @ local epoch 1: 0.007172673940658569
Local loss @ local epoch 2: 0.013886857777833939
Local loss @ local epoch 3: 0.03070034086704254
Local loss @ local epoch 4: 0.40896621346473694
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.26 seconds!
[tester] 
AGNewsMetric: acc=0.8452631578947368, hinge=1.2393484755566246, ce=8.148598668951736
Local test acc @ epoch 65: 0.8453
Global evaluate on test data...
Evaluate data in 128.79 seconds!
[tester] 
AGNewsMetric: acc=0.8756578947368421, hinge=1.0900633799402337, ce=7.843865199841951
Global test acc @ epoch 65: 0.8757
Global epoch 66...
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.10165576636791229
Local loss @ local epoch 1: 0.031826481223106384
Local loss @ local epoch 2: 0.10259288549423218
Local loss @ local epoch 3: 0.1303613781929016
Local loss @ local epoch 4: 0.0267473254352808
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.8 seconds!
[tester] 
AGNewsMetric: acc=0.8622368421052632, hinge=1.1428966886118839, ce=8.387543059901187
Local test acc @ epoch 66: 0.8622
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.03303256630897522
Local loss @ local epoch 1: 0.013546672649681568
Local loss @ local epoch 2: 0.07085368782281876
Local loss @ local epoch 3: 0.021718861535191536
Local loss @ local epoch 4: 0.056712809950113297
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.68 seconds!
[tester] 
AGNewsMetric: acc=0.8369736842105263, hinge=1.4080158110668786, ce=9.619475507234272
Local test acc @ epoch 66: 0.837
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.004057073500007391
Local loss @ local epoch 1: 0.0031539290212094784
Local loss @ local epoch 2: 0.0017312228446826339
Local loss @ local epoch 3: 0.0013765986077487469
Local loss @ local epoch 4: 0.0026458497159183025
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.74 seconds!
[tester] 
AGNewsMetric: acc=0.863421052631579, hinge=1.2470607378608303, ce=10.687309279190867
Local test acc @ epoch 66: 0.8634
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.015569470822811127
Local loss @ local epoch 1: 0.0038417165633291006
Local loss @ local epoch 2: 0.03936706855893135
Local loss @ local epoch 3: 0.07555117458105087
Local loss @ local epoch 4: 0.031417958438396454
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.41 seconds!
[tester] 
AGNewsMetric: acc=0.8468421052631578, hinge=1.322085011130885, ce=9.773622135363127
Local test acc @ epoch 66: 0.8468
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.22172501683235168
Local loss @ local epoch 1: 0.17492400109767914
Local loss @ local epoch 2: 0.08428654074668884
Local loss @ local epoch 3: 0.0850783959031105
Local loss @ local epoch 4: 0.20321859419345856
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.46 seconds!
[tester] 
AGNewsMetric: acc=0.8236842105263158, hinge=1.3299991672917417, ce=9.059164237976074
Local test acc @ epoch 66: 0.8237
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.1015021875500679
Local loss @ local epoch 1: 0.005503410007804632
Local loss @ local epoch 2: 0.03147773817181587
Local loss @ local epoch 3: 0.18751563131809235
Local loss @ local epoch 4: 0.012672322802245617
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.27 seconds!
[tester] 
AGNewsMetric: acc=0.8630263157894736, hinge=0.9662825044832731, ce=8.199189067639802
Local test acc @ epoch 66: 0.863
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.10765980184078217
Local loss @ local epoch 1: 0.053873755037784576
Local loss @ local epoch 2: 0.023611806333065033
Local loss @ local epoch 3: 0.05610896274447441
Local loss @ local epoch 4: 0.2386133223772049
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.89 seconds!
[tester] 
AGNewsMetric: acc=0.8186842105263158, hinge=1.262585708467584, ce=8.888461161161723
Local test acc @ epoch 66: 0.8187
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.007189223542809486
Local loss @ local epoch 1: 0.0015239837812259793
Local loss @ local epoch 2: 0.013529998250305653
Local loss @ local epoch 3: 0.015417566522955894
Local loss @ local epoch 4: 0.017026152461767197
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.82 seconds!
[tester] 
AGNewsMetric: acc=0.8578947368421053, hinge=1.2021117519077502, ce=9.796324535169099
Local test acc @ epoch 66: 0.8579
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.4480946958065033
Local loss @ local epoch 1: 0.12131080776453018
Local loss @ local epoch 2: 0.23590296506881714
Local loss @ local epoch 3: 0.7032886743545532
Local loss @ local epoch 4: 0.363262802362442
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.54 seconds!
[tester] 
AGNewsMetric: acc=0.8573684210526316, hinge=1.157496536405463, ce=7.876844129060444
Local test acc @ epoch 66: 0.8574
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.008012253791093826
Local loss @ local epoch 1: 0.018932383507490158
Local loss @ local epoch 2: 0.013525369577109814
Local loss @ local epoch 3: 0.028340429067611694
Local loss @ local epoch 4: 0.054561909288167953
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.94 seconds!
[tester] 
AGNewsMetric: acc=0.8219736842105263, hinge=1.411072366363124, ce=7.774940069098221
Local test acc @ epoch 66: 0.822
Global evaluate on test data...
Evaluate data in 130.42 seconds!
[tester] 
AGNewsMetric: acc=0.8635526315789473, hinge=1.2239056998804996, ce=8.505251603377493
Global test acc @ epoch 66: 0.8636
Global epoch 67...
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.1436668485403061
Local loss @ local epoch 1: 0.17352284491062164
Local loss @ local epoch 2: 0.04815801978111267
Local loss @ local epoch 3: 0.4721880555152893
Local loss @ local epoch 4: 0.07039891928434372
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.07 seconds!
[tester] 
AGNewsMetric: acc=0.8659210526315789, hinge=1.0899755367479826, ce=6.587229010933324
Local test acc @ epoch 67: 0.8659
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.008337747305631638
Local loss @ local epoch 1: 0.04431472346186638
Local loss @ local epoch 2: 0.009351884014904499
Local loss @ local epoch 3: 0.17168627679347992
Local loss @ local epoch 4: 0.01759810373187065
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.84 seconds!
[tester] 
AGNewsMetric: acc=0.8297368421052631, hinge=1.5345714714652614, ce=7.2104559988724555
Local test acc @ epoch 67: 0.8297
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.079964280128479
Local loss @ local epoch 1: 0.09662441164255142
Local loss @ local epoch 2: 0.03419744595885277
Local loss @ local epoch 3: 0.05526096001267433
Local loss @ local epoch 4: 0.19384141266345978
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.39 seconds!
[tester] 
AGNewsMetric: acc=0.7869736842105263, hinge=1.4776405472504466, ce=8.516526511342901
Local test acc @ epoch 67: 0.787
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.07389368861913681
Local loss @ local epoch 1: 0.01109994389116764
Local loss @ local epoch 2: 0.030478332191705704
Local loss @ local epoch 3: 0.01451677642762661
Local loss @ local epoch 4: 0.016099249944090843
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.11 seconds!
[tester] 
AGNewsMetric: acc=0.8281578947368421, hinge=1.3201951852597689, ce=4.4760944868388925
Local test acc @ epoch 67: 0.8282
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.18111449480056763
Local loss @ local epoch 1: 0.12086263298988342
Local loss @ local epoch 2: 0.18883267045021057
Local loss @ local epoch 3: 0.06689301878213882
Local loss @ local epoch 4: 0.16679269075393677
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.53 seconds!
[tester] 
AGNewsMetric: acc=0.8406578947368422, hinge=1.2641905232479698, ce=6.670807476043701
Local test acc @ epoch 67: 0.8407
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.004261151887476444
Local loss @ local epoch 1: 0.30385899543762207
Local loss @ local epoch 2: 0.01236771047115326
Local loss @ local epoch 3: 0.04933701455593109
Local loss @ local epoch 4: 0.08710405230522156
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.89 seconds!
[tester] 
AGNewsMetric: acc=0.8439473684210527, hinge=1.2432528832084255, ce=7.7912296666597065
Local test acc @ epoch 67: 0.8439
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0023829631973057985
Local loss @ local epoch 1: 0.0011188770877197385
Local loss @ local epoch 2: 0.0209762342274189
Local loss @ local epoch 3: 0.009727402590215206
Local loss @ local epoch 4: 0.003372340463101864
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.76 seconds!
[tester] 
AGNewsMetric: acc=0.8667105263157895, hinge=1.2560399429421676, ce=6.920151688425165
Local test acc @ epoch 67: 0.8667
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0031720618717372417
Local loss @ local epoch 1: 0.0077581945806741714
Local loss @ local epoch 2: 0.0018411049386486411
Local loss @ local epoch 3: 0.009524372406303883
Local loss @ local epoch 4: 0.010069508105516434
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.65 seconds!
[tester] 
AGNewsMetric: acc=0.8530263157894736, hinge=1.3899113115511443, ce=7.484927544844778
Local test acc @ epoch 67: 0.853
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.02938687428832054
Local loss @ local epoch 1: 0.007022202014923096
Local loss @ local epoch 2: 0.1601274162530899
Local loss @ local epoch 3: 0.03890936076641083
Local loss @ local epoch 4: 0.15706473588943481
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.57 seconds!
[tester] 
AGNewsMetric: acc=0.7627631578947368, hinge=1.9034586540021394, ce=10.104670466372841
Local test acc @ epoch 67: 0.7628
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.019865574315190315
Local loss @ local epoch 1: 0.012278592213988304
Local loss @ local epoch 2: 0.007338738068938255
Local loss @ local epoch 3: 0.1479477882385254
Local loss @ local epoch 4: 0.03214188665151596
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.33 seconds!
[tester] 
AGNewsMetric: acc=0.8582894736842105, hinge=1.2118344773744283, ce=9.058345565795898
Local test acc @ epoch 67: 0.8583
Global evaluate on test data...
Evaluate data in 129.85 seconds!
[tester] 
AGNewsMetric: acc=0.8735526315789474, hinge=1.173745813369751, ce=7.421078537388852
Global test acc @ epoch 67: 0.8736
Global epoch 68...
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.018396396189928055
Local loss @ local epoch 1: 0.19202105700969696
Local loss @ local epoch 2: 0.11829737573862076
Local loss @ local epoch 3: 0.20981931686401367
Local loss @ local epoch 4: 0.020959410816431046
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.7 seconds!
[tester] 
AGNewsMetric: acc=0.866578947368421, hinge=1.0772323442760268, ce=8.882952977230675
Local test acc @ epoch 68: 0.8666
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.004911055322736502
Local loss @ local epoch 1: 0.561533510684967
Local loss @ local epoch 2: 0.009281745180487633
Local loss @ local epoch 3: 0.033465102314949036
Local loss @ local epoch 4: 0.09506945312023163
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.41 seconds!
[tester] 
AGNewsMetric: acc=0.868421052631579, hinge=0.9746789425297787, ce=6.358947741859837
Local test acc @ epoch 68: 0.8684
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.18963117897510529
Local loss @ local epoch 1: 0.02695200778543949
Local loss @ local epoch 2: 0.0926331952214241
Local loss @ local epoch 3: 0.03834175691008568
Local loss @ local epoch 4: 0.17658744752407074
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.66 seconds!
[tester] 
AGNewsMetric: acc=0.8581578947368421, hinge=1.2196776553204185, ce=8.515063902202405
Local test acc @ epoch 68: 0.8582
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.1853673905134201
Local loss @ local epoch 1: 0.0899193063378334
Local loss @ local epoch 2: 0.1614171266555786
Local loss @ local epoch 3: 0.06721356511116028
Local loss @ local epoch 4: 0.16730794310569763
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.49 seconds!
[tester] 
AGNewsMetric: acc=0.7919736842105263, hinge=1.4871973956258673, ce=5.885572817953009
Local test acc @ epoch 68: 0.792
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.01140536554157734
Local loss @ local epoch 1: 0.01725420542061329
Local loss @ local epoch 2: 0.16484318673610687
Local loss @ local epoch 3: 0.0315730944275856
Local loss @ local epoch 4: 0.03804776445031166
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.92 seconds!
[tester] 
AGNewsMetric: acc=0.7821052631578947, hinge=1.8796004343032837, ce=6.804517344424599
Local test acc @ epoch 68: 0.7821
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.002434544265270233
Local loss @ local epoch 1: 0.016605259850621223
Local loss @ local epoch 2: 0.006219933275133371
Local loss @ local epoch 3: 0.10296153277158737
Local loss @ local epoch 4: 0.01254030130803585
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.95 seconds!
[tester] 
AGNewsMetric: acc=0.8623684210526316, hinge=1.1385825935162996, ce=9.281400786951968
Local test acc @ epoch 68: 0.8624
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.16530852019786835
Local loss @ local epoch 1: 0.3704814910888672
Local loss @ local epoch 2: 0.07619532942771912
Local loss @ local epoch 3: 0.07727594673633575
Local loss @ local epoch 4: 0.00931121688336134
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.8 seconds!
[tester] 
AGNewsMetric: acc=0.7602631578947369, hinge=2.2800260664287366, ce=11.49592469064813
Local test acc @ epoch 68: 0.7603
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.006356431171298027
Local loss @ local epoch 1: 0.005355110391974449
Local loss @ local epoch 2: 0.002239915542304516
Local loss @ local epoch 3: 0.002254950813949108
Local loss @ local epoch 4: 0.03829842805862427
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.27 seconds!
[tester] 
AGNewsMetric: acc=0.8639473684210527, hinge=1.2886864064869128, ce=6.9441271530954465
Local test acc @ epoch 68: 0.8639
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.060357093811035156
Local loss @ local epoch 1: 0.07031885534524918
Local loss @ local epoch 2: 0.17292436957359314
Local loss @ local epoch 3: 0.5123414993286133
Local loss @ local epoch 4: 0.18914839625358582
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.69 seconds!
[tester] 
AGNewsMetric: acc=0.844078947368421, hinge=1.0902035439641853, ce=7.387914037202534
Local test acc @ epoch 68: 0.8441
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.009144744835793972
Local loss @ local epoch 1: 0.0019773519597947598
Local loss @ local epoch 2: 0.01629377342760563
Local loss @ local epoch 3: 0.06563772261142731
Local loss @ local epoch 4: 0.14561183750629425
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.65 seconds!
[tester] 
AGNewsMetric: acc=0.8101315789473684, hinge=1.753924523905704, ce=7.097598152160645
Local test acc @ epoch 68: 0.8101
Global evaluate on test data...
Evaluate data in 130.09 seconds!
[tester] 
AGNewsMetric: acc=0.8655263157894737, hinge=1.2774853811765972, ce=7.442816405045359
Global test acc @ epoch 68: 0.8655
Global epoch 69...
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0015040884027257562
Local loss @ local epoch 1: 0.018409335985779762
Local loss @ local epoch 2: 0.007639664225280285
Local loss @ local epoch 3: 0.20211857557296753
Local loss @ local epoch 4: 0.0009757468942552805
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.5 seconds!
[tester] 
AGNewsMetric: acc=0.8503947368421053, hinge=1.3299748701798288, ce=7.5563787078857425
Local test acc @ epoch 69: 0.8504
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.226705864071846
Local loss @ local epoch 1: 0.026339460164308548
Local loss @ local epoch 2: 0.37908512353897095
Local loss @ local epoch 3: 0.3327697217464447
Local loss @ local epoch 4: 0.1310371309518814
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.19 seconds!
[tester] 
AGNewsMetric: acc=0.810921052631579, hinge=1.7641337000696282, ce=8.70967922813014
Local test acc @ epoch 69: 0.8109
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.4042465090751648
Local loss @ local epoch 1: 0.18049871921539307
Local loss @ local epoch 2: 0.16462914645671844
Local loss @ local epoch 3: 0.29542699456214905
Local loss @ local epoch 4: 0.43924403190612793
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.68 seconds!
[tester] 
AGNewsMetric: acc=0.8261842105263157, hinge=1.2229324242943211, ce=9.604825997603568
Local test acc @ epoch 69: 0.8262
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.15374015271663666
Local loss @ local epoch 1: 0.13874827325344086
Local loss @ local epoch 2: 0.13385316729545593
Local loss @ local epoch 3: 0.3341836631298065
Local loss @ local epoch 4: 0.3066273033618927
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.45 seconds!
[tester] 
AGNewsMetric: acc=0.8023684210526316, hinge=1.3951268459621229, ce=6.5730610606544895
Local test acc @ epoch 69: 0.8024
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.005368503276258707
Local loss @ local epoch 1: 0.004379077814519405
Local loss @ local epoch 2: 0.02307053841650486
Local loss @ local epoch 3: 0.005098820198327303
Local loss @ local epoch 4: 0.027479806914925575
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.92 seconds!
[tester] 
AGNewsMetric: acc=0.8705263157894737, hinge=1.078370054897509, ce=7.4181602698878235
Local test acc @ epoch 69: 0.8705
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0012109960662201047
Local loss @ local epoch 1: 0.0009975507855415344
Local loss @ local epoch 2: 0.055822256952524185
Local loss @ local epoch 3: 0.00205865316092968
Local loss @ local epoch 4: 0.0035988884046673775
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.06 seconds!
[tester] 
AGNewsMetric: acc=0.8468421052631578, hinge=1.4593753573769017, ce=6.364469827350817
Local test acc @ epoch 69: 0.8468
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0029652314260601997
Local loss @ local epoch 1: 0.23670010268688202
Local loss @ local epoch 2: 0.02146044187247753
Local loss @ local epoch 3: 0.10253319144248962
Local loss @ local epoch 4: 0.005854791030287743
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.05 seconds!
[tester] 
AGNewsMetric: acc=0.8613157894736843, hinge=1.0511595183924625, ce=7.4945792388916015
Local test acc @ epoch 69: 0.8613
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.02193605899810791
Local loss @ local epoch 1: 0.0022817193530499935
Local loss @ local epoch 2: 0.25106537342071533
Local loss @ local epoch 3: 0.05592544004321098
Local loss @ local epoch 4: 0.16580381989479065
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.91 seconds!
[tester] 
AGNewsMetric: acc=0.8676315789473684, hinge=1.245265979264912, ce=8.572123331772653
Local test acc @ epoch 69: 0.8676
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.010268990881741047
Local loss @ local epoch 1: 0.02009960636496544
Local loss @ local epoch 2: 0.009904852136969566
Local loss @ local epoch 3: 0.04942043498158455
Local loss @ local epoch 4: 0.021368108689785004
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.93 seconds!
[tester] 
AGNewsMetric: acc=0.8701315789473684, hinge=0.9024618023320248, ce=7.927783193086323
Local test acc @ epoch 69: 0.8701
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.021337008103728294
Local loss @ local epoch 1: 0.05106150731444359
Local loss @ local epoch 2: 0.031052619218826294
Local loss @ local epoch 3: 0.09895013272762299
Local loss @ local epoch 4: 0.12506939470767975
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.1 seconds!
[tester] 
AGNewsMetric: acc=0.8421052631578947, hinge=1.4056891883047002, ce=7.170953341032329
Local test acc @ epoch 69: 0.8421
Global evaluate on test data...
Evaluate data in 129.85 seconds!
[tester] 
AGNewsMetric: acc=0.8761842105263158, hinge=1.092736546867772, ce=7.63651145332738
Global test acc @ epoch 69: 0.8762
Global epoch 70...
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0013673101784661412
Local loss @ local epoch 1: 0.008175985887646675
Local loss @ local epoch 2: 0.0012968323426321149
Local loss @ local epoch 3: 0.003262878395617008
Local loss @ local epoch 4: 0.012319260276854038
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.04 seconds!
[tester] 
AGNewsMetric: acc=0.8527631578947369, hinge=1.2947889034371627, ce=8.739682900278192
Local test acc @ epoch 70: 0.8528
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.001842829049564898
Local loss @ local epoch 1: 0.0332343652844429
Local loss @ local epoch 2: 0.004597860854119062
Local loss @ local epoch 3: 0.010921982116997242
Local loss @ local epoch 4: 0.02550322934985161
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.13 seconds!
[tester] 
AGNewsMetric: acc=0.8668421052631579, hinge=1.2580328760649029, ce=9.34628714912816
Local test acc @ epoch 70: 0.8668
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0274103544652462
Local loss @ local epoch 1: 0.007837471552193165
Local loss @ local epoch 2: 0.09000243991613388
Local loss @ local epoch 3: 0.06844853609800339
Local loss @ local epoch 4: 0.03302536904811859
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.36 seconds!
[tester] 
AGNewsMetric: acc=0.8146052631578947, hinge=1.94418624200319, ce=8.576691585339997
Local test acc @ epoch 70: 0.8146
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.16484855115413666
Local loss @ local epoch 1: 0.011659031733870506
Local loss @ local epoch 2: 0.03406866267323494
Local loss @ local epoch 3: 0.13483241200447083
Local loss @ local epoch 4: 0.029448719695210457
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.63 seconds!
[tester] 
AGNewsMetric: acc=0.8546052631578948, hinge=1.271522062201249, ce=6.95328526346307
Local test acc @ epoch 70: 0.8546
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.038424160331487656
Local loss @ local epoch 1: 0.012387050315737724
Local loss @ local epoch 2: 0.018553415313363075
Local loss @ local epoch 3: 0.01573566533625126
Local loss @ local epoch 4: 0.006194682791829109
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.28 seconds!
[tester] 
AGNewsMetric: acc=0.8552631578947368, hinge=1.1031455270867598, ce=8.883194262855932
Local test acc @ epoch 70: 0.8553
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.10035306960344315
Local loss @ local epoch 1: 0.0380810871720314
Local loss @ local epoch 2: 0.1361709088087082
Local loss @ local epoch 3: 0.04864279925823212
Local loss @ local epoch 4: 0.14069761335849762
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.91 seconds!
[tester] 
AGNewsMetric: acc=0.8168421052631579, hinge=1.7462365562037419, ce=7.52812113912482
Local test acc @ epoch 70: 0.8168
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.022187281399965286
Local loss @ local epoch 1: 0.009635799564421177
Local loss @ local epoch 2: 0.0310214813798666
Local loss @ local epoch 3: 0.017214080318808556
Local loss @ local epoch 4: 0.07416605949401855
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.57 seconds!
[tester] 
AGNewsMetric: acc=0.8801315789473684, hinge=0.9568256955397757, ce=6.336856330068488
Local test acc @ epoch 70: 0.8801
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.05701672285795212
Local loss @ local epoch 1: 0.10943694412708282
Local loss @ local epoch 2: 0.12049321085214615
Local loss @ local epoch 3: 0.03740463778376579
Local loss @ local epoch 4: 0.18597786128520966
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.66 seconds!
[tester] 
AGNewsMetric: acc=0.8180263157894737, hinge=1.4028409240120336, ce=7.641770358838533
Local test acc @ epoch 70: 0.818
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.1562340259552002
Local loss @ local epoch 1: 0.07811035960912704
Local loss @ local epoch 2: 0.004863550420850515
Local loss @ local epoch 3: 0.01050310768187046
Local loss @ local epoch 4: 0.10260426253080368
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.76 seconds!
[tester] 
AGNewsMetric: acc=0.7888157894736842, hinge=1.7893100377133018, ce=9.029725791529605
Local test acc @ epoch 70: 0.7888
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0641729012131691
Local loss @ local epoch 1: 0.2038196176290512
Local loss @ local epoch 2: 0.08474080264568329
Local loss @ local epoch 3: 0.036969784647226334
Local loss @ local epoch 4: 0.04891335591673851
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.36 seconds!
[tester] 
AGNewsMetric: acc=0.7871052631578948, hinge=1.9018824881001524, ce=8.556394481658936
Local test acc @ epoch 70: 0.7871
Global evaluate on test data...
Evaluate data in 129.09 seconds!
[tester] 
AGNewsMetric: acc=0.8664473684210526, hinge=1.3340234560715525, ce=8.123695662649054
Global test acc @ epoch 70: 0.8664
Global epoch 71...
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.013737814500927925
Local loss @ local epoch 1: 0.086380735039711
Local loss @ local epoch 2: 0.03210616484284401
Local loss @ local epoch 3: 0.15122190117835999
Local loss @ local epoch 4: 0.0042844959534704685
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 128.86 seconds!
[tester] 
AGNewsMetric: acc=0.845, hinge=1.597708905370612, ce=7.956564459549753
Local test acc @ epoch 71: 0.845
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0017831256845965981
Local loss @ local epoch 1: 0.004051276948302984
Local loss @ local epoch 2: 0.005430999677628279
Local loss @ local epoch 3: 0.019629597663879395
Local loss @ local epoch 4: 0.014205780811607838
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 128.96 seconds!
[tester] 
AGNewsMetric: acc=0.8425, hinge=1.374434434740167, ce=9.56030864314029
Local test acc @ epoch 71: 0.8425
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0023624105378985405
Local loss @ local epoch 1: 0.012672962620854378
Local loss @ local epoch 2: 0.003310196567326784
Local loss @ local epoch 3: 0.015134645625948906
Local loss @ local epoch 4: 0.009830611757934093
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.35 seconds!
[tester] 
AGNewsMetric: acc=0.8310526315789474, hinge=1.3231281079744037, ce=9.823297910188375
Local test acc @ epoch 71: 0.8311
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.23214282095432281
Local loss @ local epoch 1: 0.20972733199596405
Local loss @ local epoch 2: 0.22783757746219635
Local loss @ local epoch 3: 0.48519447445869446
Local loss @ local epoch 4: 0.3668227195739746
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.13 seconds!
[tester] 
AGNewsMetric: acc=0.8175, hinge=1.2322455752523322, ce=7.126989764163369
Local test acc @ epoch 71: 0.8175
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.049360763281583786
Local loss @ local epoch 1: 0.10992096364498138
Local loss @ local epoch 2: 0.25179240107536316
Local loss @ local epoch 3: 0.04185075685381889
Local loss @ local epoch 4: 0.11150535941123962
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.05 seconds!
[tester] 
AGNewsMetric: acc=0.8144736842105263, hinge=1.5069804916883769, ce=8.125650976080644
Local test acc @ epoch 71: 0.8145
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.01554882526397705
Local loss @ local epoch 1: 0.08593771606683731
Local loss @ local epoch 2: 0.0027000964619219303
Local loss @ local epoch 3: 0.0034281141124665737
Local loss @ local epoch 4: 0.34896352887153625
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.86 seconds!
[tester] 
AGNewsMetric: acc=0.8257894736842105, hinge=1.6308038056524177, ce=8.742069999293276
Local test acc @ epoch 71: 0.8258
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.006383187603205442
Local loss @ local epoch 1: 0.025585243478417397
Local loss @ local epoch 2: 0.00493997847661376
Local loss @ local epoch 3: 0.0024518142454326153
Local loss @ local epoch 4: 0.010172255337238312
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.68 seconds!
[tester] 
AGNewsMetric: acc=0.8611842105263158, hinge=1.3212469718330784, ce=8.60054894899067
Local test acc @ epoch 71: 0.8612
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.01929955929517746
Local loss @ local epoch 1: 0.04108460620045662
Local loss @ local epoch 2: 0.003576125716790557
Local loss @ local epoch 3: 0.026283781975507736
Local loss @ local epoch 4: 0.03355349227786064
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.3 seconds!
[tester] 
AGNewsMetric: acc=0.8613157894736843, hinge=1.1542450360247964, ce=8.290236390766344
Local test acc @ epoch 71: 0.8613
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0668511837720871
Local loss @ local epoch 1: 0.14844480156898499
Local loss @ local epoch 2: 0.10509545356035233
Local loss @ local epoch 3: 0.021177301183342934
Local loss @ local epoch 4: 0.1670100837945938
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.46 seconds!
[tester] 
AGNewsMetric: acc=0.8280263157894737, hinge=1.439203822487279, ce=6.516434019992226
Local test acc @ epoch 71: 0.828
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.008222423493862152
Local loss @ local epoch 1: 0.005227591842412949
Local loss @ local epoch 2: 0.009224088862538338
Local loss @ local epoch 3: 0.04325643181800842
Local loss @ local epoch 4: 0.027491027489304543
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.81 seconds!
[tester] 
AGNewsMetric: acc=0.8582894736842105, hinge=1.0755525139758462, ce=5.117344467765407
Local test acc @ epoch 71: 0.8583
Global evaluate on test data...
Evaluate data in 129.44 seconds!
[tester] 
AGNewsMetric: acc=0.8706578947368421, hinge=1.241667675470051, ce=7.696201663770173
Global test acc @ epoch 71: 0.8707
Global epoch 72...
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0011968878097832203
Local loss @ local epoch 1: 0.004481458105146885
Local loss @ local epoch 2: 0.03272116184234619
Local loss @ local epoch 3: 0.007994018495082855
Local loss @ local epoch 4: 0.02595684863626957
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.43 seconds!
[tester] 
AGNewsMetric: acc=0.8314473684210526, hinge=1.5373506593704223, ce=6.985186726419549
Local test acc @ epoch 72: 0.8314
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.10875910520553589
Local loss @ local epoch 1: 0.09034213423728943
Local loss @ local epoch 2: 0.4280689060688019
Local loss @ local epoch 3: 0.3661927878856659
Local loss @ local epoch 4: 0.35956016182899475
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.93 seconds!
[tester] 
AGNewsMetric: acc=0.8371052631578947, hinge=1.2312812546679848, ce=9.583519078304892
Local test acc @ epoch 72: 0.8371
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.020353076979517937
Local loss @ local epoch 1: 0.3119603395462036
Local loss @ local epoch 2: 0.02912677451968193
Local loss @ local epoch 3: 0.07783550024032593
Local loss @ local epoch 4: 0.126591295003891
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.28 seconds!
[tester] 
AGNewsMetric: acc=0.8628947368421053, hinge=1.2313576005634508, ce=8.231390961094906
Local test acc @ epoch 72: 0.8629
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.12467130273580551
Local loss @ local epoch 1: 0.049886856228113174
Local loss @ local epoch 2: 0.1204376369714737
Local loss @ local epoch 3: 0.025117821991443634
Local loss @ local epoch 4: 0.08059922605752945
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.3 seconds!
[tester] 
AGNewsMetric: acc=0.8321052631578948, hinge=1.2872500073282342, ce=7.036138719257555
Local test acc @ epoch 72: 0.8321
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.004013524856418371
Local loss @ local epoch 1: 0.007659923750907183
Local loss @ local epoch 2: 0.004148303531110287
Local loss @ local epoch 3: 0.03438725695014
Local loss @ local epoch 4: 0.015965614467859268
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 128.99 seconds!
[tester] 
AGNewsMetric: acc=0.8247368421052632, hinge=1.4876280779587594, ce=7.561312395396985
Local test acc @ epoch 72: 0.8247
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.03204601630568504
Local loss @ local epoch 1: 0.14160402119159698
Local loss @ local epoch 2: 0.10928408801555634
Local loss @ local epoch 3: 0.18494677543640137
Local loss @ local epoch 4: 0.041034597903490067
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.33 seconds!
[tester] 
AGNewsMetric: acc=0.8356578947368422, hinge=1.3179155510350278, ce=9.372470849689684
Local test acc @ epoch 72: 0.8357
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.003165698144584894
Local loss @ local epoch 1: 0.03163253888487816
Local loss @ local epoch 2: 0.002800511894747615
Local loss @ local epoch 3: 0.17174381017684937
Local loss @ local epoch 4: 0.06529340147972107
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.08 seconds!
[tester] 
AGNewsMetric: acc=0.8369736842105263, hinge=1.4876051192534598, ce=9.677309056332238
Local test acc @ epoch 72: 0.837
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.02926897630095482
Local loss @ local epoch 1: 0.04205651208758354
Local loss @ local epoch 2: 0.002933176001533866
Local loss @ local epoch 3: 0.11649604886770248
Local loss @ local epoch 4: 0.009485429152846336
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.89 seconds!
[tester] 
AGNewsMetric: acc=0.8542105263157894, hinge=1.2278084059765464, ce=8.811415820874666
Local test acc @ epoch 72: 0.8542
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.06085364148020744
Local loss @ local epoch 1: 0.07148343324661255
Local loss @ local epoch 2: 0.01868719421327114
Local loss @ local epoch 3: 0.3700380325317383
Local loss @ local epoch 4: 0.2898953855037689
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.84 seconds!
[tester] 
AGNewsMetric: acc=0.7717105263157895, hinge=2.0159810686111452, ce=8.745064534639058
Local test acc @ epoch 72: 0.7717
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.002721145050600171
Local loss @ local epoch 1: 0.051820337772369385
Local loss @ local epoch 2: 0.002555831568315625
Local loss @ local epoch 3: 0.011042801663279533
Local loss @ local epoch 4: 0.00347115658223629
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.71 seconds!
[tester] 
AGNewsMetric: acc=0.8361842105263158, hinge=1.5117581804175126, ce=8.641807056226229
Local test acc @ epoch 72: 0.8362
Global evaluate on test data...
Evaluate data in 129.38 seconds!
[tester] 
AGNewsMetric: acc=0.8696052631578948, hinge=1.2799784369217722, ce=8.219805926272743
Global test acc @ epoch 72: 0.8696
Global epoch 73...
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.08593234419822693
Local loss @ local epoch 1: 0.009924259036779404
Local loss @ local epoch 2: 0.012240455485880375
Local loss @ local epoch 3: 0.0869012176990509
Local loss @ local epoch 4: 0.03442006930708885
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.33 seconds!
[tester] 
AGNewsMetric: acc=0.8307894736842105, hinge=1.3286929456811203, ce=7.813144342522872
Local test acc @ epoch 73: 0.8308
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.1996045559644699
Local loss @ local epoch 1: 0.024796590209007263
Local loss @ local epoch 2: 0.8532998561859131
Local loss @ local epoch 3: 0.13313817977905273
Local loss @ local epoch 4: 0.6019397377967834
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.56 seconds!
[tester] 
AGNewsMetric: acc=0.815, hinge=1.4632688201101203, ce=9.300926549811113
Local test acc @ epoch 73: 0.815
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0017062344122678041
Local loss @ local epoch 1: 0.020126868039369583
Local loss @ local epoch 2: 0.0038510204758495092
Local loss @ local epoch 3: 0.004943093750625849
Local loss @ local epoch 4: 0.0008114648517221212
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.26 seconds!
[tester] 
AGNewsMetric: acc=0.8509210526315789, hinge=1.5282801625603124, ce=8.750320940519634
Local test acc @ epoch 73: 0.8509
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.026615183800458908
Local loss @ local epoch 1: 0.018449334427714348
Local loss @ local epoch 2: 0.18790508806705475
Local loss @ local epoch 3: 0.4717181921005249
Local loss @ local epoch 4: 0.4935622215270996
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.33 seconds!
[tester] 
AGNewsMetric: acc=0.6839473684210526, hinge=2.6110846946113986, ce=13.800101278204666
Local test acc @ epoch 73: 0.6839
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0007552606402896345
Local loss @ local epoch 1: 0.003528905799612403
Local loss @ local epoch 2: 0.009655236266553402
Local loss @ local epoch 3: 0.004249271005392075
Local loss @ local epoch 4: 0.0031901744659990072
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.7 seconds!
[tester] 
AGNewsMetric: acc=0.8723684210526316, hinge=1.2490176981373837, ce=9.012854861209266
Local test acc @ epoch 73: 0.8724
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00137043627910316
Local loss @ local epoch 1: 0.015091431327164173
Local loss @ local epoch 2: 0.0012269590515643358
Local loss @ local epoch 3: 0.034065984189510345
Local loss @ local epoch 4: 0.005747425369918346
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.95 seconds!
[tester] 
AGNewsMetric: acc=0.8563157894736843, hinge=1.2558977029198095, ce=7.5267709410818
Local test acc @ epoch 73: 0.8563
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0004827922966796905
Local loss @ local epoch 1: 0.0021036190446466208
Local loss @ local epoch 2: 0.00827561691403389
Local loss @ local epoch 3: 0.03403651341795921
Local loss @ local epoch 4: 0.0034790702629834414
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 128.31 seconds!
[tester] 
AGNewsMetric: acc=0.8486842105263158, hinge=1.6059140413685848, ce=9.396621449119166
Local test acc @ epoch 73: 0.8487
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.007181570865213871
Local loss @ local epoch 1: 0.5066892504692078
Local loss @ local epoch 2: 0.012302848510444164
Local loss @ local epoch 3: 0.011063545010983944
Local loss @ local epoch 4: 0.08759006857872009
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 128.93 seconds!
[tester] 
AGNewsMetric: acc=0.8496052631578948, hinge=1.040302327306647, ce=6.2551921974985225
Local test acc @ epoch 73: 0.8496
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.01532745361328125
Local loss @ local epoch 1: 0.04522360488772392
Local loss @ local epoch 2: 0.2142755389213562
Local loss @ local epoch 3: 0.02970949560403824
Local loss @ local epoch 4: 0.01826152577996254
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.31 seconds!
[tester] 
AGNewsMetric: acc=0.8264473684210526, hinge=1.8397282653105886, ce=9.9262186331498
Local test acc @ epoch 73: 0.8264
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.040780387818813324
Local loss @ local epoch 1: 0.0727795884013176
Local loss @ local epoch 2: 0.006470930762588978
Local loss @ local epoch 3: 0.11911377310752869
Local loss @ local epoch 4: 0.05600618198513985
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 128.97 seconds!
[tester] 
AGNewsMetric: acc=0.7768421052631579, hinge=2.1377352438474957, ce=8.232477246334678
Local test acc @ epoch 73: 0.7768
Global evaluate on test data...
Evaluate data in 128.84 seconds!
[tester] 
AGNewsMetric: acc=0.8626315789473684, hinge=1.4018112554048237, ce=8.638514542830618
Global test acc @ epoch 73: 0.8626
Global epoch 74...
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.005465877708047628
Local loss @ local epoch 1: 0.0032228585332632065
Local loss @ local epoch 2: 0.0036695124581456184
Local loss @ local epoch 3: 0.11117694526910782
Local loss @ local epoch 4: 0.006427831947803497
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.33 seconds!
[tester] 
AGNewsMetric: acc=0.8682894736842105, hinge=1.1479771220056634, ce=7.509541025663677
Local test acc @ epoch 74: 0.8683
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0008832453167997301
Local loss @ local epoch 1: 0.021390652284026146
Local loss @ local epoch 2: 0.005089491605758667
Local loss @ local epoch 3: 0.0190905574709177
Local loss @ local epoch 4: 0.00827107299119234
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.57 seconds!
[tester] 
AGNewsMetric: acc=0.8593421052631579, hinge=1.4051059878499885, ce=10.493401607714201
Local test acc @ epoch 74: 0.8593
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.01358877494931221
Local loss @ local epoch 1: 0.14825354516506195
Local loss @ local epoch 2: 0.48687678575515747
Local loss @ local epoch 3: 0.08029785007238388
Local loss @ local epoch 4: 0.48898881673812866
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.33 seconds!
[tester] 
AGNewsMetric: acc=0.8497368421052631, hinge=1.3364171620419152, ce=6.93648980391653
Local test acc @ epoch 74: 0.8497
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.12699607014656067
Local loss @ local epoch 1: 0.031062109395861626
Local loss @ local epoch 2: 0.1527862697839737
Local loss @ local epoch 3: 0.12396573275327682
Local loss @ local epoch 4: 0.06560566276311874
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.09 seconds!
[tester] 
AGNewsMetric: acc=0.8181578947368421, hinge=1.1891464283591822, ce=7.384563015385678
Local test acc @ epoch 74: 0.8182
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.039929699152708054
Local loss @ local epoch 1: 0.018216362223029137
Local loss @ local epoch 2: 0.004538856912404299
Local loss @ local epoch 3: 0.11143080145120621
Local loss @ local epoch 4: 0.2245682179927826
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.62 seconds!
[tester] 
AGNewsMetric: acc=0.8257894736842105, hinge=1.3660126023543508, ce=7.736038790251079
Local test acc @ epoch 74: 0.8258
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.002957011805847287
Local loss @ local epoch 1: 0.19322651624679565
Local loss @ local epoch 2: 0.02211867645382881
Local loss @ local epoch 3: 0.004533631261438131
Local loss @ local epoch 4: 0.010702723637223244
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.17 seconds!
[tester] 
AGNewsMetric: acc=0.8509210526315789, hinge=1.2713128396084434, ce=9.202503368980006
Local test acc @ epoch 74: 0.8509
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0525919534265995
Local loss @ local epoch 1: 1.2889386415481567
Local loss @ local epoch 2: 0.02416609786450863
Local loss @ local epoch 3: 0.11699528992176056
Local loss @ local epoch 4: 0.05238718539476395
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.5 seconds!
[tester] 
AGNewsMetric: acc=0.8136842105263158, hinge=1.772827182067068, ce=10.203133830020302
Local test acc @ epoch 74: 0.8137
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.006880121771246195
Local loss @ local epoch 1: 0.028019988909363747
Local loss @ local epoch 2: 0.03433091193437576
Local loss @ local epoch 3: 0.07923455536365509
Local loss @ local epoch 4: 0.04682772606611252
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.43 seconds!
[tester] 
AGNewsMetric: acc=0.8521052631578947, hinge=1.383494654956617, ce=9.060885630155864
Local test acc @ epoch 74: 0.8521
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0018288838909938931
Local loss @ local epoch 1: 0.05319041758775711
Local loss @ local epoch 2: 0.000440066447481513
Local loss @ local epoch 3: 0.0026528011076152325
Local loss @ local epoch 4: 0.0034188099671155214
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.87 seconds!
[tester] 
AGNewsMetric: acc=0.8546052631578948, hinge=1.5198167482175324, ce=6.765180842750951
Local test acc @ epoch 74: 0.8546
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0015684734098613262
Local loss @ local epoch 1: 0.0014414617326110601
Local loss @ local epoch 2: 0.0009440099820494652
Local loss @ local epoch 3: 0.003611993743106723
Local loss @ local epoch 4: 0.0015578385209664702
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.02 seconds!
[tester] 
AGNewsMetric: acc=0.8730263157894737, hinge=1.215902768938165, ce=9.858443310386257
Local test acc @ epoch 74: 0.873
Global evaluate on test data...
Evaluate data in 129.58 seconds!
[tester] 
AGNewsMetric: acc=0.8709210526315789, hinge=1.2694527289741917, ce=8.242357649552195
Global test acc @ epoch 74: 0.8709
Global epoch 75...
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.002489154925569892
Local loss @ local epoch 1: 0.009380572475492954
Local loss @ local epoch 2: 0.0057374052703380585
Local loss @ local epoch 3: 0.012129063718020916
Local loss @ local epoch 4: 0.007007054518908262
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.04 seconds!
[tester] 
AGNewsMetric: acc=0.8419736842105263, hinge=1.6324269209410014, ce=10.063450614527651
Local test acc @ epoch 75: 0.842
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.003967432305216789
Local loss @ local epoch 1: 0.02293241024017334
Local loss @ local epoch 2: 0.00627081748098135
Local loss @ local epoch 3: 0.06547216325998306
Local loss @ local epoch 4: 0.005090027116239071
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.9 seconds!
[tester] 
AGNewsMetric: acc=0.7953947368421053, hinge=2.026808998208297, ce=10.69039107473273
Local test acc @ epoch 75: 0.7954
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.09358927607536316
Local loss @ local epoch 1: 0.15494738519191742
Local loss @ local epoch 2: 0.10927718132734299
Local loss @ local epoch 3: 0.34991392493247986
Local loss @ local epoch 4: 0.1352015882730484
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.59 seconds!
[tester] 
AGNewsMetric: acc=0.84, hinge=1.1081911292829012, ce=8.762582554064299
Local test acc @ epoch 75: 0.84
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.010410006158053875
Local loss @ local epoch 1: 0.007891529239714146
Local loss @ local epoch 2: 0.7320883870124817
Local loss @ local epoch 3: 0.034549910575151443
Local loss @ local epoch 4: 0.06420570611953735
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.9 seconds!
[tester] 
AGNewsMetric: acc=0.8477631578947369, hinge=1.2034346206564652, ce=7.217309071390252
Local test acc @ epoch 75: 0.8478
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.06486130505800247
Local loss @ local epoch 1: 0.03494824841618538
Local loss @ local epoch 2: 0.6033982038497925
Local loss @ local epoch 3: 0.15550287067890167
Local loss @ local epoch 4: 0.13552728295326233
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.0 seconds!
[tester] 
AGNewsMetric: acc=0.7996052631578947, hinge=2.113056620547646, ce=7.5587556096127155
Local test acc @ epoch 75: 0.7996
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.06741847842931747
Local loss @ local epoch 1: 0.026450734585523605
Local loss @ local epoch 2: 0.6363314986228943
Local loss @ local epoch 3: 0.11745651811361313
Local loss @ local epoch 4: 0.01509473379701376
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.41 seconds!
[tester] 
AGNewsMetric: acc=0.8486842105263158, hinge=1.2895478226009167, ce=6.763513369309274
Local test acc @ epoch 75: 0.8487
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.16688062250614166
Local loss @ local epoch 1: 0.2150498330593109
Local loss @ local epoch 2: 0.0019410384120419621
Local loss @ local epoch 3: 0.20778484642505646
Local loss @ local epoch 4: 0.11075963079929352
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.98 seconds!
[tester] 
AGNewsMetric: acc=0.8144736842105263, hinge=1.603319401741028, ce=7.718845553147165
Local test acc @ epoch 75: 0.8145
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.011712078005075455
Local loss @ local epoch 1: 0.01690618507564068
Local loss @ local epoch 2: 0.0431194081902504
Local loss @ local epoch 3: 0.004655798431485891
Local loss @ local epoch 4: 0.49099671840667725
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.1 seconds!
[tester] 
AGNewsMetric: acc=0.8388157894736842, hinge=1.5872037551277562, ce=7.87919459794697
Local test acc @ epoch 75: 0.8388
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.11113926768302917
Local loss @ local epoch 1: 0.01657232642173767
Local loss @ local epoch 2: 0.2615407109260559
Local loss @ local epoch 3: 0.1337817907333374
Local loss @ local epoch 4: 0.02971641905605793
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.61 seconds!
[tester] 
AGNewsMetric: acc=0.8632894736842105, hinge=1.0623332502967433, ce=6.104273940638492
Local test acc @ epoch 75: 0.8633
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0010463588405400515
Local loss @ local epoch 1: 0.0017706055659800768
Local loss @ local epoch 2: 0.0027135300915688276
Local loss @ local epoch 3: 0.0006305003189481795
Local loss @ local epoch 4: 0.0007225007866509259
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.01 seconds!
[tester] 
AGNewsMetric: acc=0.8589473684210527, hinge=1.3322875462080304, ce=8.195276216205798
Local test acc @ epoch 75: 0.8589
Global evaluate on test data...
Evaluate data in 130.13 seconds!
[tester] 
AGNewsMetric: acc=0.8688157894736842, hinge=1.3180209385721307, ce=7.897685829965692
Global test acc @ epoch 75: 0.8688
Global epoch 76...
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.000955374154727906
Local loss @ local epoch 1: 0.002693123184144497
Local loss @ local epoch 2: 0.001579116564244032
Local loss @ local epoch 3: 0.09885866940021515
Local loss @ local epoch 4: 0.01321292296051979
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.78 seconds!
[tester] 
AGNewsMetric: acc=0.8452631578947368, hinge=1.421619946831151, ce=7.22177668420892
Local test acc @ epoch 76: 0.8453
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.01685781031847
Local loss @ local epoch 1: 0.015034934505820274
Local loss @ local epoch 2: 0.1993194818496704
Local loss @ local epoch 3: 0.18715283274650574
Local loss @ local epoch 4: 0.0053167096339166164
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.47 seconds!
[tester] 
AGNewsMetric: acc=0.8727631578947368, hinge=1.1293195885106138, ce=9.062730616519326
Local test acc @ epoch 76: 0.8728
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0005778678460046649
Local loss @ local epoch 1: 0.0007898122421465814
Local loss @ local epoch 2: 0.0021610851399600506
Local loss @ local epoch 3: 0.002769109094515443
Local loss @ local epoch 4: 0.01854795403778553
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.15 seconds!
[tester] 
AGNewsMetric: acc=0.8572368421052632, hinge=1.541664538383484, ce=8.909914837887413
Local test acc @ epoch 76: 0.8572
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0029121863190084696
Local loss @ local epoch 1: 0.0071929339319467545
Local loss @ local epoch 2: 0.002232511527836323
Local loss @ local epoch 3: 0.06520748883485794
Local loss @ local epoch 4: 0.0005938896210864186
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.57 seconds!
[tester] 
AGNewsMetric: acc=0.8576315789473684, hinge=1.335998857899716, ce=8.168327295403731
Local test acc @ epoch 76: 0.8576
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.013393213041126728
Local loss @ local epoch 1: 0.05567097291350365
Local loss @ local epoch 2: 0.004719819873571396
Local loss @ local epoch 3: 0.015222987160086632
Local loss @ local epoch 4: 0.03921150043606758
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.32 seconds!
[tester] 
AGNewsMetric: acc=0.8467105263157895, hinge=1.4930395984649658, ce=7.531177783765291
Local test acc @ epoch 76: 0.8467
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.026619138196110725
Local loss @ local epoch 1: 0.07395409792661667
Local loss @ local epoch 2: 0.011821619234979153
Local loss @ local epoch 3: 0.012379735708236694
Local loss @ local epoch 4: 0.003144721733406186
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.21 seconds!
[tester] 
AGNewsMetric: acc=0.8057894736842105, hinge=1.572588580533078, ce=6.974118347167969
Local test acc @ epoch 76: 0.8058
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.04598480835556984
Local loss @ local epoch 1: 0.14047890901565552
Local loss @ local epoch 2: 0.022127417847514153
Local loss @ local epoch 3: 0.1912524402141571
Local loss @ local epoch 4: 0.34471988677978516
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.02 seconds!
[tester] 
AGNewsMetric: acc=0.8414473684210526, hinge=1.2583140860105815, ce=7.263688284221448
Local test acc @ epoch 76: 0.8414
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.09750079363584518
Local loss @ local epoch 1: 0.01853262446820736
Local loss @ local epoch 2: 0.05782635882496834
Local loss @ local epoch 3: 0.0637115091085434
Local loss @ local epoch 4: 0.08257231116294861
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.69 seconds!
[tester] 
AGNewsMetric: acc=0.8467105263157895, hinge=1.4298371194538317, ce=9.654018797623484
Local test acc @ epoch 76: 0.8467
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.001351017621345818
Local loss @ local epoch 1: 0.014547670260071754
Local loss @ local epoch 2: 0.001359276589937508
Local loss @ local epoch 3: 0.045392949134111404
Local loss @ local epoch 4: 0.0037530476693063974
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.66 seconds!
[tester] 
AGNewsMetric: acc=0.8425, hinge=1.62068375863527, ce=7.226974655954462
Local test acc @ epoch 76: 0.8425
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0009103091433644295
Local loss @ local epoch 1: 0.009176721796393394
Local loss @ local epoch 2: 0.0013134701875969768
Local loss @ local epoch 3: 0.0094836987555027
Local loss @ local epoch 4: 0.0012419563718140125
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.22 seconds!
[tester] 
AGNewsMetric: acc=0.8621052631578947, hinge=1.2783469953035054, ce=7.781373680516293
Local test acc @ epoch 76: 0.8621
Global evaluate on test data...
Evaluate data in 130.45 seconds!
[tester] 
AGNewsMetric: acc=0.8648684210526316, hinge=1.4597968681235063, ce=8.108412987558465
Global test acc @ epoch 76: 0.8649
Global epoch 77...
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.005113391671329737
Local loss @ local epoch 1: 0.1255931556224823
Local loss @ local epoch 2: 0.0038637013640254736
Local loss @ local epoch 3: 0.014945887960493565
Local loss @ local epoch 4: 0.10549642145633698
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.27 seconds!
[tester] 
AGNewsMetric: acc=0.8553947368421052, hinge=1.493624754704927, ce=9.436984710693359
Local test acc @ epoch 77: 0.8554
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.20955964922904968
Local loss @ local epoch 1: 0.07699483633041382
Local loss @ local epoch 2: 0.5635223388671875
Local loss @ local epoch 3: 0.4483979642391205
Local loss @ local epoch 4: 0.4079161286354065
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.02 seconds!
[tester] 
AGNewsMetric: acc=0.8506578947368421, hinge=1.1143258887843082, ce=9.36728784661544
Local test acc @ epoch 77: 0.8507
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00020471504831220955
Local loss @ local epoch 1: 0.001619746326468885
Local loss @ local epoch 2: 0.0007539326325058937
Local loss @ local epoch 3: 0.0480196438729763
Local loss @ local epoch 4: 0.011532445438206196
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.58 seconds!
[tester] 
AGNewsMetric: acc=0.8389473684210527, hinge=1.773520474182932, ce=9.211458704095138
Local test acc @ epoch 77: 0.8389
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0009174137958325446
Local loss @ local epoch 1: 0.0001456850441172719
Local loss @ local epoch 2: 0.0036199346650391817
Local loss @ local epoch 3: 0.0002869184536393732
Local loss @ local epoch 4: 0.0023765398655086756
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.59 seconds!
[tester] 
AGNewsMetric: acc=0.8475, hinge=1.7364486204950433, ce=8.953448721233167
Local test acc @ epoch 77: 0.8475
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.05290123447775841
Local loss @ local epoch 1: 0.019468897953629494
Local loss @ local epoch 2: 0.25371286273002625
Local loss @ local epoch 3: 0.03350459039211273
Local loss @ local epoch 4: 0.031521569937467575
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.26 seconds!
[tester] 
AGNewsMetric: acc=0.8171052631578948, hinge=1.5054318724180522, ce=7.336144887020714
Local test acc @ epoch 77: 0.8171
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.010231157764792442
Local loss @ local epoch 1: 0.0015566275687888265
Local loss @ local epoch 2: 0.009676928631961346
Local loss @ local epoch 3: 0.016639094799757004
Local loss @ local epoch 4: 0.026538662612438202
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.76 seconds!
[tester] 
AGNewsMetric: acc=0.8298684210526316, hinge=1.7382508963032772, ce=7.912274605600458
Local test acc @ epoch 77: 0.8299
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.07064267247915268
Local loss @ local epoch 1: 0.005036117509007454
Local loss @ local epoch 2: 0.1863747537136078
Local loss @ local epoch 3: 0.07906307280063629
Local loss @ local epoch 4: 0.557815670967102
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.45 seconds!
[tester] 
AGNewsMetric: acc=0.8360526315789474, hinge=1.671600217568247, ce=6.38882324620297
Local test acc @ epoch 77: 0.8361
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0015488045755773783
Local loss @ local epoch 1: 0.24720856547355652
Local loss @ local epoch 2: 0.0009104441851377487
Local loss @ local epoch 3: 0.01925574615597725
Local loss @ local epoch 4: 0.1289369910955429
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.63 seconds!
[tester] 
AGNewsMetric: acc=0.8488157894736842, hinge=1.308676531942267, ce=7.117931044729132
Local test acc @ epoch 77: 0.8488
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0016688029281795025
Local loss @ local epoch 1: 0.0022127963602542877
Local loss @ local epoch 2: 0.0031329900957643986
Local loss @ local epoch 3: 0.019217558205127716
Local loss @ local epoch 4: 0.004560978151857853
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.18 seconds!
[tester] 
AGNewsMetric: acc=0.8526315789473684, hinge=1.4746603747418052, ce=8.233330325076455
Local test acc @ epoch 77: 0.8526
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.04383575916290283
Local loss @ local epoch 1: 0.059405162930488586
Local loss @ local epoch 2: 0.05083843693137169
Local loss @ local epoch 3: 0.036943815648555756
Local loss @ local epoch 4: 0.0482584610581398
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.5 seconds!
[tester] 
AGNewsMetric: acc=0.8423684210526315, hinge=1.6825431906549555, ce=7.539431744625694
Local test acc @ epoch 77: 0.8424
Global evaluate on test data...
Evaluate data in 129.8 seconds!
[tester] 
AGNewsMetric: acc=0.8598684210526316, hinge=1.548673519586262, ce=8.010941786515085
Global test acc @ epoch 77: 0.8599
Global epoch 78...
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.019497785717248917
Local loss @ local epoch 1: 0.04803085699677467
Local loss @ local epoch 2: 0.01303758006542921
Local loss @ local epoch 3: 0.00978238694369793
Local loss @ local epoch 4: 0.007644086144864559
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.89 seconds!
[tester] 
AGNewsMetric: acc=0.8663157894736843, hinge=1.2375254176792345, ce=11.968902019701506
Local test acc @ epoch 78: 0.8663
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0012681928928941488
Local loss @ local epoch 1: 0.004494030959904194
Local loss @ local epoch 2: 0.0034295334480702877
Local loss @ local epoch 3: 0.01073079276829958
Local loss @ local epoch 4: 0.012126488611102104
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.86 seconds!
[tester] 
AGNewsMetric: acc=0.8610526315789474, hinge=1.316015957531176, ce=9.761996588456004
Local test acc @ epoch 78: 0.8611
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.23794890940189362
Local loss @ local epoch 1: 0.6989442110061646
Local loss @ local epoch 2: 0.13894258439540863
Local loss @ local epoch 3: 0.024349354207515717
Local loss @ local epoch 4: 0.2829338312149048
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.29 seconds!
[tester] 
AGNewsMetric: acc=0.8592105263157894, hinge=1.2194381894563373, ce=7.7274678902877
Local test acc @ epoch 78: 0.8592
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.004258646629750729
Local loss @ local epoch 1: 0.016830338165163994
Local loss @ local epoch 2: 0.0021369541063904762
Local loss @ local epoch 3: 0.05599689111113548
Local loss @ local epoch 4: 0.13039369881153107
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.39 seconds!
[tester] 
AGNewsMetric: acc=0.8422368421052632, hinge=1.7157952373906187, ce=8.703931045532226
Local test acc @ epoch 78: 0.8422
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.02058124542236328
Local loss @ local epoch 1: 0.42789289355278015
Local loss @ local epoch 2: 0.0008030497701838613
Local loss @ local epoch 3: 0.20681968331336975
Local loss @ local epoch 4: 0.23559671640396118
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.91 seconds!
[tester] 
AGNewsMetric: acc=0.8530263157894736, hinge=1.4373484910161871, ce=7.937696553280479
Local test acc @ epoch 78: 0.853
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.022582203149795532
Local loss @ local epoch 1: 0.004829129669815302
Local loss @ local epoch 2: 0.03366238623857498
Local loss @ local epoch 3: 0.004821077920496464
Local loss @ local epoch 4: 0.011488275602459908
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.39 seconds!
[tester] 
AGNewsMetric: acc=0.8386842105263158, hinge=1.5513870738681994, ce=11.055995814674779
Local test acc @ epoch 78: 0.8387
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.007089696824550629
Local loss @ local epoch 1: 0.0013915892923250794
Local loss @ local epoch 2: 0.0016454944852739573
Local loss @ local epoch 3: 0.005995552986860275
Local loss @ local epoch 4: 0.004815182648599148
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.46 seconds!
[tester] 
AGNewsMetric: acc=0.8275, hinge=1.7065484897713912, ce=9.092911736337761
Local test acc @ epoch 78: 0.8275
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.4278568923473358
Local loss @ local epoch 1: 0.007077475544065237
Local loss @ local epoch 2: 0.009342079982161522
Local loss @ local epoch 3: 0.4236357808113098
Local loss @ local epoch 4: 0.05517367273569107
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.25 seconds!
[tester] 
AGNewsMetric: acc=0.7936842105263158, hinge=1.5973264862361707, ce=5.931144453349867
Local test acc @ epoch 78: 0.7937
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.002282808069139719
Local loss @ local epoch 1: 0.005749473348259926
Local loss @ local epoch 2: 0.00339956721290946
Local loss @ local epoch 3: 0.013918116688728333
Local loss @ local epoch 4: 0.0394827164709568
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.48 seconds!
[tester] 
AGNewsMetric: acc=0.8011842105263158, hinge=2.069261935133683, ce=9.168180766858553
Local test acc @ epoch 78: 0.8012
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.009036505594849586
Local loss @ local epoch 1: 0.058030229061841965
Local loss @ local epoch 2: 0.008029363118112087
Local loss @ local epoch 3: 0.08031024038791656
Local loss @ local epoch 4: 0.002661265665665269
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.89 seconds!
[tester] 
AGNewsMetric: acc=0.8402631578947368, hinge=1.335555252025002, ce=6.503502766458611
Local test acc @ epoch 78: 0.8403
Global evaluate on test data...
Evaluate data in 129.36 seconds!
[tester] 
AGNewsMetric: acc=0.868421052631579, hinge=1.378681260410108, ce=8.468356799075478
Global test acc @ epoch 78: 0.8684
Global epoch 79...
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0008772846194915473
Local loss @ local epoch 1: 0.021464640274643898
Local loss @ local epoch 2: 0.0022864886559545994
Local loss @ local epoch 3: 0.0010073244338855147
Local loss @ local epoch 4: 0.03400564193725586
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.66 seconds!
[tester] 
AGNewsMetric: acc=0.8536842105263158, hinge=1.2875209552363345, ce=8.779191904569927
Local test acc @ epoch 79: 0.8537
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.33401405811309814
Local loss @ local epoch 1: 0.004332451615482569
Local loss @ local epoch 2: 0.051879044622182846
Local loss @ local epoch 3: 0.11531238257884979
Local loss @ local epoch 4: 0.038444507867097855
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.49 seconds!
[tester] 
AGNewsMetric: acc=0.8118421052631579, hinge=1.6481987915540997, ce=10.089036764847604
Local test acc @ epoch 79: 0.8118
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.4370492100715637
Local loss @ local epoch 1: 0.0690707191824913
Local loss @ local epoch 2: 0.32480302453041077
Local loss @ local epoch 3: 0.09749852865934372
Local loss @ local epoch 4: 0.05830933898687363
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.38 seconds!
[tester] 
AGNewsMetric: acc=0.8092105263157895, hinge=1.55302263234791, ce=10.97122586099725
Local test acc @ epoch 79: 0.8092
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.08522696048021317
Local loss @ local epoch 1: 0.0020465597044676542
Local loss @ local epoch 2: 0.8709757924079895
Local loss @ local epoch 3: 0.37924492359161377
Local loss @ local epoch 4: 0.21642224490642548
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.81 seconds!
[tester] 
AGNewsMetric: acc=0.7647368421052632, hinge=2.1513528936787654, ce=9.640198476690996
Local test acc @ epoch 79: 0.7647
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.006619905587285757
Local loss @ local epoch 1: 0.0030944233294576406
Local loss @ local epoch 2: 0.0028821236919611692
Local loss @ local epoch 3: 0.004247685894370079
Local loss @ local epoch 4: 0.010302617214620113
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.72 seconds!
[tester] 
AGNewsMetric: acc=0.7996052631578947, hinge=1.7973182873976858, ce=8.601650250083521
Local test acc @ epoch 79: 0.7996
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0007940998766571283
Local loss @ local epoch 1: 0.0006707016727887094
Local loss @ local epoch 2: 0.008101722225546837
Local loss @ local epoch 3: 0.0009946196805685759
Local loss @ local epoch 4: 0.014315173961222172
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.76 seconds!
[tester] 
AGNewsMetric: acc=0.8663157894736843, hinge=1.1730418247925607, ce=7.909181319788883
Local test acc @ epoch 79: 0.8663
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.05906163528561592
Local loss @ local epoch 1: 0.004237656947225332
Local loss @ local epoch 2: 0.01577048748731613
Local loss @ local epoch 3: 0.05235639587044716
Local loss @ local epoch 4: 0.1049245148897171
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.4 seconds!
[tester] 
AGNewsMetric: acc=0.7767105263157895, hinge=2.4160222043489155, ce=8.737532404849404
Local test acc @ epoch 79: 0.7767
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.014206807129085064
Local loss @ local epoch 1: 0.008398766629397869
Local loss @ local epoch 2: 0.1681278496980667
Local loss @ local epoch 3: 0.08927076309919357
Local loss @ local epoch 4: 0.27847787737846375
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.74 seconds!
[tester] 
AGNewsMetric: acc=0.7669736842105264, hinge=2.5350031466233105, ce=10.839752116956209
Local test acc @ epoch 79: 0.767
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0007501349318772554
Local loss @ local epoch 1: 0.0019003304187208414
Local loss @ local epoch 2: 0.0007626321166753769
Local loss @ local epoch 3: 0.008318985812366009
Local loss @ local epoch 4: 0.007960299029946327
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.9 seconds!
[tester] 
AGNewsMetric: acc=0.8278947368421052, hinge=2.2803082970569006, ce=9.567222677531996
Local test acc @ epoch 79: 0.8279
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.06335132569074631
Local loss @ local epoch 1: 0.008876834064722061
Local loss @ local epoch 2: 0.05004943907260895
Local loss @ local epoch 3: 0.03559675067663193
Local loss @ local epoch 4: 0.03441833704710007
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.93 seconds!
[tester] 
AGNewsMetric: acc=0.8477631578947369, hinge=1.3236964027505171, ce=8.521625257793225
Local test acc @ epoch 79: 0.8478
Global evaluate on test data...
Evaluate data in 130.13 seconds!
[tester] 
AGNewsMetric: acc=0.86, hinge=1.4480033247094406, ce=8.784210690950092
Global test acc @ epoch 79: 0.86
Global epoch 80...
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.013979587703943253
Local loss @ local epoch 1: 0.016227232292294502
Local loss @ local epoch 2: 0.18765489757061005
Local loss @ local epoch 3: 0.10176055133342743
Local loss @ local epoch 4: 0.21276286244392395
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.64 seconds!
[tester] 
AGNewsMetric: acc=0.7878947368421053, hinge=2.4236247336237056, ce=8.706944212662547
Local test acc @ epoch 80: 0.7879
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00047312842798419297
Local loss @ local epoch 1: 0.0005343211814761162
Local loss @ local epoch 2: 0.0011828503338620067
Local loss @ local epoch 3: 0.0031182272359728813
Local loss @ local epoch 4: 0.0007031424902379513
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.65 seconds!
[tester] 
AGNewsMetric: acc=0.8561842105263158, hinge=1.6581409424229672, ce=7.442055160120914
Local test acc @ epoch 80: 0.8562
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0022543217055499554
Local loss @ local epoch 1: 0.01655094511806965
Local loss @ local epoch 2: 0.0049533843994140625
Local loss @ local epoch 3: 0.058588117361068726
Local loss @ local epoch 4: 0.015672484412789345
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.96 seconds!
[tester] 
AGNewsMetric: acc=0.799078947368421, hinge=2.3588834054846513, ce=10.518500396326969
Local test acc @ epoch 80: 0.7991
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.16677889227867126
Local loss @ local epoch 1: 0.01631130464375019
Local loss @ local epoch 2: 0.016804752871394157
Local loss @ local epoch 3: 0.03240445256233215
Local loss @ local epoch 4: 0.12458775192499161
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.0 seconds!
[tester] 
AGNewsMetric: acc=0.7519736842105263, hinge=2.075835479686135, ce=6.598134157281173
Local test acc @ epoch 80: 0.752
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.058090634644031525
Local loss @ local epoch 1: 0.038052406162023544
Local loss @ local epoch 2: 0.10543780773878098
Local loss @ local epoch 3: 0.022334616631269455
Local loss @ local epoch 4: 0.698647677898407
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.94 seconds!
[tester] 
AGNewsMetric: acc=0.8477631578947369, hinge=1.5383095487795377, ce=10.216316949944748
Local test acc @ epoch 80: 0.8478
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.01051266212016344
Local loss @ local epoch 1: 0.003214194905012846
Local loss @ local epoch 2: 0.004525478463619947
Local loss @ local epoch 3: 0.13744674623012543
Local loss @ local epoch 4: 0.03259725123643875
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.88 seconds!
[tester] 
AGNewsMetric: acc=0.8451315789473685, hinge=1.5263829424506739, ce=7.161868757950632
Local test acc @ epoch 80: 0.8451
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0015962180914357305
Local loss @ local epoch 1: 0.007616589777171612
Local loss @ local epoch 2: 0.0013236956438049674
Local loss @ local epoch 3: 0.0014467894798144698
Local loss @ local epoch 4: 0.008272151462733746
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.69 seconds!
[tester] 
AGNewsMetric: acc=0.8185526315789474, hinge=1.8387371713236758, ce=10.361187573483116
Local test acc @ epoch 80: 0.8186
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.003317480441182852
Local loss @ local epoch 1: 0.0020842505618929863
Local loss @ local epoch 2: 0.0020824961829930544
Local loss @ local epoch 3: 0.02068537101149559
Local loss @ local epoch 4: 0.04889775812625885
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.84 seconds!
[tester] 
AGNewsMetric: acc=0.8432894736842105, hinge=1.5898106005317287, ce=8.23371567174008
Local test acc @ epoch 80: 0.8433
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00024072008091025054
Local loss @ local epoch 1: 0.008172676898539066
Local loss @ local epoch 2: 0.0007481097709387541
Local loss @ local epoch 3: 0.009755875915288925
Local loss @ local epoch 4: 0.18578945100307465
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.29 seconds!
[tester] 
AGNewsMetric: acc=0.866578947368421, hinge=1.3280863131974874, ce=9.292780245730752
Local test acc @ epoch 80: 0.8666
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.01974361203610897
Local loss @ local epoch 1: 0.001676305546425283
Local loss @ local epoch 2: 0.21607191860675812
Local loss @ local epoch 3: 0.03534064069390297
Local loss @ local epoch 4: 0.21570883691310883
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.57 seconds!
[tester] 
AGNewsMetric: acc=0.8730263157894737, hinge=1.1732371661537573, ce=6.216215408726742
Local test acc @ epoch 80: 0.873
Global evaluate on test data...
Evaluate data in 130.37 seconds!
[tester] 
AGNewsMetric: acc=0.8603947368421052, hinge=1.5427923556378014, ce=8.092182163439299
Global test acc @ epoch 80: 0.8604
Global epoch 81...
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.035838719457387924
Local loss @ local epoch 1: 0.015228236094117165
Local loss @ local epoch 2: 1.0870105028152466
Local loss @ local epoch 3: 0.03678756207227707
Local loss @ local epoch 4: 0.1834242194890976
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.43 seconds!
[tester] 
AGNewsMetric: acc=0.8268421052631579, hinge=1.4741555535165887, ce=7.242918211284437
Local test acc @ epoch 81: 0.8268
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.000778535904828459
Local loss @ local epoch 1: 0.0005711420672014356
Local loss @ local epoch 2: 0.004560054279863834
Local loss @ local epoch 3: 0.0005590642686001956
Local loss @ local epoch 4: 0.007004554383456707
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.42 seconds!
[tester] 
AGNewsMetric: acc=0.8389473684210527, hinge=1.6617112887533088, ce=8.93204353131746
Local test acc @ epoch 81: 0.8389
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.012475782074034214
Local loss @ local epoch 1: 0.017015818506479263
Local loss @ local epoch 2: 0.14818936586380005
Local loss @ local epoch 3: 0.009016887284815311
Local loss @ local epoch 4: 0.1417422592639923
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 128.95 seconds!
[tester] 
AGNewsMetric: acc=0.8580263157894736, hinge=1.2985559822383679, ce=8.413475337781405
Local test acc @ epoch 81: 0.858
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.01763742044568062
Local loss @ local epoch 1: 0.009820116683840752
Local loss @ local epoch 2: 0.0607503242790699
Local loss @ local epoch 3: 0.05261971801519394
Local loss @ local epoch 4: 0.015374474227428436
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.28 seconds!
[tester] 
AGNewsMetric: acc=0.8659210526315789, hinge=1.1550679784072073, ce=9.202000672189813
Local test acc @ epoch 81: 0.8659
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.021769829094409943
Local loss @ local epoch 1: 0.9819695353507996
Local loss @ local epoch 2: 0.40006497502326965
Local loss @ local epoch 3: 0.3498731255531311
Local loss @ local epoch 4: 0.2950577139854431
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.2 seconds!
[tester] 
AGNewsMetric: acc=0.8113157894736842, hinge=1.7201547991602044, ce=7.912400875091553
Local test acc @ epoch 81: 0.8113
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00021962019673082978
Local loss @ local epoch 1: 0.00019624430569820106
Local loss @ local epoch 2: 0.008554231375455856
Local loss @ local epoch 3: 0.0006286116549745202
Local loss @ local epoch 4: 0.002073409967124462
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.54 seconds!
[tester] 
AGNewsMetric: acc=0.8348684210526316, hinge=1.7585600087517186, ce=7.659827698155453
Local test acc @ epoch 81: 0.8349
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0005044619902037084
Local loss @ local epoch 1: 0.003333368571475148
Local loss @ local epoch 2: 0.0004506348632276058
Local loss @ local epoch 3: 0.0011812576558440924
Local loss @ local epoch 4: 0.003444111905992031
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.53 seconds!
[tester] 
AGNewsMetric: acc=0.8407894736842105, hinge=1.5928610410188373, ce=8.980833334671823
Local test acc @ epoch 81: 0.8408
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.004015095066279173
Local loss @ local epoch 1: 0.007011156063526869
Local loss @ local epoch 2: 0.00257587106898427
Local loss @ local epoch 3: 0.0011280179023742676
Local loss @ local epoch 4: 0.026858709752559662
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.91 seconds!
[tester] 
AGNewsMetric: acc=0.8561842105263158, hinge=1.398729405905071, ce=8.050189670763517
Local test acc @ epoch 81: 0.8562
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.03824052959680557
Local loss @ local epoch 1: 0.038049228489398956
Local loss @ local epoch 2: 0.03081679902970791
Local loss @ local epoch 3: 0.09635347872972488
Local loss @ local epoch 4: 0.052399687469005585
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.1 seconds!
[tester] 
AGNewsMetric: acc=0.7303947368421052, hinge=2.523478508999473, ce=8.269811174493087
Local test acc @ epoch 81: 0.7304
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.23546622693538666
Local loss @ local epoch 1: 0.0008537272806279361
Local loss @ local epoch 2: 0.0513940304517746
Local loss @ local epoch 3: 0.01268863957375288
Local loss @ local epoch 4: 0.011087081395089626
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.45 seconds!
[tester] 
AGNewsMetric: acc=0.77, hinge=2.8604282873555236, ce=9.386860211021022
Local test acc @ epoch 81: 0.77
Global evaluate on test data...
Evaluate data in 130.2 seconds!
[tester] 
AGNewsMetric: acc=0.8636842105263158, hinge=1.4677733491596423, ce=8.803519104405453
Global test acc @ epoch 81: 0.8637
Global epoch 82...
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0047011966817080975
Local loss @ local epoch 1: 0.0011264828499406576
Local loss @ local epoch 2: 0.004075746517628431
Local loss @ local epoch 3: 0.00989670678973198
Local loss @ local epoch 4: 0.011322895996272564
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.5 seconds!
[tester] 
AGNewsMetric: acc=0.8117105263157894, hinge=2.1090630666833174, ce=9.555736047845137
Local test acc @ epoch 82: 0.8117
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.055292703211307526
Local loss @ local epoch 1: 0.04155220836400986
Local loss @ local epoch 2: 0.010937893763184547
Local loss @ local epoch 3: 0.03602893278002739
Local loss @ local epoch 4: 0.1399105042219162
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.12 seconds!
[tester] 
AGNewsMetric: acc=0.7798684210526315, hinge=1.8211741397255345, ce=8.292959572641474
Local test acc @ epoch 82: 0.7799
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0029920043889433146
Local loss @ local epoch 1: 0.007743312045931816
Local loss @ local epoch 2: 0.0022360750008374453
Local loss @ local epoch 3: 0.01349270436912775
Local loss @ local epoch 4: 0.001334587810561061
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.78 seconds!
[tester] 
AGNewsMetric: acc=0.8515789473684211, hinge=1.3862876849425467, ce=9.27226221385755
Local test acc @ epoch 82: 0.8516
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.14567677676677704
Local loss @ local epoch 1: 0.02224656380712986
Local loss @ local epoch 2: 0.2164030820131302
Local loss @ local epoch 3: 0.05516820773482323
Local loss @ local epoch 4: 0.04713335260748863
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.9 seconds!
[tester] 
AGNewsMetric: acc=0.7825, hinge=1.9149945156197798, ce=8.383080733449836
Local test acc @ epoch 82: 0.7825
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.010678648017346859
Local loss @ local epoch 1: 0.05349164456129074
Local loss @ local epoch 2: 0.014475532807409763
Local loss @ local epoch 3: 0.005699207074940205
Local loss @ local epoch 4: 0.3359423279762268
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.11 seconds!
[tester] 
AGNewsMetric: acc=0.8582894736842105, hinge=1.302629946156552, ce=9.72953526346307
Local test acc @ epoch 82: 0.8583
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.05750799551606178
Local loss @ local epoch 1: 0.14940793812274933
Local loss @ local epoch 2: 0.10060352087020874
Local loss @ local epoch 3: 0.030056610703468323
Local loss @ local epoch 4: 0.1119428426027298
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.75 seconds!
[tester] 
AGNewsMetric: acc=0.7871052631578948, hinge=1.8904840805656031, ce=8.057503533614309
Local test acc @ epoch 82: 0.7871
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0004628809401765466
Local loss @ local epoch 1: 0.0014335286105051637
Local loss @ local epoch 2: 0.019106479361653328
Local loss @ local epoch 3: 0.0012732881586998701
Local loss @ local epoch 4: 0.001351541723124683
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.78 seconds!
[tester] 
AGNewsMetric: acc=0.8292105263157895, hinge=1.9105131209524053, ce=9.722624822917737
Local test acc @ epoch 82: 0.8292
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.04150809720158577
Local loss @ local epoch 1: 0.0075446139089763165
Local loss @ local epoch 2: 0.1279381811618805
Local loss @ local epoch 3: 0.1237831637263298
Local loss @ local epoch 4: 0.017095040529966354
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.77 seconds!
[tester] 
AGNewsMetric: acc=0.8326315789473684, hinge=1.5713606312400417, ce=9.909934953388415
Local test acc @ epoch 82: 0.8326
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.001167474896647036
Local loss @ local epoch 1: 0.04104853421449661
Local loss @ local epoch 2: 0.000724318262655288
Local loss @ local epoch 3: 0.04321744665503502
Local loss @ local epoch 4: 0.002738849027082324
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.7 seconds!
[tester] 
AGNewsMetric: acc=0.829078947368421, hinge=1.6522391259042841, ce=8.44655928561562
Local test acc @ epoch 82: 0.8291
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0025217952206730843
Local loss @ local epoch 1: 0.3823982775211334
Local loss @ local epoch 2: 0.005921740084886551
Local loss @ local epoch 3: 0.08972573280334473
Local loss @ local epoch 4: 0.32046064734458923
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.28 seconds!
[tester] 
AGNewsMetric: acc=0.8173684210526316, hinge=1.774647422338787, ce=8.738312289589329
Local test acc @ epoch 82: 0.8174
Global evaluate on test data...
Evaluate data in 129.86 seconds!
[tester] 
AGNewsMetric: acc=0.8601315789473685, hinge=1.4070931856255782, ce=8.327319851925498
Global test acc @ epoch 82: 0.8601
Global epoch 83...
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.2159615159034729
Local loss @ local epoch 1: 0.1262385994195938
Local loss @ local epoch 2: 0.020377695560455322
Local loss @ local epoch 3: 0.11468356847763062
Local loss @ local epoch 4: 0.03409668058156967
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.32 seconds!
[tester] 
AGNewsMetric: acc=0.8036842105263158, hinge=1.8189846934770284, ce=7.958007756283409
Local test acc @ epoch 83: 0.8037
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.018674790859222412
Local loss @ local epoch 1: 0.014017246663570404
Local loss @ local epoch 2: 0.248058021068573
Local loss @ local epoch 3: 0.007919729687273502
Local loss @ local epoch 4: 0.018161041662096977
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.37 seconds!
[tester] 
AGNewsMetric: acc=0.838421052631579, hinge=1.4371203558068526, ce=11.350619364286723
Local test acc @ epoch 83: 0.8384
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.10928232222795486
Local loss @ local epoch 1: 0.003039624309167266
Local loss @ local epoch 2: 0.12779369950294495
Local loss @ local epoch 3: 0.03864549472928047
Local loss @ local epoch 4: 0.010508201085031033
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.13 seconds!
[tester] 
AGNewsMetric: acc=0.8603947368421052, hinge=1.1332397842407227, ce=6.407830050619025
Local test acc @ epoch 83: 0.8604
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.003804377978667617
Local loss @ local epoch 1: 0.0025785702746361494
Local loss @ local epoch 2: 0.07348725944757462
Local loss @ local epoch 3: 0.002295251004397869
Local loss @ local epoch 4: 0.040259428322315216
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.55 seconds!
[tester] 
AGNewsMetric: acc=0.8651315789473685, hinge=1.4145487521824083, ce=7.764396211724533
Local test acc @ epoch 83: 0.8651
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00051185890333727
Local loss @ local epoch 1: 0.04533767327666283
Local loss @ local epoch 2: 0.0008330243290401995
Local loss @ local epoch 3: 0.00034030902315862477
Local loss @ local epoch 4: 0.0029503144323825836
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.35 seconds!
[tester] 
AGNewsMetric: acc=0.8213157894736842, hinge=1.7217231996435869, ce=8.789612958807695
Local test acc @ epoch 83: 0.8213
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0023169226478785276
Local loss @ local epoch 1: 0.0023864260874688625
Local loss @ local epoch 2: 0.01416602823883295
Local loss @ local epoch 3: 0.16355758905410767
Local loss @ local epoch 4: 0.1758434772491455
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.67 seconds!
[tester] 
AGNewsMetric: acc=0.841842105263158, hinge=1.3597051821256938, ce=6.842280140926963
Local test acc @ epoch 83: 0.8418
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.07936207205057144
Local loss @ local epoch 1: 0.11233410239219666
Local loss @ local epoch 2: 0.14161930978298187
Local loss @ local epoch 3: 0.12924139201641083
Local loss @ local epoch 4: 0.1553109884262085
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.69 seconds!
[tester] 
AGNewsMetric: acc=0.8376315789473684, hinge=1.4750934791564942, ce=10.214381633557771
Local test acc @ epoch 83: 0.8376
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00033345300471410155
Local loss @ local epoch 1: 0.0002443594275973737
Local loss @ local epoch 2: 0.0006170346168801188
Local loss @ local epoch 3: 0.0020564147271215916
Local loss @ local epoch 4: 0.0004515429027378559
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.93 seconds!
[tester] 
AGNewsMetric: acc=0.8577631578947369, hinge=1.4925938247379504, ce=8.25810319800126
Local test acc @ epoch 83: 0.8578
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0003069886297453195
Local loss @ local epoch 1: 0.0012891101650893688
Local loss @ local epoch 2: 0.000520097732078284
Local loss @ local epoch 3: 0.02238926850259304
Local loss @ local epoch 4: 0.0016734059900045395
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.36 seconds!
[tester] 
AGNewsMetric: acc=0.855, hinge=1.4778522054772627, ce=7.615513126975611
Local test acc @ epoch 83: 0.855
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.02146066166460514
Local loss @ local epoch 1: 0.15980470180511475
Local loss @ local epoch 2: 0.023418517783284187
Local loss @ local epoch 3: 0.005968005862087011
Local loss @ local epoch 4: 0.02029574289917946
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.0 seconds!
[tester] 
AGNewsMetric: acc=0.8117105263157894, hinge=1.697387248340406, ce=7.465540556656687
Local test acc @ epoch 83: 0.8117
Global evaluate on test data...
Evaluate data in 129.73 seconds!
[tester] 
AGNewsMetric: acc=0.8675, hinge=1.4255961666609112, ce=8.452019544902601
Global test acc @ epoch 83: 0.8675
Global epoch 84...
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.008109474554657936
Local loss @ local epoch 1: 0.0030747256241738796
Local loss @ local epoch 2: 0.005397414322942495
Local loss @ local epoch 3: 0.0687687024474144
Local loss @ local epoch 4: 0.27203673124313354
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.67 seconds!
[tester] 
AGNewsMetric: acc=0.8064473684210526, hinge=1.859185862039265, ce=10.64860540691175
Local test acc @ epoch 84: 0.8064
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0013585034757852554
Local loss @ local epoch 1: 0.001215251861140132
Local loss @ local epoch 2: 0.003800953971222043
Local loss @ local epoch 3: 0.0023927565198391676
Local loss @ local epoch 4: 0.0013718135887756944
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.05 seconds!
[tester] 
AGNewsMetric: acc=0.8126315789473684, hinge=2.1205427167290134, ce=10.651328592802349
Local test acc @ epoch 84: 0.8126
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0003654798783827573
Local loss @ local epoch 1: 0.0001469804410589859
Local loss @ local epoch 2: 0.0012566517107188702
Local loss @ local epoch 3: 0.0020175809040665627
Local loss @ local epoch 4: 0.0019751908257603645
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.96 seconds!
[tester] 
AGNewsMetric: acc=0.843421052631579, hinge=1.5217839810722753, ce=7.946598091125488
Local test acc @ epoch 84: 0.8434
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.030989868566393852
Local loss @ local epoch 1: 0.018745258450508118
Local loss @ local epoch 2: 0.02265484258532524
Local loss @ local epoch 3: 0.0503096804022789
Local loss @ local epoch 4: 0.056669432669878006
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.8 seconds!
[tester] 
AGNewsMetric: acc=0.7425, hinge=3.177929067862661, ce=7.99602441687333
Local test acc @ epoch 84: 0.7425
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00932639092206955
Local loss @ local epoch 1: 0.10371138155460358
Local loss @ local epoch 2: 0.010961859486997128
Local loss @ local epoch 3: 0.005324050318449736
Local loss @ local epoch 4: 0.07696675509214401
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.21 seconds!
[tester] 
AGNewsMetric: acc=0.87, hinge=1.1631316699479755, ce=10.112287135877107
Local test acc @ epoch 84: 0.87
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.21148069202899933
Local loss @ local epoch 1: 0.12300125509500504
Local loss @ local epoch 2: 0.2298285812139511
Local loss @ local epoch 3: 0.046980272978544235
Local loss @ local epoch 4: 0.6422320008277893
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.37 seconds!
[tester] 
AGNewsMetric: acc=0.7746052631578947, hinge=1.9380642767956382, ce=9.823684563887747
Local test acc @ epoch 84: 0.7746
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00020625571778509766
Local loss @ local epoch 1: 0.0003523381019476801
Local loss @ local epoch 2: 0.0014502168633043766
Local loss @ local epoch 3: 0.0027331337332725525
Local loss @ local epoch 4: 0.0005411661113612354
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.36 seconds!
[tester] 
AGNewsMetric: acc=0.8184210526315789, hinge=1.8828324721988878, ce=9.501979743555973
Local test acc @ epoch 84: 0.8184
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.034420743584632874
Local loss @ local epoch 1: 0.009898057207465172
Local loss @ local epoch 2: 0.018718715757131577
Local loss @ local epoch 3: 0.03105262666940689
Local loss @ local epoch 4: 0.04425647109746933
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.03 seconds!
[tester] 
AGNewsMetric: acc=0.8467105263157895, hinge=1.5307864701120477, ce=6.549697697288112
Local test acc @ epoch 84: 0.8467
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.03366966173052788
Local loss @ local epoch 1: 0.06501448154449463
Local loss @ local epoch 2: 0.032461777329444885
Local loss @ local epoch 3: 0.4698059856891632
Local loss @ local epoch 4: 0.04492419958114624
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.61 seconds!
[tester] 
AGNewsMetric: acc=0.7669736842105264, hinge=2.464244704748455, ce=9.334525086252313
Local test acc @ epoch 84: 0.767
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0015785659197717905
Local loss @ local epoch 1: 0.004469586536288261
Local loss @ local epoch 2: 0.03995886817574501
Local loss @ local epoch 3: 0.001605577184818685
Local loss @ local epoch 4: 0.07143097370862961
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.73 seconds!
[tester] 
AGNewsMetric: acc=0.8175, hinge=1.7607939122852527, ce=10.482387749521356
Local test acc @ epoch 84: 0.8175
Global evaluate on test data...
Evaluate data in 131.11 seconds!
[tester] 
AGNewsMetric: acc=0.8625, hinge=1.532699781217073, ce=8.771583934583163
Global test acc @ epoch 84: 0.8625
Global epoch 85...
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.24988143146038055
Local loss @ local epoch 1: 0.009077495895326138
Local loss @ local epoch 2: 0.050433266907930374
Local loss @ local epoch 3: 0.02032710611820221
Local loss @ local epoch 4: 0.004341806285083294
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.99 seconds!
[tester] 
AGNewsMetric: acc=0.8025, hinge=1.794526835240816, ce=7.328449428959897
Local test acc @ epoch 85: 0.8025
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00029494913178496063
Local loss @ local epoch 1: 0.0014396053738892078
Local loss @ local epoch 2: 0.0023910319432616234
Local loss @ local epoch 3: 0.002628057263791561
Local loss @ local epoch 4: 0.03159421682357788
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.48 seconds!
[tester] 
AGNewsMetric: acc=0.8585526315789473, hinge=1.5566715900521528, ce=8.750803925363641
Local test acc @ epoch 85: 0.8586
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.001050483202561736
Local loss @ local epoch 1: 0.0004347807262092829
Local loss @ local epoch 2: 0.013474109582602978
Local loss @ local epoch 3: 0.0007694127853028476
Local loss @ local epoch 4: 0.018353451043367386
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.67 seconds!
[tester] 
AGNewsMetric: acc=0.82, hinge=1.8510599377280788, ce=11.003575776752673
Local test acc @ epoch 85: 0.82
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.254658043384552
Local loss @ local epoch 1: 0.030036626383662224
Local loss @ local epoch 2: 0.25656265020370483
Local loss @ local epoch 3: 0.12246992439031601
Local loss @ local epoch 4: 0.09807753562927246
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.63 seconds!
[tester] 
AGNewsMetric: acc=0.8506578947368421, hinge=1.3094079745443243, ce=7.0233667303386484
Local test acc @ epoch 85: 0.8507
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0009345156722702086
Local loss @ local epoch 1: 0.001173187862150371
Local loss @ local epoch 2: 0.006872888188809156
Local loss @ local epoch 3: 0.0013762753224000335
Local loss @ local epoch 4: 0.005860988982021809
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.93 seconds!
[tester] 
AGNewsMetric: acc=0.8740789473684211, hinge=1.148146828099301, ce=7.298120235643888
Local test acc @ epoch 85: 0.8741
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.002664670580998063
Local loss @ local epoch 1: 0.0012640065979212523
Local loss @ local epoch 2: 0.07793480902910233
Local loss @ local epoch 3: 0.003230434376746416
Local loss @ local epoch 4: 0.003598882583901286
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.43 seconds!
[tester] 
AGNewsMetric: acc=0.7876315789473685, hinge=2.844563138610438, ce=8.112152503164191
Local test acc @ epoch 85: 0.7876
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.017053702846169472
Local loss @ local epoch 1: 0.02363637275993824
Local loss @ local epoch 2: 0.0807575210928917
Local loss @ local epoch 3: 0.00626783724874258
Local loss @ local epoch 4: 0.012012124992907047
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.06 seconds!
[tester] 
AGNewsMetric: acc=0.828421052631579, hinge=1.8426928781208238, ce=7.19041339271947
Local test acc @ epoch 85: 0.8284
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0031204945407807827
Local loss @ local epoch 1: 0.0008486728183925152
Local loss @ local epoch 2: 0.0021626281086355448
Local loss @ local epoch 3: 0.0011146541219204664
Local loss @ local epoch 4: 0.004454051610082388
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.13 seconds!
[tester] 
AGNewsMetric: acc=0.8625, hinge=1.3850821781158447, ce=7.74804430710642
Local test acc @ epoch 85: 0.8625
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.005641131196171045
Local loss @ local epoch 1: 0.07086056470870972
Local loss @ local epoch 2: 0.04173593968153
Local loss @ local epoch 3: 0.03605073690414429
Local loss @ local epoch 4: 0.03066730499267578
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.03 seconds!
[tester] 
AGNewsMetric: acc=0.8473684210526315, hinge=1.4010053300857543, ce=8.440306936565198
Local test acc @ epoch 85: 0.8474
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.010756159201264381
Local loss @ local epoch 1: 0.01169327087700367
Local loss @ local epoch 2: 0.0026031469460576773
Local loss @ local epoch 3: 0.0510035902261734
Local loss @ local epoch 4: 0.008948341943323612
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.36 seconds!
[tester] 
AGNewsMetric: acc=0.8053947368421053, hinge=2.2033769346538343, ce=9.991014699433979
Local test acc @ epoch 85: 0.8054
Global evaluate on test data...
Evaluate data in 130.46 seconds!
[tester] 
AGNewsMetric: acc=0.8663157894736843, hinge=1.5059713323492754, ce=7.682387884039628
Global test acc @ epoch 85: 0.8663
Global epoch 86...
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.012390898540616035
Local loss @ local epoch 1: 0.1429920792579651
Local loss @ local epoch 2: 0.0026234304532408714
Local loss @ local epoch 3: 0.03896229341626167
Local loss @ local epoch 4: 0.0336785726249218
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.82 seconds!
[tester] 
AGNewsMetric: acc=0.7977631578947368, hinge=2.340435667037964, ce=8.642424292313425
Local test acc @ epoch 86: 0.7978
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0006365448352880776
Local loss @ local epoch 1: 0.005499396938830614
Local loss @ local epoch 2: 0.0013915573945268989
Local loss @ local epoch 3: 0.0036682207137346268
Local loss @ local epoch 4: 0.0064679961651563644
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.3 seconds!
[tester] 
AGNewsMetric: acc=0.8631578947368421, hinge=1.453613489552548, ce=9.053951002422131
Local test acc @ epoch 86: 0.8632
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00217735068872571
Local loss @ local epoch 1: 0.020160382613539696
Local loss @ local epoch 2: 0.00045981083530932665
Local loss @ local epoch 3: 0.008136635646224022
Local loss @ local epoch 4: 0.006982448976486921
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.2 seconds!
[tester] 
AGNewsMetric: acc=0.8092105263157895, hinge=2.2465919364126106, ce=8.771767893339458
Local test acc @ epoch 86: 0.8092
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0013337575364857912
Local loss @ local epoch 1: 0.0008249655365943909
Local loss @ local epoch 2: 0.011157568544149399
Local loss @ local epoch 3: 0.0029989464674144983
Local loss @ local epoch 4: 0.002157557290047407
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.47 seconds!
[tester] 
AGNewsMetric: acc=0.8648684210526316, hinge=1.2395043029283221, ce=7.586533773321855
Local test acc @ epoch 86: 0.8649
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0005550960777327418
Local loss @ local epoch 1: 0.012352414429187775
Local loss @ local epoch 2: 0.0004914259188808501
Local loss @ local epoch 3: 0.0009316639043390751
Local loss @ local epoch 4: 0.18813829123973846
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.34 seconds!
[tester] 
AGNewsMetric: acc=0.8452631578947368, hinge=1.6211525006043284, ce=8.289265126680073
Local test acc @ epoch 86: 0.8453
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.11609859019517899
Local loss @ local epoch 1: 0.5351547002792358
Local loss @ local epoch 2: 0.14719125628471375
Local loss @ local epoch 3: 0.014635601080954075
Local loss @ local epoch 4: 0.08625347912311554
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.09 seconds!
[tester] 
AGNewsMetric: acc=0.8605263157894737, hinge=1.2988320440995065, ce=9.550074229993319
Local test acc @ epoch 86: 0.8605
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.1507411152124405
Local loss @ local epoch 1: 0.0252078864723444
Local loss @ local epoch 2: 0.18049432337284088
Local loss @ local epoch 3: 0.02884124591946602
Local loss @ local epoch 4: 0.07234878093004227
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.76 seconds!
[tester] 
AGNewsMetric: acc=0.8313157894736842, hinge=1.5238182509572882, ce=7.294416493867573
Local test acc @ epoch 86: 0.8313
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0008045548456721008
Local loss @ local epoch 1: 0.008852715604007244
Local loss @ local epoch 2: 0.0040931738913059235
Local loss @ local epoch 3: 0.09131676703691483
Local loss @ local epoch 4: 0.004969402216374874
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.27 seconds!
[tester] 
AGNewsMetric: acc=0.8189473684210526, hinge=1.5901515865325928, ce=10.880803136323628
Local test acc @ epoch 86: 0.8189
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0029164585284888744
Local loss @ local epoch 1: 0.0049332501366734505
Local loss @ local epoch 2: 0.1454908847808838
Local loss @ local epoch 3: 0.009329674765467644
Local loss @ local epoch 4: 0.0270383358001709
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.98 seconds!
[tester] 
AGNewsMetric: acc=0.8193421052631579, hinge=1.7186067907433762, ce=9.136200738204153
Local test acc @ epoch 86: 0.8193
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0006346909794956446
Local loss @ local epoch 1: 0.002112088492140174
Local loss @ local epoch 2: 0.0018969787051901221
Local loss @ local epoch 3: 0.3402114808559418
Local loss @ local epoch 4: 0.2109944373369217
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.82 seconds!
[tester] 
AGNewsMetric: acc=0.8278947368421052, hinge=1.1801970496930574, ce=7.037956007907265
Local test acc @ epoch 86: 0.8279
Global evaluate on test data...
Evaluate data in 129.86 seconds!
[tester] 
AGNewsMetric: acc=0.8678947368421053, hinge=1.4503969734593443, ce=8.263489614787854
Global test acc @ epoch 86: 0.8679
Global epoch 87...
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0012621970381587744
Local loss @ local epoch 1: 0.0027283192612230778
Local loss @ local epoch 2: 0.003543452126905322
Local loss @ local epoch 3: 0.02804839052259922
Local loss @ local epoch 4: 0.006173570640385151
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.3 seconds!
[tester] 
AGNewsMetric: acc=0.8568421052631578, hinge=1.3490298883538496, ce=7.067399122338546
Local test acc @ epoch 87: 0.8568
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.17091555893421173
Local loss @ local epoch 1: 0.013912505470216274
Local loss @ local epoch 2: 0.05061693862080574
Local loss @ local epoch 3: 0.012909414246678352
Local loss @ local epoch 4: 0.017391487956047058
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.78 seconds!
[tester] 
AGNewsMetric: acc=0.795921052631579, hinge=1.6072141060076262, ce=6.233616948378714
Local test acc @ epoch 87: 0.7959
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.029892683029174805
Local loss @ local epoch 1: 0.14460137486457825
Local loss @ local epoch 2: 0.07534727454185486
Local loss @ local epoch 3: 0.05562383309006691
Local loss @ local epoch 4: 0.04315880313515663
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.45 seconds!
[tester] 
AGNewsMetric: acc=0.8571052631578947, hinge=1.2116820378052562, ce=8.016091447127494
Local test acc @ epoch 87: 0.8571
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0012132776901125908
Local loss @ local epoch 1: 0.0035754467826336622
Local loss @ local epoch 2: 0.006492724176496267
Local loss @ local epoch 3: 0.05002012103796005
Local loss @ local epoch 4: 0.00041562950355000794
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.31 seconds!
[tester] 
AGNewsMetric: acc=0.8309210526315789, hinge=1.8544750652815167, ce=8.294752480356317
Local test acc @ epoch 87: 0.8309
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0019160484662279487
Local loss @ local epoch 1: 0.04252892732620239
Local loss @ local epoch 2: 0.001295451307669282
Local loss @ local epoch 3: 0.018435945734381676
Local loss @ local epoch 4: 0.128020778298378
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.95 seconds!
[tester] 
AGNewsMetric: acc=0.7905263157894736, hinge=1.999711015851874, ce=6.829923880727668
Local test acc @ epoch 87: 0.7905
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.017063898965716362
Local loss @ local epoch 1: 0.04712400212883949
Local loss @ local epoch 2: 0.009317790158092976
Local loss @ local epoch 3: 0.11826963722705841
Local loss @ local epoch 4: 0.0022629813756793737
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.44 seconds!
[tester] 
AGNewsMetric: acc=0.8609210526315789, hinge=1.2726701558263678, ce=8.412415468316329
Local test acc @ epoch 87: 0.8609
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.3492070734500885
Local loss @ local epoch 1: 0.02831445448100567
Local loss @ local epoch 2: 0.07306726276874542
Local loss @ local epoch 3: 0.35435009002685547
Local loss @ local epoch 4: 0.4331587851047516
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.08 seconds!
[tester] 
AGNewsMetric: acc=0.8576315789473684, hinge=1.1926919879411397, ce=8.3454632206967
Local test acc @ epoch 87: 0.8576
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0005877463263459504
Local loss @ local epoch 1: 0.04336410388350487
Local loss @ local epoch 2: 0.0001999284722842276
Local loss @ local epoch 3: 0.013239257037639618
Local loss @ local epoch 4: 0.056996263563632965
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.52 seconds!
[tester] 
AGNewsMetric: acc=0.7461842105263158, hinge=3.7384635644210014, ce=9.938982391357422
Local test acc @ epoch 87: 0.7462
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0015161905903369188
Local loss @ local epoch 1: 0.00018556888971943408
Local loss @ local epoch 2: 0.00040352248470298946
Local loss @ local epoch 3: 0.00048083116416819394
Local loss @ local epoch 4: 0.000273641460807994
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.44 seconds!
[tester] 
AGNewsMetric: acc=0.8422368421052632, hinge=1.676973803168849, ce=9.478939763119346
Local test acc @ epoch 87: 0.8422
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.004212514963001013
Local loss @ local epoch 1: 0.0008911771001294255
Local loss @ local epoch 2: 0.015447186306118965
Local loss @ local epoch 3: 0.011077769100666046
Local loss @ local epoch 4: 0.0016903001815080643
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.53 seconds!
[tester] 
AGNewsMetric: acc=0.8555263157894737, hinge=1.5245622943577013, ce=9.011663834421258
Local test acc @ epoch 87: 0.8555
Global evaluate on test data...
Evaluate data in 130.23 seconds!
[tester] 
AGNewsMetric: acc=0.861578947368421, hinge=1.494018006575735, ce=7.320653983668278
Global test acc @ epoch 87: 0.8616
Global epoch 88...
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.007350381929427385
Local loss @ local epoch 1: 0.0006194557063281536
Local loss @ local epoch 2: 0.033233642578125
Local loss @ local epoch 3: 0.17232359945774078
Local loss @ local epoch 4: 0.002177685732021928
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.33 seconds!
[tester] 
AGNewsMetric: acc=0.7394736842105263, hinge=3.419112564388074, ce=10.68882689827367
Local test acc @ epoch 88: 0.7395
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0010184700367972255
Local loss @ local epoch 1: 0.001750253839418292
Local loss @ local epoch 2: 0.000840546446852386
Local loss @ local epoch 3: 0.001222345745190978
Local loss @ local epoch 4: 0.006530330516397953
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.32 seconds!
[tester] 
AGNewsMetric: acc=0.8136842105263158, hinge=2.108768031220687, ce=9.939886237696598
Local test acc @ epoch 88: 0.8137
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0027119384612888098
Local loss @ local epoch 1: 0.01583932526409626
Local loss @ local epoch 2: 0.026833944022655487
Local loss @ local epoch 3: 0.011873179115355015
Local loss @ local epoch 4: 0.008829433470964432
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.57 seconds!
[tester] 
AGNewsMetric: acc=0.8367105263157895, hinge=1.665773710953562, ce=10.937788672196238
Local test acc @ epoch 88: 0.8367
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.026762064546346664
Local loss @ local epoch 1: 0.019078733399510384
Local loss @ local epoch 2: 0.016607679426670074
Local loss @ local epoch 3: 0.01070859469473362
Local loss @ local epoch 4: 0.010017472319304943
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.69 seconds!
[tester] 
AGNewsMetric: acc=0.8034210526315789, hinge=2.0530115544168575, ce=9.401374029862254
Local test acc @ epoch 88: 0.8034
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.001195585704408586
Local loss @ local epoch 1: 0.0009660787764005363
Local loss @ local epoch 2: 0.0010103649692609906
Local loss @ local epoch 3: 0.015003004111349583
Local loss @ local epoch 4: 0.00036661248304881155
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.62 seconds!
[tester] 
AGNewsMetric: acc=0.8328947368421052, hinge=1.6485438856325652, ce=8.68513300644724
Local test acc @ epoch 88: 0.8329
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.05005044490098953
Local loss @ local epoch 1: 0.011297204531729221
Local loss @ local epoch 2: 0.03387925773859024
Local loss @ local epoch 3: 0.006809792015701532
Local loss @ local epoch 4: 0.3709535002708435
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.99 seconds!
[tester] 
AGNewsMetric: acc=0.8328947368421052, hinge=1.6501512487311112, ce=9.512113814102976
Local test acc @ epoch 88: 0.8329
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0013254391960799694
Local loss @ local epoch 1: 0.00273511023260653
Local loss @ local epoch 2: 0.00035602174466475844
Local loss @ local epoch 3: 0.017110643908381462
Local loss @ local epoch 4: 0.006997734308242798
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.66 seconds!
[tester] 
AGNewsMetric: acc=0.8606578947368421, hinge=1.4720585366299277, ce=8.054736571060984
Local test acc @ epoch 88: 0.8607
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0997280403971672
Local loss @ local epoch 1: 0.010365952737629414
Local loss @ local epoch 2: 0.01753331907093525
Local loss @ local epoch 3: 0.22532150149345398
Local loss @ local epoch 4: 0.03653161600232124
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.28 seconds!
[tester] 
AGNewsMetric: acc=0.7782894736842105, hinge=2.1980256943953664, ce=10.811418320505243
Local test acc @ epoch 88: 0.7783
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0011618302669376135
Local loss @ local epoch 1: 0.0693017989397049
Local loss @ local epoch 2: 0.0252627432346344
Local loss @ local epoch 3: 0.022779958322644234
Local loss @ local epoch 4: 0.0004780382150784135
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.74 seconds!
[tester] 
AGNewsMetric: acc=0.8606578947368421, hinge=1.2983652930510672, ce=7.906875752900776
Local test acc @ epoch 88: 0.8607
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.007171077188104391
Local loss @ local epoch 1: 0.002963385544717312
Local loss @ local epoch 2: 0.002110507572069764
Local loss @ local epoch 3: 0.002689146436750889
Local loss @ local epoch 4: 0.002954800147563219
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.52 seconds!
[tester] 
AGNewsMetric: acc=0.7969736842105263, hinge=1.9796258447044774, ce=10.488056345487896
Local test acc @ epoch 88: 0.797
Global evaluate on test data...
Evaluate data in 130.13 seconds!
[tester] 
AGNewsMetric: acc=0.861578947368421, hinge=1.5597475960380152, ce=8.944212722778321
Global test acc @ epoch 88: 0.8616
Global epoch 89...
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0009082278702408075
Local loss @ local epoch 1: 0.025682536885142326
Local loss @ local epoch 2: 0.007589044515043497
Local loss @ local epoch 3: 0.005833559203892946
Local loss @ local epoch 4: 0.010207215324044228
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.96 seconds!
[tester] 
AGNewsMetric: acc=0.8419736842105263, hinge=1.5348152117980154, ce=9.679440183137592
Local test acc @ epoch 89: 0.842
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.000926879933103919
Local loss @ local epoch 1: 0.011358092539012432
Local loss @ local epoch 2: 0.0003431389923207462
Local loss @ local epoch 3: 0.01595153659582138
Local loss @ local epoch 4: 0.0008693602867424488
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.23 seconds!
[tester] 
AGNewsMetric: acc=0.8206578947368421, hinge=1.8477991186945062, ce=7.167298562903153
Local test acc @ epoch 89: 0.8207
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0008615407277829945
Local loss @ local epoch 1: 0.0005708983517251909
Local loss @ local epoch 2: 0.0009244436514563859
Local loss @ local epoch 3: 0.0001409824617439881
Local loss @ local epoch 4: 0.026694854721426964
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.66 seconds!
[tester] 
AGNewsMetric: acc=0.845657894736842, hinge=1.90133965943989, ce=7.632972755432129
Local test acc @ epoch 89: 0.8457
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.05436138063669205
Local loss @ local epoch 1: 0.18976686894893646
Local loss @ local epoch 2: 0.04450707510113716
Local loss @ local epoch 3: 0.05859331414103508
Local loss @ local epoch 4: 0.026649421080946922
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.3 seconds!
[tester] 
AGNewsMetric: acc=0.7884210526315789, hinge=2.2424926933489346, ce=10.798511228059468
Local test acc @ epoch 89: 0.7884
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0024812521878629923
Local loss @ local epoch 1: 0.018122589215636253
Local loss @ local epoch 2: 0.0062140594236552715
Local loss @ local epoch 3: 0.041740547865629196
Local loss @ local epoch 4: 0.015524443238973618
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.25 seconds!
[tester] 
AGNewsMetric: acc=0.8196052631578947, hinge=2.014853526416578, ce=9.528104133605957
Local test acc @ epoch 89: 0.8196
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.04691262170672417
Local loss @ local epoch 1: 0.0020131131168454885
Local loss @ local epoch 2: 0.25590065121650696
Local loss @ local epoch 3: 0.06565626710653305
Local loss @ local epoch 4: 0.20304901897907257
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.87 seconds!
[tester] 
AGNewsMetric: acc=0.8673684210526316, hinge=1.2573170857680471, ce=10.48378731978567
Local test acc @ epoch 89: 0.8674
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.002731683198362589
Local loss @ local epoch 1: 0.005163505673408508
Local loss @ local epoch 2: 0.0012877166736871004
Local loss @ local epoch 3: 0.003907688893377781
Local loss @ local epoch 4: 0.006673997733741999
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.84 seconds!
[tester] 
AGNewsMetric: acc=0.8478947368421053, hinge=1.5381839006825497, ce=7.709008670606111
Local test acc @ epoch 89: 0.8479
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.002715376438573003
Local loss @ local epoch 1: 0.0768735334277153
Local loss @ local epoch 2: 0.03948293253779411
Local loss @ local epoch 3: 0.060265153646469116
Local loss @ local epoch 4: 0.12516753375530243
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.87 seconds!
[tester] 
AGNewsMetric: acc=0.8247368421052632, hinge=1.7465960394708733, ce=6.362864181117008
Local test acc @ epoch 89: 0.8247
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0002513664949219674
Local loss @ local epoch 1: 0.0046966481022536755
Local loss @ local epoch 2: 0.0003162749926559627
Local loss @ local epoch 3: 0.01125865988433361
Local loss @ local epoch 4: 0.0025162994861602783
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.54 seconds!
[tester] 
AGNewsMetric: acc=0.8709210526315789, hinge=1.2588741545928153, ce=8.980151531821804
Local test acc @ epoch 89: 0.8709
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00015406198508571833
Local loss @ local epoch 1: 0.0005745574599131942
Local loss @ local epoch 2: 0.0006319753592833877
Local loss @ local epoch 3: 0.0026121202390640974
Local loss @ local epoch 4: 0.0002166900085285306
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.46 seconds!
[tester] 
AGNewsMetric: acc=0.8415789473684211, hinge=1.8249451403868826, ce=10.361319100229364
Local test acc @ epoch 89: 0.8416
Global evaluate on test data...
Evaluate data in 129.69 seconds!
[tester] 
AGNewsMetric: acc=0.8642105263157894, hinge=1.6068019884511044, ce=8.45777348970112
Global test acc @ epoch 89: 0.8642
Global epoch 90...
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0003003122692462057
Local loss @ local epoch 1: 0.0043803248554468155
Local loss @ local epoch 2: 0.00025905747315846384
Local loss @ local epoch 3: 0.008381130173802376
Local loss @ local epoch 4: 0.0009040864533744752
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.97 seconds!
[tester] 
AGNewsMetric: acc=0.8598684210526316, hinge=1.440771107422678, ce=9.547092807167454
Local test acc @ epoch 90: 0.8599
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.029672130942344666
Local loss @ local epoch 1: 0.9677879214286804
Local loss @ local epoch 2: 0.06141370162367821
Local loss @ local epoch 3: 0.03536684438586235
Local loss @ local epoch 4: 0.025293366983532906
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.97 seconds!
[tester] 
AGNewsMetric: acc=0.8677631578947368, hinge=1.3309583751778853, ce=7.885267571901021
Local test acc @ epoch 90: 0.8678
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0013657044619321823
Local loss @ local epoch 1: 0.0017330619739368558
Local loss @ local epoch 2: 0.07670263946056366
Local loss @ local epoch 3: 0.035857271403074265
Local loss @ local epoch 4: 0.09452491253614426
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.69 seconds!
[tester] 
AGNewsMetric: acc=0.8444736842105263, hinge=1.5940870428085328, ce=10.675126680072985
Local test acc @ epoch 90: 0.8445
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.002266696421429515
Local loss @ local epoch 1: 0.006354260258376598
Local loss @ local epoch 2: 0.06968329101800919
Local loss @ local epoch 3: 0.0007990584708750248
Local loss @ local epoch 4: 0.011052066460251808
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.22 seconds!
[tester] 
AGNewsMetric: acc=0.8228947368421052, hinge=1.7815045198641326, ce=11.001959393149928
Local test acc @ epoch 90: 0.8229
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.003277616109699011
Local loss @ local epoch 1: 0.0032674516551196575
Local loss @ local epoch 2: 0.05651285499334335
Local loss @ local epoch 3: 0.14104081690311432
Local loss @ local epoch 4: 0.002222850453108549
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.97 seconds!
[tester] 
AGNewsMetric: acc=0.8621052631578947, hinge=1.166779657665052, ce=9.319802452890496
Local test acc @ epoch 90: 0.8621
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.004567889496684074
Local loss @ local epoch 1: 0.019830312579870224
Local loss @ local epoch 2: 0.03198418766260147
Local loss @ local epoch 3: 0.0036001838743686676
Local loss @ local epoch 4: 0.011038749478757381
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.72 seconds!
[tester] 
AGNewsMetric: acc=0.8344736842105264, hinge=1.9054671327691328, ce=9.764605369567871
Local test acc @ epoch 90: 0.8345
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00041073531610891223
Local loss @ local epoch 1: 0.00012388081813696772
Local loss @ local epoch 2: 9.755554492585361e-05
Local loss @ local epoch 3: 0.00014618369459640235
Local loss @ local epoch 4: 0.0003181078645866364
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.04 seconds!
[tester] 
AGNewsMetric: acc=0.8015789473684211, hinge=2.2404453980295282, ce=9.399273464805201
Local test acc @ epoch 90: 0.8016
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.03567744791507721
Local loss @ local epoch 1: 0.06514342129230499
Local loss @ local epoch 2: 0.010082363151013851
Local loss @ local epoch 3: 0.06223868951201439
Local loss @ local epoch 4: 1.9420956373214722
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 131.14 seconds!
[tester] 
AGNewsMetric: acc=0.8431578947368421, hinge=1.5299426497911153, ce=9.75578150297466
Local test acc @ epoch 90: 0.8432
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.2732906937599182
Local loss @ local epoch 1: 0.00172416924033314
Local loss @ local epoch 2: 0.10117199271917343
Local loss @ local epoch 3: 0.06073567271232605
Local loss @ local epoch 4: 0.1335323005914688
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.86 seconds!
[tester] 
AGNewsMetric: acc=0.800921052631579, hinge=1.652514389188666, ce=6.207819725839715
Local test acc @ epoch 90: 0.8009
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0002577111008577049
Local loss @ local epoch 1: 0.02459295652806759
Local loss @ local epoch 2: 0.0003154463192913681
Local loss @ local epoch 3: 0.10162071138620377
Local loss @ local epoch 4: 0.009530575014650822
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.86 seconds!
[tester] 
AGNewsMetric: acc=0.8560526315789474, hinge=1.3250484190489116, ce=7.985024578696803
Local test acc @ epoch 90: 0.8561
Global evaluate on test data...
Evaluate data in 129.86 seconds!
[tester] 
AGNewsMetric: acc=0.866578947368421, hinge=1.4939024182369836, ce=8.398790475945724
Global test acc @ epoch 90: 0.8666
Global epoch 91...
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.006281004287302494
Local loss @ local epoch 1: 0.42008739709854126
Local loss @ local epoch 2: 0.010821918956935406
Local loss @ local epoch 3: 0.03743436560034752
Local loss @ local epoch 4: 0.06441929191350937
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.59 seconds!
[tester] 
AGNewsMetric: acc=0.8053947368421053, hinge=2.0950559796785053, ce=11.87125600513659
Local test acc @ epoch 91: 0.8054
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0008422957034781575
Local loss @ local epoch 1: 0.0004886058159172535
Local loss @ local epoch 2: 0.0003895852423738688
Local loss @ local epoch 3: 0.006610326003283262
Local loss @ local epoch 4: 0.0073737893253564835
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.97 seconds!
[tester] 
AGNewsMetric: acc=0.8392105263157895, hinge=1.3872748146559062, ce=6.434008122494347
Local test acc @ epoch 91: 0.8392
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.003301379270851612
Local loss @ local epoch 1: 0.0011539121624082327
Local loss @ local epoch 2: 0.02199074998497963
Local loss @ local epoch 3: 0.015943052247166634
Local loss @ local epoch 4: 0.010488060303032398
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.18 seconds!
[tester] 
AGNewsMetric: acc=0.8125, hinge=2.199122632930153, ce=9.160876637508995
Local test acc @ epoch 91: 0.8125
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0015307265566661954
Local loss @ local epoch 1: 0.0020346506498754025
Local loss @ local epoch 2: 0.005901233293116093
Local loss @ local epoch 3: 0.10908489674329758
Local loss @ local epoch 4: 0.010215509682893753
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.68 seconds!
[tester] 
AGNewsMetric: acc=0.7764473684210527, hinge=2.3995653175052842, ce=11.437792408591823
Local test acc @ epoch 91: 0.7764
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0006523777265101671
Local loss @ local epoch 1: 0.003700209315866232
Local loss @ local epoch 2: 0.0010694126831367612
Local loss @ local epoch 3: 0.007933278568089008
Local loss @ local epoch 4: 0.0009381634299643338
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.35 seconds!
[tester] 
AGNewsMetric: acc=0.8531578947368421, hinge=1.5261521703318546, ce=9.03574299059416
Local test acc @ epoch 91: 0.8532
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.005455834791064262
Local loss @ local epoch 1: 0.010121091268956661
Local loss @ local epoch 2: 0.22181114554405212
Local loss @ local epoch 3: 0.005315425805747509
Local loss @ local epoch 4: 0.004272072575986385
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.52 seconds!
[tester] 
AGNewsMetric: acc=0.8184210526315789, hinge=1.9447878895307842, ce=9.729428883602745
Local test acc @ epoch 91: 0.8184
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.009675640612840652
Local loss @ local epoch 1: 0.0013963186647742987
Local loss @ local epoch 2: 0.29660871624946594
Local loss @ local epoch 3: 0.0352170504629612
Local loss @ local epoch 4: 0.1593458354473114
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.71 seconds!
[tester] 
AGNewsMetric: acc=0.8453947368421053, hinge=1.6606090713802137, ce=10.401533187063118
Local test acc @ epoch 91: 0.8454
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0003159964981023222
Local loss @ local epoch 1: 0.00033031171187758446
Local loss @ local epoch 2: 0.0002495094377081841
Local loss @ local epoch 3: 0.004530874080955982
Local loss @ local epoch 4: 0.004744534380733967
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.26 seconds!
[tester] 
AGNewsMetric: acc=0.8507894736842105, hinge=1.6657833297629105, ce=9.644654986732885
Local test acc @ epoch 91: 0.8508
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.047200217843055725
Local loss @ local epoch 1: 0.005237182602286339
Local loss @ local epoch 2: 0.06439835578203201
Local loss @ local epoch 3: 0.015556669794023037
Local loss @ local epoch 4: 0.02616637572646141
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.92 seconds!
[tester] 
AGNewsMetric: acc=0.8194736842105264, hinge=1.4440028988687617, ce=6.447755757382041
Local test acc @ epoch 91: 0.8195
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00019639014499261975
Local loss @ local epoch 1: 0.00021644624939654022
Local loss @ local epoch 2: 0.0012908399803563952
Local loss @ local epoch 3: 0.0019942554645240307
Local loss @ local epoch 4: 0.006060242652893066
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.15 seconds!
[tester] 
AGNewsMetric: acc=0.8560526315789474, hinge=1.5639971780776978, ce=8.226470091970343
Local test acc @ epoch 91: 0.8561
Global evaluate on test data...
Evaluate data in 129.37 seconds!
[tester] 
AGNewsMetric: acc=0.8602631578947368, hinge=1.5812354025087858, ce=8.376517249659488
Global test acc @ epoch 91: 0.8603
Global epoch 92...
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0004293351375963539
Local loss @ local epoch 1: 0.001266178791411221
Local loss @ local epoch 2: 0.0002998565323650837
Local loss @ local epoch 3: 0.0009222020162269473
Local loss @ local epoch 4: 0.0031473636627197266
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.07 seconds!
[tester] 
AGNewsMetric: acc=0.8398684210526316, hinge=1.6540151239696301, ce=8.07045724166067
Local test acc @ epoch 92: 0.8399
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.01341067161411047
Local loss @ local epoch 1: 0.47629109025001526
Local loss @ local epoch 2: 0.08025102317333221
Local loss @ local epoch 3: 0.2697448432445526
Local loss @ local epoch 4: 0.04293222725391388
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.32 seconds!
[tester] 
AGNewsMetric: acc=0.7969736842105263, hinge=2.3472160392058523, ce=9.704524857370476
Local test acc @ epoch 92: 0.797
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.01982995495200157
Local loss @ local epoch 1: 0.014512676745653152
Local loss @ local epoch 2: 0.023820530623197556
Local loss @ local epoch 3: 0.014957590959966183
Local loss @ local epoch 4: 0.0052212015725672245
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.02 seconds!
[tester] 
AGNewsMetric: acc=0.8589473684210527, hinge=1.4938290912226626, ce=9.843897797433954
Local test acc @ epoch 92: 0.8589
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0008987659239210188
Local loss @ local epoch 1: 0.0021758361253887415
Local loss @ local epoch 2: 0.019609522074460983
Local loss @ local epoch 3: 0.0015490829246118665
Local loss @ local epoch 4: 0.03335915878415108
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.72 seconds!
[tester] 
AGNewsMetric: acc=0.8767105263157895, hinge=1.1630178730111373, ce=5.9654695139433205
Local test acc @ epoch 92: 0.8767
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0004240308771841228
Local loss @ local epoch 1: 0.0635538324713707
Local loss @ local epoch 2: 0.05491451919078827
Local loss @ local epoch 3: 0.0019039926119148731
Local loss @ local epoch 4: 0.19064345955848694
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.08 seconds!
[tester] 
AGNewsMetric: acc=0.785, hinge=2.487100746757106, ce=9.935594149137797
Local test acc @ epoch 92: 0.785
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0007133355247788131
Local loss @ local epoch 1: 0.0014869279693812132
Local loss @ local epoch 2: 0.003552470589056611
Local loss @ local epoch 3: 0.016913700848817825
Local loss @ local epoch 4: 0.03752445802092552
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.92 seconds!
[tester] 
AGNewsMetric: acc=0.8573684210526316, hinge=1.4020825381028024, ce=10.527941199854801
Local test acc @ epoch 92: 0.8574
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0017115615773946047
Local loss @ local epoch 1: 0.027574777603149414
Local loss @ local epoch 2: 0.013662552461028099
Local loss @ local epoch 3: 0.007912779226899147
Local loss @ local epoch 4: 0.10409114509820938
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.46 seconds!
[tester] 
AGNewsMetric: acc=0.7796052631578947, hinge=2.4574608785227725, ce=10.54900139055754
Local test acc @ epoch 92: 0.7796
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.04254147410392761
Local loss @ local epoch 1: 0.013208433985710144
Local loss @ local epoch 2: 0.19680093228816986
Local loss @ local epoch 3: 0.00873683113604784
Local loss @ local epoch 4: 0.13893567025661469
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.13 seconds!
[tester] 
AGNewsMetric: acc=0.8194736842105264, hinge=1.6747056311055233, ce=6.6413076671801115
Local test acc @ epoch 92: 0.8195
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0002299131010659039
Local loss @ local epoch 1: 0.00013482962094713002
Local loss @ local epoch 2: 0.0003421104629524052
Local loss @ local epoch 3: 0.00012274447362869978
Local loss @ local epoch 4: 0.0007844564388506114
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.42 seconds!
[tester] 
AGNewsMetric: acc=0.8368421052631579, hinge=1.7350034974750719, ce=9.52156581075568
Local test acc @ epoch 92: 0.8368
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0008515334920957685
Local loss @ local epoch 1: 0.004354826640337706
Local loss @ local epoch 2: 0.09760720282793045
Local loss @ local epoch 3: 0.002655537100508809
Local loss @ local epoch 4: 0.018787287175655365
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.34 seconds!
[tester] 
AGNewsMetric: acc=0.8497368421052631, hinge=1.683159482102645, ce=7.612240098652086
Local test acc @ epoch 92: 0.8497
Global evaluate on test data...
Evaluate data in 129.84 seconds!
[tester] 
AGNewsMetric: acc=0.8669736842105263, hinge=1.5868069011286685, ce=8.57596529910439
Global test acc @ epoch 92: 0.867
Global epoch 93...
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00028930717962794006
Local loss @ local epoch 1: 0.006951542105525732
Local loss @ local epoch 2: 0.0015456181718036532
Local loss @ local epoch 3: 0.05725758522748947
Local loss @ local epoch 4: 0.0011680679162964225
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.17 seconds!
[tester] 
AGNewsMetric: acc=0.8227631578947369, hinge=1.940015031663995, ce=8.316131210327148
Local test acc @ epoch 93: 0.8228
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00040137721225619316
Local loss @ local epoch 1: 0.053410209715366364
Local loss @ local epoch 2: 0.0017446838319301605
Local loss @ local epoch 3: 0.08280753344297409
Local loss @ local epoch 4: 0.22183537483215332
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.97 seconds!
[tester] 
AGNewsMetric: acc=0.8469736842105263, hinge=1.3534071578477558, ce=9.974836859452097
Local test acc @ epoch 93: 0.847
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.006946701090782881
Local loss @ local epoch 1: 0.0026366510428488255
Local loss @ local epoch 2: 0.0016362491296604276
Local loss @ local epoch 3: 0.07650380581617355
Local loss @ local epoch 4: 0.006042911671102047
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.1 seconds!
[tester] 
AGNewsMetric: acc=0.8651315789473685, hinge=1.3621416774548982, ce=8.322623539974815
Local test acc @ epoch 93: 0.8651
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.012834029272198677
Local loss @ local epoch 1: 0.17240887880325317
Local loss @ local epoch 2: 0.17992927134037018
Local loss @ local epoch 3: 0.01205184031277895
Local loss @ local epoch 4: 0.21115314960479736
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.97 seconds!
[tester] 
AGNewsMetric: acc=0.8032894736842106, hinge=2.095401967952126, ce=8.662141954522383
Local test acc @ epoch 93: 0.8033
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 7.943126547615975e-05
Local loss @ local epoch 1: 0.005970179568976164
Local loss @ local epoch 2: 0.0007274433737620711
Local loss @ local epoch 3: 0.0004759928851854056
Local loss @ local epoch 4: 0.0006466630147770047
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.59 seconds!
[tester] 
AGNewsMetric: acc=0.8597368421052631, hinge=1.3546788634751972, ce=8.157805438794588
Local test acc @ epoch 93: 0.8597
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.004791295621544123
Local loss @ local epoch 1: 0.012048983946442604
Local loss @ local epoch 2: 0.003679537447169423
Local loss @ local epoch 3: 0.14028571546077728
Local loss @ local epoch 4: 0.0008292191778309643
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.7 seconds!
[tester] 
AGNewsMetric: acc=0.8178947368421052, hinge=1.7740008948978625, ce=8.186492217214484
Local test acc @ epoch 93: 0.8179
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.007073872722685337
Local loss @ local epoch 1: 0.6213847994804382
Local loss @ local epoch 2: 0.0022207945585250854
Local loss @ local epoch 3: 1.0260798931121826
Local loss @ local epoch 4: 0.3167003095149994
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 131.13 seconds!
[tester] 
AGNewsMetric: acc=0.8252631578947368, hinge=1.701679915628935, ce=10.498814450314171
Local test acc @ epoch 93: 0.8253
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.02127254009246826
Local loss @ local epoch 1: 0.02031749114394188
Local loss @ local epoch 2: 0.028625573962926865
Local loss @ local epoch 3: 0.0015631411224603653
Local loss @ local epoch 4: 0.012784726917743683
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.84 seconds!
[tester] 
AGNewsMetric: acc=0.8343421052631579, hinge=1.3387608703814056, ce=6.729569193187513
Local test acc @ epoch 93: 0.8343
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0011247207876294851
Local loss @ local epoch 1: 0.009233875200152397
Local loss @ local epoch 2: 0.002100807847455144
Local loss @ local epoch 3: 0.0246479082852602
Local loss @ local epoch 4: 0.007962473668158054
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.92 seconds!
[tester] 
AGNewsMetric: acc=0.8193421052631579, hinge=1.7545866885938142, ce=9.831048244677092
Local test acc @ epoch 93: 0.8193
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 9.786691225599498e-05
Local loss @ local epoch 1: 0.0005081705749034882
Local loss @ local epoch 2: 0.001168603077530861
Local loss @ local epoch 3: 0.19197218120098114
Local loss @ local epoch 4: 0.00016537256306037307
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.42 seconds!
[tester] 
AGNewsMetric: acc=0.7696052631578948, hinge=3.4926287866893566, ce=9.355000467802348
Local test acc @ epoch 93: 0.7696
Global evaluate on test data...
Evaluate data in 129.35 seconds!
[tester] 
AGNewsMetric: acc=0.8636842105263158, hinge=1.5714450801046271, ce=8.317352276852256
Global test acc @ epoch 93: 0.8637
Global epoch 94...
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.11256688088178635
Local loss @ local epoch 1: 0.045572616159915924
Local loss @ local epoch 2: 0.11810974776744843
Local loss @ local epoch 3: 0.018929582089185715
Local loss @ local epoch 4: 0.01723194308578968
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.21 seconds!
[tester] 
AGNewsMetric: acc=0.7823684210526316, hinge=2.1796296907726087, ce=9.456574705023515
Local test acc @ epoch 94: 0.7824
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0013601338723674417
Local loss @ local epoch 1: 0.00451612425968051
Local loss @ local epoch 2: 0.0015364571008831263
Local loss @ local epoch 3: 0.005392609164118767
Local loss @ local epoch 4: 0.009504805319011211
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.58 seconds!
[tester] 
AGNewsMetric: acc=0.8685526315789474, hinge=1.3502842873021177, ce=7.468770588322689
Local test acc @ epoch 94: 0.8686
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.004306164104491472
Local loss @ local epoch 1: 0.0010606128489598632
Local loss @ local epoch 2: 0.003670712234452367
Local loss @ local epoch 3: 0.0175076462328434
Local loss @ local epoch 4: 0.005625905469059944
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.51 seconds!
[tester] 
AGNewsMetric: acc=0.7851315789473684, hinge=2.4773597862845973, ce=9.17785363649067
Local test acc @ epoch 94: 0.7851
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00021692246082238853
Local loss @ local epoch 1: 0.010500924661755562
Local loss @ local epoch 2: 0.0004982601967640221
Local loss @ local epoch 3: 0.028391309082508087
Local loss @ local epoch 4: 0.05445823818445206
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.92 seconds!
[tester] 
AGNewsMetric: acc=0.8596052631578948, hinge=1.333836216424641, ce=7.87304754759136
Local test acc @ epoch 94: 0.8596
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0005790638970211148
Local loss @ local epoch 1: 0.0010015685111284256
Local loss @ local epoch 2: 0.0005962144932709634
Local loss @ local epoch 3: 0.0006420929566957057
Local loss @ local epoch 4: 0.0004901283537037671
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.51 seconds!
[tester] 
AGNewsMetric: acc=0.8531578947368421, hinge=1.6459871432655735, ce=7.272384444788883
Local test acc @ epoch 94: 0.8532
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0004362417384982109
Local loss @ local epoch 1: 7.934778113849461e-05
Local loss @ local epoch 2: 0.00016324353055097163
Local loss @ local epoch 3: 0.0003469029616098851
Local loss @ local epoch 4: 0.0010553484316915274
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.3 seconds!
[tester] 
AGNewsMetric: acc=0.854078947368421, hinge=1.629286668928046, ce=8.98963199414705
Local test acc @ epoch 94: 0.8541
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.020748790353536606
Local loss @ local epoch 1: 0.004854694474488497
Local loss @ local epoch 2: 0.12807931005954742
Local loss @ local epoch 3: 0.15872375667095184
Local loss @ local epoch 4: 0.1858951300382614
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.06 seconds!
[tester] 
AGNewsMetric: acc=0.8107894736842105, hinge=1.9290897261468987, ce=10.978091141550165
Local test acc @ epoch 94: 0.8108
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.008637586608529091
Local loss @ local epoch 1: 0.016788871958851814
Local loss @ local epoch 2: 0.081110879778862
Local loss @ local epoch 3: 0.0012860341230407357
Local loss @ local epoch 4: 0.08502115309238434
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.29 seconds!
[tester] 
AGNewsMetric: acc=0.7685526315789474, hinge=2.540056240935075, ce=11.275960787722939
Local test acc @ epoch 94: 0.7686
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.03263987600803375
Local loss @ local epoch 1: 0.0029759325552731752
Local loss @ local epoch 2: 0.12340129166841507
Local loss @ local epoch 3: 0.47029775381088257
Local loss @ local epoch 4: 0.007599141448736191
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.17 seconds!
[tester] 
AGNewsMetric: acc=0.7710526315789473, hinge=2.0162382954045346, ce=7.63186897277832
Local test acc @ epoch 94: 0.7711
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0004385802894830704
Local loss @ local epoch 1: 0.002142732497304678
Local loss @ local epoch 2: 0.0014157131081447005
Local loss @ local epoch 3: 0.007004712708294392
Local loss @ local epoch 4: 0.0074477228336036205
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.37 seconds!
[tester] 
AGNewsMetric: acc=0.8557894736842105, hinge=1.6124881571217586, ce=8.810279400474148
Local test acc @ epoch 94: 0.8558
Global evaluate on test data...
Evaluate data in 130.01 seconds!
[tester] 
AGNewsMetric: acc=0.8605263157894737, hinge=1.7038398293444985, ce=8.332402946070621
Global test acc @ epoch 94: 0.8605
Global epoch 95...
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0012420066632330418
Local loss @ local epoch 1: 0.1589086502790451
Local loss @ local epoch 2: 0.001219458063133061
Local loss @ local epoch 3: 0.589241623878479
Local loss @ local epoch 4: 0.0065739769488573074
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.82 seconds!
[tester] 
AGNewsMetric: acc=0.7631578947368421, hinge=2.8186453508075915, ce=10.723474360014263
Local test acc @ epoch 95: 0.7632
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00078655342804268
Local loss @ local epoch 1: 0.0011636234121397138
Local loss @ local epoch 2: 0.0014036541106179357
Local loss @ local epoch 3: 0.003398597240447998
Local loss @ local epoch 4: 0.0022038323804736137
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 131.13 seconds!
[tester] 
AGNewsMetric: acc=0.7918421052631579, hinge=2.384854891174718, ce=10.489684454265394
Local test acc @ epoch 95: 0.7918
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00019092223374173045
Local loss @ local epoch 1: 0.0005076699890196323
Local loss @ local epoch 2: 0.000632155395578593
Local loss @ local epoch 3: 0.00021125515922904015
Local loss @ local epoch 4: 0.0978054329752922
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.87 seconds!
[tester] 
AGNewsMetric: acc=0.8485526315789473, hinge=1.7778360685549284, ce=8.696870725531326
Local test acc @ epoch 95: 0.8486
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.014159117825329304
Local loss @ local epoch 1: 0.001604245277121663
Local loss @ local epoch 2: 0.11951316893100739
Local loss @ local epoch 3: 0.0153804337605834
Local loss @ local epoch 4: 0.0017634410178288817
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.63 seconds!
[tester] 
AGNewsMetric: acc=0.8156578947368421, hinge=2.0361617755889894, ce=6.91257016734073
Local test acc @ epoch 95: 0.8157
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00041069742292165756
Local loss @ local epoch 1: 0.06296893209218979
Local loss @ local epoch 2: 0.006591398268938065
Local loss @ local epoch 3: 0.001276715542189777
Local loss @ local epoch 4: 0.010858457535505295
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.97 seconds!
[tester] 
AGNewsMetric: acc=0.8543421052631579, hinge=1.3174570866634971, ce=8.137574637563604
Local test acc @ epoch 95: 0.8543
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.061627063900232315
Local loss @ local epoch 1: 0.07711464911699295
Local loss @ local epoch 2: 0.06943360716104507
Local loss @ local epoch 3: 0.047658465802669525
Local loss @ local epoch 4: 0.035816844552755356
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.38 seconds!
[tester] 
AGNewsMetric: acc=0.8425, hinge=1.502488418629295, ce=9.431950171621223
Local test acc @ epoch 95: 0.8425
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0012271093437448144
Local loss @ local epoch 1: 0.003421969711780548
Local loss @ local epoch 2: 0.0039232876151800156
Local loss @ local epoch 3: 0.004529353231191635
Local loss @ local epoch 4: 0.5609469413757324
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.3 seconds!
[tester] 
AGNewsMetric: acc=0.844078947368421, hinge=1.446167994800367, ce=7.975367149553801
Local test acc @ epoch 95: 0.8441
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0039690290577709675
Local loss @ local epoch 1: 0.00023516264627687633
Local loss @ local epoch 2: 0.42590823769569397
Local loss @ local epoch 3: 0.0028090262785553932
Local loss @ local epoch 4: 0.0016111221630126238
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.9 seconds!
[tester] 
AGNewsMetric: acc=0.8338157894736842, hinge=1.8133096323515239, ce=9.14237691176565
Local test acc @ epoch 95: 0.8338
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0002645576314534992
Local loss @ local epoch 1: 0.0002169742074329406
Local loss @ local epoch 2: 5.1085997256450355e-05
Local loss @ local epoch 3: 0.0010630151955410838
Local loss @ local epoch 4: 0.00024392979685217142
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.1 seconds!
[tester] 
AGNewsMetric: acc=0.8425, hinge=1.8817498776787205, ce=8.259256160133763
Local test acc @ epoch 95: 0.8425
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.044789668172597885
Local loss @ local epoch 1: 0.013031773269176483
Local loss @ local epoch 2: 0.037785910069942474
Local loss @ local epoch 3: 0.025668630376458168
Local loss @ local epoch 4: 0.034660033881664276
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.4 seconds!
[tester] 
AGNewsMetric: acc=0.8201315789473684, hinge=1.9948221552999397, ce=9.643741661874872
Local test acc @ epoch 95: 0.8201
Global evaluate on test data...
Evaluate data in 130.2 seconds!
[tester] 
AGNewsMetric: acc=0.8606578947368421, hinge=1.657404098510742, ce=8.381183969598068
Global test acc @ epoch 95: 0.8607
Global epoch 96...
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0005657447036355734
Local loss @ local epoch 1: 0.0008764107478782535
Local loss @ local epoch 2: 0.00031751516507938504
Local loss @ local epoch 3: 0.0001847164094215259
Local loss @ local epoch 4: 0.0004619141109287739
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.2 seconds!
[tester] 
AGNewsMetric: acc=0.8294736842105264, hinge=1.7710730434718884, ce=9.413473801863821
Local test acc @ epoch 96: 0.8295
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00042605289490893483
Local loss @ local epoch 1: 0.05877786502242088
Local loss @ local epoch 2: 0.10745979845523834
Local loss @ local epoch 3: 0.0015913883689790964
Local loss @ local epoch 4: 0.1417243480682373
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.28 seconds!
[tester] 
AGNewsMetric: acc=0.8027631578947368, hinge=2.1310229677903023, ce=10.623946563319157
Local test acc @ epoch 96: 0.8028
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0012486008927226067
Local loss @ local epoch 1: 0.10760784894227982
Local loss @ local epoch 2: 0.012761243619024754
Local loss @ local epoch 3: 0.09533069282770157
Local loss @ local epoch 4: 0.2286694347858429
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.47 seconds!
[tester] 
AGNewsMetric: acc=0.8242105263157895, hinge=1.85921572007631, ce=11.118462933992085
Local test acc @ epoch 96: 0.8242
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.03651285544037819
Local loss @ local epoch 1: 0.0012083621695637703
Local loss @ local epoch 2: 0.019733760505914688
Local loss @ local epoch 3: 0.2798617482185364
Local loss @ local epoch 4: 0.131564661860466
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.06 seconds!
[tester] 
AGNewsMetric: acc=0.8510526315789474, hinge=1.3522003688310322, ce=11.076438678942228
Local test acc @ epoch 96: 0.8511
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0003999176842626184
Local loss @ local epoch 1: 0.0015161216724663973
Local loss @ local epoch 2: 0.0008399369544349611
Local loss @ local epoch 3: 0.002986431587487459
Local loss @ local epoch 4: 0.0015839977422729135
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.61 seconds!
[tester] 
AGNewsMetric: acc=0.8605263157894737, hinge=1.4327861467160676, ce=8.313722552249306
Local test acc @ epoch 96: 0.8605
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.031768955290317535
Local loss @ local epoch 1: 0.022911304607987404
Local loss @ local epoch 2: 0.015486284159123898
Local loss @ local epoch 3: 0.04686039686203003
Local loss @ local epoch 4: 0.009254174306988716
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.47 seconds!
[tester] 
AGNewsMetric: acc=0.8397368421052631, hinge=1.7624570013347425, ce=7.106358935707494
Local test acc @ epoch 96: 0.8397
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0008955150260590017
Local loss @ local epoch 1: 0.0003370627819094807
Local loss @ local epoch 2: 0.0014616309199482203
Local loss @ local epoch 3: 0.0006819039699621499
Local loss @ local epoch 4: 0.000723247358109802
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.75 seconds!
[tester] 
AGNewsMetric: acc=0.8152631578947368, hinge=2.22098475682108, ce=9.675531690497147
Local test acc @ epoch 96: 0.8153
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.06710359454154968
Local loss @ local epoch 1: 0.022092901170253754
Local loss @ local epoch 2: 0.03160339221358299
Local loss @ local epoch 3: 0.1148725375533104
Local loss @ local epoch 4: 0.01278301514685154
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.58 seconds!
[tester] 
AGNewsMetric: acc=0.8542105263157894, hinge=1.37010624157755, ce=10.389744646172774
Local test acc @ epoch 96: 0.8542
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0026802520733326674
Local loss @ local epoch 1: 0.012408379465341568
Local loss @ local epoch 2: 0.0014464579289779067
Local loss @ local epoch 3: 0.0868091806769371
Local loss @ local epoch 4: 0.002974499249830842
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.7 seconds!
[tester] 
AGNewsMetric: acc=0.8478947368421053, hinge=1.696311338073329, ce=8.160567259537546
Local test acc @ epoch 96: 0.8479
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 5.458557643578388e-05
Local loss @ local epoch 1: 0.000807077216450125
Local loss @ local epoch 2: 0.0004147218423895538
Local loss @ local epoch 3: 0.0008174777613021433
Local loss @ local epoch 4: 0.0025501768104732037
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.57 seconds!
[tester] 
AGNewsMetric: acc=0.8328947368421052, hinge=1.9140915991130627, ce=10.59350785907946
Local test acc @ epoch 96: 0.8329
Global evaluate on test data...
Evaluate data in 129.81 seconds!
[tester] 
AGNewsMetric: acc=0.8589473684210527, hinge=1.6076875350349829, ce=9.47045527207224
Global test acc @ epoch 96: 0.8589
Global epoch 97...
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.022986948490142822
Local loss @ local epoch 1: 0.008790243417024612
Local loss @ local epoch 2: 0.05053345859050751
Local loss @ local epoch 3: 0.01596265845000744
Local loss @ local epoch 4: 0.11318300664424896
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.98 seconds!
[tester] 
AGNewsMetric: acc=0.8180263157894737, hinge=1.4488674843938727, ce=9.620640043961375
Local test acc @ epoch 97: 0.818
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.015563699416816235
Local loss @ local epoch 1: 0.00020710629178211093
Local loss @ local epoch 2: 0.011892558075487614
Local loss @ local epoch 3: 0.11900985985994339
Local loss @ local epoch 4: 0.006337917409837246
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.12 seconds!
[tester] 
AGNewsMetric: acc=0.8757894736842106, hinge=1.081189627396433, ce=10.5723959410818
Local test acc @ epoch 97: 0.8758
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.05830061435699463
Local loss @ local epoch 1: 0.0046079992316663265
Local loss @ local epoch 2: 0.08589020371437073
Local loss @ local epoch 3: 0.01582755334675312
Local loss @ local epoch 4: 0.00587870879098773
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.64 seconds!
[tester] 
AGNewsMetric: acc=0.7555263157894737, hinge=2.539498835362886, ce=8.956261972126208
Local test acc @ epoch 97: 0.7555
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.004318392835557461
Local loss @ local epoch 1: 0.0005159971187822521
Local loss @ local epoch 2: 0.010575933381915092
Local loss @ local epoch 3: 0.030623823404312134
Local loss @ local epoch 4: 0.0030723160598427057
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.25 seconds!
[tester] 
AGNewsMetric: acc=0.8228947368421052, hinge=1.842770881401865, ce=11.259363744635332
Local test acc @ epoch 97: 0.8229
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0003120374458376318
Local loss @ local epoch 1: 0.004254871979355812
Local loss @ local epoch 2: 0.0007679720292799175
Local loss @ local epoch 3: 0.0005401297239586711
Local loss @ local epoch 4: 0.0010163438273593783
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 131.27 seconds!
[tester] 
AGNewsMetric: acc=0.8657894736842106, hinge=1.3039730601561696, ce=10.417465792204204
Local test acc @ epoch 97: 0.8658
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.12769509851932526
Local loss @ local epoch 1: 0.06779305636882782
Local loss @ local epoch 2: 0.020265091210603714
Local loss @ local epoch 3: 0.3081252872943878
Local loss @ local epoch 4: 0.05721321702003479
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.41 seconds!
[tester] 
AGNewsMetric: acc=0.7775, hinge=2.072250115494979, ce=10.06746699082224
Local test acc @ epoch 97: 0.7775
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00025774945970624685
Local loss @ local epoch 1: 0.0016443496569991112
Local loss @ local epoch 2: 0.000640684156678617
Local loss @ local epoch 3: 0.03360713645815849
Local loss @ local epoch 4: 0.0008489710162393749
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.55 seconds!
[tester] 
AGNewsMetric: acc=0.7948684210526316, hinge=2.783605940969367, ce=10.351801061128315
Local test acc @ epoch 97: 0.7949
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0001582360710017383
Local loss @ local epoch 1: 0.0014932615449652076
Local loss @ local epoch 2: 0.00014747303794138134
Local loss @ local epoch 3: 0.000647593813482672
Local loss @ local epoch 4: 0.014007754623889923
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.39 seconds!
[tester] 
AGNewsMetric: acc=0.8475, hinge=1.7678264497455798, ce=7.517956812005294
Local test acc @ epoch 97: 0.8475
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0003060211311094463
Local loss @ local epoch 1: 0.0066003985702991486
Local loss @ local epoch 2: 0.00042916194070130587
Local loss @ local epoch 3: 0.001131930504925549
Local loss @ local epoch 4: 0.000823856214992702
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.09 seconds!
[tester] 
AGNewsMetric: acc=0.8575, hinge=1.7918984390559949, ce=9.990200430217541
Local test acc @ epoch 97: 0.8575
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.01619253307580948
Local loss @ local epoch 1: 0.009516448713839054
Local loss @ local epoch 2: 0.12408194690942764
Local loss @ local epoch 3: 0.040503956377506256
Local loss @ local epoch 4: 0.0002834939514286816
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.23 seconds!
[tester] 
AGNewsMetric: acc=0.7931578947368421, hinge=2.3855441221437954, ce=7.871328665080823
Local test acc @ epoch 97: 0.7932
Global evaluate on test data...
Evaluate data in 129.45 seconds!
[tester] 
AGNewsMetric: acc=0.8655263157894737, hinge=1.5271471982253226, ce=9.503678729408666
Global test acc @ epoch 97: 0.8655
Global epoch 98...
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0316382572054863
Local loss @ local epoch 1: 0.29028019309043884
Local loss @ local epoch 2: 0.050866495817899704
Local loss @ local epoch 3: 0.15009501576423645
Local loss @ local epoch 4: 0.0353856235742569
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.63 seconds!
[tester] 
AGNewsMetric: acc=0.835, hinge=1.6040671461506895, ce=9.396855392456054
Local test acc @ epoch 98: 0.835
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0002372191083850339
Local loss @ local epoch 1: 3.235636177123524e-05
Local loss @ local epoch 2: 6.502142787212506e-05
Local loss @ local epoch 3: 0.0011766518000513315
Local loss @ local epoch 4: 0.012517009861767292
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.5 seconds!
[tester] 
AGNewsMetric: acc=0.8427631578947369, hinge=1.801992614645707, ce=10.514910547356857
Local test acc @ epoch 98: 0.8428
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.05437310412526131
Local loss @ local epoch 1: 0.016140971332788467
Local loss @ local epoch 2: 0.3329850137233734
Local loss @ local epoch 3: 0.0012091778917238116
Local loss @ local epoch 4: 0.0015788937453180552
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.7 seconds!
[tester] 
AGNewsMetric: acc=0.8436842105263158, hinge=1.685435283560502, ce=9.870025652835244
Local test acc @ epoch 98: 0.8437
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.19229689240455627
Local loss @ local epoch 1: 0.0032538140658289194
Local loss @ local epoch 2: 0.11905120313167572
Local loss @ local epoch 3: 0.126073956489563
Local loss @ local epoch 4: 0.04201207682490349
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.84 seconds!
[tester] 
AGNewsMetric: acc=0.7885526315789474, hinge=1.6666737513793142, ce=7.811675716199373
Local test acc @ epoch 98: 0.7886
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.007958589121699333
Local loss @ local epoch 1: 0.01043567806482315
Local loss @ local epoch 2: 0.0007617345545440912
Local loss @ local epoch 3: 0.0049855588003993034
Local loss @ local epoch 4: 0.0900377705693245
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.78 seconds!
[tester] 
AGNewsMetric: acc=0.6931578947368421, hinge=4.319303344927336, ce=11.50082766281931
Local test acc @ epoch 98: 0.6932
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0005717765307053924
Local loss @ local epoch 1: 0.0010708069894462824
Local loss @ local epoch 2: 0.020408766344189644
Local loss @ local epoch 3: 0.0027926466427743435
Local loss @ local epoch 4: 0.003366026794537902
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.31 seconds!
[tester] 
AGNewsMetric: acc=0.8688157894736842, hinge=1.2234752828196476, ce=10.685174389889365
Local test acc @ epoch 98: 0.8688
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00018241499492432922
Local loss @ local epoch 1: 0.00016424644854851067
Local loss @ local epoch 2: 0.0007997116772457957
Local loss @ local epoch 3: 0.0011696573346853256
Local loss @ local epoch 4: 0.00041569641325622797
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.27 seconds!
[tester] 
AGNewsMetric: acc=0.7607894736842106, hinge=3.5354974475659824, ce=10.230876157660234
Local test acc @ epoch 98: 0.7608
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0024005777668207884
Local loss @ local epoch 1: 0.002468725200742483
Local loss @ local epoch 2: 0.0016600589733570814
Local loss @ local epoch 3: 0.0011133479420095682
Local loss @ local epoch 4: 0.0006547312368638813
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.21 seconds!
[tester] 
AGNewsMetric: acc=0.8306578947368422, hinge=1.6578258915951378, ce=11.195338116696007
Local test acc @ epoch 98: 0.8307
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0068542081862688065
Local loss @ local epoch 1: 0.0011815008474513888
Local loss @ local epoch 2: 0.0032172829378396273
Local loss @ local epoch 3: 0.0004658474354073405
Local loss @ local epoch 4: 0.006183498073369265
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.76 seconds!
[tester] 
AGNewsMetric: acc=0.825921052631579, hinge=1.9213784576717177, ce=9.96636930566085
Local test acc @ epoch 98: 0.8259
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0004644727741833776
Local loss @ local epoch 1: 0.0008356118923984468
Local loss @ local epoch 2: 0.0002812919265124947
Local loss @ local epoch 3: 0.0002842653193511069
Local loss @ local epoch 4: 0.0006468428182415664
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.13 seconds!
[tester] 
AGNewsMetric: acc=0.8402631578947368, hinge=1.787824215888977, ce=8.993492044147692
Local test acc @ epoch 98: 0.8403
Global evaluate on test data...
Evaluate data in 130.27 seconds!
[tester] 
AGNewsMetric: acc=0.8598684210526316, hinge=1.690891243784051, ce=9.15608256490607
Global test acc @ epoch 98: 0.8599
Global epoch 99...
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00011301976337563246
Local loss @ local epoch 1: 0.00021133446716703475
Local loss @ local epoch 2: 3.412885416764766e-05
Local loss @ local epoch 3: 0.0015564329223707318
Local loss @ local epoch 4: 0.32568007707595825
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.28 seconds!
[tester] 
AGNewsMetric: acc=0.8406578947368422, hinge=1.8475921791478207, ce=8.772575031079745
Local test acc @ epoch 99: 0.8407
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 6.769646279281005e-05
Local loss @ local epoch 1: 0.000722775177564472
Local loss @ local epoch 2: 0.0022314037196338177
Local loss @ local epoch 3: 0.0003209569549653679
Local loss @ local epoch 4: 0.00025209004525095224
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.98 seconds!
[tester] 
AGNewsMetric: acc=0.8257894736842105, hinge=1.747618673475165, ce=9.007795857881245
Local test acc @ epoch 99: 0.8258
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.01397720631211996
Local loss @ local epoch 1: 0.00458521768450737
Local loss @ local epoch 2: 0.6184490919113159
Local loss @ local epoch 3: 0.09508336335420609
Local loss @ local epoch 4: 0.022479988634586334
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.48 seconds!
[tester] 
AGNewsMetric: acc=0.8192105263157895, hinge=1.3108811212840834, ce=6.802335431952225
Local test acc @ epoch 99: 0.8192
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.005637882277369499
Local loss @ local epoch 1: 0.7448333501815796
Local loss @ local epoch 2: 0.02509981580078602
Local loss @ local epoch 3: 0.1551479995250702
Local loss @ local epoch 4: 0.009866539388895035
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.5 seconds!
[tester] 
AGNewsMetric: acc=0.8731578947368421, hinge=1.1678625904886346, ce=10.166862136439272
Local test acc @ epoch 99: 0.8732
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0016867188969627023
Local loss @ local epoch 1: 0.008802328258752823
Local loss @ local epoch 2: 0.0002923416905105114
Local loss @ local epoch 3: 0.0014826443511992693
Local loss @ local epoch 4: 0.3325100839138031
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 131.13 seconds!
[tester] 
AGNewsMetric: acc=0.815921052631579, hinge=2.0783142340810676, ce=10.48862551036634
Local test acc @ epoch 99: 0.8159
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 9.862561273621395e-05
Local loss @ local epoch 1: 0.0433356948196888
Local loss @ local epoch 2: 9.461854642722756e-05
Local loss @ local epoch 3: 0.00027378552476875484
Local loss @ local epoch 4: 0.005588078405708075
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.33 seconds!
[tester] 
AGNewsMetric: acc=0.8497368421052631, hinge=1.6653534502732126, ce=8.484092977423417
Local test acc @ epoch 99: 0.8497
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.018810169771313667
Local loss @ local epoch 1: 0.008707382716238499
Local loss @ local epoch 2: 0.8612090349197388
Local loss @ local epoch 3: 0.44645947217941284
Local loss @ local epoch 4: 0.15794530510902405
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.53 seconds!
[tester] 
AGNewsMetric: acc=0.8451315789473685, hinge=1.1012606452640734, ce=7.284543789311459
Local test acc @ epoch 99: 0.8451
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0034704834688454866
Local loss @ local epoch 1: 0.0011838434729725122
Local loss @ local epoch 2: 0.10664039105176926
Local loss @ local epoch 3: 0.002385212341323495
Local loss @ local epoch 4: 0.13286980986595154
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.73 seconds!
[tester] 
AGNewsMetric: acc=0.8298684210526316, hinge=2.1655168094133077, ce=10.227937963385331
Local test acc @ epoch 99: 0.8299
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 4.013321449747309e-05
Local loss @ local epoch 1: 0.00031457244767807424
Local loss @ local epoch 2: 0.00038715836126357317
Local loss @ local epoch 3: 0.0001028464175760746
Local loss @ local epoch 4: 0.0045272125862538815
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.68 seconds!
[tester] 
AGNewsMetric: acc=0.8318421052631579, hinge=1.8325411947149979, ce=10.761836491634972
Local test acc @ epoch 99: 0.8318
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.045259881764650345
Local loss @ local epoch 1: 0.001298049814067781
Local loss @ local epoch 2: 0.002048216760158539
Local loss @ local epoch 3: 0.17968294024467468
Local loss @ local epoch 4: 0.03760753944516182
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.85 seconds!
[tester] 
AGNewsMetric: acc=0.8567105263157895, hinge=1.0636384979047273, ce=8.003930107919793
Local test acc @ epoch 99: 0.8567
Global evaluate on test data...
Evaluate data in 130.74 seconds!
[tester] 
AGNewsMetric: acc=0.866578947368421, hinge=1.5515253694433915, ce=8.877694547552812
Global test acc @ epoch 99: 0.8666
Global epoch 100...
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.007618661969900131
Local loss @ local epoch 1: 0.00017333353753201663
Local loss @ local epoch 2: 0.16624905169010162
Local loss @ local epoch 3: 0.0010367233771830797
Local loss @ local epoch 4: 0.002592345466837287
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.93 seconds!
[tester] 
AGNewsMetric: acc=0.8485526315789473, hinge=1.6084344926633334, ce=10.189510275188246
Local test acc @ epoch 100: 0.8486
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00018800442921929061
Local loss @ local epoch 1: 0.00015797406376805156
Local loss @ local epoch 2: 0.00010173498594667763
Local loss @ local epoch 3: 0.006745376158505678
Local loss @ local epoch 4: 0.00019986399274785072
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.05 seconds!
[tester] 
AGNewsMetric: acc=0.8177631578947369, hinge=2.0314158299094753, ce=8.635387517025595
Local test acc @ epoch 100: 0.8178
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.1551065444946289
Local loss @ local epoch 1: 0.024611881002783775
Local loss @ local epoch 2: 0.34036391973495483
Local loss @ local epoch 3: 0.27276548743247986
Local loss @ local epoch 4: 0.19785593450069427
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 131.24 seconds!
[tester] 
AGNewsMetric: acc=0.8442105263157895, hinge=1.254067302252117, ce=7.403046460402639
Local test acc @ epoch 100: 0.8442
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 6.730075983796269e-05
Local loss @ local epoch 1: 0.0001098186694434844
Local loss @ local epoch 2: 0.0005046013393439353
Local loss @ local epoch 3: 0.0004391538386698812
Local loss @ local epoch 4: 0.0003301241958979517
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.75 seconds!
[tester] 
AGNewsMetric: acc=0.8243421052631579, hinge=2.0711194849014283, ce=9.180444289759587
Local test acc @ epoch 100: 0.8243
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0013070794520899653
Local loss @ local epoch 1: 0.001027783495374024
Local loss @ local epoch 2: 0.9157878756523132
Local loss @ local epoch 3: 0.000809678400401026
Local loss @ local epoch 4: 0.0081138014793396
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.53 seconds!
[tester] 
AGNewsMetric: acc=0.8251315789473684, hinge=1.9136254295549895, ce=7.405779422960784
Local test acc @ epoch 100: 0.8251
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00011234513658564538
Local loss @ local epoch 1: 0.0008464015554636717
Local loss @ local epoch 2: 0.015010721981525421
Local loss @ local epoch 3: 6.057337668607943e-05
Local loss @ local epoch 4: 0.09271719306707382
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.62 seconds!
[tester] 
AGNewsMetric: acc=0.8507894736842105, hinge=1.7510593040365923, ce=9.828909261603105
Local test acc @ epoch 100: 0.8508
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0016586289275437593
Local loss @ local epoch 1: 0.0001846791128627956
Local loss @ local epoch 2: 0.05044356361031532
Local loss @ local epoch 3: 0.026176167652010918
Local loss @ local epoch 4: 0.0008779495256021619
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.66 seconds!
[tester] 
AGNewsMetric: acc=0.8442105263157895, hinge=1.7502086247895894, ce=10.055142021179199
Local test acc @ epoch 100: 0.8442
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.04369967803359032
Local loss @ local epoch 1: 0.008769280277192593
Local loss @ local epoch 2: 0.0035693671088665724
Local loss @ local epoch 3: 0.06230626255273819
Local loss @ local epoch 4: 0.033998917788267136
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.32 seconds!
[tester] 
AGNewsMetric: acc=0.7951315789473684, hinge=1.671681432723999, ce=7.724952265086927
Local test acc @ epoch 100: 0.7951
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0029816466849297285
Local loss @ local epoch 1: 0.0698235034942627
Local loss @ local epoch 2: 0.0006041587330400944
Local loss @ local epoch 3: 0.024203738197684288
Local loss @ local epoch 4: 0.007188320159912109
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.8 seconds!
[tester] 
AGNewsMetric: acc=0.799078947368421, hinge=2.392537744923642, ce=9.924536383779426
Local test acc @ epoch 100: 0.7991
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.01240611169487238
Local loss @ local epoch 1: 0.00017802900401875377
Local loss @ local epoch 2: 0.00022243609419092536
Local loss @ local epoch 3: 0.0005464870482683182
Local loss @ local epoch 4: 0.002069917507469654
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.57 seconds!
[tester] 
AGNewsMetric: acc=0.8373684210526315, hinge=1.6331861004076507, ce=10.493118615401418
Local test acc @ epoch 100: 0.8374
Global evaluate on test data...
Evaluate data in 129.96 seconds!
[tester] 
AGNewsMetric: acc=0.8575, hinge=1.7534944313450864, ce=9.194091385289243
Global test acc @ epoch 100: 0.8575
Global epoch 101...
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00020437657076399773
Local loss @ local epoch 1: 0.33755412697792053
Local loss @ local epoch 2: 0.005689649377018213
Local loss @ local epoch 3: 0.006494640838354826
Local loss @ local epoch 4: 0.14209328591823578
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.82 seconds!
[tester] 
AGNewsMetric: acc=0.8280263157894737, hinge=1.7553071242884586, ce=10.885364315635279
Local test acc @ epoch 101: 0.828
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0027957556303590536
Local loss @ local epoch 1: 0.038261331617832184
Local loss @ local epoch 2: 0.004098472185432911
Local loss @ local epoch 3: 0.2455352246761322
Local loss @ local epoch 4: 0.020245973020792007
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.96 seconds!
[tester] 
AGNewsMetric: acc=0.7310526315789474, hinge=3.460652649528102, ce=10.89322213223106
Local test acc @ epoch 101: 0.7311
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0001711949153104797
Local loss @ local epoch 1: 0.09275434166193008
Local loss @ local epoch 2: 0.0011102884309366345
Local loss @ local epoch 3: 0.16213901340961456
Local loss @ local epoch 4: 0.0021028597839176655
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.71 seconds!
[tester] 
AGNewsMetric: acc=0.8381578947368421, hinge=1.8526196128443668, ce=7.833594374405711
Local test acc @ epoch 101: 0.8382
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0055523463524878025
Local loss @ local epoch 1: 0.0027643200010061264
Local loss @ local epoch 2: 0.002193745691329241
Local loss @ local epoch 3: 0.003956594504415989
Local loss @ local epoch 4: 0.0017205491894856095
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.69 seconds!
[tester] 
AGNewsMetric: acc=0.7781578947368422, hinge=2.3844717201433685, ce=11.664329079075863
Local test acc @ epoch 101: 0.7782
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0007042664801701903
Local loss @ local epoch 1: 0.0001633434440009296
Local loss @ local epoch 2: 0.007443865295499563
Local loss @ local epoch 3: 0.0003748518938664347
Local loss @ local epoch 4: 0.0058725387789309025
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.93 seconds!
[tester] 
AGNewsMetric: acc=0.85, hinge=1.5786254958102577, ce=9.822899782281173
Local test acc @ epoch 101: 0.85
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.028934236615896225
Local loss @ local epoch 1: 0.0069719525054097176
Local loss @ local epoch 2: 0.06589855253696442
Local loss @ local epoch 3: 0.04111439362168312
Local loss @ local epoch 4: 0.036207329481840134
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.1 seconds!
[tester] 
AGNewsMetric: acc=0.8738157894736842, hinge=1.071560482727854, ce=9.021890218634354
Local test acc @ epoch 101: 0.8738
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0009672592277638614
Local loss @ local epoch 1: 0.0029481439851224422
Local loss @ local epoch 2: 0.10642050951719284
Local loss @ local epoch 3: 0.0021950663067400455
Local loss @ local epoch 4: 0.12170623987913132
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.01 seconds!
[tester] 
AGNewsMetric: acc=0.8380263157894737, hinge=1.904659514929119, ce=9.636471890901264
Local test acc @ epoch 101: 0.838
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0016454521100968122
Local loss @ local epoch 1: 0.00039391755126416683
Local loss @ local epoch 2: 0.008541064336895943
Local loss @ local epoch 3: 0.8048231601715088
Local loss @ local epoch 4: 0.5336065292358398
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.18 seconds!
[tester] 
AGNewsMetric: acc=0.8265789473684211, hinge=2.0931245914258456, ce=9.86713715603477
Local test acc @ epoch 101: 0.8266
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 5.6978427892317995e-05
Local loss @ local epoch 1: 0.00011787309631472453
Local loss @ local epoch 2: 7.455120794475079e-05
Local loss @ local epoch 3: 0.0007747289491817355
Local loss @ local epoch 4: 0.002795351669192314
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.05 seconds!
[tester] 
AGNewsMetric: acc=0.8365789473684211, hinge=1.9704158692610891, ce=9.454481195148668
Local test acc @ epoch 101: 0.8366
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0012017732951790094
Local loss @ local epoch 1: 0.0012351605109870434
Local loss @ local epoch 2: 0.0045016054064035416
Local loss @ local epoch 3: 0.002839242573827505
Local loss @ local epoch 4: 0.00045499519910663366
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.47 seconds!
[tester] 
AGNewsMetric: acc=0.8625, hinge=1.6141548761568572, ce=10.488729043257864
Local test acc @ epoch 101: 0.8625
Global evaluate on test data...
Evaluate data in 130.39 seconds!
[tester] 
AGNewsMetric: acc=0.8557894736842105, hinge=1.7881238337566978, ce=9.910822045175653
Global test acc @ epoch 101: 0.8558
Global epoch 102...
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00010749515058705583
Local loss @ local epoch 1: 0.0003012486267834902
Local loss @ local epoch 2: 0.5393630266189575
Local loss @ local epoch 3: 3.870376167469658e-05
Local loss @ local epoch 4: 6.335184298222885e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.36 seconds!
[tester] 
AGNewsMetric: acc=0.8557894736842105, hinge=1.6049722887340345, ce=10.088316963597348
Local test acc @ epoch 102: 0.8558
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.05492374673485756
Local loss @ local epoch 1: 0.021059716120362282
Local loss @ local epoch 2: 0.01467285118997097
Local loss @ local epoch 3: 0.7359032034873962
Local loss @ local epoch 4: 0.1169954314827919
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.67 seconds!
[tester] 
AGNewsMetric: acc=0.7996052631578947, hinge=1.9045411503942389, ce=9.032064998024389
Local test acc @ epoch 102: 0.7996
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00015175434236880392
Local loss @ local epoch 1: 0.0025188582949340343
Local loss @ local epoch 2: 2.840040178853087e-05
Local loss @ local epoch 3: 0.0027141873724758625
Local loss @ local epoch 4: 0.000781712238676846
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.97 seconds!
[tester] 
AGNewsMetric: acc=0.8338157894736842, hinge=2.028155190442738, ce=10.638501590929533
Local test acc @ epoch 102: 0.8338
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0005919416435062885
Local loss @ local epoch 1: 0.0009208173723891377
Local loss @ local epoch 2: 0.0013905154773965478
Local loss @ local epoch 3: 0.04426514357328415
Local loss @ local epoch 4: 0.004202744923532009
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.62 seconds!
[tester] 
AGNewsMetric: acc=0.7285526315789473, hinge=4.248584180380169, ce=11.14489477458753
Local test acc @ epoch 102: 0.7286
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0865219384431839
Local loss @ local epoch 1: 0.005044718738645315
Local loss @ local epoch 2: 0.0017252739053219557
Local loss @ local epoch 3: 0.0994734838604927
Local loss @ local epoch 4: 0.21546903252601624
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.51 seconds!
[tester] 
AGNewsMetric: acc=0.8222368421052632, hinge=1.6076121119449014, ce=9.86060195320531
Local test acc @ epoch 102: 0.8222
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.063900426030159
Local loss @ local epoch 1: 0.15172433853149414
Local loss @ local epoch 2: 0.002573433332145214
Local loss @ local epoch 3: 0.01352589763700962
Local loss @ local epoch 4: 0.7701788544654846
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.54 seconds!
[tester] 
AGNewsMetric: acc=0.5885526315789473, hinge=5.2537831334063885, ce=12.1034144130506
Local test acc @ epoch 102: 0.5886
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 7.602528057759628e-05
Local loss @ local epoch 1: 0.3027895390987396
Local loss @ local epoch 2: 0.0006559047615155578
Local loss @ local epoch 3: 0.0014284781645983458
Local loss @ local epoch 4: 0.024844475090503693
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.02 seconds!
[tester] 
AGNewsMetric: acc=0.8327631578947369, hinge=1.7284640036131207, ce=9.746725957770096
Local test acc @ epoch 102: 0.8328
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0024924776516854763
Local loss @ local epoch 1: 0.0001107229691115208
Local loss @ local epoch 2: 0.0009682962554506958
Local loss @ local epoch 3: 0.003484355052933097
Local loss @ local epoch 4: 0.0002349867281736806
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.22 seconds!
[tester] 
AGNewsMetric: acc=0.8257894736842105, hinge=1.6423133960523104, ce=7.284433118920577
Local test acc @ epoch 102: 0.8258
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0028052658308297396
Local loss @ local epoch 1: 0.0008379300124943256
Local loss @ local epoch 2: 0.0007471564458683133
Local loss @ local epoch 3: 0.001890021376311779
Local loss @ local epoch 4: 0.0016185101121664047
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.3 seconds!
[tester] 
AGNewsMetric: acc=0.7789473684210526, hinge=2.6041708715338454, ce=11.159399478310032
Local test acc @ epoch 102: 0.7789
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.009670548141002655
Local loss @ local epoch 1: 0.04174455255270004
Local loss @ local epoch 2: 0.0043112654238939285
Local loss @ local epoch 3: 0.011422673240303993
Local loss @ local epoch 4: 0.3311624228954315
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.18 seconds!
[tester] 
AGNewsMetric: acc=0.7928947368421052, hinge=2.333032014244481, ce=9.564845328080027
Local test acc @ epoch 102: 0.7929
Global evaluate on test data...
Evaluate data in 130.95 seconds!
[tester] 
AGNewsMetric: acc=0.841842105263158, hinge=1.940527145486129, ce=9.92854631524337
Global test acc @ epoch 102: 0.8418
Global epoch 103...
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.000581315835006535
Local loss @ local epoch 1: 0.00012103695189580321
Local loss @ local epoch 2: 0.04168626666069031
Local loss @ local epoch 3: 0.002030785894021392
Local loss @ local epoch 4: 0.142140194773674
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.91 seconds!
[tester] 
AGNewsMetric: acc=0.7706578947368421, hinge=2.538198480355112, ce=9.535857407419305
Local test acc @ epoch 103: 0.7707
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00013552310701925308
Local loss @ local epoch 1: 0.0009674724424257874
Local loss @ local epoch 2: 0.0018821554258465767
Local loss @ local epoch 3: 0.0008194994879886508
Local loss @ local epoch 4: 0.016919691115617752
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.73 seconds!
[tester] 
AGNewsMetric: acc=0.8503947368421053, hinge=1.7522197689508137, ce=9.394991406892474
Local test acc @ epoch 103: 0.8504
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0006356676458381116
Local loss @ local epoch 1: 0.0011615059338510036
Local loss @ local epoch 2: 0.3205622136592865
Local loss @ local epoch 3: 0.0030163435731083155
Local loss @ local epoch 4: 0.0028959407936781645
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.19 seconds!
[tester] 
AGNewsMetric: acc=0.8189473684210526, hinge=1.9198673421458194, ce=10.233306324607447
Local test acc @ epoch 103: 0.8189
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0010617459192872047
Local loss @ local epoch 1: 0.021184425801038742
Local loss @ local epoch 2: 0.5890558362007141
Local loss @ local epoch 3: 0.0008826669072732329
Local loss @ local epoch 4: 0.003851574845612049
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.51 seconds!
[tester] 
AGNewsMetric: acc=0.8375, hinge=1.7619269817753842, ce=9.953085381357294
Local test acc @ epoch 103: 0.8375
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0005830454756505787
Local loss @ local epoch 1: 0.00017183284217026085
Local loss @ local epoch 2: 0.0030785687267780304
Local loss @ local epoch 3: 0.002208021702244878
Local loss @ local epoch 4: 0.04011586308479309
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.78 seconds!
[tester] 
AGNewsMetric: acc=0.8536842105263158, hinge=1.7016819991563497, ce=9.46465513731304
Local test acc @ epoch 103: 0.8537
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0047188070602715015
Local loss @ local epoch 1: 0.009402327239513397
Local loss @ local epoch 2: 0.33173468708992004
Local loss @ local epoch 3: 0.23674127459526062
Local loss @ local epoch 4: 0.1405516266822815
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.04 seconds!
[tester] 
AGNewsMetric: acc=0.8023684210526316, hinge=2.078374642572905, ce=10.05825624164782
Local test acc @ epoch 103: 0.8024
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00541214132681489
Local loss @ local epoch 1: 0.14776627719402313
Local loss @ local epoch 2: 0.04458891227841377
Local loss @ local epoch 3: 0.28792741894721985
Local loss @ local epoch 4: 0.12355393916368484
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.09 seconds!
[tester] 
AGNewsMetric: acc=0.841842105263158, hinge=1.333680739151804, ce=9.541555974859941
Local test acc @ epoch 103: 0.8418
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00014013763575349003
Local loss @ local epoch 1: 0.03214481472969055
Local loss @ local epoch 2: 0.0012659089406952262
Local loss @ local epoch 3: 0.004736870527267456
Local loss @ local epoch 4: 0.4898221790790558
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.84 seconds!
[tester] 
AGNewsMetric: acc=0.8406578947368422, hinge=1.6079698013004504, ce=9.853220710754394
Local test acc @ epoch 103: 0.8407
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00030082606826908886
Local loss @ local epoch 1: 0.0002309662231709808
Local loss @ local epoch 2: 0.00020405356190167367
Local loss @ local epoch 3: 0.0002119561395375058
Local loss @ local epoch 4: 0.0006712671020068228
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.71 seconds!
[tester] 
AGNewsMetric: acc=0.8623684210526316, hinge=1.550685597469932, ce=10.291909346329538
Local test acc @ epoch 103: 0.8624
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.036033667623996735
Local loss @ local epoch 1: 0.0028705745935440063
Local loss @ local epoch 2: 0.07589985430240631
Local loss @ local epoch 3: 0.09637890011072159
Local loss @ local epoch 4: 0.006908105220645666
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.46 seconds!
[tester] 
AGNewsMetric: acc=0.8696052631578948, hinge=1.3990000812630905, ce=9.937200823332134
Local test acc @ epoch 103: 0.8696
Global evaluate on test data...
Evaluate data in 130.03 seconds!
[tester] 
AGNewsMetric: acc=0.8613157894736843, hinge=1.5770717698649357, ce=10.028851087469803
Global test acc @ epoch 103: 0.8613
Global epoch 104...
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.28228622674942017
Local loss @ local epoch 1: 0.04269946739077568
Local loss @ local epoch 2: 0.18318518996238708
Local loss @ local epoch 3: 0.03147374838590622
Local loss @ local epoch 4: 0.14827649295330048
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.3 seconds!
[tester] 
AGNewsMetric: acc=0.8161842105263157, hinge=1.7556086991962634, ce=9.707887256019994
Local test acc @ epoch 104: 0.8162
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0001673954539000988
Local loss @ local epoch 1: 0.0015691115986555815
Local loss @ local epoch 2: 0.0013914740411564708
Local loss @ local epoch 3: 0.16788022220134735
Local loss @ local epoch 4: 0.35667839646339417
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.96 seconds!
[tester] 
AGNewsMetric: acc=0.8143421052631579, hinge=1.5684180086537411, ce=7.260693211806448
Local test acc @ epoch 104: 0.8143
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.03382944315671921
Local loss @ local epoch 1: 0.0014909245073795319
Local loss @ local epoch 2: 0.002805394120514393
Local loss @ local epoch 3: 0.29264479875564575
Local loss @ local epoch 4: 0.028346126899123192
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.58 seconds!
[tester] 
AGNewsMetric: acc=0.8560526315789474, hinge=1.5843633486095228, ce=10.153735811333908
Local test acc @ epoch 104: 0.8561
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0008975291857495904
Local loss @ local epoch 1: 0.0010941727086901665
Local loss @ local epoch 2: 0.0004703566955868155
Local loss @ local epoch 3: 0.0006477950373664498
Local loss @ local epoch 4: 0.0023780721239745617
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.31 seconds!
[tester] 
AGNewsMetric: acc=0.7767105263157895, hinge=2.170879285962958, ce=8.542978365044846
Local test acc @ epoch 104: 0.7767
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.003630557097494602
Local loss @ local epoch 1: 0.0004514463653322309
Local loss @ local epoch 2: 0.02163412608206272
Local loss @ local epoch 3: 0.1921588033437729
Local loss @ local epoch 4: 0.44022107124328613
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.57 seconds!
[tester] 
AGNewsMetric: acc=0.8556578947368421, hinge=1.3274984706075568, ce=9.684729879278885
Local test acc @ epoch 104: 0.8557
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00013086326362099499
Local loss @ local epoch 1: 0.0005594789399765432
Local loss @ local epoch 2: 0.00020174038945697248
Local loss @ local epoch 3: 0.0034808358177542686
Local loss @ local epoch 4: 8.29373238957487e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.96 seconds!
[tester] 
AGNewsMetric: acc=0.8527631578947369, hinge=1.5782590770721436, ce=9.91765674791838
Local test acc @ epoch 104: 0.8528
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.01294589601457119
Local loss @ local epoch 1: 0.0007539239013567567
Local loss @ local epoch 2: 0.00015600139158777893
Local loss @ local epoch 3: 0.05889328569173813
Local loss @ local epoch 4: 0.00791596807539463
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.6 seconds!
[tester] 
AGNewsMetric: acc=0.8523684210526316, hinge=1.3181382756484181, ce=11.934815416837994
Local test acc @ epoch 104: 0.8524
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00017148599727079272
Local loss @ local epoch 1: 0.0003747062582988292
Local loss @ local epoch 2: 0.014264136552810669
Local loss @ local epoch 3: 6.290119199547917e-05
Local loss @ local epoch 4: 0.006266008596867323
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.37 seconds!
[tester] 
AGNewsMetric: acc=0.8451315789473685, hinge=1.80689160171308, ce=9.785361414457622
Local test acc @ epoch 104: 0.8451
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0010891287820413709
Local loss @ local epoch 1: 0.0002666141663212329
Local loss @ local epoch 2: 0.04126003384590149
Local loss @ local epoch 3: 0.008008906617760658
Local loss @ local epoch 4: 0.008048505522310734
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.48 seconds!
[tester] 
AGNewsMetric: acc=0.775921052631579, hinge=2.6700399155365795, ce=9.912741578754625
Local test acc @ epoch 104: 0.7759
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 7.82132992753759e-05
Local loss @ local epoch 1: 0.00037068070378154516
Local loss @ local epoch 2: 4.9238140491070226e-05
Local loss @ local epoch 3: 0.00035484725958667696
Local loss @ local epoch 4: 0.00023036518541630358
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.47 seconds!
[tester] 
AGNewsMetric: acc=0.854078947368421, hinge=1.49629200834977, ce=9.15113122237356
Local test acc @ epoch 104: 0.8541
Global evaluate on test data...
Evaluate data in 130.2 seconds!
[tester] 
AGNewsMetric: acc=0.859078947368421, hinge=1.6591248843544408, ce=9.90581241607666
Global test acc @ epoch 104: 0.8591
Global epoch 105...
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 6.032898454577662e-05
Local loss @ local epoch 1: 0.000540948414709419
Local loss @ local epoch 2: 0.0002278807805851102
Local loss @ local epoch 3: 7.53169588278979e-05
Local loss @ local epoch 4: 0.19359779357910156
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.3 seconds!
[tester] 
AGNewsMetric: acc=0.8603947368421052, hinge=1.6541227543981452, ce=9.858502566688939
Local test acc @ epoch 105: 0.8604
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0012059836881235242
Local loss @ local epoch 1: 0.0006151533452793956
Local loss @ local epoch 2: 0.004313420969992876
Local loss @ local epoch 3: 0.0029094722121953964
Local loss @ local epoch 4: 0.3624137341976166
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.16 seconds!
[tester] 
AGNewsMetric: acc=0.8321052631578948, hinge=1.2256231041958459, ce=4.278123678910105
Local test acc @ epoch 105: 0.8321
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0002876439248211682
Local loss @ local epoch 1: 0.0006947627989575267
Local loss @ local epoch 2: 0.12271278351545334
Local loss @ local epoch 3: 0.0006004142924211919
Local loss @ local epoch 4: 0.005846504587680101
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.77 seconds!
[tester] 
AGNewsMetric: acc=0.7882894736842105, hinge=2.5763746211403293, ce=9.828497890673185
Local test acc @ epoch 105: 0.7883
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00019819170120172203
Local loss @ local epoch 1: 0.1490100920200348
Local loss @ local epoch 2: 0.0006996773881837726
Local loss @ local epoch 3: 0.032617323100566864
Local loss @ local epoch 4: 0.09200379252433777
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.8 seconds!
[tester] 
AGNewsMetric: acc=0.8517105263157895, hinge=1.8520244457847195, ce=9.83689889004356
Local test acc @ epoch 105: 0.8517
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.01592845283448696
Local loss @ local epoch 1: 0.010302376002073288
Local loss @ local epoch 2: 0.03768426179885864
Local loss @ local epoch 3: 0.9671892523765564
Local loss @ local epoch 4: 0.07701381295919418
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.66 seconds!
[tester] 
AGNewsMetric: acc=0.8446052631578947, hinge=1.9762662513632523, ce=10.459674610338713
Local test acc @ epoch 105: 0.8446
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 5.154728933121078e-05
Local loss @ local epoch 1: 0.0008527023019269109
Local loss @ local epoch 2: 0.0013795160921290517
Local loss @ local epoch 3: 7.472470315406099e-05
Local loss @ local epoch 4: 0.000409326225053519
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.96 seconds!
[tester] 
AGNewsMetric: acc=0.8396052631578947, hinge=1.6847224908126028, ce=10.282366979498612
Local test acc @ epoch 105: 0.8396
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 1.7113452486228198e-05
Local loss @ local epoch 1: 0.00036310619907453656
Local loss @ local epoch 2: 0.00317972619086504
Local loss @ local epoch 3: 0.0032555386424064636
Local loss @ local epoch 4: 0.0024983342736959457
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.35 seconds!
[tester] 
AGNewsMetric: acc=0.8407894736842105, hinge=2.090527599108847, ce=10.870353136564557
Local test acc @ epoch 105: 0.8408
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.006717615760862827
Local loss @ local epoch 1: 0.0329999215900898
Local loss @ local epoch 2: 0.006905949674546719
Local loss @ local epoch 3: 0.0025244452990591526
Local loss @ local epoch 4: 0.22872263193130493
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.28 seconds!
[tester] 
AGNewsMetric: acc=0.7917105263157894, hinge=2.0391754004829807, ce=9.829623539573268
Local test acc @ epoch 105: 0.7917
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0037923897616565228
Local loss @ local epoch 1: 0.0007206218433566391
Local loss @ local epoch 2: 0.17621731758117676
Local loss @ local epoch 3: 0.0027431845664978027
Local loss @ local epoch 4: 0.0045955791138112545
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.29 seconds!
[tester] 
AGNewsMetric: acc=0.8327631578947369, hinge=1.8292826250979775, ce=10.2690771484375
Local test acc @ epoch 105: 0.8328
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.005964986048638821
Local loss @ local epoch 1: 0.002145437290892005
Local loss @ local epoch 2: 0.02361290529370308
Local loss @ local epoch 3: 0.004202855285257101
Local loss @ local epoch 4: 0.006922549102455378
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.43 seconds!
[tester] 
AGNewsMetric: acc=0.8363157894736842, hinge=1.8908361359646446, ce=10.801761613143118
Local test acc @ epoch 105: 0.8363
Global evaluate on test data...
Evaluate data in 130.77 seconds!
[tester] 
AGNewsMetric: acc=0.8622368421052632, hinge=1.7806244729694567, ce=10.091035692315353
Global test acc @ epoch 105: 0.8622
Global epoch 106...
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0018686895491555333
Local loss @ local epoch 1: 0.27275893092155457
Local loss @ local epoch 2: 0.014540049247443676
Local loss @ local epoch 3: 0.1951102763414383
Local loss @ local epoch 4: 0.016285397112369537
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.44 seconds!
[tester] 
AGNewsMetric: acc=0.8511842105263158, hinge=1.3905198330628243, ce=10.53852960887708
Local test acc @ epoch 106: 0.8512
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 5.495263758348301e-05
Local loss @ local epoch 1: 0.0011759675107896328
Local loss @ local epoch 2: 0.0002894674544222653
Local loss @ local epoch 3: 9.840822167461738e-05
Local loss @ local epoch 4: 0.0018927932251244783
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.56 seconds!
[tester] 
AGNewsMetric: acc=0.8461842105263158, hinge=1.7270312494980662, ce=10.134716126291375
Local test acc @ epoch 106: 0.8462
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.007952181622385979
Local loss @ local epoch 1: 0.0018042614683508873
Local loss @ local epoch 2: 0.006665065418928862
Local loss @ local epoch 3: 0.1141262948513031
Local loss @ local epoch 4: 0.0020623840391635895
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.22 seconds!
[tester] 
AGNewsMetric: acc=0.7889473684210526, hinge=3.0452137630864193, ce=11.257853933635511
Local test acc @ epoch 106: 0.7889
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00010887892130995169
Local loss @ local epoch 1: 0.00046848508645780385
Local loss @ local epoch 2: 0.00026703462935984135
Local loss @ local epoch 3: 0.00022044967045076191
Local loss @ local epoch 4: 0.0012884136522188783
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.4 seconds!
[tester] 
AGNewsMetric: acc=0.8689473684210526, hinge=1.388074080316644, ce=9.61005672454834
Local test acc @ epoch 106: 0.8689
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.000421525735873729
Local loss @ local epoch 1: 0.1744510382413864
Local loss @ local epoch 2: 0.0010795851703733206
Local loss @ local epoch 3: 0.00434713764116168
Local loss @ local epoch 4: 0.001096439315006137
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.31 seconds!
[tester] 
AGNewsMetric: acc=0.7456578947368421, hinge=2.9953781409012645, ce=9.360507157978258
Local test acc @ epoch 106: 0.7457
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.056373003870248795
Local loss @ local epoch 1: 0.17234106361865997
Local loss @ local epoch 2: 0.0018779869424179196
Local loss @ local epoch 3: 0.1438755989074707
Local loss @ local epoch 4: 0.09921998530626297
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.04 seconds!
[tester] 
AGNewsMetric: acc=0.8027631578947368, hinge=2.0674968400754428, ce=10.04917109238474
Local test acc @ epoch 106: 0.8028
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.012853892520070076
Local loss @ local epoch 1: 0.0010357341961935163
Local loss @ local epoch 2: 0.30554166436195374
Local loss @ local epoch 3: 0.0038104169070720673
Local loss @ local epoch 4: 0.0036943089216947556
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.47 seconds!
[tester] 
AGNewsMetric: acc=0.8085526315789474, hinge=2.3794751508612384, ce=10.9837618356002
Local test acc @ epoch 106: 0.8086
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.001634477637708187
Local loss @ local epoch 1: 0.0014788026455789804
Local loss @ local epoch 2: 0.0766720101237297
Local loss @ local epoch 3: 0.009930513799190521
Local loss @ local epoch 4: 0.2769158184528351
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.44 seconds!
[tester] 
AGNewsMetric: acc=0.8621052631578947, hinge=1.3785301469501696, ce=9.666293776662727
Local test acc @ epoch 106: 0.8621
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 4.288252966944128e-05
Local loss @ local epoch 1: 0.0002685585932340473
Local loss @ local epoch 2: 0.0007375685963779688
Local loss @ local epoch 3: 0.010040784254670143
Local loss @ local epoch 4: 0.00017107176245190203
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.58 seconds!
[tester] 
AGNewsMetric: acc=0.8286842105263158, hinge=2.2853310529809248, ce=10.562016772220009
Local test acc @ epoch 106: 0.8287
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00012001237337244675
Local loss @ local epoch 1: 0.00020655216940212995
Local loss @ local epoch 2: 0.0008779289782978594
Local loss @ local epoch 3: 0.014252954162657261
Local loss @ local epoch 4: 0.0001656118838582188
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 131.04 seconds!
[tester] 
AGNewsMetric: acc=0.8569736842105263, hinge=1.6019191528621473, ce=10.071697724994861
Local test acc @ epoch 106: 0.857
Global evaluate on test data...
Evaluate data in 130.6 seconds!
[tester] 
AGNewsMetric: acc=0.8581578947368421, hinge=1.787847789212277, ce=9.769173907229774
Global test acc @ epoch 106: 0.8582
Global epoch 107...
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00024359714007005095
Local loss @ local epoch 1: 0.00012441400031093508
Local loss @ local epoch 2: 0.09171154350042343
Local loss @ local epoch 3: 0.04039013013243675
Local loss @ local epoch 4: 0.0012871214421465993
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.11 seconds!
[tester] 
AGNewsMetric: acc=0.8372368421052632, hinge=2.019295779027437, ce=10.547317091289319
Local test acc @ epoch 107: 0.8372
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00013207759184297174
Local loss @ local epoch 1: 0.0008813171298243105
Local loss @ local epoch 2: 0.0007566501735709608
Local loss @ local epoch 3: 0.0001016240639728494
Local loss @ local epoch 4: 0.000220488800550811
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.47 seconds!
[tester] 
AGNewsMetric: acc=0.8139473684210526, hinge=2.1856657364493923, ce=10.30479352047569
Local test acc @ epoch 107: 0.8139
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0007668977486900985
Local loss @ local epoch 1: 0.00037611002335324883
Local loss @ local epoch 2: 0.0010021424386650324
Local loss @ local epoch 3: 0.0009675707551650703
Local loss @ local epoch 4: 0.1444905400276184
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.92 seconds!
[tester] 
AGNewsMetric: acc=0.8027631578947368, hinge=2.669436039422688, ce=11.165249643827739
Local test acc @ epoch 107: 0.8028
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0004940452636219561
Local loss @ local epoch 1: 0.0006275589694269001
Local loss @ local epoch 2: 0.019302809610962868
Local loss @ local epoch 3: 0.0009656232432462275
Local loss @ local epoch 4: 0.03783425688743591
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.2 seconds!
[tester] 
AGNewsMetric: acc=0.8635526315789473, hinge=1.5485134516264263, ce=10.6940503411544
Local test acc @ epoch 107: 0.8636
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.46307042241096497
Local loss @ local epoch 1: 0.18079817295074463
Local loss @ local epoch 2: 1.0531436204910278
Local loss @ local epoch 3: 0.20476064085960388
Local loss @ local epoch 4: 0.0983167216181755
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.37 seconds!
[tester] 
AGNewsMetric: acc=0.7844736842105263, hinge=1.7301565564306158, ce=7.49089836321379
Local test acc @ epoch 107: 0.7845
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.002291925484314561
Local loss @ local epoch 1: 0.34047892689704895
Local loss @ local epoch 2: 0.14363239705562592
Local loss @ local epoch 3: 0.021444182842969894
Local loss @ local epoch 4: 0.034365102648735046
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.81 seconds!
[tester] 
AGNewsMetric: acc=0.766578947368421, hinge=2.6956379220360205, ce=11.07171643508108
Local test acc @ epoch 107: 0.7666
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 8.954753866419196e-05
Local loss @ local epoch 1: 0.0011180223664268851
Local loss @ local epoch 2: 0.00015801939298398793
Local loss @ local epoch 3: 0.00024744245456531644
Local loss @ local epoch 4: 0.011660929769277573
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.28 seconds!
[tester] 
AGNewsMetric: acc=0.8331578947368421, hinge=1.9319702311566, ce=10.811528729890522
Local test acc @ epoch 107: 0.8332
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 9.93389476207085e-05
Local loss @ local epoch 1: 0.04146740958094597
Local loss @ local epoch 2: 0.0013802779139950871
Local loss @ local epoch 3: 0.0053166961297392845
Local loss @ local epoch 4: 0.013356437906622887
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.73 seconds!
[tester] 
AGNewsMetric: acc=0.8101315789473684, hinge=2.0075013072867143, ce=9.935322496514571
Local test acc @ epoch 107: 0.8101
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 5.410040830611251e-05
Local loss @ local epoch 1: 0.00015034254465717822
Local loss @ local epoch 2: 0.0020121480338275433
Local loss @ local epoch 3: 0.0037972875870764256
Local loss @ local epoch 4: 6.762151315342635e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.46 seconds!
[tester] 
AGNewsMetric: acc=0.8535526315789473, hinge=1.679310164451599, ce=9.686372752942537
Local test acc @ epoch 107: 0.8536
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.2089824378490448
Local loss @ local epoch 1: 0.04028967395424843
Local loss @ local epoch 2: 0.08393054455518723
Local loss @ local epoch 3: 0.0038354170974344015
Local loss @ local epoch 4: 0.03734441101551056
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.82 seconds!
[tester] 
AGNewsMetric: acc=0.7330263157894736, hinge=3.1502685260772707, ce=11.112026124251516
Local test acc @ epoch 107: 0.733
Global evaluate on test data...
Evaluate data in 130.09 seconds!
[tester] 
AGNewsMetric: acc=0.8602631578947368, hinge=1.7755640579524794, ce=9.517441378141704
Global test acc @ epoch 107: 0.8603
Global epoch 108...
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00025057297898456454
Local loss @ local epoch 1: 0.0008680997416377068
Local loss @ local epoch 2: 0.000952573143877089
Local loss @ local epoch 3: 0.0005866714054718614
Local loss @ local epoch 4: 8.023951522773132e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.9 seconds!
[tester] 
AGNewsMetric: acc=0.8392105263157895, hinge=1.9156606839832506, ce=10.018454893011796
Local test acc @ epoch 108: 0.8392
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.011526394635438919
Local loss @ local epoch 1: 0.004275597631931305
Local loss @ local epoch 2: 0.0004990803427062929
Local loss @ local epoch 3: 0.01659061759710312
Local loss @ local epoch 4: 0.0212335716933012
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.93 seconds!
[tester] 
AGNewsMetric: acc=0.8548684210526316, hinge=1.414040765762329, ce=9.668641465839587
Local test acc @ epoch 108: 0.8549
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 8.549104677513242e-05
Local loss @ local epoch 1: 0.0012567387893795967
Local loss @ local epoch 2: 0.003331088228151202
Local loss @ local epoch 3: 0.0005841391393914819
Local loss @ local epoch 4: 0.00033852641354314983
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.81 seconds!
[tester] 
AGNewsMetric: acc=0.8084210526315789, hinge=2.33870047644565, ce=10.436791309557464
Local test acc @ epoch 108: 0.8084
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 3.3644111681496724e-05
Local loss @ local epoch 1: 8.336332393810153e-05
Local loss @ local epoch 2: 0.002185484394431114
Local loss @ local epoch 3: 0.0002431415196042508
Local loss @ local epoch 4: 0.0005026172730140388
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.33 seconds!
[tester] 
AGNewsMetric: acc=0.8026315789473685, hinge=2.2632038588272896, ce=9.051544872083163
Local test acc @ epoch 108: 0.8026
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0004860756453126669
Local loss @ local epoch 1: 0.0006568630342371762
Local loss @ local epoch 2: 0.014597867615520954
Local loss @ local epoch 3: 0.012490814551711082
Local loss @ local epoch 4: 0.0069195362739264965
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.83 seconds!
[tester] 
AGNewsMetric: acc=0.8568421052631578, hinge=1.3724315668407239, ce=9.780621269627622
Local test acc @ epoch 108: 0.8568
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0004895590245723724
Local loss @ local epoch 1: 0.00035203792504034936
Local loss @ local epoch 2: 0.10375329852104187
Local loss @ local epoch 3: 0.0021321990061551332
Local loss @ local epoch 4: 0.07348503172397614
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.26 seconds!
[tester] 
AGNewsMetric: acc=0.8321052631578948, hinge=1.55553609396282, ce=10.71749817898399
Local test acc @ epoch 108: 0.8321
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00022597012866754085
Local loss @ local epoch 1: 9.198295447276905e-05
Local loss @ local epoch 2: 0.00046277078217826784
Local loss @ local epoch 3: 0.007374316453933716
Local loss @ local epoch 4: 0.009768557734787464
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.49 seconds!
[tester] 
AGNewsMetric: acc=0.8355263157894737, hinge=2.0290472517515483, ce=10.121808373300652
Local test acc @ epoch 108: 0.8355
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00021850873599760234
Local loss @ local epoch 1: 0.0005967292236164212
Local loss @ local epoch 2: 0.00039411120815202594
Local loss @ local epoch 3: 0.25181758403778076
Local loss @ local epoch 4: 0.007780747022479773
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.21 seconds!
[tester] 
AGNewsMetric: acc=0.85, hinge=1.6447324622304815, ce=9.572991865057695
Local test acc @ epoch 108: 0.85
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0008915744838304818
Local loss @ local epoch 1: 0.008942097425460815
Local loss @ local epoch 2: 0.0004373385454528034
Local loss @ local epoch 3: 0.06524486094713211
Local loss @ local epoch 4: 0.02194969356060028
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.35 seconds!
[tester] 
AGNewsMetric: acc=0.8130263157894737, hinge=2.3439892025997766, ce=10.556810886985378
Local test acc @ epoch 108: 0.813
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00985580962151289
Local loss @ local epoch 1: 0.0014054436469450593
Local loss @ local epoch 2: 0.5475377440452576
Local loss @ local epoch 3: 0.0010480184573680162
Local loss @ local epoch 4: 0.004294313490390778
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.77 seconds!
[tester] 
AGNewsMetric: acc=0.7422368421052632, hinge=3.228968252884714, ce=11.518425116288034
Local test acc @ epoch 108: 0.7422
Global evaluate on test data...
Evaluate data in 130.31 seconds!
[tester] 
AGNewsMetric: acc=0.8553947368421052, hinge=1.778942659277665, ce=9.448620400679738
Global test acc @ epoch 108: 0.8554
Global epoch 109...
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00019157126371283084
Local loss @ local epoch 1: 0.1129121407866478
Local loss @ local epoch 2: 0.008870622143149376
Local loss @ local epoch 3: 0.021673688665032387
Local loss @ local epoch 4: 0.20834863185882568
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.97 seconds!
[tester] 
AGNewsMetric: acc=0.765, hinge=2.3095359498576116, ce=9.520383569817794
Local test acc @ epoch 109: 0.765
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 9.417807450518012e-05
Local loss @ local epoch 1: 2.0414085156517103e-05
Local loss @ local epoch 2: 0.001352684455923736
Local loss @ local epoch 3: 0.0013009003596380353
Local loss @ local epoch 4: 0.00028833065880462527
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.27 seconds!
[tester] 
AGNewsMetric: acc=0.8255263157894737, hinge=2.2901578017284994, ce=10.157597192463122
Local test acc @ epoch 109: 0.8255
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0001959199144039303
Local loss @ local epoch 1: 0.008445017971098423
Local loss @ local epoch 2: 0.01009676605463028
Local loss @ local epoch 3: 0.002029580995440483
Local loss @ local epoch 4: 0.010484403930604458
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.5 seconds!
[tester] 
AGNewsMetric: acc=0.7431578947368421, hinge=3.5000195902272275, ce=10.093974567212557
Local test acc @ epoch 109: 0.7432
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 9.795080404728651e-05
Local loss @ local epoch 1: 0.000897842925041914
Local loss @ local epoch 2: 0.0005910567124374211
Local loss @ local epoch 3: 0.00532950647175312
Local loss @ local epoch 4: 0.00025001715403050184
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.82 seconds!
[tester] 
AGNewsMetric: acc=0.8385526315789473, hinge=1.9196797446200722, ce=9.760531985634252
Local test acc @ epoch 109: 0.8386
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0002862247347366065
Local loss @ local epoch 1: 0.0005484223365783691
Local loss @ local epoch 2: 0.0015726935816928744
Local loss @ local epoch 3: 0.0007515045581385493
Local loss @ local epoch 4: 0.05182243138551712
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.13 seconds!
[tester] 
AGNewsMetric: acc=0.8472368421052632, hinge=1.8167237761146144, ce=9.580878663314015
Local test acc @ epoch 109: 0.8472
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.01626773737370968
Local loss @ local epoch 1: 0.00022106921824160963
Local loss @ local epoch 2: 0.05205044522881508
Local loss @ local epoch 3: 0.005119407083839178
Local loss @ local epoch 4: 0.25624004006385803
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.88 seconds!
[tester] 
AGNewsMetric: acc=0.7688157894736842, hinge=3.4738516518944187, ce=10.150721658405505
Local test acc @ epoch 109: 0.7688
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 3.599020419642329e-05
Local loss @ local epoch 1: 0.00012718309881165624
Local loss @ local epoch 2: 9.067617793334648e-05
Local loss @ local epoch 3: 1.4059014574741013e-05
Local loss @ local epoch 4: 0.0003008860512636602
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.9 seconds!
[tester] 
AGNewsMetric: acc=0.8426315789473684, hinge=1.8963353661486977, ce=9.951195411682129
Local test acc @ epoch 109: 0.8426
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00010145384294446558
Local loss @ local epoch 1: 0.00010613143240334466
Local loss @ local epoch 2: 0.0002230495010735467
Local loss @ local epoch 3: 0.0002513545914553106
Local loss @ local epoch 4: 0.00016959379718173295
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.12 seconds!
[tester] 
AGNewsMetric: acc=0.8198684210526316, hinge=2.558684472786753, ce=9.675295319808157
Local test acc @ epoch 109: 0.8199
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.027863455936312675
Local loss @ local epoch 1: 0.13669978082180023
Local loss @ local epoch 2: 0.004623966291546822
Local loss @ local epoch 3: 0.4279070496559143
Local loss @ local epoch 4: 0.013728827238082886
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.86 seconds!
[tester] 
AGNewsMetric: acc=0.8184210526315789, hinge=1.9899715892892136, ce=9.43736828251889
Local test acc @ epoch 109: 0.8184
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0003410796634852886
Local loss @ local epoch 1: 0.0011715872678905725
Local loss @ local epoch 2: 0.0020742546766996384
Local loss @ local epoch 3: 0.03152058646082878
Local loss @ local epoch 4: 0.0017468875739723444
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.3 seconds!
[tester] 
AGNewsMetric: acc=0.873421052631579, hinge=1.3534551542683653, ce=10.27972768080862
Local test acc @ epoch 109: 0.8734
Global evaluate on test data...
Evaluate data in 130.16 seconds!
[tester] 
AGNewsMetric: acc=0.8593421052631579, hinge=1.8689067491732145, ce=9.322647060595061
Global test acc @ epoch 109: 0.8593
Global epoch 110...
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 4.647982132155448e-05
Local loss @ local epoch 1: 0.00045646741637028754
Local loss @ local epoch 2: 1.8588774764793925e-05
Local loss @ local epoch 3: 0.000169002145412378
Local loss @ local epoch 4: 0.0013516801409423351
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.4 seconds!
[tester] 
AGNewsMetric: acc=0.8425, hinge=1.8998557246358772, ce=8.832773628234863
Local test acc @ epoch 110: 0.8425
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 6.139349716249853e-05
Local loss @ local epoch 1: 0.004561909940093756
Local loss @ local epoch 2: 0.0001335176930297166
Local loss @ local epoch 3: 1.1329911947250366
Local loss @ local epoch 4: 0.01936587132513523
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.01 seconds!
[tester] 
AGNewsMetric: acc=0.8278947368421052, hinge=1.9868177102741442, ce=10.085450019836426
Local test acc @ epoch 110: 0.8279
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.05143871158361435
Local loss @ local epoch 1: 0.0043120961636304855
Local loss @ local epoch 2: 0.011081011965870857
Local loss @ local epoch 3: 0.11430172622203827
Local loss @ local epoch 4: 0.010174215771257877
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.74 seconds!
[tester] 
AGNewsMetric: acc=0.8227631578947369, hinge=1.4482186392733924, ce=9.166878527591104
Local test acc @ epoch 110: 0.8228
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 8.584138413425535e-05
Local loss @ local epoch 1: 0.00012443828745745122
Local loss @ local epoch 2: 0.0017346760723739862
Local loss @ local epoch 3: 0.0008733907015994191
Local loss @ local epoch 4: 0.0020602336153388023
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.81 seconds!
[tester] 
AGNewsMetric: acc=0.8405263157894737, hinge=1.798227152573435, ce=10.28547258879009
Local test acc @ epoch 110: 0.8405
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0002109658671543002
Local loss @ local epoch 1: 0.23134037852287292
Local loss @ local epoch 2: 6.131916597951204e-05
Local loss @ local epoch 3: 0.0005514367367140949
Local loss @ local epoch 4: 0.25386565923690796
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.3 seconds!
[tester] 
AGNewsMetric: acc=0.8265789473684211, hinge=2.2575341889732763, ce=10.327418377524928
Local test acc @ epoch 110: 0.8266
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0024781660176813602
Local loss @ local epoch 1: 0.008495144546031952
Local loss @ local epoch 2: 0.4273209869861603
Local loss @ local epoch 3: 0.0017122443532571197
Local loss @ local epoch 4: 0.008279272355139256
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.24 seconds!
[tester] 
AGNewsMetric: acc=0.8151315789473684, hinge=1.9511919920068037, ce=10.046368193375438
Local test acc @ epoch 110: 0.8151
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00924140028655529
Local loss @ local epoch 1: 0.0035965247079730034
Local loss @ local epoch 2: 0.31400007009506226
Local loss @ local epoch 3: 0.003707029391080141
Local loss @ local epoch 4: 0.003422096371650696
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.21 seconds!
[tester] 
AGNewsMetric: acc=0.8338157894736842, hinge=1.636096309109738, ce=10.373387989244963
Local test acc @ epoch 110: 0.8338
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 5.279026663629338e-05
Local loss @ local epoch 1: 3.3843378332676366e-05
Local loss @ local epoch 2: 0.00014973687939345837
Local loss @ local epoch 3: 9.067400242201984e-05
Local loss @ local epoch 4: 0.00034415494883432984
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.03 seconds!
[tester] 
AGNewsMetric: acc=0.8369736842105263, hinge=2.151956670660722, ce=9.54659508554559
Local test acc @ epoch 110: 0.837
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0002063497668132186
Local loss @ local epoch 1: 0.001825764193199575
Local loss @ local epoch 2: 0.0005327656399458647
Local loss @ local epoch 3: 0.0024840598925948143
Local loss @ local epoch 4: 0.003442279063165188
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 131.43 seconds!
[tester] 
AGNewsMetric: acc=0.8251315789473684, hinge=2.2212324837634436, ce=9.384542125902678
Local test acc @ epoch 110: 0.8251
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0001687000913079828
Local loss @ local epoch 1: 0.0004112067981623113
Local loss @ local epoch 2: 0.0003426296461839229
Local loss @ local epoch 3: 0.03695112094283104
Local loss @ local epoch 4: 0.00040351631469093263
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.07 seconds!
[tester] 
AGNewsMetric: acc=0.7452631578947368, hinge=2.8787648444426686, ce=10.627755141007272
Local test acc @ epoch 110: 0.7453
Global evaluate on test data...
Evaluate data in 129.56 seconds!
[tester] 
AGNewsMetric: acc=0.8527631578947369, hinge=1.9618557423039487, ce=9.158810328433388
Global test acc @ epoch 110: 0.8528
Global epoch 111...
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 2.7102811145596206e-05
Local loss @ local epoch 1: 0.00025810705847106874
Local loss @ local epoch 2: 0.000399511685827747
Local loss @ local epoch 3: 0.00012778560630977154
Local loss @ local epoch 4: 0.00023148595937527716
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.54 seconds!
[tester] 
AGNewsMetric: acc=0.8523684210526316, hinge=1.7567368795997218, ce=9.976879382886384
Local test acc @ epoch 111: 0.8524
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.06194450706243515
Local loss @ local epoch 1: 0.001272164867259562
Local loss @ local epoch 2: 0.00237473682500422
Local loss @ local epoch 3: 0.009954470209777355
Local loss @ local epoch 4: 0.11410176008939743
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.61 seconds!
[tester] 
AGNewsMetric: acc=0.8153947368421053, hinge=2.130760837103191, ce=10.031207711069207
Local test acc @ epoch 111: 0.8154
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.004695984069257975
Local loss @ local epoch 1: 0.08122555166482925
Local loss @ local epoch 2: 0.0002563843154348433
Local loss @ local epoch 3: 0.0005532533396035433
Local loss @ local epoch 4: 0.04920559376478195
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.23 seconds!
[tester] 
AGNewsMetric: acc=0.8323684210526315, hinge=2.0300470472636976, ce=10.523238412957442
Local test acc @ epoch 111: 0.8324
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00031745483283884823
Local loss @ local epoch 1: 0.016347501426935196
Local loss @ local epoch 2: 0.0006585657247342169
Local loss @ local epoch 3: 0.06124400347471237
Local loss @ local epoch 4: 0.02156144008040428
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.46 seconds!
[tester] 
AGNewsMetric: acc=0.8347368421052631, hinge=2.077691421759756, ce=9.887838610598916
Local test acc @ epoch 111: 0.8347
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 3.51758353644982e-05
Local loss @ local epoch 1: 2.724515798036009e-05
Local loss @ local epoch 2: 0.0022774916142225266
Local loss @ local epoch 3: 0.0002219004963990301
Local loss @ local epoch 4: 0.00027825342840515077
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.26 seconds!
[tester] 
AGNewsMetric: acc=0.8355263157894737, hinge=2.0881374848516363, ce=9.31105363946212
Local test acc @ epoch 111: 0.8355
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 3.5468623536871746e-05
Local loss @ local epoch 1: 9.48187371250242e-05
Local loss @ local epoch 2: 0.0003892132663168013
Local loss @ local epoch 3: 0.0006169541156850755
Local loss @ local epoch 4: 0.0004400597244966775
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.96 seconds!
[tester] 
AGNewsMetric: acc=0.8310526315789474, hinge=2.043820279271979, ce=10.075219883165861
Local test acc @ epoch 111: 0.8311
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.09516111016273499
Local loss @ local epoch 1: 0.00042282347567379475
Local loss @ local epoch 2: 0.008901560679078102
Local loss @ local epoch 3: 0.0038513783365488052
Local loss @ local epoch 4: 0.003287836443632841
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.46 seconds!
[tester] 
AGNewsMetric: acc=0.8314473684210526, hinge=1.6450043904153924, ce=11.109379822580438
Local test acc @ epoch 111: 0.8314
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0195789597928524
Local loss @ local epoch 1: 0.5339618921279907
Local loss @ local epoch 2: 0.21015706658363342
Local loss @ local epoch 3: 0.0005865934654138982
Local loss @ local epoch 4: 0.0006383776199072599
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 131.66 seconds!
[tester] 
AGNewsMetric: acc=0.7585526315789474, hinge=2.6442954803767957, ce=9.213178474024723
Local test acc @ epoch 111: 0.7586
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00012579289614222944
Local loss @ local epoch 1: 0.010719606652855873
Local loss @ local epoch 2: 0.0006228736601769924
Local loss @ local epoch 3: 0.0705747902393341
Local loss @ local epoch 4: 0.011841407045722008
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.86 seconds!
[tester] 
AGNewsMetric: acc=0.8546052631578948, hinge=1.5376459540818868, ce=9.629568260594418
Local test acc @ epoch 111: 0.8546
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0013508825795724988
Local loss @ local epoch 1: 0.004858330823481083
Local loss @ local epoch 2: 0.00013773827231489122
Local loss @ local epoch 3: 0.000541249115485698
Local loss @ local epoch 4: 0.05219445377588272
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.86 seconds!
[tester] 
AGNewsMetric: acc=0.8410526315789474, hinge=1.766161376300611, ce=10.183611922013132
Local test acc @ epoch 111: 0.8411
Global evaluate on test data...
Evaluate data in 130.36 seconds!
[tester] 
AGNewsMetric: acc=0.865, hinge=1.7870551448119314, ce=9.478349595320852
Global test acc @ epoch 111: 0.865
Global epoch 112...
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.03286613151431084
Local loss @ local epoch 1: 0.015553253702819347
Local loss @ local epoch 2: 0.5177018642425537
Local loss @ local epoch 3: 0.003367243567481637
Local loss @ local epoch 4: 0.12699443101882935
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.53 seconds!
[tester] 
AGNewsMetric: acc=0.7881578947368421, hinge=2.396324601424368, ce=11.140158321982936
Local test acc @ epoch 112: 0.7882
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.05328569933772087
Local loss @ local epoch 1: 0.006464019417762756
Local loss @ local epoch 2: 0.019275575876235962
Local loss @ local epoch 3: 0.45660507678985596
Local loss @ local epoch 4: 0.16259953379631042
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.97 seconds!
[tester] 
AGNewsMetric: acc=0.6806578947368421, hinge=3.7411208790226986, ce=10.670867689032304
Local test acc @ epoch 112: 0.6807
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00014127034228295088
Local loss @ local epoch 1: 1.8715119949774817e-05
Local loss @ local epoch 2: 0.0008774069137871265
Local loss @ local epoch 3: 0.0019200773676857352
Local loss @ local epoch 4: 0.05042475834488869
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.56 seconds!
[tester] 
AGNewsMetric: acc=0.8496052631578948, hinge=1.5941541734494662, ce=9.40965336448268
Local test acc @ epoch 112: 0.8496
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.007263612002134323
Local loss @ local epoch 1: 0.008383788168430328
Local loss @ local epoch 2: 0.002257291227579117
Local loss @ local epoch 3: 0.35973480343818665
Local loss @ local epoch 4: 0.7590785026550293
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.12 seconds!
[tester] 
AGNewsMetric: acc=0.6507894736842105, hinge=3.9406845740268106, ce=11.730904386419999
Local test acc @ epoch 112: 0.6508
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 1.8551269022282213e-05
Local loss @ local epoch 1: 1.886401696538087e-05
Local loss @ local epoch 2: 8.021064422791824e-05
Local loss @ local epoch 3: 3.589360858313739e-05
Local loss @ local epoch 4: 5.232420880929567e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.71 seconds!
[tester] 
AGNewsMetric: acc=0.8357894736842105, hinge=2.086139749225817, ce=9.977835821854441
Local test acc @ epoch 112: 0.8358
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.01691034436225891
Local loss @ local epoch 1: 0.0008750130655243993
Local loss @ local epoch 2: 0.8706585168838501
Local loss @ local epoch 3: 0.0039841909892857075
Local loss @ local epoch 4: 0.007204137276858091
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.42 seconds!
[tester] 
AGNewsMetric: acc=0.8453947368421053, hinge=1.6905020422684518, ce=10.435732980025442
Local test acc @ epoch 112: 0.8454
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0001665008021518588
Local loss @ local epoch 1: 0.0002884472196456045
Local loss @ local epoch 2: 0.0010093452874571085
Local loss @ local epoch 3: 8.746547973714769e-05
Local loss @ local epoch 4: 0.0021415958181023598
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.95 seconds!
[tester] 
AGNewsMetric: acc=0.7269736842105263, hinge=3.9951749794106735, ce=10.518136626795718
Local test acc @ epoch 112: 0.727
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0004618107923306525
Local loss @ local epoch 1: 0.00014211362577043474
Local loss @ local epoch 2: 0.16231444478034973
Local loss @ local epoch 3: 0.003224644809961319
Local loss @ local epoch 4: 0.01852942258119583
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.82 seconds!
[tester] 
AGNewsMetric: acc=0.8243421052631579, hinge=2.13079851451673, ce=9.041365521079616
Local test acc @ epoch 112: 0.8243
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00013599910016637295
Local loss @ local epoch 1: 0.0006469748914241791
Local loss @ local epoch 2: 0.00024107829085551202
Local loss @ local epoch 3: 0.0007435855222865939
Local loss @ local epoch 4: 0.000986112980172038
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.4 seconds!
[tester] 
AGNewsMetric: acc=0.7948684210526316, hinge=2.8824616781033967, ce=10.751422600997122
Local test acc @ epoch 112: 0.7949
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 7.1257512900047e-05
Local loss @ local epoch 1: 0.00041901806253008544
Local loss @ local epoch 2: 5.518128818948753e-05
Local loss @ local epoch 3: 0.0002983914455398917
Local loss @ local epoch 4: 0.01492885872721672
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.03 seconds!
[tester] 
AGNewsMetric: acc=0.8214473684210526, hinge=2.3310788440704346, ce=10.165513450221011
Local test acc @ epoch 112: 0.8214
Global evaluate on test data...
Evaluate data in 130.94 seconds!
[tester] 
AGNewsMetric: acc=0.845, hinge=2.0753187668950934, ce=9.494096637525056
Global test acc @ epoch 112: 0.845
Global epoch 113...
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 3.975324216298759e-05
Local loss @ local epoch 1: 0.02249855175614357
Local loss @ local epoch 2: 0.005764448083937168
Local loss @ local epoch 3: 0.0012679033679887652
Local loss @ local epoch 4: 0.5795972347259521
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.67 seconds!
[tester] 
AGNewsMetric: acc=0.7614473684210527, hinge=2.3325857102243526, ce=11.219233105308131
Local test acc @ epoch 113: 0.7614
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.000126573140732944
Local loss @ local epoch 1: 0.00036863452987745404
Local loss @ local epoch 2: 0.3577131927013397
Local loss @ local epoch 3: 0.0034128869883716106
Local loss @ local epoch 4: 0.033002838492393494
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.96 seconds!
[tester] 
AGNewsMetric: acc=0.8619736842105263, hinge=1.5307023015775179, ce=9.562033299897847
Local test acc @ epoch 113: 0.862
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 7.798138540238142e-05
Local loss @ local epoch 1: 1.7582637156010605e-05
Local loss @ local epoch 2: 0.0015745308483019471
Local loss @ local epoch 3: 0.0003676069900393486
Local loss @ local epoch 4: 0.004227603320032358
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.84 seconds!
[tester] 
AGNewsMetric: acc=0.8227631578947369, hinge=2.3713771225276745, ce=8.793895474484092
Local test acc @ epoch 113: 0.8228
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.022537479177117348
Local loss @ local epoch 1: 0.0011543802684172988
Local loss @ local epoch 2: 0.02150871604681015
Local loss @ local epoch 3: 0.19602003693580627
Local loss @ local epoch 4: 0.00744490884244442
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.55 seconds!
[tester] 
AGNewsMetric: acc=0.8443421052631579, hinge=1.7903698474482486, ce=9.421356954072651
Local test acc @ epoch 113: 0.8443
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 2.1046689653303474e-05
Local loss @ local epoch 1: 0.001980862580239773
Local loss @ local epoch 2: 4.473806620808318e-05
Local loss @ local epoch 3: 9.127585508394986e-05
Local loss @ local epoch 4: 0.007974321022629738
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.89 seconds!
[tester] 
AGNewsMetric: acc=0.8293421052631579, hinge=2.093322816898948, ce=9.165005886680202
Local test acc @ epoch 113: 0.8293
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0004159488307777792
Local loss @ local epoch 1: 0.00026034630718640983
Local loss @ local epoch 2: 0.005401638802140951
Local loss @ local epoch 3: 0.7047623991966248
Local loss @ local epoch 4: 0.02764284797012806
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.01 seconds!
[tester] 
AGNewsMetric: acc=0.8309210526315789, hinge=1.8812389223199142, ce=9.901493885642603
Local test acc @ epoch 113: 0.8309
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0012919206637889147
Local loss @ local epoch 1: 0.012837550602853298
Local loss @ local epoch 2: 0.1313084363937378
Local loss @ local epoch 3: 0.014421412721276283
Local loss @ local epoch 4: 0.0035464775282889605
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.97 seconds!
[tester] 
AGNewsMetric: acc=0.853421052631579, hinge=1.2885637913252177, ce=9.264656711377595
Local test acc @ epoch 113: 0.8534
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0007761512533761561
Local loss @ local epoch 1: 0.0005498838727362454
Local loss @ local epoch 2: 0.42863523960113525
Local loss @ local epoch 3: 0.0006843226728960872
Local loss @ local epoch 4: 0.00046339540858753026
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.97 seconds!
[tester] 
AGNewsMetric: acc=0.8330263157894737, hinge=1.86509436757941, ce=9.426422825863487
Local test acc @ epoch 113: 0.833
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 2.0525543732219376e-05
Local loss @ local epoch 1: 1.8513412214815617e-05
Local loss @ local epoch 2: 4.061512663611211e-05
Local loss @ local epoch 3: 2.3781491108820774e-05
Local loss @ local epoch 4: 3.5231103538535535e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.94 seconds!
[tester] 
AGNewsMetric: acc=0.8325, hinge=2.1264763026488454, ce=9.365301521702817
Local test acc @ epoch 113: 0.8325
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.033678434789180756
Local loss @ local epoch 1: 0.6728338003158569
Local loss @ local epoch 2: 1.1725136041641235
Local loss @ local epoch 3: 0.18484146893024445
Local loss @ local epoch 4: 0.17529672384262085
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.43 seconds!
[tester] 
AGNewsMetric: acc=0.7281578947368421, hinge=3.208330914597762, ce=10.224987007944208
Local test acc @ epoch 113: 0.7282
Global evaluate on test data...
Evaluate data in 129.94 seconds!
[tester] 
AGNewsMetric: acc=0.8543421052631579, hinge=1.8876861848329243, ce=9.25002456263492
Global test acc @ epoch 113: 0.8543
Global epoch 114...
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0002481067494954914
Local loss @ local epoch 1: 0.00016592966858297586
Local loss @ local epoch 2: 0.02343357726931572
Local loss @ local epoch 3: 0.000291024538455531
Local loss @ local epoch 4: 0.0003118760068900883
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.62 seconds!
[tester] 
AGNewsMetric: acc=0.7967105263157894, hinge=2.352233967781067, ce=8.871314733404862
Local test acc @ epoch 114: 0.7967
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.15502865612506866
Local loss @ local epoch 1: 0.003729369957000017
Local loss @ local epoch 2: 0.0012881485745310783
Local loss @ local epoch 3: 0.15107570588588715
Local loss @ local epoch 4: 0.025835126638412476
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.46 seconds!
[tester] 
AGNewsMetric: acc=0.8594736842105263, hinge=1.2725600849954706, ce=9.452350558230751
Local test acc @ epoch 114: 0.8595
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0024277057964354753
Local loss @ local epoch 1: 9.111675899475813e-05
Local loss @ local epoch 2: 0.5746931433677673
Local loss @ local epoch 3: 0.00207953411154449
Local loss @ local epoch 4: 0.0013124551624059677
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.54 seconds!
[tester] 
AGNewsMetric: acc=0.8532894736842105, hinge=1.8270723011619165, ce=9.961461569133558
Local test acc @ epoch 114: 0.8533
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.004212656058371067
Local loss @ local epoch 1: 0.0007474441663362086
Local loss @ local epoch 2: 0.24859796464443207
Local loss @ local epoch 3: 0.1955765336751938
Local loss @ local epoch 4: 0.000850958691444248
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.04 seconds!
[tester] 
AGNewsMetric: acc=0.8347368421052631, hinge=1.9404602223948428, ce=10.151240655999434
Local test acc @ epoch 114: 0.8347
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0009425198659300804
Local loss @ local epoch 1: 0.10474421083927155
Local loss @ local epoch 2: 0.00010396947618573904
Local loss @ local epoch 3: 0.0003877235285472125
Local loss @ local epoch 4: 0.00011090470070485026
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.21 seconds!
[tester] 
AGNewsMetric: acc=0.8327631578947369, hinge=2.045428937861794, ce=10.014208084909539
Local test acc @ epoch 114: 0.8328
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0027104229666292667
Local loss @ local epoch 1: 0.011596349067986012
Local loss @ local epoch 2: 0.1689593493938446
Local loss @ local epoch 3: 0.0012328900629654527
Local loss @ local epoch 4: 0.011219068430364132
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.82 seconds!
[tester] 
AGNewsMetric: acc=0.8407894736842105, hinge=1.7218580933621055, ce=9.288433793720445
Local test acc @ epoch 114: 0.8408
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.012967846356332302
Local loss @ local epoch 1: 0.6678553819656372
Local loss @ local epoch 2: 0.010598772205412388
Local loss @ local epoch 3: 0.024135801941156387
Local loss @ local epoch 4: 0.03738966956734657
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.29 seconds!
[tester] 
AGNewsMetric: acc=0.8126315789473684, hinge=1.807297409710131, ce=8.270976036473325
Local test acc @ epoch 114: 0.8126
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0031290892511606216
Local loss @ local epoch 1: 0.0031288457103073597
Local loss @ local epoch 2: 0.17215779423713684
Local loss @ local epoch 3: 0.0011764299124479294
Local loss @ local epoch 4: 0.03928684443235397
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.93 seconds!
[tester] 
AGNewsMetric: acc=0.7719736842105264, hinge=2.9914241462004814, ce=10.573968196668122
Local test acc @ epoch 114: 0.772
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 8.680970495333895e-05
Local loss @ local epoch 1: 6.566107913386077e-05
Local loss @ local epoch 2: 2.8005882995785214e-05
Local loss @ local epoch 3: 0.0018193786963820457
Local loss @ local epoch 4: 0.00015209117555059493
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.02 seconds!
[tester] 
AGNewsMetric: acc=0.8113157894736842, hinge=2.50467100193626, ce=8.568365038821572
Local test acc @ epoch 114: 0.8113
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 3.72648355551064e-05
Local loss @ local epoch 1: 0.0002222246548626572
Local loss @ local epoch 2: 0.0007929640123620629
Local loss @ local epoch 3: 3.9694517909083515e-05
Local loss @ local epoch 4: 0.0006401058053597808
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.06 seconds!
[tester] 
AGNewsMetric: acc=0.8238157894736842, hinge=2.0639469515649895, ce=9.673763363486842
Local test acc @ epoch 114: 0.8238
Global evaluate on test data...
Evaluate data in 130.45 seconds!
[tester] 
AGNewsMetric: acc=0.8565789473684211, hinge=1.935733229486566, ce=9.347841740658408
Global test acc @ epoch 114: 0.8566
Global epoch 115...
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.006727167870849371
Local loss @ local epoch 1: 0.0005281229387037456
Local loss @ local epoch 2: 0.00033889643964357674
Local loss @ local epoch 3: 0.7943300604820251
Local loss @ local epoch 4: 0.061988431960344315
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.56 seconds!
[tester] 
AGNewsMetric: acc=0.8084210526315789, hinge=1.7800529971875643, ce=8.743428182099995
Local test acc @ epoch 115: 0.8084
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.011236539110541344
Local loss @ local epoch 1: 0.12265893816947937
Local loss @ local epoch 2: 0.001158359693363309
Local loss @ local epoch 3: 0.10720592737197876
Local loss @ local epoch 4: 0.13624423742294312
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.2 seconds!
[tester] 
AGNewsMetric: acc=0.839078947368421, hinge=1.4497950508719997, ce=8.730347862243653
Local test acc @ epoch 115: 0.8391
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 7.777842984069139e-05
Local loss @ local epoch 1: 0.00016572998720221221
Local loss @ local epoch 2: 3.6595123674487695e-05
Local loss @ local epoch 3: 7.607798033859581e-05
Local loss @ local epoch 4: 0.00015922317106742412
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.51 seconds!
[tester] 
AGNewsMetric: acc=0.859078947368421, hinge=1.6387921263042249, ce=8.591839440998278
Local test acc @ epoch 115: 0.8591
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00020064615819137543
Local loss @ local epoch 1: 0.03205888718366623
Local loss @ local epoch 2: 0.008690661750733852
Local loss @ local epoch 3: 0.0060827904380857944
Local loss @ local epoch 4: 0.13130837678909302
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.05 seconds!
[tester] 
AGNewsMetric: acc=0.8501315789473685, hinge=1.8366746940110859, ce=8.285508932816354
Local test acc @ epoch 115: 0.8501
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0006132876151241362
Local loss @ local epoch 1: 0.0007728822529315948
Local loss @ local epoch 2: 0.004704589489847422
Local loss @ local epoch 3: 0.00015245920803863555
Local loss @ local epoch 4: 0.3188508450984955
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.48 seconds!
[tester] 
AGNewsMetric: acc=0.7978947368421052, hinge=2.7138036584854124, ce=10.241082605060779
Local test acc @ epoch 115: 0.7979
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.016607079654932022
Local loss @ local epoch 1: 0.07349272072315216
Local loss @ local epoch 2: 0.005304612219333649
Local loss @ local epoch 3: 0.3684946298599243
Local loss @ local epoch 4: 0.4960220754146576
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.9 seconds!
[tester] 
AGNewsMetric: acc=0.7292105263157894, hinge=2.9034934189445094, ce=10.398900491814864
Local test acc @ epoch 115: 0.7292
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0001280206342926249
Local loss @ local epoch 1: 4.5393633627099916e-05
Local loss @ local epoch 2: 0.0002617977443151176
Local loss @ local epoch 3: 0.00016733939992263913
Local loss @ local epoch 4: 8.557330875191838e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.42 seconds!
[tester] 
AGNewsMetric: acc=0.8396052631578947, hinge=1.8813422459050229, ce=9.346050951104415
Local test acc @ epoch 115: 0.8396
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0001020028066704981
Local loss @ local epoch 1: 0.0003300991957075894
Local loss @ local epoch 2: 0.0008078340906649828
Local loss @ local epoch 3: 0.00010915757593465969
Local loss @ local epoch 4: 0.007067336700856686
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.47 seconds!
[tester] 
AGNewsMetric: acc=0.8477631578947369, hinge=1.9769588611000461, ce=9.434349937438965
Local test acc @ epoch 115: 0.8478
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00014197459677234292
Local loss @ local epoch 1: 6.785961159039289e-05
Local loss @ local epoch 2: 0.0006989580579102039
Local loss @ local epoch 3: 0.00010970643779728562
Local loss @ local epoch 4: 0.0003817224351223558
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.9 seconds!
[tester] 
AGNewsMetric: acc=0.8055263157894736, hinge=2.2590625263515274, ce=9.21754501543547
Local test acc @ epoch 115: 0.8055
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00016994356701616198
Local loss @ local epoch 1: 0.006343739572912455
Local loss @ local epoch 2: 0.00021274827304296196
Local loss @ local epoch 3: 1.451529622077942
Local loss @ local epoch 4: 0.0033836504444479942
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.74 seconds!
[tester] 
AGNewsMetric: acc=0.8325, hinge=2.2299625999049137, ce=9.921165363914088
Local test acc @ epoch 115: 0.8325
Global evaluate on test data...
Evaluate data in 130.42 seconds!
[tester] 
AGNewsMetric: acc=0.8531578947368421, hinge=1.922477018707677, ce=9.30718692779541
Global test acc @ epoch 115: 0.8532
Global epoch 116...
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 3.508142617647536e-05
Local loss @ local epoch 1: 7.726132025709376e-05
Local loss @ local epoch 2: 4.330215961090289e-05
Local loss @ local epoch 3: 0.0001335423585260287
Local loss @ local epoch 4: 8.054772479226813e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.11 seconds!
[tester] 
AGNewsMetric: acc=0.8486842105263158, hinge=1.9058046471445185, ce=9.481733759829872
Local test acc @ epoch 116: 0.8487
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0003276665520388633
Local loss @ local epoch 1: 0.0017560841515660286
Local loss @ local epoch 2: 0.00031931960256770253
Local loss @ local epoch 3: 0.0011949671898037195
Local loss @ local epoch 4: 0.0005270543042570353
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.55 seconds!
[tester] 
AGNewsMetric: acc=0.845657894736842, hinge=1.7983288275568108, ce=10.025054196809467
Local test acc @ epoch 116: 0.8457
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.38937506079673767
Local loss @ local epoch 1: 0.01556283887475729
Local loss @ local epoch 2: 0.05262545496225357
Local loss @ local epoch 3: 0.09193561226129532
Local loss @ local epoch 4: 0.16246609389781952
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.46 seconds!
[tester] 
AGNewsMetric: acc=0.8077631578947368, hinge=1.9323956466975964, ce=9.254758881016782
Local test acc @ epoch 116: 0.8078
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0002129447238985449
Local loss @ local epoch 1: 0.00030151131795719266
Local loss @ local epoch 2: 0.0006119541940279305
Local loss @ local epoch 3: 0.01354385819286108
Local loss @ local epoch 4: 0.0008278514142148197
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.53 seconds!
[tester] 
AGNewsMetric: acc=0.8528947368421053, hinge=1.745820137576053, ce=9.142133775008352
Local test acc @ epoch 116: 0.8529
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0025927587412297726
Local loss @ local epoch 1: 0.001632258528843522
Local loss @ local epoch 2: 0.5084831714630127
Local loss @ local epoch 3: 0.0002852681209333241
Local loss @ local epoch 4: 0.002426204737275839
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.24 seconds!
[tester] 
AGNewsMetric: acc=0.7542105263157894, hinge=2.8300612213737084, ce=8.896250815140574
Local test acc @ epoch 116: 0.7542
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.04985841363668442
Local loss @ local epoch 1: 0.003278512042015791
Local loss @ local epoch 2: 0.024307595565915108
Local loss @ local epoch 3: 0.5611728429794312
Local loss @ local epoch 4: 0.07283883541822433
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.93 seconds!
[tester] 
AGNewsMetric: acc=0.785, hinge=2.097680274059898, ce=11.08370446456106
Local test acc @ epoch 116: 0.785
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 2.5115061362157576e-05
Local loss @ local epoch 1: 0.00023749927640892565
Local loss @ local epoch 2: 1.7396625480614603e-05
Local loss @ local epoch 3: 0.017607001587748528
Local loss @ local epoch 4: 5.567424523178488e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.97 seconds!
[tester] 
AGNewsMetric: acc=0.819078947368421, hinge=2.7199554081967, ce=9.660732490138004
Local test acc @ epoch 116: 0.8191
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00011275153519818559
Local loss @ local epoch 1: 0.001359541085548699
Local loss @ local epoch 2: 8.244907803600654e-05
Local loss @ local epoch 3: 0.002155544701963663
Local loss @ local epoch 4: 0.000803910952527076
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.29 seconds!
[tester] 
AGNewsMetric: acc=0.8639473684210527, hinge=1.7424453042682848, ce=8.614159545898438
Local test acc @ epoch 116: 0.8639
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0029229954816401005
Local loss @ local epoch 1: 0.059530217200517654
Local loss @ local epoch 2: 0.42844969034194946
Local loss @ local epoch 3: 0.0005495861987583339
Local loss @ local epoch 4: 0.053116507828235626
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.59 seconds!
[tester] 
AGNewsMetric: acc=0.7823684210526316, hinge=2.768969413857711, ce=10.134146947358785
Local test acc @ epoch 116: 0.7824
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0005695276195183396
Local loss @ local epoch 1: 0.06661762297153473
Local loss @ local epoch 2: 0.0014147027395665646
Local loss @ local epoch 3: 0.0058440472930669785
Local loss @ local epoch 4: 0.022260891273617744
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.55 seconds!
[tester] 
AGNewsMetric: acc=0.8419736842105263, hinge=1.5487912659896048, ce=10.300911505849738
Local test acc @ epoch 116: 0.842
Global evaluate on test data...
Evaluate data in 129.69 seconds!
[tester] 
AGNewsMetric: acc=0.8552631578947368, hinge=1.9378580176202875, ce=9.262621373628315
Global test acc @ epoch 116: 0.8553
Global epoch 117...
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.005460783373564482
Local loss @ local epoch 1: 0.2711773216724396
Local loss @ local epoch 2: 0.06678805500268936
Local loss @ local epoch 3: 0.007114103529602289
Local loss @ local epoch 4: 0.10794475674629211
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.48 seconds!
[tester] 
AGNewsMetric: acc=0.7555263157894737, hinge=2.661774434290434, ce=10.848315696716309
Local test acc @ epoch 117: 0.7555
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0008145065512508154
Local loss @ local epoch 1: 0.00022580182121600956
Local loss @ local epoch 2: 0.0010866497177630663
Local loss @ local epoch 3: 0.0011281835613772273
Local loss @ local epoch 4: 0.00606577331200242
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.08 seconds!
[tester] 
AGNewsMetric: acc=0.8376315789473684, hinge=2.0885528255763806, ce=9.524385321767706
Local test acc @ epoch 117: 0.8376
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 6.943925109226257e-05
Local loss @ local epoch 1: 0.0025132973678410053
Local loss @ local epoch 2: 0.0021188261453062296
Local loss @ local epoch 3: 0.0005825265543535352
Local loss @ local epoch 4: 0.11420201510190964
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.46 seconds!
[tester] 
AGNewsMetric: acc=0.8398684210526316, hinge=1.8520635248485364, ce=7.685371969122635
Local test acc @ epoch 117: 0.8399
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0013441317714750767
Local loss @ local epoch 1: 0.004569727927446365
Local loss @ local epoch 2: 0.0002772457664832473
Local loss @ local epoch 3: 0.0003241131780669093
Local loss @ local epoch 4: 0.047326892614364624
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.12 seconds!
[tester] 
AGNewsMetric: acc=0.838421052631579, hinge=1.7386040228291562, ce=8.813823958949039
Local test acc @ epoch 117: 0.8384
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 2.741639400483109e-05
Local loss @ local epoch 1: 4.517556953942403e-05
Local loss @ local epoch 2: 7.077923510223627e-05
Local loss @ local epoch 3: 0.00010114897304447368
Local loss @ local epoch 4: 3.204269160050899e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.54 seconds!
[tester] 
AGNewsMetric: acc=0.8698684210526316, hinge=1.5360729832398263, ce=9.606469594051964
Local test acc @ epoch 117: 0.8699
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00204722722992301
Local loss @ local epoch 1: 0.00028038211166858673
Local loss @ local epoch 2: 0.001568503095768392
Local loss @ local epoch 3: 0.00507736299186945
Local loss @ local epoch 4: 0.004580369219183922
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.85 seconds!
[tester] 
AGNewsMetric: acc=0.8561842105263158, hinge=1.5501014217577482, ce=8.615779503270199
Local test acc @ epoch 117: 0.8562
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 9.769844473339617e-05
Local loss @ local epoch 1: 7.403428026009351e-05
Local loss @ local epoch 2: 0.0014125816524028778
Local loss @ local epoch 3: 0.10944666713476181
Local loss @ local epoch 4: 0.0011300987098366022
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.05 seconds!
[tester] 
AGNewsMetric: acc=0.8521052631578947, hinge=1.903914811485692, ce=9.774208034716155
Local test acc @ epoch 117: 0.8521
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00010781709715956822
Local loss @ local epoch 1: 0.00018683465896174312
Local loss @ local epoch 2: 0.0019713775254786015
Local loss @ local epoch 3: 0.00022846298816148192
Local loss @ local epoch 4: 7.758689025649801e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.29 seconds!
[tester] 
AGNewsMetric: acc=0.8269736842105263, hinge=2.2966878619946933, ce=9.926855326200787
Local test acc @ epoch 117: 0.827
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 6.020432192599401e-05
Local loss @ local epoch 1: 0.0006031289813108742
Local loss @ local epoch 2: 0.0007097604684531689
Local loss @ local epoch 3: 0.0008195866830646992
Local loss @ local epoch 4: 0.0006383233703672886
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.21 seconds!
[tester] 
AGNewsMetric: acc=0.8023684210526316, hinge=2.5275549770656385, ce=10.287801549811112
Local test acc @ epoch 117: 0.8024
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00045981371658854187
Local loss @ local epoch 1: 0.0010024314979091287
Local loss @ local epoch 2: 7.820298196747899e-05
Local loss @ local epoch 3: 0.0002309782721567899
Local loss @ local epoch 4: 0.07959487289190292
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.28 seconds!
[tester] 
AGNewsMetric: acc=0.7280263157894736, hinge=4.1630013247540125, ce=10.966393452694541
Local test acc @ epoch 117: 0.728
Global evaluate on test data...
Evaluate data in 129.72 seconds!
[tester] 
AGNewsMetric: acc=0.8555263157894737, hinge=2.025339125834013, ce=9.284577363666735
Global test acc @ epoch 117: 0.8555
Global epoch 118...
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0003296257636975497
Local loss @ local epoch 1: 1.1659993106150068e-05
Local loss @ local epoch 2: 0.0003654396568890661
Local loss @ local epoch 3: 0.00013139663496986032
Local loss @ local epoch 4: 0.007424413226544857
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.69 seconds!
[tester] 
AGNewsMetric: acc=0.8532894736842105, hinge=1.74566145294591, ce=7.70954471487748
Local test acc @ epoch 118: 0.8533
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.002825263189151883
Local loss @ local epoch 1: 0.0031742870341986418
Local loss @ local epoch 2: 0.0001458153419662267
Local loss @ local epoch 3: 0.02271295338869095
Local loss @ local epoch 4: 0.007987274788320065
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.06 seconds!
[tester] 
AGNewsMetric: acc=0.8135526315789474, hinge=2.2207699657741347, ce=10.270400990937885
Local test acc @ epoch 118: 0.8136
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 9.194973245030269e-05
Local loss @ local epoch 1: 4.261596404830925e-05
Local loss @ local epoch 2: 0.00031422890606336296
Local loss @ local epoch 3: 3.6060623642697465e-06
Local loss @ local epoch 4: 0.0023148171603679657
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.77 seconds!
[tester] 
AGNewsMetric: acc=0.8069736842105263, hinge=2.9599565970270256, ce=9.92457268363551
Local test acc @ epoch 118: 0.807
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 2.1790767277707346e-05
Local loss @ local epoch 1: 2.282735840708483e-05
Local loss @ local epoch 2: 7.296619151020423e-05
Local loss @ local epoch 3: 0.02977484092116356
Local loss @ local epoch 4: 0.0008138939738273621
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.43 seconds!
[tester] 
AGNewsMetric: acc=0.7955263157894736, hinge=2.9708991517518695, ce=10.609893371180485
Local test acc @ epoch 118: 0.7955
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0003823526785708964
Local loss @ local epoch 1: 0.0006241800729185343
Local loss @ local epoch 2: 0.003791866824030876
Local loss @ local epoch 3: 0.00012865611643064767
Local loss @ local epoch 4: 0.0007850062102079391
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.67 seconds!
[tester] 
AGNewsMetric: acc=0.7931578947368421, hinge=2.8429748778594166, ce=9.28857299603914
Local test acc @ epoch 118: 0.7932
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.013998444192111492
Local loss @ local epoch 1: 0.011215897276997566
Local loss @ local epoch 2: 0.0104308370500803
Local loss @ local epoch 3: 0.011858330108225346
Local loss @ local epoch 4: 0.0027860733680427074
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.77 seconds!
[tester] 
AGNewsMetric: acc=0.8517105263157895, hinge=1.4591253182762547, ce=7.291513460058915
Local test acc @ epoch 118: 0.8517
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 1.1741900380002335e-05
Local loss @ local epoch 1: 6.570843106601387e-05
Local loss @ local epoch 2: 0.00037466856883838773
Local loss @ local epoch 3: 6.763084093108773e-05
Local loss @ local epoch 4: 0.00014156469842419028
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.95 seconds!
[tester] 
AGNewsMetric: acc=0.825921052631579, hinge=2.2970476770401, ce=8.766348160191587
Local test acc @ epoch 118: 0.8259
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0004331278323661536
Local loss @ local epoch 1: 0.05724791809916496
Local loss @ local epoch 2: 0.010419584810733795
Local loss @ local epoch 3: 0.4895334541797638
Local loss @ local epoch 4: 0.002153134671971202
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.44 seconds!
[tester] 
AGNewsMetric: acc=0.7989473684210526, hinge=2.5594971584018906, ce=8.526584251805355
Local test acc @ epoch 118: 0.7989
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0001724113681120798
Local loss @ local epoch 1: 1.875909583759494e-05
Local loss @ local epoch 2: 0.00025972453295253217
Local loss @ local epoch 3: 6.954295531613752e-05
Local loss @ local epoch 4: 0.0004864150832872838
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.98 seconds!
[tester] 
AGNewsMetric: acc=0.8157894736842105, hinge=2.778342658846002, ce=10.318417498939915
Local test acc @ epoch 118: 0.8158
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 1.1197981621080544e-05
Local loss @ local epoch 1: 1.2665765098063275e-05
Local loss @ local epoch 2: 8.332557626999915e-05
Local loss @ local epoch 3: 2.7945972760790028e-05
Local loss @ local epoch 4: 0.0007844297215342522
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.71 seconds!
[tester] 
AGNewsMetric: acc=0.8502631578947368, hinge=1.8514299402738872, ce=8.55076826597515
Local test acc @ epoch 118: 0.8503
Global evaluate on test data...
Evaluate data in 130.19 seconds!
[tester] 
AGNewsMetric: acc=0.859078947368421, hinge=2.0029055886519584, ce=9.024446951213635
Global test acc @ epoch 118: 0.8591
Global epoch 119...
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00047349391388706863
Local loss @ local epoch 1: 0.0007722867885604501
Local loss @ local epoch 2: 0.00010705213207984343
Local loss @ local epoch 3: 0.00027730732108466327
Local loss @ local epoch 4: 0.0008639978477731347
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.72 seconds!
[tester] 
AGNewsMetric: acc=0.8177631578947369, hinge=2.5977503706279554, ce=9.125816911396228
Local test acc @ epoch 119: 0.8178
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.050034768879413605
Local loss @ local epoch 1: 2.7596039217314683e-05
Local loss @ local epoch 2: 0.0005142936715856194
Local loss @ local epoch 3: 0.00010962167289108038
Local loss @ local epoch 4: 0.001251276582479477
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.12 seconds!
[tester] 
AGNewsMetric: acc=0.8546052631578948, hinge=1.6563651150151304, ce=9.608803799277858
Local test acc @ epoch 119: 0.8546
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0002531962236389518
Local loss @ local epoch 1: 0.13114839792251587
Local loss @ local epoch 2: 0.008526111952960491
Local loss @ local epoch 3: 0.00972958654165268
Local loss @ local epoch 4: 0.016370903700590134
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.41 seconds!
[tester] 
AGNewsMetric: acc=0.8347368421052631, hinge=1.9339379074699001, ce=9.726755961367958
Local test acc @ epoch 119: 0.8347
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 3.924262273358181e-05
Local loss @ local epoch 1: 7.290567009476945e-05
Local loss @ local epoch 2: 5.785978282801807e-05
Local loss @ local epoch 3: 0.00014401036605704576
Local loss @ local epoch 4: 9.753612539498135e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.48 seconds!
[tester] 
AGNewsMetric: acc=0.8385526315789473, hinge=2.269691149310062, ce=8.486555607444362
Local test acc @ epoch 119: 0.8386
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 4.039761915919371e-05
Local loss @ local epoch 1: 0.01100413128733635
Local loss @ local epoch 2: 1.6912523278733715e-05
Local loss @ local epoch 3: 0.2236471027135849
Local loss @ local epoch 4: 0.0040096803568303585
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.43 seconds!
[tester] 
AGNewsMetric: acc=0.8398684210526316, hinge=2.0590657462571795, ce=9.209522446080259
Local test acc @ epoch 119: 0.8399
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00018548814114183187
Local loss @ local epoch 1: 0.00019764389435295016
Local loss @ local epoch 2: 7.9024386650417e-05
Local loss @ local epoch 3: 0.0007172878249548376
Local loss @ local epoch 4: 0.00010256430687149987
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.29 seconds!
[tester] 
AGNewsMetric: acc=0.8659210526315789, hinge=1.5510521223670557, ce=9.211831418087607
Local test acc @ epoch 119: 0.8659
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 7.713203376624733e-05
Local loss @ local epoch 1: 0.0005051762564107776
Local loss @ local epoch 2: 0.0017023871187120676
Local loss @ local epoch 3: 0.00781509280204773
Local loss @ local epoch 4: 0.030077071860432625
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.25 seconds!
[tester] 
AGNewsMetric: acc=0.853421052631579, hinge=1.9384936367838006, ce=9.838552292271665
Local test acc @ epoch 119: 0.8534
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00042684568325057626
Local loss @ local epoch 1: 0.0008180233999155462
Local loss @ local epoch 2: 0.1962653249502182
Local loss @ local epoch 3: 0.0037879357114434242
Local loss @ local epoch 4: 0.11782020330429077
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.16 seconds!
[tester] 
AGNewsMetric: acc=0.8478947368421053, hinge=1.7667698441053692, ce=8.7978093639173
Local test acc @ epoch 119: 0.8479
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00013274380762595683
Local loss @ local epoch 1: 0.0001567360886838287
Local loss @ local epoch 2: 0.006728161126375198
Local loss @ local epoch 3: 0.18272681534290314
Local loss @ local epoch 4: 0.00041693542152643204
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 131.05 seconds!
[tester] 
AGNewsMetric: acc=0.8027631578947368, hinge=2.336010675179331, ce=9.204917150798597
Local test acc @ epoch 119: 0.8028
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0001009081897791475
Local loss @ local epoch 1: 2.8295693482505158e-05
Local loss @ local epoch 2: 7.988337165443227e-05
Local loss @ local epoch 3: 0.010187742300331593
Local loss @ local epoch 4: 0.27742132544517517
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.1 seconds!
[tester] 
AGNewsMetric: acc=0.8028947368421052, hinge=2.904172058105469, ce=9.954691559640985
Local test acc @ epoch 119: 0.8029
Global evaluate on test data...
Evaluate data in 129.22 seconds!
[tester] 
AGNewsMetric: acc=0.8592105263157894, hinge=1.9335128072688454, ce=8.743186870374178
Global test acc @ epoch 119: 0.8592
Global epoch 120...
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 9.183871588902548e-05
Local loss @ local epoch 1: 0.00029203473241068423
Local loss @ local epoch 2: 0.00011924343561986461
Local loss @ local epoch 3: 0.004174918867647648
Local loss @ local epoch 4: 7.248414476634935e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.31 seconds!
[tester] 
AGNewsMetric: acc=0.8073684210526316, hinge=2.4620567123513473, ce=9.767730237057334
Local test acc @ epoch 120: 0.8074
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00017372578440699726
Local loss @ local epoch 1: 0.0003198268823325634
Local loss @ local epoch 2: 1.7329548427369446e-05
Local loss @ local epoch 3: 0.00060578080592677
Local loss @ local epoch 4: 0.00025004326016642153
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.16 seconds!
[tester] 
AGNewsMetric: acc=0.8092105263157895, hinge=2.554800612801, ce=8.866953843769274
Local test acc @ epoch 120: 0.8092
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.006032182835042477
Local loss @ local epoch 1: 0.25291907787323
Local loss @ local epoch 2: 0.0002934474032372236
Local loss @ local epoch 3: 0.7504881620407104
Local loss @ local epoch 4: 0.053002603352069855
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.03 seconds!
[tester] 
AGNewsMetric: acc=0.7901315789473684, hinge=2.432251130656192, ce=9.446974404987536
Local test acc @ epoch 120: 0.7901
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0005359974456951022
Local loss @ local epoch 1: 6.750188185833395e-05
Local loss @ local epoch 2: 0.004076709970831871
Local loss @ local epoch 3: 0.00022445984359364957
Local loss @ local epoch 4: 0.01660497859120369
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.94 seconds!
[tester] 
AGNewsMetric: acc=0.815921052631579, hinge=2.7515396886122856, ce=10.426064449109528
Local test acc @ epoch 120: 0.8159
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.01791621930897236
Local loss @ local epoch 1: 0.007624492514878511
Local loss @ local epoch 2: 0.5829496383666992
Local loss @ local epoch 3: 0.009264133870601654
Local loss @ local epoch 4: 0.0644138753414154
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.59 seconds!
[tester] 
AGNewsMetric: acc=0.8244736842105264, hinge=1.802417079774957, ce=9.712244913201584
Local test acc @ epoch 120: 0.8245
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.2958824336528778
Local loss @ local epoch 1: 0.9095649123191833
Local loss @ local epoch 2: 0.008807962760329247
Local loss @ local epoch 3: 0.1285923272371292
Local loss @ local epoch 4: 0.13408881425857544
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.93 seconds!
[tester] 
AGNewsMetric: acc=0.7453947368421052, hinge=3.511432160829243, ce=8.99044416527999
Local test acc @ epoch 120: 0.7454
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00023195658286567777
Local loss @ local epoch 1: 0.22538113594055176
Local loss @ local epoch 2: 0.00039794796612113714
Local loss @ local epoch 3: 0.001461395644582808
Local loss @ local epoch 4: 0.039335157722234726
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.94 seconds!
[tester] 
AGNewsMetric: acc=0.853421052631579, hinge=1.4062744825764706, ce=10.148416930750797
Local test acc @ epoch 120: 0.8534
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 1.5772397091495804e-05
Local loss @ local epoch 1: 2.645458334882278e-05
Local loss @ local epoch 2: 8.322072062583175e-06
Local loss @ local epoch 3: 8.642519787827041e-06
Local loss @ local epoch 4: 0.006118019111454487
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.61 seconds!
[tester] 
AGNewsMetric: acc=0.8194736842105264, hinge=2.3767692008771393, ce=9.16080029136256
Local test acc @ epoch 120: 0.8195
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 3.6369125155033544e-05
Local loss @ local epoch 1: 2.0875562768196687e-05
Local loss @ local epoch 2: 5.913560016779229e-05
Local loss @ local epoch 3: 7.048922998365015e-05
Local loss @ local epoch 4: 0.0006224247044883668
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.41 seconds!
[tester] 
AGNewsMetric: acc=0.843421052631579, hinge=2.1013529175206234, ce=9.28361649563438
Local test acc @ epoch 120: 0.8434
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.004816435743123293
Local loss @ local epoch 1: 0.13636451959609985
Local loss @ local epoch 2: 0.0001505487598478794
Local loss @ local epoch 3: 0.21303518116474152
Local loss @ local epoch 4: 0.002574366983026266
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.28 seconds!
[tester] 
AGNewsMetric: acc=0.8519736842105263, hinge=1.682179133264642, ce=9.949006624723735
Local test acc @ epoch 120: 0.852
Global evaluate on test data...
Evaluate data in 129.49 seconds!
[tester] 
AGNewsMetric: acc=0.8485526315789473, hinge=2.0496195256082634, ce=9.243303754706131
Global test acc @ epoch 120: 0.8486
Global epoch 121...
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 3.0029310437384993e-05
Local loss @ local epoch 1: 1.1361760698491707e-05
Local loss @ local epoch 2: 0.030834985896945
Local loss @ local epoch 3: 5.97332400502637e-05
Local loss @ local epoch 4: 0.00017630810907576233
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.44 seconds!
[tester] 
AGNewsMetric: acc=0.85, hinge=2.1031211707466526, ce=9.49741584777832
Local test acc @ epoch 121: 0.85
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.000981625635176897
Local loss @ local epoch 1: 1.606299338163808e-05
Local loss @ local epoch 2: 0.007496660575270653
Local loss @ local epoch 3: 0.0002458144736010581
Local loss @ local epoch 4: 0.00036058505065739155
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.5 seconds!
[tester] 
AGNewsMetric: acc=0.8478947368421053, hinge=1.7965809297561646, ce=9.018631121986791
Local test acc @ epoch 121: 0.8479
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 4.821418770006858e-05
Local loss @ local epoch 1: 8.523123688064516e-05
Local loss @ local epoch 2: 0.0567067451775074
Local loss @ local epoch 3: 0.0005815568147227168
Local loss @ local epoch 4: 0.5345216989517212
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.41 seconds!
[tester] 
AGNewsMetric: acc=0.7421052631578947, hinge=3.6928759005195215, ce=9.787375169051321
Local test acc @ epoch 121: 0.7421
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00030483337468467653
Local loss @ local epoch 1: 0.0031818978022783995
Local loss @ local epoch 2: 0.00041676609544083476
Local loss @ local epoch 3: 0.005665611941367388
Local loss @ local epoch 4: 0.010268325917422771
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.54 seconds!
[tester] 
AGNewsMetric: acc=0.8163157894736842, hinge=2.270428957186247, ce=9.543916130065918
Local test acc @ epoch 121: 0.8163
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0011556795798242092
Local loss @ local epoch 1: 0.044507164508104324
Local loss @ local epoch 2: 0.00016208493616431952
Local loss @ local epoch 3: 0.042245496064424515
Local loss @ local epoch 4: 0.11186259984970093
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.98 seconds!
[tester] 
AGNewsMetric: acc=0.7834210526315789, hinge=2.40841239377072, ce=8.41034207193475
Local test acc @ epoch 121: 0.7834
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 2.1828333046869375e-05
Local loss @ local epoch 1: 6.622602086281404e-05
Local loss @ local epoch 2: 7.144898700062186e-05
Local loss @ local epoch 3: 0.000191686354810372
Local loss @ local epoch 4: 1.0244246368529275e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.83 seconds!
[tester] 
AGNewsMetric: acc=0.8393421052631579, hinge=2.4012446117401125, ce=8.99194699739155
Local test acc @ epoch 121: 0.8393
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 6.014700193190947e-05
Local loss @ local epoch 1: 1.2099340892746113e-05
Local loss @ local epoch 2: 2.0741785192512907e-05
Local loss @ local epoch 3: 0.0006120848702266812
Local loss @ local epoch 4: 0.0001714332029223442
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.22 seconds!
[tester] 
AGNewsMetric: acc=0.7392105263157894, hinge=2.9549833483445016, ce=8.132488483629729
Local test acc @ epoch 121: 0.7392
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 8.170225191861391e-05
Local loss @ local epoch 1: 0.10318558663129807
Local loss @ local epoch 2: 0.003534847404807806
Local loss @ local epoch 3: 0.0162370465695858
Local loss @ local epoch 4: 0.020563015714287758
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.76 seconds!
[tester] 
AGNewsMetric: acc=0.8227631578947369, hinge=2.384315098210385, ce=10.340468866448653
Local test acc @ epoch 121: 0.8228
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0012754700146615505
Local loss @ local epoch 1: 0.06487742066383362
Local loss @ local epoch 2: 0.011654340662062168
Local loss @ local epoch 3: 0.026618553325533867
Local loss @ local epoch 4: 0.09103193134069443
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.71 seconds!
[tester] 
AGNewsMetric: acc=0.8098684210526316, hinge=2.366410442904422, ce=10.748360133923983
Local test acc @ epoch 121: 0.8099
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.08440953493118286
Local loss @ local epoch 1: 0.00029808541876263916
Local loss @ local epoch 2: 0.0001755703560775146
Local loss @ local epoch 3: 0.059290144592523575
Local loss @ local epoch 4: 0.005192765034735203
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.71 seconds!
[tester] 
AGNewsMetric: acc=0.8496052631578948, hinge=1.4914953349765978, ce=10.092102062827662
Local test acc @ epoch 121: 0.8496
Global evaluate on test data...
Evaluate data in 130.51 seconds!
[tester] 
AGNewsMetric: acc=0.8576315789473684, hinge=1.997224524397599, ce=9.030551733719674
Global test acc @ epoch 121: 0.8576
Global epoch 122...
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.24963589012622833
Local loss @ local epoch 1: 0.002109576715156436
Local loss @ local epoch 2: 0.006512611638754606
Local loss @ local epoch 3: 0.21188884973526
Local loss @ local epoch 4: 0.12498784065246582
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.15 seconds!
[tester] 
AGNewsMetric: acc=0.8126315789473684, hinge=1.766861988870721, ce=9.396970168665836
Local test acc @ epoch 122: 0.8126
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.001087720855139196
Local loss @ local epoch 1: 3.197530168108642e-05
Local loss @ local epoch 2: 0.19714540243148804
Local loss @ local epoch 3: 0.0006615014281123877
Local loss @ local epoch 4: 0.0013328797649592161
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 131.01 seconds!
[tester] 
AGNewsMetric: acc=0.7772368421052631, hinge=3.7610915274369088, ce=10.560214942129035
Local test acc @ epoch 122: 0.7772
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00512683717533946
Local loss @ local epoch 1: 0.0020965433213859797
Local loss @ local epoch 2: 0.017765622586011887
Local loss @ local epoch 3: 0.11506213247776031
Local loss @ local epoch 4: 0.012032822705805302
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.4 seconds!
[tester] 
AGNewsMetric: acc=0.7768421052631579, hinge=2.3974640602814525, ce=9.483185679787084
Local test acc @ epoch 122: 0.7768
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.02030036598443985
Local loss @ local epoch 1: 0.0002886708243750036
Local loss @ local epoch 2: 1.2710223197937012
Local loss @ local epoch 3: 0.07464340329170227
Local loss @ local epoch 4: 0.1968398094177246
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.94 seconds!
[tester] 
AGNewsMetric: acc=0.8282894736842106, hinge=1.7708544924384668, ce=8.61018649854158
Local test acc @ epoch 122: 0.8283
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 2.9188960979809053e-05
Local loss @ local epoch 1: 4.9583064537728205e-05
Local loss @ local epoch 2: 0.0027730122674256563
Local loss @ local epoch 3: 0.0018153312848880887
Local loss @ local epoch 4: 0.00010306204057997093
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.76 seconds!
[tester] 
AGNewsMetric: acc=0.8328947368421052, hinge=2.1431399797138413, ce=9.948060198332135
Local test acc @ epoch 122: 0.8329
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 1.0050684977613855e-05
Local loss @ local epoch 1: 5.651733590639196e-05
Local loss @ local epoch 2: 0.00014187597844284028
Local loss @ local epoch 3: 2.7311869416735135e-05
Local loss @ local epoch 4: 0.00041506552952341735
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.56 seconds!
[tester] 
AGNewsMetric: acc=0.8419736842105263, hinge=2.002295186896073, ce=9.444773250379061
Local test acc @ epoch 122: 0.842
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 4.336213805800071e-06
Local loss @ local epoch 1: 1.3931872672401369e-05
Local loss @ local epoch 2: 1.5169074686127715e-05
Local loss @ local epoch 3: 4.388377874420257e-06
Local loss @ local epoch 4: 4.0167156839743257e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.24 seconds!
[tester] 
AGNewsMetric: acc=0.7757894736842105, hinge=2.6451487051813225, ce=9.814813198290373
Local test acc @ epoch 122: 0.7758
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0006918176077306271
Local loss @ local epoch 1: 0.0024628210812807083
Local loss @ local epoch 2: 0.00038084929110482335
Local loss @ local epoch 3: 0.0003222282393835485
Local loss @ local epoch 4: 0.0002945937740150839
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.96 seconds!
[tester] 
AGNewsMetric: acc=0.7917105263157894, hinge=3.208933216145164, ce=10.243572084527267
Local test acc @ epoch 122: 0.7917
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.01151486486196518
Local loss @ local epoch 1: 0.015330635011196136
Local loss @ local epoch 2: 0.3614560663700104
Local loss @ local epoch 3: 0.0032143767457455397
Local loss @ local epoch 4: 0.00047288797213695943
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.54 seconds!
[tester] 
AGNewsMetric: acc=0.8706578947368421, hinge=1.41710246462571, ce=10.169541585821854
Local test acc @ epoch 122: 0.8707
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0002512454229872674
Local loss @ local epoch 1: 6.295463390415534e-05
Local loss @ local epoch 2: 0.0011245239293202758
Local loss @ local epoch 3: 0.0007823695777915418
Local loss @ local epoch 4: 0.0002902949636336416
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.24 seconds!
[tester] 
AGNewsMetric: acc=0.8228947368421052, hinge=2.567379144869353, ce=10.33827548980713
Local test acc @ epoch 122: 0.8229
Global evaluate on test data...
Evaluate data in 129.82 seconds!
[tester] 
AGNewsMetric: acc=0.8567105263157895, hinge=2.0002120911447627, ce=9.145045975132993
Global test acc @ epoch 122: 0.8567
Global epoch 123...
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00026893217000178993
Local loss @ local epoch 1: 0.00012597179738804698
Local loss @ local epoch 2: 0.00044419540790840983
Local loss @ local epoch 3: 0.006906470283865929
Local loss @ local epoch 4: 0.0009978808229789138
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.88 seconds!
[tester] 
AGNewsMetric: acc=0.7948684210526316, hinge=2.6153505844818916, ce=10.658835543582313
Local test acc @ epoch 123: 0.7949
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0070424554869532585
Local loss @ local epoch 1: 0.0006191688007675111
Local loss @ local epoch 2: 0.0034530884586274624
Local loss @ local epoch 3: 0.020871007815003395
Local loss @ local epoch 4: 0.3230170011520386
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.67 seconds!
[tester] 
AGNewsMetric: acc=0.8448684210526316, hinge=1.9258064009013929, ce=8.868146255894711
Local test acc @ epoch 123: 0.8449
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 3.158067192998715e-05
Local loss @ local epoch 1: 2.316972313565202e-05
Local loss @ local epoch 2: 3.2652733352733776e-05
Local loss @ local epoch 3: 2.2953334337216802e-05
Local loss @ local epoch 4: 1.8014470697380602e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.33 seconds!
[tester] 
AGNewsMetric: acc=0.8347368421052631, hinge=2.1806907437977037, ce=8.760928790443822
Local test acc @ epoch 123: 0.8347
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00010919272608589381
Local loss @ local epoch 1: 0.00016887535457499325
Local loss @ local epoch 2: 0.00038498282083310187
Local loss @ local epoch 3: 0.00302856951020658
Local loss @ local epoch 4: 0.0012916037812829018
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.67 seconds!
[tester] 
AGNewsMetric: acc=0.8563157894736843, hinge=1.8047568624898007, ce=9.618871829384252
Local test acc @ epoch 123: 0.8563
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0003387302567716688
Local loss @ local epoch 1: 0.0054469662718474865
Local loss @ local epoch 2: 0.0004333730321377516
Local loss @ local epoch 3: 0.012336847372353077
Local loss @ local epoch 4: 0.0009390313643962145
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.77 seconds!
[tester] 
AGNewsMetric: acc=0.8239473684210527, hinge=2.4011633142672086, ce=10.515903960780093
Local test acc @ epoch 123: 0.8239
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 8.076336598605849e-06
Local loss @ local epoch 1: 8.970346243586391e-06
Local loss @ local epoch 2: 8.538261681678705e-06
Local loss @ local epoch 3: 2.868905539799016e-05
Local loss @ local epoch 4: 0.0006476644775830209
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.58 seconds!
[tester] 
AGNewsMetric: acc=0.8565789473684211, hinge=1.9701430428655524, ce=8.835367080286929
Local test acc @ epoch 123: 0.8566
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00012071333185303956
Local loss @ local epoch 1: 0.005076538305729628
Local loss @ local epoch 2: 0.476249635219574
Local loss @ local epoch 3: 0.006764486897736788
Local loss @ local epoch 4: 0.2766452133655548
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.37 seconds!
[tester] 
AGNewsMetric: acc=0.8296052631578947, hinge=2.1605422396408884, ce=10.137115492569773
Local test acc @ epoch 123: 0.8296
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00027441445854492486
Local loss @ local epoch 1: 0.001230997615493834
Local loss @ local epoch 2: 0.0001495818141847849
Local loss @ local epoch 3: 0.0008269856916740537
Local loss @ local epoch 4: 0.006815584842115641
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.2 seconds!
[tester] 
AGNewsMetric: acc=0.7886842105263158, hinge=2.7964386365288183, ce=9.511248327556409
Local test acc @ epoch 123: 0.7887
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 7.42814336263109e-06
Local loss @ local epoch 1: 3.236162956454791e-05
Local loss @ local epoch 2: 2.07336252060486e-05
Local loss @ local epoch 3: 0.3405003547668457
Local loss @ local epoch 4: 3.639812348410487e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.59 seconds!
[tester] 
AGNewsMetric: acc=0.8465789473684211, hinge=2.0104256833227057, ce=8.4768705368042
Local test acc @ epoch 123: 0.8466
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 3.5051762097282335e-05
Local loss @ local epoch 1: 0.013724186457693577
Local loss @ local epoch 2: 0.0025986889377236366
Local loss @ local epoch 3: 0.006915983743965626
Local loss @ local epoch 4: 0.0035876051988452673
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 131.11 seconds!
[tester] 
AGNewsMetric: acc=0.7747368421052632, hinge=2.9315624372582687, ce=10.275824870059365
Local test acc @ epoch 123: 0.7747
Global evaluate on test data...
Evaluate data in 129.67 seconds!
[tester] 
AGNewsMetric: acc=0.8628947368421053, hinge=1.9339397621154786, ce=9.04425026140715
Global test acc @ epoch 123: 0.8629
Global epoch 124...
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 7.985051342984661e-05
Local loss @ local epoch 1: 1.2323052033025306e-05
Local loss @ local epoch 2: 0.00014911615289747715
Local loss @ local epoch 3: 0.00010315010149497539
Local loss @ local epoch 4: 0.0016921221977099776
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.7 seconds!
[tester] 
AGNewsMetric: acc=0.8275, hinge=2.394794744190417, ce=7.881020393371582
Local test acc @ epoch 124: 0.8275
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0006025500479154289
Local loss @ local epoch 1: 6.625155947403982e-05
Local loss @ local epoch 2: 0.22728170454502106
Local loss @ local epoch 3: 0.0005374756292439997
Local loss @ local epoch 4: 0.2355416864156723
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.09 seconds!
[tester] 
AGNewsMetric: acc=0.7978947368421052, hinge=2.7057441259685318, ce=9.875880841706929
Local test acc @ epoch 124: 0.7979
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0006048259674571455
Local loss @ local epoch 1: 0.670697808265686
Local loss @ local epoch 2: 0.013638528063893318
Local loss @ local epoch 3: 0.002111647743731737
Local loss @ local epoch 4: 0.0077179716899991035
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.24 seconds!
[tester] 
AGNewsMetric: acc=0.8519736842105263, hinge=1.7989417015878777, ce=10.034132252743369
Local test acc @ epoch 124: 0.852
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 8.596491534262896e-05
Local loss @ local epoch 1: 0.019432654604315758
Local loss @ local epoch 2: 0.0030283054802566767
Local loss @ local epoch 3: 0.00031413682154379785
Local loss @ local epoch 4: 0.0019185547716915607
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.93 seconds!
[tester] 
AGNewsMetric: acc=0.8293421052631579, hinge=1.9108631216852288, ce=9.650831752576327
Local test acc @ epoch 124: 0.8293
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0060678706504404545
Local loss @ local epoch 1: 2.7677711841533892e-05
Local loss @ local epoch 2: 0.005714454222470522
Local loss @ local epoch 3: 0.021215397864580154
Local loss @ local epoch 4: 0.0013880633050575852
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.3 seconds!
[tester] 
AGNewsMetric: acc=0.7232894736842105, hinge=3.9770772913882606, ce=11.711252893146716
Local test acc @ epoch 124: 0.7233
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0004376843571662903
Local loss @ local epoch 1: 0.00025045828078873456
Local loss @ local epoch 2: 0.0001229950285051018
Local loss @ local epoch 3: 0.0019000190077349544
Local loss @ local epoch 4: 0.14737306535243988
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.4 seconds!
[tester] 
AGNewsMetric: acc=0.7623684210526316, hinge=3.6768530057605946, ce=9.98438537196109
Local test acc @ epoch 124: 0.7624
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 6.500544986920431e-05
Local loss @ local epoch 1: 0.0002001782995648682
Local loss @ local epoch 2: 0.0024532147217541933
Local loss @ local epoch 3: 3.175720848958008e-05
Local loss @ local epoch 4: 5.841182064614259e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.48 seconds!
[tester] 
AGNewsMetric: acc=0.8314473684210526, hinge=2.3323899093427154, ce=9.024182907907587
Local test acc @ epoch 124: 0.8314
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 4.017239189124666e-05
Local loss @ local epoch 1: 0.0001480704522691667
Local loss @ local epoch 2: 8.112932118820027e-05
Local loss @ local epoch 3: 0.00012399765546433628
Local loss @ local epoch 4: 2.784893149510026e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.51 seconds!
[tester] 
AGNewsMetric: acc=0.8438157894736842, hinge=1.7961568654210944, ce=9.029088636699475
Local test acc @ epoch 124: 0.8438
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 3.840242061414756e-05
Local loss @ local epoch 1: 6.251010927371681e-05
Local loss @ local epoch 2: 0.0013998764334246516
Local loss @ local epoch 3: 7.501605432480574e-05
Local loss @ local epoch 4: 0.00018625763186719269
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.98 seconds!
[tester] 
AGNewsMetric: acc=0.8085526315789474, hinge=2.4760430411288614, ce=10.187474379288522
Local test acc @ epoch 124: 0.8086
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0008433260372839868
Local loss @ local epoch 1: 0.0005793354357592762
Local loss @ local epoch 2: 0.01604093797504902
Local loss @ local epoch 3: 0.0006189608247950673
Local loss @ local epoch 4: 0.002051242394372821
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.79 seconds!
[tester] 
AGNewsMetric: acc=0.8642105263157894, hinge=1.6570122743907727, ce=9.480398033543636
Local test acc @ epoch 124: 0.8642
Global evaluate on test data...
Evaluate data in 130.22 seconds!
[tester] 
AGNewsMetric: acc=0.8553947368421052, hinge=2.0115195146359897, ce=8.93037082270572
Global test acc @ epoch 124: 0.8554
Global epoch 125...
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00019901066843885928
Local loss @ local epoch 1: 0.0016159337246790528
Local loss @ local epoch 2: 2.316255631740205e-05
Local loss @ local epoch 3: 4.762832759297453e-05
Local loss @ local epoch 4: 0.0004130634479224682
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 131.21 seconds!
[tester] 
AGNewsMetric: acc=0.8257894736842105, hinge=2.4738333217721236, ce=10.428103204024465
Local test acc @ epoch 125: 0.8258
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.004504496697336435
Local loss @ local epoch 1: 0.00014991268108133227
Local loss @ local epoch 2: 0.0990055724978447
Local loss @ local epoch 3: 4.765713674714789e-05
Local loss @ local epoch 4: 0.029325058683753014
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.89 seconds!
[tester] 
AGNewsMetric: acc=0.8302631578947368, hinge=1.8246248516283536, ce=10.14062540154708
Local test acc @ epoch 125: 0.8303
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.06394616514444351
Local loss @ local epoch 1: 0.035143472254276276
Local loss @ local epoch 2: 0.03145062178373337
Local loss @ local epoch 3: 0.5023931264877319
Local loss @ local epoch 4: 0.00485442578792572
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.57 seconds!
[tester] 
AGNewsMetric: acc=0.8101315789473684, hinge=2.3007271166851644, ce=9.225292324266936
Local test acc @ epoch 125: 0.8101
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0008319094777107239
Local loss @ local epoch 1: 0.0009140275651589036
Local loss @ local epoch 2: 0.0005908010061830282
Local loss @ local epoch 3: 0.46928200125694275
Local loss @ local epoch 4: 0.00018922243907582015
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.69 seconds!
[tester] 
AGNewsMetric: acc=0.8351315789473684, hinge=2.2934812051371525, ce=10.387517344826145
Local test acc @ epoch 125: 0.8351
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 9.991070328396745e-06
Local loss @ local epoch 1: 0.00042730223503895104
Local loss @ local epoch 2: 1.8536578863859177e-05
Local loss @ local epoch 3: 6.211314757820219e-05
Local loss @ local epoch 4: 4.195461588096805e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.8 seconds!
[tester] 
AGNewsMetric: acc=0.8398684210526316, hinge=1.9584993909534656, ce=9.1365160309641
Local test acc @ epoch 125: 0.8399
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 2.5681534680188634e-05
Local loss @ local epoch 1: 1.4207367712515406e-05
Local loss @ local epoch 2: 0.29426735639572144
Local loss @ local epoch 3: 2.7528079954208806e-05
Local loss @ local epoch 4: 0.00026196485850960016
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.34 seconds!
[tester] 
AGNewsMetric: acc=0.8659210526315789, hinge=1.5550910349896079, ce=8.464851797003496
Local test acc @ epoch 125: 0.8659
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00010855554864974692
Local loss @ local epoch 1: 0.0032042895909398794
Local loss @ local epoch 2: 0.0022278176620602608
Local loss @ local epoch 3: 0.00011567639012355357
Local loss @ local epoch 4: 0.1051076278090477
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.69 seconds!
[tester] 
AGNewsMetric: acc=0.7731578947368422, hinge=3.0324836929220904, ce=9.236255264282226
Local test acc @ epoch 125: 0.7732
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4081047083891463e-05
Local loss @ local epoch 1: 7.517534413636895e-06
Local loss @ local epoch 2: 5.641940515488386e-05
Local loss @ local epoch 3: 4.664036168833263e-06
Local loss @ local epoch 4: 0.0012940648011863232
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.92 seconds!
[tester] 
AGNewsMetric: acc=0.8496052631578948, hinge=1.8920913314819336, ce=8.639482829445287
Local test acc @ epoch 125: 0.8496
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 8.410777809331194e-05
Local loss @ local epoch 1: 0.0052593122236430645
Local loss @ local epoch 2: 9.994189167628065e-05
Local loss @ local epoch 3: 0.00014622457092627883
Local loss @ local epoch 4: 0.0002534730010665953
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.45 seconds!
[tester] 
AGNewsMetric: acc=0.8165789473684211, hinge=2.617074263723273, ce=9.615935490256861
Local test acc @ epoch 125: 0.8166
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.010801025666296482
Local loss @ local epoch 1: 0.01064671017229557
Local loss @ local epoch 2: 0.0004021929926238954
Local loss @ local epoch 3: 0.3801932632923126
Local loss @ local epoch 4: 0.06316129118204117
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.09 seconds!
[tester] 
AGNewsMetric: acc=0.8007894736842105, hinge=2.6006872109362953, ce=9.44701398949874
Local test acc @ epoch 125: 0.8008
Global evaluate on test data...
Evaluate data in 130.38 seconds!
[tester] 
AGNewsMetric: acc=0.8596052631578948, hinge=2.0445752020886068, ce=9.03289266887464
Global test acc @ epoch 125: 0.8596
Global epoch 126...
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00036621326580643654
Local loss @ local epoch 1: 9.079877054318786e-05
Local loss @ local epoch 2: 0.516754150390625
Local loss @ local epoch 3: 0.0003552005218807608
Local loss @ local epoch 4: 0.04774188622832298
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.88 seconds!
[tester] 
AGNewsMetric: acc=0.8297368421052631, hinge=1.8734787915882312, ce=8.432903141222502
Local test acc @ epoch 126: 0.8297
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.010226457379758358
Local loss @ local epoch 1: 0.008148141205310822
Local loss @ local epoch 2: 0.0008147712214849889
Local loss @ local epoch 3: 0.2134498953819275
Local loss @ local epoch 4: 0.013480070047080517
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.35 seconds!
[tester] 
AGNewsMetric: acc=0.7514473684210526, hinge=3.154741978394358, ce=9.820731580633867
Local test acc @ epoch 126: 0.7514
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00025398595607839525
Local loss @ local epoch 1: 8.194865949917585e-05
Local loss @ local epoch 2: 0.02643844299018383
Local loss @ local epoch 3: 0.00014505902072414756
Local loss @ local epoch 4: 0.0005065464065410197
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.15 seconds!
[tester] 
AGNewsMetric: acc=0.8134210526315789, hinge=2.2599984347192863, ce=9.507759011921129
Local test acc @ epoch 126: 0.8134
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.019909542053937912
Local loss @ local epoch 1: 0.0002812528400681913
Local loss @ local epoch 2: 0.04143914952874184
Local loss @ local epoch 3: 0.0260915569961071
Local loss @ local epoch 4: 0.09868686646223068
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.31 seconds!
[tester] 
AGNewsMetric: acc=0.741578947368421, hinge=3.171932207659671, ce=9.565712730006167
Local test acc @ epoch 126: 0.7416
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.012002693489193916
Local loss @ local epoch 1: 1.3068084626866039e-05
Local loss @ local epoch 2: 0.0015128921950235963
Local loss @ local epoch 3: 0.0021831863559782505
Local loss @ local epoch 4: 0.025350261479616165
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.18 seconds!
[tester] 
AGNewsMetric: acc=0.8211842105263157, hinge=2.256567995673732, ce=7.922641376696135
Local test acc @ epoch 126: 0.8212
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 4.217006789986044e-06
Local loss @ local epoch 1: 8.396513294428587e-06
Local loss @ local epoch 2: 0.00013338406279217452
Local loss @ local epoch 3: 4.232121864333749e-05
Local loss @ local epoch 4: 0.0009715651394799352
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.83 seconds!
[tester] 
AGNewsMetric: acc=0.8231578947368421, hinge=2.4715021314119037, ce=8.905647524783486
Local test acc @ epoch 126: 0.8232
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 1.339588561677374e-05
Local loss @ local epoch 1: 9.700508599053137e-06
Local loss @ local epoch 2: 0.0019886966329067945
Local loss @ local epoch 3: 5.331783177098259e-05
Local loss @ local epoch 4: 0.21283766627311707
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.73 seconds!
[tester] 
AGNewsMetric: acc=0.8447368421052631, hinge=2.1387929688001934, ce=9.415277199996146
Local test acc @ epoch 126: 0.8447
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 2.8370070140226744e-05
Local loss @ local epoch 1: 1.6308416888932697e-05
Local loss @ local epoch 2: 0.00011143589654238895
Local loss @ local epoch 3: 0.00012290877930354327
Local loss @ local epoch 4: 0.0008002729737199843
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.18 seconds!
[tester] 
AGNewsMetric: acc=0.7538157894736842, hinge=3.6045558314574393, ce=10.48767366308915
Local test acc @ epoch 126: 0.7538
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 9.558887541061267e-06
Local loss @ local epoch 1: 3.74350966012571e-05
Local loss @ local epoch 2: 4.373463070805883e-06
Local loss @ local epoch 3: 6.190803833305836e-05
Local loss @ local epoch 4: 0.0004969145520590246
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.16 seconds!
[tester] 
AGNewsMetric: acc=0.8423684210526315, hinge=2.2943106849570025, ce=8.47155034516987
Local test acc @ epoch 126: 0.8424
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 2.167308957723435e-05
Local loss @ local epoch 1: 7.26041616871953e-05
Local loss @ local epoch 2: 2.4047896658885293e-05
Local loss @ local epoch 3: 0.00015524034097325057
Local loss @ local epoch 4: 1.1458699191280175e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.49 seconds!
[tester] 
AGNewsMetric: acc=0.8517105263157895, hinge=1.9511781945981477, ce=9.314039274516858
Local test acc @ epoch 126: 0.8517
Global evaluate on test data...
Evaluate data in 130.23 seconds!
[tester] 
AGNewsMetric: acc=0.849078947368421, hinge=2.147639765237507, ce=8.684963222302889
Global test acc @ epoch 126: 0.8491
Global epoch 127...
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0006532660918310285
Local loss @ local epoch 1: 0.0005808749701827765
Local loss @ local epoch 2: 0.00034037468140013516
Local loss @ local epoch 3: 0.0007690550992265344
Local loss @ local epoch 4: 0.00256900186650455
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.29 seconds!
[tester] 
AGNewsMetric: acc=0.8001315789473684, hinge=2.806867938292654, ce=9.552970149391577
Local test acc @ epoch 127: 0.8001
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0075681619346141815
Local loss @ local epoch 1: 0.0021363748237490654
Local loss @ local epoch 2: 0.000560722837690264
Local loss @ local epoch 3: 0.007634823676198721
Local loss @ local epoch 4: 0.04007558152079582
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.16 seconds!
[tester] 
AGNewsMetric: acc=0.7617105263157895, hinge=3.1948207827618247, ce=8.576417529457494
Local test acc @ epoch 127: 0.7617
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 5.662851617671549e-05
Local loss @ local epoch 1: 0.0112939877435565
Local loss @ local epoch 2: 0.011591440066695213
Local loss @ local epoch 3: 0.03349238261580467
Local loss @ local epoch 4: 0.0013172730104997754
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.7 seconds!
[tester] 
AGNewsMetric: acc=0.8403947368421053, hinge=2.044476503321999, ce=8.208177319576865
Local test acc @ epoch 127: 0.8404
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.000628673704341054
Local loss @ local epoch 1: 0.002819541608914733
Local loss @ local epoch 2: 0.015128805302083492
Local loss @ local epoch 3: 0.003661135910078883
Local loss @ local epoch 4: 1.4370105266571045
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.19 seconds!
[tester] 
AGNewsMetric: acc=0.8230263157894737, hinge=2.191831387469643, ce=9.295279779936138
Local test acc @ epoch 127: 0.823
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0009885376784950495
Local loss @ local epoch 1: 0.00014029021258465946
Local loss @ local epoch 2: 0.06555424630641937
Local loss @ local epoch 3: 0.04651322215795517
Local loss @ local epoch 4: 0.00011286351218586788
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.31 seconds!
[tester] 
AGNewsMetric: acc=0.8285526315789473, hinge=2.5129592850333764, ce=10.317277715582597
Local test acc @ epoch 127: 0.8286
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 6.601134373340756e-06
Local loss @ local epoch 1: 1.4267118785937782e-05
Local loss @ local epoch 2: 4.3319727410562336e-05
Local loss @ local epoch 3: 0.00027635940932668746
Local loss @ local epoch 4: 3.7790145142935216e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.42 seconds!
[tester] 
AGNewsMetric: acc=0.8389473684210527, hinge=2.183605102237902, ce=8.722400249681975
Local test acc @ epoch 127: 0.8389
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 2.4137787477229722e-05
Local loss @ local epoch 1: 3.3974461075558793e-06
Local loss @ local epoch 2: 8.250866085290909e-05
Local loss @ local epoch 3: 0.0003118173044640571
Local loss @ local epoch 4: 6.014171231072396e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.82 seconds!
[tester] 
AGNewsMetric: acc=0.8472368421052632, hinge=1.935103769553335, ce=8.73820330368845
Local test acc @ epoch 127: 0.8472
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00013750586367677897
Local loss @ local epoch 1: 6.597891479032114e-05
Local loss @ local epoch 2: 0.31128546595573425
Local loss @ local epoch 3: 0.0021953408140689135
Local loss @ local epoch 4: 0.002591585274785757
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.89 seconds!
[tester] 
AGNewsMetric: acc=0.6359210526315789, hinge=6.637110930994937, ce=12.731557665373149
Local test acc @ epoch 127: 0.6359
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 1.2092084944015369e-05
Local loss @ local epoch 1: 2.9726488719461486e-05
Local loss @ local epoch 2: 6.568233948200941e-05
Local loss @ local epoch 3: 0.00029755342984572053
Local loss @ local epoch 4: 0.0018154344288632274
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.01 seconds!
[tester] 
AGNewsMetric: acc=0.8330263157894737, hinge=2.362177717309249, ce=9.628515195344624
Local test acc @ epoch 127: 0.833
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 1.3150012819096446e-05
Local loss @ local epoch 1: 1.0974292308674194e-05
Local loss @ local epoch 2: 3.402210131753236e-05
Local loss @ local epoch 3: 3.55304655386135e-05
Local loss @ local epoch 4: 2.454116111039184e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 131.06 seconds!
[tester] 
AGNewsMetric: acc=0.855, hinge=1.7515820821962858, ce=9.4853031539917
Local test acc @ epoch 127: 0.855
Global evaluate on test data...
Evaluate data in 130.46 seconds!
[tester] 
AGNewsMetric: acc=0.8582894736842105, hinge=2.111280927909048, ce=8.76608403256065
Global test acc @ epoch 127: 0.8583
Global epoch 128...
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 4.991852620150894e-06
Local loss @ local epoch 1: 1.966124546015635e-05
Local loss @ local epoch 2: 0.00026575414813123643
Local loss @ local epoch 3: 1.7434319943276932e-06
Local loss @ local epoch 4: 0.00046129676047712564
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.57 seconds!
[tester] 
AGNewsMetric: acc=0.8588157894736842, hinge=1.8895203500044973, ce=9.347121859098735
Local test acc @ epoch 128: 0.8588
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00014086383453104645
Local loss @ local epoch 1: 0.005837142933160067
Local loss @ local epoch 2: 4.074270691489801e-05
Local loss @ local epoch 3: 0.0005062658456154168
Local loss @ local epoch 4: 0.0025556618347764015
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.05 seconds!
[tester] 
AGNewsMetric: acc=0.795, hinge=2.582151666691429, ce=10.56535260652241
Local test acc @ epoch 128: 0.795
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 4.4060725485906005e-05
Local loss @ local epoch 1: 0.11046461015939713
Local loss @ local epoch 2: 4.311985685490072e-05
Local loss @ local epoch 3: 0.0007613650523126125
Local loss @ local epoch 4: 0.0067923953756690025
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.45 seconds!
[tester] 
AGNewsMetric: acc=0.7996052631578947, hinge=2.50131101558083, ce=10.46979168139006
Local test acc @ epoch 128: 0.7996
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0004685845342464745
Local loss @ local epoch 1: 0.4069618284702301
Local loss @ local epoch 2: 0.0021719259675592184
Local loss @ local epoch 3: 0.27121177315711975
Local loss @ local epoch 4: 0.0950133353471756
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.42 seconds!
[tester] 
AGNewsMetric: acc=0.7956578947368421, hinge=2.5133213555185416, ce=7.873068110817357
Local test acc @ epoch 128: 0.7957
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.003005924168974161
Local loss @ local epoch 1: 0.00032878376077860594
Local loss @ local epoch 2: 0.0013149997685104609
Local loss @ local epoch 3: 0.13170765340328217
Local loss @ local epoch 4: 0.011436286382377148
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.86 seconds!
[tester] 
AGNewsMetric: acc=0.8243421052631579, hinge=2.2517309349461607, ce=9.128353351793791
Local test acc @ epoch 128: 0.8243
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 8.11363133834675e-06
Local loss @ local epoch 1: 3.4007134672719985e-05
Local loss @ local epoch 2: 2.051831870630849e-05
Local loss @ local epoch 3: 0.04322754591703415
Local loss @ local epoch 4: 0.023786399513483047
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.14 seconds!
[tester] 
AGNewsMetric: acc=0.845, hinge=2.281786658638402, ce=10.072025612278988
Local test acc @ epoch 128: 0.845
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 5.431439149106154e-06
Local loss @ local epoch 1: 1.6583697288297117e-05
Local loss @ local epoch 2: 6.452014986280119e-06
Local loss @ local epoch 3: 6.450690125348046e-05
Local loss @ local epoch 4: 6.908664363436401e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.05 seconds!
[tester] 
AGNewsMetric: acc=0.7596052631578948, hinge=4.183628699654027, ce=10.209068533244887
Local test acc @ epoch 128: 0.7596
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 3.4043674531858414e-05
Local loss @ local epoch 1: 0.19223009049892426
Local loss @ local epoch 2: 9.121301263803616e-05
Local loss @ local epoch 3: 0.297857403755188
Local loss @ local epoch 4: 0.0034219406079500914
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.18 seconds!
[tester] 
AGNewsMetric: acc=0.7980263157894737, hinge=2.7840106341713353, ce=10.297997302005166
Local test acc @ epoch 128: 0.798
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00036998442374169827
Local loss @ local epoch 1: 0.8253753781318665
Local loss @ local epoch 2: 0.0006285515846684575
Local loss @ local epoch 3: 0.1669190675020218
Local loss @ local epoch 4: 0.42767125368118286
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.83 seconds!
[tester] 
AGNewsMetric: acc=0.8185526315789474, hinge=2.4993492713727448, ce=9.591348294709858
Local test acc @ epoch 128: 0.8186
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00034504663199186325
Local loss @ local epoch 1: 0.0023690415546298027
Local loss @ local epoch 2: 0.0006288958247750998
Local loss @ local epoch 3: 0.3773246705532074
Local loss @ local epoch 4: 0.0003701508976519108
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.54 seconds!
[tester] 
AGNewsMetric: acc=0.8093421052631579, hinge=2.5122884195729305, ce=8.799239475852564
Local test acc @ epoch 128: 0.8093
Global evaluate on test data...
Evaluate data in 129.52 seconds!
[tester] 
AGNewsMetric: acc=0.8577631578947369, hinge=2.07306531655161, ce=8.994264168990286
Global test acc @ epoch 128: 0.8578
Global epoch 129...
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00012218303163535893
Local loss @ local epoch 1: 0.0007007837994024158
Local loss @ local epoch 2: 0.001536717638373375
Local loss @ local epoch 3: 0.00010492004366824403
Local loss @ local epoch 4: 0.00028993768501095474
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.14 seconds!
[tester] 
AGNewsMetric: acc=0.8193421052631579, hinge=2.813363020545558, ce=9.376047640348736
Local test acc @ epoch 129: 0.8193
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0036704507656395435
Local loss @ local epoch 1: 0.0031554787419736385
Local loss @ local epoch 2: 8.49311109050177e-05
Local loss @ local epoch 3: 0.0026850616559386253
Local loss @ local epoch 4: 0.01125304400920868
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.18 seconds!
[tester] 
AGNewsMetric: acc=0.8063157894736842, hinge=2.539496783457304, ce=9.16509001280132
Local test acc @ epoch 129: 0.8063
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 1.2032363883918151e-05
Local loss @ local epoch 1: 7.4951622082153335e-06
Local loss @ local epoch 2: 1.3775535080640111e-05
Local loss @ local epoch 3: 0.005461155436933041
Local loss @ local epoch 4: 0.00494740204885602
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.22 seconds!
[tester] 
AGNewsMetric: acc=0.8261842105263157, hinge=2.1754229841734234, ce=9.291864407188013
Local test acc @ epoch 129: 0.8262
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00032868050038814545
Local loss @ local epoch 1: 0.0005582085577771068
Local loss @ local epoch 2: 0.0014175676042214036
Local loss @ local epoch 3: 0.00025936748716048896
Local loss @ local epoch 4: 0.001479941071011126
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.08 seconds!
[tester] 
AGNewsMetric: acc=0.8427631578947369, hinge=1.910249568286695, ce=8.25014499061986
Local test acc @ epoch 129: 0.8428
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0001377668377244845
Local loss @ local epoch 1: 0.00011729461402865127
Local loss @ local epoch 2: 2.9040755180176347e-05
Local loss @ local epoch 3: 0.0001640181289985776
Local loss @ local epoch 4: 0.0007587607251480222
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.01 seconds!
[tester] 
AGNewsMetric: acc=0.854078947368421, hinge=1.8666134121543483, ce=8.628088021529349
Local test acc @ epoch 129: 0.8541
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 2.9611830541398376e-05
Local loss @ local epoch 1: 1.4080878827371635e-05
Local loss @ local epoch 2: 0.0032013943418860435
Local loss @ local epoch 3: 0.0008951062336564064
Local loss @ local epoch 4: 6.899864820297807e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.6 seconds!
[tester] 
AGNewsMetric: acc=0.8268421052631579, hinge=2.306179801288404, ce=9.034544693796258
Local test acc @ epoch 129: 0.8268
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 1.5391990018542856e-05
Local loss @ local epoch 1: 4.915749013889581e-05
Local loss @ local epoch 2: 0.0035170891787856817
Local loss @ local epoch 3: 3.641224975581281e-05
Local loss @ local epoch 4: 0.0018179549369961023
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.24 seconds!
[tester] 
AGNewsMetric: acc=0.8257894736842105, hinge=2.647779923740186, ce=9.345402344151546
Local test acc @ epoch 129: 0.8258
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 1.6569692888879217e-05
Local loss @ local epoch 1: 7.116617052815855e-05
Local loss @ local epoch 2: 0.00012022245937259868
Local loss @ local epoch 3: 1.9184095435775816e-05
Local loss @ local epoch 4: 0.027460258454084396
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.13 seconds!
[tester] 
AGNewsMetric: acc=0.8305263157894737, hinge=2.439235328624123, ce=8.533873072172467
Local test acc @ epoch 129: 0.8305
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00021966014173813164
Local loss @ local epoch 1: 0.0003536085714586079
Local loss @ local epoch 2: 0.00017801154172047973
Local loss @ local epoch 3: 0.002235853811725974
Local loss @ local epoch 4: 0.30336204171180725
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.46 seconds!
[tester] 
AGNewsMetric: acc=0.8376315789473684, hinge=2.2163725634625084, ce=7.530422074167352
Local test acc @ epoch 129: 0.8376
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.012784143909811974
Local loss @ local epoch 1: 0.010003902018070221
Local loss @ local epoch 2: 0.019292185083031654
Local loss @ local epoch 3: 0.0013148075668141246
Local loss @ local epoch 4: 0.3521770238876343
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.6 seconds!
[tester] 
AGNewsMetric: acc=0.8536842105263158, hinge=1.8144672315999082, ce=9.078770796123305
Local test acc @ epoch 129: 0.8537
Global evaluate on test data...
Evaluate data in 130.05 seconds!
[tester] 
AGNewsMetric: acc=0.8531578947368421, hinge=2.1986743527964543, ce=8.718499173616108
Global test acc @ epoch 129: 0.8532
Global epoch 130...
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0002551740035414696
Local loss @ local epoch 1: 3.721212488017045e-05
Local loss @ local epoch 2: 0.327346533536911
Local loss @ local epoch 3: 0.0012088109506294131
Local loss @ local epoch 4: 0.014636619947850704
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.96 seconds!
[tester] 
AGNewsMetric: acc=0.8013157894736842, hinge=2.7991554834968166, ce=9.565487907811216
Local test acc @ epoch 130: 0.8013
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 5.997667813062435e-06
Local loss @ local epoch 1: 1.1019043995474931e-05
Local loss @ local epoch 2: 6.64954714011401e-05
Local loss @ local epoch 3: 7.450469638570212e-06
Local loss @ local epoch 4: 3.52441165887285e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.1 seconds!
[tester] 
AGNewsMetric: acc=0.841842105263158, hinge=1.9887286919041685, ce=8.782562737715871
Local test acc @ epoch 130: 0.8418
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 6.0424648836487904e-05
Local loss @ local epoch 1: 0.0007932063890621066
Local loss @ local epoch 2: 0.0002945503802038729
Local loss @ local epoch 3: 0.7245948314666748
Local loss @ local epoch 4: 0.008577458560466766
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.75 seconds!
[tester] 
AGNewsMetric: acc=0.8439473684210527, hinge=2.0294279402180724, ce=8.827627641778243
Local test acc @ epoch 130: 0.8439
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 7.502662811020855e-06
Local loss @ local epoch 1: 2.4719262000871822e-05
Local loss @ local epoch 2: 1.2486825653468259e-05
Local loss @ local epoch 3: 0.00013498282351065427
Local loss @ local epoch 4: 4.896500468021259e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.16 seconds!
[tester] 
AGNewsMetric: acc=0.8281578947368421, hinge=2.2963826119272333, ce=9.626301301655017
Local test acc @ epoch 130: 0.8282
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00019676402735058218
Local loss @ local epoch 1: 6.0714057326549664e-05
Local loss @ local epoch 2: 0.0005043214187026024
Local loss @ local epoch 3: 0.003539521247148514
Local loss @ local epoch 4: 0.0004000698681920767
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.25 seconds!
[tester] 
AGNewsMetric: acc=0.8463157894736842, hinge=2.1917614163850483, ce=9.856581746151573
Local test acc @ epoch 130: 0.8463
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.009206444956362247
Local loss @ local epoch 1: 0.00010443553037475795
Local loss @ local epoch 2: 0.00041377413435839117
Local loss @ local epoch 3: 4.908041955786757e-05
Local loss @ local epoch 4: 0.001132338191382587
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.13 seconds!
[tester] 
AGNewsMetric: acc=0.8496052631578948, hinge=1.8444761881075407, ce=8.677172562448602
Local test acc @ epoch 130: 0.8496
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00018241669749841094
Local loss @ local epoch 1: 0.8921113610267639
Local loss @ local epoch 2: 6.250390288187191e-05
Local loss @ local epoch 3: 0.00018291911692358553
Local loss @ local epoch 4: 0.0025766759645193815
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.45 seconds!
[tester] 
AGNewsMetric: acc=0.8410526315789474, hinge=1.7159609076851292, ce=9.571740303039551
Local test acc @ epoch 130: 0.8411
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00015786387666594237
Local loss @ local epoch 1: 0.00030391255859285593
Local loss @ local epoch 2: 0.5932527184486389
Local loss @ local epoch 3: 0.00039383856346830726
Local loss @ local epoch 4: 8.176716073649004e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.77 seconds!
[tester] 
AGNewsMetric: acc=0.8346052631578947, hinge=2.1554318852173653, ce=9.250701408386231
Local test acc @ epoch 130: 0.8346
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 1.1011625247192569e-05
Local loss @ local epoch 1: 1.1868495676026214e-05
Local loss @ local epoch 2: 1.0825414392456878e-05
Local loss @ local epoch 3: 4.842197449761443e-05
Local loss @ local epoch 4: 0.14220130443572998
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.01 seconds!
[tester] 
AGNewsMetric: acc=0.8438157894736842, hinge=2.2458850313487804, ce=8.703851089477538
Local test acc @ epoch 130: 0.8438
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 1.1399041795812082e-05
Local loss @ local epoch 1: 4.286956391297281e-05
Local loss @ local epoch 2: 0.021586040034890175
Local loss @ local epoch 3: 0.00016911621787585318
Local loss @ local epoch 4: 0.001745677087455988
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.98 seconds!
[tester] 
AGNewsMetric: acc=0.6853947368421053, hinge=7.24510357003463, ce=11.205547613846628
Local test acc @ epoch 130: 0.6854
Global evaluate on test data...
Evaluate data in 130.31 seconds!
[tester] 
AGNewsMetric: acc=0.8576315789473684, hinge=2.1910173247989855, ce=8.673769380669844
Global test acc @ epoch 130: 0.8576
Global epoch 131...
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 1.814114693843294e-05
Local loss @ local epoch 1: 4.0978034121508244e-06
Local loss @ local epoch 2: 1.9876973965438083e-05
Local loss @ local epoch 3: 0.02821681834757328
Local loss @ local epoch 4: 0.0005187076167203486
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.62 seconds!
[tester] 
AGNewsMetric: acc=0.8486842105263158, hinge=2.093665466559561, ce=8.75353218680934
Local test acc @ epoch 131: 0.8487
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.48115143179893494
Local loss @ local epoch 1: 0.0022759651765227318
Local loss @ local epoch 2: 0.023141559213399887
Local loss @ local epoch 3: 0.04909015819430351
Local loss @ local epoch 4: 0.011727195233106613
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.89 seconds!
[tester] 
AGNewsMetric: acc=0.8409210526315789, hinge=1.6717701653430337, ce=9.379131556059185
Local test acc @ epoch 131: 0.8409
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00011601326696109027
Local loss @ local epoch 1: 0.0003466517955530435
Local loss @ local epoch 2: 0.0006231233710423112
Local loss @ local epoch 3: 0.0809425488114357
Local loss @ local epoch 4: 8.406736014876515e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.43 seconds!
[tester] 
AGNewsMetric: acc=0.8023684210526316, hinge=2.5353520659396525, ce=9.832519298352693
Local test acc @ epoch 131: 0.8024
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 5.558071734412806e-06
Local loss @ local epoch 1: 7.078391354298219e-05
Local loss @ local epoch 2: 6.250970727705862e-06
Local loss @ local epoch 3: 0.00022010617249179631
Local loss @ local epoch 4: 1.411817629559664e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.45 seconds!
[tester] 
AGNewsMetric: acc=0.8052631578947368, hinge=2.625628574772885, ce=8.636454112404271
Local test acc @ epoch 131: 0.8053
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 6.362790009006858e-05
Local loss @ local epoch 1: 0.00336063071154058
Local loss @ local epoch 2: 0.000112660534796305
Local loss @ local epoch 3: 0.0009447598713450134
Local loss @ local epoch 4: 0.8118810057640076
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.68 seconds!
[tester] 
AGNewsMetric: acc=0.8459210526315789, hinge=2.2628142763438976, ce=9.360162329422801
Local test acc @ epoch 131: 0.8459
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 2.2036792870494537e-05
Local loss @ local epoch 1: 9.160774061456323e-05
Local loss @ local epoch 2: 0.00011026568245142698
Local loss @ local epoch 3: 0.007269338238984346
Local loss @ local epoch 4: 0.00010017496242653579
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.21 seconds!
[tester] 
AGNewsMetric: acc=0.855, hinge=1.927065198045028, ce=9.25053690860146
Local test acc @ epoch 131: 0.855
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0005806534318253398
Local loss @ local epoch 1: 0.0012751631438732147
Local loss @ local epoch 2: 0.007434182800352573
Local loss @ local epoch 3: 0.0021452009677886963
Local loss @ local epoch 4: 0.08384764939546585
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.29 seconds!
[tester] 
AGNewsMetric: acc=0.8018421052631579, hinge=2.916810323815597, ce=9.313121767546
Local test acc @ epoch 131: 0.8018
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 2.1954836483928375e-05
Local loss @ local epoch 1: 1.6651512851240113e-05
Local loss @ local epoch 2: 4.901772990706377e-05
Local loss @ local epoch 3: 7.62184345148853e-06
Local loss @ local epoch 4: 0.00016368436627089977
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.46 seconds!
[tester] 
AGNewsMetric: acc=0.8531578947368421, hinge=2.159735907253466, ce=9.003646047491776
Local test acc @ epoch 131: 0.8532
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 7.100249604263809e-06
Local loss @ local epoch 1: 0.001256509916856885
Local loss @ local epoch 2: 1.8908576748799533e-05
Local loss @ local epoch 3: 0.02292470820248127
Local loss @ local epoch 4: 0.00011352699948474765
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.66 seconds!
[tester] 
AGNewsMetric: acc=0.8497368421052631, hinge=2.136260589298449, ce=8.883806051956979
Local test acc @ epoch 131: 0.8497
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 9.626860992284492e-05
Local loss @ local epoch 1: 0.030858714133501053
Local loss @ local epoch 2: 0.00010307903721695766
Local loss @ local epoch 3: 0.20346291363239288
Local loss @ local epoch 4: 0.0004314251127652824
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.28 seconds!
[tester] 
AGNewsMetric: acc=0.7848684210526315, hinge=3.167628291531613, ce=9.631091908906635
Local test acc @ epoch 131: 0.7849
Global evaluate on test data...
Evaluate data in 129.78 seconds!
[tester] 
AGNewsMetric: acc=0.8573684210526316, hinge=2.1669644463689703, ce=8.58524962575812
Global test acc @ epoch 131: 0.8574
Global epoch 132...
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 1.2330163372098468e-05
Local loss @ local epoch 1: 4.775773049914278e-06
Local loss @ local epoch 2: 3.837023541564122e-06
Local loss @ local epoch 3: 2.7915544706047513e-05
Local loss @ local epoch 4: 7.4505028351268265e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.84 seconds!
[tester] 
AGNewsMetric: acc=0.8335526315789473, hinge=2.4948096026872335, ce=8.870573513633326
Local test acc @ epoch 132: 0.8336
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 1.075085765478434e-05
Local loss @ local epoch 1: 1.310519473918248e-05
Local loss @ local epoch 2: 1.3917192518420052e-05
Local loss @ local epoch 3: 4.920595165458508e-05
Local loss @ local epoch 4: 7.033160363789648e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.58 seconds!
[tester] 
AGNewsMetric: acc=0.8198684210526316, hinge=2.5708239964434974, ce=8.933168314883584
Local test acc @ epoch 132: 0.8199
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 2.648397821758408e-05
Local loss @ local epoch 1: 0.00018473481759428978
Local loss @ local epoch 2: 0.019580209627747536
Local loss @ local epoch 3: 0.018408115953207016
Local loss @ local epoch 4: 0.0007867194944992661
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.81 seconds!
[tester] 
AGNewsMetric: acc=0.8226315789473684, hinge=2.4327050083561947, ce=9.9919357600965
Local test acc @ epoch 132: 0.8226
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00021488501806743443
Local loss @ local epoch 1: 0.00016901633352972567
Local loss @ local epoch 2: 0.3732717037200928
Local loss @ local epoch 3: 0.0004032901197206229
Local loss @ local epoch 4: 0.051849622279405594
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.39 seconds!
[tester] 
AGNewsMetric: acc=0.8296052631578947, hinge=2.196387527992851, ce=9.485773530257376
Local test acc @ epoch 132: 0.8296
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.004535673651844263
Local loss @ local epoch 1: 0.0001474830787628889
Local loss @ local epoch 2: 0.0030982012394815683
Local loss @ local epoch 3: 0.00048449228052049875
Local loss @ local epoch 4: 0.0029818250332027674
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.47 seconds!
[tester] 
AGNewsMetric: acc=0.78, hinge=2.4517639539116307, ce=9.557924876965975
Local test acc @ epoch 132: 0.78
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 6.161544661154039e-06
Local loss @ local epoch 1: 0.002796929795295
Local loss @ local epoch 2: 0.00016844624769873917
Local loss @ local epoch 3: 0.00017850690346676856
Local loss @ local epoch 4: 0.00010095669131260365
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.74 seconds!
[tester] 
AGNewsMetric: acc=0.8114473684210526, hinge=2.6263345025715075, ce=8.374227676391602
Local test acc @ epoch 132: 0.8114
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 1.9593431716202758e-05
Local loss @ local epoch 1: 0.00012153938587289304
Local loss @ local epoch 2: 0.000269490759819746
Local loss @ local epoch 3: 0.00012422847794368863
Local loss @ local epoch 4: 3.75430790882092e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.96 seconds!
[tester] 
AGNewsMetric: acc=0.8496052631578948, hinge=2.0923631324266134, ce=8.35358630330939
Local test acc @ epoch 132: 0.8496
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00010821351315826178
Local loss @ local epoch 1: 0.002696150913834572
Local loss @ local epoch 2: 3.9170965465018526e-05
Local loss @ local epoch 3: 0.0032006639521569014
Local loss @ local epoch 4: 0.0011355149326846004
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.62 seconds!
[tester] 
AGNewsMetric: acc=0.766578947368421, hinge=3.1945771664067317, ce=8.748437991895173
Local test acc @ epoch 132: 0.7666
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 3.510423266561702e-05
Local loss @ local epoch 1: 0.0006006090552546084
Local loss @ local epoch 2: 0.00032310644746758044
Local loss @ local epoch 3: 0.4382113516330719
Local loss @ local epoch 4: 0.003573949448764324
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.64 seconds!
[tester] 
AGNewsMetric: acc=0.733421052631579, hinge=3.503065044001529, ce=10.345086533395868
Local test acc @ epoch 132: 0.7334
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 6.752808258170262e-05
Local loss @ local epoch 1: 0.0019962703809142113
Local loss @ local epoch 2: 0.002005795482546091
Local loss @ local epoch 3: 0.06278610974550247
Local loss @ local epoch 4: 0.2162507027387619
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.23 seconds!
[tester] 
AGNewsMetric: acc=0.8361842105263158, hinge=2.5205446150428372, ce=10.440731221249228
Local test acc @ epoch 132: 0.8362
Global evaluate on test data...
Evaluate data in 129.58 seconds!
[tester] 
AGNewsMetric: acc=0.8551315789473685, hinge=2.1772034557242144, ce=8.73526394693475
Global test acc @ epoch 132: 0.8551
Global epoch 133...
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 3.8072105326136807e-06
Local loss @ local epoch 1: 4.3245436245342717e-05
Local loss @ local epoch 2: 5.908231742068892e-06
Local loss @ local epoch 3: 1.8417347746435553e-05
Local loss @ local epoch 4: 0.0086875781416893
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.28 seconds!
[tester] 
AGNewsMetric: acc=0.8473684210526315, hinge=2.149252246555529, ce=8.564245593422337
Local test acc @ epoch 133: 0.8474
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 7.964529686432797e-06
Local loss @ local epoch 1: 3.505935819703154e-05
Local loss @ local epoch 2: 1.2255837646080181e-05
Local loss @ local epoch 3: 7.681449460505974e-06
Local loss @ local epoch 4: 3.290298627689481e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.44 seconds!
[tester] 
AGNewsMetric: acc=0.8261842105263157, hinge=2.643916761749669, ce=9.100743518628573
Local test acc @ epoch 133: 0.8262
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 7.956967237987556e-06
Local loss @ local epoch 1: 0.0001732704695314169
Local loss @ local epoch 2: 1.3246792150312103e-05
Local loss @ local epoch 3: 9.51357651501894e-05
Local loss @ local epoch 4: 0.03194890543818474
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.42 seconds!
[tester] 
AGNewsMetric: acc=0.8157894736842105, hinge=2.336014256226389, ce=7.788825217799136
Local test acc @ epoch 133: 0.8158
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.010555349290370941
Local loss @ local epoch 1: 0.010402902029454708
Local loss @ local epoch 2: 0.11126821488142014
Local loss @ local epoch 3: 0.0010338530410081148
Local loss @ local epoch 4: 0.004485839977860451
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.4 seconds!
[tester] 
AGNewsMetric: acc=0.819078947368421, hinge=2.3197813955106232, ce=8.579344094928942
Local test acc @ epoch 133: 0.8191
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.004063330125063658
Local loss @ local epoch 1: 0.035020697861909866
Local loss @ local epoch 2: 0.006112094968557358
Local loss @ local epoch 3: 0.0007554855546914041
Local loss @ local epoch 4: 0.00030586670618504286
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.1 seconds!
[tester] 
AGNewsMetric: acc=0.8360526315789474, hinge=2.3684292938834743, ce=9.426060686613384
Local test acc @ epoch 133: 0.8361
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0003054812550544739
Local loss @ local epoch 1: 9.768126619746909e-05
Local loss @ local epoch 2: 0.004443164449185133
Local loss @ local epoch 3: 0.00016544919344596565
Local loss @ local epoch 4: 2.519565350667108e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.39 seconds!
[tester] 
AGNewsMetric: acc=0.828421052631579, hinge=2.330889459409212, ce=9.059228573849326
Local test acc @ epoch 133: 0.8284
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00014032723265700042
Local loss @ local epoch 1: 0.02515563927590847
Local loss @ local epoch 2: 5.573768794420175e-05
Local loss @ local epoch 3: 0.2459540218114853
Local loss @ local epoch 4: 0.9721636176109314
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.63 seconds!
[tester] 
AGNewsMetric: acc=0.7127631578947369, hinge=4.424686206014533, ce=10.528218480160362
Local test acc @ epoch 133: 0.7128
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00016496329044457525
Local loss @ local epoch 1: 0.001094955950975418
Local loss @ local epoch 2: 0.08067364245653152
Local loss @ local epoch 3: 0.0023158162366598845
Local loss @ local epoch 4: 0.04776996001601219
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.97 seconds!
[tester] 
AGNewsMetric: acc=0.8189473684210526, hinge=2.440574073038603, ce=9.499002326162238
Local test acc @ epoch 133: 0.8189
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0010337610729038715
Local loss @ local epoch 1: 0.06248588114976883
Local loss @ local epoch 2: 2.8586773623828776e-05
Local loss @ local epoch 3: 0.0002990673528984189
Local loss @ local epoch 4: 0.0001255042152479291
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.06 seconds!
[tester] 
AGNewsMetric: acc=0.8252631578947368, hinge=2.429365346055282, ce=9.526506837543689
Local test acc @ epoch 133: 0.8253
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 1.1726576303772163e-05
Local loss @ local epoch 1: 1.7805916286306456e-05
Local loss @ local epoch 2: 2.2954101950745098e-05
Local loss @ local epoch 3: 0.00033186786458827555
Local loss @ local epoch 4: 0.016177406534552574
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.39 seconds!
[tester] 
AGNewsMetric: acc=0.7518421052631579, hinge=3.898952249727751, ce=9.844711436221473
Local test acc @ epoch 133: 0.7518
Global evaluate on test data...
Evaluate data in 130.48 seconds!
[tester] 
AGNewsMetric: acc=0.8489473684210527, hinge=2.3922363610016673, ce=8.686222018191689
Global test acc @ epoch 133: 0.8489
Global epoch 134...
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 1.9683669961523265e-05
Local loss @ local epoch 1: 2.3990710360521916e-06
Local loss @ local epoch 2: 4.353308031568304e-05
Local loss @ local epoch 3: 1.332865303993458e-05
Local loss @ local epoch 4: 3.7137066101422533e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.46 seconds!
[tester] 
AGNewsMetric: acc=0.8631578947368421, hinge=1.7975346653085007, ce=8.982136168228953
Local test acc @ epoch 134: 0.8632
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 9.354716894449666e-05
Local loss @ local epoch 1: 0.00018114961858373135
Local loss @ local epoch 2: 0.021211812272667885
Local loss @ local epoch 3: 0.008434407413005829
Local loss @ local epoch 4: 0.3824305832386017
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.24 seconds!
[tester] 
AGNewsMetric: acc=0.8525, hinge=2.0503863530409965, ce=7.343390823163484
Local test acc @ epoch 134: 0.8525
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 4.5473967475118116e-05
Local loss @ local epoch 1: 8.043771958909929e-05
Local loss @ local epoch 2: 7.822970474080648e-06
Local loss @ local epoch 3: 0.021522456780076027
Local loss @ local epoch 4: 1.9311095456941985e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.17 seconds!
[tester] 
AGNewsMetric: acc=0.7721052631578947, hinge=3.082923906727841, ce=8.89003452501799
Local test acc @ epoch 134: 0.7721
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 6.721188401570544e-05
Local loss @ local epoch 1: 5.98717451794073e-05
Local loss @ local epoch 2: 0.00010036117600975558
Local loss @ local epoch 3: 0.00011538654507603496
Local loss @ local epoch 4: 0.00011247394286328927
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.07 seconds!
[tester] 
AGNewsMetric: acc=0.8475, hinge=2.0268398631246467, ce=9.410122915569104
Local test acc @ epoch 134: 0.8475
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 6.366943125613034e-05
Local loss @ local epoch 1: 8.615819388069212e-05
Local loss @ local epoch 2: 4.315656769904308e-05
Local loss @ local epoch 3: 0.0004608097951859236
Local loss @ local epoch 4: 5.524787411559373e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.51 seconds!
[tester] 
AGNewsMetric: acc=0.8036842105263158, hinge=2.9904368229916223, ce=8.834323037800036
Local test acc @ epoch 134: 0.8037
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 5.811404662381392e-06
Local loss @ local epoch 1: 9.625979146221653e-06
Local loss @ local epoch 2: 2.8158832719782367e-05
Local loss @ local epoch 3: 8.970202543423511e-06
Local loss @ local epoch 4: 0.002285147551447153
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.53 seconds!
[tester] 
AGNewsMetric: acc=0.8394736842105263, hinge=2.37641046348371, ce=8.863883767378958
Local test acc @ epoch 134: 0.8395
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0009136067237704992
Local loss @ local epoch 1: 0.00057374028256163
Local loss @ local epoch 2: 0.09225429594516754
Local loss @ local epoch 3: 0.38747358322143555
Local loss @ local epoch 4: 0.0004671077767852694
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.49 seconds!
[tester] 
AGNewsMetric: acc=0.8282894736842106, hinge=2.573264461818494, ce=9.540321629172878
Local test acc @ epoch 134: 0.8283
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.010051040910184383
Local loss @ local epoch 1: 0.07137341052293777
Local loss @ local epoch 2: 8.323210931848735e-05
Local loss @ local epoch 3: 0.0012463969178497791
Local loss @ local epoch 4: 0.09125766158103943
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.4 seconds!
[tester] 
AGNewsMetric: acc=0.825, hinge=2.7849021223971717, ce=8.959405387075323
Local test acc @ epoch 134: 0.825
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 2.3618222257937305e-06
Local loss @ local epoch 1: 2.9788903702865355e-05
Local loss @ local epoch 2: 0.0006399095873348415
Local loss @ local epoch 3: 1.9713465007953346e-05
Local loss @ local epoch 4: 0.0014868868747726083
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.79 seconds!
[tester] 
AGNewsMetric: acc=0.8127631578947369, hinge=3.2170071094914485, ce=9.058289074144865
Local test acc @ epoch 134: 0.8128
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 4.9490910896565765e-05
Local loss @ local epoch 1: 0.00010178235970670357
Local loss @ local epoch 2: 9.199495980283245e-05
Local loss @ local epoch 3: 5.8116434956900775e-05
Local loss @ local epoch 4: 0.0029287792276591063
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.69 seconds!
[tester] 
AGNewsMetric: acc=0.7931578947368421, hinge=3.078006389517533, ce=9.386134854366905
Local test acc @ epoch 134: 0.7932
Global evaluate on test data...
Evaluate data in 129.8 seconds!
[tester] 
AGNewsMetric: acc=0.8560526315789474, hinge=2.2719770554492347, ce=8.583838802136873
Global test acc @ epoch 134: 0.8561
Global epoch 135...
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0003169674309901893
Local loss @ local epoch 1: 4.3138538785569835e-06
Local loss @ local epoch 2: 1.4308912754058838
Local loss @ local epoch 3: 0.00014805245155002922
Local loss @ local epoch 4: 0.057077761739492416
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.81 seconds!
[tester] 
AGNewsMetric: acc=0.7589473684210526, hinge=3.317901867565356, ce=10.634465787787187
Local test acc @ epoch 135: 0.7589
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.01937679387629032
Local loss @ local epoch 1: 0.001063149538822472
Local loss @ local epoch 2: 0.10456285625696182
Local loss @ local epoch 3: 0.010789782740175724
Local loss @ local epoch 4: 0.0319879874587059
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.31 seconds!
[tester] 
AGNewsMetric: acc=0.7751315789473684, hinge=3.1154667809135037, ce=9.391943323235763
Local test acc @ epoch 135: 0.7751
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 7.718673259660136e-06
Local loss @ local epoch 1: 3.1888305329630384e-06
Local loss @ local epoch 2: 2.2298703697742894e-05
Local loss @ local epoch 3: 2.953069270006381e-05
Local loss @ local epoch 4: 0.002748568542301655
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.46 seconds!
[tester] 
AGNewsMetric: acc=0.8468421052631578, hinge=2.1893507181970695, ce=9.026967259457237
Local test acc @ epoch 135: 0.8468
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00010431173723191023
Local loss @ local epoch 1: 8.020009408937767e-05
Local loss @ local epoch 2: 2.2886766601004638e-05
Local loss @ local epoch 3: 0.21433311700820923
Local loss @ local epoch 4: 4.6459153963951394e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.65 seconds!
[tester] 
AGNewsMetric: acc=0.684078947368421, hinge=4.9944832224594915, ce=11.34526922326339
Local test acc @ epoch 135: 0.6841
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 1.8297858332516626e-05
Local loss @ local epoch 1: 0.004998889751732349
Local loss @ local epoch 2: 6.422339538403321e-06
Local loss @ local epoch 3: 0.00015328552399296314
Local loss @ local epoch 4: 0.0012640469940379262
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.58 seconds!
[tester] 
AGNewsMetric: acc=0.8544736842105263, hinge=2.085385763017755, ce=8.774751613014622
Local test acc @ epoch 135: 0.8545
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 5.0067137635778636e-06
Local loss @ local epoch 1: 8.292570419143885e-05
Local loss @ local epoch 2: 5.721949491999112e-06
Local loss @ local epoch 3: 9.55886298470432e-06
Local loss @ local epoch 4: 0.0007043388905003667
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.85 seconds!
[tester] 
AGNewsMetric: acc=0.8365789473684211, hinge=2.365768397230851, ce=8.68235787040309
Local test acc @ epoch 135: 0.8366
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.339730829000473
Local loss @ local epoch 1: 0.00011612654634518549
Local loss @ local epoch 2: 0.0031686092261224985
Local loss @ local epoch 3: 0.4250740110874176
Local loss @ local epoch 4: 0.047108229249715805
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.86 seconds!
[tester] 
AGNewsMetric: acc=0.7669736842105264, hinge=2.828086367908277, ce=6.554547708410966
Local test acc @ epoch 135: 0.767
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 6.755814683856443e-05
Local loss @ local epoch 1: 0.0036929957568645477
Local loss @ local epoch 2: 2.1717245545005426e-05
Local loss @ local epoch 3: 7.364238263107836e-05
Local loss @ local epoch 4: 0.0037210709415376186
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.83 seconds!
[tester] 
AGNewsMetric: acc=0.8447368421052631, hinge=2.341544247426485, ce=7.974083753886975
Local test acc @ epoch 135: 0.8447
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 1.093712398869684e-05
Local loss @ local epoch 1: 1.6242211131611839e-06
Local loss @ local epoch 2: 3.3836287911981344e-05
Local loss @ local epoch 3: 9.598547330824658e-05
Local loss @ local epoch 4: 2.7790565582108684e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.65 seconds!
[tester] 
AGNewsMetric: acc=0.7702631578947369, hinge=3.705432230798822, ce=9.095111969395688
Local test acc @ epoch 135: 0.7703
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 1.0050565833807923e-05
Local loss @ local epoch 1: 1.353737843601266e-05
Local loss @ local epoch 2: 0.000391264446079731
Local loss @ local epoch 3: 2.2059464754420333e-05
Local loss @ local epoch 4: 6.299280357779935e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.71 seconds!
[tester] 
AGNewsMetric: acc=0.839078947368421, hinge=2.2919224395250017, ce=9.642096445184006
Local test acc @ epoch 135: 0.8391
Global evaluate on test data...
Evaluate data in 129.74 seconds!
[tester] 
AGNewsMetric: acc=0.8478947368421053, hinge=2.4553074500435277, ce=8.653271139044511
Global test acc @ epoch 135: 0.8479
Global epoch 136...
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4498285054287408e-05
Local loss @ local epoch 1: 0.0002689831890165806
Local loss @ local epoch 2: 0.000134024114231579
Local loss @ local epoch 3: 6.614260200876743e-05
Local loss @ local epoch 4: 0.0005724263610318303
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.2 seconds!
[tester] 
AGNewsMetric: acc=0.8098684210526316, hinge=3.0228729576813547, ce=9.64124994779888
Local test acc @ epoch 136: 0.8099
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 8.538154361303896e-06
Local loss @ local epoch 1: 3.0249250357883284e-06
Local loss @ local epoch 2: 6.732581823598593e-05
Local loss @ local epoch 3: 0.0001547856372781098
Local loss @ local epoch 4: 1.3619272067444399e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.7 seconds!
[tester] 
AGNewsMetric: acc=0.8511842105263158, hinge=2.3030571162073237, ce=9.097066513864618
Local test acc @ epoch 136: 0.8512
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 8.426492058788426e-06
Local loss @ local epoch 1: 0.014273086562752724
Local loss @ local epoch 2: 0.00615828949958086
Local loss @ local epoch 3: 0.2660430669784546
Local loss @ local epoch 4: 0.024359455332159996
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.03 seconds!
[tester] 
AGNewsMetric: acc=0.8315789473684211, hinge=2.4932053902274682, ce=9.466846737108732
Local test acc @ epoch 136: 0.8316
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 9.752421647135634e-06
Local loss @ local epoch 1: 8.426441127085127e-06
Local loss @ local epoch 2: 1.4967399692977779e-05
Local loss @ local epoch 3: 0.0003007816558238119
Local loss @ local epoch 4: 1.0199473763350397e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.64 seconds!
[tester] 
AGNewsMetric: acc=0.8371052631578947, hinge=2.302206913797479, ce=9.93305367519981
Local test acc @ epoch 136: 0.8371
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00012731211609207094
Local loss @ local epoch 1: 0.002731593558564782
Local loss @ local epoch 2: 1.1242421351198573e-05
Local loss @ local epoch 3: 3.899877629010007e-05
Local loss @ local epoch 4: 0.0005491828196682036
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.63 seconds!
[tester] 
AGNewsMetric: acc=0.8307894736842105, hinge=2.294114986971805, ce=10.035665124592029
Local test acc @ epoch 136: 0.8308
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00018761615501716733
Local loss @ local epoch 1: 0.00013230442709755152
Local loss @ local epoch 2: 0.0004814409767277539
Local loss @ local epoch 3: 0.0003288881271146238
Local loss @ local epoch 4: 0.0013298412086442113
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.12 seconds!
[tester] 
AGNewsMetric: acc=0.8296052631578947, hinge=2.205175488120631, ce=8.934719698052657
Local test acc @ epoch 136: 0.8296
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 3.06924557662569e-05
Local loss @ local epoch 1: 0.08777005225419998
Local loss @ local epoch 2: 0.00018651272694114596
Local loss @ local epoch 3: 4.245113814249635e-05
Local loss @ local epoch 4: 0.08171097189188004
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.74 seconds!
[tester] 
AGNewsMetric: acc=0.8628947368421053, hinge=1.9283771346744738, ce=8.552608134621067
Local test acc @ epoch 136: 0.8629
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.000639556092210114
Local loss @ local epoch 1: 0.0005239163292571902
Local loss @ local epoch 2: 0.0007392140105366707
Local loss @ local epoch 3: 0.332724004983902
Local loss @ local epoch 4: 9.501096064923331e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.82 seconds!
[tester] 
AGNewsMetric: acc=0.8203947368421053, hinge=2.275944861612822, ce=9.052250789843107
Local test acc @ epoch 136: 0.8204
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 4.522453309618868e-05
Local loss @ local epoch 1: 2.048904207185842e-06
Local loss @ local epoch 2: 4.1437524487264454e-05
Local loss @ local epoch 3: 0.0003224424144718796
Local loss @ local epoch 4: 7.984038529684767e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.07 seconds!
[tester] 
AGNewsMetric: acc=0.8026315789473685, hinge=2.4066701761044955, ce=9.298756533171002
Local test acc @ epoch 136: 0.8026
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 2.466578735038638e-05
Local loss @ local epoch 1: 2.2073430955060758e-05
Local loss @ local epoch 2: 0.000356976903276518
Local loss @ local epoch 3: 0.00013413916167337447
Local loss @ local epoch 4: 0.3891281485557556
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.98 seconds!
[tester] 
AGNewsMetric: acc=0.8425, hinge=2.187200012457998, ce=10.687539877640573
Local test acc @ epoch 136: 0.8425
Global evaluate on test data...
Evaluate data in 129.47 seconds!
[tester] 
AGNewsMetric: acc=0.8528947368421053, hinge=2.2293625254380074, ce=8.934286904585989
Global test acc @ epoch 136: 0.8529
Global epoch 137...
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 6.079633749322966e-05
Local loss @ local epoch 1: 0.0019457894377410412
Local loss @ local epoch 2: 1.3499859960575122e-05
Local loss @ local epoch 3: 0.24443671107292175
Local loss @ local epoch 4: 0.0003600205818656832
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.15 seconds!
[tester] 
AGNewsMetric: acc=0.735, hinge=4.348712672183388, ce=10.458242587039345
Local test acc @ epoch 137: 0.735
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00047698451089672744
Local loss @ local epoch 1: 0.0002444643760100007
Local loss @ local epoch 2: 0.6323161721229553
Local loss @ local epoch 3: 0.4109816551208496
Local loss @ local epoch 4: 0.0030197901651263237
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.7 seconds!
[tester] 
AGNewsMetric: acc=0.7609210526315789, hinge=3.6165291454917505, ce=9.486690019306383
Local test acc @ epoch 137: 0.7609
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0036349191796034575
Local loss @ local epoch 1: 5.419321314548142e-05
Local loss @ local epoch 2: 0.031838309019804
Local loss @ local epoch 3: 0.03778060898184776
Local loss @ local epoch 4: 0.5332844257354736
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.61 seconds!
[tester] 
AGNewsMetric: acc=0.8465789473684211, hinge=2.1891238978034573, ce=9.808305973253752
Local test acc @ epoch 137: 0.8466
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 3.389986659385613e-06
Local loss @ local epoch 1: 2.3469219740945846e-06
Local loss @ local epoch 2: 6.2210465330281295e-06
Local loss @ local epoch 3: 2.8461054171202704e-06
Local loss @ local epoch 4: 3.119141183560714e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.69 seconds!
[tester] 
AGNewsMetric: acc=0.8255263157894737, hinge=2.869899314579211, ce=9.122063409905685
Local test acc @ epoch 137: 0.8255
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 1.8402893147140276e-06
Local loss @ local epoch 1: 2.4545435735490173e-05
Local loss @ local epoch 2: 6.76504714647308e-06
Local loss @ local epoch 3: 2.932856477855239e-05
Local loss @ local epoch 4: 1.5123931007110514e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.02 seconds!
[tester] 
AGNewsMetric: acc=0.8521052631578947, hinge=2.218644887522647, ce=8.777678549917121
Local test acc @ epoch 137: 0.8521
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 9.737779691931792e-06
Local loss @ local epoch 1: 1.656110180192627e-05
Local loss @ local epoch 2: 2.809440229611937e-05
Local loss @ local epoch 3: 1.3924700397183187e-05
Local loss @ local epoch 4: 0.001263251295313239
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.4 seconds!
[tester] 
AGNewsMetric: acc=0.8478947368421053, hinge=2.3743923101927105, ce=9.275366026225843
Local test acc @ epoch 137: 0.8479
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 6.824624506407417e-06
Local loss @ local epoch 1: 1.527298263681587e-05
Local loss @ local epoch 2: 0.00018582760822027922
Local loss @ local epoch 3: 0.00037955830339342356
Local loss @ local epoch 4: 2.39512010011822e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.47 seconds!
[tester] 
AGNewsMetric: acc=0.8286842105263158, hinge=2.4705264703850998, ce=9.214138799968518
Local test acc @ epoch 137: 0.8287
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 2.4959322217910085e-06
Local loss @ local epoch 1: 3.866824044962414e-06
Local loss @ local epoch 2: 8.918119419831783e-06
Local loss @ local epoch 3: 1.9070817870669998e-05
Local loss @ local epoch 4: 0.00019454541325103492
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.09 seconds!
[tester] 
AGNewsMetric: acc=0.8298684210526316, hinge=2.6560122961747017, ce=8.19600299835205
Local test acc @ epoch 137: 0.8299
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 4.9718386435415596e-05
Local loss @ local epoch 1: 6.951290743018035e-06
Local loss @ local epoch 2: 3.941891554859467e-05
Local loss @ local epoch 3: 5.138874985277653e-05
Local loss @ local epoch 4: 0.00016681145643815398
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.69 seconds!
[tester] 
AGNewsMetric: acc=0.8306578947368422, hinge=2.61843053817749, ce=9.457443592673854
Local test acc @ epoch 137: 0.8307
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 7.97188749857014e-06
Local loss @ local epoch 1: 8.20294826553436e-06
Local loss @ local epoch 2: 4.225295560900122e-05
Local loss @ local epoch 3: 4.633495700545609e-05
Local loss @ local epoch 4: 0.00035567814484238625
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.28 seconds!
[tester] 
AGNewsMetric: acc=0.7792105263157895, hinge=2.87046997195796, ce=9.538581366288035
Local test acc @ epoch 137: 0.7792
Global evaluate on test data...
Evaluate data in 130.43 seconds!
[tester] 
AGNewsMetric: acc=0.8513157894736842, hinge=2.4294362760844983, ce=8.607799600300035
Global test acc @ epoch 137: 0.8513
Global epoch 138...
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4252236724132672e-05
Local loss @ local epoch 1: 4.716194780485239e-06
Local loss @ local epoch 2: 7.637432281626388e-05
Local loss @ local epoch 3: 0.00027582261827774346
Local loss @ local epoch 4: 3.6319273931439966e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.19 seconds!
[tester] 
AGNewsMetric: acc=0.8336842105263158, hinge=2.5720297447003815, ce=9.868637729444002
Local test acc @ epoch 138: 0.8337
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 3.40488986694254e-06
Local loss @ local epoch 1: 2.0449817384360358e-05
Local loss @ local epoch 2: 4.2840383684961125e-06
Local loss @ local epoch 3: 7.891165296314284e-05
Local loss @ local epoch 4: 0.00010175514034926891
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.41 seconds!
[tester] 
AGNewsMetric: acc=0.8436842105263158, hinge=2.381050615812603, ce=8.103062714024594
Local test acc @ epoch 138: 0.8437
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 8.294755389215425e-05
Local loss @ local epoch 1: 0.0001013670553220436
Local loss @ local epoch 2: 6.32761511951685e-05
Local loss @ local epoch 3: 0.037784550338983536
Local loss @ local epoch 4: 0.00023343763314187527
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.84 seconds!
[tester] 
AGNewsMetric: acc=0.8296052631578947, hinge=2.3736971006895367, ce=9.090894917939838
Local test acc @ epoch 138: 0.8296
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 3.166481292282697e-06
Local loss @ local epoch 1: 5.58038891540491e-06
Local loss @ local epoch 2: 2.220263468188932e-06
Local loss @ local epoch 3: 0.0002594830293674022
Local loss @ local epoch 4: 5.548443004954606e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.6 seconds!
[tester] 
AGNewsMetric: acc=0.8265789473684211, hinge=2.5567392381868865, ce=8.84155502319336
Local test acc @ epoch 138: 0.8266
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 8.302833157358691e-05
Local loss @ local epoch 1: 7.25477293599397e-05
Local loss @ local epoch 2: 0.001546986517496407
Local loss @ local epoch 3: 0.0006610898999497294
Local loss @ local epoch 4: 0.0007519092177972198
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.85 seconds!
[tester] 
AGNewsMetric: acc=0.6286842105263157, hinge=5.816920425013492, ce=10.763280264201917
Local test acc @ epoch 138: 0.6287
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00012266836711205542
Local loss @ local epoch 1: 0.0007271204376593232
Local loss @ local epoch 2: 0.0015781879192218184
Local loss @ local epoch 3: 6.364821456372738e-05
Local loss @ local epoch 4: 0.010089905001223087
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.66 seconds!
[tester] 
AGNewsMetric: acc=0.849078947368421, hinge=2.0109252781617015, ce=9.038045509739925
Local test acc @ epoch 138: 0.8491
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 6.66073083266383e-06
Local loss @ local epoch 1: 2.8535628189274576e-06
Local loss @ local epoch 2: 1.4425153732299805
Local loss @ local epoch 3: 2.5337343686260283e-05
Local loss @ local epoch 4: 0.5712206363677979
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.7 seconds!
[tester] 
AGNewsMetric: acc=0.8173684210526316, hinge=2.5378974144082322, ce=8.64310125451339
Local test acc @ epoch 138: 0.8174
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 7.082719093887135e-05
Local loss @ local epoch 1: 0.010231335647404194
Local loss @ local epoch 2: 3.715394632308744e-05
Local loss @ local epoch 3: 7.93476738181198e-06
Local loss @ local epoch 4: 0.00012629844422917813
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.34 seconds!
[tester] 
AGNewsMetric: acc=0.845, hinge=1.9413962123268529, ce=8.632263251856754
Local test acc @ epoch 138: 0.845
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 1.0058271300295019e-06
Local loss @ local epoch 1: 5.960459930065554e-07
Local loss @ local epoch 2: 1.8179346170654753e-06
Local loss @ local epoch 3: 8.411549788434058e-05
Local loss @ local epoch 4: 1.266596541427134e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.99 seconds!
[tester] 
AGNewsMetric: acc=0.8314473684210526, hinge=2.553831717089603, ce=8.464237126802143
Local test acc @ epoch 138: 0.8314
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 2.8287413442740217e-05
Local loss @ local epoch 1: 5.446323029900668e-06
Local loss @ local epoch 2: 0.32936596870422363
Local loss @ local epoch 3: 6.149998080218211e-05
Local loss @ local epoch 4: 0.003322245553135872
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.09 seconds!
[tester] 
AGNewsMetric: acc=0.799078947368421, hinge=3.3306891170300936, ce=9.7651950856259
Local test acc @ epoch 138: 0.7991
Global evaluate on test data...
Evaluate data in 130.12 seconds!
[tester] 
AGNewsMetric: acc=0.8531578947368421, hinge=2.3820713597849794, ce=8.457356001201429
Global test acc @ epoch 138: 0.8532
Global epoch 139...
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00016370267258025706
Local loss @ local epoch 1: 0.2801119089126587
Local loss @ local epoch 2: 0.04646000266075134
Local loss @ local epoch 3: 0.011399747803807259
Local loss @ local epoch 4: 0.00018883096345234662
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.09 seconds!
[tester] 
AGNewsMetric: acc=0.8597368421052631, hinge=2.021368902607968, ce=8.267184416118422
Local test acc @ epoch 139: 0.8597
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 3.240981413910049e-06
Local loss @ local epoch 1: 0.011925065889954567
Local loss @ local epoch 2: 1.166720630862983e-05
Local loss @ local epoch 3: 0.6668832898139954
Local loss @ local epoch 4: 0.03233500197529793
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.37 seconds!
[tester] 
AGNewsMetric: acc=0.7892105263157895, hinge=2.938072160670632, ce=8.504974509791325
Local test acc @ epoch 139: 0.7892
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.05942670628428459
Local loss @ local epoch 1: 6.012512130837422e-06
Local loss @ local epoch 2: 0.033837608993053436
Local loss @ local epoch 3: 0.06825944781303406
Local loss @ local epoch 4: 0.00843146350234747
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.16 seconds!
[tester] 
AGNewsMetric: acc=0.8044736842105263, hinge=2.5294618363129464, ce=8.303257221422697
Local test acc @ epoch 139: 0.8045
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0004792275431100279
Local loss @ local epoch 1: 5.158752537681721e-05
Local loss @ local epoch 2: 0.0002567036426626146
Local loss @ local epoch 3: 0.00021945967455394566
Local loss @ local epoch 4: 0.01314893551170826
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.77 seconds!
[tester] 
AGNewsMetric: acc=0.8269736842105263, hinge=2.241052777390731, ce=8.552603759765624
Local test acc @ epoch 139: 0.827
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 5.870879249414429e-06
Local loss @ local epoch 1: 0.004158817231655121
Local loss @ local epoch 2: 8.23588197818026e-05
Local loss @ local epoch 3: 1.9019373655319214
Local loss @ local epoch 4: 0.00042976977420039475
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.98 seconds!
[tester] 
AGNewsMetric: acc=0.8064473684210526, hinge=2.231520874123824, ce=10.159087588661595
Local test acc @ epoch 139: 0.8064
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0003639421775005758
Local loss @ local epoch 1: 0.00038431299617514014
Local loss @ local epoch 2: 0.021357188001275063
Local loss @ local epoch 3: 0.0015641584759578109
Local loss @ local epoch 4: 0.02823185920715332
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.81 seconds!
[tester] 
AGNewsMetric: acc=0.8402631578947368, hinge=2.3086591687955353, ce=8.860415942543431
Local test acc @ epoch 139: 0.8403
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 8.307121788675431e-06
Local loss @ local epoch 1: 2.7268979465588927e-06
Local loss @ local epoch 2: 4.762951721204445e-05
Local loss @ local epoch 3: 3.990679397247732e-05
Local loss @ local epoch 4: 4.3045245547546074e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.46 seconds!
[tester] 
AGNewsMetric: acc=0.8203947368421053, hinge=2.681027630253842, ce=8.72081447802092
Local test acc @ epoch 139: 0.8204
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 1.0572005521680694e-05
Local loss @ local epoch 1: 2.376722250119201e-06
Local loss @ local epoch 2: 0.000304381683235988
Local loss @ local epoch 3: 3.183386434102431e-05
Local loss @ local epoch 4: 0.00192699721083045
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.3 seconds!
[tester] 
AGNewsMetric: acc=0.8202631578947368, hinge=2.4640576455467627, ce=7.7383564657914015
Local test acc @ epoch 139: 0.8203
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 5.781788058811799e-05
Local loss @ local epoch 1: 2.6275245545548387e-05
Local loss @ local epoch 2: 0.26229164004325867
Local loss @ local epoch 3: 0.00020730313553940505
Local loss @ local epoch 4: 0.006783288437873125
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.38 seconds!
[tester] 
AGNewsMetric: acc=0.8269736842105263, hinge=2.885762549450523, ce=8.990423810858475
Local test acc @ epoch 139: 0.827
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 2.026551101153018e-06
Local loss @ local epoch 1: 9.253200914827175e-06
Local loss @ local epoch 2: 3.837021267827367e-06
Local loss @ local epoch 3: 0.00016088558186311275
Local loss @ local epoch 4: 1.7806830783229088e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.12 seconds!
[tester] 
AGNewsMetric: acc=0.8288157894736842, hinge=2.42439497445759, ce=8.594414331536544
Local test acc @ epoch 139: 0.8288
Global evaluate on test data...
Evaluate data in 129.88 seconds!
[tester] 
AGNewsMetric: acc=0.8539473684210527, hinge=2.440162505601582, ce=8.30801969628585
Global test acc @ epoch 139: 0.8539
Global epoch 140...
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 1.0936892067547888e-05
Local loss @ local epoch 1: 6.19782877038233e-05
Local loss @ local epoch 2: 4.328753220761428e-06
Local loss @ local epoch 3: 1.0669036782928742e-05
Local loss @ local epoch 4: 2.64255577349104e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.76 seconds!
[tester] 
AGNewsMetric: acc=0.8364473684210526, hinge=2.317859936764366, ce=8.866586006566099
Local test acc @ epoch 140: 0.8364
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 9.387706541019725e-07
Local loss @ local epoch 1: 5.803931344416924e-06
Local loss @ local epoch 2: 1.609320861462038e-06
Local loss @ local epoch 3: 0.0002966684114653617
Local loss @ local epoch 4: 1.0907335308729671e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.66 seconds!
[tester] 
AGNewsMetric: acc=0.8252631578947368, hinge=2.2124414679878637, ce=8.998822973150956
Local test acc @ epoch 140: 0.8253
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4036609172762837e-05
Local loss @ local epoch 1: 0.00023209054779727012
Local loss @ local epoch 2: 0.0001810756220947951
Local loss @ local epoch 3: 0.0004590957541950047
Local loss @ local epoch 4: 9.950460662366822e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.2 seconds!
[tester] 
AGNewsMetric: acc=0.8178947368421052, hinge=2.7322982768008583, ce=8.55906989448949
Local test acc @ epoch 140: 0.8179
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0009626916144043207
Local loss @ local epoch 1: 0.0889374315738678
Local loss @ local epoch 2: 0.016741668805480003
Local loss @ local epoch 3: 0.6906720399856567
Local loss @ local epoch 4: 0.02149922400712967
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.33 seconds!
[tester] 
AGNewsMetric: acc=0.8321052631578948, hinge=2.306074985704924, ce=8.742364991840564
Local test acc @ epoch 140: 0.8321
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 5.036547918280121e-06
Local loss @ local epoch 1: 4.343658474681433e-06
Local loss @ local epoch 2: 2.6685620468924753e-05
Local loss @ local epoch 3: 0.00044204623554833233
Local loss @ local epoch 4: 1.8841914425138384e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.19 seconds!
[tester] 
AGNewsMetric: acc=0.8381578947368421, hinge=2.4647997971584923, ce=9.598750164634303
Local test acc @ epoch 140: 0.8382
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.5191221791610587e-05
Local loss @ local epoch 1: 6.020015916874399e-06
Local loss @ local epoch 2: 2.5717779863043688e-05
Local loss @ local epoch 3: 1.0184753591602203e-05
Local loss @ local epoch 4: 7.80539630795829e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.79 seconds!
[tester] 
AGNewsMetric: acc=0.8442105263157895, hinge=2.423586576361405, ce=8.34580972571122
Local test acc @ epoch 140: 0.8442
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 1.3417466107057407e-05
Local loss @ local epoch 1: 2.3408496417687275e-05
Local loss @ local epoch 2: 0.00014610527432523668
Local loss @ local epoch 3: 5.394101208366919e-06
Local loss @ local epoch 4: 2.298363506270107e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.83 seconds!
[tester] 
AGNewsMetric: acc=0.83, hinge=2.209038465148524, ce=8.740108686748304
Local test acc @ epoch 140: 0.83
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 4.576439459924586e-05
Local loss @ local epoch 1: 9.059604053618386e-06
Local loss @ local epoch 2: 0.01019735261797905
Local loss @ local epoch 3: 6.296258652582765e-05
Local loss @ local epoch 4: 0.00035471131559461355
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.38 seconds!
[tester] 
AGNewsMetric: acc=0.8394736842105263, hinge=2.2853079888695165, ce=8.363690669411108
Local test acc @ epoch 140: 0.8395
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0003738634695764631
Local loss @ local epoch 1: 1.4274835848482326e-05
Local loss @ local epoch 2: 0.09319015592336655
Local loss @ local epoch 3: 0.000521877605933696
Local loss @ local epoch 4: 0.00013257293903734535
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.71 seconds!
[tester] 
AGNewsMetric: acc=0.8438157894736842, hinge=2.185558819017912, ce=9.05955411409077
Local test acc @ epoch 140: 0.8438
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 6.0720244619005825e-06
Local loss @ local epoch 1: 5.03962037328165e-05
Local loss @ local epoch 2: 2.3295398932532407e-05
Local loss @ local epoch 3: 2.918218706327025e-05
Local loss @ local epoch 4: 2.0353985746623948e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.19 seconds!
[tester] 
AGNewsMetric: acc=0.8338157894736842, hinge=2.5801694112075, ce=9.097024206864207
Local test acc @ epoch 140: 0.8338
Global evaluate on test data...
Evaluate data in 129.7 seconds!
[tester] 
AGNewsMetric: acc=0.8485526315789473, hinge=2.361354435870522, ce=8.364370020816201
Global test acc @ epoch 140: 0.8486
Global epoch 141...
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 2.719451003940776e-06
Local loss @ local epoch 1: 0.42429301142692566
Local loss @ local epoch 2: 3.309039675514214e-05
Local loss @ local epoch 3: 0.00010851483966689557
Local loss @ local epoch 4: 0.06992244720458984
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.4 seconds!
[tester] 
AGNewsMetric: acc=0.8310526315789474, hinge=2.1854266284641466, ce=9.355162488033898
Local test acc @ epoch 141: 0.8311
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 2.2879174139234237e-05
Local loss @ local epoch 1: 5.648216756526381e-05
Local loss @ local epoch 2: 0.2907300591468811
Local loss @ local epoch 3: 9.40629979595542e-05
Local loss @ local epoch 4: 0.0027695305179804564
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.57 seconds!
[tester] 
AGNewsMetric: acc=0.7975, hinge=3.356437473799053, ce=9.478217807569003
Local test acc @ epoch 141: 0.7975
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 6.377561931003584e-06
Local loss @ local epoch 1: 0.0027400145772844553
Local loss @ local epoch 2: 1.9428995074122213e-05
Local loss @ local epoch 3: 0.06756038963794708
Local loss @ local epoch 4: 2.848889198503457e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.99 seconds!
[tester] 
AGNewsMetric: acc=0.7988157894736843, hinge=3.1773136565559787, ce=9.315487839548211
Local test acc @ epoch 141: 0.7988
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 5.040509859099984e-05
Local loss @ local epoch 1: 1.0341227607568726e-05
Local loss @ local epoch 2: 0.7176904678344727
Local loss @ local epoch 3: 1.9028031601919793e-05
Local loss @ local epoch 4: 9.491982928011566e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.6 seconds!
[tester] 
AGNewsMetric: acc=0.8275, hinge=2.7540075896915637, ce=8.497412777950888
Local test acc @ epoch 141: 0.8275
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 3.5762202514888486e-06
Local loss @ local epoch 1: 1.7225271221832372e-05
Local loss @ local epoch 2: 1.2039507964800578e-05
Local loss @ local epoch 3: 0.23518957197666168
Local loss @ local epoch 4: 1.8521019228501245e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.43 seconds!
[tester] 
AGNewsMetric: acc=0.8314473684210526, hinge=2.5599661104302656, ce=7.8224340278223945
Local test acc @ epoch 141: 0.8314
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 2.952423892566003e-05
Local loss @ local epoch 1: 0.18628083169460297
Local loss @ local epoch 2: 6.98856229064404e-06
Local loss @ local epoch 3: 9.204211528412998e-05
Local loss @ local epoch 4: 1.73992919921875
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.15 seconds!
[tester] 
AGNewsMetric: acc=0.7975, hinge=3.0754752681129855, ce=8.900869357460424
Local test acc @ epoch 141: 0.7975
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 4.04557886213297e-06
Local loss @ local epoch 1: 1.0803324812513893e-06
Local loss @ local epoch 2: 0.13117215037345886
Local loss @ local epoch 3: 4.2928284528898075e-05
Local loss @ local epoch 4: 0.0004940242506563663
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.02 seconds!
[tester] 
AGNewsMetric: acc=0.7918421052631579, hinge=2.8247218975267914, ce=9.456211272791812
Local test acc @ epoch 141: 0.7918
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 2.853556907211896e-06
Local loss @ local epoch 1: 2.1606499558401993e-06
Local loss @ local epoch 2: 4.410721885506064e-06
Local loss @ local epoch 3: 7.726004696451128e-06
Local loss @ local epoch 4: 2.071249582513701e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.68 seconds!
[tester] 
AGNewsMetric: acc=0.8515789473684211, hinge=2.2419888708465976, ce=9.288950193304764
Local test acc @ epoch 141: 0.8516
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 3.444521644269116e-05
Local loss @ local epoch 1: 0.09853081405162811
Local loss @ local epoch 2: 0.0011227503418922424
Local loss @ local epoch 3: 0.0049556586891412735
Local loss @ local epoch 4: 0.0006635639001615345
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.35 seconds!
[tester] 
AGNewsMetric: acc=0.8303947368421053, hinge=2.022459139071013, ce=8.611162872314454
Local test acc @ epoch 141: 0.8304
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 1.0817922884598374e-05
Local loss @ local epoch 1: 2.2416918000089936e-05
Local loss @ local epoch 2: 2.366886656091083e-05
Local loss @ local epoch 3: 0.021938415244221687
Local loss @ local epoch 4: 3.928954174625687e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.56 seconds!
[tester] 
AGNewsMetric: acc=0.8576315789473684, hinge=2.201252489340933, ce=8.394003446478592
Local test acc @ epoch 141: 0.8576
Global evaluate on test data...
Evaluate data in 130.63 seconds!
[tester] 
AGNewsMetric: acc=0.8509210526315789, hinge=2.454696898460388, ce=8.280786269338508
Global test acc @ epoch 141: 0.8509
Global epoch 142...
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 1.1584987078094855e-05
Local loss @ local epoch 1: 2.555534138082294e-06
Local loss @ local epoch 2: 9.484203474130481e-06
Local loss @ local epoch 3: 2.914490323746577e-05
Local loss @ local epoch 4: 1.3254278201202396e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.24 seconds!
[tester] 
AGNewsMetric: acc=0.8438157894736842, hinge=2.375400743986431, ce=9.560593169362921
Local test acc @ epoch 142: 0.8438
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4156057659420185e-06
Local loss @ local epoch 1: 1.5682440789532848e-05
Local loss @ local epoch 2: 4.842872272092791e-07
Local loss @ local epoch 3: 1.4028461009729654e-05
Local loss @ local epoch 4: 0.0009941535536199808
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.85 seconds!
[tester] 
AGNewsMetric: acc=0.8407894736842105, hinge=2.5244606356871757, ce=8.279638268320184
Local test acc @ epoch 142: 0.8408
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 1.832762973208446e-05
Local loss @ local epoch 1: 0.0001153686607722193
Local loss @ local epoch 2: 7.451869896613061e-05
Local loss @ local epoch 3: 0.014141656458377838
Local loss @ local epoch 4: 0.0002137549308827147
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.72 seconds!
[tester] 
AGNewsMetric: acc=0.7127631578947369, hinge=4.396490531720613, ce=10.482346277738872
Local test acc @ epoch 142: 0.7128
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 1.959495648407028e-06
Local loss @ local epoch 1: 3.8295752347039524e-06
Local loss @ local epoch 2: 1.79097678483231e-05
Local loss @ local epoch 3: 3.278231133663212e-06
Local loss @ local epoch 4: 7.361019015661441e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.03 seconds!
[tester] 
AGNewsMetric: acc=0.8460526315789474, hinge=2.4891148298665096, ce=8.621199487384997
Local test acc @ epoch 142: 0.8461
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 3.0025689738977235e-06
Local loss @ local epoch 1: 4.641664418159053e-06
Local loss @ local epoch 2: 0.0004360304737929255
Local loss @ local epoch 3: 4.9246932576352265e-06
Local loss @ local epoch 4: 9.004607272800058e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.05 seconds!
[tester] 
AGNewsMetric: acc=0.8385526315789473, hinge=2.6694024698357834, ce=8.474116851405094
Local test acc @ epoch 142: 0.8386
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 4.656105375033803e-05
Local loss @ local epoch 1: 7.614411515532993e-06
Local loss @ local epoch 2: 0.5715014934539795
Local loss @ local epoch 3: 0.00024309866421390325
Local loss @ local epoch 4: 0.00045179654262028635
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.5 seconds!
[tester] 
AGNewsMetric: acc=0.8114473684210526, hinge=3.027034609192296, ce=9.472690947683233
Local test acc @ epoch 142: 0.8114
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.005240770056843758
Local loss @ local epoch 1: 0.0001254648232134059
Local loss @ local epoch 2: 0.04558151587843895
Local loss @ local epoch 3: 0.024513322860002518
Local loss @ local epoch 4: 0.03658464178442955
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.72 seconds!
[tester] 
AGNewsMetric: acc=0.7919736842105263, hinge=2.779933305037649, ce=8.206455341138337
Local test acc @ epoch 142: 0.792
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00013230157492216676
Local loss @ local epoch 1: 5.5035277910064906e-05
Local loss @ local epoch 2: 1.4780632257461548
Local loss @ local epoch 3: 0.005753226578235626
Local loss @ local epoch 4: 0.062329236418008804
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.06 seconds!
[tester] 
AGNewsMetric: acc=0.7796052631578947, hinge=3.2769230232740703, ce=8.993178855494449
Local test acc @ epoch 142: 0.7796
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 1.5578414604533464e-05
Local loss @ local epoch 1: 2.6841888029593974e-05
Local loss @ local epoch 2: 4.991298192180693e-05
Local loss @ local epoch 3: 0.02918355166912079
Local loss @ local epoch 4: 0.0007405850919894874
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.7 seconds!
[tester] 
AGNewsMetric: acc=0.6810526315789474, hinge=5.65042271588978, ce=11.40962038542095
Local test acc @ epoch 142: 0.6811
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.03747202083468437
Local loss @ local epoch 1: 0.16695691645145416
Local loss @ local epoch 2: 0.00948006846010685
Local loss @ local epoch 3: 0.0007727586198598146
Local loss @ local epoch 4: 0.010717852041125298
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.48 seconds!
[tester] 
AGNewsMetric: acc=0.8614473684210526, hinge=1.6208941261391892, ce=8.796738825346294
Local test acc @ epoch 142: 0.8614
Global evaluate on test data...
Evaluate data in 130.23 seconds!
[tester] 
AGNewsMetric: acc=0.8543421052631579, hinge=2.4521248636747663, ce=8.227388084813168
Global test acc @ epoch 142: 0.8543
Global epoch 143...
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 2.495934495527763e-06
Local loss @ local epoch 1: 8.344635489265784e-07
Local loss @ local epoch 2: 0.00010379122250014916
Local loss @ local epoch 3: 0.568673849105835
Local loss @ local epoch 4: 5.809687354485504e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.56 seconds!
[tester] 
AGNewsMetric: acc=0.8442105263157895, hinge=2.3354914921208434, ce=8.607278301841335
Local test acc @ epoch 143: 0.8442
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 3.2633249702485045e-06
Local loss @ local epoch 1: 1.2814971341867931e-06
Local loss @ local epoch 2: 1.09670108940918e-05
Local loss @ local epoch 3: 8.776523827691562e-06
Local loss @ local epoch 4: 1.1212198842258658e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 131.01 seconds!
[tester] 
AGNewsMetric: acc=0.8486842105263158, hinge=2.1423846759294207, ce=8.836372730857448
Local test acc @ epoch 143: 0.8487
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.018533697351813316
Local loss @ local epoch 1: 0.00024342087272088975
Local loss @ local epoch 2: 0.7939028143882751
Local loss @ local epoch 3: 0.023465212434530258
Local loss @ local epoch 4: 0.20799480378627777
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.79 seconds!
[tester] 
AGNewsMetric: acc=0.8444736842105263, hinge=1.8731426040749801, ce=9.67657189017848
Local test acc @ epoch 143: 0.8445
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 3.3303824693575734e-06
Local loss @ local epoch 1: 3.851911060337443e-06
Local loss @ local epoch 2: 9.089690138353035e-07
Local loss @ local epoch 3: 0.004292958416044712
Local loss @ local epoch 4: 7.167301191657316e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.91 seconds!
[tester] 
AGNewsMetric: acc=0.7789473684210526, hinge=3.771760628097936, ce=9.528773333900853
Local test acc @ epoch 143: 0.7789
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0006485944031737745
Local loss @ local epoch 1: 2.9457236450980417e-05
Local loss @ local epoch 2: 0.00032872441806830466
Local loss @ local epoch 3: 0.0009031561785377562
Local loss @ local epoch 4: 0.004439200274646282
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.35 seconds!
[tester] 
AGNewsMetric: acc=0.8386842105263158, hinge=2.061830867215207, ce=8.511302257337068
Local test acc @ epoch 143: 0.8387
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.000619735277723521
Local loss @ local epoch 1: 0.3761185109615326
Local loss @ local epoch 2: 9.760018656379543e-06
Local loss @ local epoch 3: 2.5449962777202018e-05
Local loss @ local epoch 4: 0.14026081562042236
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.04 seconds!
[tester] 
AGNewsMetric: acc=0.6668421052631579, hinge=4.895361067872298, ce=10.610387818185906
Local test acc @ epoch 143: 0.6668
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0022673336789011955
Local loss @ local epoch 1: 0.00014583341544494033
Local loss @ local epoch 2: 0.794087827205658
Local loss @ local epoch 3: 0.6837942004203796
Local loss @ local epoch 4: 0.001205140259116888
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.75 seconds!
[tester] 
AGNewsMetric: acc=0.8105263157894737, hinge=2.9132555055618288, ce=8.1986645989669
Local test acc @ epoch 143: 0.8105
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.058490317314863205
Local loss @ local epoch 1: 0.00013049374683760107
Local loss @ local epoch 2: 0.0023004610557109118
Local loss @ local epoch 3: 0.10614151507616043
Local loss @ local epoch 4: 0.004209398292005062
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.95 seconds!
[tester] 
AGNewsMetric: acc=0.7844736842105263, hinge=2.4108805623807403, ce=9.695329666137695
Local test acc @ epoch 143: 0.7845
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 5.628652434097603e-05
Local loss @ local epoch 1: 9.53653307078639e-06
Local loss @ local epoch 2: 0.00037941403570584953
Local loss @ local epoch 3: 0.00017107557505369186
Local loss @ local epoch 4: 0.11766566336154938
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.01 seconds!
[tester] 
AGNewsMetric: acc=0.8436842105263158, hinge=2.458650224836249, ce=8.66439941807797
Local test acc @ epoch 143: 0.8437
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 9.074549780052621e-06
Local loss @ local epoch 1: 1.9147933016938623e-06
Local loss @ local epoch 2: 2.6314173737773672e-05
Local loss @ local epoch 3: 1.1421498129493557e-05
Local loss @ local epoch 4: 0.0003795049851760268
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.19 seconds!
[tester] 
AGNewsMetric: acc=0.8514473684210526, hinge=2.2900811461398476, ce=8.284557972958213
Local test acc @ epoch 143: 0.8514
Global evaluate on test data...
Evaluate data in 130.45 seconds!
[tester] 
AGNewsMetric: acc=0.8527631578947369, hinge=2.3819597003334447, ce=8.285420158787778
Global test acc @ epoch 143: 0.8528
Global epoch 144...
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 3.25602522934787e-05
Local loss @ local epoch 1: 1.1294644536974374e-05
Local loss @ local epoch 2: 1.0750915862445254e-05
Local loss @ local epoch 3: 0.0005122208967804909
Local loss @ local epoch 4: 0.00021620019106194377
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.9 seconds!
[tester] 
AGNewsMetric: acc=0.8498684210526316, hinge=2.1159519948457417, ce=8.521136239704333
Local test acc @ epoch 144: 0.8499
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 4.1275989133282565e-06
Local loss @ local epoch 1: 4.443575380719267e-05
Local loss @ local epoch 2: 1.7604977983864956e-05
Local loss @ local epoch 3: 0.00012793233327101916
Local loss @ local epoch 4: 0.0007271869108080864
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.08 seconds!
[tester] 
AGNewsMetric: acc=0.8403947368421053, hinge=2.626704316139221, ce=8.256042434290835
Local test acc @ epoch 144: 0.8404
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00022947238176129758
Local loss @ local epoch 1: 4.306398750486551e-06
Local loss @ local epoch 2: 0.00022292204084806144
Local loss @ local epoch 3: 0.0006200585630722344
Local loss @ local epoch 4: 0.0001581659453222528
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.64 seconds!
[tester] 
AGNewsMetric: acc=0.8389473684210527, hinge=2.4710462728299594, ce=9.336004369635331
Local test acc @ epoch 144: 0.8389
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 5.535611308005173e-06
Local loss @ local epoch 1: 3.978555923822569e-06
Local loss @ local epoch 2: 4.3475301936268806e-05
Local loss @ local epoch 3: 0.0003101294278167188
Local loss @ local epoch 4: 0.0002864724665414542
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.96 seconds!
[tester] 
AGNewsMetric: acc=0.8198684210526316, hinge=2.48503131464908, ce=9.24255470677426
Local test acc @ epoch 144: 0.8199
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 1.1309568435535766e-05
Local loss @ local epoch 1: 2.365256477787625e-05
Local loss @ local epoch 2: 4.2922554712276906e-05
Local loss @ local epoch 3: 0.00012781392433680594
Local loss @ local epoch 4: 0.00020311976550146937
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.65 seconds!
[tester] 
AGNewsMetric: acc=0.8073684210526316, hinge=3.180763689091331, ce=9.6815385396857
Local test acc @ epoch 144: 0.8074
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.007991544902324677
Local loss @ local epoch 1: 0.0006384534062817693
Local loss @ local epoch 2: 6.977024168008938e-05
Local loss @ local epoch 3: 0.5434154868125916
Local loss @ local epoch 4: 0.005645995028316975
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.1 seconds!
[tester] 
AGNewsMetric: acc=0.8446052631578947, hinge=1.9850367322720979, ce=8.950245552062988
Local test acc @ epoch 144: 0.8446
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00018340605311095715
Local loss @ local epoch 1: 0.009948711842298508
Local loss @ local epoch 2: 0.2864048480987549
Local loss @ local epoch 3: 0.00021783221745863557
Local loss @ local epoch 4: 0.3413184881210327
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.6 seconds!
[tester] 
AGNewsMetric: acc=0.7871052631578948, hinge=3.1571486872120906, ce=8.398192678752698
Local test acc @ epoch 144: 0.7871
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 1.6465191947645508e-05
Local loss @ local epoch 1: 1.0473016500473022
Local loss @ local epoch 2: 0.16015268862247467
Local loss @ local epoch 3: 0.4037991464138031
Local loss @ local epoch 4: 0.015410779044032097
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.06 seconds!
[tester] 
AGNewsMetric: acc=0.7805263157894737, hinge=3.0631213720221266, ce=10.109040812442178
Local test acc @ epoch 144: 0.7805
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 5.766617505287286e-06
Local loss @ local epoch 1: 0.5000333786010742
Local loss @ local epoch 2: 0.000111831133835949
Local loss @ local epoch 3: 2.7139140001963824e-05
Local loss @ local epoch 4: 0.012570460326969624
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.44 seconds!
[tester] 
AGNewsMetric: acc=0.8296052631578947, hinge=2.206452058239987, ce=8.586706340187474
Local test acc @ epoch 144: 0.8296
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 2.3692714421486016e-06
Local loss @ local epoch 1: 2.3800523194950074e-05
Local loss @ local epoch 2: 2.041442712652497e-06
Local loss @ local epoch 3: 4.231861566950101e-06
Local loss @ local epoch 4: 7.684405136387795e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.68 seconds!
[tester] 
AGNewsMetric: acc=0.8515789473684211, hinge=2.1822455160241376, ce=8.707864008451763
Local test acc @ epoch 144: 0.8516
Global evaluate on test data...
Evaluate data in 129.17 seconds!
[tester] 
AGNewsMetric: acc=0.8578947368421053, hinge=2.3590294965944794, ce=8.26860037151136
Global test acc @ epoch 144: 0.8579
Global epoch 145...
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 3.188804612364038e-06
Local loss @ local epoch 1: 0.014482884667813778
Local loss @ local epoch 2: 3.505220229271799e-05
Local loss @ local epoch 3: 0.09956925362348557
Local loss @ local epoch 4: 0.014574866741895676
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.36 seconds!
[tester] 
AGNewsMetric: acc=0.845, hinge=2.314271552939164, ce=8.966226176211709
Local test acc @ epoch 145: 0.845
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0006150505505502224
Local loss @ local epoch 1: 7.442173227900639e-05
Local loss @ local epoch 2: 0.8255895972251892
Local loss @ local epoch 3: 5.5306274589383975e-05
Local loss @ local epoch 4: 0.0003613353183027357
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.5 seconds!
[tester] 
AGNewsMetric: acc=0.8017105263157894, hinge=2.675792915193658, ce=9.412984757674367
Local test acc @ epoch 145: 0.8017
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 1.9818469354504487e-06
Local loss @ local epoch 1: 6.1539976741187274e-06
Local loss @ local epoch 2: 7.957016350701451e-06
Local loss @ local epoch 3: 1.4438725884247106e-05
Local loss @ local epoch 4: 4.447962510312209e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.38 seconds!
[tester] 
AGNewsMetric: acc=0.7952631578947369, hinge=3.1532318820451435, ce=9.247186835439582
Local test acc @ epoch 145: 0.7953
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 3.956161890528165e-06
Local loss @ local epoch 1: 4.067972440680023e-06
Local loss @ local epoch 2: 0.01241997443139553
Local loss @ local epoch 3: 0.002150071319192648
Local loss @ local epoch 4: 0.006873766891658306
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.38 seconds!
[tester] 
AGNewsMetric: acc=0.8401315789473685, hinge=2.1524954617650884, ce=8.63964938916658
Local test acc @ epoch 145: 0.8401
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 3.392947110114619e-05
Local loss @ local epoch 1: 1.2442441175153363e-06
Local loss @ local epoch 2: 2.3949874957907014e-05
Local loss @ local epoch 3: 0.01568129099905491
Local loss @ local epoch 4: 6.731173925800249e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.0 seconds!
[tester] 
AGNewsMetric: acc=0.8356578947368422, hinge=2.4548842605791594, ce=8.436846972013775
Local test acc @ epoch 145: 0.8357
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 3.829564775514882e-06
Local loss @ local epoch 1: 4.038182396470802e-06
Local loss @ local epoch 2: 9.573627721692901e-06
Local loss @ local epoch 3: 2.9355185233725933e-06
Local loss @ local epoch 4: 2.0219938960508443e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.84 seconds!
[tester] 
AGNewsMetric: acc=0.8425, hinge=2.2509333106091147, ce=8.515304095619603
Local test acc @ epoch 145: 0.8425
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0014189023058861494
Local loss @ local epoch 1: 0.01591680385172367
Local loss @ local epoch 2: 0.01795467548072338
Local loss @ local epoch 3: 0.006824745796620846
Local loss @ local epoch 4: 0.1323108971118927
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.26 seconds!
[tester] 
AGNewsMetric: acc=0.8181578947368421, hinge=2.8303066459454986, ce=9.105251304224918
Local test acc @ epoch 145: 0.8182
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 6.6233569668838754e-06
Local loss @ local epoch 1: 2.970381137856748e-05
Local loss @ local epoch 2: 0.0010767257772386074
Local loss @ local epoch 3: 0.0003607759135775268
Local loss @ local epoch 4: 9.553310519549996e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.22 seconds!
[tester] 
AGNewsMetric: acc=0.8463157894736842, hinge=2.344073136982165, ce=8.744739574633147
Local test acc @ epoch 145: 0.8463
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 7.877538882894441e-05
Local loss @ local epoch 1: 5.570898065343499e-05
Local loss @ local epoch 2: 0.3929847478866577
Local loss @ local epoch 3: 0.0005739137995988131
Local loss @ local epoch 4: 0.003108253702521324
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.19 seconds!
[tester] 
AGNewsMetric: acc=0.8596052631578948, hinge=1.9036301146055523, ce=8.909955416227643
Local test acc @ epoch 145: 0.8596
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00039652775740250945
Local loss @ local epoch 1: 0.0005709833931177855
Local loss @ local epoch 2: 0.0021932958625257015
Local loss @ local epoch 3: 0.004255872685462236
Local loss @ local epoch 4: 0.001471274415962398
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.63 seconds!
[tester] 
AGNewsMetric: acc=0.8222368421052632, hinge=2.4318370628356933, ce=8.09017049689042
Local test acc @ epoch 145: 0.8222
Global evaluate on test data...
Evaluate data in 130.01 seconds!
[tester] 
AGNewsMetric: acc=0.8525, hinge=2.3463482229333175, ce=8.341701720388311
Global test acc @ epoch 145: 0.8525
Global epoch 146...
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0005351930158212781
Local loss @ local epoch 1: 6.123623461462557e-05
Local loss @ local epoch 2: 0.2601224184036255
Local loss @ local epoch 3: 7.158971129683778e-05
Local loss @ local epoch 4: 0.10838918387889862
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.71 seconds!
[tester] 
AGNewsMetric: acc=0.7468421052631579, hinge=3.7548411642877677, ce=10.098242745650442
Local test acc @ epoch 146: 0.7468
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0006268166471272707
Local loss @ local epoch 1: 0.006903126370161772
Local loss @ local epoch 2: 2.8063912395737134e-05
Local loss @ local epoch 3: 0.7685722708702087
Local loss @ local epoch 4: 0.0002718004398047924
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.67 seconds!
[tester] 
AGNewsMetric: acc=0.7571052631578947, hinge=3.2502130465758476, ce=8.767936196578177
Local test acc @ epoch 146: 0.7571
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 1.8848120816983283e-05
Local loss @ local epoch 1: 1.0713763913372532e-05
Local loss @ local epoch 2: 1.5228003576339688e-05
Local loss @ local epoch 3: 0.4359825849533081
Local loss @ local epoch 4: 4.9715399654814973e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.21 seconds!
[tester] 
AGNewsMetric: acc=0.7655263157894737, hinge=2.8883129237827503, ce=9.333682628430818
Local test acc @ epoch 146: 0.7655
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 3.177954931743443e-05
Local loss @ local epoch 1: 2.2641344912699424e-05
Local loss @ local epoch 2: 3.514031777740456e-05
Local loss @ local epoch 3: 0.00014506076695397496
Local loss @ local epoch 4: 9.593860158929601e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.91 seconds!
[tester] 
AGNewsMetric: acc=0.8397368421052631, hinge=2.3794425941768447, ce=9.188528755589536
Local test acc @ epoch 146: 0.8397
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 1.5497124650210026e-06
Local loss @ local epoch 1: 2.369274170632707e-06
Local loss @ local epoch 2: 1.1622854572124197e-06
Local loss @ local epoch 3: 4.522466042544693e-06
Local loss @ local epoch 4: 1.6599289665464312e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.59 seconds!
[tester] 
AGNewsMetric: acc=0.8102631578947368, hinge=2.975062138155887, ce=8.0855435120432
Local test acc @ epoch 146: 0.8103
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 2.3989579858607613e-05
Local loss @ local epoch 1: 6.563891474797856e-06
Local loss @ local epoch 2: 0.002181239891797304
Local loss @ local epoch 3: 0.018778173252940178
Local loss @ local epoch 4: 1.3328546629054472e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.76 seconds!
[tester] 
AGNewsMetric: acc=0.6460526315789473, hinge=6.100514829535233, ce=11.647875044973272
Local test acc @ epoch 146: 0.6461
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 1.0281788718202733e-06
Local loss @ local epoch 1: 1.6242232732111006e-06
Local loss @ local epoch 2: 1.0356277471146313e-06
Local loss @ local epoch 3: 4.194625489617465e-06
Local loss @ local epoch 4: 0.0001368090306641534
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.83 seconds!
[tester] 
AGNewsMetric: acc=0.8043421052631579, hinge=3.133318549959283, ce=8.60201079719945
Local test acc @ epoch 146: 0.8043
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.01400797814130783
Local loss @ local epoch 1: 0.023353710770606995
Local loss @ local epoch 2: 0.0013433335116133094
Local loss @ local epoch 3: 0.0014406105037778616
Local loss @ local epoch 4: 0.07638423144817352
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.08 seconds!
[tester] 
AGNewsMetric: acc=0.8530263157894736, hinge=1.7467045638435765, ce=8.49075072639867
Local test acc @ epoch 146: 0.853
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 2.6374784738436574e-06
Local loss @ local epoch 1: 0.0017639290308579803
Local loss @ local epoch 2: 2.279871296195779e-06
Local loss @ local epoch 3: 1.7210792293553823e-06
Local loss @ local epoch 4: 2.825802584993653e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.21 seconds!
[tester] 
AGNewsMetric: acc=0.7586842105263157, hinge=3.8634365792023506, ce=9.571684058339972
Local test acc @ epoch 146: 0.7587
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 8.717170203453861e-07
Local loss @ local epoch 1: 2.950396037704195e-06
Local loss @ local epoch 2: 1.2591436870934558e-06
Local loss @ local epoch 3: 7.107738383638207e-06
Local loss @ local epoch 4: 3.308024588477565e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.25 seconds!
[tester] 
AGNewsMetric: acc=0.819078947368421, hinge=2.629962595387509, ce=8.694732001455206
Local test acc @ epoch 146: 0.8191
Global evaluate on test data...
Evaluate data in 130.23 seconds!
[tester] 
AGNewsMetric: acc=0.8457894736842105, hinge=2.551275299473813, ce=8.269476382606907
Global test acc @ epoch 146: 0.8458
Global epoch 147...
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 1.9743940811167704e-06
Local loss @ local epoch 1: 5.416477051767288e-06
Local loss @ local epoch 2: 1.937140496011125e-06
Local loss @ local epoch 3: 7.0108671934576705e-06
Local loss @ local epoch 4: 2.945566848211456e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.01 seconds!
[tester] 
AGNewsMetric: acc=0.8385526315789473, hinge=2.5922004252985906, ce=8.25040367929559
Local test acc @ epoch 147: 0.8386
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 2.526278331060894e-05
Local loss @ local epoch 1: 0.011396637186408043
Local loss @ local epoch 2: 0.0004552282625809312
Local loss @ local epoch 3: 0.3074241876602173
Local loss @ local epoch 4: 0.0001920222130138427
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.99 seconds!
[tester] 
AGNewsMetric: acc=0.8359210526315789, hinge=2.579608765652305, ce=9.688647697850277
Local test acc @ epoch 147: 0.8359
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 4.3958397100141156e-07
Local loss @ local epoch 1: 1.4305019249150064e-06
Local loss @ local epoch 2: 2.071250492008403e-06
Local loss @ local epoch 3: 0.004306648392230272
Local loss @ local epoch 4: 1.4305048807727871e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.32 seconds!
[tester] 
AGNewsMetric: acc=0.8463157894736842, hinge=2.6137344764408312, ce=8.285201849686471
Local test acc @ epoch 147: 0.8463
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 2.5209801606251858e-05
Local loss @ local epoch 1: 0.0055652884766459465
Local loss @ local epoch 2: 9.499287443759385e-06
Local loss @ local epoch 3: 0.0012681415537372231
Local loss @ local epoch 4: 0.001162162865512073
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.56 seconds!
[tester] 
AGNewsMetric: acc=0.7823684210526316, hinge=3.304242219422993, ce=9.9725964596397
Local test acc @ epoch 147: 0.7824
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 3.017465360244387e-06
Local loss @ local epoch 1: 1.543679172755219e-05
Local loss @ local epoch 2: 3.5017524169234093e-06
Local loss @ local epoch 3: 2.260320798086468e-05
Local loss @ local epoch 4: 3.5986129205412e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.76 seconds!
[tester] 
AGNewsMetric: acc=0.8235526315789473, hinge=2.4364720015776786, ce=8.565186853910747
Local test acc @ epoch 147: 0.8236
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0035976427607238293
Local loss @ local epoch 1: 2.9932331017334945e-05
Local loss @ local epoch 2: 0.009634262882173061
Local loss @ local epoch 3: 0.08961103111505508
Local loss @ local epoch 4: 0.00011455080675659701
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.25 seconds!
[tester] 
AGNewsMetric: acc=0.8305263157894737, hinge=2.086529570629722, ce=7.904584703947369
Local test acc @ epoch 147: 0.8305
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 2.2714835722581483e-05
Local loss @ local epoch 1: 0.002086636144667864
Local loss @ local epoch 2: 7.581406680401415e-05
Local loss @ local epoch 3: 0.0020492456387728453
Local loss @ local epoch 4: 6.608429248444736e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.9 seconds!
[tester] 
AGNewsMetric: acc=0.8467105263157895, hinge=2.0691203338221498, ce=8.434944612603438
Local test acc @ epoch 147: 0.8467
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 1.9779794456553645e-05
Local loss @ local epoch 1: 0.5802547931671143
Local loss @ local epoch 2: 1.7127034880104475e-05
Local loss @ local epoch 3: 0.0003439327992964536
Local loss @ local epoch 4: 5.132903243065812e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.34 seconds!
[tester] 
AGNewsMetric: acc=0.7585526315789474, hinge=3.1370031085767245, ce=9.234631739164653
Local test acc @ epoch 147: 0.7586
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 3.7699128370149992e-06
Local loss @ local epoch 1: 1.3693406799575314e-05
Local loss @ local epoch 2: 1.3411026884568855e-06
Local loss @ local epoch 3: 0.047906383872032166
Local loss @ local epoch 4: 0.00016430369578301907
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.65 seconds!
[tester] 
AGNewsMetric: acc=0.8244736842105264, hinge=2.099187701626828, ce=9.601856641267476
Local test acc @ epoch 147: 0.8245
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 1.8030331148111145e-06
Local loss @ local epoch 1: 0.29990842938423157
Local loss @ local epoch 2: 1.141371285484638e-05
Local loss @ local epoch 3: 3.844481852866011e-06
Local loss @ local epoch 4: 0.6539519429206848
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.62 seconds!
[tester] 
AGNewsMetric: acc=0.8176315789473684, hinge=2.6118849317651045, ce=8.95791257557116
Local test acc @ epoch 147: 0.8176
Global evaluate on test data...
Evaluate data in 130.01 seconds!
[tester] 
AGNewsMetric: acc=0.8530263157894736, hinge=2.424083887652347, ce=8.22295835595382
Global test acc @ epoch 147: 0.853
Global epoch 148...
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 3.511701288516633e-05
Local loss @ local epoch 1: 1.1473873655631905e-06
Local loss @ local epoch 2: 1.3053117072558962e-05
Local loss @ local epoch 3: 0.1093176007270813
Local loss @ local epoch 4: 0.004938434809446335
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.38 seconds!
[tester] 
AGNewsMetric: acc=0.8135526315789474, hinge=2.8924676307878996, ce=9.328481180291426
Local test acc @ epoch 148: 0.8136
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 3.599898627726361e-05
Local loss @ local epoch 1: 0.00013076742470730096
Local loss @ local epoch 2: 1.5079580407473259e-05
Local loss @ local epoch 3: 1.577822208404541
Local loss @ local epoch 4: 0.0006408157059922814
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.31 seconds!
[tester] 
AGNewsMetric: acc=0.8152631578947368, hinge=2.8176271363308554, ce=8.515052982129548
Local test acc @ epoch 148: 0.8153
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 2.1904604636802105e-06
Local loss @ local epoch 1: 9.298006261815317e-06
Local loss @ local epoch 2: 8.46476323204115e-05
Local loss @ local epoch 3: 4.665710366680287e-05
Local loss @ local epoch 4: 1.5131551663216669e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.86 seconds!
[tester] 
AGNewsMetric: acc=0.8307894736842105, hinge=2.907702052467748, ce=8.070363569761577
Local test acc @ epoch 148: 0.8308
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 1.0646583177731372e-05
Local loss @ local epoch 1: 1.3261679669085424e-05
Local loss @ local epoch 2: 1.3217026207712479e-05
Local loss @ local epoch 3: 1.4472527503967285
Local loss @ local epoch 4: 0.0004990856978110969
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.13 seconds!
[tester] 
AGNewsMetric: acc=0.8086842105263158, hinge=2.8997051826276277, ce=8.902407612047698
Local test acc @ epoch 148: 0.8087
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 1.5720681858510943e-06
Local loss @ local epoch 1: 1.8700882264965912e-06
Local loss @ local epoch 2: 1.467758693252108e-06
Local loss @ local epoch 3: 2.1457569800986676e-06
Local loss @ local epoch 4: 1.3961643162474502e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.29 seconds!
[tester] 
AGNewsMetric: acc=0.8286842105263158, hinge=2.748477030804283, ce=8.520652250992624
Local test acc @ epoch 148: 0.8287
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 1.385804694109538e-06
Local loss @ local epoch 1: 6.9531197368633e-05
Local loss @ local epoch 2: 0.0007474427111446857
Local loss @ local epoch 3: 2.5331876258860575e-06
Local loss @ local epoch 4: 1.6352198144886643e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.07 seconds!
[tester] 
AGNewsMetric: acc=0.839078947368421, hinge=2.4261154551255077, ce=8.500044800607782
Local test acc @ epoch 148: 0.8391
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 1.5273647022695513e-06
Local loss @ local epoch 1: 1.3783549093204783e-06
Local loss @ local epoch 2: 7.003533823990438e-07
Local loss @ local epoch 3: 1.4528578731187736e-06
Local loss @ local epoch 4: 3.112855847575702e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.53 seconds!
[tester] 
AGNewsMetric: acc=0.8363157894736842, hinge=2.3608915923771105, ce=6.67784854888916
Local test acc @ epoch 148: 0.8363
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 3.226081162210903e-06
Local loss @ local epoch 1: 0.0016635855427011847
Local loss @ local epoch 2: 2.43632348428946e-06
Local loss @ local epoch 3: 5.57297607883811e-06
Local loss @ local epoch 4: 0.09646566212177277
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.83 seconds!
[tester] 
AGNewsMetric: acc=0.8460526315789474, hinge=2.325789478201615, ce=8.926473127666272
Local test acc @ epoch 148: 0.8461
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0023430881556123495
Local loss @ local epoch 1: 0.006133893504738808
Local loss @ local epoch 2: 0.0007419520989060402
Local loss @ local epoch 3: 0.0020546773448586464
Local loss @ local epoch 4: 0.012077545747160912
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.2 seconds!
[tester] 
AGNewsMetric: acc=0.8396052631578947, hinge=2.4072537221406636, ce=8.112225371912906
Local test acc @ epoch 148: 0.8396
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 7.666393685212824e-06
Local loss @ local epoch 1: 7.396536238957196e-05
Local loss @ local epoch 2: 6.815560482209548e-05
Local loss @ local epoch 3: 8.164824976120144e-05
Local loss @ local epoch 4: 1.0184558050241321e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.53 seconds!
[tester] 
AGNewsMetric: acc=0.815921052631579, hinge=3.0185537006980496, ce=8.328333704095138
Local test acc @ epoch 148: 0.8159
Global evaluate on test data...
Evaluate data in 130.52 seconds!
[tester] 
AGNewsMetric: acc=0.845657894736842, hinge=2.6929314688632364, ce=8.030041688617906
Global test acc @ epoch 148: 0.8457
Global epoch 149...
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 6.332767497951863e-06
Local loss @ local epoch 1: 3.189409471815452e-05
Local loss @ local epoch 2: 1.4632246347900946e-05
Local loss @ local epoch 3: 1.527321910543833e-05
Local loss @ local epoch 4: 0.32856205105781555
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.46 seconds!
[tester] 
AGNewsMetric: acc=0.8068421052631579, hinge=3.2681559399554603, ce=8.613713499370375
Local test acc @ epoch 149: 0.8068
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 3.755047373488196e-06
Local loss @ local epoch 1: 1.7806737560022157e-06
Local loss @ local epoch 2: 6.468884384958073e-05
Local loss @ local epoch 3: 9.533919364912435e-05
Local loss @ local epoch 4: 9.634942398406565e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.89 seconds!
[tester] 
AGNewsMetric: acc=0.8276315789473684, hinge=2.6527746067549054, ce=7.959682352166427
Local test acc @ epoch 149: 0.8276
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 3.48685034623486e-06
Local loss @ local epoch 1: 4.3630214349832386e-05
Local loss @ local epoch 2: 3.4123172554245684e-06
Local loss @ local epoch 3: 1.7932830814970657e-05
Local loss @ local epoch 4: 0.029766906052827835
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.05 seconds!
[tester] 
AGNewsMetric: acc=0.8167105263157894, hinge=3.266849327087402, ce=8.554547474509791
Local test acc @ epoch 149: 0.8167
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 2.7492492336023133e-06
Local loss @ local epoch 1: 1.3350942026590928e-05
Local loss @ local epoch 2: 2.4363180273212492e-06
Local loss @ local epoch 3: 1.1979698683717288e-05
Local loss @ local epoch 4: 1.3709031918551773e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.91 seconds!
[tester] 
AGNewsMetric: acc=0.8444736842105263, hinge=2.1898068548503673, ce=9.386112199080618
Local test acc @ epoch 149: 0.8445
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.03162674978375435
Local loss @ local epoch 1: 3.593801739043556e-05
Local loss @ local epoch 2: 0.007035929709672928
Local loss @ local epoch 3: 0.029635919257998466
Local loss @ local epoch 4: 0.0026263634208589792
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.17 seconds!
[tester] 
AGNewsMetric: acc=0.8260526315789474, hinge=2.3409116524144222, ce=8.030322829798648
Local test acc @ epoch 149: 0.8261
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 2.0712482182716485e-06
Local loss @ local epoch 1: 6.481992613771581e-07
Local loss @ local epoch 2: 9.611236464479589e-07
Local loss @ local epoch 3: 1.2076847269781865e-05
Local loss @ local epoch 4: 1.5348105080192909e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.72 seconds!
[tester] 
AGNewsMetric: acc=0.8435526315789473, hinge=2.5012120021016973, ce=8.06191306264777
Local test acc @ epoch 149: 0.8436
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 2.5853346414805856e-06
Local loss @ local epoch 1: 4.388282832223922e-06
Local loss @ local epoch 2: 4.39583999423121e-07
Local loss @ local epoch 3: 6.958614903851412e-06
Local loss @ local epoch 4: 1.054961103363894e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.36 seconds!
[tester] 
AGNewsMetric: acc=0.7280263157894736, hinge=4.6675836093802205, ce=9.959607746726588
Local test acc @ epoch 149: 0.728
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 5.066312496637693e-06
Local loss @ local epoch 1: 1.8477280718798283e-06
Local loss @ local epoch 2: 7.733504389761947e-06
Local loss @ local epoch 3: 1.653882827667985e-05
Local loss @ local epoch 4: 0.0065820468589663506
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.4 seconds!
[tester] 
AGNewsMetric: acc=0.8169736842105263, hinge=2.6286296169381393, ce=8.519148563585784
Local test acc @ epoch 149: 0.817
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 2.7343403417035006e-06
Local loss @ local epoch 1: 4.78321771879564e-06
Local loss @ local epoch 2: 0.27474913001060486
Local loss @ local epoch 3: 5.230269380263053e-06
Local loss @ local epoch 4: 4.314916077419184e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 131.16 seconds!
[tester] 
AGNewsMetric: acc=0.6490789473684211, hinge=7.6111561428873165, ce=11.77078043285169
Local test acc @ epoch 149: 0.6491
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00024890864733606577
Local loss @ local epoch 1: 1.156295638793381e-05
Local loss @ local epoch 2: 1.3032892942428589
Local loss @ local epoch 3: 3.162394932587631e-05
Local loss @ local epoch 4: 4.135453127673827e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.9 seconds!
[tester] 
AGNewsMetric: acc=0.8042105263157895, hinge=2.9151467918094838, ce=9.202480207744397
Local test acc @ epoch 149: 0.8042
Global evaluate on test data...
Evaluate data in 130.11 seconds!
[tester] 
AGNewsMetric: acc=0.8453947368421053, hinge=2.7826985221160085, ce=8.09497299595883
Global test acc @ epoch 149: 0.8454
Global epoch 150...
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 1.564615331517416e-06
Local loss @ local epoch 1: 2.995119075421826e-06
Local loss @ local epoch 2: 1.1801129403465893e-05
Local loss @ local epoch 3: 1.512464677944081e-06
Local loss @ local epoch 4: 3.230180300306529e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.87 seconds!
[tester] 
AGNewsMetric: acc=0.8360526315789474, hinge=2.6745556863985565, ce=8.94273550133956
Local test acc @ epoch 150: 0.8361
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 3.4868296552303946e-06
Local loss @ local epoch 1: 1.6434169083368033e-05
Local loss @ local epoch 2: 1.251633329957258e-05
Local loss @ local epoch 3: 0.0006737633957527578
Local loss @ local epoch 4: 7.178289524745196e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.92 seconds!
[tester] 
AGNewsMetric: acc=0.8392105263157895, hinge=2.640145794215955, ce=8.484504268043919
Local test acc @ epoch 150: 0.8392
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 2.1159526113478933e-06
Local loss @ local epoch 1: 2.1755590751126874e-06
Local loss @ local epoch 2: 2.8161104637547396e-05
Local loss @ local epoch 3: 1.0854841093532741e-05
Local loss @ local epoch 4: 0.00010007416130974889
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.3 seconds!
[tester] 
AGNewsMetric: acc=0.77, hinge=4.262206047208686, ce=8.94413895657188
Local test acc @ epoch 150: 0.77
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 1.110134235204896e-06
Local loss @ local epoch 1: 4.172322576323495e-07
Local loss @ local epoch 2: 9.238685265700042e-07
Local loss @ local epoch 3: 2.1239722627797164e-05
Local loss @ local epoch 4: 4.507557605393231e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.94 seconds!
[tester] 
AGNewsMetric: acc=0.8113157894736842, hinge=3.216062345253794, ce=7.8898925279316146
Local test acc @ epoch 150: 0.8113
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 3.874299636663636e-07
Local loss @ local epoch 1: 6.481988066298072e-07
Local loss @ local epoch 2: 3.4272648008482065e-07
Local loss @ local epoch 3: 8.046146831475198e-06
Local loss @ local epoch 4: 8.992287803266663e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.6 seconds!
[tester] 
AGNewsMetric: acc=0.7571052631578947, hinge=4.3260869723872135, ce=9.377476617913498
Local test acc @ epoch 150: 0.7571
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 2.8651455068029463e-05
Local loss @ local epoch 1: 1.3752608538197819e-05
Local loss @ local epoch 2: 0.0002516382955946028
Local loss @ local epoch 3: 4.380512473289855e-05
Local loss @ local epoch 4: 0.90228670835495
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.22 seconds!
[tester] 
AGNewsMetric: acc=0.7368421052631579, hinge=4.138770519055818, ce=8.534505472685161
Local test acc @ epoch 150: 0.7368
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 5.349378625396639e-06
Local loss @ local epoch 1: 0.0053983512334525585
Local loss @ local epoch 2: 1.2337737643974833e-05
Local loss @ local epoch 3: 0.0006989179528318346
Local loss @ local epoch 4: 0.00336916814558208
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.48 seconds!
[tester] 
AGNewsMetric: acc=0.8264473684210526, hinge=2.931359416058189, ce=8.494306524176347
Local test acc @ epoch 150: 0.8264
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 2.1308565010258462e-06
Local loss @ local epoch 1: 1.1026839956684853e-06
Local loss @ local epoch 2: 0.010535725392401218
Local loss @ local epoch 3: 2.8759054657712113e-06
Local loss @ local epoch 4: 0.000244647148065269
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.12 seconds!
[tester] 
AGNewsMetric: acc=0.6473684210526316, hinge=6.399276909577219, ce=11.814947483665065
Local test acc @ epoch 150: 0.6474
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.006748241372406483
Local loss @ local epoch 1: 0.00018400678527541459
Local loss @ local epoch 2: 0.0032688206993043423
Local loss @ local epoch 3: 0.0066163502633571625
Local loss @ local epoch 4: 0.01000178512185812
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.95 seconds!
[tester] 
AGNewsMetric: acc=0.8303947368421053, hinge=2.496010242261385, ce=8.40755427912662
Local test acc @ epoch 150: 0.8304
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 9.015182058647042e-07
Local loss @ local epoch 1: 1.6018665291994694e-06
Local loss @ local epoch 2: 3.427264516631112e-07
Local loss @ local epoch 3: 4.030656782560982e-06
Local loss @ local epoch 4: 6.705517989757936e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.65 seconds!
[tester] 
AGNewsMetric: acc=0.8488157894736842, hinge=2.491477827272917, ce=7.856977011028089
Local test acc @ epoch 150: 0.8488
Global evaluate on test data...
Evaluate data in 130.27 seconds!
[tester] 
AGNewsMetric: acc=0.8448684210526316, hinge=2.738736729872854, ce=8.020091555745978
Global test acc @ epoch 150: 0.8449
Global epoch 151...
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 7.442782134603476e-06
Local loss @ local epoch 1: 3.1366498660645448e-06
Local loss @ local epoch 2: 0.004361389204859734
Local loss @ local epoch 3: 2.935511247414979e-06
Local loss @ local epoch 4: 7.01665339875035e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.37 seconds!
[tester] 
AGNewsMetric: acc=0.8338157894736842, hinge=2.553681542998866, ce=8.23239957106741
Local test acc @ epoch 151: 0.8338
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 3.5762775496550603e-07
Local loss @ local epoch 1: 4.991881610294513e-07
Local loss @ local epoch 2: 0.011503663845360279
Local loss @ local epoch 3: 6.034957777956151e-07
Local loss @ local epoch 4: 7.081912190187722e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.59 seconds!
[tester] 
AGNewsMetric: acc=0.7557894736842106, hinge=3.7847451162338257, ce=9.128667769181101
Local test acc @ epoch 151: 0.7558
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 5.563490049098618e-05
Local loss @ local epoch 1: 3.3009291655616835e-05
Local loss @ local epoch 2: 0.0006963196792639792
Local loss @ local epoch 3: 0.12285292893648148
Local loss @ local epoch 4: 0.0003746999427676201
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.11 seconds!
[tester] 
AGNewsMetric: acc=0.8173684210526316, hinge=2.72473204035508, ce=9.194759057697498
Local test acc @ epoch 151: 0.8174
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.1399363302189158e-06
Local loss @ local epoch 1: 1.5944203823892167e-06
Local loss @ local epoch 2: 2.69709698841325e-06
Local loss @ local epoch 3: 8.210172381950542e-06
Local loss @ local epoch 4: 1.1622884130702005e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.27 seconds!
[tester] 
AGNewsMetric: acc=0.8078947368421052, hinge=3.4631194967972605, ce=8.627988712913112
Local test acc @ epoch 151: 0.8079
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 2.6970883482135832e-06
Local loss @ local epoch 1: 3.874239155265968e-06
Local loss @ local epoch 2: 1.9892984255420743e-06
Local loss @ local epoch 3: 5.38608874194324e-05
Local loss @ local epoch 4: 3.933812877221499e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.6 seconds!
[tester] 
AGNewsMetric: acc=0.8326315789473684, hinge=2.668447043519271, ce=8.797020576878598
Local test acc @ epoch 151: 0.8326
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 5.811448886561266e-07
Local loss @ local epoch 1: 9.909242635330884e-07
Local loss @ local epoch 2: 3.278253473126824e-07
Local loss @ local epoch 3: 1.452860942663392e-06
Local loss @ local epoch 4: 2.6896404961007647e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.38 seconds!
[tester] 
AGNewsMetric: acc=0.8443421052631579, hinge=2.81609752353869, ce=7.699667735852693
Local test acc @ epoch 151: 0.8443
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 9.015190016725683e-07
Local loss @ local epoch 1: 3.6507825029730157e-07
Local loss @ local epoch 2: 5.364414050745836e-07
Local loss @ local epoch 3: 0.5636649131774902
Local loss @ local epoch 4: 4.704275488620624e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.77 seconds!
[tester] 
AGNewsMetric: acc=0.8086842105263158, hinge=2.9193695700796027, ce=8.655138206481933
Local test acc @ epoch 151: 0.8087
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00011897392687387764
Local loss @ local epoch 1: 8.43857487780042e-05
Local loss @ local epoch 2: 0.00011441499373177066
Local loss @ local epoch 3: 7.28292579879053e-05
Local loss @ local epoch 4: 0.009852390736341476
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.29 seconds!
[tester] 
AGNewsMetric: acc=0.7942105263157895, hinge=3.126792598021658, ce=8.98067965858861
Local test acc @ epoch 151: 0.7942
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.10105209797620773
Local loss @ local epoch 1: 9.476950253883842e-06
Local loss @ local epoch 2: 0.13197985291481018
Local loss @ local epoch 3: 0.34686022996902466
Local loss @ local epoch 4: 0.00038200782728381455
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.92 seconds!
[tester] 
AGNewsMetric: acc=0.8352631578947368, hinge=2.497475931769923, ce=7.895206860994038
Local test acc @ epoch 151: 0.8353
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 4.656455985241337e-06
Local loss @ local epoch 1: 0.0001816732983570546
Local loss @ local epoch 2: 0.007912886328995228
Local loss @ local epoch 3: 0.00036537248524837196
Local loss @ local epoch 4: 9.171536476060282e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.35 seconds!
[tester] 
AGNewsMetric: acc=0.7232894736842105, hinge=4.699278929860968, ce=9.09772594652678
Local test acc @ epoch 151: 0.7233
Global evaluate on test data...
Evaluate data in 129.76 seconds!
[tester] 
AGNewsMetric: acc=0.84, hinge=2.763581996967918, ce=8.050504704525597
Global test acc @ epoch 151: 0.84
Global epoch 152...
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 2.302214625160559e-06
Local loss @ local epoch 1: 4.4852022256236523e-05
Local loss @ local epoch 2: 3.8146622500789817e-06
Local loss @ local epoch 3: 0.8236603736877441
Local loss @ local epoch 4: 0.4828028380870819
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.74 seconds!
[tester] 
AGNewsMetric: acc=0.8192105263157895, hinge=2.9674425313347266, ce=7.941019423635383
Local test acc @ epoch 152: 0.8192
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 3.7252880247251596e-07
Local loss @ local epoch 1: 4.917376372759463e-07
Local loss @ local epoch 2: 2.883324668800924e-06
Local loss @ local epoch 3: 8.71713382366579e-07
Local loss @ local epoch 4: 1.0259152077196632e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.47 seconds!
[tester] 
AGNewsMetric: acc=0.848421052631579, hinge=2.6184601234134877, ce=8.53247426685534
Local test acc @ epoch 152: 0.8484
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 5.556010364671238e-05
Local loss @ local epoch 1: 3.65819164471759e-06
Local loss @ local epoch 2: 1.9466378944343887e-05
Local loss @ local epoch 3: 5.930957922828384e-05
Local loss @ local epoch 4: 0.017330482602119446
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.64 seconds!
[tester] 
AGNewsMetric: acc=0.7977631578947368, hinge=3.0384320773576436, ce=8.386940693102385
Local test acc @ epoch 152: 0.7978
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 4.843370334128849e-05
Local loss @ local epoch 1: 2.7939472602156457e-06
Local loss @ local epoch 2: 0.0007445990922860801
Local loss @ local epoch 3: 6.139067409094423e-06
Local loss @ local epoch 4: 6.0704434872604907e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.08 seconds!
[tester] 
AGNewsMetric: acc=0.8285526315789473, hinge=3.1633349714781107, ce=8.470629067671926
Local test acc @ epoch 152: 0.8286
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.045481838285923004
Local loss @ local epoch 1: 0.6136018633842468
Local loss @ local epoch 2: 9.650747233536094e-05
Local loss @ local epoch 3: 0.39311593770980835
Local loss @ local epoch 4: 0.004276495426893234
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.97 seconds!
[tester] 
AGNewsMetric: acc=0.8019736842105263, hinge=2.6992498952464055, ce=9.208656347174394
Local test acc @ epoch 152: 0.802
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00030186542426235974
Local loss @ local epoch 1: 9.35748357733246e-06
Local loss @ local epoch 2: 0.08814416080713272
Local loss @ local epoch 3: 2.7748474167310633e-05
Local loss @ local epoch 4: 0.02220766246318817
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.22 seconds!
[tester] 
AGNewsMetric: acc=0.8426315789473684, hinge=2.6137133781533493, ce=7.927951702318693
Local test acc @ epoch 152: 0.8426
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.5326821208000183
Local loss @ local epoch 1: 1.6465738781334949e-06
Local loss @ local epoch 2: 0.000165048215421848
Local loss @ local epoch 3: 0.6572793126106262
Local loss @ local epoch 4: 3.4719374525593594e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 131.24 seconds!
[tester] 
AGNewsMetric: acc=0.7231578947368421, hinge=4.684305552181445, ce=10.373623827884071
Local test acc @ epoch 152: 0.7232
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00016472623974550515
Local loss @ local epoch 1: 6.884158665343421e-06
Local loss @ local epoch 2: 0.30303502082824707
Local loss @ local epoch 3: 4.477760739973746e-06
Local loss @ local epoch 4: 4.313858880777843e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.86 seconds!
[tester] 
AGNewsMetric: acc=0.8523684210526316, hinge=2.1961575214486375, ce=8.506259410255833
Local test acc @ epoch 152: 0.8524
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 3.874299636663636e-07
Local loss @ local epoch 1: 1.5646214990283625e-07
Local loss @ local epoch 2: 0.00022258643002714962
Local loss @ local epoch 3: 8.195627856366627e-07
Local loss @ local epoch 4: 0.00010046731767943129
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.26 seconds!
[tester] 
AGNewsMetric: acc=0.8330263157894737, hinge=2.688701918250636, ce=8.931223409552324
Local test acc @ epoch 152: 0.833
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 1.9520314253895776e-06
Local loss @ local epoch 1: 7.599580840178533e-07
Local loss @ local epoch 2: 9.424854397366289e-06
Local loss @ local epoch 3: 9.439262612431776e-06
Local loss @ local epoch 4: 0.00025833345716819167
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 131.02 seconds!
[tester] 
AGNewsMetric: acc=0.8457894736842105, hinge=2.690083499707674, ce=8.241481656526265
Local test acc @ epoch 152: 0.8458
Global evaluate on test data...
Evaluate data in 130.1 seconds!
[tester] 
AGNewsMetric: acc=0.848421052631579, hinge=2.744886272079066, ce=7.982264291863692
Global test acc @ epoch 152: 0.8484
Global epoch 153...
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 1.6167711009984487e-06
Local loss @ local epoch 1: 5.0215139708598144e-06
Local loss @ local epoch 2: 3.948722678615013e-06
Local loss @ local epoch 3: 7.33864180801902e-06
Local loss @ local epoch 4: 2.0787024368473794e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.23 seconds!
[tester] 
AGNewsMetric: acc=0.8061842105263158, hinge=3.0024306573365864, ce=9.745745602657921
Local test acc @ epoch 153: 0.8062
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 2.8312194899626775e-07
Local loss @ local epoch 1: 8.49364710120426e-07
Local loss @ local epoch 2: 2.1606675204566272e-07
Local loss @ local epoch 3: 1.348551791124919e-06
Local loss @ local epoch 4: 4.321331061873934e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.37 seconds!
[tester] 
AGNewsMetric: acc=0.8511842105263158, hinge=2.690303348742033, ce=8.37499108163934
Local test acc @ epoch 153: 0.8512
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 1.0579756235529203e-06
Local loss @ local epoch 1: 2.1457581169670448e-06
Local loss @ local epoch 2: 2.384184938364342e-07
Local loss @ local epoch 3: 7.525078444814426e-07
Local loss @ local epoch 4: 1.628502104722429e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.61 seconds!
[tester] 
AGNewsMetric: acc=0.7985526315789474, hinge=3.853190184894361, ce=8.742385932520817
Local test acc @ epoch 153: 0.7986
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 5.9378703554102685e-06
Local loss @ local epoch 1: 0.0014162342995405197
Local loss @ local epoch 2: 8.791642471805972e-07
Local loss @ local epoch 3: 6.876364204799756e-05
Local loss @ local epoch 4: 0.00012533065455500036
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.34 seconds!
[tester] 
AGNewsMetric: acc=0.7606578947368421, hinge=3.561028528715435, ce=8.259231892635947
Local test acc @ epoch 153: 0.7607
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.48553226608783e-05
Local loss @ local epoch 1: 7.227057494674227e-07
Local loss @ local epoch 2: 2.0993498765164986e-05
Local loss @ local epoch 3: 0.00012853059160988778
Local loss @ local epoch 4: 0.00019902552594430745
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.6 seconds!
[tester] 
AGNewsMetric: acc=0.8101315789473684, hinge=3.243642627816451, ce=8.555313503867701
Local test acc @ epoch 153: 0.8101
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0044366843067109585
Local loss @ local epoch 1: 5.535602667805506e-06
Local loss @ local epoch 2: 0.617755115032196
Local loss @ local epoch 3: 0.011011685244739056
Local loss @ local epoch 4: 0.05897355452179909
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.79 seconds!
[tester] 
AGNewsMetric: acc=0.8403947368421053, hinge=2.212339503639623, ce=8.667570792750308
Local test acc @ epoch 153: 0.8404
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 3.81749305233825e-05
Local loss @ local epoch 1: 1.3231033335614484e-05
Local loss @ local epoch 2: 4.268315024091862e-05
Local loss @ local epoch 3: 0.41367149353027344
Local loss @ local epoch 4: 2.4735848001000704e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.59 seconds!
[tester] 
AGNewsMetric: acc=0.7561842105263158, hinge=3.959627453653436, ce=9.906275152909128
Local test acc @ epoch 153: 0.7562
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 6.929025175850256e-07
Local loss @ local epoch 1: 7.450574344147753e-07
Local loss @ local epoch 2: 0.0028740211855620146
Local loss @ local epoch 3: 2.5693154384498484e-05
Local loss @ local epoch 4: 0.2617105543613434
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.2 seconds!
[tester] 
AGNewsMetric: acc=0.8421052631578947, hinge=2.7145519567790783, ce=7.68536342018529
Local test acc @ epoch 153: 0.8421
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 4.4434731535147876e-05
Local loss @ local epoch 1: 0.00042868679156526923
Local loss @ local epoch 2: 0.42757731676101685
Local loss @ local epoch 3: 9.288826549891382e-05
Local loss @ local epoch 4: 0.001439903280697763
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.88 seconds!
[tester] 
AGNewsMetric: acc=0.7696052631578948, hinge=3.999573618487308, ce=8.611838292573628
Local test acc @ epoch 153: 0.7696
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 6.281853711698204e-05
Local loss @ local epoch 1: 0.009404098615050316
Local loss @ local epoch 2: 1.1525145055202302e-05
Local loss @ local epoch 3: 1.6370378732681274
Local loss @ local epoch 4: 9.334878996014595e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.59 seconds!
[tester] 
AGNewsMetric: acc=0.8514473684210526, hinge=2.0889983430661654, ce=8.306936519020482
Local test acc @ epoch 153: 0.8514
Global evaluate on test data...
Evaluate data in 130.1 seconds!
[tester] 
AGNewsMetric: acc=0.8469736842105263, hinge=2.683495546642103, ce=7.991944636294717
Global test acc @ epoch 153: 0.847
Global epoch 154...
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 6.79466211295221e-06
Local loss @ local epoch 1: 8.953970245784149e-05
Local loss @ local epoch 2: 5.109712219564244e-05
Local loss @ local epoch 3: 0.007531337905675173
Local loss @ local epoch 4: 3.200842547812499e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.49 seconds!
[tester] 
AGNewsMetric: acc=0.8076315789473684, hinge=3.1656200170516966, ce=8.372039218701815
Local test acc @ epoch 154: 0.8076
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 7.152548846534046e-07
Local loss @ local epoch 1: 2.592770670162281e-06
Local loss @ local epoch 2: 3.203746814506303e-07
Local loss @ local epoch 3: 9.893667083815672e-06
Local loss @ local epoch 4: 9.707410754344892e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.43 seconds!
[tester] 
AGNewsMetric: acc=0.8176315789473684, hinge=3.103452499289262, ce=7.9277349211040296
Local test acc @ epoch 154: 0.8176
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.014355549588799477
Local loss @ local epoch 1: 9.365062396682333e-06
Local loss @ local epoch 2: 0.0026730734389275312
Local loss @ local epoch 3: 0.019250039011240005
Local loss @ local epoch 4: 0.036905430257320404
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.28 seconds!
[tester] 
AGNewsMetric: acc=0.8281578947368421, hinge=2.5355617166820323, ce=8.083310548882736
Local test acc @ epoch 154: 0.8282
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 4.917296791973058e-06
Local loss @ local epoch 1: 6.183968253026251e-07
Local loss @ local epoch 2: 0.000135974187287502
Local loss @ local epoch 3: 6.541510629176628e-06
Local loss @ local epoch 4: 1.4305085187515942e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.32 seconds!
[tester] 
AGNewsMetric: acc=0.8297368421052631, hinge=2.7290488752565887, ce=8.255958615353233
Local test acc @ epoch 154: 0.8297
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 3.2782520520413527e-07
Local loss @ local epoch 1: 2.1606666678053443e-07
Local loss @ local epoch 2: 4.395838288928644e-07
Local loss @ local epoch 3: 1.0832394764292985e-05
Local loss @ local epoch 4: 3.2037482355917746e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.11 seconds!
[tester] 
AGNewsMetric: acc=0.8296052631578947, hinge=2.889304081013328, ce=8.538656923394454
Local test acc @ epoch 154: 0.8296
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450566386069113e-07
Local loss @ local epoch 1: 1.4901158351676713e-07
Local loss @ local epoch 2: 7.740686669421848e-06
Local loss @ local epoch 3: 4.842872840526979e-07
Local loss @ local epoch 4: 1.6987261233225581e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.59 seconds!
[tester] 
AGNewsMetric: acc=0.8472368421052632, hinge=2.3185457430387797, ce=7.710307974564402
Local test acc @ epoch 154: 0.8472
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4379511412698776e-06
Local loss @ local epoch 1: 0.0009140173206105828
Local loss @ local epoch 2: 3.822066446446115e-06
Local loss @ local epoch 3: 9.059596777660772e-06
Local loss @ local epoch 4: 0.0011642141034826636
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.61 seconds!
[tester] 
AGNewsMetric: acc=0.8034210526315789, hinge=3.545383677733572, ce=9.112272284658332
Local test acc @ epoch 154: 0.8034
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 1.9669439552671975e-06
Local loss @ local epoch 1: 0.00011101687414338812
Local loss @ local epoch 2: 1.9594940567913e-06
Local loss @ local epoch 3: 0.02180737815797329
Local loss @ local epoch 4: 9.424672498425934e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.34 seconds!
[tester] 
AGNewsMetric: acc=0.7713157894736842, hinge=4.275326431926928, ce=9.342837658932334
Local test acc @ epoch 154: 0.7713
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 4.9956110160565004e-05
Local loss @ local epoch 1: 0.7640987038612366
Local loss @ local epoch 2: 3.5240650504420046e-06
Local loss @ local epoch 3: 0.08810088038444519
Local loss @ local epoch 4: 0.00957466196268797
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.77 seconds!
[tester] 
AGNewsMetric: acc=0.8548684210526316, hinge=2.1638109059082833, ce=8.785272911473324
Local test acc @ epoch 154: 0.8549
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.000276654667686671
Local loss @ local epoch 1: 5.925754885538481e-05
Local loss @ local epoch 2: 0.04736778512597084
Local loss @ local epoch 3: 0.06609909981489182
Local loss @ local epoch 4: 0.009897630661725998
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.14 seconds!
[tester] 
AGNewsMetric: acc=0.48657894736842106, hinge=10.14496578191456, ce=13.15260039480109
Local test acc @ epoch 154: 0.4866
Global evaluate on test data...
Evaluate data in 130.08 seconds!
[tester] 
AGNewsMetric: acc=0.8539473684210527, hinge=2.6418209540216546, ce=7.802807862131219
Global test acc @ epoch 154: 0.8539
Global epoch 155...
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.03384454920887947
Local loss @ local epoch 1: 0.09314895421266556
Local loss @ local epoch 2: 1.668926188358455e-06
Local loss @ local epoch 3: 0.0001374550920445472
Local loss @ local epoch 4: 0.005458875559270382
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.56 seconds!
[tester] 
AGNewsMetric: acc=0.838421052631579, hinge=2.3836773684150296, ce=8.396873164929842
Local test acc @ epoch 155: 0.8384
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 2.10850498660875e-06
Local loss @ local epoch 1: 5.364413482311647e-07
Local loss @ local epoch 2: 3.816707248915918e-05
Local loss @ local epoch 3: 1.616767690393317e-06
Local loss @ local epoch 4: 5.715219958801754e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.06 seconds!
[tester] 
AGNewsMetric: acc=0.8469736842105263, hinge=2.4981301270033183, ce=8.68267246647885
Local test acc @ epoch 155: 0.847
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 6.228293932508677e-05
Local loss @ local epoch 1: 0.9210644364356995
Local loss @ local epoch 2: 0.00012351854820735753
Local loss @ local epoch 3: 1.2680222425842658e-05
Local loss @ local epoch 4: 0.02088029682636261
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.86 seconds!
[tester] 
AGNewsMetric: acc=0.8398684210526316, hinge=2.34259269262615, ce=8.097729112725508
Local test acc @ epoch 155: 0.8399
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.002111658453941345
Local loss @ local epoch 1: 5.327826875145547e-05
Local loss @ local epoch 2: 0.01020119059830904
Local loss @ local epoch 3: 0.000479476380860433
Local loss @ local epoch 4: 1.2265558242797852
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.5 seconds!
[tester] 
AGNewsMetric: acc=0.8338157894736842, hinge=2.4847978258132937, ce=7.734594515750283
Local test acc @ epoch 155: 0.8338
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 2.7939477149629965e-06
Local loss @ local epoch 1: 1.8700807231653016e-06
Local loss @ local epoch 2: 7.487470156775089e-06
Local loss @ local epoch 3: 8.128253284667153e-06
Local loss @ local epoch 4: 2.2834137780591846e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.91 seconds!
[tester] 
AGNewsMetric: acc=0.8363157894736842, hinge=2.7910024301629317, ce=9.057135322972348
Local test acc @ epoch 155: 0.8363
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 3.3676246857794467e-06
Local loss @ local epoch 1: 2.7148000299348496e-05
Local loss @ local epoch 2: 2.2798503778176382e-06
Local loss @ local epoch 3: 3.971134447056102e-06
Local loss @ local epoch 4: 0.0008491530315950513
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.82 seconds!
[tester] 
AGNewsMetric: acc=0.7980263157894737, hinge=3.4043591072684842, ce=9.530136485852694
Local test acc @ epoch 155: 0.798
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 7.376054895757989e-07
Local loss @ local epoch 1: 1.154837264039088e-06
Local loss @ local epoch 2: 1.5607065506628715e-05
Local loss @ local epoch 3: 1.63166259881109e-06
Local loss @ local epoch 4: 0.0028718155808746815
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.43 seconds!
[tester] 
AGNewsMetric: acc=0.8448684210526316, hinge=2.7739556646347046, ce=8.22889165777909
Local test acc @ epoch 155: 0.8449
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 4.179704319540178e-06
Local loss @ local epoch 1: 2.955081254185643e-05
Local loss @ local epoch 2: 6.489300176326651e-06
Local loss @ local epoch 3: 0.5658097267150879
Local loss @ local epoch 4: 6.690543614240596e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.08 seconds!
[tester] 
AGNewsMetric: acc=0.8502631578947368, hinge=2.2840955950084485, ce=8.107782341806512
Local test acc @ epoch 155: 0.8503
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.6167696230695583e-06
Local loss @ local epoch 1: 0.00317109446041286
Local loss @ local epoch 2: 9.12682298803702e-06
Local loss @ local epoch 3: 0.01083896029740572
Local loss @ local epoch 4: 4.198825990897603e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.11 seconds!
[tester] 
AGNewsMetric: acc=0.8413157894736842, hinge=2.396648981947648, ce=7.93120663090756
Local test acc @ epoch 155: 0.8413
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 5.692122613254469e-06
Local loss @ local epoch 1: 1.77539222931955e-05
Local loss @ local epoch 2: 0.0003729517920874059
Local loss @ local epoch 3: 0.0010681785643100739
Local loss @ local epoch 4: 2.317121015948942e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.74 seconds!
[tester] 
AGNewsMetric: acc=0.8042105263157895, hinge=3.075640687440571, ce=8.820055186623021
Local test acc @ epoch 155: 0.8042
Global evaluate on test data...
Evaluate data in 131.14 seconds!
[tester] 
AGNewsMetric: acc=0.854078947368421, hinge=2.6334463091900475, ce=7.971118095799496
Global test acc @ epoch 155: 0.8541
Global epoch 156...
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 2.0190950635878835e-06
Local loss @ local epoch 1: 6.109468131398899e-07
Local loss @ local epoch 2: 1.2300376511120703e-05
Local loss @ local epoch 3: 3.054736623653298e-07
Local loss @ local epoch 4: 2.3469051484426018e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.15 seconds!
[tester] 
AGNewsMetric: acc=0.8147368421052632, hinge=3.1430552427392255, ce=7.893594506916247
Local test acc @ epoch 156: 0.8147
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.22884595394134521
Local loss @ local epoch 1: 4.388324214232853e-06
Local loss @ local epoch 2: 0.06913802772760391
Local loss @ local epoch 3: 0.9064857363700867
Local loss @ local epoch 4: 0.3872099220752716
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.1 seconds!
[tester] 
AGNewsMetric: acc=0.7425, hinge=4.068976431394878, ce=9.434201565792685
Local test acc @ epoch 156: 0.7425
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 2.905725295931916e-07
Local loss @ local epoch 1: 4.5448425112226687e-07
Local loss @ local epoch 2: 4.619352012014133e-07
Local loss @ local epoch 3: 1.5273523104042397e-06
Local loss @ local epoch 4: 4.879959760728525e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.49 seconds!
[tester] 
AGNewsMetric: acc=0.85, hinge=2.768055678668775, ce=8.092878639823512
Local test acc @ epoch 156: 0.85
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.001664697309024632
Local loss @ local epoch 1: 4.274299863027409e-05
Local loss @ local epoch 2: 0.9822256565093994
Local loss @ local epoch 3: 0.3186800479888916
Local loss @ local epoch 4: 0.03813475742936134
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.08 seconds!
[tester] 
AGNewsMetric: acc=0.7832894736842105, hinge=3.1305000265021072, ce=8.177748233393618
Local test acc @ epoch 156: 0.7833
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 9.593672439223155e-05
Local loss @ local epoch 1: 8.970249837148003e-06
Local loss @ local epoch 2: 0.00017827600822784007
Local loss @ local epoch 3: 0.0844920426607132
Local loss @ local epoch 4: 9.38011180551257e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.13 seconds!
[tester] 
AGNewsMetric: acc=0.8375, hinge=2.8218335206885086, ce=7.552074803804096
Local test acc @ epoch 156: 0.8375
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4379571666722768e-06
Local loss @ local epoch 1: 8.866171583576943e-07
Local loss @ local epoch 2: 1.785661697795149e-05
Local loss @ local epoch 3: 9.138959285337478e-05
Local loss @ local epoch 4: 3.7476211218745448e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.48 seconds!
[tester] 
AGNewsMetric: acc=0.8431578947368421, hinge=2.4635288055319533, ce=8.574884133589896
Local test acc @ epoch 156: 0.8432
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0002401331439614296
Local loss @ local epoch 1: 1.952043476194376e-06
Local loss @ local epoch 2: 0.0004958147183060646
Local loss @ local epoch 3: 0.9837710857391357
Local loss @ local epoch 4: 8.416559285251424e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.61 seconds!
[tester] 
AGNewsMetric: acc=0.7701315789473684, hinge=3.935083041191101, ce=10.66935810691432
Local test acc @ epoch 156: 0.7701
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 4.7683681714261184e-07
Local loss @ local epoch 1: 5.960458793197176e-07
Local loss @ local epoch 2: 4.544848479781649e-07
Local loss @ local epoch 3: 3.9040619412844535e-06
Local loss @ local epoch 4: 0.0001307395432377234
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.4 seconds!
[tester] 
AGNewsMetric: acc=0.8110526315789474, hinge=3.473098796794289, ce=8.044733200073242
Local test acc @ epoch 156: 0.8111
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 2.2575068214791827e-06
Local loss @ local epoch 1: 6.705515147586993e-07
Local loss @ local epoch 2: 4.120134235563455e-06
Local loss @ local epoch 3: 0.02011031284928322
Local loss @ local epoch 4: 8.940334737417288e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.44 seconds!
[tester] 
AGNewsMetric: acc=0.775921052631579, hinge=4.380715719524183, ce=9.426200165999562
Local test acc @ epoch 156: 0.7759
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 2.6958510716212913e-05
Local loss @ local epoch 1: 3.545704748830758e-05
Local loss @ local epoch 2: 5.2610193961299956e-05
Local loss @ local epoch 3: 1.8222854123450816e-05
Local loss @ local epoch 4: 0.0015706355916336179
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.01 seconds!
[tester] 
AGNewsMetric: acc=0.8089473684210526, hinge=2.9614411444413036, ce=8.799941239607962
Local test acc @ epoch 156: 0.8089
Global evaluate on test data...
Evaluate data in 129.47 seconds!
[tester] 
AGNewsMetric: acc=0.8472368421052632, hinge=2.833446119459052, ce=7.7131013789929845
Global test acc @ epoch 156: 0.8472
Global epoch 157...
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00036656102747656405
Local loss @ local epoch 1: 0.01598428562283516
Local loss @ local epoch 2: 2.053907883237116e-05
Local loss @ local epoch 3: 1.4051126527192537e-05
Local loss @ local epoch 4: 0.40913280844688416
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.75 seconds!
[tester] 
AGNewsMetric: acc=0.8161842105263157, hinge=2.971008852155585, ce=7.942269024096038
Local test acc @ epoch 157: 0.8162
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.5795152421560488e-06
Local loss @ local epoch 1: 9.424619747733232e-06
Local loss @ local epoch 2: 2.630037442941102e-06
Local loss @ local epoch 3: 1.1846402685478097e-06
Local loss @ local epoch 4: 1.4081531389820157e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.2 seconds!
[tester] 
AGNewsMetric: acc=0.8472368421052632, hinge=2.687102287443061, ce=8.214722330193771
Local test acc @ epoch 157: 0.8472
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 1.7136329688582919e-07
Local loss @ local epoch 1: 5.736939101552707e-07
Local loss @ local epoch 2: 1.0207274954154855e-06
Local loss @ local epoch 3: 7.301550795091316e-07
Local loss @ local epoch 4: 7.5695488703786395e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.6 seconds!
[tester] 
AGNewsMetric: acc=0.7868421052631579, hinge=3.755722687118932, ce=8.899563233224969
Local test acc @ epoch 157: 0.7868
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 2.456842048559338e-05
Local loss @ local epoch 1: 0.008192957378923893
Local loss @ local epoch 2: 1.8849896150641143e-06
Local loss @ local epoch 3: 1.8253833786729956e-06
Local loss @ local epoch 4: 1.0363163710280787e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.59 seconds!
[tester] 
AGNewsMetric: acc=0.83, hinge=2.898283614359404, ce=9.197440207631965
Local test acc @ epoch 157: 0.83
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0001348602818325162
Local loss @ local epoch 1: 1.4967079550842755e-05
Local loss @ local epoch 2: 0.0002757878683041781
Local loss @ local epoch 3: 0.02419528365135193
Local loss @ local epoch 4: 8.255071406892966e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 131.08 seconds!
[tester] 
AGNewsMetric: acc=0.8497368421052631, hinge=2.4915466040059138, ce=7.794927910252621
Local test acc @ epoch 157: 0.8497
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 2.2128047021396924e-06
Local loss @ local epoch 1: 1.922241835927707e-06
Local loss @ local epoch 2: 0.23998385667800903
Local loss @ local epoch 3: 4.559710305329645e-06
Local loss @ local epoch 4: 0.00015344834537245333
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.81 seconds!
[tester] 
AGNewsMetric: acc=0.8230263157894737, hinge=2.8784178324749594, ce=8.348511380647357
Local test acc @ epoch 157: 0.823
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00010793601541081443
Local loss @ local epoch 1: 9.685739996712073e-07
Local loss @ local epoch 2: 2.8535459932754748e-06
Local loss @ local epoch 3: 0.012103023007512093
Local loss @ local epoch 4: 2.5768169507500716e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.42 seconds!
[tester] 
AGNewsMetric: acc=0.724078947368421, hinge=4.6589551855388445, ce=10.176141174717953
Local test acc @ epoch 157: 0.7241
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 1.775258351699449e-05
Local loss @ local epoch 1: 7.5250136433169246e-06
Local loss @ local epoch 2: 0.6335216760635376
Local loss @ local epoch 3: 0.0005964853335171938
Local loss @ local epoch 4: 0.5171093940734863
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.52 seconds!
[tester] 
AGNewsMetric: acc=0.7068421052631579, hinge=4.647252009291398, ce=9.69361083984375
Local test acc @ epoch 157: 0.7068
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 2.756713683993439e-07
Local loss @ local epoch 1: 1.6316693063345156e-06
Local loss @ local epoch 2: 2.1606669520224386e-07
Local loss @ local epoch 3: 5.364411777009082e-07
Local loss @ local epoch 4: 3.2484133498655865e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.3 seconds!
[tester] 
AGNewsMetric: acc=0.8459210526315789, hinge=2.5834672558935066, ce=8.519532943524812
Local test acc @ epoch 157: 0.8459
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 3.60602825821843e-06
Local loss @ local epoch 1: 1.2761602192767896e-05
Local loss @ local epoch 2: 0.0009366414742544293
Local loss @ local epoch 3: 5.6921480791061185e-06
Local loss @ local epoch 4: 2.4256863980554044e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.5 seconds!
[tester] 
AGNewsMetric: acc=0.8001315789473684, hinge=2.945076080623426, ce=9.294515589663856
Local test acc @ epoch 157: 0.8001
Global evaluate on test data...
Evaluate data in 130.08 seconds!
[tester] 
AGNewsMetric: acc=0.8547368421052631, hinge=2.657268722182826, ce=7.787316025181821
Global test acc @ epoch 157: 0.8547
Global epoch 158...
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 2.0993538782931864e-05
Local loss @ local epoch 1: 0.00015056715346872807
Local loss @ local epoch 2: 2.8108772312407382e-05
Local loss @ local epoch 3: 6.474214023910463e-05
Local loss @ local epoch 4: 0.13766321539878845
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.12 seconds!
[tester] 
AGNewsMetric: acc=0.780921052631579, hinge=3.795281404445046, ce=9.079199983697189
Local test acc @ epoch 158: 0.7809
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 1.7387597836204804e-05
Local loss @ local epoch 1: 1.8179365497417166e-06
Local loss @ local epoch 2: 5.09713172505144e-05
Local loss @ local epoch 3: 1.5720048395451158e-05
Local loss @ local epoch 4: 6.802273219363997e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.71 seconds!
[tester] 
AGNewsMetric: acc=0.8468421052631578, hinge=2.368995053517191, ce=8.600075135481985
Local test acc @ epoch 158: 0.8468
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 8.940673978941049e-07
Local loss @ local epoch 1: 1.4156066754367203e-06
Local loss @ local epoch 2: 4.567068572214339e-06
Local loss @ local epoch 3: 1.5199107110674959e-06
Local loss @ local epoch 4: 0.2303832471370697
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.0 seconds!
[tester] 
AGNewsMetric: acc=0.8413157894736842, hinge=3.0100211273996456, ce=7.805276133888646
Local test acc @ epoch 158: 0.8413
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 6.962696352275088e-05
Local loss @ local epoch 1: 3.859336629830068e-06
Local loss @ local epoch 2: 0.05101289227604866
Local loss @ local epoch 3: 1.745596091495827e-05
Local loss @ local epoch 4: 0.00017391718574799597
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.59 seconds!
[tester] 
AGNewsMetric: acc=0.8027631578947368, hinge=2.9464646507564343, ce=8.92888677095112
Local test acc @ epoch 158: 0.8028
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 6.705506621074164e-07
Local loss @ local epoch 1: 2.8312183530943e-07
Local loss @ local epoch 2: 0.00035375478910282254
Local loss @ local epoch 3: 3.427265085065301e-07
Local loss @ local epoch 4: 1.4007064237375744e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.98 seconds!
[tester] 
AGNewsMetric: acc=0.7936842105263158, hinge=3.583033686939039, ce=8.636901313380191
Local test acc @ epoch 158: 0.7937
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 3.5762766970037774e-07
Local loss @ local epoch 1: 6.631006499446812e-07
Local loss @ local epoch 2: 0.00024412253696937114
Local loss @ local epoch 3: 1.1175837926202803e-06
Local loss @ local epoch 4: 3.19623882205633e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.67 seconds!
[tester] 
AGNewsMetric: acc=0.8171052631578948, hinge=2.7186219185277034, ce=9.700436375266626
Local test acc @ epoch 158: 0.8171
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 6.556497282872442e-07
Local loss @ local epoch 1: 2.756713683993439e-07
Local loss @ local epoch 2: 2.1308576378942234e-06
Local loss @ local epoch 3: 4.321332482959406e-07
Local loss @ local epoch 4: 2.5331962660857243e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.93 seconds!
[tester] 
AGNewsMetric: acc=0.8455263157894737, hinge=2.485237668187995, ce=8.38717751151637
Local test acc @ epoch 158: 0.8455
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 8.717156561033335e-07
Local loss @ local epoch 1: 7.674077551200753e-07
Local loss @ local epoch 2: 2.2276963136391714e-06
Local loss @ local epoch 3: 8.493639711559808e-07
Local loss @ local epoch 4: 2.42886471824022e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.67 seconds!
[tester] 
AGNewsMetric: acc=0.8265789473684211, hinge=2.810533719313772, ce=8.180093126798932
Local test acc @ epoch 158: 0.8266
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0009342958801425993
Local loss @ local epoch 1: 1.0430558177176863e-05
Local loss @ local epoch 2: 0.049117352813482285
Local loss @ local epoch 3: 4.3436411942821e-06
Local loss @ local epoch 4: 0.20505571365356445
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.44 seconds!
[tester] 
AGNewsMetric: acc=0.820921052631579, hinge=2.969455471540752, ce=8.67054894095973
Local test acc @ epoch 158: 0.8209
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0005294299335218966
Local loss @ local epoch 1: 0.0018010020721703768
Local loss @ local epoch 2: 2.741796379268635e-06
Local loss @ local epoch 3: 0.00019042575149796903
Local loss @ local epoch 4: 0.03128892928361893
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.1 seconds!
[tester] 
AGNewsMetric: acc=0.8448684210526316, hinge=2.4450654614599125, ce=7.953443816335578
Local test acc @ epoch 158: 0.8449
Global evaluate on test data...
Evaluate data in 129.43 seconds!
[tester] 
AGNewsMetric: acc=0.8489473684210527, hinge=2.7505855896598415, ce=7.960005712007222
Global test acc @ epoch 158: 0.8489
Global epoch 159...
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0004873306315857917
Local loss @ local epoch 1: 4.2940344428643584e-05
Local loss @ local epoch 2: 0.8574644923210144
Local loss @ local epoch 3: 0.0007078915368765593
Local loss @ local epoch 4: 0.42177432775497437
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.67 seconds!
[tester] 
AGNewsMetric: acc=0.8401315789473685, hinge=2.2419922565159043, ce=7.128922675283332
Local test acc @ epoch 159: 0.8401
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 9.38771677283512e-07
Local loss @ local epoch 1: 3.576275275918306e-07
Local loss @ local epoch 2: 1.288945668420638e-06
Local loss @ local epoch 3: 1.6018580026866402e-06
Local loss @ local epoch 4: 6.280650268308818e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.49 seconds!
[tester] 
AGNewsMetric: acc=0.8227631578947369, hinge=3.2068166810587835, ce=8.400956762213456
Local test acc @ epoch 159: 0.8228
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 6.929029723323765e-07
Local loss @ local epoch 1: 0.00030998417059890926
Local loss @ local epoch 2: 0.00020078381930943578
Local loss @ local epoch 3: 1.355774164199829
Local loss @ local epoch 4: 1.0407847184978891e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.42 seconds!
[tester] 
AGNewsMetric: acc=0.8467105263157895, hinge=2.62715791212885, ce=7.934418758593107
Local test acc @ epoch 159: 0.8467
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 2.1010550881328527e-06
Local loss @ local epoch 1: 2.9343291316763498e-05
Local loss @ local epoch 2: 0.7218511700630188
Local loss @ local epoch 3: 5.662433295583469e-07
Local loss @ local epoch 4: 0.636044979095459
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.93 seconds!
[tester] 
AGNewsMetric: acc=0.7853947368421053, hinge=3.777195241576747, ce=9.498195567883943
Local test acc @ epoch 159: 0.7854
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 2.3841846541472478e-07
Local loss @ local epoch 1: 4.358527803560719e-06
Local loss @ local epoch 2: 6.183972232065571e-07
Local loss @ local epoch 3: 0.0007231098134070635
Local loss @ local epoch 4: 5.014060207031434e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.95 seconds!
[tester] 
AGNewsMetric: acc=0.8276315789473684, hinge=3.0652051431254335, ce=7.692841929385537
Local test acc @ epoch 159: 0.8276
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 2.0116557664096035e-07
Local loss @ local epoch 1: 1.773215331013489e-06
Local loss @ local epoch 2: 5.215401870373171e-07
Local loss @ local epoch 3: 7.376049779850291e-07
Local loss @ local epoch 4: 9.462212346988963e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.72 seconds!
[tester] 
AGNewsMetric: acc=0.8081578947368421, hinge=3.2224785265169644, ce=8.344411032827278
Local test acc @ epoch 159: 0.8082
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 2.4288531221827725e-06
Local loss @ local epoch 1: 3.5836594634020003e-06
Local loss @ local epoch 2: 7.525077307946049e-07
Local loss @ local epoch 3: 9.722709364723414e-06
Local loss @ local epoch 4: 0.19001562893390656
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.72 seconds!
[tester] 
AGNewsMetric: acc=0.8111842105263158, hinge=3.6547179121720164, ce=9.101972696404708
Local test acc @ epoch 159: 0.8112
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 5.215399596636416e-07
Local loss @ local epoch 1: 4.32133077765684e-07
Local loss @ local epoch 2: 1.4901156930591242e-07
Local loss @ local epoch 3: 1.2665958593061077e-06
Local loss @ local epoch 4: 5.066389121566317e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.25 seconds!
[tester] 
AGNewsMetric: acc=0.8468421052631578, hinge=2.604162695533351, ce=8.600768858257092
Local test acc @ epoch 159: 0.8468
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 2.8758738608303247e-06
Local loss @ local epoch 1: 8.068546776485164e-06
Local loss @ local epoch 2: 4.7683673187748354e-07
Local loss @ local epoch 3: 5.453694484458538e-06
Local loss @ local epoch 4: 6.5042863752751146e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.52 seconds!
[tester] 
AGNewsMetric: acc=0.8364473684210526, hinge=2.81909055207905, ce=8.731632318998638
Local test acc @ epoch 159: 0.8364
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 6.846645555924624e-05
Local loss @ local epoch 1: 2.7236881578573957e-05
Local loss @ local epoch 2: 0.0008752782014198601
Local loss @ local epoch 3: 0.000437096634414047
Local loss @ local epoch 4: 2.057100296020508
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.51 seconds!
[tester] 
AGNewsMetric: acc=0.8423684210526315, hinge=2.6678292660964162, ce=8.115987125195955
Local test acc @ epoch 159: 0.8424
Global evaluate on test data...
Evaluate data in 129.89 seconds!
[tester] 
AGNewsMetric: acc=0.8492105263157895, hinge=2.8301844192806045, ce=7.904373038442511
Global test acc @ epoch 159: 0.8492
Global epoch 160...
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 3.799788999003795e-07
Local loss @ local epoch 1: 3.6507822187559213e-07
Local loss @ local epoch 2: 2.90572359062935e-07
Local loss @ local epoch 3: 1.3067087820672896e-05
Local loss @ local epoch 4: 2.458689607465203e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.09 seconds!
[tester] 
AGNewsMetric: acc=0.838421052631579, hinge=2.993185712663751, ce=8.499197461981522
Local test acc @ epoch 160: 0.8384
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 1.847721250669565e-06
Local loss @ local epoch 1: 0.00010957693302771077
Local loss @ local epoch 2: 1.981841023734887e-06
Local loss @ local epoch 3: 1.6242150877587846e-06
Local loss @ local epoch 4: 7.703735718678217e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.39 seconds!
[tester] 
AGNewsMetric: acc=0.8325, hinge=2.578215012801321, ce=7.729378832766884
Local test acc @ epoch 160: 0.8325
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 3.784809450735338e-06
Local loss @ local epoch 1: 7.45056354389817e-07
Local loss @ local epoch 2: 0.00014589015336241573
Local loss @ local epoch 3: 3.293041663710028e-05
Local loss @ local epoch 4: 3.958111483370885e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 131.11 seconds!
[tester] 
AGNewsMetric: acc=0.8565789473684211, hinge=2.3888709156136763, ce=8.238680962010434
Local test acc @ epoch 160: 0.8566
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 3.874294804973033e-07
Local loss @ local epoch 1: 2.5108006411755923e-06
Local loss @ local epoch 2: 1.0952337561320746e-06
Local loss @ local epoch 3: 3.4868312468461227e-06
Local loss @ local epoch 4: 2.7196414521313272e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.86 seconds!
[tester] 
AGNewsMetric: acc=0.8352631578947368, hinge=3.025540825191297, ce=8.877536586962249
Local test acc @ epoch 160: 0.8353
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 1.2665984172599565e-07
Local loss @ local epoch 1: 1.1175868053214799e-07
Local loss @ local epoch 2: 2.682208162241295e-07
Local loss @ local epoch 3: 8.940695295223122e-08
Local loss @ local epoch 4: 1.6391273049976007e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.75 seconds!
[tester] 
AGNewsMetric: acc=0.8426315789473684, hinge=2.7989940106241327, ce=8.344915958203767
Local test acc @ epoch 160: 0.8426
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 1.7881218354887096e-06
Local loss @ local epoch 1: 7.003537803029758e-07
Local loss @ local epoch 2: 7.986865057318937e-06
Local loss @ local epoch 3: 1.5422631349792937e-06
Local loss @ local epoch 4: 3.8667240005452186e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.09 seconds!
[tester] 
AGNewsMetric: acc=0.7946052631578947, hinge=4.01190211747822, ce=9.216199405067846
Local test acc @ epoch 160: 0.7946
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 8.612558303866535e-06
Local loss @ local epoch 1: 1.9967508251284016e-06
Local loss @ local epoch 2: 0.3260549306869507
Local loss @ local epoch 3: 0.00016631865582894534
Local loss @ local epoch 4: 0.0004903656663373113
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.74 seconds!
[tester] 
AGNewsMetric: acc=0.8072368421052631, hinge=3.1239979716351156, ce=9.009974602147153
Local test acc @ epoch 160: 0.8072
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0005278369062580168
Local loss @ local epoch 1: 0.016811318695545197
Local loss @ local epoch 2: 0.0012663959059864283
Local loss @ local epoch 3: 8.226269710576162e-05
Local loss @ local epoch 4: 0.405690997838974
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.33 seconds!
[tester] 
AGNewsMetric: acc=0.8232894736842106, hinge=2.9124584105140285, ce=9.066133324472528
Local test acc @ epoch 160: 0.8233
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0034110997803509235
Local loss @ local epoch 1: 7.480215572286397e-06
Local loss @ local epoch 2: 0.958818793296814
Local loss @ local epoch 3: 0.0017605210887268186
Local loss @ local epoch 4: 0.0008132532238960266
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.56 seconds!
[tester] 
AGNewsMetric: acc=0.8269736842105263, hinge=2.4235282350841323, ce=8.21426566073769
Local test acc @ epoch 160: 0.827
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 1.0952296634059167e-06
Local loss @ local epoch 1: 1.9967308162449626e-06
Local loss @ local epoch 2: 1.0058249699795851e-06
Local loss @ local epoch 3: 3.3229391647182638e-06
Local loss @ local epoch 4: 0.004062815569341183
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.01 seconds!
[tester] 
AGNewsMetric: acc=0.8036842105263158, hinge=3.857903942057961, ce=8.136345518011796
Local test acc @ epoch 160: 0.8037
Global evaluate on test data...
Evaluate data in 130.1 seconds!
[tester] 
AGNewsMetric: acc=0.8505263157894737, hinge=2.808015264711882, ce=7.955457809849789
Global test acc @ epoch 160: 0.8505
Global epoch 161...
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 6.137781019788235e-05
Local loss @ local epoch 1: 8.195624445761496e-07
Local loss @ local epoch 2: 1.739308476448059
Local loss @ local epoch 3: 0.0011647064238786697
Local loss @ local epoch 4: 0.3317493200302124
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.68 seconds!
[tester] 
AGNewsMetric: acc=0.7476315789473684, hinge=4.6998008062964995, ce=10.254208426224558
Local test acc @ epoch 161: 0.7476
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 5.72676544834394e-05
Local loss @ local epoch 1: 1.212122879223898e-05
Local loss @ local epoch 2: 1.6097408533096313
Local loss @ local epoch 3: 0.001475770492106676
Local loss @ local epoch 4: 0.002406052080914378
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.15 seconds!
[tester] 
AGNewsMetric: acc=0.8121052631578948, hinge=2.1146323178943836, ce=6.918843556454307
Local test acc @ epoch 161: 0.8121
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 1.7881387748275301e-07
Local loss @ local epoch 1: 4.470348002882929e-08
Local loss @ local epoch 2: 4.023308690648264e-07
Local loss @ local epoch 3: 2.756712547125062e-07
Local loss @ local epoch 4: 4.917372962154332e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.43 seconds!
[tester] 
AGNewsMetric: acc=0.8497368421052631, hinge=2.6842132949829103, ce=8.227829501503392
Local test acc @ epoch 161: 0.8497
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 2.5331945607831585e-07
Local loss @ local epoch 1: 1.7136329688582919e-07
Local loss @ local epoch 2: 4.455332600628026e-06
Local loss @ local epoch 3: 6.70552182668871e-08
Local loss @ local epoch 4: 9.313203008787241e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.37 seconds!
[tester] 
AGNewsMetric: acc=0.8057894736842105, hinge=3.360991264895389, ce=8.703400635970267
Local test acc @ epoch 161: 0.8058
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 7.376048642981914e-07
Local loss @ local epoch 1: 5.945351404079702e-06
Local loss @ local epoch 2: 2.2649630864179926e-06
Local loss @ local epoch 3: 5.684645657311194e-06
Local loss @ local epoch 4: 1.61670886882348e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.02 seconds!
[tester] 
AGNewsMetric: acc=0.7885526315789474, hinge=3.719390648540698, ce=8.340288664165296
Local test acc @ epoch 161: 0.7886
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.010219288058578968
Local loss @ local epoch 1: 0.00020994464284740388
Local loss @ local epoch 2: 0.021610459312796593
Local loss @ local epoch 3: 0.002001814544200897
Local loss @ local epoch 4: 0.004292955156415701
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.22 seconds!
[tester] 
AGNewsMetric: acc=0.8372368421052632, hinge=2.315523464052301, ce=7.952560426812423
Local test acc @ epoch 161: 0.8372
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 1.0132729357792414e-06
Local loss @ local epoch 1: 1.0654300695023267e-06
Local loss @ local epoch 2: 2.1308565010258462e-06
Local loss @ local epoch 3: 4.4703386947730905e-07
Local loss @ local epoch 4: 4.991881610294513e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.66 seconds!
[tester] 
AGNewsMetric: acc=0.8194736842105264, hinge=3.143038379769576, ce=8.374935268602874
Local test acc @ epoch 161: 0.8195
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 7.972113280629856e-07
Local loss @ local epoch 1: 3.799794114911492e-07
Local loss @ local epoch 2: 9.313212672168447e-07
Local loss @ local epoch 3: 3.258053038734943e-05
Local loss @ local epoch 4: 4.135031304031145e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.9 seconds!
[tester] 
AGNewsMetric: acc=0.7272368421052632, hinge=4.960598922528718, ce=9.647489527652137
Local test acc @ epoch 161: 0.7272
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 7.972096227604197e-07
Local loss @ local epoch 1: 1.1920926112907182e-07
Local loss @ local epoch 2: 9.697657515062019e-05
Local loss @ local epoch 3: 5.960457656328799e-07
Local loss @ local epoch 4: 2.3236050765262917e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.8 seconds!
[tester] 
AGNewsMetric: acc=0.704078947368421, hinge=5.909805810827958, ce=9.960162096525494
Local test acc @ epoch 161: 0.7041
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 1.415610029198433e-07
Local loss @ local epoch 1: 4.8707897803978994e-05
Local loss @ local epoch 2: 1.557157474962878e-06
Local loss @ local epoch 3: 0.00012959956075064838
Local loss @ local epoch 4: 0.00012348130985628814
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.16 seconds!
[tester] 
AGNewsMetric: acc=0.7946052631578947, hinge=3.690754186730636, ce=9.23449385994359
Local test acc @ epoch 161: 0.7946
Global evaluate on test data...
Evaluate data in 129.42 seconds!
[tester] 
AGNewsMetric: acc=0.825, hinge=3.449020027863352, ce=8.234477761921129
Global test acc @ epoch 161: 0.825
Global epoch 162...
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 1.043075940287963e-06
Local loss @ local epoch 1: 4.38080223830184e-06
Local loss @ local epoch 2: 9.462195293963305e-07
Local loss @ local epoch 3: 3.0546950711141108e-06
Local loss @ local epoch 4: 3.816616299445741e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.9 seconds!
[tester] 
AGNewsMetric: acc=0.8115789473684211, hinge=3.3759926452134783, ce=8.766226680153295
Local test acc @ epoch 162: 0.8116
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.415610029198433e-07
Local loss @ local epoch 1: 8.121112387016183e-07
Local loss @ local epoch 2: 4.5448462060448946e-07
Local loss @ local epoch 3: 4.91737750962784e-07
Local loss @ local epoch 4: 4.649096808861941e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.3 seconds!
[tester] 
AGNewsMetric: acc=0.8339473684210527, hinge=3.130606114487899, ce=7.960242797450015
Local test acc @ epoch 162: 0.8339
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 5.662423063768074e-07
Local loss @ local epoch 1: 1.4081492736295331e-06
Local loss @ local epoch 2: 2.682207878024201e-07
Local loss @ local epoch 3: 6.124134870333364e-06
Local loss @ local epoch 4: 0.005880880635231733
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.69 seconds!
[tester] 
AGNewsMetric: acc=0.8018421052631579, hinge=3.5314491445139833, ce=8.789763723674573
Local test acc @ epoch 162: 0.8018
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 4.0978176230055396e-07
Local loss @ local epoch 1: 8.940694584680386e-08
Local loss @ local epoch 2: 9.21603168535512e-06
Local loss @ local epoch 3: 1.0601384019537363e-05
Local loss @ local epoch 4: 0.7246928811073303
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.44 seconds!
[tester] 
AGNewsMetric: acc=0.8267105263157895, hinge=3.324222883174294, ce=8.78813205317447
Local test acc @ epoch 162: 0.8267
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 1.1175869474300271e-07
Local loss @ local epoch 1: 2.3841840857130592e-07
Local loss @ local epoch 2: 1.415610029198433e-07
Local loss @ local epoch 3: 4.2468229821679415e-07
Local loss @ local epoch 4: 2.83121636357464e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.59 seconds!
[tester] 
AGNewsMetric: acc=0.8482894736842105, hinge=2.9170185126756367, ce=7.8488638646979085
Local test acc @ epoch 162: 0.8483
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00020023249089717865
Local loss @ local epoch 1: 0.00010865614603972062
Local loss @ local epoch 2: 7.724903844064102e-05
Local loss @ local epoch 3: 0.004762509372085333
Local loss @ local epoch 4: 8.620214066468179e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.72 seconds!
[tester] 
AGNewsMetric: acc=0.8397368421052631, hinge=2.180489182472229, ce=8.239379736247816
Local test acc @ epoch 162: 0.8397
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 2.0116559085181507e-07
Local loss @ local epoch 1: 1.9371503867660067e-07
Local loss @ local epoch 2: 7.227051241898153e-07
Local loss @ local epoch 3: 9.611217137717176e-07
Local loss @ local epoch 4: 6.034955504219397e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.51 seconds!
[tester] 
AGNewsMetric: acc=0.839078947368421, hinge=3.0406089474025526, ce=8.393330704538446
Local test acc @ epoch 162: 0.8391
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00014019545051269233
Local loss @ local epoch 1: 0.0009263741667382419
Local loss @ local epoch 2: 0.0006052805110812187
Local loss @ local epoch 3: 0.0004169907479081303
Local loss @ local epoch 4: 0.9030080437660217
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.82 seconds!
[tester] 
AGNewsMetric: acc=0.8082894736842106, hinge=3.123548022320396, ce=8.562836179231342
Local test acc @ epoch 162: 0.8083
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 3.1440722523257136e-06
Local loss @ local epoch 1: 1.1175869474300271e-07
Local loss @ local epoch 2: 6.734994258295046e-06
Local loss @ local epoch 3: 1.557168502586137e-06
Local loss @ local epoch 4: 1.1009156703948975
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.93 seconds!
[tester] 
AGNewsMetric: acc=0.8373684210526315, hinge=2.560019598760103, ce=8.050211791992188
Local test acc @ epoch 162: 0.8374
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 1.1920927533992653e-07
Local loss @ local epoch 1: 2.2351707684720168e-07
Local loss @ local epoch 2: 2.0041866264364216e-06
Local loss @ local epoch 3: 8.19563723553074e-08
Local loss @ local epoch 4: 1.788138632718983e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.87 seconds!
[tester] 
AGNewsMetric: acc=0.8001315789473684, hinge=3.96504276175248, ce=8.456641518442254
Local test acc @ epoch 162: 0.8001
Global evaluate on test data...
Evaluate data in 129.67 seconds!
[tester] 
AGNewsMetric: acc=0.8476315789473684, hinge=2.942292974873593, ce=7.967645177339253
Global test acc @ epoch 162: 0.8476
Global epoch 163...
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 2.384183801495965e-07
Local loss @ local epoch 1: 8.568128464503388e-07
Local loss @ local epoch 2: 0.0004854181606788188
Local loss @ local epoch 3: 4.917368414680823e-07
Local loss @ local epoch 4: 4.075719334650785e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.28 seconds!
[tester] 
AGNewsMetric: acc=0.7743421052631579, hinge=4.037271644692672, ce=8.479294020000257
Local test acc @ epoch 163: 0.7743
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 7.557046774309129e-05
Local loss @ local epoch 1: 0.02088138833642006
Local loss @ local epoch 2: 3.3899641493917443e-06
Local loss @ local epoch 3: 0.03340477496385574
Local loss @ local epoch 4: 0.22633591294288635
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.56 seconds!
[tester] 
AGNewsMetric: acc=0.8213157894736842, hinge=3.0622720926686338, ce=8.395291071440043
Local test acc @ epoch 163: 0.8213
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 2.3841835172788706e-07
Local loss @ local epoch 1: 1.9371501025489124e-07
Local loss @ local epoch 2: 1.1175868053214799e-07
Local loss @ local epoch 3: 1.1175868763757535e-07
Local loss @ local epoch 4: 3.203746814506303e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.2 seconds!
[tester] 
AGNewsMetric: acc=0.8327631578947369, hinge=3.1660598278045655, ce=8.208288911518297
Local test acc @ epoch 163: 0.8328
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 2.279861973875086e-06
Local loss @ local epoch 1: 3.0547363394362037e-07
Local loss @ local epoch 2: 0.2716882824897766
Local loss @ local epoch 3: 2.3767188395140693e-06
Local loss @ local epoch 4: 2.7119917831441853e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.38 seconds!
[tester] 
AGNewsMetric: acc=0.8517105263157895, hinge=2.330172317655463, ce=7.980013088427092
Local test acc @ epoch 163: 0.8517
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 1.7881387748275301e-07
Local loss @ local epoch 1: 8.940693874137651e-08
Local loss @ local epoch 2: 2.8312157951404515e-07
Local loss @ local epoch 3: 1.691265424597077e-06
Local loss @ local epoch 4: 2.5331962660857243e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.16 seconds!
[tester] 
AGNewsMetric: acc=0.8197368421052632, hinge=3.5908033943176267, ce=8.351255879653127
Local test acc @ epoch 163: 0.8197
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 3.874299636663636e-07
Local loss @ local epoch 1: 1.415599058418593e-06
Local loss @ local epoch 2: 6.78001356391178e-07
Local loss @ local epoch 3: 1.6838228020787938e-06
Local loss @ local epoch 4: 8.552891813451424e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.89 seconds!
[tester] 
AGNewsMetric: acc=0.8289473684210527, hinge=3.422258812753778, ce=8.547318123265317
Local test acc @ epoch 163: 0.8289
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00012867512123193592
Local loss @ local epoch 1: 6.779877367080189e-06
Local loss @ local epoch 2: 0.0018946576165035367
Local loss @ local epoch 3: 0.0007396134315058589
Local loss @ local epoch 4: 0.14993791282176971
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.83 seconds!
[tester] 
AGNewsMetric: acc=0.8185526315789474, hinge=3.1373229561353986, ce=8.266714152285926
Local test acc @ epoch 163: 0.8186
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 1.3634423794428585e-06
Local loss @ local epoch 1: 1.1175868053214799e-07
Local loss @ local epoch 2: 0.8572493195533752
Local loss @ local epoch 3: 2.771600520645734e-06
Local loss @ local epoch 4: 4.9023956307792105e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.4 seconds!
[tester] 
AGNewsMetric: acc=0.810921052631579, hinge=3.4396616411209107, ce=7.786652400368139
Local test acc @ epoch 163: 0.8109
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 2.972717766169808e-06
Local loss @ local epoch 1: 0.12966829538345337
Local loss @ local epoch 2: 2.8907925297971815e-06
Local loss @ local epoch 3: 2.5257368179154582e-06
Local loss @ local epoch 4: 0.02751697041094303
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.74 seconds!
[tester] 
AGNewsMetric: acc=0.8330263157894737, hinge=2.711338384778876, ce=9.128915481567383
Local test acc @ epoch 163: 0.833
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 2.7567119786908734e-07
Local loss @ local epoch 1: 5.438902803689416e-07
Local loss @ local epoch 2: 7.450579175838357e-08
Local loss @ local epoch 3: 5.908213552174857e-06
Local loss @ local epoch 4: 7.376044095508405e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.3 seconds!
[tester] 
AGNewsMetric: acc=0.8380263157894737, hinge=3.221556850483543, ce=8.035855477985583
Local test acc @ epoch 163: 0.838
Global evaluate on test data...
Evaluate data in 130.39 seconds!
[tester] 
AGNewsMetric: acc=0.8376315789473684, hinge=3.1697550597943756, ce=7.936770217293187
Global test acc @ epoch 163: 0.8376
Global epoch 164...
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0002157189737772569
Local loss @ local epoch 1: 0.0011183550814166665
Local loss @ local epoch 2: 9.484805923420936e-05
Local loss @ local epoch 3: 0.0050476728938519955
Local loss @ local epoch 4: 0.00046669633593410254
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.83 seconds!
[tester] 
AGNewsMetric: acc=0.8381578947368421, hinge=2.5581082717995893, ce=8.324554569846706
Local test acc @ epoch 164: 0.8382
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 1.0058267889689887e-06
Local loss @ local epoch 1: 3.501767764646502e-07
Local loss @ local epoch 2: 8.344633215529029e-07
Local loss @ local epoch 3: 8.270128546428168e-07
Local loss @ local epoch 4: 0.21489742398262024
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.13 seconds!
[tester] 
AGNewsMetric: acc=0.8189473684210526, hinge=3.598847019295943, ce=8.678538366618909
Local test acc @ epoch 164: 0.8189
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 1.5646216411369096e-07
Local loss @ local epoch 1: 3.3527592790960625e-07
Local loss @ local epoch 2: 2.607701503620774e-07
Local loss @ local epoch 3: 3.576276128569589e-07
Local loss @ local epoch 4: 1.5646212148112681e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.14 seconds!
[tester] 
AGNewsMetric: acc=0.7602631578947369, hinge=4.571491389776531, ce=9.735186520626671
Local test acc @ epoch 164: 0.7603
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 9.83472659754625e-07
Local loss @ local epoch 1: 8.195637946073475e-08
Local loss @ local epoch 2: 3.7997926938260207e-07
Local loss @ local epoch 3: 4.060500941704959e-06
Local loss @ local epoch 4: 5.736941375289462e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.84 seconds!
[tester] 
AGNewsMetric: acc=0.8494736842105263, hinge=2.5630164392370927, ce=8.038355141689904
Local test acc @ epoch 164: 0.8495
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 5.4684992392139975e-06
Local loss @ local epoch 1: 1.7881389169360773e-07
Local loss @ local epoch 2: 3.943128103855997e-05
Local loss @ local epoch 3: 6.057083737687208e-06
Local loss @ local epoch 4: 0.0001548964937683195
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.92 seconds!
[tester] 
AGNewsMetric: acc=0.8414473684210526, hinge=2.8368204882270414, ce=8.072235689665142
Local test acc @ epoch 164: 0.8414
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 3.8742982155781647e-07
Local loss @ local epoch 1: 2.3096789902865567e-07
Local loss @ local epoch 2: 1.4156096028727916e-07
Local loss @ local epoch 3: 1.6018598216760438e-06
Local loss @ local epoch 4: 1.8551845641923137e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.99 seconds!
[tester] 
AGNewsMetric: acc=0.8473684210526315, hinge=3.0102992097955, ce=8.032341376856754
Local test acc @ epoch 164: 0.8474
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.45858946442604065
Local loss @ local epoch 1: 5.006631909054704e-06
Local loss @ local epoch 2: 5.364369826565962e-06
Local loss @ local epoch 3: 0.5870331525802612
Local loss @ local epoch 4: 0.0018691390287131071
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.23 seconds!
[tester] 
AGNewsMetric: acc=0.8153947368421053, hinge=2.695749666565343, ce=8.448440188357704
Local test acc @ epoch 164: 0.8154
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 1.2188523214717861e-05
Local loss @ local epoch 1: 1.7835996914072894e-05
Local loss @ local epoch 2: 2.5853159968391992e-06
Local loss @ local epoch 3: 0.0048316786997020245
Local loss @ local epoch 4: 0.0002589637879282236
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.54 seconds!
[tester] 
AGNewsMetric: acc=0.8513157894736842, hinge=2.518752653473302, ce=8.149972903603002
Local test acc @ epoch 164: 0.8513
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 1.2144407719461014e-06
Local loss @ local epoch 1: 2.510826561774593e-06
Local loss @ local epoch 2: 0.00016800480079837143
Local loss @ local epoch 3: 5.776965190307237e-05
Local loss @ local epoch 4: 3.607419057516381e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.4 seconds!
[tester] 
AGNewsMetric: acc=0.805, hinge=3.49074181857862, ce=8.66235968740363
Local test acc @ epoch 164: 0.805
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 1.0654289326339494e-06
Local loss @ local epoch 1: 0.008301910944283009
Local loss @ local epoch 2: 1.8626445807967684e-07
Local loss @ local epoch 3: 5.215401301938982e-07
Local loss @ local epoch 4: 0.006150136701762676
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.17 seconds!
[tester] 
AGNewsMetric: acc=0.7356578947368421, hinge=4.761650499795612, ce=10.0504263245432
Local test acc @ epoch 164: 0.7357
Global evaluate on test data...
Evaluate data in 130.34 seconds!
[tester] 
AGNewsMetric: acc=0.8517105263157895, hinge=2.8418748097670705, ce=7.8964705226295875
Global test acc @ epoch 164: 0.8517
Global epoch 165...
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 1.0430812125150624e-07
Local loss @ local epoch 1: 1.4901156930591242e-07
Local loss @ local epoch 2: 0.6445074677467346
Local loss @ local epoch 3: 1.4155982626107289e-06
Local loss @ local epoch 4: 2.384184938364342e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.99 seconds!
[tester] 
AGNewsMetric: acc=0.755, hinge=4.564052605879934, ce=9.225278143631785
Local test acc @ epoch 165: 0.755
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 1.9371505288745539e-07
Local loss @ local epoch 1: 3.129240440102876e-07
Local loss @ local epoch 2: 3.948804305764497e-07
Local loss @ local epoch 3: 8.419127084380307e-07
Local loss @ local epoch 4: 2.3543689167127013e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.05 seconds!
[tester] 
AGNewsMetric: acc=0.7875, hinge=4.446288737748799, ce=9.46217653374923
Local test acc @ epoch 165: 0.7875
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.1920897122763563e-06
Local loss @ local epoch 1: 3.129242145405442e-07
Local loss @ local epoch 2: 0.0032789481338113546
Local loss @ local epoch 3: 3.4257751394761726e-05
Local loss @ local epoch 4: 0.682520866394043
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.38 seconds!
[tester] 
AGNewsMetric: acc=0.7625, hinge=3.9408027641396774, ce=9.195181493257222
Local test acc @ epoch 165: 0.7625
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 2.138287527486682e-06
Local loss @ local epoch 1: 0.0002580329601187259
Local loss @ local epoch 2: 4.6193542857508874e-07
Local loss @ local epoch 3: 0.6699599623680115
Local loss @ local epoch 4: 1.2978310223843437e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.72 seconds!
[tester] 
AGNewsMetric: acc=0.8139473684210526, hinge=3.318329431132266, ce=8.390051371925756
Local test acc @ epoch 165: 0.8139
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 1.0132715715371887e-06
Local loss @ local epoch 1: 1.5720542023700546e-06
Local loss @ local epoch 2: 4.678801360569196e-06
Local loss @ local epoch 3: 2.011656192735245e-07
Local loss @ local epoch 4: 1.2053905265929643e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.76 seconds!
[tester] 
AGNewsMetric: acc=0.8375, hinge=2.713700497903322, ce=7.837655723973325
Local test acc @ epoch 165: 0.8375
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.2498689591884613
Local loss @ local epoch 1: 0.012226532213389874
Local loss @ local epoch 2: 0.5421218276023865
Local loss @ local epoch 3: 1.405792500008829e-05
Local loss @ local epoch 4: 2.4793242118903436e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.69 seconds!
[tester] 
AGNewsMetric: acc=0.8115789473684211, hinge=3.0048659896850585, ce=8.780048699629933
Local test acc @ epoch 165: 0.8116
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.17356045544147491
Local loss @ local epoch 1: 5.550608875637408e-06
Local loss @ local epoch 2: 0.6699205636978149
Local loss @ local epoch 3: 0.017237698659300804
Local loss @ local epoch 4: 0.2582791745662689
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.6 seconds!
[tester] 
AGNewsMetric: acc=0.6502631578947369, hinge=5.528483301965814, ce=9.64798117988988
Local test acc @ epoch 165: 0.6503
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 1.7657680473348591e-06
Local loss @ local epoch 1: 4.0978164861371624e-07
Local loss @ local epoch 2: 2.0339898583188187e-06
Local loss @ local epoch 3: 6.459531869040802e-05
Local loss @ local epoch 4: 2.7417745513957925e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.71 seconds!
[tester] 
AGNewsMetric: acc=0.7903947368421053, hinge=3.870006591144361, ce=8.49567098918714
Local test acc @ epoch 165: 0.7904
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 1.0430811414607888e-07
Local loss @ local epoch 1: 1.2665984172599565e-07
Local loss @ local epoch 2: 2.3096788481780095e-07
Local loss @ local epoch 3: 1.6391268786719593e-07
Local loss @ local epoch 4: 2.130833763658302e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.13 seconds!
[tester] 
AGNewsMetric: acc=0.8363157894736842, hinge=3.225534255128158, ce=8.136731391705965
Local test acc @ epoch 165: 0.8363
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 2.2512616851599887e-05
Local loss @ local epoch 1: 0.00020557349489536136
Local loss @ local epoch 2: 3.106558142462745e-05
Local loss @ local epoch 3: 8.88825161382556e-06
Local loss @ local epoch 4: 3.4999848139705136e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.93 seconds!
[tester] 
AGNewsMetric: acc=0.7622368421052632, hinge=4.067989685660915, ce=8.57926103089985
Local test acc @ epoch 165: 0.7622
Global evaluate on test data...
Evaluate data in 130.69 seconds!
[tester] 
AGNewsMetric: acc=0.8356578947368422, hinge=3.1532676807202793, ce=7.932512219077663
Global test acc @ epoch 165: 0.8357
Global epoch 166...
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 6.52643484500004e-06
Local loss @ local epoch 1: 3.687988282763399e-06
Local loss @ local epoch 2: 0.005432189907878637
Local loss @ local epoch 3: 0.0001127553332480602
Local loss @ local epoch 4: 0.0006936435820534825
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.04 seconds!
[tester] 
AGNewsMetric: acc=0.8311842105263157, hinge=2.679254780066641, ce=8.492221594358746
Local test acc @ epoch 166: 0.8312
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 2.101043946822756e-06
Local loss @ local epoch 1: 6.111753464210778e-05
Local loss @ local epoch 2: 1.1584624189708848e-05
Local loss @ local epoch 3: 1.639032234379556e-05
Local loss @ local epoch 4: 0.000531638041138649
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.74 seconds!
[tester] 
AGNewsMetric: acc=0.8319736842105263, hinge=3.177836235698901, ce=7.716998051091244
Local test acc @ epoch 166: 0.832
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 3.1590063827025006e-06
Local loss @ local epoch 1: 2.4586907443335804e-07
Local loss @ local epoch 2: 1.1051832437515259
Local loss @ local epoch 3: 2.458680683048442e-06
Local loss @ local epoch 4: 2.6804726076079533e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.64 seconds!
[tester] 
AGNewsMetric: acc=0.8373684210526315, hinge=2.69657851645821, ce=8.180943840428403
Local test acc @ epoch 166: 0.8374
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 5.215391638557776e-07
Local loss @ local epoch 1: 2.756713399776345e-07
Local loss @ local epoch 2: 9.403796138940379e-05
Local loss @ local epoch 3: 0.001562794204801321
Local loss @ local epoch 4: 4.99187876812357e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.33 seconds!
[tester] 
AGNewsMetric: acc=0.7944736842105263, hinge=4.199219754871569, ce=8.485404506482576
Local test acc @ epoch 166: 0.7945
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 6.705521116145974e-08
Local loss @ local epoch 1: 1.7136329688582919e-07
Local loss @ local epoch 2: 1.7881387748275301e-07
Local loss @ local epoch 3: 5.960463056453591e-08
Local loss @ local epoch 4: 0.5934411287307739
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.88 seconds!
[tester] 
AGNewsMetric: acc=0.8503947368421053, hinge=2.772447903532731, ce=8.111303386688233
Local test acc @ epoch 166: 0.8504
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 5.505749413714511e-06
Local loss @ local epoch 1: 7.495164481952088e-06
Local loss @ local epoch 2: 0.009540312923491001
Local loss @ local epoch 3: 2.2304906451608986e-05
Local loss @ local epoch 4: 1.1674750567181036e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.68 seconds!
[tester] 
AGNewsMetric: acc=0.8281578947368421, hinge=2.6880476422058908, ce=8.078902425264058
Local test acc @ epoch 166: 0.8282
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 8.940673410506861e-07
Local loss @ local epoch 1: 1.5086004168551881e-05
Local loss @ local epoch 2: 3.078911322518252e-05
Local loss @ local epoch 3: 0.18482302129268646
Local loss @ local epoch 4: 0.00021574622951447964
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.75 seconds!
[tester] 
AGNewsMetric: acc=0.7055263157894737, hinge=5.6516572462885, ce=9.9957481705515
Local test acc @ epoch 166: 0.7055
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 8.195637946073475e-08
Local loss @ local epoch 1: 2.2351733264258655e-07
Local loss @ local epoch 2: 1.788137637959153e-07
Local loss @ local epoch 3: 8.940695295223122e-08
Local loss @ local epoch 4: 1.564621072702721e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.31 seconds!
[tester] 
AGNewsMetric: acc=0.8201315789473684, hinge=3.5757047876558805, ce=8.424072859914679
Local test acc @ epoch 166: 0.8201
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 8.195636524988004e-08
Local loss @ local epoch 1: 1.8626427333856554e-07
Local loss @ local epoch 2: 1.1920923981278975e-07
Local loss @ local epoch 3: 1.08778021967737e-06
Local loss @ local epoch 4: 0.00027605961076915264
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.16 seconds!
[tester] 
AGNewsMetric: acc=0.845, hinge=3.0240652056744226, ce=7.806691934685958
Local test acc @ epoch 166: 0.845
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 1.2665984172599565e-07
Local loss @ local epoch 1: 2.533194276566064e-07
Local loss @ local epoch 2: 1.9371503867660067e-07
Local loss @ local epoch 3: 2.682207878024201e-07
Local loss @ local epoch 4: 2.3096775692010851e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.29 seconds!
[tester] 
AGNewsMetric: acc=0.8431578947368421, hinge=2.9266966009140014, ce=8.282084001239978
Local test acc @ epoch 166: 0.8432
Global evaluate on test data...
Evaluate data in 130.67 seconds!
[tester] 
AGNewsMetric: acc=0.8411842105263158, hinge=3.1267044426265516, ce=7.959119952352423
Global test acc @ epoch 166: 0.8412
Global epoch 167...
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 1.6391263102377707e-07
Local loss @ local epoch 1: 8.642617785881157e-07
Local loss @ local epoch 2: 1.5869627532083541e-06
Local loss @ local epoch 3: 2.1606675204566272e-07
Local loss @ local epoch 4: 4.991883315597079e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.52 seconds!
[tester] 
AGNewsMetric: acc=0.8477631578947369, hinge=2.8564262671219676, ce=7.557206451014468
Local test acc @ epoch 167: 0.8478
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 8.19563723553074e-08
Local loss @ local epoch 1: 2.3096767165498022e-07
Local loss @ local epoch 2: 1.2665982751514093e-07
Local loss @ local epoch 3: 1.4156094607642444e-07
Local loss @ local epoch 4: 2.0861605776190117e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.38 seconds!
[tester] 
AGNewsMetric: acc=0.8414473684210526, hinge=3.1227661381269756, ce=7.79065103430497
Local test acc @ epoch 167: 0.8414
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 1.0132745273949695e-06
Local loss @ local epoch 1: 0.0001126487331930548
Local loss @ local epoch 2: 2.6072058972204104e-05
Local loss @ local epoch 3: 0.24179361760616302
Local loss @ local epoch 4: 3.1813788154977374e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.72 seconds!
[tester] 
AGNewsMetric: acc=0.7992105263157895, hinge=3.828681640875967, ce=8.440476315146999
Local test acc @ epoch 167: 0.7992
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0001466866524424404
Local loss @ local epoch 1: 5.4239399105426855e-06
Local loss @ local epoch 2: 0.0004252662183716893
Local loss @ local epoch 3: 0.0016163464169949293
Local loss @ local epoch 4: 3.698523869388737e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.15 seconds!
[tester] 
AGNewsMetric: acc=0.8103947368421053, hinge=2.972058650317945, ce=7.991088933442768
Local test acc @ epoch 167: 0.8104
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 3.7252880247251596e-07
Local loss @ local epoch 1: 2.0861615723788418e-07
Local loss @ local epoch 2: 5.28990710790822e-07
Local loss @ local epoch 3: 6.70552182668871e-08
Local loss @ local epoch 4: 5.215404996761208e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.2 seconds!
[tester] 
AGNewsMetric: acc=0.8275, hinge=3.5740539294794984, ce=8.324293443780196
Local test acc @ epoch 167: 0.8275
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 6.109457899583504e-07
Local loss @ local epoch 1: 1.6391273049976007e-07
Local loss @ local epoch 2: 8.493615268889698e-07
Local loss @ local epoch 3: 1.2665984172599565e-07
Local loss @ local epoch 4: 9.387696877638518e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.0 seconds!
[tester] 
AGNewsMetric: acc=0.8453947368421053, hinge=2.575935677478188, ce=8.072698136379845
Local test acc @ epoch 167: 0.8454
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 3.278247504567844e-07
Local loss @ local epoch 1: 9.685753354915505e-08
Local loss @ local epoch 2: 4.6193517277970386e-07
Local loss @ local epoch 3: 2.3543670977232978e-06
Local loss @ local epoch 4: 2.4194947400246747e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.67 seconds!
[tester] 
AGNewsMetric: acc=0.8436842105263158, hinge=2.9942697319231537, ce=7.09509411862022
Local test acc @ epoch 167: 0.8437
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 8.195636524988004e-08
Local loss @ local epoch 1: 1.6391273049976007e-07
Local loss @ local epoch 2: 2.2276983600022504e-06
Local loss @ local epoch 3: 5.140892653798801e-07
Local loss @ local epoch 4: 7.368227215920342e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.62 seconds!
[tester] 
AGNewsMetric: acc=0.7948684210526316, hinge=3.9455650997161866, ce=8.947499405710321
Local test acc @ epoch 167: 0.7949
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 5.885947302886052e-07
Local loss @ local epoch 1: 3.4569961826491635e-06
Local loss @ local epoch 2: 0.004725063685327768
Local loss @ local epoch 3: 3.203746814506303e-07
Local loss @ local epoch 4: 0.03804216533899307
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.1 seconds!
[tester] 
AGNewsMetric: acc=0.7986842105263158, hinge=3.611997757710909, ce=8.509863225033408
Local test acc @ epoch 167: 0.7987
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 5.289906539474032e-07
Local loss @ local epoch 1: 4.7683681714261184e-07
Local loss @ local epoch 2: 0.005651222076267004
Local loss @ local epoch 3: 5.513417136171483e-07
Local loss @ local epoch 4: 0.5901933908462524
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.44 seconds!
[tester] 
AGNewsMetric: acc=0.8417105263157895, hinge=3.122749094712107, ce=8.122254281294973
Local test acc @ epoch 167: 0.8417
Global evaluate on test data...
Evaluate data in 129.83 seconds!
[tester] 
AGNewsMetric: acc=0.8481578947368421, hinge=3.0245955547533536, ce=7.717072421626041
Global test acc @ epoch 167: 0.8482
Global epoch 168...
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 2.1606669520224386e-07
Local loss @ local epoch 1: 5.215405707303944e-08
Local loss @ local epoch 2: 2.9802320611338473e-08
Local loss @ local epoch 3: 9.685753354915505e-08
Local loss @ local epoch 4: 1.7136329688582919e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.8 seconds!
[tester] 
AGNewsMetric: acc=0.8415789473684211, hinge=3.197232488331042, ce=7.847271240635922
Local test acc @ epoch 168: 0.8416
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 2.2351731843173184e-07
Local loss @ local epoch 1: 3.4346871871093754e-06
Local loss @ local epoch 2: 1.154836468231224e-06
Local loss @ local epoch 3: 0.058501049876213074
Local loss @ local epoch 4: 5.1929050641774666e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.19 seconds!
[tester] 
AGNewsMetric: acc=0.8342105263157895, hinge=3.130376063648023, ce=8.064494159096165
Local test acc @ epoch 168: 0.8342
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 1.0058222414954798e-06
Local loss @ local epoch 1: 1.2069876902387477e-06
Local loss @ local epoch 2: 2.0861622829215776e-07
Local loss @ local epoch 3: 1.7881309304357274e-06
Local loss @ local epoch 4: 1.213643372466322e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.38 seconds!
[tester] 
AGNewsMetric: acc=0.8451315789473685, hinge=2.622801328458284, ce=8.276635495236045
Local test acc @ epoch 168: 0.8451
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 9.164165817310277e-07
Local loss @ local epoch 1: 1.9371501025489124e-07
Local loss @ local epoch 2: 2.682207878024201e-07
Local loss @ local epoch 3: 4.739771975437179e-05
Local loss @ local epoch 4: 0.0002937537501566112
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.27 seconds!
[tester] 
AGNewsMetric: acc=0.8163157894736842, hinge=3.498064434653834, ce=8.378114395141601
Local test acc @ epoch 168: 0.8163
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.9371503867660067e-07
Local loss @ local epoch 1: 2.756713683993439e-07
Local loss @ local epoch 2: 4.768359644913289e-07
Local loss @ local epoch 3: 8.19563723553074e-08
Local loss @ local epoch 4: 4.3213327671765e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.2 seconds!
[tester] 
AGNewsMetric: acc=0.8502631578947368, hinge=2.8781593485882406, ce=8.050820806402909
Local test acc @ epoch 168: 0.8503
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.629176914691925
Local loss @ local epoch 1: 6.653029231529217e-06
Local loss @ local epoch 2: 0.7402966022491455
Local loss @ local epoch 3: 2.3773724024067633e-05
Local loss @ local epoch 4: 0.29639819264411926
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.16 seconds!
[tester] 
AGNewsMetric: acc=0.8175, hinge=2.776210008922376, ce=9.404917186937833
Local test acc @ epoch 168: 0.8175
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 7.078014050421189e-07
Local loss @ local epoch 1: 5.215405707303944e-08
Local loss @ local epoch 2: 0.0345897302031517
Local loss @ local epoch 3: 2.4065122943284223e-06
Local loss @ local epoch 4: 0.0369902029633522
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.1 seconds!
[tester] 
AGNewsMetric: acc=0.8614473684210526, hinge=2.3184797896836935, ce=8.260018568540874
Local test acc @ epoch 168: 0.8614
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.001344450400210917
Local loss @ local epoch 1: 1.4677601711809984e-06
Local loss @ local epoch 2: 2.1791965991724283e-05
Local loss @ local epoch 3: 0.0003209005226381123
Local loss @ local epoch 4: 0.00110616663005203
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.41 seconds!
[tester] 
AGNewsMetric: acc=0.7978947368421052, hinge=3.249406620075828, ce=7.377764663696289
Local test acc @ epoch 168: 0.7979
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 1.5646213569198153e-07
Local loss @ local epoch 1: 1.2665982751514093e-07
Local loss @ local epoch 2: 1.154836013483873e-06
Local loss @ local epoch 3: 2.086161856595936e-07
Local loss @ local epoch 4: 7.623268902534619e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.93 seconds!
[tester] 
AGNewsMetric: acc=0.8193421052631579, hinge=3.4417661523818968, ce=8.383665707236842
Local test acc @ epoch 168: 0.8193
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 1.085494841390755e-05
Local loss @ local epoch 1: 0.47991710901260376
Local loss @ local epoch 2: 4.590873504639603e-05
Local loss @ local epoch 3: 0.006731539033353329
Local loss @ local epoch 4: 0.4335777163505554
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.9 seconds!
[tester] 
AGNewsMetric: acc=0.7877631578947368, hinge=3.943164922312686, ce=8.585635070800782
Local test acc @ epoch 168: 0.7878
Global evaluate on test data...
Evaluate data in 130.43 seconds!
[tester] 
AGNewsMetric: acc=0.8493421052631579, hinge=2.9846511328847787, ce=7.812415767468904
Global test acc @ epoch 168: 0.8493
Global epoch 169...
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 1.1920926112907182e-07
Local loss @ local epoch 1: 1.7061702237697318e-06
Local loss @ local epoch 2: 1.4355955499922857e-05
Local loss @ local epoch 3: 0.056037262082099915
Local loss @ local epoch 4: 3.322911652503535e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.29 seconds!
[tester] 
AGNewsMetric: acc=0.741578947368421, hinge=4.6666301769959295, ce=9.504106664155659
Local test acc @ epoch 169: 0.7416
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 2.756712547125062e-07
Local loss @ local epoch 2: 3.725289943190546e-08
Local loss @ local epoch 3: 1.1175868053214799e-07
Local loss @ local epoch 4: 1.1175867342672063e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.99 seconds!
[tester] 
AGNewsMetric: acc=0.8325, hinge=3.2010374076742876, ce=8.537198600769043
Local test acc @ epoch 169: 0.8325
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.18851816654205322
Local loss @ local epoch 1: 0.0001450512936571613
Local loss @ local epoch 2: 2.0128157138824463
Local loss @ local epoch 3: 0.15845252573490143
Local loss @ local epoch 4: 0.004086846485733986
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.95 seconds!
[tester] 
AGNewsMetric: acc=0.8167105263157894, hinge=2.184161606336895, ce=8.89299983777498
Local test acc @ epoch 169: 0.8167
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 1.3410917745204642e-06
Local loss @ local epoch 1: 4.470348002882929e-08
Local loss @ local epoch 2: 9.909216487358208e-07
Local loss @ local epoch 3: 2.3096791323951038e-07
Local loss @ local epoch 4: 1.0348191608500201e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.57 seconds!
[tester] 
AGNewsMetric: acc=0.8153947368421053, hinge=3.4568887055547615, ce=8.422467695537366
Local test acc @ epoch 169: 0.8154
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 4.0233061326944153e-07
Local loss @ local epoch 1: 1.981835794140352e-06
Local loss @ local epoch 2: 1.8030285673376056e-06
Local loss @ local epoch 3: 7.003538371463947e-07
Local loss @ local epoch 4: 0.00012647816038224846
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.48 seconds!
[tester] 
AGNewsMetric: acc=0.8228947368421052, hinge=3.274723069040399, ce=8.241776193317614
Local test acc @ epoch 169: 0.8229
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.2562731206417084
Local loss @ local epoch 1: 4.917379783364595e-07
Local loss @ local epoch 2: 0.10309574753046036
Local loss @ local epoch 3: 0.832277238368988
Local loss @ local epoch 4: 0.002171612810343504
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.04 seconds!
[tester] 
AGNewsMetric: acc=0.7757894736842105, hinge=3.059238066673279, ce=8.14813461303711
Local test acc @ epoch 169: 0.7758
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 1.0132737315871054e-06
Local loss @ local epoch 1: 1.8253687130709295e-06
Local loss @ local epoch 2: 4.134971732128179e-06
Local loss @ local epoch 3: 0.00027307693380862474
Local loss @ local epoch 4: 7.48754246160388e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.27 seconds!
[tester] 
AGNewsMetric: acc=0.7698684210526315, hinge=4.027222161042062, ce=9.245580711364745
Local test acc @ epoch 169: 0.7699
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 7.763907342450693e-05
Local loss @ local epoch 1: 8.046591233323852e-07
Local loss @ local epoch 2: 0.1983097791671753
Local loss @ local epoch 3: 0.003009007778018713
Local loss @ local epoch 4: 0.3982204496860504
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.94 seconds!
[tester] 
AGNewsMetric: acc=0.7618421052631579, hinge=4.474035616924888, ce=9.194232970789859
Local test acc @ epoch 169: 0.7618
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0001447985996492207
Local loss @ local epoch 1: 0.00021965272026136518
Local loss @ local epoch 2: 5.505899480340304e-06
Local loss @ local epoch 3: 1.5687716007232666
Local loss @ local epoch 4: 0.07285021245479584
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 131.0 seconds!
[tester] 
AGNewsMetric: acc=0.8439473684210527, hinge=2.8264773441615856, ce=7.929313324376157
Local test acc @ epoch 169: 0.8439
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 1.564621072702721e-07
Local loss @ local epoch 1: 2.0116556243010564e-07
Local loss @ local epoch 2: 2.086161714487389e-07
Local loss @ local epoch 3: 1.1175869474300271e-07
Local loss @ local epoch 4: 1.3112975238982472e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.91 seconds!
[tester] 
AGNewsMetric: acc=0.8444736842105263, hinge=2.9651248283135265, ce=7.660682668183979
Local test acc @ epoch 169: 0.8445
Global evaluate on test data...
Evaluate data in 129.51 seconds!
[tester] 
AGNewsMetric: acc=0.8355263157894737, hinge=3.179749124426591, ce=7.929282079997815
Global test acc @ epoch 169: 0.8355
Global epoch 170...
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.004728234838694334
Local loss @ local epoch 1: 4.1722100831975695e-06
Local loss @ local epoch 2: 0.7232144474983215
Local loss @ local epoch 3: 4.5500713895307854e-05
Local loss @ local epoch 4: 0.0001033118533086963
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.78 seconds!
[tester] 
AGNewsMetric: acc=0.8396052631578947, hinge=2.2438227844238283, ce=8.599449324356883
Local test acc @ epoch 170: 0.8396
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 9.5123250503093e-05
Local loss @ local epoch 1: 2.5331965503028187e-07
Local loss @ local epoch 2: 0.8921540379524231
Local loss @ local epoch 3: 3.106869371549692e-06
Local loss @ local epoch 4: 0.3325467109680176
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.65 seconds!
[tester] 
AGNewsMetric: acc=0.8336842105263158, hinge=2.786990915599622, ce=9.076020792910928
Local test acc @ epoch 170: 0.8337
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 3.7252868878567824e-07
Local loss @ local epoch 1: 3.725289943190546e-08
Local loss @ local epoch 2: 2.0861610039446532e-07
Local loss @ local epoch 3: 1.668916411290411e-06
Local loss @ local epoch 4: 2.2351704842549225e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.72 seconds!
[tester] 
AGNewsMetric: acc=0.8414473684210526, hinge=2.864928573809172, ce=7.985204983761436
Local test acc @ epoch 170: 0.8414
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 2.4586898916822975e-07
Local loss @ local epoch 1: 7.450579175838357e-08
Local loss @ local epoch 2: 8.940695295223122e-08
Local loss @ local epoch 3: 2.905723874846444e-07
Local loss @ local epoch 4: 5.960463766996327e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.22 seconds!
[tester] 
AGNewsMetric: acc=0.8403947368421053, hinge=2.7967174301649393, ce=8.061006242852462
Local test acc @ epoch 170: 0.8404
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450565817634924e-07
Local loss @ local epoch 1: 0.00019108039850834757
Local loss @ local epoch 2: 2.473573204042623e-06
Local loss @ local epoch 3: 1.718745261314325e-05
Local loss @ local epoch 4: 0.0005854878108948469
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.34 seconds!
[tester] 
AGNewsMetric: acc=0.8013157894736842, hinge=3.424854057211625, ce=8.579836210953562
Local test acc @ epoch 170: 0.8013
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 2.5182755507557886e-06
Local loss @ local epoch 1: 1.0504592864890583e-05
Local loss @ local epoch 2: 0.22979073226451874
Local loss @ local epoch 3: 0.01642131805419922
Local loss @ local epoch 4: 0.0010912608122453094
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.33 seconds!
[tester] 
AGNewsMetric: acc=0.815, hinge=2.7908836191578916, ce=8.658595870168586
Local test acc @ epoch 170: 0.815
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 3.2104879210237414e-05
Local loss @ local epoch 1: 1.2404399967635982e-05
Local loss @ local epoch 2: 4.69381893708487e-06
Local loss @ local epoch 3: 1.4043755072634667e-05
Local loss @ local epoch 4: 0.6477295756340027
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.18 seconds!
[tester] 
AGNewsMetric: acc=0.8084210526315789, hinge=2.9393638033615916, ce=7.6323589857001055
Local test acc @ epoch 170: 0.8084
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 7.748562893539201e-07
Local loss @ local epoch 1: 9.53669427872228e-07
Local loss @ local epoch 2: 5.811444339087757e-07
Local loss @ local epoch 3: 1.2144400898250751e-06
Local loss @ local epoch 4: 6.55650637781946e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.46 seconds!
[tester] 
AGNewsMetric: acc=0.8421052631578947, hinge=2.7637291285866183, ce=8.100882528204666
Local test acc @ epoch 170: 0.8421
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 2.980231101901154e-07
Local loss @ local epoch 1: 1.1175862368872913e-07
Local loss @ local epoch 2: 4.917378646496218e-07
Local loss @ local epoch 3: 2.4586890390310145e-07
Local loss @ local epoch 4: 2.0116554821925092e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 131.07 seconds!
[tester] 
AGNewsMetric: acc=0.8139473684210526, hinge=3.673299772613927, ce=8.47782966412996
Local test acc @ epoch 170: 0.8139
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 4.1796720324782655e-06
Local loss @ local epoch 1: 6.929030860192142e-07
Local loss @ local epoch 2: 6.116445001680404e-05
Local loss @ local epoch 3: 4.53827487945091e-05
Local loss @ local epoch 4: 0.0003544250794220716
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.82 seconds!
[tester] 
AGNewsMetric: acc=0.8177631578947369, hinge=3.3048935646759836, ce=8.235333189713328
Local test acc @ epoch 170: 0.8178
Global evaluate on test data...
Evaluate data in 130.18 seconds!
[tester] 
AGNewsMetric: acc=0.8481578947368421, hinge=2.967020693578218, ce=7.859279376582095
Global test acc @ epoch 170: 0.8482
Global epoch 171...
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 9.685753354915505e-08
Local loss @ local epoch 1: 3.725289943190546e-08
Local loss @ local epoch 2: 1.1920920428565296e-07
Local loss @ local epoch 3: 3.725289587919178e-08
Local loss @ local epoch 4: 2.2351740014414645e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.34 seconds!
[tester] 
AGNewsMetric: acc=0.8393421052631579, hinge=3.1876528521587972, ce=7.804492636228862
Local test acc @ epoch 171: 0.8393
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 3.203746814506303e-07
Local loss @ local epoch 1: 2.3692502963967854e-06
Local loss @ local epoch 2: 1.1920919007479824e-07
Local loss @ local epoch 3: 1.415610029198433e-07
Local loss @ local epoch 4: 0.9720200300216675
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.4 seconds!
[tester] 
AGNewsMetric: acc=0.8469736842105263, hinge=2.823881788253784, ce=8.193909942225407
Local test acc @ epoch 171: 0.847
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 3.427265369282395e-07
Local loss @ local epoch 1: 8.940695295223122e-08
Local loss @ local epoch 2: 8.940695295223122e-08
Local loss @ local epoch 3: 8.19559829778882e-07
Local loss @ local epoch 4: 1.3485429235515767e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.24 seconds!
[tester] 
AGNewsMetric: acc=0.8477631578947369, hinge=3.0198265570088436, ce=7.855940838863975
Local test acc @ epoch 171: 0.8478
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 1.1450628335296642e-05
Local loss @ local epoch 1: 2.4672834115335718e-05
Local loss @ local epoch 2: 0.005077884998172522
Local loss @ local epoch 3: 8.657400030642748e-06
Local loss @ local epoch 4: 0.01032791007310152
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.26 seconds!
[tester] 
AGNewsMetric: acc=0.8357894736842105, hinge=3.0054841711646634, ce=8.238128198322498
Local test acc @ epoch 171: 0.8358
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 2.756713683993439e-07
Local loss @ local epoch 1: 2.086161856595936e-07
Local loss @ local epoch 2: 2.3767061065882444e-06
Local loss @ local epoch 3: 1.8626438702540327e-07
Local loss @ local epoch 4: 7.301554205696448e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.55 seconds!
[tester] 
AGNewsMetric: acc=0.7630263157894737, hinge=4.655575864440516, ce=9.064983576724403
Local test acc @ epoch 171: 0.763
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 3.799792978043115e-07
Local loss @ local epoch 1: 1.1920923270736239e-07
Local loss @ local epoch 2: 3.2037473829404917e-07
Local loss @ local epoch 3: 3.4272648008482065e-07
Local loss @ local epoch 4: 0.4666562080383301
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.58 seconds!
[tester] 
AGNewsMetric: acc=0.8386842105263158, hinge=3.197044429779053, ce=7.631904296875
Local test acc @ epoch 171: 0.8387
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 4.470347647611561e-08
Local loss @ local epoch 1: 5.215405707303944e-08
Local loss @ local epoch 2: 4.470347647611561e-08
Local loss @ local epoch 3: 5.960463766996327e-08
Local loss @ local epoch 4: 1.0430811414607888e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.73 seconds!
[tester] 
AGNewsMetric: acc=0.8413157894736842, hinge=3.1426315021514895, ce=7.642606034529837
Local test acc @ epoch 171: 0.8413
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0012745739659294486
Local loss @ local epoch 1: 5.438809694169322e-06
Local loss @ local epoch 2: 0.0008061873959377408
Local loss @ local epoch 3: 0.005633241031318903
Local loss @ local epoch 4: 0.19058996438980103
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.1 seconds!
[tester] 
AGNewsMetric: acc=0.7930263157894737, hinge=3.5260734133971363, ce=7.854222594813296
Local test acc @ epoch 171: 0.793
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 1.573382905917242e-05
Local loss @ local epoch 1: 2.115948973369086e-06
Local loss @ local epoch 2: 0.22182078659534454
Local loss @ local epoch 3: 2.5480571821390186e-06
Local loss @ local epoch 4: 3.3690055715851486e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.62 seconds!
[tester] 
AGNewsMetric: acc=0.8125, hinge=3.1777184431176435, ce=8.950635566711426
Local test acc @ epoch 171: 0.8125
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4156101713069802e-07
Local loss @ local epoch 1: 4.470348002882929e-08
Local loss @ local epoch 2: 8.940694584680386e-08
Local loss @ local epoch 3: 1.415609887089886e-07
Local loss @ local epoch 4: 3.094953717663884e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.55 seconds!
[tester] 
AGNewsMetric: acc=0.8247368421052632, hinge=3.522948835021571, ce=8.009611049451326
Local test acc @ epoch 171: 0.8247
Global evaluate on test data...
Evaluate data in 130.0 seconds!
[tester] 
AGNewsMetric: acc=0.8439473684210527, hinge=3.156993444844296, ce=7.723547974636681
Global test acc @ epoch 171: 0.8439
Global epoch 172...
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450579886381092e-08
Local loss @ local epoch 1: 2.0116550558668678e-07
Local loss @ local epoch 2: 1.4901154088420299e-07
Local loss @ local epoch 3: 1.490115550950577e-07
Local loss @ local epoch 4: 3.725289943190546e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.11 seconds!
[tester] 
AGNewsMetric: acc=0.8389473684210527, hinge=3.2774220321052954, ce=7.647086265965512
Local test acc @ epoch 172: 0.8389
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.004510689992457628
Local loss @ local epoch 1: 0.3929581940174103
Local loss @ local epoch 2: 8.155534305842593e-05
Local loss @ local epoch 3: 0.7058542370796204
Local loss @ local epoch 4: 0.6961279511451721
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.73 seconds!
[tester] 
AGNewsMetric: acc=0.8275, hinge=2.5860487290432577, ce=7.887063020405017
Local test acc @ epoch 172: 0.8275
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 3.725289943190546e-08
Local loss @ local epoch 1: 1.1473790664240369e-06
Local loss @ local epoch 2: 1.0430809993522416e-07
Local loss @ local epoch 3: 2.011656192735245e-07
Local loss @ local epoch 4: 1.4156097449813387e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.57 seconds!
[tester] 
AGNewsMetric: acc=0.8489473684210527, hinge=2.9704165704626786, ce=7.854940892269737
Local test acc @ epoch 172: 0.8489
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 1.5422624528582674e-06
Local loss @ local epoch 1: 0.1611097902059555
Local loss @ local epoch 2: 7.95546657172963e-05
Local loss @ local epoch 3: 0.0009215768077410758
Local loss @ local epoch 4: 1.1382038593292236
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.49 seconds!
[tester] 
AGNewsMetric: acc=0.6492105263157895, hinge=6.236412858963012, ce=9.956688748409874
Local test acc @ epoch 172: 0.6492
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0061669801361858845
Local loss @ local epoch 1: 1.6316706705765682e-06
Local loss @ local epoch 2: 0.09721668809652328
Local loss @ local epoch 3: 0.7296555638313293
Local loss @ local epoch 4: 0.4174978733062744
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.55 seconds!
[tester] 
AGNewsMetric: acc=0.8264473684210526, hinge=2.8716575680280987, ce=7.570369118138363
Local test acc @ epoch 172: 0.8264
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 2.9802318834981634e-08
Local loss @ local epoch 1: 1.3411040811206476e-07
Local loss @ local epoch 2: 1.3411040811206476e-07
Local loss @ local epoch 3: 1.2225225873407908e-05
Local loss @ local epoch 4: 1.5646209305941738e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.2 seconds!
[tester] 
AGNewsMetric: acc=0.7839473684210526, hinge=4.097209213156449, ce=8.754119445399235
Local test acc @ epoch 172: 0.7839
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 2.3584107111673802e-05
Local loss @ local epoch 1: 0.36240434646606445
Local loss @ local epoch 2: 1.7881384906104358e-07
Local loss @ local epoch 3: 0.9251129627227783
Local loss @ local epoch 4: 9.729700104799122e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.54 seconds!
[tester] 
AGNewsMetric: acc=0.839078947368421, hinge=2.7566773013064734, ce=8.414257651881167
Local test acc @ epoch 172: 0.8391
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 5.930394763709046e-06
Local loss @ local epoch 1: 1.8402754449198255e-06
Local loss @ local epoch 2: 5.229785165283829e-05
Local loss @ local epoch 3: 5.289840373734478e-06
Local loss @ local epoch 4: 7.97211157532729e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.74 seconds!
[tester] 
AGNewsMetric: acc=0.8051315789473684, hinge=3.633855908795407, ce=8.043004598115619
Local test acc @ epoch 172: 0.8051
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 5.960463766996327e-08
Local loss @ local epoch 1: 8.940694584680386e-08
Local loss @ local epoch 2: 3.054732644613978e-07
Local loss @ local epoch 3: 2.0116557664096035e-07
Local loss @ local epoch 4: 2.9802318834981634e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.01 seconds!
[tester] 
AGNewsMetric: acc=0.8557894736842105, hinge=2.8166054464641372, ce=7.578439654300087
Local test acc @ epoch 172: 0.8558
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 9.834743650571909e-07
Local loss @ local epoch 1: 1.3411039390121005e-07
Local loss @ local epoch 2: 7.033252131805057e-06
Local loss @ local epoch 3: 6.109469268267276e-07
Local loss @ local epoch 4: 1.3857970770914108e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.13 seconds!
[tester] 
AGNewsMetric: acc=0.8598684210526316, hinge=2.408172568898452, ce=7.8164380033392655
Local test acc @ epoch 172: 0.8599
Global evaluate on test data...
Evaluate data in 130.69 seconds!
[tester] 
AGNewsMetric: acc=0.8506578947368421, hinge=3.033423942013791, ce=7.389753489243357
Global test acc @ epoch 172: 0.8507
Global epoch 173...
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4683491826872341e-05
Local loss @ local epoch 1: 3.204452877980657e-05
Local loss @ local epoch 2: 0.00019410313689149916
Local loss @ local epoch 3: 0.0007941870717331767
Local loss @ local epoch 4: 0.0036202617920935154
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.58 seconds!
[tester] 
AGNewsMetric: acc=0.8471052631578947, hinge=2.5965961938155324, ce=8.181181547265304
Local test acc @ epoch 173: 0.8471
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 1.944301402545534e-05
Local loss @ local epoch 2: 3.3527553000567423e-07
Local loss @ local epoch 3: 8.940695295223122e-08
Local loss @ local epoch 4: 4.4703443791149766e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.27 seconds!
[tester] 
AGNewsMetric: acc=0.8482894736842105, hinge=2.678563878159774, ce=7.595379284306576
Local test acc @ epoch 173: 0.8483
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 1.7881384906104358e-07
Local loss @ local epoch 1: 1.1175866632129328e-07
Local loss @ local epoch 2: 1.0690690032788552e-05
Local loss @ local epoch 3: 1.6391268786719593e-07
Local loss @ local epoch 4: 1.7359723187837517e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.61 seconds!
[tester] 
AGNewsMetric: acc=0.6984210526315789, hinge=7.260281202416671, ce=10.880227831790322
Local test acc @ epoch 173: 0.6984
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 8.940695295223122e-08
Local loss @ local epoch 1: 2.2351740014414645e-08
Local loss @ local epoch 2: 2.980226554427645e-07
Local loss @ local epoch 3: 4.4703367052534304e-07
Local loss @ local epoch 4: 6.705521116145974e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.54 seconds!
[tester] 
AGNewsMetric: acc=0.8326315789473684, hinge=3.334902434850994, ce=7.527397097537392
Local test acc @ epoch 173: 0.8326
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 3.1068320822669193e-06
Local loss @ local epoch 1: 4.019060725113377e-05
Local loss @ local epoch 2: 1.6093077874757e-06
Local loss @ local epoch 3: 0.30305609107017517
Local loss @ local epoch 4: 1.4826616734353593e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.97 seconds!
[tester] 
AGNewsMetric: acc=0.8548684210526316, hinge=2.6203751378310356, ce=7.975653919420744
Local test acc @ epoch 173: 0.8549
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 5.513418273039861e-07
Local loss @ local epoch 1: 3.1292427138396306e-07
Local loss @ local epoch 2: 2.0116560506266978e-07
Local loss @ local epoch 3: 0.18982267379760742
Local loss @ local epoch 4: 0.005592784378677607
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.41 seconds!
[tester] 
AGNewsMetric: acc=0.7847368421052632, hinge=3.895541699560065, ce=9.213279529370759
Local test acc @ epoch 173: 0.7847
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901152667334827e-07
Local loss @ local epoch 1: 2.2351711947976582e-07
Local loss @ local epoch 2: 3.20374397233536e-07
Local loss @ local epoch 3: 8.19563723553074e-08
Local loss @ local epoch 4: 6.70552182668871e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.31 seconds!
[tester] 
AGNewsMetric: acc=0.8480263157894737, hinge=2.8680417648114656, ce=7.916403951142963
Local test acc @ epoch 173: 0.848
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 1.1271762559772469e-05
Local loss @ local epoch 1: 2.995113845827291e-06
Local loss @ local epoch 2: 2.3698244094848633
Local loss @ local epoch 3: 7.331086180784041e-06
Local loss @ local epoch 4: 3.634879976743832e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.83 seconds!
[tester] 
AGNewsMetric: acc=0.8453947368421053, hinge=2.6085089211714894, ce=8.02358650006746
Local test acc @ epoch 173: 0.8454
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 4.507471021497622e-05
Local loss @ local epoch 1: 0.32768577337265015
Local loss @ local epoch 2: 2.905724727497727e-07
Local loss @ local epoch 3: 0.2952248454093933
Local loss @ local epoch 4: 3.191523501300253e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.84 seconds!
[tester] 
AGNewsMetric: acc=0.824078947368421, hinge=2.854738412907249, ce=8.18847554859362
Local test acc @ epoch 173: 0.8241
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 1.6093058547994588e-06
Local loss @ local epoch 1: 9.760225339050521e-07
Local loss @ local epoch 2: 9.760244665812934e-07
Local loss @ local epoch 3: 7.837674274924211e-06
Local loss @ local epoch 4: 0.00040797574911266565
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.27 seconds!
[tester] 
AGNewsMetric: acc=0.845, hinge=2.5559572187222934, ce=8.093384696558902
Local test acc @ epoch 173: 0.845
Global evaluate on test data...
Evaluate data in 130.15 seconds!
[tester] 
AGNewsMetric: acc=0.8556578947368421, hinge=2.838866414019936, ce=7.692070602617766
Global test acc @ epoch 173: 0.8557
Global epoch 174...
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.006648806389421225
Local loss @ local epoch 1: 6.422154001484159e-06
Local loss @ local epoch 2: 0.025848761200904846
Local loss @ local epoch 3: 1.1316908967273775e-05
Local loss @ local epoch 4: 1.8022294170805253e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.16 seconds!
[tester] 
AGNewsMetric: acc=0.8327631578947369, hinge=2.8207577958859895, ce=7.902028457240054
Local test acc @ epoch 174: 0.8328
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 5.51342282051337e-07
Local loss @ local epoch 1: 1.6391198869314394e-06
Local loss @ local epoch 2: 1.5497096228500595e-06
Local loss @ local epoch 3: 0.10307794064283371
Local loss @ local epoch 4: 1.8924330333902617e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.75 seconds!
[tester] 
AGNewsMetric: acc=0.8461842105263158, hinge=2.803313568767748, ce=8.020911023993241
Local test acc @ epoch 174: 0.8462
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 1.1175869474300271e-07
Local loss @ local epoch 1: 5.215405707303944e-08
Local loss @ local epoch 2: 1.7136319740984618e-07
Local loss @ local epoch 3: 3.725289943190546e-08
Local loss @ local epoch 4: 1.3411036547950062e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.21 seconds!
[tester] 
AGNewsMetric: acc=0.8321052631578948, hinge=3.3742099164661608, ce=7.7248789335552015
Local test acc @ epoch 174: 0.8321
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 4.917367846246634e-07
Local loss @ local epoch 1: 8.19563723553074e-08
Local loss @ local epoch 2: 1.7136329688582919e-07
Local loss @ local epoch 3: 7.003529844951117e-07
Local loss @ local epoch 4: 0.00015790887118782848
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.66 seconds!
[tester] 
AGNewsMetric: acc=0.8447368421052631, hinge=2.970841225071957, ce=7.528818688643606
Local test acc @ epoch 174: 0.8447
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 2.346902192584821e-06
Local loss @ local epoch 1: 4.634192009689286e-06
Local loss @ local epoch 2: 1.505010004620999e-06
Local loss @ local epoch 3: 2.8263488275115378e-05
Local loss @ local epoch 4: 1.952041429831297e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.2 seconds!
[tester] 
AGNewsMetric: acc=0.8194736842105264, hinge=3.544651231012846, ce=8.293162153143632
Local test acc @ epoch 174: 0.8195
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 2.03398531084531e-06
Local loss @ local epoch 1: 5.364410640140704e-07
Local loss @ local epoch 2: 5.811446612824511e-07
Local loss @ local epoch 3: 1.3514664715330582e-05
Local loss @ local epoch 4: 3.3303795134997927e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.14 seconds!
[tester] 
AGNewsMetric: acc=0.7463157894736843, hinge=5.161770555345636, ce=9.094171560187089
Local test acc @ epoch 174: 0.7463
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0001686027826508507
Local loss @ local epoch 1: 0.6814242601394653
Local loss @ local epoch 2: 2.6747225092549343e-06
Local loss @ local epoch 3: 0.004136126022785902
Local loss @ local epoch 4: 4.954473752150079e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 131.01 seconds!
[tester] 
AGNewsMetric: acc=0.8198684210526316, hinge=3.230300168489155, ce=8.60251931240684
Local test acc @ epoch 174: 0.8199
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 8.19563723553074e-08
Local loss @ local epoch 1: 3.725289587919178e-08
Local loss @ local epoch 2: 5.960463056453591e-08
Local loss @ local epoch 3: 2.2351740014414645e-08
Local loss @ local epoch 4: 4.470347647611561e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.87 seconds!
[tester] 
AGNewsMetric: acc=0.8380263157894737, hinge=3.246378341975965, ce=7.940607221503007
Local test acc @ epoch 174: 0.838
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.04736468568444252
Local loss @ local epoch 1: 1.2665982751514093e-07
Local loss @ local epoch 2: 0.5758991837501526
Local loss @ local epoch 3: 2.2759203910827637
Local loss @ local epoch 4: 0.21006183326244354
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.99 seconds!
[tester] 
AGNewsMetric: acc=0.7768421052631579, hinge=2.2833060934669094, ce=9.372813931515342
Local test acc @ epoch 174: 0.7768
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 2.831215510923357e-07
Local loss @ local epoch 1: 1.2665982751514093e-07
Local loss @ local epoch 2: 7.450579175838357e-08
Local loss @ local epoch 3: 1.3411040811206476e-07
Local loss @ local epoch 4: 4.827799330087146e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.56 seconds!
[tester] 
AGNewsMetric: acc=0.8344736842105264, hinge=3.1227671640797667, ce=7.239489751113089
Local test acc @ epoch 174: 0.8345
Global evaluate on test data...
Evaluate data in 130.09 seconds!
[tester] 
AGNewsMetric: acc=0.8513157894736842, hinge=3.011954029986733, ce=7.646371552316766
Global test acc @ epoch 174: 0.8513
Global epoch 175...
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.5646213569198153e-07
Local loss @ local epoch 1: 2.0861611460532004e-07
Local loss @ local epoch 2: 4.0978139281833137e-07
Local loss @ local epoch 3: 9.685751223287298e-08
Local loss @ local epoch 4: 8.493636869388865e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.96 seconds!
[tester] 
AGNewsMetric: acc=0.8382894736842105, hinge=3.120999012244375, ce=8.281317810259367
Local test acc @ epoch 175: 0.8383
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 1.2665982751514093e-07
Local loss @ local epoch 1: 1.110128096115659e-06
Local loss @ local epoch 2: 1.0430805019723266e-07
Local loss @ local epoch 3: 7.823100531823002e-07
Local loss @ local epoch 4: 1.0154740266443696e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.04 seconds!
[tester] 
AGNewsMetric: acc=0.8465789473684211, hinge=2.882576118017498, ce=7.782062019548918
Local test acc @ epoch 175: 0.8466
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 2.756711410256685e-07
Local loss @ local epoch 1: 2.905724727497727e-07
Local loss @ local epoch 2: 3.4793431495927507e-06
Local loss @ local epoch 3: 1.624219066798105e-06
Local loss @ local epoch 4: 5.36441234544327e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.9 seconds!
[tester] 
AGNewsMetric: acc=0.8168421052631579, hinge=3.4653620147705078, ce=8.329832197490491
Local test acc @ epoch 175: 0.8168
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 3.725289943190546e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 8.419133337156381e-07
Local loss @ local epoch 3: 6.70552182668871e-08
Local loss @ local epoch 4: 1.0430806440808738e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.01 seconds!
[tester] 
AGNewsMetric: acc=0.8075, hinge=4.191153283119202, ce=7.8006970475849355
Local test acc @ epoch 175: 0.8075
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 1.862644296579674e-07
Local loss @ local epoch 1: 2.9802320611338473e-08
Local loss @ local epoch 2: 1.1920920428565296e-07
Local loss @ local epoch 3: 9.685753354915505e-08
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.97 seconds!
[tester] 
AGNewsMetric: acc=0.8531578947368421, hinge=3.0708703600732905, ce=7.375759693948846
Local test acc @ epoch 175: 0.8532
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 1.2665977067172207e-07
Local loss @ local epoch 1: 3.5762704442277027e-07
Local loss @ local epoch 2: 2.6374641493021045e-06
Local loss @ local epoch 3: 0.0013351632514968514
Local loss @ local epoch 4: 8.373961463803425e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.65 seconds!
[tester] 
AGNewsMetric: acc=0.8313157894736842, hinge=3.396221649270309, ce=7.8998828928094165
Local test acc @ epoch 175: 0.8313
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 7.674075845898187e-07
Local loss @ local epoch 1: 2.451198724884307e-06
Local loss @ local epoch 2: 8.73157478054054e-06
Local loss @ local epoch 3: 0.00010733108501881361
Local loss @ local epoch 4: 3.0547363394362037e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.41 seconds!
[tester] 
AGNewsMetric: acc=0.8353947368421053, hinge=3.147452395338761, ce=7.416903298026637
Local test acc @ epoch 175: 0.8354
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 5.215405707303944e-08
Local loss @ local epoch 1: 4.470347647611561e-08
Local loss @ local epoch 2: 8.195637946073475e-08
Local loss @ local epoch 3: 1.0430809993522416e-07
Local loss @ local epoch 4: 6.70552182668871e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.22 seconds!
[tester] 
AGNewsMetric: acc=0.8427631578947369, hinge=3.2068515403647173, ce=7.7683610775596215
Local test acc @ epoch 175: 0.8428
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 2.5468589228694327e-05
Local loss @ local epoch 1: 5.178027095098514e-06
Local loss @ local epoch 2: 1.591935396194458
Local loss @ local epoch 3: 1.1972317224717699e-05
Local loss @ local epoch 4: 2.831219205745583e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.78 seconds!
[tester] 
AGNewsMetric: acc=0.8405263157894737, hinge=3.117670645462839, ce=8.073663456565455
Local test acc @ epoch 175: 0.8405
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 5.960463766996327e-08
Local loss @ local epoch 1: 4.470348002882929e-08
Local loss @ local epoch 2: 6.705521116145974e-08
Local loss @ local epoch 3: 8.19563723553074e-08
Local loss @ local epoch 4: 5.960463766996327e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.82 seconds!
[tester] 
AGNewsMetric: acc=0.8518421052631578, hinge=3.0371340124230635, ce=7.93511564555921
Local test acc @ epoch 175: 0.8518
Global evaluate on test data...
Evaluate data in 130.05 seconds!
[tester] 
AGNewsMetric: acc=0.8505263157894737, hinge=3.156062399713617, ce=7.629822809319747
Global test acc @ epoch 175: 0.8505
Global epoch 176...
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 1.0430806440808738e-07
Local loss @ local epoch 1: 1.4901159417490817e-08
Local loss @ local epoch 2: 3.129238450583216e-07
Local loss @ local epoch 3: 0.0021603424102067947
Local loss @ local epoch 4: 1.0430811414607888e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.9 seconds!
[tester] 
AGNewsMetric: acc=0.8530263157894736, hinge=3.0352814631713065, ce=7.896877647199129
Local test acc @ epoch 176: 0.853
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 5.14088469572016e-07
Local loss @ local epoch 1: 1.6391270207805064e-07
Local loss @ local epoch 2: 1.8253749658470042e-06
Local loss @ local epoch 3: 1.2069893955413136e-06
Local loss @ local epoch 4: 1.4155958751871367e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.05 seconds!
[tester] 
AGNewsMetric: acc=0.8169736842105263, hinge=3.5636395908656873, ce=8.529318564565559
Local test acc @ epoch 176: 0.817
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 2.8312166477917344e-07
Local loss @ local epoch 1: 4.1723183130670805e-07
Local loss @ local epoch 2: 0.00016728299669921398
Local loss @ local epoch 3: 7.674080961805885e-07
Local loss @ local epoch 4: 1.9631273971754126e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.01 seconds!
[tester] 
AGNewsMetric: acc=0.7628947368421053, hinge=4.282419354037235, ce=8.856599869979055
Local test acc @ epoch 176: 0.7629
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 6.705521116145974e-08
Local loss @ local epoch 1: 2.9802320611338473e-08
Local loss @ local epoch 2: 4.470347647611561e-08
Local loss @ local epoch 3: 2.9802318834981634e-08
Local loss @ local epoch 4: 3.7252823403832735e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.39 seconds!
[tester] 
AGNewsMetric: acc=0.8467105263157895, hinge=3.1750826873277362, ce=7.685975099864759
Local test acc @ epoch 176: 0.8467
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 3.725289943190546e-08
Local loss @ local epoch 1: 6.705521116145974e-08
Local loss @ local epoch 2: 7.450576333667414e-08
Local loss @ local epoch 3: 1.8626440123625798e-07
Local loss @ local epoch 4: 2.9802318834981634e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.23 seconds!
[tester] 
AGNewsMetric: acc=0.8471052631578947, hinge=3.056102181233858, ce=7.554442636590255
Local test acc @ epoch 176: 0.8471
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 8.19563723553074e-08
Local loss @ local epoch 1: 1.713632258315556e-07
Local loss @ local epoch 2: 1.3187413969717454e-06
Local loss @ local epoch 3: 8.940694584680386e-08
Local loss @ local epoch 4: 4.5448507535184035e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 131.02 seconds!
[tester] 
AGNewsMetric: acc=0.7005263157894737, hinge=6.0193666832070605, ce=11.164286874469958
Local test acc @ epoch 176: 0.7005
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901156930591242e-07
Local loss @ local epoch 1: 4.283951057004742e-06
Local loss @ local epoch 2: 5.960463056453591e-08
Local loss @ local epoch 3: 2.90572359062935e-07
Local loss @ local epoch 4: 3.9488017478106485e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.3 seconds!
[tester] 
AGNewsMetric: acc=0.8448684210526316, hinge=2.8266124712793452, ce=7.25434864244963
Local test acc @ epoch 176: 0.8449
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 9.685751933830034e-08
Local loss @ local epoch 1: 2.16066538882842e-07
Local loss @ local epoch 2: 2.1606666678053443e-07
Local loss @ local epoch 3: 1.5646213569198153e-07
Local loss @ local epoch 4: 1.415609887089886e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.29 seconds!
[tester] 
AGNewsMetric: acc=0.7871052631578948, hinge=4.468661031723022, ce=8.30761250546104
Local test acc @ epoch 176: 0.7871
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 3.8742922470191843e-07
Local loss @ local epoch 1: 5.960463766996327e-08
Local loss @ local epoch 2: 5.215405707303944e-08
Local loss @ local epoch 3: 2.1084917989355745e-06
Local loss @ local epoch 4: 6.407484534065588e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.31 seconds!
[tester] 
AGNewsMetric: acc=0.854078947368421, hinge=2.558985475239001, ce=7.920810663323653
Local test acc @ epoch 176: 0.8541
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 1.415597012055514e-06
Local loss @ local epoch 1: 9.760240118339425e-07
Local loss @ local epoch 2: 1.3708972801396158e-06
Local loss @ local epoch 3: 5.215403007241548e-07
Local loss @ local epoch 4: 1.733366847038269
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.45 seconds!
[tester] 
AGNewsMetric: acc=0.8296052631578947, hinge=3.0542378483320536, ce=7.868726593820672
Local test acc @ epoch 176: 0.8296
Global evaluate on test data...
Evaluate data in 129.76 seconds!
[tester] 
AGNewsMetric: acc=0.8536842105263158, hinge=3.0354073107870003, ce=7.553094999413741
Global test acc @ epoch 176: 0.8537
Global epoch 177...
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0008151853689923882
Local loss @ local epoch 1: 2.5331767119496362e-06
Local loss @ local epoch 2: 0.00885829422622919
Local loss @ local epoch 3: 0.0018073534592986107
Local loss @ local epoch 4: 0.689839780330658
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.95 seconds!
[tester] 
AGNewsMetric: acc=0.8138157894736842, hinge=3.3572103688591404, ce=8.68974390130294
Local test acc @ epoch 177: 0.8138
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 4.470347647611561e-08
Local loss @ local epoch 1: 6.70552182668871e-08
Local loss @ local epoch 2: 6.70552182668871e-08
Local loss @ local epoch 3: 2.2351740014414645e-08
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.04 seconds!
[tester] 
AGNewsMetric: acc=0.8447368421052631, hinge=3.4050894925468844, ce=7.721495274995503
Local test acc @ epoch 177: 0.8447
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 1.8626438702540327e-07
Local loss @ local epoch 1: 2.384183801495965e-07
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 5.215405707303944e-08
Local loss @ local epoch 4: 2.160666241479703e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.12 seconds!
[tester] 
AGNewsMetric: acc=0.8367105263157895, hinge=3.2571011201958906, ce=7.638068352749473
Local test acc @ epoch 177: 0.8367
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 8.19563723553074e-08
Local loss @ local epoch 1: 3.4123286241083406e-06
Local loss @ local epoch 2: 7.98653309175279e-06
Local loss @ local epoch 3: 1.6540228671146906e-06
Local loss @ local epoch 4: 6.638303602812812e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.88 seconds!
[tester] 
AGNewsMetric: acc=0.8119736842105263, hinge=4.3607714321738795, ce=9.113095932006836
Local test acc @ epoch 177: 0.812
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 3.725289587919178e-08
Local loss @ local epoch 1: 1.3411032284693647e-07
Local loss @ local epoch 2: 6.705521116145974e-08
Local loss @ local epoch 3: 2.3096771428754437e-07
Local loss @ local epoch 4: 1.7881372116335115e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.64 seconds!
[tester] 
AGNewsMetric: acc=0.8302631578947368, hinge=3.4996542694694117, ce=7.840832180223967
Local test acc @ epoch 177: 0.8303
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 5.215405707303944e-08
Local loss @ local epoch 1: 1.4901159417490817e-08
Local loss @ local epoch 2: 5.215406062575312e-08
Local loss @ local epoch 3: 6.929022902113502e-07
Local loss @ local epoch 4: 6.481986929429695e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.22 seconds!
[tester] 
AGNewsMetric: acc=0.7905263157894736, hinge=4.5294514869388784, ce=8.211351197895251
Local test acc @ epoch 177: 0.7905
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 8.19563723553074e-08
Local loss @ local epoch 1: 3.725289943190546e-08
Local loss @ local epoch 2: 1.7136324004241033e-07
Local loss @ local epoch 3: 2.533195697651536e-07
Local loss @ local epoch 4: 3.725289943190546e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.81 seconds!
[tester] 
AGNewsMetric: acc=0.8219736842105263, hinge=3.7643300219586022, ce=8.24134851254915
Local test acc @ epoch 177: 0.822
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 5.9604641222676946e-08
Local loss @ local epoch 1: 1.0676136298570782e-05
Local loss @ local epoch 2: 4.693855828463711e-07
Local loss @ local epoch 3: 0.16420802474021912
Local loss @ local epoch 4: 2.607702640489151e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.34 seconds!
[tester] 
AGNewsMetric: acc=0.7471052631578947, hinge=5.2848514998586555, ce=9.478602284883198
Local test acc @ epoch 177: 0.7471
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 2.2351730422087712e-07
Local loss @ local epoch 1: 5.736940238421084e-07
Local loss @ local epoch 2: 9.387710520059045e-07
Local loss @ local epoch 3: 0.18193022906780243
Local loss @ local epoch 4: 3.870128057315014e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.35 seconds!
[tester] 
AGNewsMetric: acc=0.8073684210526316, hinge=3.692008951839648, ce=7.694942376990067
Local test acc @ epoch 177: 0.8074
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 3.725289943190546e-08
Local loss @ local epoch 1: 2.0116556243010564e-07
Local loss @ local epoch 2: 1.7881380642847944e-07
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 8.195635814445268e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.6 seconds!
[tester] 
AGNewsMetric: acc=0.8447368421052631, hinge=3.063628144264221, ce=8.008501175328306
Local test acc @ epoch 177: 0.8447
Global evaluate on test data...
Evaluate data in 130.23 seconds!
[tester] 
AGNewsMetric: acc=0.8377631578947369, hinge=3.462988559823287, ce=7.843689271023399
Global test acc @ epoch 177: 0.8378
Global epoch 178...
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 1.788138632718983e-07
Local loss @ local epoch 1: 6.705521116145974e-08
Local loss @ local epoch 2: 1.6391271628890536e-07
Local loss @ local epoch 3: 3.87429395232175e-07
Local loss @ local epoch 4: 1.7136328267497447e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.9 seconds!
[tester] 
AGNewsMetric: acc=0.8460526315789474, hinge=3.088022547270122, ce=7.550166744432952
Local test acc @ epoch 178: 0.8461
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 9.834734555624891e-07
Local loss @ local epoch 1: 7.152527814469067e-07
Local loss @ local epoch 2: 1.788138632718983e-07
Local loss @ local epoch 3: 0.00041545674321241677
Local loss @ local epoch 4: 0.3165789544582367
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.88 seconds!
[tester] 
AGNewsMetric: acc=0.814078947368421, hinge=3.712462419961628, ce=7.885561542510986
Local test acc @ epoch 178: 0.8141
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 2.2351740014414645e-08
Local loss @ local epoch 1: 2.2351740014414645e-08
Local loss @ local epoch 2: 6.705521116145974e-08
Local loss @ local epoch 3: 3.725289587919178e-08
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.99 seconds!
[tester] 
AGNewsMetric: acc=0.8469736842105263, hinge=3.1488015375639264, ce=7.558935294904207
Local test acc @ epoch 178: 0.847
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.117586450050112e-07
Local loss @ local epoch 2: 1.1920926823449918e-07
Local loss @ local epoch 3: 2.9802320611338473e-08
Local loss @ local epoch 4: 2.9802318834981634e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.96 seconds!
[tester] 
AGNewsMetric: acc=0.8478947368421053, hinge=3.072401942453886, ce=7.946417647913883
Local test acc @ epoch 178: 0.8479
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 1.8775240278046113e-06
Local loss @ local epoch 1: 2.0472049072850496e-05
Local loss @ local epoch 2: 4.574574631988071e-06
Local loss @ local epoch 3: 2.3222358226776123
Local loss @ local epoch 4: 2.1842464775545523e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.96 seconds!
[tester] 
AGNewsMetric: acc=0.8002631578947368, hinge=3.715367375173067, ce=8.214891678659539
Local test acc @ epoch 178: 0.8003
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 1.0132746410818072e-06
Local loss @ local epoch 1: 2.9429220376187004e-06
Local loss @ local epoch 2: 6.298880907706916e-05
Local loss @ local epoch 3: 1.1175869474300271e-07
Local loss @ local epoch 4: 0.0007483019144274294
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.58 seconds!
[tester] 
AGNewsMetric: acc=0.8197368421052632, hinge=3.524693585696973, ce=8.190876121520995
Local test acc @ epoch 178: 0.8197
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.7136324004241033e-07
Local loss @ local epoch 1: 5.215405707303944e-08
Local loss @ local epoch 2: 7.3235464697063435e-06
Local loss @ local epoch 3: 2.0861612881617475e-07
Local loss @ local epoch 4: 0.5622588992118835
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.6 seconds!
[tester] 
AGNewsMetric: acc=0.8207894736842105, hinge=3.543907441214511, ce=7.655720252990722
Local test acc @ epoch 178: 0.8208
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450579175838357e-08
Local loss @ local epoch 1: 5.215405707303944e-08
Local loss @ local epoch 2: 2.9802318834981634e-08
Local loss @ local epoch 3: 1.8104667560692178e-06
Local loss @ local epoch 4: 9.685751223287298e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.94 seconds!
[tester] 
AGNewsMetric: acc=0.8410526315789474, hinge=3.1004548767993323, ce=8.533337596090217
Local test acc @ epoch 178: 0.8411
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.10709358751773834
Local loss @ local epoch 1: 0.03677252680063248
Local loss @ local epoch 2: 2.0562069416046143
Local loss @ local epoch 3: 0.5045695304870605
Local loss @ local epoch 4: 0.9030106067657471
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.32 seconds!
[tester] 
AGNewsMetric: acc=0.8560526315789474, hinge=2.1241767843146073, ce=7.812406600149054
Local test acc @ epoch 178: 0.8561
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 1.3411036547950062e-07
Local loss @ local epoch 2: 8.642638249511947e-07
Local loss @ local epoch 3: 1.7136329688582919e-07
Local loss @ local epoch 4: 4.470347647611561e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.49 seconds!
[tester] 
AGNewsMetric: acc=0.6175, hinge=8.62115093005331, ce=11.605249716106213
Local test acc @ epoch 178: 0.6175
Global evaluate on test data...
Evaluate data in 130.05 seconds!
[tester] 
AGNewsMetric: acc=0.8503947368421053, hinge=3.24260077024761, ce=7.482814009817023
Global test acc @ epoch 178: 0.8504
Global epoch 179...
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 6.705521116145974e-08
Local loss @ local epoch 1: 1.4901152667334827e-07
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 5.960463056453591e-08
Local loss @ local epoch 4: 4.3062882468802854e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.21 seconds!
[tester] 
AGNewsMetric: acc=0.8163157894736842, hinge=3.8054240254351965, ce=8.398857769213224
Local test acc @ epoch 179: 0.8163
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 2.9802318834981634e-08
Local loss @ local epoch 1: 7.450577044210149e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 5.960463056453591e-08
Local loss @ local epoch 4: 7.450579175838357e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.53 seconds!
[tester] 
AGNewsMetric: acc=0.8453947368421053, hinge=3.115409776537042, ce=7.659961376190186
Local test acc @ epoch 179: 0.8454
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 1.0430808572436945e-07
Local loss @ local epoch 3: 4.470348002882929e-08
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.11 seconds!
[tester] 
AGNewsMetric: acc=0.8422368421052632, hinge=3.2226279303902072, ce=7.6391181373596195
Local test acc @ epoch 179: 0.8422
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 6.548728833877249e-06
Local loss @ local epoch 1: 1.6391268786719593e-07
Local loss @ local epoch 2: 0.12184154242277145
Local loss @ local epoch 3: 0.0001963911927305162
Local loss @ local epoch 4: 0.00041835143929347396
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.77 seconds!
[tester] 
AGNewsMetric: acc=0.6431578947368422, hinge=7.2125467450995195, ce=10.296601269370631
Local test acc @ epoch 179: 0.6432
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 4.554940096568316e-05
Local loss @ local epoch 1: 3.6880073821521364e-06
Local loss @ local epoch 2: 1.9807274341583252
Local loss @ local epoch 3: 3.4868301099777455e-06
Local loss @ local epoch 4: 0.004681301303207874
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.64 seconds!
[tester] 
AGNewsMetric: acc=0.7955263157894736, hinge=3.64650522533216, ce=8.49518485621402
Local test acc @ epoch 179: 0.7955
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 1.266597848825768e-07
Local loss @ local epoch 1: 5.215404996761208e-08
Local loss @ local epoch 2: 0.001106803072616458
Local loss @ local epoch 3: 1.415609887089886e-07
Local loss @ local epoch 4: 5.628638245980255e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.97 seconds!
[tester] 
AGNewsMetric: acc=0.8106578947368421, hinge=3.6065691262797306, ce=8.533857343573318
Local test acc @ epoch 179: 0.8107
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 5.469324241857976e-05
Local loss @ local epoch 1: 0.1346539705991745
Local loss @ local epoch 2: 0.5416204929351807
Local loss @ local epoch 3: 0.000616211153101176
Local loss @ local epoch 4: 0.7083885073661804
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.43 seconds!
[tester] 
AGNewsMetric: acc=0.8419736842105263, hinge=2.7968093493110255, ce=8.159598113612125
Local test acc @ epoch 179: 0.842
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 5.215405707303944e-08
Local loss @ local epoch 1: 3.7252892326478104e-08
Local loss @ local epoch 2: 4.470347647611561e-08
Local loss @ local epoch 3: 2.2351740014414645e-08
Local loss @ local epoch 4: 5.215405352032576e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.29 seconds!
[tester] 
AGNewsMetric: acc=0.8376315789473684, hinge=3.388182732431512, ce=8.002535448576275
Local test acc @ epoch 179: 0.8376
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 2.9802318834981634e-08
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 6.705521116145974e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.88 seconds!
[tester] 
AGNewsMetric: acc=0.8489473684210527, hinge=3.2923064640948647, ce=7.50173647328427
Local test acc @ epoch 179: 0.8489
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 8.940693874137651e-08
Local loss @ local epoch 1: 1.1175867342672063e-07
Local loss @ local epoch 2: 3.725289943190546e-08
Local loss @ local epoch 3: 2.8312169320088287e-07
Local loss @ local epoch 4: 3.6507759659798467e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.3 seconds!
[tester] 
AGNewsMetric: acc=0.8365789473684211, hinge=3.4130981422725477, ce=7.797750073483115
Local test acc @ epoch 179: 0.8366
Global evaluate on test data...
Evaluate data in 130.56 seconds!
[tester] 
AGNewsMetric: acc=0.8478947368421053, hinge=3.178702674163015, ce=7.564649248625103
Global test acc @ epoch 179: 0.8479
Global epoch 180...
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 8.270106945929001e-07
Local loss @ local epoch 1: 3.836998075712472e-06
Local loss @ local epoch 2: 8.419134474024759e-07
Local loss @ local epoch 3: 5.1403938414296135e-05
Local loss @ local epoch 4: 0.00010910341370617971
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.94 seconds!
[tester] 
AGNewsMetric: acc=0.7582894736842105, hinge=4.905903054287559, ce=8.559493709363435
Local test acc @ epoch 180: 0.7583
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 5.215404996761208e-08
Local loss @ local epoch 1: 1.4156094607642444e-07
Local loss @ local epoch 2: 1.4156094607642444e-07
Local loss @ local epoch 3: 2.9802320611338473e-08
Local loss @ local epoch 4: 6.362571184581611e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.72 seconds!
[tester] 
AGNewsMetric: acc=0.8438157894736842, hinge=3.1349091512278506, ce=7.7881630746941815
Local test acc @ epoch 180: 0.8438
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 3.725289943190546e-08
Local loss @ local epoch 1: 2.9802320611338473e-08
Local loss @ local epoch 2: 2.8312140898378857e-07
Local loss @ local epoch 3: 2.2351740014414645e-08
Local loss @ local epoch 4: 1.4156101713069802e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.18 seconds!
[tester] 
AGNewsMetric: acc=0.8442105263157895, hinge=3.0426505944603366, ce=7.951666468570107
Local test acc @ epoch 180: 0.8442
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 3.432344601606019e-05
Local loss @ local epoch 1: 1.333645059276023e-06
Local loss @ local epoch 2: 0.0003089495876338333
Local loss @ local epoch 3: 2.795957334456034e-05
Local loss @ local epoch 4: 0.13587355613708496
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.33 seconds!
[tester] 
AGNewsMetric: acc=0.8123684210526316, hinge=2.4922536777195177, ce=8.797831832484196
Local test acc @ epoch 180: 0.8124
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 2.950361704279203e-06
Local loss @ local epoch 1: 4.99187876812357e-07
Local loss @ local epoch 2: 1.585429345141165e-05
Local loss @ local epoch 3: 9.685753354915505e-08
Local loss @ local epoch 4: 0.09924318641424179
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.07 seconds!
[tester] 
AGNewsMetric: acc=0.770921052631579, hinge=4.693960892024793, ce=9.653169947172467
Local test acc @ epoch 180: 0.7709
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 2.9802320611338473e-08
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 4.596839062287472e-06
Local loss @ local epoch 3: 4.4703469370688254e-08
Local loss @ local epoch 4: 0.001018967479467392
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.35 seconds!
[tester] 
AGNewsMetric: acc=0.8401315789473685, hinge=3.3561885632966693, ce=8.034904314342297
Local test acc @ epoch 180: 0.8401
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 8.195634393359796e-08
Local loss @ local epoch 1: 0.0008743671351112425
Local loss @ local epoch 2: 7.152540320021217e-07
Local loss @ local epoch 3: 0.6742866039276123
Local loss @ local epoch 4: 5.4909251048229635e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.95 seconds!
[tester] 
AGNewsMetric: acc=0.7744736842105263, hinge=4.4544409335287, ce=8.382724057247763
Local test acc @ epoch 180: 0.7745
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 6.1985879256099e-06
Local loss @ local epoch 1: 0.6077098250389099
Local loss @ local epoch 2: 2.4586898916822975e-07
Local loss @ local epoch 3: 0.3642135262489319
Local loss @ local epoch 4: 0.21872040629386902
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.11 seconds!
[tester] 
AGNewsMetric: acc=0.7823684210526316, hinge=4.006504991180019, ce=9.056974900898181
Local test acc @ epoch 180: 0.7824
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 2.2351740014414645e-08
Local loss @ local epoch 1: 0.00023435254115611315
Local loss @ local epoch 2: 6.705498094561335e-07
Local loss @ local epoch 3: 0.7279518246650696
Local loss @ local epoch 4: 1.0207229479419766e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.44 seconds!
[tester] 
AGNewsMetric: acc=0.7897368421052632, hinge=4.241221784541481, ce=8.06322179091604
Local test acc @ epoch 180: 0.7897
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 1.043080928297968e-07
Local loss @ local epoch 1: 1.4901159417490817e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 5.960463766996327e-08
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.03 seconds!
[tester] 
AGNewsMetric: acc=0.8480263157894737, hinge=3.085124277566609, ce=8.10809293847335
Local test acc @ epoch 180: 0.848
Global evaluate on test data...
Evaluate data in 129.68 seconds!
[tester] 
AGNewsMetric: acc=0.8467105263157895, hinge=3.20607648548327, ce=7.6754200915286415
Global test acc @ epoch 180: 0.8467
Global epoch 181...
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901156930591242e-07
Local loss @ local epoch 1: 2.011656192735245e-07
Local loss @ local epoch 2: 2.622578904265538e-06
Local loss @ local epoch 3: 1.5646212148112681e-07
Local loss @ local epoch 4: 3.948802884679026e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.3 seconds!
[tester] 
AGNewsMetric: acc=0.7876315789473685, hinge=4.736758435148942, ce=9.22624795612536
Local test acc @ epoch 181: 0.7876
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 5.960463056453591e-08
Local loss @ local epoch 1: 8.940693874137651e-08
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 3.054735771002015e-07
Local loss @ local epoch 4: 2.9802318834981634e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.93 seconds!
[tester] 
AGNewsMetric: acc=0.8296052631578947, hinge=3.6136357917283712, ce=8.058875823773835
Local test acc @ epoch 181: 0.8296
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 3.725289943190546e-08
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 2.9802315282267955e-08
Local loss @ local epoch 3: 2.9802318834981634e-08
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.29 seconds!
[tester] 
AGNewsMetric: acc=0.8431578947368421, hinge=3.3264017423830534, ce=7.675823029969868
Local test acc @ epoch 181: 0.8432
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 4.470347647611561e-08
Local loss @ local epoch 1: 5.960463766996327e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.9802320611338473e-08
Local loss @ local epoch 4: 2.9802315282267955e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.0 seconds!
[tester] 
AGNewsMetric: acc=0.8455263157894737, hinge=3.219785811775609, ce=8.013627780111213
Local test acc @ epoch 181: 0.8455
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 4.470339263207279e-07
Local loss @ local epoch 1: 5.555685129365884e-05
Local loss @ local epoch 2: 8.19563723553074e-08
Local loss @ local epoch 3: 9.447699994780123e-05
Local loss @ local epoch 4: 1.95204279407335e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.86 seconds!
[tester] 
AGNewsMetric: acc=0.8401315789473685, hinge=2.960368607922604, ce=7.703638757404528
Local test acc @ epoch 181: 0.8401
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.743206121318508e-05
Local loss @ local epoch 1: 4.4703404000756564e-07
Local loss @ local epoch 2: 8.985070962808095e-06
Local loss @ local epoch 3: 0.006951630115509033
Local loss @ local epoch 4: 6.869538628961891e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.95 seconds!
[tester] 
AGNewsMetric: acc=0.7672368421052631, hinge=4.949681366619311, ce=9.745193764536005
Local test acc @ epoch 181: 0.7672
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 2.086160861836106e-07
Local loss @ local epoch 1: 2.9802318834981634e-08
Local loss @ local epoch 2: 5.215405707303944e-08
Local loss @ local epoch 3: 2.9802318834981634e-08
Local loss @ local epoch 4: 1.2665984172599565e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.7 seconds!
[tester] 
AGNewsMetric: acc=0.8389473684210527, hinge=3.345920500253376, ce=7.991622692911249
Local test acc @ epoch 181: 0.8389
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 1.862644154471127e-07
Local loss @ local epoch 1: 8.19563723553074e-08
Local loss @ local epoch 2: 1.1175866632129328e-07
Local loss @ local epoch 3: 9.685750512744562e-08
Local loss @ local epoch 4: 1.1846329925901955e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.97 seconds!
[tester] 
AGNewsMetric: acc=0.8365789473684211, hinge=3.3691165630440962, ce=8.272346876044022
Local test acc @ epoch 181: 0.8366
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 4.5969285565661266e-05
Local loss @ local epoch 1: 1.9594897366914665e-06
Local loss @ local epoch 2: 2.642203980940394e-05
Local loss @ local epoch 3: 1.2963978406332899e-06
Local loss @ local epoch 4: 8.597783562436234e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.63 seconds!
[tester] 
AGNewsMetric: acc=0.839078947368421, hinge=2.3683095364821583, ce=7.395084439327842
Local test acc @ epoch 181: 0.8391
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 1.3411039390121005e-07
Local loss @ local epoch 1: 1.9073290786764119e-06
Local loss @ local epoch 2: 8.940695295223122e-08
Local loss @ local epoch 3: 0.0004232154751662165
Local loss @ local epoch 4: 7.078028829710092e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.73 seconds!
[tester] 
AGNewsMetric: acc=0.6636842105263158, hinge=7.140055835121556, ce=11.274358524523283
Local test acc @ epoch 181: 0.6637
Global evaluate on test data...
Evaluate data in 129.44 seconds!
[tester] 
AGNewsMetric: acc=0.8472368421052632, hinge=3.2526134977842633, ce=7.732460622285542
Global test acc @ epoch 181: 0.8472
Global epoch 182...
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 6.705521116145974e-08
Local loss @ local epoch 1: 9.685753354915505e-08
Local loss @ local epoch 2: 2.980225417559268e-07
Local loss @ local epoch 3: 2.682204467419069e-07
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.11 seconds!
[tester] 
AGNewsMetric: acc=0.8465789473684211, hinge=3.1228142738342286, ce=7.802001235359594
Local test acc @ epoch 182: 0.8466
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 5.215405707303944e-08
Local loss @ local epoch 1: 2.384182948844682e-07
Local loss @ local epoch 2: 4.470347292340193e-08
Local loss @ local epoch 3: 7.450579175838357e-08
Local loss @ local epoch 4: 6.556489324793802e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.59 seconds!
[tester] 
AGNewsMetric: acc=0.780921052631579, hinge=4.394780842630487, ce=8.840089486774646
Local test acc @ epoch 182: 0.7809
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 2.2351740014414645e-08
Local loss @ local epoch 1: 1.9718603653018363e-05
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.00023088243324309587
Local loss @ local epoch 4: 0.01349764596670866
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.16 seconds!
[tester] 
AGNewsMetric: acc=0.838421052631579, hinge=3.3084265726491027, ce=7.929856452941895
Local test acc @ epoch 182: 0.8384
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 1.6391271628890536e-07
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 1.4901159417490817e-08
Local loss @ local epoch 3: 2.980229965032777e-07
Local loss @ local epoch 4: 6.705521116145974e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.7 seconds!
[tester] 
AGNewsMetric: acc=0.8468421052631578, hinge=3.1203165373049284, ce=7.844984034488076
Local test acc @ epoch 182: 0.8468
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 2.384182948844682e-07
Local loss @ local epoch 1: 2.309678279743821e-07
Local loss @ local epoch 2: 3.725289943190546e-08
Local loss @ local epoch 3: 0.0002623284817673266
Local loss @ local epoch 4: 2.0116557664096035e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.05 seconds!
[tester] 
AGNewsMetric: acc=0.8463157894736842, hinge=3.0513927467245803, ce=7.882309110541093
Local test acc @ epoch 182: 0.8463
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 5.215400733504794e-07
Local loss @ local epoch 1: 4.470348002882929e-08
Local loss @ local epoch 2: 4.544847342913272e-07
Local loss @ local epoch 3: 6.63100308884168e-07
Local loss @ local epoch 4: 1.415609887089886e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.53 seconds!
[tester] 
AGNewsMetric: acc=0.8218421052631579, hinge=3.9094475510245874, ce=7.3727913936815765
Local test acc @ epoch 182: 0.8218
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 1.937149818331818e-07
Local loss @ local epoch 1: 9.685753354915505e-08
Local loss @ local epoch 2: 1.2665982751514093e-07
Local loss @ local epoch 3: 4.619347464540624e-07
Local loss @ local epoch 4: 2.086161714487389e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.38 seconds!
[tester] 
AGNewsMetric: acc=0.8035526315789474, hinge=3.9729063390430652, ce=8.090614095989027
Local test acc @ epoch 182: 0.8036
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 5.1402788812993094e-05
Local loss @ local epoch 2: 6.705521116145974e-08
Local loss @ local epoch 3: 1.2069831427652389e-06
Local loss @ local epoch 4: 5.960463766996327e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.1 seconds!
[tester] 
AGNewsMetric: acc=0.8439473684210527, hinge=2.763516862015975, ce=8.278566766036183
Local test acc @ epoch 182: 0.8439
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 1.900398638099432e-05
Local loss @ local epoch 1: 1.974389761016937e-06
Local loss @ local epoch 2: 2.1842342903255485e-05
Local loss @ local epoch 3: 0.0002292603749083355
Local loss @ local epoch 4: 4.552272912405897e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.79 seconds!
[tester] 
AGNewsMetric: acc=0.8085526315789474, hinge=3.379728079595064, ce=8.180453546423662
Local test acc @ epoch 182: 0.8086
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 1.5646213569198153e-07
Local loss @ local epoch 1: 1.3411036547950062e-07
Local loss @ local epoch 2: 3.725289943190546e-08
Local loss @ local epoch 3: 1.9371501025489124e-07
Local loss @ local epoch 4: 0.21243968605995178
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.18 seconds!
[tester] 
AGNewsMetric: acc=0.7956578947368421, hinge=4.28534681269997, ce=8.335987279791581
Local test acc @ epoch 182: 0.7957
Global evaluate on test data...
Evaluate data in 130.35 seconds!
[tester] 
AGNewsMetric: acc=0.8402631578947368, hinge=3.374175963903728, ce=7.69565969065616
Global test acc @ epoch 182: 0.8403
Global epoch 183...
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 1.2665982751514093e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.2351740014414645e-08
Local loss @ local epoch 3: 2.2351726158831298e-07
Local loss @ local epoch 4: 7.450577754752885e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.72 seconds!
[tester] 
AGNewsMetric: acc=0.828421052631579, hinge=3.6076701703824496, ce=8.24437554610403
Local test acc @ epoch 183: 0.8284
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 4.470347647611561e-08
Local loss @ local epoch 1: 4.470347647611561e-08
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 1.4901159417490817e-08
Local loss @ local epoch 4: 1.1920926112907182e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.43 seconds!
[tester] 
AGNewsMetric: acc=0.8385526315789473, hinge=3.4494626210865222, ce=7.999336869089227
Local test acc @ epoch 183: 0.8386
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 2.9802320611338473e-08
Local loss @ local epoch 1: 7.450577754752885e-08
Local loss @ local epoch 2: 8.940693163594915e-08
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 4.470348002882929e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.51 seconds!
[tester] 
AGNewsMetric: acc=0.839078947368421, hinge=3.3976783255526892, ce=8.229753512332314
Local test acc @ epoch 183: 0.8391
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 2.0116554821925092e-07
Local loss @ local epoch 1: 7.278837983903941e-06
Local loss @ local epoch 2: 9.041489101946354e-05
Local loss @ local epoch 3: 0.33259010314941406
Local loss @ local epoch 4: 9.68572521742317e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.75 seconds!
[tester] 
AGNewsMetric: acc=0.8518421052631578, hinge=2.7429205861844514, ce=7.648724384307862
Local test acc @ epoch 183: 0.8518
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 3.725289943190546e-08
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 5.215405352032576e-08
Local loss @ local epoch 3: 2.9802320611338473e-08
Local loss @ local epoch 4: 2.9802318834981634e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.81 seconds!
[tester] 
AGNewsMetric: acc=0.8414473684210526, hinge=3.3418528100063924, ce=7.899631737156918
Local test acc @ epoch 183: 0.8414
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 4.0233061326944153e-07
Local loss @ local epoch 1: 0.17402876913547516
Local loss @ local epoch 2: 1.5646216411369096e-07
Local loss @ local epoch 3: 0.003724725218489766
Local loss @ local epoch 4: 0.7716327905654907
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.51 seconds!
[tester] 
AGNewsMetric: acc=0.758421052631579, hinge=4.028362453360306, ce=9.85947455155222
Local test acc @ epoch 183: 0.7584
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 4.395831467718381e-07
Local loss @ local epoch 1: 5.960463766996327e-08
Local loss @ local epoch 2: 3.730889511643909e-05
Local loss @ local epoch 3: 2.3841845120387006e-07
Local loss @ local epoch 4: 2.0116560506266978e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.58 seconds!
[tester] 
AGNewsMetric: acc=0.8505263157894737, hinge=2.958305718271356, ce=7.6154357669228006
Local test acc @ epoch 183: 0.8505
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 2.9802318834981634e-08
Local loss @ local epoch 1: 5.215405707303944e-08
Local loss @ local epoch 2: 2.9802320611338473e-08
Local loss @ local epoch 3: 3.7252892326478104e-08
Local loss @ local epoch 4: 6.705521116145974e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 128.96 seconds!
[tester] 
AGNewsMetric: acc=0.8476315789473684, hinge=3.200850924190722, ce=7.674943345722399
Local test acc @ epoch 183: 0.8476
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 3.203742835466983e-07
Local loss @ local epoch 1: 1.7881389169360773e-07
Local loss @ local epoch 2: 2.860997710740776e-06
Local loss @ local epoch 3: 0.40939784049987793
Local loss @ local epoch 4: 2.1606678046737215e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 131.07 seconds!
[tester] 
AGNewsMetric: acc=0.8219736842105263, hinge=3.4161723852157593, ce=8.329282228570236
Local test acc @ epoch 183: 0.822
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 3.57627158109608e-07
Local loss @ local epoch 1: 9.603501894162036e-06
Local loss @ local epoch 2: 0.0003455106634646654
Local loss @ local epoch 3: 2.2351740014414645e-08
Local loss @ local epoch 4: 2.0861615723788418e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.07 seconds!
[tester] 
AGNewsMetric: acc=0.7588157894736842, hinge=5.326281338239971, ce=8.75780525408293
Local test acc @ epoch 183: 0.7588
Global evaluate on test data...
Evaluate data in 130.41 seconds!
[tester] 
AGNewsMetric: acc=0.8492105263157895, hinge=3.211537292631049, ce=7.763430756016781
Global test acc @ epoch 183: 0.8492
Global epoch 184...
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 5.960463056453591e-08
Local loss @ local epoch 1: 2.1606668099138915e-07
Local loss @ local epoch 2: 3.725289943190546e-08
Local loss @ local epoch 3: 0.4197235107421875
Local loss @ local epoch 4: 6.70552182668871e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.03 seconds!
[tester] 
AGNewsMetric: acc=0.833421052631579, hinge=3.402789368754939, ce=8.133538958900854
Local test acc @ epoch 184: 0.8334
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 3.866734459734289e-06
Local loss @ local epoch 1: 4.17231433402776e-07
Local loss @ local epoch 2: 1.5348055057984311e-06
Local loss @ local epoch 3: 7.823094279046927e-07
Local loss @ local epoch 4: 1.0952338698189124e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.63 seconds!
[tester] 
AGNewsMetric: acc=0.7377631578947368, hinge=4.819909844398499, ce=9.717044476960835
Local test acc @ epoch 184: 0.7378
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4155943972582463e-06
Local loss @ local epoch 1: 1.1920921849650767e-07
Local loss @ local epoch 2: 6.929024038981879e-07
Local loss @ local epoch 3: 5.1252041885163635e-05
Local loss @ local epoch 4: 2.3841852225814364e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.37 seconds!
[tester] 
AGNewsMetric: acc=0.8464473684210526, hinge=3.016977195739746, ce=7.675368082146895
Local test acc @ epoch 184: 0.8464
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 3.725289943190546e-08
Local loss @ local epoch 1: 2.2351740014414645e-08
Local loss @ local epoch 2: 2.2351740014414645e-08
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 4.470347647611561e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.08 seconds!
[tester] 
AGNewsMetric: acc=0.8432894736842105, hinge=3.3893480185458533, ce=7.767259181173224
Local test acc @ epoch 184: 0.8433
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 5.215405707303944e-08
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 2.0116542032155849e-07
Local loss @ local epoch 3: 5.215405707303944e-08
Local loss @ local epoch 4: 4.470348002882929e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.29 seconds!
[tester] 
AGNewsMetric: acc=0.8343421052631579, hinge=3.318833346115915, ce=7.686673728541324
Local test acc @ epoch 184: 0.8343
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 5.200325176701881e-06
Local loss @ local epoch 1: 4.216906745568849e-06
Local loss @ local epoch 2: 3.3303640520898625e-06
Local loss @ local epoch 3: 0.017363596707582474
Local loss @ local epoch 4: 2.559853601269424e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.85 seconds!
[tester] 
AGNewsMetric: acc=0.8228947368421052, hinge=2.7664134326734042, ce=7.757650425559596
Local test acc @ epoch 184: 0.8229
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 6.70552182668871e-08
Local loss @ local epoch 1: 7.078018029460509e-07
Local loss @ local epoch 2: 1.9472810890874825e-05
Local loss @ local epoch 3: 3.725289943190546e-08
Local loss @ local epoch 4: 0.00014879793161526322
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.63 seconds!
[tester] 
AGNewsMetric: acc=0.8125, hinge=4.039641720872177, ce=8.110899632102564
Local test acc @ epoch 184: 0.8125
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 2.682207025372918e-07
Local loss @ local epoch 1: 7.152535772547708e-07
Local loss @ local epoch 2: 1.8626440123625798e-07
Local loss @ local epoch 3: 1.0952297770927544e-06
Local loss @ local epoch 4: 6.034963462298037e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.24 seconds!
[tester] 
AGNewsMetric: acc=0.7901315789473684, hinge=4.325934483879491, ce=8.2535089302063
Local test acc @ epoch 184: 0.7901
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 5.960463766996327e-08
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 3.725289943190546e-08
Local loss @ local epoch 3: 8.195634393359796e-08
Local loss @ local epoch 4: 2.2351740014414645e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.91 seconds!
[tester] 
AGNewsMetric: acc=0.8465789473684211, hinge=3.3035974374570345, ce=7.6911076535676655
Local test acc @ epoch 184: 0.8466
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 2.9802318834981634e-08
Local loss @ local epoch 1: 7.450577754752885e-08
Local loss @ local epoch 2: 1.0430809993522416e-07
Local loss @ local epoch 3: 2.5331945607831585e-07
Local loss @ local epoch 4: 8.717148602954694e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.39 seconds!
[tester] 
AGNewsMetric: acc=0.8485526315789473, hinge=3.2631651240900945, ce=8.232723397706684
Local test acc @ epoch 184: 0.8486
Global evaluate on test data...
Evaluate data in 130.14 seconds!
[tester] 
AGNewsMetric: acc=0.843421052631579, hinge=3.382238344644245, ce=7.723515796661377
Global test acc @ epoch 184: 0.8434
Global epoch 185...
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 2.040383878920693e-05
Local loss @ local epoch 1: 2.607701503620774e-07
Local loss @ local epoch 2: 2.450942277908325
Local loss @ local epoch 3: 3.352756721142214e-07
Local loss @ local epoch 4: 0.17505162954330444
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 131.17 seconds!
[tester] 
AGNewsMetric: acc=0.8271052631578948, hinge=3.318727539464047, ce=7.69223540657445
Local test acc @ epoch 185: 0.8271
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 5.960463766996327e-08
Local loss @ local epoch 1: 8.940695295223122e-08
Local loss @ local epoch 2: 5.960463766996327e-08
Local loss @ local epoch 3: 5.215404996761208e-08
Local loss @ local epoch 4: 2.3841818119763047e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.48 seconds!
[tester] 
AGNewsMetric: acc=0.8385526315789473, hinge=3.510850242564553, ce=7.731705570220948
Local test acc @ epoch 185: 0.8386
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450579886381092e-08
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 2.2351740014414645e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.17 seconds!
[tester] 
AGNewsMetric: acc=0.8421052631578947, hinge=3.3152301808407434, ce=7.628985346743935
Local test acc @ epoch 185: 0.8421
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901159417490817e-08
Local loss @ local epoch 1: 3.725289943190546e-08
Local loss @ local epoch 2: 2.2351740014414645e-08
Local loss @ local epoch 3: 2.607698661449831e-07
Local loss @ local epoch 4: 5.215404996761208e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.43 seconds!
[tester] 
AGNewsMetric: acc=0.845, hinge=3.2167204194319874, ce=7.58731887315449
Local test acc @ epoch 185: 0.845
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0023186407051980495
Local loss @ local epoch 1: 1.4230540728021879e-06
Local loss @ local epoch 2: 0.00011123935837531462
Local loss @ local epoch 3: 0.0008997612167149782
Local loss @ local epoch 4: 0.00022292029461823404
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.2 seconds!
[tester] 
AGNewsMetric: acc=0.7884210526315789, hinge=3.499578029983922, ce=8.563469796431692
Local test acc @ epoch 185: 0.7884
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 5.960463766996327e-08
Local loss @ local epoch 1: 4.470347647611561e-08
Local loss @ local epoch 2: 5.215405707303944e-08
Local loss @ local epoch 3: 4.470347292340193e-08
Local loss @ local epoch 4: 1.5646207884856267e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.46 seconds!
[tester] 
AGNewsMetric: acc=0.8319736842105263, hinge=3.617159285043415, ce=8.145338544343646
Local test acc @ epoch 185: 0.832
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 2.2351740014414645e-08
Local loss @ local epoch 1: 2.2351740014414645e-08
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 4.470347647611561e-08
Local loss @ local epoch 4: 3.7252892326478104e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.43 seconds!
[tester] 
AGNewsMetric: acc=0.835, hinge=3.6707789985757127, ce=7.8292989891453795
Local test acc @ epoch 185: 0.835
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 2.9802320611338473e-08
Local loss @ local epoch 1: 1.1920922560193503e-07
Local loss @ local epoch 2: 7.450579175838357e-08
Local loss @ local epoch 3: 6.705521116145974e-08
Local loss @ local epoch 4: 7.450551606780209e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.94 seconds!
[tester] 
AGNewsMetric: acc=0.8403947368421053, hinge=3.362424710424323, ce=8.306006188643606
Local test acc @ epoch 185: 0.8404
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 3.725289943190546e-08
Local loss @ local epoch 1: 4.470347647611561e-08
Local loss @ local epoch 2: 8.19563723553074e-08
Local loss @ local epoch 3: 6.705487294311752e-07
Local loss @ local epoch 4: 2.9802318834981634e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.71 seconds!
[tester] 
AGNewsMetric: acc=0.8280263157894737, hinge=3.6262409709629257, ce=7.827863777562191
Local test acc @ epoch 185: 0.828
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 5.811432970403985e-07
Local loss @ local epoch 1: 6.70552182668871e-08
Local loss @ local epoch 2: 6.705496389258769e-07
Local loss @ local epoch 3: 1.1718797395587899e-05
Local loss @ local epoch 4: 4.5149331526772585e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.25 seconds!
[tester] 
AGNewsMetric: acc=0.7121052631578947, hinge=6.699235690267463, ce=10.208553954676578
Local test acc @ epoch 185: 0.7121
Global evaluate on test data...
Evaluate data in 129.92 seconds!
[tester] 
AGNewsMetric: acc=0.8405263157894737, hinge=3.510125981632032, ce=7.767671654349879
Global test acc @ epoch 185: 0.8405
Global epoch 186...
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 4.470347647611561e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.4901159417490817e-08
Local loss @ local epoch 3: 5.215405707303944e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.47 seconds!
[tester] 
AGNewsMetric: acc=0.8251315789473684, hinge=3.8858916739413614, ce=7.906313976488615
Local test acc @ epoch 186: 0.8251
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 8.940693874137651e-08
Local loss @ local epoch 1: 1.564621072702721e-07
Local loss @ local epoch 2: 1.974380438696244e-06
Local loss @ local epoch 3: 1.4156094607642444e-07
Local loss @ local epoch 4: 2.5331934239147813e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.64 seconds!
[tester] 
AGNewsMetric: acc=0.800921052631579, hinge=3.9164492275840357, ce=8.268071985746685
Local test acc @ epoch 186: 0.8009
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 5.960463056453591e-08
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 5.215404996761208e-08
Local loss @ local epoch 4: 1.639126594454865e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.11 seconds!
[tester] 
AGNewsMetric: acc=0.834078947368421, hinge=3.672950324510273, ce=7.79409985492104
Local test acc @ epoch 186: 0.8341
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 2.2351738238057806e-08
Local loss @ local epoch 1: 6.70552182668871e-08
Local loss @ local epoch 2: 5.960463766996327e-08
Local loss @ local epoch 3: 9.685751933830034e-08
Local loss @ local epoch 4: 9.685751933830034e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.87 seconds!
[tester] 
AGNewsMetric: acc=0.839078947368421, hinge=3.518848923632973, ce=7.6614194548757455
Local test acc @ epoch 186: 0.8391
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 4.172317744632892e-07
Local loss @ local epoch 1: 1.966929403351969e-06
Local loss @ local epoch 2: 9.164191965282953e-07
Local loss @ local epoch 3: 2.011656192735245e-07
Local loss @ local epoch 4: 4.485114459384931e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.13 seconds!
[tester] 
AGNewsMetric: acc=0.8325, hinge=3.2343146145971198, ce=7.789366597627339
Local test acc @ epoch 186: 0.8325
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.9371491077890823e-07
Local loss @ local epoch 1: 1.4901159417490817e-08
Local loss @ local epoch 2: 3.725289943190546e-08
Local loss @ local epoch 3: 3.427258548072132e-07
Local loss @ local epoch 4: 9.983750715036876e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.05 seconds!
[tester] 
AGNewsMetric: acc=0.7944736842105263, hinge=4.1883478159653516, ce=8.751065276296515
Local test acc @ epoch 186: 0.7945
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 2.2351738238057806e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.2351740014414645e-08
Local loss @ local epoch 3: 2.9802318834981634e-08
Local loss @ local epoch 4: 1.8626188875714433e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.07 seconds!
[tester] 
AGNewsMetric: acc=0.8382894736842105, hinge=3.4487637853622437, ce=7.6352700885973475
Local test acc @ epoch 186: 0.8383
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 2.0116539189984906e-07
Local loss @ local epoch 1: 3.7252892326478104e-08
Local loss @ local epoch 2: 7.9720911116965e-07
Local loss @ local epoch 3: 4.023307837996981e-07
Local loss @ local epoch 4: 1.4156094607642444e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.24 seconds!
[tester] 
AGNewsMetric: acc=0.8186842105263158, hinge=3.61931826566395, ce=7.704680535165887
Local test acc @ epoch 186: 0.8187
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 1.4901159417490817e-08
Local loss @ local epoch 2: 7.450577044210149e-08
Local loss @ local epoch 3: 1.1175860947787442e-07
Local loss @ local epoch 4: 1.7230828234460205e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.05 seconds!
[tester] 
AGNewsMetric: acc=0.8402631578947368, hinge=3.4418234027059453, ce=7.964213546953704
Local test acc @ epoch 186: 0.8403
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 3.725289587919178e-08
Local loss @ local epoch 1: 2.2351740014414645e-08
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 2.3841835172788706e-07
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.36 seconds!
[tester] 
AGNewsMetric: acc=0.8018421052631579, hinge=4.239153830628646, ce=8.535670083698474
Local test acc @ epoch 186: 0.8018
Global evaluate on test data...
Evaluate data in 130.44 seconds!
[tester] 
AGNewsMetric: acc=0.8421052631578947, hinge=3.4394419456783094, ce=7.630046353591116
Global test acc @ epoch 186: 0.8421
Global epoch 187...
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 2.2351740014414645e-08
Local loss @ local epoch 1: 1.266597990934315e-07
Local loss @ local epoch 2: 2.9802320611338473e-08
Local loss @ local epoch 3: 6.70552182668871e-08
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.62 seconds!
[tester] 
AGNewsMetric: acc=0.8402631578947368, hinge=3.4127535978116486, ce=8.12705705743087
Local test acc @ epoch 187: 0.8403
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901159417490817e-08
Local loss @ local epoch 1: 2.2351740014414645e-08
Local loss @ local epoch 2: 3.725289943190546e-08
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 5.960462345910855e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.12 seconds!
[tester] 
AGNewsMetric: acc=0.8407894736842105, hinge=3.518997775629947, ce=7.726656148810136
Local test acc @ epoch 187: 0.8408
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 1.9681356207001954e-05
Local loss @ local epoch 1: 5.1258843996038195e-06
Local loss @ local epoch 2: 0.008908810093998909
Local loss @ local epoch 3: 0.00020409515127539635
Local loss @ local epoch 4: 1.2424319982528687
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.97 seconds!
[tester] 
AGNewsMetric: acc=0.7626315789473684, hinge=4.612492323925621, ce=8.240254096984863
Local test acc @ epoch 187: 0.7626
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 1.3411030863608175e-07
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 5.215405707303944e-08
Local loss @ local epoch 3: 2.0861332359345397e-06
Local loss @ local epoch 4: 2.9802320611338473e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.05 seconds!
[tester] 
AGNewsMetric: acc=0.8376315789473684, hinge=3.4423182818764135, ce=8.584676637147602
Local test acc @ epoch 187: 0.8376
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 4.470347647611561e-08
Local loss @ local epoch 1: 2.160665530936967e-07
Local loss @ local epoch 2: 1.1175868053214799e-07
Local loss @ local epoch 3: 4.470334431516676e-07
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.61 seconds!
[tester] 
AGNewsMetric: acc=0.8317105263157895, hinge=3.6173770410136172, ce=7.857543472490812
Local test acc @ epoch 187: 0.8317
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 6.705521116145974e-08
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 3.7252892326478104e-08
Local loss @ local epoch 3: 2.2351740014414645e-08
Local loss @ local epoch 4: 1.3411033705779118e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.9 seconds!
[tester] 
AGNewsMetric: acc=0.8303947368421053, hinge=3.678093567396465, ce=7.764292039369282
Local test acc @ epoch 187: 0.8304
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 1.7136326846411976e-07
Local loss @ local epoch 1: 1.4901159417490817e-08
Local loss @ local epoch 2: 4.470347647611561e-08
Local loss @ local epoch 3: 3.725289943190546e-08
Local loss @ local epoch 4: 3.725289943190546e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.9 seconds!
[tester] 
AGNewsMetric: acc=0.8303947368421053, hinge=3.685670495033264, ce=8.03285272899427
Local test acc @ epoch 187: 0.8304
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 8.940693163594915e-08
Local loss @ local epoch 1: 4.470347647611561e-08
Local loss @ local epoch 2: 2.9802318834981634e-08
Local loss @ local epoch 3: 3.948802316244837e-07
Local loss @ local epoch 4: 1.117586450050112e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.01 seconds!
[tester] 
AGNewsMetric: acc=0.8261842105263157, hinge=3.801046256266142, ce=7.960785426089638
Local test acc @ epoch 187: 0.8262
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 4.470347647611561e-08
Local loss @ local epoch 1: 1.8626425912771083e-07
Local loss @ local epoch 2: 8.046602602007624e-07
Local loss @ local epoch 3: 2.2351740014414645e-08
Local loss @ local epoch 4: 3.146433300571516e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.45 seconds!
[tester] 
AGNewsMetric: acc=0.8144736842105263, hinge=3.945312166213989, ce=8.614646648607756
Local test acc @ epoch 187: 0.8145
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 3.725289943190546e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 8.642640523248701e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.14 seconds!
[tester] 
AGNewsMetric: acc=0.844078947368421, hinge=3.4461935966893247, ce=7.559608867042943
Local test acc @ epoch 187: 0.8441
Global evaluate on test data...
Evaluate data in 129.79 seconds!
[tester] 
AGNewsMetric: acc=0.8388157894736842, hinge=3.575233968935515, ce=7.756602389686986
Global test acc @ epoch 187: 0.8388
Global epoch 188...
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 5.393990250013303e-06
Local loss @ local epoch 1: 0.11446831375360489
Local loss @ local epoch 2: 1.2694703400484286e-05
Local loss @ local epoch 3: 2.1010494037909666e-06
Local loss @ local epoch 4: 0.5084731578826904
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.48 seconds!
[tester] 
AGNewsMetric: acc=0.7648684210526315, hinge=4.36124159913314, ce=8.864555129001015
Local test acc @ epoch 188: 0.7649
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 6.896176637383178e-05
Local loss @ local epoch 1: 6.70552182668871e-08
Local loss @ local epoch 2: 2.089702844619751
Local loss @ local epoch 3: 0.0004807071527466178
Local loss @ local epoch 4: 2.533195697651536e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.46 seconds!
[tester] 
AGNewsMetric: acc=0.8305263157894737, hinge=2.9525522159275255, ce=8.121892491390831
Local test acc @ epoch 188: 0.8305
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 4.470347292340193e-08
Local loss @ local epoch 1: 1.1175865921586592e-07
Local loss @ local epoch 2: 4.470347647611561e-08
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 4.470347647611561e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.69 seconds!
[tester] 
AGNewsMetric: acc=0.839078947368421, hinge=3.555450117211593, ce=7.989414330532676
Local test acc @ epoch 188: 0.8391
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450579175838357e-08
Local loss @ local epoch 1: 2.1606668099138915e-07
Local loss @ local epoch 2: 5.960463766996327e-08
Local loss @ local epoch 3: 2.9802318834981634e-08
Local loss @ local epoch 4: 2.2649364836979657e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.29 seconds!
[tester] 
AGNewsMetric: acc=0.7978947368421052, hinge=4.457478577714217, ce=8.193242444490132
Local test acc @ epoch 188: 0.7979
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 2.2351740014414645e-08
Local loss @ local epoch 1: 5.2154042862184724e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 3.725289587919178e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.65 seconds!
[tester] 
AGNewsMetric: acc=0.8432894736842105, hinge=3.362681073389555, ce=7.574474836650648
Local test acc @ epoch 188: 0.8433
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450577044210149e-08
Local loss @ local epoch 1: 3.12923674528065e-07
Local loss @ local epoch 2: 3.948797484554234e-07
Local loss @ local epoch 3: 6.705521116145974e-08
Local loss @ local epoch 4: 0.6351453065872192
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.91 seconds!
[tester] 
AGNewsMetric: acc=0.8310526315789474, hinge=3.5882374274103266, ce=7.8906223046152215
Local test acc @ epoch 188: 0.8311
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 2.9802320611338473e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.19 seconds!
[tester] 
AGNewsMetric: acc=0.8357894736842105, hinge=3.5868830653240806, ce=7.725633613184879
Local test acc @ epoch 188: 0.8358
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 5.215404996761208e-08
Local loss @ local epoch 1: 3.725289587919178e-08
Local loss @ local epoch 2: 4.470347292340193e-08
Local loss @ local epoch 3: 6.705521116145974e-08
Local loss @ local epoch 4: 1.5646209305941738e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.75 seconds!
[tester] 
AGNewsMetric: acc=0.8036842105263158, hinge=4.076422954609519, ce=8.525110122279116
Local test acc @ epoch 188: 0.8037
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 4.470347647611561e-08
Local loss @ local epoch 1: 0.007023612502962351
Local loss @ local epoch 2: 3.7252892326478104e-08
Local loss @ local epoch 3: 0.00044954995973967016
Local loss @ local epoch 4: 1.4715101718902588
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.64 seconds!
[tester] 
AGNewsMetric: acc=0.780921052631579, hinge=4.727801972188447, ce=9.489170861495168
Local test acc @ epoch 188: 0.7809
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 3.616210597101599e-05
Local loss @ local epoch 1: 1.4076696634292603
Local loss @ local epoch 2: 4.947001343680313e-06
Local loss @ local epoch 3: 0.08034820854663849
Local loss @ local epoch 4: 0.00013350954395718873
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.51 seconds!
[tester] 
AGNewsMetric: acc=0.7560526315789474, hinge=5.054202535026952, ce=9.96961341054816
Local test acc @ epoch 188: 0.7561
Global evaluate on test data...
Evaluate data in 129.84 seconds!
[tester] 
AGNewsMetric: acc=0.8423684210526315, hinge=3.525652574990925, ce=7.7442599929006475
Global test acc @ epoch 188: 0.8424
Global epoch 189...
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 2.9802318834981634e-08
Local loss @ local epoch 1: 2.3841840857130592e-07
Local loss @ local epoch 2: 5.960463766996327e-08
Local loss @ local epoch 3: 1.2895678082713857e-05
Local loss @ local epoch 4: 0.0015140988398343325
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.98 seconds!
[tester] 
AGNewsMetric: acc=0.8118421052631579, hinge=4.2749545541562535, ce=8.318574529948988
Local test acc @ epoch 189: 0.8118
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 2.9802318834981634e-08
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.399056938884314e-06
Local loss @ local epoch 4: 2.2351740014414645e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.89 seconds!
[tester] 
AGNewsMetric: acc=0.7957894736842105, hinge=4.712959407756203, ce=8.55080219268799
Local test acc @ epoch 189: 0.7958
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 2.9802318834981634e-08
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 4.470347647611561e-08
Local loss @ local epoch 3: 2.2351738238057806e-08
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.77 seconds!
[tester] 
AGNewsMetric: acc=0.8438157894736842, hinge=3.4510616028936285, ce=7.5855284329464565
Local test acc @ epoch 189: 0.8438
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 4.3213302092226513e-07
Local loss @ local epoch 1: 3.725289587919178e-08
Local loss @ local epoch 2: 8.940683073888067e-07
Local loss @ local epoch 3: 1.666539192199707
Local loss @ local epoch 4: 1.341104365337742e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.78 seconds!
[tester] 
AGNewsMetric: acc=0.8353947368421053, hinge=3.4044483784625403, ce=8.268053486472683
Local test acc @ epoch 189: 0.8354
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 5.930457973590819e-06
Local loss @ local epoch 1: 1.6242200899796444e-06
Local loss @ local epoch 2: 3.7326863093767315e-06
Local loss @ local epoch 3: 2.9355123842833564e-06
Local loss @ local epoch 4: 1.7955812836589757e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.49 seconds!
[tester] 
AGNewsMetric: acc=0.8406578947368422, hinge=2.685004903642755, ce=7.754604728096409
Local test acc @ epoch 189: 0.8407
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 4.842860903409019e-07
Local loss @ local epoch 1: 3.427261674460169e-07
Local loss @ local epoch 2: 0.0407666452229023
Local loss @ local epoch 3: 3.352756721142214e-07
Local loss @ local epoch 4: 1.6167665535249398e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.71 seconds!
[tester] 
AGNewsMetric: acc=0.7861842105263158, hinge=4.123688126363253, ce=9.170805146066765
Local test acc @ epoch 189: 0.7862
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 3.725289943190546e-08
Local loss @ local epoch 1: 5.215405707303944e-08
Local loss @ local epoch 2: 2.2351740014414645e-08
Local loss @ local epoch 3: 2.2351740014414645e-08
Local loss @ local epoch 4: 3.948795779251668e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.39 seconds!
[tester] 
AGNewsMetric: acc=0.8180263157894737, hinge=3.94212714069768, ce=8.212426095259817
Local test acc @ epoch 189: 0.818
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901159417490817e-08
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 2.9802320611338473e-08
Local loss @ local epoch 3: 3.725289587919178e-08
Local loss @ local epoch 4: 2.9802320611338473e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.24 seconds!
[tester] 
AGNewsMetric: acc=0.8421052631578947, hinge=3.4592180354971633, ce=7.77506739867361
Local test acc @ epoch 189: 0.8421
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.9802318834981634e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.16066538882842e-07
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.31 seconds!
[tester] 
AGNewsMetric: acc=0.8386842105263158, hinge=3.555863935320001, ce=7.744092614023309
Local test acc @ epoch 189: 0.8387
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 1.117586450050112e-07
Local loss @ local epoch 3: 2.2351740014414645e-08
Local loss @ local epoch 4: 9.685751933830034e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.6 seconds!
[tester] 
AGNewsMetric: acc=0.8472368421052632, hinge=3.328134712420012, ce=7.880245153527511
Local test acc @ epoch 189: 0.8472
Global evaluate on test data...
Evaluate data in 129.44 seconds!
[tester] 
AGNewsMetric: acc=0.8419736842105263, hinge=3.5135080867064628, ce=7.82703902395148
Global test acc @ epoch 189: 0.842
Global epoch 190...
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 2.2351740014414645e-08
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 4.209436610835837e-06
Local loss @ local epoch 4: 2.2351740014414645e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.36 seconds!
[tester] 
AGNewsMetric: acc=0.85, hinge=3.1817980003356934, ce=7.645153326737253
Local test acc @ epoch 190: 0.85
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 2.9802318834981634e-08
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 1.0058204225060763e-06
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.97 seconds!
[tester] 
AGNewsMetric: acc=0.833421052631579, hinge=3.3778067237452456, ce=7.718230247497559
Local test acc @ epoch 190: 0.8334
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 1.8626434439283912e-07
Local loss @ local epoch 1: 1.043080928297968e-07
Local loss @ local epoch 2: 4.470347647611561e-08
Local loss @ local epoch 3: 8.940693874137651e-08
Local loss @ local epoch 4: 1.266597848825768e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.42 seconds!
[tester] 
AGNewsMetric: acc=0.7631578947368421, hinge=5.212916540597615, ce=9.826075692427786
Local test acc @ epoch 190: 0.7632
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450579175838357e-08
Local loss @ local epoch 1: 5.215392206991964e-07
Local loss @ local epoch 2: 1.8626434439283912e-07
Local loss @ local epoch 3: 5.587925784311665e-07
Local loss @ local epoch 4: 2.8332161903381348
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.3 seconds!
[tester] 
AGNewsMetric: acc=0.7828947368421053, hinge=4.648656474916558, ce=8.817983183609812
Local test acc @ epoch 190: 0.7829
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0005559621495194733
Local loss @ local epoch 1: 0.00013572321040555835
Local loss @ local epoch 2: 0.3318786919116974
Local loss @ local epoch 3: 0.42305895686149597
Local loss @ local epoch 4: 0.0001006724196486175
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.7 seconds!
[tester] 
AGNewsMetric: acc=0.7439473684210526, hinge=5.257592756371749, ce=8.581241643805253
Local test acc @ epoch 190: 0.7439
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 2.7567091365199303e-07
Local loss @ local epoch 1: 1.2367877388896886e-06
Local loss @ local epoch 2: 1.4304981732493616e-06
Local loss @ local epoch 3: 4.827854809263954e-06
Local loss @ local epoch 4: 1.4454039956035558e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.58 seconds!
[tester] 
AGNewsMetric: acc=0.8203947368421053, hinge=3.6300773497631673, ce=8.541435291892604
Local test acc @ epoch 190: 0.8204
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.2665981330428622e-07
Local loss @ local epoch 1: 4.470347647611561e-08
Local loss @ local epoch 2: 1.7136326846411976e-07
Local loss @ local epoch 3: 7.450579175838357e-08
Local loss @ local epoch 4: 9.685751933830034e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.26 seconds!
[tester] 
AGNewsMetric: acc=0.8356578947368422, hinge=3.481609662457516, ce=7.9481550507796435
Local test acc @ epoch 190: 0.8357
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 2.9802320611338473e-08
Local loss @ local epoch 1: 2.2351740014414645e-08
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 4.470347292340193e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.11 seconds!
[tester] 
AGNewsMetric: acc=0.8271052631578948, hinge=3.945478931979129, ce=8.09518970489502
Local test acc @ epoch 190: 0.8271
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 2.2351740014414645e-08
Local loss @ local epoch 2: 1.3411033705779118e-07
Local loss @ local epoch 3: 7.450579175838357e-08
Local loss @ local epoch 4: 1.862643159711297e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.47 seconds!
[tester] 
AGNewsMetric: acc=0.8460526315789474, hinge=3.412682880853352, ce=7.827198140997636
Local test acc @ epoch 190: 0.8461
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0018003308214247227
Local loss @ local epoch 4: 1.1920923270736239e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.01 seconds!
[tester] 
AGNewsMetric: acc=0.8043421052631579, hinge=4.000810789810984, ce=8.461175231933593
Local test acc @ epoch 190: 0.8043
Global evaluate on test data...
Evaluate data in 129.37 seconds!
[tester] 
AGNewsMetric: acc=0.8439473684210527, hinge=3.499639184098495, ce=7.815147193105597
Global test acc @ epoch 190: 0.8439
Global epoch 191...
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 1.4901159417490817e-08
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 2.7567102733883075e-07
Local loss @ local epoch 4: 2.9802318834981634e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.43 seconds!
[tester] 
AGNewsMetric: acc=0.828421052631579, hinge=3.819168555360091, ce=7.909507513548198
Local test acc @ epoch 191: 0.8284
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.235171905340394e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.75 seconds!
[tester] 
AGNewsMetric: acc=0.8444736842105263, hinge=3.3824212199763246, ce=7.969382638429341
Local test acc @ epoch 191: 0.8445
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 2.8312177846601116e-07
Local loss @ local epoch 1: 2.3841815277592104e-07
Local loss @ local epoch 2: 2.39159089687746e-06
Local loss @ local epoch 3: 2.980230249249871e-07
Local loss @ local epoch 4: 3.65078278719011e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.56 seconds!
[tester] 
AGNewsMetric: acc=0.715, hinge=5.905573191893728, ce=10.018770836278012
Local test acc @ epoch 191: 0.715
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 2.2351738238057806e-08
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 1.4901159417490817e-08
Local loss @ local epoch 4: 2.2351740014414645e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.36 seconds!
[tester] 
AGNewsMetric: acc=0.8442105263157895, hinge=3.4163802668922827, ce=7.768515099977192
Local test acc @ epoch 191: 0.8442
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 6.705521116145974e-08
Local loss @ local epoch 1: 9.685750512744562e-08
Local loss @ local epoch 2: 1.7881369274164172e-07
Local loss @ local epoch 3: 1.6167556395885185e-06
Local loss @ local epoch 4: 4.470347647611561e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.67 seconds!
[tester] 
AGNewsMetric: acc=0.8492105263157895, hinge=3.329597126810174, ce=7.411639845998663
Local test acc @ epoch 191: 0.8492
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 6.101729923102539e-06
Local loss @ local epoch 1: 9.462210073252209e-07
Local loss @ local epoch 2: 0.03821749612689018
Local loss @ local epoch 3: 1.3783535450784257e-06
Local loss @ local epoch 4: 0.0009207484545186162
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.19 seconds!
[tester] 
AGNewsMetric: acc=0.8475, hinge=2.743509011268616, ce=7.541790116962634
Local test acc @ epoch 191: 0.8475
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 2.9802320611338473e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.29 seconds!
[tester] 
AGNewsMetric: acc=0.8438157894736842, hinge=3.490644446674146, ce=7.788345541703074
Local test acc @ epoch 191: 0.8438
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450577754752885e-08
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.0352446474134922
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.7 seconds!
[tester] 
AGNewsMetric: acc=0.8446052631578947, hinge=3.344539048044305, ce=7.851109572962711
Local test acc @ epoch 191: 0.8446
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 2.2351740014414645e-08
Local loss @ local epoch 1: 8.940690321423972e-08
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 1.4156097449813387e-07
Local loss @ local epoch 4: 4.470347292340193e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.99 seconds!
[tester] 
AGNewsMetric: acc=0.8355263157894737, hinge=3.4932667492565357, ce=8.129119987487792
Local test acc @ epoch 191: 0.8355
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 7.823084615665721e-07
Local loss @ local epoch 1: 7.450579175838357e-08
Local loss @ local epoch 2: 0.010188151150941849
Local loss @ local epoch 3: 1.862644296579674e-07
Local loss @ local epoch 4: 3.4272648008482065e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.88 seconds!
[tester] 
AGNewsMetric: acc=0.8307894736842105, hinge=3.425065279759859, ce=7.8961438028435955
Local test acc @ epoch 191: 0.8308
Global evaluate on test data...
Evaluate data in 129.57 seconds!
[tester] 
AGNewsMetric: acc=0.8425, hinge=3.510408919234025, ce=7.777151622772217
Global test acc @ epoch 191: 0.8425
Global epoch 192...
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 2.2351740014414645e-08
Local loss @ local epoch 1: 8.940692453052179e-08
Local loss @ local epoch 2: 4.470347647611561e-08
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.03 seconds!
[tester] 
AGNewsMetric: acc=0.8378947368421052, hinge=3.493744841876783, ce=7.861746603313246
Local test acc @ epoch 192: 0.8379
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 1.3783442227577325e-06
Local loss @ local epoch 1: 1.5646214990283625e-07
Local loss @ local epoch 2: 1.0132754368896713e-06
Local loss @ local epoch 3: 6.929031428626331e-07
Local loss @ local epoch 4: 2.413964921288425e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.72 seconds!
[tester] 
AGNewsMetric: acc=0.8227631578947369, hinge=3.4250617032302055, ce=7.511158144097579
Local test acc @ epoch 192: 0.8228
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 1.2665982751514093e-07
Local loss @ local epoch 1: 0.0001051138824550435
Local loss @ local epoch 2: 9.685753354915505e-08
Local loss @ local epoch 3: 0.5303515195846558
Local loss @ local epoch 4: 5.885950713491184e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.53 seconds!
[tester] 
AGNewsMetric: acc=0.7848684210526315, hinge=4.543078915947362, ce=8.861835140429045
Local test acc @ epoch 192: 0.7849
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 5.215405707303944e-08
Local loss @ local epoch 1: 2.7567094207370246e-07
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 2.060490987787489e-05
Local loss @ local epoch 4: 4.4703469370688254e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.1 seconds!
[tester] 
AGNewsMetric: acc=0.7555263157894737, hinge=5.141151324824283, ce=9.187746182491905
Local test acc @ epoch 192: 0.7555
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 2.2351740014414645e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 4.470347647611561e-08
Local loss @ local epoch 3: 2.9802320611338473e-08
Local loss @ local epoch 4: 4.4703469370688254e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.23 seconds!
[tester] 
AGNewsMetric: acc=0.8357894736842105, hinge=3.7260234682183517, ce=8.025930283195095
Local test acc @ epoch 192: 0.8358
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 5.215405707303944e-08
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 2.2351740014414645e-08
Local loss @ local epoch 3: 5.960463411724959e-08
Local loss @ local epoch 4: 8.195635103902532e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.74 seconds!
[tester] 
AGNewsMetric: acc=0.7953947368421053, hinge=4.456364725263495, ce=8.771901502107319
Local test acc @ epoch 192: 0.7954
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 3.725289587919178e-08
Local loss @ local epoch 1: 2.2351740014414645e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.55 seconds!
[tester] 
AGNewsMetric: acc=0.841842105263158, hinge=3.4528816167931806, ce=7.797447930386192
Local test acc @ epoch 192: 0.8418
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 2.461939766362775e-05
Local loss @ local epoch 1: 1.057979829965916e-06
Local loss @ local epoch 2: 1.8402829482511152e-06
Local loss @ local epoch 3: 0.0058675785548985004
Local loss @ local epoch 4: 0.0006131753325462341
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 131.04 seconds!
[tester] 
AGNewsMetric: acc=0.7897368421052632, hinge=3.618325632747851, ce=8.342162654274388
Local test acc @ epoch 192: 0.7897
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4156088923300558e-07
Local loss @ local epoch 1: 7.450579175838357e-08
Local loss @ local epoch 2: 5.960463766996327e-08
Local loss @ local epoch 3: 5.215406062575312e-08
Local loss @ local epoch 4: 9.685752644372769e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 128.54 seconds!
[tester] 
AGNewsMetric: acc=0.8218421052631579, hinge=3.689843394881801, ce=8.53024707091482
Local test acc @ epoch 192: 0.8218
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 3.8742945207559387e-07
Local loss @ local epoch 1: 7.450579175838357e-08
Local loss @ local epoch 2: 2.011654345324132e-07
Local loss @ local epoch 3: 2.4586898916822975e-07
Local loss @ local epoch 4: 0.00041471916483715177
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.63 seconds!
[tester] 
AGNewsMetric: acc=0.7876315789473685, hinge=4.88583243545733, ce=9.194033572548314
Local test acc @ epoch 192: 0.7876
Global evaluate on test data...
Evaluate data in 129.53 seconds!
[tester] 
AGNewsMetric: acc=0.8344736842105264, hinge=3.7134697889026844, ce=8.032350406646728
Global test acc @ epoch 192: 0.8345
Global epoch 193...
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 1.549702460579283e-06
Local loss @ local epoch 1: 6.929004143785278e-07
Local loss @ local epoch 2: 4.135002200200688e-06
Local loss @ local epoch 3: 1.7955807152247871e-06
Local loss @ local epoch 4: 1.8551878611106076e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.14 seconds!
[tester] 
AGNewsMetric: acc=0.8294736842105264, hinge=2.9106574901781586, ce=7.986581989087557
Local test acc @ epoch 193: 0.8295
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 5.06637547914579e-07
Local loss @ local epoch 1: 2.235170910580564e-07
Local loss @ local epoch 2: 5.885947302886052e-07
Local loss @ local epoch 3: 1.0207273817286477e-06
Local loss @ local epoch 4: 5.84609188081231e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.12 seconds!
[tester] 
AGNewsMetric: acc=0.8076315789473684, hinge=4.053294734703867, ce=7.840860279484799
Local test acc @ epoch 193: 0.8076
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 2.2351740014414645e-08
Local loss @ local epoch 1: 1.2665975646086736e-07
Local loss @ local epoch 2: 3.725289587919178e-08
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 2.2351740014414645e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 128.97 seconds!
[tester] 
AGNewsMetric: acc=0.8353947368421053, hinge=3.645785272246913, ce=7.711211751636706
Local test acc @ epoch 193: 0.8354
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901159417490817e-08
Local loss @ local epoch 1: 4.4703469370688254e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 5.215405707303944e-08
Local loss @ local epoch 4: 2.2351740014414645e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.01 seconds!
[tester] 
AGNewsMetric: acc=0.8332894736842106, hinge=3.695873035631682, ce=8.011480624550268
Local test acc @ epoch 193: 0.8333
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901159417490817e-08
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 5.960463056453591e-08
Local loss @ local epoch 3: 2.2351740014414645e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.96 seconds!
[tester] 
AGNewsMetric: acc=0.8248684210526316, hinge=4.078567719961468, ce=7.99174088829442
Local test acc @ epoch 193: 0.8249
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 5.587918394667213e-07
Local loss @ local epoch 1: 5.215405707303944e-08
Local loss @ local epoch 2: 8.19563723553074e-08
Local loss @ local epoch 3: 4.097813075532031e-07
Local loss @ local epoch 4: 5.066386279395374e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.09 seconds!
[tester] 
AGNewsMetric: acc=0.8169736842105263, hinge=3.6135793859080265, ce=8.679835140830592
Local test acc @ epoch 193: 0.817
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 3.725289587919178e-08
Local loss @ local epoch 1: 1.3411032284693647e-07
Local loss @ local epoch 2: 3.725289943190546e-08
Local loss @ local epoch 3: 1.1565266847610474
Local loss @ local epoch 4: 1.4901159417490817e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.58 seconds!
[tester] 
AGNewsMetric: acc=0.8459210526315789, hinge=3.3127211489175497, ce=7.893878288269043
Local test acc @ epoch 193: 0.8459
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 2.9802318834981634e-08
Local loss @ local epoch 1: 1.4901159417490817e-08
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 1.117586450050112e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.9 seconds!
[tester] 
AGNewsMetric: acc=0.8372368421052632, hinge=3.6863450239834035, ce=8.009116066380551
Local test acc @ epoch 193: 0.8372
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 1.6391263102377707e-07
Local loss @ local epoch 1: 1.0430809993522416e-07
Local loss @ local epoch 2: 0.000338197685778141
Local loss @ local epoch 3: 1.9818314740405185e-06
Local loss @ local epoch 4: 1.6018661881389562e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.15 seconds!
[tester] 
AGNewsMetric: acc=0.8017105263157894, hinge=3.72635774838297, ce=8.016314044751619
Local test acc @ epoch 193: 0.8017
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.4901148404078413e-07
Local loss @ local epoch 2: 2.9802318834981634e-08
Local loss @ local epoch 3: 2.2351740014414645e-08
Local loss @ local epoch 4: 1.9371501025489124e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.55 seconds!
[tester] 
AGNewsMetric: acc=0.8181578947368421, hinge=4.017904813164159, ce=8.182589623300652
Local test acc @ epoch 193: 0.8182
Global evaluate on test data...
Evaluate data in 130.46 seconds!
[tester] 
AGNewsMetric: acc=0.8443421052631579, hinge=3.419553978819596, ce=7.670982306630988
Global test acc @ epoch 193: 0.8443
Global epoch 194...
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 3.725289943190546e-08
Local loss @ local epoch 1: 1.3187402601033682e-06
Local loss @ local epoch 2: 2.2351740014414645e-08
Local loss @ local epoch 3: 0.0046783387660980225
Local loss @ local epoch 4: 8.19563723553074e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.88 seconds!
[tester] 
AGNewsMetric: acc=0.8372368421052632, hinge=3.4569612274671857, ce=8.017021932099995
Local test acc @ epoch 194: 0.8372
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 3.3527527421028935e-07
Local loss @ local epoch 1: 1.7881377800677e-07
Local loss @ local epoch 2: 1.3411040811206476e-07
Local loss @ local epoch 3: 0.18540625274181366
Local loss @ local epoch 4: 0.06754295527935028
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.76 seconds!
[tester] 
AGNewsMetric: acc=0.8357894736842105, hinge=3.3846354527222484, ce=8.035604021172775
Local test acc @ epoch 194: 0.8358
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 2.9802251333421736e-07
Local loss @ local epoch 1: 0.5385840535163879
Local loss @ local epoch 2: 4.656516466639005e-06
Local loss @ local epoch 3: 0.0002564741880632937
Local loss @ local epoch 4: 0.15845580399036407
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.91 seconds!
[tester] 
AGNewsMetric: acc=0.8317105263157895, hinge=2.8199191700784785, ce=7.697250221653989
Local test acc @ epoch 194: 0.8317
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 5.960463766996327e-08
Local loss @ local epoch 1: 5.215406062575312e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.2351740014414645e-08
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.42 seconds!
[tester] 
AGNewsMetric: acc=0.8493421052631579, hinge=3.3172894274561027, ce=7.952411448830053
Local test acc @ epoch 194: 0.8493
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 4.470347647611561e-08
Local loss @ local epoch 1: 5.140882421983406e-07
Local loss @ local epoch 2: 0.000418081326643005
Local loss @ local epoch 3: 1.989275233427179e-06
Local loss @ local epoch 4: 1.1890649795532227
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.81 seconds!
[tester] 
AGNewsMetric: acc=0.7981578947368421, hinge=4.210983911313509, ce=7.608919613486842
Local test acc @ epoch 194: 0.7982
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.2351740014414645e-08
Local loss @ local epoch 4: 5.215404996761208e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.09 seconds!
[tester] 
AGNewsMetric: acc=0.8492105263157895, hinge=3.305146454760903, ce=7.785615741328189
Local test acc @ epoch 194: 0.8492
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 2.9802318834981634e-08
Local loss @ local epoch 1: 5.215405707303944e-08
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 2.2351738238057806e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.44 seconds!
[tester] 
AGNewsMetric: acc=0.8442105263157895, hinge=3.4004374679766203, ce=7.92329819127133
Local test acc @ epoch 194: 0.8442
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901159417490817e-08
Local loss @ local epoch 1: 1.4901159417490817e-08
Local loss @ local epoch 2: 4.470347292340193e-08
Local loss @ local epoch 3: 7.450577044210149e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.7 seconds!
[tester] 
AGNewsMetric: acc=0.8223684210526315, hinge=3.930121188916658, ce=7.832635414725856
Local test acc @ epoch 194: 0.8224
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 7.003506539149384e-07
Local loss @ local epoch 2: 1.6391271628890536e-07
Local loss @ local epoch 3: 8.940693874137651e-08
Local loss @ local epoch 4: 5.215406062575312e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.95 seconds!
[tester] 
AGNewsMetric: acc=0.8028947368421052, hinge=4.466232273955094, ce=8.929749134465268
Local test acc @ epoch 194: 0.8029
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00022553917369805276
Local loss @ local epoch 1: 4.4478551899374e-06
Local loss @ local epoch 2: 4.917379783364595e-07
Local loss @ local epoch 3: 0.3406696021556854
Local loss @ local epoch 4: 0.33199605345726013
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.51 seconds!
[tester] 
AGNewsMetric: acc=0.8409210526315789, hinge=2.760806515593278, ce=7.7495819653962785
Local test acc @ epoch 194: 0.8409
Global evaluate on test data...
Evaluate data in 130.06 seconds!
[tester] 
AGNewsMetric: acc=0.8465789473684211, hinge=3.362353918928849, ce=7.657427600057502
Global test acc @ epoch 194: 0.8466
Global epoch 195...
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 1.4901159417490817e-08
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 9.68574909165909e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.48 seconds!
[tester] 
AGNewsMetric: acc=0.8369736842105263, hinge=3.7134692237251685, ce=7.917831006301077
Local test acc @ epoch 195: 0.837
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 6.705518984517767e-08
Local loss @ local epoch 1: 2.2351738238057806e-08
Local loss @ local epoch 2: 2.2351740014414645e-08
Local loss @ local epoch 3: 1.1920917586394353e-07
Local loss @ local epoch 4: 1.6838115470818593e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.57 seconds!
[tester] 
AGNewsMetric: acc=0.8296052631578947, hinge=3.9129537798229017, ce=7.910772582606265
Local test acc @ epoch 195: 0.8296
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 3.725289943190546e-08
Local loss @ local epoch 1: 1.6912590581341647e-06
Local loss @ local epoch 2: 3.725289587919178e-08
Local loss @ local epoch 3: 0.02635885402560234
Local loss @ local epoch 4: 1.192092469182171e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.16 seconds!
[tester] 
AGNewsMetric: acc=0.7784210526315789, hinge=4.357688173996775, ce=8.560314907274748
Local test acc @ epoch 195: 0.7784
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 1.0877755585170235e-06
Local loss @ local epoch 1: 5.066381163487677e-07
Local loss @ local epoch 2: 2.056352286672336e-06
Local loss @ local epoch 3: 2.1234059204289224e-06
Local loss @ local epoch 4: 3.0547360552191094e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.89 seconds!
[tester] 
AGNewsMetric: acc=0.7621052631578947, hinge=4.440818358722486, ce=8.694710998535156
Local test acc @ epoch 195: 0.7621
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 2.2351740014414645e-08
Local loss @ local epoch 3: 1.1175860947787442e-07
Local loss @ local epoch 4: 2.9802320611338473e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.16 seconds!
[tester] 
AGNewsMetric: acc=0.8457894736842105, hinge=3.3161382951234515, ce=7.685766229127583
Local test acc @ epoch 195: 0.8458
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 1.6391268786719593e-07
Local loss @ local epoch 1: 3.725289943190546e-08
Local loss @ local epoch 2: 4.470348002882929e-08
Local loss @ local epoch 3: 2.309678279743821e-07
Local loss @ local epoch 4: 8.940695295223122e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.0 seconds!
[tester] 
AGNewsMetric: acc=0.7988157894736843, hinge=4.257239802511115, ce=8.317267241226999
Local test acc @ epoch 195: 0.7988
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 3.7252892326478104e-08
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 2.2351740014414645e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.78 seconds!
[tester] 
AGNewsMetric: acc=0.8473684210526315, hinge=3.4048842497875818, ce=7.924356146360698
Local test acc @ epoch 195: 0.8474
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.2351740014414645e-08
Local loss @ local epoch 2: 7.450579175838357e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 6.705519695060502e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.93 seconds!
[tester] 
AGNewsMetric: acc=0.8489473684210527, hinge=3.32133424608331, ce=7.7595877265930175
Local test acc @ epoch 195: 0.8489
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 2.2351740014414645e-08
Local loss @ local epoch 1: 5.960462345910855e-08
Local loss @ local epoch 2: 1.1920920428565296e-07
Local loss @ local epoch 3: 5.9604616353681195e-08
Local loss @ local epoch 4: 3.725289943190546e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.84 seconds!
[tester] 
AGNewsMetric: acc=0.844078947368421, hinge=3.4816333994112516, ce=8.06665415914435
Local test acc @ epoch 195: 0.8441
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 4.470347647611561e-08
Local loss @ local epoch 1: 5.289897444527014e-07
Local loss @ local epoch 2: 8.940694584680386e-08
Local loss @ local epoch 3: 1.4156097449813387e-07
Local loss @ local epoch 4: 9.909247182804393e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.56 seconds!
[tester] 
AGNewsMetric: acc=0.7892105263157895, hinge=4.3034906643315365, ce=8.892565588700144
Local test acc @ epoch 195: 0.7892
Global evaluate on test data...
Evaluate data in 130.21 seconds!
[tester] 
AGNewsMetric: acc=0.8411842105263158, hinge=3.535566170090123, ce=7.804601430391011
Global test acc @ epoch 195: 0.8412
Global epoch 196...
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 5.668070662068203e-05
Local loss @ local epoch 1: 1.0951873264275491e-05
Local loss @ local epoch 2: 0.00017183672753162682
Local loss @ local epoch 3: 0.9044376611709595
Local loss @ local epoch 4: 0.00013212801422923803
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.67 seconds!
[tester] 
AGNewsMetric: acc=0.7526315789473684, hinge=4.272183221264889, ce=8.455454597473144
Local test acc @ epoch 196: 0.7526
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 2.2351740014414645e-08
Local loss @ local epoch 2: 3.725289587919178e-08
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 2.9802318834981634e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.18 seconds!
[tester] 
AGNewsMetric: acc=0.8380263157894737, hinge=3.65694999468954, ce=7.865683869813618
Local test acc @ epoch 196: 0.838
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901159417490817e-08
Local loss @ local epoch 1: 2.2351740014414645e-08
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 9.685751223287298e-08
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.27 seconds!
[tester] 
AGNewsMetric: acc=0.8409210526315789, hinge=3.4380269359287463, ce=7.848535933243601
Local test acc @ epoch 196: 0.8409
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 2.9802318834981634e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.72 seconds!
[tester] 
AGNewsMetric: acc=0.8422368421052632, hinge=3.548026671409607, ce=7.833445926465486
Local test acc @ epoch 196: 0.8422
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.4392164647579193
Local loss @ local epoch 3: 5.960463766996327e-08
Local loss @ local epoch 4: 0.553088903427124
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.28 seconds!
[tester] 
AGNewsMetric: acc=0.8356578947368422, hinge=3.1952467617235687, ce=8.32988517560457
Local test acc @ epoch 196: 0.8357
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 2.2351740014414645e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 5.289890623316751e-07
Local loss @ local epoch 4: 1.0377799299021717e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.28 seconds!
[tester] 
AGNewsMetric: acc=0.8376315789473684, hinge=3.528949926024989, ce=7.7610940431293685
Local test acc @ epoch 196: 0.8376
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 9.685748381116355e-08
Local loss @ local epoch 1: 8.195635814445268e-08
Local loss @ local epoch 2: 3.5017646382584644e-07
Local loss @ local epoch 3: 1.415609887089886e-07
Local loss @ local epoch 4: 6.929012101863918e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.65 seconds!
[tester] 
AGNewsMetric: acc=0.7913157894736842, hinge=4.8149045668150245, ce=9.09054047634727
Local test acc @ epoch 196: 0.7913
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 8.940695295223122e-08
Local loss @ local epoch 1: 2.9802320611338473e-08
Local loss @ local epoch 2: 2.1606651046113257e-07
Local loss @ local epoch 3: 1.4156093186556973e-07
Local loss @ local epoch 4: 3.4048630368488375e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 131.1 seconds!
[tester] 
AGNewsMetric: acc=0.8410526315789474, hinge=3.3238849313635574, ce=7.927511193124872
Local test acc @ epoch 196: 0.8411
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.6391263102377707e-07
Local loss @ local epoch 1: 0.0005281104822643101
Local loss @ local epoch 2: 2.9802318834981634e-08
Local loss @ local epoch 3: 0.0006295462371781468
Local loss @ local epoch 4: 4.619346611889341e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.07 seconds!
[tester] 
AGNewsMetric: acc=0.8098684210526316, hinge=3.766409665032437, ce=8.456163155405145
Local test acc @ epoch 196: 0.8099
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 5.215404996761208e-08
Local loss @ local epoch 2: 5.215405707303944e-08
Local loss @ local epoch 3: 3.725289943190546e-08
Local loss @ local epoch 4: 4.470347647611561e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.2 seconds!
[tester] 
AGNewsMetric: acc=0.8401315789473685, hinge=3.4828502250972546, ce=7.628548859044125
Local test acc @ epoch 196: 0.8401
Global evaluate on test data...
Evaluate data in 129.53 seconds!
[tester] 
AGNewsMetric: acc=0.8503947368421053, hinge=3.3068429276817723, ce=7.64979012639899
Global test acc @ epoch 196: 0.8504
Global epoch 197...
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.84 seconds!
[tester] 
AGNewsMetric: acc=0.8515789473684211, hinge=3.2205639308377316, ce=7.7897411225971425
Local test acc @ epoch 197: 0.8516
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 2.9802315282267955e-08
Local loss @ local epoch 3: 2.011653492672849e-07
Local loss @ local epoch 4: 2.2351740014414645e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.56 seconds!
[tester] 
AGNewsMetric: acc=0.8481578947368421, hinge=3.2870814175354806, ce=7.749007784190931
Local test acc @ epoch 197: 0.8482
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 4.470347647611561e-08
Local loss @ local epoch 1: 5.215404996761208e-08
Local loss @ local epoch 2: 2.9802318834981634e-08
Local loss @ local epoch 3: 2.9802315282267955e-08
Local loss @ local epoch 4: 5.960463766996327e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.14 seconds!
[tester] 
AGNewsMetric: acc=0.8257894736842105, hinge=4.006731193693061, ce=8.141910805953176
Local test acc @ epoch 197: 0.8258
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 6.705521116145974e-08
Local loss @ local epoch 1: 9.685753354915505e-08
Local loss @ local epoch 2: 1.862644296579674e-07
Local loss @ local epoch 3: 1.4156096028727916e-07
Local loss @ local epoch 4: 2.309678279743821e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.7 seconds!
[tester] 
AGNewsMetric: acc=0.7405263157894737, hinge=5.69657390544289, ce=9.603605692010177
Local test acc @ epoch 197: 0.7405
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 5.215404996761208e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 1.192092469182171e-07
Local loss @ local epoch 4: 9.685750512744562e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.32 seconds!
[tester] 
AGNewsMetric: acc=0.8410526315789474, hinge=3.233758128316779, ce=6.848203790564286
Local test acc @ epoch 197: 0.8411
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 2.2351740014414645e-08
Local loss @ local epoch 3: 6.705521116145974e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.82 seconds!
[tester] 
AGNewsMetric: acc=0.8203947368421053, hinge=3.974480427691811, ce=8.15579968502647
Local test acc @ epoch 197: 0.8204
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 3.427258548072132e-07
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.756710557605402e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.94 seconds!
[tester] 
AGNewsMetric: acc=0.845657894736842, hinge=3.201937245067797, ce=7.575712460969624
Local test acc @ epoch 197: 0.8457
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 2.0861612881617475e-07
Local loss @ local epoch 1: 1.7881384906104358e-07
Local loss @ local epoch 2: 5.960463766996327e-08
Local loss @ local epoch 3: 2.0861597249677288e-07
Local loss @ local epoch 4: 0.02387269027531147
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.29 seconds!
[tester] 
AGNewsMetric: acc=0.8405263157894737, hinge=3.111894215533608, ce=7.359694102437873
Local test acc @ epoch 197: 0.8405
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 5.960463056453591e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 3.725289943190546e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.29 seconds!
[tester] 
AGNewsMetric: acc=0.8431578947368421, hinge=3.448808987015172, ce=7.452894877383583
Local test acc @ epoch 197: 0.8432
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 2.2351740014414645e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.6590251107118092e-05
Local loss @ local epoch 3: 2.607699798318208e-07
Local loss @ local epoch 4: 0.7839968204498291
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.07 seconds!
[tester] 
AGNewsMetric: acc=0.8193421052631579, hinge=3.4912245747917576, ce=7.954656940259431
Local test acc @ epoch 197: 0.8193
Global evaluate on test data...
Evaluate data in 129.7 seconds!
[tester] 
AGNewsMetric: acc=0.8413157894736842, hinge=3.5026170607617026, ce=7.616770239378277
Global test acc @ epoch 197: 0.8413
Global epoch 198...
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450578465295621e-08
Local loss @ local epoch 2: 2.2351740014414645e-08
Local loss @ local epoch 3: 1.8626427333856554e-07
Local loss @ local epoch 4: 8.195634393359796e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.2 seconds!
[tester] 
AGNewsMetric: acc=0.8361842105263158, hinge=3.6379158227067245, ce=7.900110174480237
Local test acc @ epoch 198: 0.8362
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 8.19563723553074e-08
Local loss @ local epoch 1: 1.4901159417490817e-08
Local loss @ local epoch 2: 4.470347647611561e-08
Local loss @ local epoch 3: 2.2351740014414645e-08
Local loss @ local epoch 4: 7.450579175838357e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.51 seconds!
[tester] 
AGNewsMetric: acc=0.8280263157894737, hinge=3.7273331107591328, ce=8.024344338868794
Local test acc @ epoch 198: 0.828
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 5.960462345910855e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.4901159417490817e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.01 seconds!
[tester] 
AGNewsMetric: acc=0.8242105263157895, hinge=3.8973849959122506, ce=7.971964049088328
Local test acc @ epoch 198: 0.8242
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.04 seconds!
[tester] 
AGNewsMetric: acc=0.8351315789473684, hinge=3.6165767393614114, ce=7.672990693544087
Local test acc @ epoch 198: 0.8351
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 1.0430805019723266e-07
Local loss @ local epoch 1: 3.759180981433019e-05
Local loss @ local epoch 2: 1.2665984172599565e-07
Local loss @ local epoch 3: 1.1920917586394353e-07
Local loss @ local epoch 4: 6.0424186813179404e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.4 seconds!
[tester] 
AGNewsMetric: acc=0.7953947368421053, hinge=4.279973642951564, ce=8.079917905707108
Local test acc @ epoch 198: 0.7954
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 1.266597848825768e-07
Local loss @ local epoch 1: 1.2665985593685036e-07
Local loss @ local epoch 2: 1.7136318319899146e-07
Local loss @ local epoch 3: 6.481996024376713e-07
Local loss @ local epoch 4: 5.0512935558799654e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.24 seconds!
[tester] 
AGNewsMetric: acc=0.8313157894736842, hinge=3.763083008214047, ce=7.752610733634548
Local test acc @ epoch 198: 0.8313
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 2.6076980930156424e-07
Local loss @ local epoch 1: 1.4901152667334827e-07
Local loss @ local epoch 2: 2.980229396598588e-07
Local loss @ local epoch 3: 1.749160401232075e-05
Local loss @ local epoch 4: 5.066386279395374e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.64 seconds!
[tester] 
AGNewsMetric: acc=0.838421052631579, hinge=3.191943071014003, ce=7.979490075362356
Local test acc @ epoch 198: 0.8384
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 2.2351740014414645e-08
Local loss @ local epoch 2: 3.725289587919178e-08
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 2.9802315282267955e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.32 seconds!
[tester] 
AGNewsMetric: acc=0.8338157894736842, hinge=3.6665936748605024, ce=7.827165550432707
Local test acc @ epoch 198: 0.8338
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 4.470347647611561e-08
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.58 seconds!
[tester] 
AGNewsMetric: acc=0.8381578947368421, hinge=3.5659779566212704, ce=7.691958864111649
Local test acc @ epoch 198: 0.8382
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 3.725289943190546e-08
Local loss @ local epoch 1: 2.2351740014414645e-08
Local loss @ local epoch 2: 2.9802318834981634e-08
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 4.4703469370688254e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.43 seconds!
[tester] 
AGNewsMetric: acc=0.8319736842105263, hinge=3.742009243212248, ce=8.124444319072522
Local test acc @ epoch 198: 0.832
Global evaluate on test data...
Evaluate data in 130.15 seconds!
[tester] 
AGNewsMetric: acc=0.8392105263157895, hinge=3.577915305087441, ce=7.692749784369218
Global test acc @ epoch 198: 0.8392
Global epoch 199...
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 2.0116550558668678e-07
Local loss @ local epoch 1: 5.215405707303944e-08
Local loss @ local epoch 2: 1.266597848825768e-07
Local loss @ local epoch 3: 1.3187400327296928e-06
Local loss @ local epoch 4: 5.960463766996327e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.48 seconds!
[tester] 
AGNewsMetric: acc=0.7525, hinge=5.3558858547712624, ce=9.513206375523618
Local test acc @ epoch 199: 0.7525
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 2.2351738238057806e-08
Local loss @ local epoch 2: 1.0430806440808738e-07
Local loss @ local epoch 3: 1.564620220051438e-07
Local loss @ local epoch 4: 2.9802318834981634e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.39 seconds!
[tester] 
AGNewsMetric: acc=0.8443421052631579, hinge=3.378113143193094, ce=7.635000016061883
Local test acc @ epoch 199: 0.8443
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 2.4586873337284487e-07
Local loss @ local epoch 1: 2.2351740014414645e-08
Local loss @ local epoch 2: 4.9415320972912014e-05
Local loss @ local epoch 3: 2.8312177846601116e-07
Local loss @ local epoch 4: 0.00028838845901191235
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.09 seconds!
[tester] 
AGNewsMetric: acc=0.8147368421052632, hinge=4.028365637377688, ce=8.531803253575376
Local test acc @ epoch 199: 0.8147
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 4.4703349999508646e-07
Local loss @ local epoch 1: 0.006186778657138348
Local loss @ local epoch 2: 9.349839274364058e-06
Local loss @ local epoch 3: 0.16817310452461243
Local loss @ local epoch 4: 2.123395006492501e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.64 seconds!
[tester] 
AGNewsMetric: acc=0.8407894736842105, hinge=2.985295900796589, ce=8.398862071790193
Local test acc @ epoch 199: 0.8408
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 2.9802320611338473e-08
Local loss @ local epoch 2: 1.4901159417490817e-08
Local loss @ local epoch 3: 2.2351740014414645e-08
Local loss @ local epoch 4: 3.725289587919178e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.14 seconds!
[tester] 
AGNewsMetric: acc=0.8427631578947369, hinge=3.5503614674116437, ce=7.636736097837749
Local test acc @ epoch 199: 0.8428
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 2.2351740014414645e-08
Local loss @ local epoch 4: 1.1920923981278975e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.88 seconds!
[tester] 
AGNewsMetric: acc=0.833421052631579, hinge=3.661049276904056, ce=7.926251094215795
Local test acc @ epoch 199: 0.8334
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.9802315282267955e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.77 seconds!
[tester] 
AGNewsMetric: acc=0.8422368421052632, hinge=3.512840495109558, ce=7.659321076242548
Local test acc @ epoch 199: 0.8422
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 2.2351740014414645e-08
Local loss @ local epoch 3: 2.2351740014414645e-08
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.56 seconds!
[tester] 
AGNewsMetric: acc=0.8317105263157895, hinge=3.798131100253055, ce=7.811108209710373
Local test acc @ epoch 199: 0.8317
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 5.215405707303944e-08
Local loss @ local epoch 1: 5.215404996761208e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.9802318834981634e-08
Local loss @ local epoch 4: 3.725289943190546e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.75 seconds!
[tester] 
AGNewsMetric: acc=0.8414473684210526, hinge=3.447259821640818, ce=7.720511251750746
Local test acc @ epoch 199: 0.8414
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 3.501763501390087e-07
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 2.1606658151540614e-07
Local loss @ local epoch 4: 6.653022410318954e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.5 seconds!
[tester] 
AGNewsMetric: acc=0.8413157894736842, hinge=3.4199180294338025, ce=7.625744233382376
Local test acc @ epoch 199: 0.8413
Global evaluate on test data...
Evaluate data in 130.15 seconds!
[tester] 
AGNewsMetric: acc=0.8431578947368421, hinge=3.528384316845944, ce=7.701620833748265
Global test acc @ epoch 199: 0.8432
Global epoch 200...
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 3.5762730021815514e-07
Local loss @ local epoch 1: 5.9604641222676946e-08
Local loss @ local epoch 2: 3.2037473829404917e-07
Local loss @ local epoch 3: 7.823077794455457e-07
Local loss @ local epoch 4: 4.321333619827783e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.55 seconds!
[tester] 
AGNewsMetric: acc=0.8397368421052631, hinge=3.0131588657278763, ce=7.335018309543007
Local test acc @ epoch 200: 0.8397
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 5.215404996761208e-08
Local loss @ local epoch 1: 2.0861597249677288e-07
Local loss @ local epoch 2: 5.960463056453591e-08
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 2.9802318834981634e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.56 seconds!
[tester] 
AGNewsMetric: acc=0.8344736842105264, hinge=3.6525133700119823, ce=8.241513461062782
Local test acc @ epoch 200: 0.8345
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 2.9802318834981634e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.2351740014414645e-08
Local loss @ local epoch 3: 2.2351740014414645e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.37 seconds!
[tester] 
AGNewsMetric: acc=0.8447368421052631, hinge=3.4810613707492224, ce=7.695793115716231
Local test acc @ epoch 200: 0.8447
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.1920919007479824e-07
Local loss @ local epoch 2: 9.83469021775818e-07
Local loss @ local epoch 3: 7.450578465295621e-08
Local loss @ local epoch 4: 7.301526920855395e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.66 seconds!
[tester] 
AGNewsMetric: acc=0.7617105263157895, hinge=5.659970453161942, ce=9.003866071199116
Local test acc @ epoch 200: 0.7617
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.8626437281454855e-07
Local loss @ local epoch 2: 2.9802318834981634e-08
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.14 seconds!
[tester] 
AGNewsMetric: acc=0.7469736842105263, hinge=6.2840501534311395, ce=9.587909088134765
Local test acc @ epoch 200: 0.747
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450578465295621e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 4.470347647611561e-08
Local loss @ local epoch 3: 4.470348002882929e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.73 seconds!
[tester] 
AGNewsMetric: acc=0.8430263157894737, hinge=3.5837466957694604, ce=7.815155465979325
Local test acc @ epoch 200: 0.843
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 2.2351740014414645e-08
Local loss @ local epoch 1: 5.215405707303944e-08
Local loss @ local epoch 2: 2.9802318834981634e-08
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.16 seconds!
[tester] 
AGNewsMetric: acc=0.8196052631578947, hinge=4.029727167832224, ce=8.181184401261179
Local test acc @ epoch 200: 0.8196
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 5.2154042862184724e-08
Local loss @ local epoch 1: 7.450577044210149e-08
Local loss @ local epoch 2: 2.9802315282267955e-08
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 5.215405707303944e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.86 seconds!
[tester] 
AGNewsMetric: acc=0.8486842105263158, hinge=3.235346389569734, ce=7.7432525032445
Local test acc @ epoch 200: 0.8487
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 9.685751223287298e-08
Local loss @ local epoch 1: 5.215405707303944e-08
Local loss @ local epoch 2: 0.509414553642273
Local loss @ local epoch 3: 5.079419497633353e-05
Local loss @ local epoch 4: 0.004756642505526543
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.46 seconds!
[tester] 
AGNewsMetric: acc=0.7635526315789474, hinge=3.850830175751134, ce=9.814543009306256
Local test acc @ epoch 200: 0.7636
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 3.7252892326478104e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.9802315282267955e-08
Local loss @ local epoch 3: 0.421568900346756
Local loss @ local epoch 4: 2.9802318834981634e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.16 seconds!
[tester] 
AGNewsMetric: acc=0.8501315789473685, hinge=3.1423939376128347, ce=7.649861869812011
Local test acc @ epoch 200: 0.8501
Global evaluate on test data...
Evaluate data in 130.87 seconds!
[tester] 
AGNewsMetric: acc=0.8455263157894737, hinge=3.4539928215428404, ce=7.75094464051096
Global test acc @ epoch 200: 0.8455
Global epoch 201...
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 6.70552182668871e-08
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 5.215405707303944e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.47 seconds!
[tester] 
AGNewsMetric: acc=0.8397368421052631, hinge=3.5632215678064445, ce=7.923979515276457
Local test acc @ epoch 201: 0.8397
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 2.9802315282267955e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 3.725289943190546e-08
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 5.960462345910855e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.81 seconds!
[tester] 
AGNewsMetric: acc=0.8419736842105263, hinge=3.4958336240366887, ce=7.605851152319657
Local test acc @ epoch 201: 0.842
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 9.685751223287298e-08
Local loss @ local epoch 1: 1.2665982751514093e-07
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 3.7252892326478104e-08
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.46 seconds!
[tester] 
AGNewsMetric: acc=0.8403947368421053, hinge=3.5262170051273545, ce=7.78685649068732
Local test acc @ epoch 201: 0.8404
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 2.2351738238057806e-08
Local loss @ local epoch 1: 9.58816508500604e-06
Local loss @ local epoch 2: 3.725289943190546e-08
Local loss @ local epoch 3: 0.010671688243746758
Local loss @ local epoch 4: 2.5331501092296094e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.05 seconds!
[tester] 
AGNewsMetric: acc=0.8598684210526316, hinge=2.7762548627351458, ce=7.5757178718165346
Local test acc @ epoch 201: 0.8599
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 2.2351738238057806e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.9802315282267955e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.16 seconds!
[tester] 
AGNewsMetric: acc=0.8467105263157895, hinge=3.3827500478844894, ce=7.601387549952457
Local test acc @ epoch 201: 0.8467
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.4901159417490817e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.4 seconds!
[tester] 
AGNewsMetric: acc=0.8427631578947369, hinge=3.492313969762702, ce=7.8061941016347784
Local test acc @ epoch 201: 0.8428
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 1.9371485393548937e-07
Local loss @ local epoch 1: 6.705521116145974e-08
Local loss @ local epoch 2: 4.470347647611561e-08
Local loss @ local epoch 3: 1.7881387748275301e-07
Local loss @ local epoch 4: 8.19563723553074e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.9 seconds!
[tester] 
AGNewsMetric: acc=0.8244736842105264, hinge=3.684296569573252, ce=7.707663618388929
Local test acc @ epoch 201: 0.8245
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 2.2351738238057806e-08
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.53 seconds!
[tester] 
AGNewsMetric: acc=0.8427631578947369, hinge=3.5227894358885914, ce=7.966711358522114
Local test acc @ epoch 201: 0.8428
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 3.725289587919178e-08
Local loss @ local epoch 1: 3.725289943190546e-08
Local loss @ local epoch 2: 2.9802315282267955e-08
Local loss @ local epoch 3: 1.1755925697798375e-05
Local loss @ local epoch 4: 2.8312186373113946e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.52 seconds!
[tester] 
AGNewsMetric: acc=0.725, hinge=6.469780498805799, ce=10.111820329364978
Local test acc @ epoch 201: 0.725
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 3.7252892326478104e-08
Local loss @ local epoch 1: 1.78813678530787e-07
Local loss @ local epoch 2: 5.2154042862184724e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.7434238088753773e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.06 seconds!
[tester] 
AGNewsMetric: acc=0.8365789473684211, hinge=3.612142294080634, ce=7.738074519508763
Local test acc @ epoch 201: 0.8366
Global evaluate on test data...
Evaluate data in 130.93 seconds!
[tester] 
AGNewsMetric: acc=0.8425, hinge=3.58142100861198, ce=7.769810029080039
Global test acc @ epoch 201: 0.8425
Global epoch 202...
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.2351740014414645e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.16 seconds!
[tester] 
AGNewsMetric: acc=0.8375, hinge=3.614494093593798, ce=7.832508540906404
Local test acc @ epoch 202: 0.8375
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 8.195634393359796e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.9802315282267955e-08
Local loss @ local epoch 4: 1.1920917586394353e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.35 seconds!
[tester] 
AGNewsMetric: acc=0.8398684210526316, hinge=3.4131382455323873, ce=7.763568593075401
Local test acc @ epoch 202: 0.8399
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 2.9802315282267955e-08
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 3.725279213995236e-07
Local loss @ local epoch 4: 9.267611312679946e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.39 seconds!
[tester] 
AGNewsMetric: acc=0.8351315789473684, hinge=3.616702417323464, ce=7.922585945129395
Local test acc @ epoch 202: 0.8351
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.2351740014414645e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.79 seconds!
[tester] 
AGNewsMetric: acc=0.8421052631578947, hinge=3.5959819816288197, ce=7.716369084809956
Local test acc @ epoch 202: 0.8421
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 1.4901159417490817e-08
Local loss @ local epoch 2: 2.9802315282267955e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.4901159417490817e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.58 seconds!
[tester] 
AGNewsMetric: acc=0.8419736842105263, hinge=3.4763786893141897, ce=7.814872563010768
Local test acc @ epoch 202: 0.842
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 4.4703469370688254e-08
Local loss @ local epoch 1: 4.470347647611561e-08
Local loss @ local epoch 2: 4.470348002882929e-08
Local loss @ local epoch 3: 1.884968924059649e-06
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.01 seconds!
[tester] 
AGNewsMetric: acc=0.7506578947368421, hinge=5.546207542419434, ce=9.13309116965846
Local test acc @ epoch 202: 0.7507
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.4901159417490817e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.71 seconds!
[tester] 
AGNewsMetric: acc=0.8417105263157895, hinge=3.560025981852883, ce=7.725373552222001
Local test acc @ epoch 202: 0.8417
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 3.2037414143815113e-07
Local loss @ local epoch 1: 2.9802315282267955e-08
Local loss @ local epoch 2: 0.0044212182983756065
Local loss @ local epoch 3: 1.6093202930278494e-06
Local loss @ local epoch 4: 1.20063316822052
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.14 seconds!
[tester] 
AGNewsMetric: acc=0.5155263157894737, hinge=10.702919134340789, ce=13.575704341687654
Local test acc @ epoch 202: 0.5155
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901159417490817e-08
Local loss @ local epoch 1: 0.0018488698406144977
Local loss @ local epoch 2: 0.00013163292896933854
Local loss @ local epoch 3: 0.7228833436965942
Local loss @ local epoch 4: 4.049578637932427e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.68 seconds!
[tester] 
AGNewsMetric: acc=0.7956578947368421, hinge=4.220165241392035, ce=9.187876484519556
Local test acc @ epoch 202: 0.7957
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 5.2154042862184724e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.7567119786908734e-07
Local loss @ local epoch 4: 5.960463056453591e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.83 seconds!
[tester] 
AGNewsMetric: acc=0.7805263157894737, hinge=4.87522374655071, ce=8.848893621344315
Local test acc @ epoch 202: 0.7805
Global evaluate on test data...
Evaluate data in 130.18 seconds!
[tester] 
AGNewsMetric: acc=0.8286842105263158, hinge=3.873602420154371, ce=8.009829500097977
Global test acc @ epoch 202: 0.8287
Global epoch 203...
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.713631121447179e-07
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 8.12805683381157e-06
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.17 seconds!
[tester] 
AGNewsMetric: acc=0.7690789473684211, hinge=4.9486354471507825, ce=8.278795053582442
Local test acc @ epoch 203: 0.7691
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.9802318834981634e-08
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.68 seconds!
[tester] 
AGNewsMetric: acc=0.8421052631578947, hinge=3.5617005531411423, ce=7.793712456351832
Local test acc @ epoch 203: 0.8421
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 1.7136315477728203e-07
Local loss @ local epoch 1: 1.1622797728705336e-06
Local loss @ local epoch 2: 8.195636524988004e-08
Local loss @ local epoch 3: 3.7550448723777663e-06
Local loss @ local epoch 4: 8.71713780270511e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.71 seconds!
[tester] 
AGNewsMetric: acc=0.8205263157894737, hinge=3.298681704872533, ce=8.143424867328845
Local test acc @ epoch 203: 0.8205
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 5.215406062575312e-08
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 1.1175865921586592e-07
Local loss @ local epoch 3: 5.215404996761208e-08
Local loss @ local epoch 4: 1.7136326846411976e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.8 seconds!
[tester] 
AGNewsMetric: acc=0.8406578947368422, hinge=3.562320717510424, ce=7.729050646330181
Local test acc @ epoch 203: 0.8407
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 5.960463056453591e-08
Local loss @ local epoch 2: 2.9802318834981634e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.01 seconds!
[tester] 
AGNewsMetric: acc=0.8448684210526316, hinge=3.4536377342123736, ce=7.765097821888171
Local test acc @ epoch 203: 0.8449
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 8.195635103902532e-08
Local loss @ local epoch 1: 1.5348025499406504e-06
Local loss @ local epoch 2: 2.6822073095900123e-07
Local loss @ local epoch 3: 4.768365897689364e-07
Local loss @ local epoch 4: 1.1399357617847272e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.39 seconds!
[tester] 
AGNewsMetric: acc=0.814078947368421, hinge=3.7951701191851965, ce=8.642111709996273
Local test acc @ epoch 203: 0.8141
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.9802318834981634e-08
Local loss @ local epoch 3: 8.195636524988004e-08
Local loss @ local epoch 4: 7.450577754752885e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.95 seconds!
[tester] 
AGNewsMetric: acc=0.8293421052631579, hinge=3.8276671643006175, ce=7.96621783808658
Local test acc @ epoch 203: 0.8293
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 2.9802318834981634e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 4.470347647611561e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.51 seconds!
[tester] 
AGNewsMetric: acc=0.8453947368421053, hinge=3.5044068423070405, ce=7.754366831528513
Local test acc @ epoch 203: 0.8454
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.2351740014414645e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.76 seconds!
[tester] 
AGNewsMetric: acc=0.8371052631578947, hinge=3.6122264937350623, ce=7.789878051155492
Local test acc @ epoch 203: 0.8371
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 4.7683550974397804e-07
Local loss @ local epoch 1: 2.2351707684720168e-07
Local loss @ local epoch 2: 0.0014920650282874703
Local loss @ local epoch 3: 5.215405707303944e-08
Local loss @ local epoch 4: 1.4065859431866556e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.83 seconds!
[tester] 
AGNewsMetric: acc=0.8014473684210527, hinge=3.879742288087544, ce=8.553325881958008
Local test acc @ epoch 203: 0.8014
Global evaluate on test data...
Evaluate data in 130.33 seconds!
[tester] 
AGNewsMetric: acc=0.8435526315789473, hinge=3.4863896540591592, ce=7.6892554303219445
Global test acc @ epoch 203: 0.8436
Global epoch 204...
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.43 seconds!
[tester] 
AGNewsMetric: acc=0.8414473684210526, hinge=3.4750919736059087, ce=7.793582465523167
Local test acc @ epoch 204: 0.8414
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 5.9604616353681195e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.1920919007479824e-07
Local loss @ local epoch 4: 1.1175867342672063e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.66 seconds!
[tester] 
AGNewsMetric: acc=0.7576315789473684, hinge=5.870004198676662, ce=10.011765080502158
Local test acc @ epoch 204: 0.7576
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 8.195635814445268e-08
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.564620220051438e-07
Local loss @ local epoch 4: 2.2351740014414645e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.05 seconds!
[tester] 
AGNewsMetric: acc=0.8257894736842105, hinge=3.8465114134236384, ce=7.468980317366751
Local test acc @ epoch 204: 0.8258
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 2.9802315282267955e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.82 seconds!
[tester] 
AGNewsMetric: acc=0.8386842105263158, hinge=3.581351886297527, ce=7.8923341821369375
Local test acc @ epoch 204: 0.8387
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 8.493607879245246e-07
Local loss @ local epoch 1: 8.419131063419627e-07
Local loss @ local epoch 2: 2.16066737834808e-07
Local loss @ local epoch 3: 1.2642670299101155e-05
Local loss @ local epoch 4: 4.215615626890212e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.08 seconds!
[tester] 
AGNewsMetric: acc=0.8201315789473684, hinge=3.708289128855655, ce=7.5825513709218875
Local test acc @ epoch 204: 0.8201
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.2351738238057806e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.05 seconds!
[tester] 
AGNewsMetric: acc=0.8415789473684211, hinge=3.4959826333899247, ce=7.723552911658036
Local test acc @ epoch 204: 0.8416
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 2.980225701776362e-07
Local loss @ local epoch 2: 2.2351740014414645e-08
Local loss @ local epoch 3: 2.2351740014414645e-08
Local loss @ local epoch 4: 3.725289943190546e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.49 seconds!
[tester] 
AGNewsMetric: acc=0.8189473684210526, hinge=3.7420135189357557, ce=8.194156694914165
Local test acc @ epoch 204: 0.8189
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.1 seconds!
[tester] 
AGNewsMetric: acc=0.8428947368421053, hinge=3.540113322860316, ce=7.663262256823088
Local test acc @ epoch 204: 0.8429
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 5.215405707303944e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.88 seconds!
[tester] 
AGNewsMetric: acc=0.8473684210526315, hinge=3.2894450295598885, ce=7.555772699054919
Local test acc @ epoch 204: 0.8474
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 2.2351738238057806e-08
Local loss @ local epoch 1: 8.940691031966708e-08
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 6.705521116145974e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.11 seconds!
[tester] 
AGNewsMetric: acc=0.828421052631579, hinge=3.8478882962778993, ce=8.040485301770662
Local test acc @ epoch 204: 0.8284
Global evaluate on test data...
Evaluate data in 130.74 seconds!
[tester] 
AGNewsMetric: acc=0.8431578947368421, hinge=3.4729762684671504, ce=7.612743973982962
Global test acc @ epoch 204: 0.8432
Global epoch 205...
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 2.9802315282267955e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 131.03 seconds!
[tester] 
AGNewsMetric: acc=0.8446052631578947, hinge=3.420295319306223, ce=7.633491982911762
Local test acc @ epoch 205: 0.8446
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0008313552243635058
Local loss @ local epoch 1: 0.04799287021160126
Local loss @ local epoch 2: 7.450577754752885e-08
Local loss @ local epoch 3: 2.6449072265677387e-06
Local loss @ local epoch 4: 2.6076772883243393e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.27 seconds!
[tester] 
AGNewsMetric: acc=0.8251315789473684, hinge=3.216460734166597, ce=7.993708702890497
Local test acc @ epoch 205: 0.8251
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901159417490817e-08
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 8.195632972274325e-08
Local loss @ local epoch 4: 6.705521116145974e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.4 seconds!
[tester] 
AGNewsMetric: acc=0.8446052631578947, hinge=3.4296857443608735, ce=7.847827178553531
Local test acc @ epoch 205: 0.8446
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 1.6391261681292235e-07
Local loss @ local epoch 1: 2.2351740014414645e-08
Local loss @ local epoch 2: 4.477652510104235e-06
Local loss @ local epoch 3: 7.376053758889611e-07
Local loss @ local epoch 4: 1.6901627779006958
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.14 seconds!
[tester] 
AGNewsMetric: acc=0.7725, hinge=5.217709191974841, ce=8.784173535798725
Local test acc @ epoch 205: 0.7725
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.9802318834981634e-08
Local loss @ local epoch 4: 2.2351738238057806e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.87 seconds!
[tester] 
AGNewsMetric: acc=0.8428947368421053, hinge=3.569773029026232, ce=7.624544246071263
Local test acc @ epoch 205: 0.8429
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901159417490817e-08
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.31 seconds!
[tester] 
AGNewsMetric: acc=0.8403947368421053, hinge=3.537151204159385, ce=7.757536956385563
Local test acc @ epoch 205: 0.8404
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 3.9488000425080827e-07
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 1.4901159417490817e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.16 seconds!
[tester] 
AGNewsMetric: acc=0.8278947368421052, hinge=3.8858233966325457, ce=7.767933030379446
Local test acc @ epoch 205: 0.8279
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 4.4703469370688254e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.15 seconds!
[tester] 
AGNewsMetric: acc=0.8435526315789473, hinge=3.4609029318156996, ce=7.879862988120631
Local test acc @ epoch 205: 0.8436
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 2.2351740014414645e-08
Local loss @ local epoch 2: 2.9802320611338473e-08
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 8.419099231105065e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.4 seconds!
[tester] 
AGNewsMetric: acc=0.8222368421052632, hinge=4.046205882524189, ce=8.120804332933927
Local test acc @ epoch 205: 0.8222
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 1.0579742593108676e-06
Local loss @ local epoch 1: 7.450579175838357e-08
Local loss @ local epoch 2: 1.0132760053238599e-06
Local loss @ local epoch 3: 1.1697316040226724e-06
Local loss @ local epoch 4: 1.929690370161552e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.34 seconds!
[tester] 
AGNewsMetric: acc=0.8181578947368421, hinge=3.2135297499204936, ce=8.465052709077534
Local test acc @ epoch 205: 0.8182
Global evaluate on test data...
Evaluate data in 129.7 seconds!
[tester] 
AGNewsMetric: acc=0.8396052631578947, hinge=3.5724311040577135, ce=7.748663547917416
Global test acc @ epoch 205: 0.8396
Global epoch 206...
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 7.003508812886139e-07
Local loss @ local epoch 1: 0.001990892691537738
Local loss @ local epoch 2: 9.685751933830034e-08
Local loss @ local epoch 3: 0.008642058819532394
Local loss @ local epoch 4: 2.53319598186863e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.09 seconds!
[tester] 
AGNewsMetric: acc=0.8281578947368421, hinge=3.5122466697190937, ce=7.690704257362767
Local test acc @ epoch 206: 0.8282
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901159417490817e-08
Local loss @ local epoch 1: 0.005628418643027544
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.466058611869812
Local loss @ local epoch 4: 6.481987497863884e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.26 seconds!
[tester] 
AGNewsMetric: acc=0.8407894736842105, hinge=2.840926540776303, ce=8.384391156246787
Local test acc @ epoch 206: 0.8408
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 4.470348002882929e-08
Local loss @ local epoch 1: 8.940659199652146e-07
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 5.960463766996327e-08
Local loss @ local epoch 4: 5.252445589576382e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.49 seconds!
[tester] 
AGNewsMetric: acc=0.8465789473684211, hinge=3.0345075762899296, ce=7.916681594848633
Local test acc @ epoch 206: 0.8466
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 2.2351738238057806e-08
Local loss @ local epoch 4: 4.470347647611561e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.88 seconds!
[tester] 
AGNewsMetric: acc=0.8385526315789473, hinge=3.5514762587296334, ce=7.907534550114682
Local test acc @ epoch 206: 0.8386
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 9.685750512744562e-08
Local loss @ local epoch 1: 2.2351740014414645e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.09 seconds!
[tester] 
AGNewsMetric: acc=0.8286842105263158, hinge=3.792684228545741, ce=8.728106537869103
Local test acc @ epoch 206: 0.8287
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 2.9802318834981634e-08
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 2.9802318834981634e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.06 seconds!
[tester] 
AGNewsMetric: acc=0.8410526315789474, hinge=3.5032507085800173, ce=7.734251836475573
Local test acc @ epoch 206: 0.8411
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901159417490817e-08
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 7.450577044210149e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.96 seconds!
[tester] 
AGNewsMetric: acc=0.8297368421052631, hinge=3.9037343675211855, ce=7.909528093839946
Local test acc @ epoch 206: 0.8297
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 5.2154042862184724e-08
Local loss @ local epoch 1: 5.736924322263803e-07
Local loss @ local epoch 2: 0.003426371840760112
Local loss @ local epoch 3: 2.980229965032777e-07
Local loss @ local epoch 4: 0.041177328675985336
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.2 seconds!
[tester] 
AGNewsMetric: acc=0.8077631578947368, hinge=3.7725573883558576, ce=7.95770423086066
Local test acc @ epoch 206: 0.8078
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 9.685746960030883e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.3411036547950062e-07
Local loss @ local epoch 4: 4.470347647611561e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.88 seconds!
[tester] 
AGNewsMetric: acc=0.8381578947368421, hinge=3.4823106130800747, ce=8.282655871541877
Local test acc @ epoch 206: 0.8382
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 2.533192287046404e-07
Local loss @ local epoch 1: 2.9802318834981634e-08
Local loss @ local epoch 2: 0.6921806335449219
Local loss @ local epoch 3: 1.4422851563722361e-05
Local loss @ local epoch 4: 2.39160885939782e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.96 seconds!
[tester] 
AGNewsMetric: acc=0.7873684210526316, hinge=4.208111174734015, ce=8.718692920082495
Local test acc @ epoch 206: 0.7874
Global evaluate on test data...
Evaluate data in 130.93 seconds!
[tester] 
AGNewsMetric: acc=0.8467105263157895, hinge=3.3806156798412927, ce=7.728614893461528
Global test acc @ epoch 206: 0.8467
Global epoch 207...
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 2.2351740014414645e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.9802320611338473e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.41 seconds!
[tester] 
AGNewsMetric: acc=0.8469736842105263, hinge=3.3736623949753612, ce=7.808657124167994
Local test acc @ epoch 207: 0.847
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 3.725289587919178e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 2.7567102733883075e-07
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.74 seconds!
[tester] 
AGNewsMetric: acc=0.8067105263157894, hinge=4.0921679429004065, ce=8.224145762794896
Local test acc @ epoch 207: 0.8067
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 2.2351740014414645e-08
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 3.725289587919178e-08
Local loss @ local epoch 4: 1.1920917586394353e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.21 seconds!
[tester] 
AGNewsMetric: acc=0.8357894736842105, hinge=3.6980565613194516, ce=7.851552555686549
Local test acc @ epoch 207: 0.8358
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 1.0430808572436945e-07
Local loss @ local epoch 1: 9.401931492902804e-06
Local loss @ local epoch 2: 0.014942266047000885
Local loss @ local epoch 3: 4.3213313460910285e-07
Local loss @ local epoch 4: 1.445401039745775e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.29 seconds!
[tester] 
AGNewsMetric: acc=0.8365789473684211, hinge=3.0962590114693893, ce=7.614498834108051
Local test acc @ epoch 207: 0.8366
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 5.215405707303944e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 4.395830046632909e-07
Local loss @ local epoch 3: 3.725289943190546e-08
Local loss @ local epoch 4: 1.4156094607642444e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.28 seconds!
[tester] 
AGNewsMetric: acc=0.8194736842105264, hinge=4.007910533327806, ce=8.253386013633326
Local test acc @ epoch 207: 0.8195
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 2.2351740014414645e-08
Local loss @ local epoch 1: 6.705521116145974e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 1.937147970920705e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.38 seconds!
[tester] 
AGNewsMetric: acc=0.8398684210526316, hinge=3.628115654242666, ce=7.940985459779438
Local test acc @ epoch 207: 0.8399
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 5.2154042862184724e-08
Local loss @ local epoch 3: 1.1920917586394353e-07
Local loss @ local epoch 4: 2.9802320611338473e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.77 seconds!
[tester] 
AGNewsMetric: acc=0.8448684210526316, hinge=3.316365190305208, ce=8.109728928616173
Local test acc @ epoch 207: 0.8449
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 2.2351740014414645e-08
Local loss @ local epoch 2: 2.2351740014414645e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.86 seconds!
[tester] 
AGNewsMetric: acc=0.8292105263157895, hinge=3.8461663753107973, ce=7.864353790283203
Local test acc @ epoch 207: 0.8292
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450576333667414e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.0712272998935077e-06
Local loss @ local epoch 3: 5.960462345910855e-08
Local loss @ local epoch 4: 3.725289943190546e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.69 seconds!
[tester] 
AGNewsMetric: acc=0.6938157894736842, hinge=7.417436116871081, ce=10.528020559612074
Local test acc @ epoch 207: 0.6938
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 2.9802320611338473e-08
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 4.470347647611561e-08
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.56 seconds!
[tester] 
AGNewsMetric: acc=0.8480263157894737, hinge=3.2925865637628657, ce=7.840353577262477
Local test acc @ epoch 207: 0.848
Global evaluate on test data...
Evaluate data in 130.95 seconds!
[tester] 
AGNewsMetric: acc=0.8422368421052632, hinge=3.5409422530625996, ce=7.7449532579120834
Global test acc @ epoch 207: 0.8422
Global epoch 208...
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 2.9802318834981634e-08
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.12 seconds!
[tester] 
AGNewsMetric: acc=0.8347368421052631, hinge=3.7039907737782127, ce=8.137873117547286
Local test acc @ epoch 208: 0.8347
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 9.022007361636497e-06
Local loss @ local epoch 1: 1.3776564598083496
Local loss @ local epoch 2: 2.0265267721697455e-06
Local loss @ local epoch 3: 0.2754864990711212
Local loss @ local epoch 4: 1.2516893548308872e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.26 seconds!
[tester] 
AGNewsMetric: acc=0.833421052631579, hinge=3.412091948609603, ce=8.052434288827996
Local test acc @ epoch 208: 0.8334
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.2351740014414645e-08
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 3.7252892326478104e-08
Local loss @ local epoch 4: 2.9802315282267955e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.32 seconds!
[tester] 
AGNewsMetric: acc=0.8439473684210527, hinge=3.5219469760593616, ce=7.751513286389803
Local test acc @ epoch 208: 0.8439
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.65 seconds!
[tester] 
AGNewsMetric: acc=0.8392105263157895, hinge=3.5464536609147723, ce=7.80892802589818
Local test acc @ epoch 208: 0.8392
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 2.2351740014414645e-08
Local loss @ local epoch 1: 2.9802320611338473e-08
Local loss @ local epoch 2: 3.725289587919178e-08
Local loss @ local epoch 3: 9.685753354915505e-08
Local loss @ local epoch 4: 3.725289943190546e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.34 seconds!
[tester] 
AGNewsMetric: acc=0.8392105263157895, hinge=3.6293710036026803, ce=7.588603323886269
Local test acc @ epoch 208: 0.8392
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 2.2351738238057806e-08
Local loss @ local epoch 1: 5.9604616353681195e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 5.215404996761208e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.56 seconds!
[tester] 
AGNewsMetric: acc=0.845657894736842, hinge=3.4437218126497773, ce=7.853620602457147
Local test acc @ epoch 208: 0.8457
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 2.8312166477917344e-07
Local loss @ local epoch 1: 7.972073490236653e-07
Local loss @ local epoch 2: 8.344595698872581e-07
Local loss @ local epoch 3: 0.001801560982130468
Local loss @ local epoch 4: 1.937148823571988e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.51 seconds!
[tester] 
AGNewsMetric: acc=0.8125, hinge=4.165840737945155, ce=8.614115158884148
Local test acc @ epoch 208: 0.8125
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 3.725289587919178e-08
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.36 seconds!
[tester] 
AGNewsMetric: acc=0.8401315789473685, hinge=3.5055945682525635, ce=8.03059002123381
Local test acc @ epoch 208: 0.8401
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 6.705521116145974e-08
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 2.9802318834981634e-08
Local loss @ local epoch 3: 9.685748381116355e-08
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.46 seconds!
[tester] 
AGNewsMetric: acc=0.7993421052631579, hinge=4.528971343040467, ce=9.136539364864952
Local test acc @ epoch 208: 0.7993
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.2351740014414645e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.4901159417490817e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.21 seconds!
[tester] 
AGNewsMetric: acc=0.8376315789473684, hinge=3.673336387433504, ce=7.856501878437243
Local test acc @ epoch 208: 0.8376
Global evaluate on test data...
Evaluate data in 129.58 seconds!
[tester] 
AGNewsMetric: acc=0.8435526315789473, hinge=3.533246159051594, ce=7.820067899603592
Global test acc @ epoch 208: 0.8436
Global epoch 209...
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 3.725289587919178e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 3.725289587919178e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 131.19 seconds!
[tester] 
AGNewsMetric: acc=0.8367105263157895, hinge=3.663192414735493, ce=7.932992050773219
Local test acc @ epoch 209: 0.8367
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 3.7252892326478104e-08
Local loss @ local epoch 4: 6.705521116145974e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.78 seconds!
[tester] 
AGNewsMetric: acc=0.8427631578947369, hinge=3.587733746076885, ce=7.818601411518298
Local test acc @ epoch 209: 0.8428
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.76 seconds!
[tester] 
AGNewsMetric: acc=0.8447368421052631, hinge=3.4480762747714393, ce=7.874781403792531
Local test acc @ epoch 209: 0.8447
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 6.705519695060502e-08
Local loss @ local epoch 1: 5.215405707303944e-08
Local loss @ local epoch 2: 2.9802318834981634e-08
Local loss @ local epoch 3: 4.470348002882929e-08
Local loss @ local epoch 4: 8.940694584680386e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.99 seconds!
[tester] 
AGNewsMetric: acc=0.8278947368421052, hinge=3.556716130156266, ce=7.8257675953915244
Local test acc @ epoch 209: 0.8279
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 9.685748381116355e-08
Local loss @ local epoch 2: 1.4901159417490817e-08
Local loss @ local epoch 3: 2.2351740014414645e-08
Local loss @ local epoch 4: 1.1175868053214799e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.06 seconds!
[tester] 
AGNewsMetric: acc=0.8459210526315789, hinge=3.5589568816988093, ce=8.008320234198319
Local test acc @ epoch 209: 0.8459
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 3.725289943190546e-08
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.09 seconds!
[tester] 
AGNewsMetric: acc=0.8192105263157895, hinge=4.103708609279833, ce=8.29336572546708
Local test acc @ epoch 209: 0.8192
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 2.9802318834981634e-08
Local loss @ local epoch 1: 2.2351740014414645e-08
Local loss @ local epoch 2: 9.685751223287298e-08
Local loss @ local epoch 3: 1.6391268786719593e-07
Local loss @ local epoch 4: 2.577852910690126e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.64 seconds!
[tester] 
AGNewsMetric: acc=0.8273684210526315, hinge=3.622514299593474, ce=7.734933180558054
Local test acc @ epoch 209: 0.8274
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 1.2665982751514093e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.77 seconds!
[tester] 
AGNewsMetric: acc=0.8563157894736843, hinge=3.126499709330107, ce=8.075282922042044
Local test acc @ epoch 209: 0.8563
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 6.705521116145974e-08
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.9802318834981634e-08
Local loss @ local epoch 4: 1.639125599695035e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.9 seconds!
[tester] 
AGNewsMetric: acc=0.8478947368421053, hinge=3.3693079832980506, ce=8.15819259944715
Local test acc @ epoch 209: 0.8479
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 1.4901159417490817e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.9802315282267955e-08
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.71 seconds!
[tester] 
AGNewsMetric: acc=0.8457894736842105, hinge=3.4838438172089425, ce=7.709390727595279
Local test acc @ epoch 209: 0.8458
Global evaluate on test data...
Evaluate data in 129.26 seconds!
[tester] 
AGNewsMetric: acc=0.8452631578947368, hinge=3.4412446305626316, ce=7.753418257863898
Global test acc @ epoch 209: 0.8453
Global epoch 210...
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 4.470347647611561e-08
Local loss @ local epoch 2: 2.2351738238057806e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.23 seconds!
[tester] 
AGNewsMetric: acc=0.8471052631578947, hinge=3.46348876953125, ce=7.868460211502878
Local test acc @ epoch 210: 0.8471
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.87 seconds!
[tester] 
AGNewsMetric: acc=0.8472368421052632, hinge=3.4245342186877603, ce=7.893398223676179
Local test acc @ epoch 210: 0.8472
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 2.086160861836106e-07
Local loss @ local epoch 1: 3.725289943190546e-08
Local loss @ local epoch 2: 5.977036926196888e-05
Local loss @ local epoch 3: 6.332977591227973e-07
Local loss @ local epoch 4: 0.002293416764587164
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.22 seconds!
[tester] 
AGNewsMetric: acc=0.8528947368421053, hinge=3.168033003305134, ce=7.306441762823807
Local test acc @ epoch 210: 0.8529
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 2.2351738238057806e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 3.725289943190546e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.43 seconds!
[tester] 
AGNewsMetric: acc=0.8255263157894737, hinge=3.920085994820846, ce=8.24433436042384
Local test acc @ epoch 210: 0.8255
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.756709704954119e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.3 seconds!
[tester] 
AGNewsMetric: acc=0.8455263157894737, hinge=3.3827842679776645, ce=7.835748901367188
Local test acc @ epoch 210: 0.8455
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 8.195635814445268e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 0.022177493199706078
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.39 seconds!
[tester] 
AGNewsMetric: acc=0.8425, hinge=3.450085035123323, ce=7.8081418228149415
Local test acc @ epoch 210: 0.8425
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901159417490817e-08
Local loss @ local epoch 1: 2.2351740014414645e-08
Local loss @ local epoch 2: 1.169730921901646e-06
Local loss @ local epoch 3: 6.705520405603238e-08
Local loss @ local epoch 4: 3.8071509607107146e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.79 seconds!
[tester] 
AGNewsMetric: acc=0.8081578947368421, hinge=4.088895105562712, ce=7.9082710878472575
Local test acc @ epoch 210: 0.8082
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 2.9802318834981634e-08
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 1.4901159417490817e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.61 seconds!
[tester] 
AGNewsMetric: acc=0.8423684210526315, hinge=3.5579590498773674, ce=7.8012365120335625
Local test acc @ epoch 210: 0.8424
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 2.2351740014414645e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.37 seconds!
[tester] 
AGNewsMetric: acc=0.8413157894736842, hinge=3.598034240321109, ce=7.8849883521230595
Local test acc @ epoch 210: 0.8413
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.16 seconds!
[tester] 
AGNewsMetric: acc=0.8436842105263158, hinge=3.48554813937137, ce=7.860089031018709
Local test acc @ epoch 210: 0.8437
Global evaluate on test data...
Evaluate data in 130.41 seconds!
[tester] 
AGNewsMetric: acc=0.8436842105263158, hinge=3.532107313306708, ce=7.731996183897319
Global test acc @ epoch 210: 0.8437
Global epoch 211...
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4156087502215087e-07
Local loss @ local epoch 1: 1.4901159417490817e-08
Local loss @ local epoch 2: 6.705521116145974e-08
Local loss @ local epoch 3: 3.650775113328564e-07
Local loss @ local epoch 4: 2.682205035853258e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.44 seconds!
[tester] 
AGNewsMetric: acc=0.8419736842105263, hinge=3.4054595284712943, ce=7.946893629776804
Local test acc @ epoch 211: 0.842
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.4901159417490817e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.38 seconds!
[tester] 
AGNewsMetric: acc=0.8431578947368421, hinge=3.4926490986974614, ce=7.730125327863191
Local test acc @ epoch 211: 0.8432
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 1.4901159417490817e-08
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.05 seconds!
[tester] 
AGNewsMetric: acc=0.8414473684210526, hinge=3.4821069381111545, ce=7.966899809586375
Local test acc @ epoch 211: 0.8414
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 2.2351740014414645e-08
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.96 seconds!
[tester] 
AGNewsMetric: acc=0.843421052631579, hinge=3.518858814239502, ce=7.824330773604544
Local test acc @ epoch 211: 0.8434
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 2.2351740014414645e-08
Local loss @ local epoch 1: 2.2351740014414645e-08
Local loss @ local epoch 2: 6.705519695060502e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 3.725289943190546e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.84 seconds!
[tester] 
AGNewsMetric: acc=0.8353947368421053, hinge=3.7335614590895805, ce=8.223118468836734
Local test acc @ epoch 211: 0.8354
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 2.2351721895574883e-07
Local loss @ local epoch 1: 2.7567091365199303e-07
Local loss @ local epoch 2: 1.9371503867660067e-07
Local loss @ local epoch 3: 4.3213236722294823e-07
Local loss @ local epoch 4: 5.960463411724959e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.56 seconds!
[tester] 
AGNewsMetric: acc=0.8023684210526316, hinge=3.8007657196647244, ce=7.683320790341026
Local test acc @ epoch 211: 0.8024
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 1.3411036547950062e-07
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.68 seconds!
[tester] 
AGNewsMetric: acc=0.8375, hinge=3.683345581355848, ce=7.8297121319017915
Local test acc @ epoch 211: 0.8375
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 2.2351740014414645e-08
Local loss @ local epoch 3: 2.2351702000378282e-07
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.06 seconds!
[tester] 
AGNewsMetric: acc=0.8377631578947369, hinge=3.5944114885832135, ce=7.8437284329063015
Local test acc @ epoch 211: 0.8378
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 6.705519695060502e-08
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 3.725289587919178e-08
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.87 seconds!
[tester] 
AGNewsMetric: acc=0.8407894736842105, hinge=3.505505794976887, ce=7.820719599472849
Local test acc @ epoch 211: 0.8408
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 2.2351740014414645e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.65 seconds!
[tester] 
AGNewsMetric: acc=0.8443421052631579, hinge=3.5209077333149157, ce=7.754347893564325
Local test acc @ epoch 211: 0.8443
Global evaluate on test data...
Evaluate data in 129.86 seconds!
[tester] 
AGNewsMetric: acc=0.8407894736842105, hinge=3.5757666128560115, ce=7.779594898223877
Global test acc @ epoch 211: 0.8408
Global epoch 212...
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.07 seconds!
[tester] 
AGNewsMetric: acc=0.8410526315789474, hinge=3.5771304642526727, ce=7.796447923559891
Local test acc @ epoch 212: 0.8411
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 1.4901159417490817e-08
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 1.4901159417490817e-08
Local loss @ local epoch 4: 8.195636524988004e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.82 seconds!
[tester] 
AGNewsMetric: acc=0.8368421052631579, hinge=3.6935527207976895, ce=7.909321970688669
Local test acc @ epoch 212: 0.8368
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.96 seconds!
[tester] 
AGNewsMetric: acc=0.8393421052631579, hinge=3.569071343196066, ce=7.9999666595458985
Local test acc @ epoch 212: 0.8393
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 2.9802318834981634e-08
Local loss @ local epoch 1: 1.4901159417490817e-08
Local loss @ local epoch 2: 2.2351740014414645e-08
Local loss @ local epoch 3: 2.9802318834981634e-08
Local loss @ local epoch 4: 3.87429196280209e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.0 seconds!
[tester] 
AGNewsMetric: acc=0.8136842105263158, hinge=4.083267066729696, ce=8.63656817787572
Local test acc @ epoch 212: 0.8137
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 2.3841812435421161e-07
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 0.00010088965063914657
Local loss @ local epoch 4: 0.0008680707542225718
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.29 seconds!
[tester] 
AGNewsMetric: acc=0.8438157894736842, hinge=3.3147679261157386, ce=7.595443473615145
Local test acc @ epoch 212: 0.8438
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 4.470348002882929e-08
Local loss @ local epoch 2: 2.2351740014414645e-08
Local loss @ local epoch 3: 3.4166499972343445e-05
Local loss @ local epoch 4: 0.001117707695811987
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.16 seconds!
[tester] 
AGNewsMetric: acc=0.8446052631578947, hinge=3.5007052343770075, ce=8.059595297763222
Local test acc @ epoch 212: 0.8446
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 2.1606651046113257e-07
Local loss @ local epoch 2: 1.4901159417490817e-08
Local loss @ local epoch 3: 0.003137588733807206
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.1 seconds!
[tester] 
AGNewsMetric: acc=0.8386842105263158, hinge=3.553840507206164, ce=8.044723514757658
Local test acc @ epoch 212: 0.8387
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 8.940690321423972e-08
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 9.68574909165909e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 131.31 seconds!
[tester] 
AGNewsMetric: acc=0.8376315789473684, hinge=3.637577351018002, ce=8.06553142346834
Local test acc @ epoch 212: 0.8376
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.3411032284693647e-07
Local loss @ local epoch 3: 1.0430806440808738e-07
Local loss @ local epoch 4: 5.9604616353681195e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.25 seconds!
[tester] 
AGNewsMetric: acc=0.8432894736842105, hinge=3.2951113949323956, ce=7.900735196565327
Local test acc @ epoch 212: 0.8433
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 1.3411030863608175e-07
Local loss @ local epoch 1: 1.0430806440808738e-07
Local loss @ local epoch 2: 5.215405707303944e-08
Local loss @ local epoch 3: 6.705510031679296e-07
Local loss @ local epoch 4: 4.7683624870842323e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.61 seconds!
[tester] 
AGNewsMetric: acc=0.8148684210526316, hinge=3.7222630709096003, ce=8.224857065301192
Local test acc @ epoch 212: 0.8149
Global evaluate on test data...
Evaluate data in 129.66 seconds!
[tester] 
AGNewsMetric: acc=0.8444736842105263, hinge=3.443192173054344, ce=7.81467525381791
Global test acc @ epoch 212: 0.8445
Global epoch 213...
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 2.2351740014414645e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.6 seconds!
[tester] 
AGNewsMetric: acc=0.8432894736842105, hinge=3.5251692387932225, ce=8.004880742524799
Local test acc @ epoch 213: 0.8433
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.56 seconds!
[tester] 
AGNewsMetric: acc=0.8442105263157895, hinge=3.4274206430033636, ce=7.9870012634678895
Local test acc @ epoch 213: 0.8442
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 3.725289943190546e-08
Local loss @ local epoch 4: 5.2154042862184724e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.14 seconds!
[tester] 
AGNewsMetric: acc=0.8396052631578947, hinge=3.635405395407426, ce=7.868372287750244
Local test acc @ epoch 213: 0.8396
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 6.33296224350488e-07
Local loss @ local epoch 2: 5.960462345910855e-08
Local loss @ local epoch 3: 5.736924322263803e-07
Local loss @ local epoch 4: 1.989283873626846e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.89 seconds!
[tester] 
AGNewsMetric: acc=0.7982894736842105, hinge=4.423236214738143, ce=8.957465489036158
Local test acc @ epoch 213: 0.7983
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 2.2351738238057806e-08
Local loss @ local epoch 1: 2.9802320611338473e-08
Local loss @ local epoch 2: 5.2154042862184724e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.95 seconds!
[tester] 
AGNewsMetric: acc=0.8252631578947368, hinge=3.9088624580282914, ce=8.210440175909746
Local test acc @ epoch 213: 0.8253
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.1175860947787442e-07
Local loss @ local epoch 1: 1.1920917586394353e-07
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 1.8626435860369384e-07
Local loss @ local epoch 4: 2.9802315282267955e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.86 seconds!
[tester] 
AGNewsMetric: acc=0.8221052631578948, hinge=4.004740808135585, ce=8.48171030747263
Local test acc @ epoch 213: 0.8221
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901159417490817e-08
Local loss @ local epoch 1: 3.725289587919178e-08
Local loss @ local epoch 2: 1.4901159417490817e-08
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 2.2351740014414645e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.2 seconds!
[tester] 
AGNewsMetric: acc=0.8402631578947368, hinge=3.5791374811373258, ce=7.824583908884149
Local test acc @ epoch 213: 0.8403
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 1.1026777428924106e-06
Local loss @ local epoch 1: 4.470348002882929e-08
Local loss @ local epoch 2: 7.227034757306683e-07
Local loss @ local epoch 3: 1.341098368357052e-06
Local loss @ local epoch 4: 2.8311860660323873e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.5 seconds!
[tester] 
AGNewsMetric: acc=0.8148684210526316, hinge=3.324113111245005, ce=7.797814856077496
Local test acc @ epoch 213: 0.8149
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 5.215404996761208e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 4.24681758204315e-07
Local loss @ local epoch 4: 2.2351740014414645e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.36 seconds!
[tester] 
AGNewsMetric: acc=0.8180263157894737, hinge=4.1605977010726924, ce=8.54272448288767
Local test acc @ epoch 213: 0.818
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 3.352756721142214e-07
Local loss @ local epoch 1: 2.9802318834981634e-08
Local loss @ local epoch 2: 3.0472474463749677e-06
Local loss @ local epoch 3: 6.77999310028099e-07
Local loss @ local epoch 4: 8.195635814445268e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.39 seconds!
[tester] 
AGNewsMetric: acc=0.8459210526315789, hinge=3.274286913871765, ce=7.861740712617573
Local test acc @ epoch 213: 0.8459
Global evaluate on test data...
Evaluate data in 129.81 seconds!
[tester] 
AGNewsMetric: acc=0.8423684210526315, hinge=3.5464554191890514, ce=7.854803504943848
Global test acc @ epoch 213: 0.8424
Global epoch 214...
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 3.725289943190546e-08
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 5.960463056453591e-08
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 8.195635814445268e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.9 seconds!
[tester] 
AGNewsMetric: acc=0.8380263157894737, hinge=3.638430387346368, ce=7.786643850426925
Local test acc @ epoch 214: 0.838
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.94 seconds!
[tester] 
AGNewsMetric: acc=0.8422368421052632, hinge=3.5196487481970538, ce=7.846177329013222
Local test acc @ epoch 214: 0.8422
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 6.705518984517767e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 3.725289587919178e-08
Local loss @ local epoch 3: 2.9802285439473053e-07
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.69 seconds!
[tester] 
AGNewsMetric: acc=0.8486842105263158, hinge=3.257044284971137, ce=8.303918930856804
Local test acc @ epoch 214: 0.8487
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.117586450050112e-07
Local loss @ local epoch 2: 6.034941293364682e-07
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 5.215405707303944e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.82 seconds!
[tester] 
AGNewsMetric: acc=0.7861842105263158, hinge=4.424253217295597, ce=8.372017780103182
Local test acc @ epoch 214: 0.7862
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 1.4901159417490817e-08
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.25 seconds!
[tester] 
AGNewsMetric: acc=0.8321052631578948, hinge=3.7625762711073225, ce=8.036121825168006
Local test acc @ epoch 214: 0.8321
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 4.2094511627510656e-06
Local loss @ local epoch 1: 2.6300026547687594e-06
Local loss @ local epoch 2: 2.302793264389038
Local loss @ local epoch 3: 5.461162800202146e-06
Local loss @ local epoch 4: 3.553863734850893e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.89 seconds!
[tester] 
AGNewsMetric: acc=0.6867105263157894, hinge=6.799552059173584, ce=10.018056899622866
Local test acc @ epoch 214: 0.6867
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 3.725289943190546e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.4901159417490817e-08
Local loss @ local epoch 3: 3.7252892326478104e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.16 seconds!
[tester] 
AGNewsMetric: acc=0.8443421052631579, hinge=3.571856967775445, ce=8.041746407559044
Local test acc @ epoch 214: 0.8443
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.4901159417490817e-08
Local loss @ local epoch 3: 3.725289943190546e-08
Local loss @ local epoch 4: 3.725289587919178e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.26 seconds!
[tester] 
AGNewsMetric: acc=0.8372368421052632, hinge=3.700953220819172, ce=7.884401146738153
Local test acc @ epoch 214: 0.8372
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.08 seconds!
[tester] 
AGNewsMetric: acc=0.8402631578947368, hinge=3.557487655438875, ce=7.968976492630808
Local test acc @ epoch 214: 0.8403
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 3.725289943190546e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 4.4703469370688254e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.03 seconds!
[tester] 
AGNewsMetric: acc=0.8436842105263158, hinge=3.492739706917813, ce=8.059099801716052
Local test acc @ epoch 214: 0.8437
Global evaluate on test data...
Evaluate data in 129.62 seconds!
[tester] 
AGNewsMetric: acc=0.8388157894736842, hinge=3.660425183773041, ce=7.91404126117104
Global test acc @ epoch 214: 0.8388
Global epoch 215...
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 1.4901159417490817e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.6 seconds!
[tester] 
AGNewsMetric: acc=0.8406578947368422, hinge=3.5530638084913555, ce=7.884174971329538
Local test acc @ epoch 215: 0.8407
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 1.2069825743310503e-06
Local loss @ local epoch 1: 0.5823571085929871
Local loss @ local epoch 2: 2.3841835172788706e-07
Local loss @ local epoch 3: 0.02481064200401306
Local loss @ local epoch 4: 1.5950990928104147e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.15 seconds!
[tester] 
AGNewsMetric: acc=0.7523684210526316, hinge=4.583487040620101, ce=10.884659516183953
Local test acc @ epoch 215: 0.7524
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.831217216225923e-07
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.2351738238057806e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.33 seconds!
[tester] 
AGNewsMetric: acc=0.8114473684210526, hinge=4.170515755101254, ce=8.80803197760331
Local test acc @ epoch 215: 0.8114
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 3.725289587919178e-08
Local loss @ local epoch 2: 2.2351740014414645e-08
Local loss @ local epoch 3: 3.7252892326478104e-08
Local loss @ local epoch 4: 5.2154042862184724e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.9 seconds!
[tester] 
AGNewsMetric: acc=0.8446052631578947, hinge=3.601748921243768, ce=7.802932781420256
Local test acc @ epoch 215: 0.8446
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 1.3411033705779118e-07
Local loss @ local epoch 2: 1.5646212148112681e-07
Local loss @ local epoch 3: 2.6076989456669253e-07
Local loss @ local epoch 4: 4.470347647611561e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.62 seconds!
[tester] 
AGNewsMetric: acc=0.8330263157894737, hinge=3.7653579543766225, ce=8.114789447784425
Local test acc @ epoch 215: 0.833
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901159417490817e-08
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.17 seconds!
[tester] 
AGNewsMetric: acc=0.8403947368421053, hinge=3.6081060718235216, ce=7.881045868522243
Local test acc @ epoch 215: 0.8404
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 2.2351740014414645e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.5124501260288525e-06
Local loss @ local epoch 4: 6.347573162202025e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.22 seconds!
[tester] 
AGNewsMetric: acc=0.7769736842105263, hinge=5.382221596868415, ce=9.035366839358682
Local test acc @ epoch 215: 0.777
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 3.725289587919178e-08
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.89 seconds!
[tester] 
AGNewsMetric: acc=0.8294736842105264, hinge=3.9013628781469243, ce=8.057981786225971
Local test acc @ epoch 215: 0.8295
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901159417490817e-08
Local loss @ local epoch 1: 2.9802315282267955e-08
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 2.2351738238057806e-08
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.59 seconds!
[tester] 
AGNewsMetric: acc=0.8303947368421053, hinge=3.8529009300784063, ce=7.825330299578215
Local test acc @ epoch 215: 0.8304
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 8.940691031966708e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 3.725289587919178e-08
Local loss @ local epoch 3: 3.725289587919178e-08
Local loss @ local epoch 4: 2.9802320611338473e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.71 seconds!
[tester] 
AGNewsMetric: acc=0.8443421052631579, hinge=3.2704202544061762, ce=7.847487141458612
Local test acc @ epoch 215: 0.8443
Global evaluate on test data...
Evaluate data in 130.25 seconds!
[tester] 
AGNewsMetric: acc=0.8297368421052631, hinge=3.8287278077476903, ce=8.1461992635225
Global test acc @ epoch 215: 0.8297
Global epoch 216...
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.2351713369062054e-07
Local loss @ local epoch 4: 1.4901159417490817e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.59 seconds!
[tester] 
AGNewsMetric: acc=0.8326315789473684, hinge=3.8472156057859723, ce=8.279358379966334
Local test acc @ epoch 216: 0.8326
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.2351740014414645e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.57 seconds!
[tester] 
AGNewsMetric: acc=0.8382894736842105, hinge=3.66592755643945, ce=7.944773944051642
Local test acc @ epoch 216: 0.8383
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 4.7683619186500437e-07
Local loss @ local epoch 1: 2.2351740014414645e-08
Local loss @ local epoch 2: 1.1740059852600098
Local loss @ local epoch 3: 0.2740553319454193
Local loss @ local epoch 4: 5.379171852837317e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.45 seconds!
[tester] 
AGNewsMetric: acc=0.6881578947368421, hinge=6.534375648498536, ce=10.927845543309262
Local test acc @ epoch 216: 0.6882
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 3.725289587919178e-08
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 8.940693874137651e-08
Local loss @ local epoch 3: 5.215405707303944e-08
Local loss @ local epoch 4: 1.2663462162017822
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.5 seconds!
[tester] 
AGNewsMetric: acc=0.8468421052631578, hinge=3.3568345930701806, ce=7.632474829021253
Local test acc @ epoch 216: 0.8468
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901159417490817e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.14 seconds!
[tester] 
AGNewsMetric: acc=0.8344736842105264, hinge=3.642372104996129, ce=8.126765789232756
Local test acc @ epoch 216: 0.8345
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 5.960463411724959e-08
Local loss @ local epoch 1: 2.3096760060070665e-07
Local loss @ local epoch 2: 3.7252892326478104e-08
Local loss @ local epoch 3: 2.2351740014414645e-08
Local loss @ local epoch 4: 2.2351740014414645e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.5 seconds!
[tester] 
AGNewsMetric: acc=0.7852631578947369, hinge=4.595823155704298, ce=8.357795044748407
Local test acc @ epoch 216: 0.7853
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450576333667414e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.4932689666748047
Local loss @ local epoch 3: 7.450576333667414e-08
Local loss @ local epoch 4: 1.1920921849650767e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.41 seconds!
[tester] 
AGNewsMetric: acc=0.8184210526315789, hinge=3.7538043801408065, ce=8.959369950545462
Local test acc @ epoch 216: 0.8184
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.4901159417490817e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.32 seconds!
[tester] 
AGNewsMetric: acc=0.8343421052631579, hinge=3.675059222924082, ce=8.104810669547634
Local test acc @ epoch 216: 0.8343
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 4.470347647611561e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 3.457018465269357e-06
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.06 seconds!
[tester] 
AGNewsMetric: acc=0.8410526315789474, hinge=3.4945101499557496, ce=7.949076176693565
Local test acc @ epoch 216: 0.8411
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.86 seconds!
[tester] 
AGNewsMetric: acc=0.8269736842105263, hinge=3.907825733485975, ce=8.215395967583907
Local test acc @ epoch 216: 0.827
Global evaluate on test data...
Evaluate data in 129.68 seconds!
[tester] 
AGNewsMetric: acc=0.8317105263157895, hinge=3.7839649862992135, ce=8.091526282461066
Global test acc @ epoch 216: 0.8317
Global epoch 217...
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 3.7252892326478104e-08
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 3.3727133995853364e-05
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.17 seconds!
[tester] 
AGNewsMetric: acc=0.75, hinge=5.637230652257016, ce=9.401663858514084
Local test acc @ epoch 217: 0.75
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 2.2351740014414645e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.17 seconds!
[tester] 
AGNewsMetric: acc=0.8286842105263158, hinge=3.8544059562683106, ce=8.253725086011384
Local test acc @ epoch 217: 0.8287
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.4901159417490817e-08
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 4.4703469370688254e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.19 seconds!
[tester] 
AGNewsMetric: acc=0.8422368421052632, hinge=3.6412597033852023, ce=7.8235603513215715
Local test acc @ epoch 217: 0.8422
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 2.9802318834981634e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 5.960462345910855e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.7 seconds!
[tester] 
AGNewsMetric: acc=0.8406578947368422, hinge=3.701594006638778, ce=7.897318011836002
Local test acc @ epoch 217: 0.8407
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 4.24681758204315e-07
Local loss @ local epoch 1: 2.0861604355104646e-07
Local loss @ local epoch 2: 2.5331764845759608e-06
Local loss @ local epoch 3: 1.3411039390121005e-07
Local loss @ local epoch 4: 0.2843959331512451
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.71 seconds!
[tester] 
AGNewsMetric: acc=0.8425, hinge=3.244630355583994, ce=7.922813337225663
Local test acc @ epoch 217: 0.8425
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.81 seconds!
[tester] 
AGNewsMetric: acc=0.8313157894736842, hinge=3.754455751368874, ce=8.116081622274299
Local test acc @ epoch 217: 0.8313
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 5.960463766996327e-08
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 2.3096757217899722e-07
Local loss @ local epoch 4: 1.7881379221762472e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.31 seconds!
[tester] 
AGNewsMetric: acc=0.8376315789473684, hinge=3.4711970494922837, ce=8.027580112658049
Local test acc @ epoch 217: 0.8376
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 2.9802315282267955e-08
Local loss @ local epoch 1: 2.2351740014414645e-08
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.22 seconds!
[tester] 
AGNewsMetric: acc=0.8403947368421053, hinge=3.59978977705303, ce=7.888680977068449
Local test acc @ epoch 217: 0.8404
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 1.2218833944643848e-06
Local loss @ local epoch 1: 0.0004309212963562459
Local loss @ local epoch 2: 4.4703469370688254e-08
Local loss @ local epoch 3: 8.388945389015134e-06
Local loss @ local epoch 4: 4.922497464576736e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.9 seconds!
[tester] 
AGNewsMetric: acc=0.7989473684210526, hinge=3.664023945958991, ce=9.424297328748201
Local test acc @ epoch 217: 0.7989
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 2.9802315282267955e-08
Local loss @ local epoch 1: 1.4901159417490817e-08
Local loss @ local epoch 2: 2.2351740014414645e-08
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.24 seconds!
[tester] 
AGNewsMetric: acc=0.8442105263157895, hinge=3.566553904633773, ce=7.958783751035991
Local test acc @ epoch 217: 0.8442
Global evaluate on test data...
Evaluate data in 130.87 seconds!
[tester] 
AGNewsMetric: acc=0.8472368421052632, hinge=3.4322789332741186, ce=7.806880675867984
Global test acc @ epoch 217: 0.8472
Global epoch 218...
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 1.78813678530787e-07
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 1.713632116207009e-07
Local loss @ local epoch 4: 1.7136318319899146e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.31 seconds!
[tester] 
AGNewsMetric: acc=0.8061842105263158, hinge=4.386965702458432, ce=8.187409239317242
Local test acc @ epoch 218: 0.8062
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 2.2351738238057806e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 3.725289587919178e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.2 seconds!
[tester] 
AGNewsMetric: acc=0.8422368421052632, hinge=3.641333048218175, ce=7.807162354117946
Local test acc @ epoch 218: 0.8422
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 1.5646203621599852e-07
Local loss @ local epoch 4: 4.172312060291006e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.91 seconds!
[tester] 
AGNewsMetric: acc=0.8215789473684211, hinge=4.189432755771437, ce=8.482205358806409
Local test acc @ epoch 218: 0.8216
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901159417490817e-08
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 1.043080430918053e-07
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 1.2442350225683185e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.49 seconds!
[tester] 
AGNewsMetric: acc=0.8201315789473684, hinge=3.9067828070489985, ce=8.681633726421156
Local test acc @ epoch 218: 0.8201
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 1.2665981330428622e-07
Local loss @ local epoch 1: 7.450536259057117e-07
Local loss @ local epoch 2: 1.1026768333977088e-06
Local loss @ local epoch 3: 1.4901159417490817e-08
Local loss @ local epoch 4: 1.3411039390121005e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.82 seconds!
[tester] 
AGNewsMetric: acc=0.835, hinge=3.37253325161181, ce=8.173276411357678
Local test acc @ epoch 218: 0.835
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 1.4901159417490817e-08
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.28 seconds!
[tester] 
AGNewsMetric: acc=0.8471052631578947, hinge=3.4229344124543037, ce=7.921537437438965
Local test acc @ epoch 218: 0.8471
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.1920917586394353e-07
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 5.215405707303944e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.31 seconds!
[tester] 
AGNewsMetric: acc=0.7635526315789474, hinge=5.755860762847098, ce=9.342624602066843
Local test acc @ epoch 218: 0.7636
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 2.2351740014414645e-08
Local loss @ local epoch 1: 6.705521116145974e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 1.639125599695035e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.87 seconds!
[tester] 
AGNewsMetric: acc=0.8051315789473684, hinge=4.491472320054707, ce=8.616271625318026
Local test acc @ epoch 218: 0.8051
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.078011208250246e-07
Local loss @ local epoch 4: 2.2351740014414645e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.47 seconds!
[tester] 
AGNewsMetric: acc=0.7893421052631578, hinge=4.99152252899973, ce=9.095499378003572
Local test acc @ epoch 218: 0.7893
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 8.379264181712642e-05
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.356313705444336
Local loss @ local epoch 4: 2.5331945607831585e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.48 seconds!
[tester] 
AGNewsMetric: acc=0.8494736842105263, hinge=3.1520984782670673, ce=7.658592154854222
Local test acc @ epoch 218: 0.8495
Global evaluate on test data...
Evaluate data in 130.06 seconds!
[tester] 
AGNewsMetric: acc=0.8410526315789474, hinge=3.6832719767721076, ce=7.956083717346192
Global test acc @ epoch 218: 0.8411
Global epoch 219...
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 2.9802315282267955e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.2351740014414645e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.9 seconds!
[tester] 
AGNewsMetric: acc=0.8427631578947369, hinge=3.6602151297268115, ce=7.7486202340377
Local test acc @ epoch 219: 0.8428
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 7.450576333667414e-08
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 2.2351740014414645e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.12 seconds!
[tester] 
AGNewsMetric: acc=0.8353947368421053, hinge=3.7203501132914893, ce=8.236511250546105
Local test acc @ epoch 219: 0.8354
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 6.705521116145974e-08
Local loss @ local epoch 4: 5.2154042862184724e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.85 seconds!
[tester] 
AGNewsMetric: acc=0.8498684210526316, hinge=3.3826859757774757, ce=7.912122188367341
Local test acc @ epoch 219: 0.8499
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 2.9802315282267955e-08
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 5.215404996761208e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.54 seconds!
[tester] 
AGNewsMetric: acc=0.820921052631579, hinge=4.078587311945464, ce=8.422254301372327
Local test acc @ epoch 219: 0.8209
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.7136324004241033e-07
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.042172715067863464
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.98 seconds!
[tester] 
AGNewsMetric: acc=0.8303947368421053, hinge=3.731442785137578, ce=8.439114405983373
Local test acc @ epoch 219: 0.8304
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 5.9604616353681195e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.97 seconds!
[tester] 
AGNewsMetric: acc=0.8402631578947368, hinge=3.7369520115852355, ce=8.137534056211774
Local test acc @ epoch 219: 0.8403
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 2.2351738238057806e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.4901159417490817e-08
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.83 seconds!
[tester] 
AGNewsMetric: acc=0.8303947368421053, hinge=3.8919232682177896, ce=8.04358407171149
Local test acc @ epoch 219: 0.8304
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 9.238667644240195e-07
Local loss @ local epoch 1: 2.2351740014414645e-08
Local loss @ local epoch 2: 1.199538701257552e-06
Local loss @ local epoch 3: 1.4901129361533094e-06
Local loss @ local epoch 4: 0.004038620740175247
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.89 seconds!
[tester] 
AGNewsMetric: acc=0.7925, hinge=3.9145989786951167, ce=8.232144950063605
Local test acc @ epoch 219: 0.7925
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 9.685750512744562e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.16 seconds!
[tester] 
AGNewsMetric: acc=0.839078947368421, hinge=3.706222042535481, ce=7.975772773341129
Local test acc @ epoch 219: 0.8391
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 4.4703469370688254e-08
Local loss @ local epoch 2: 1.1175865211043856e-07
Local loss @ local epoch 3: 2.2351740014414645e-08
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.03 seconds!
[tester] 
AGNewsMetric: acc=0.8343421052631579, hinge=3.7917761570528934, ce=8.31581970917551
Local test acc @ epoch 219: 0.8343
Global evaluate on test data...
Evaluate data in 129.98 seconds!
[tester] 
AGNewsMetric: acc=0.8413157894736842, hinge=3.623452562030993, ce=7.963542611975419
Global test acc @ epoch 219: 0.8413
Global epoch 220...
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 4.470347647611561e-08
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 2.2351740014414645e-08
Local loss @ local epoch 3: 2.9802318834981634e-08
Local loss @ local epoch 4: 4.470348002882929e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.22 seconds!
[tester] 
AGNewsMetric: acc=0.835, hinge=3.972541457728336, ce=8.442772411547208
Local test acc @ epoch 220: 0.835
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 9.313159807788907e-07
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.07 seconds!
[tester] 
AGNewsMetric: acc=0.838421052631579, hinge=3.505075892900166, ce=8.81212527224892
Local test acc @ epoch 220: 0.8384
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.942064773174934e-05
Local loss @ local epoch 2: 1.1175867342672063e-07
Local loss @ local epoch 3: 2.507504940032959
Local loss @ local epoch 4: 1.4156097449813387e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.75 seconds!
[tester] 
AGNewsMetric: acc=0.8301315789473684, hinge=3.396212825022246, ce=8.28457561894467
Local test acc @ epoch 220: 0.8301
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 2.2351738238057806e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 7.450579175838357e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 131.47 seconds!
[tester] 
AGNewsMetric: acc=0.8118421052631579, hinge=4.295253422636735, ce=8.42649486541748
Local test acc @ epoch 220: 0.8118
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.2351738238057806e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 3.725289587919178e-08
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.59 seconds!
[tester] 
AGNewsMetric: acc=0.8332894736842106, hinge=3.834092926979065, ce=8.224805356075889
Local test acc @ epoch 220: 0.8333
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 8.195632972274325e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.12 seconds!
[tester] 
AGNewsMetric: acc=0.844078947368421, hinge=3.5164982145710995, ce=8.165168930856805
Local test acc @ epoch 220: 0.8441
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 2.2351740014414645e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.9802320611338473e-08
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.12 seconds!
[tester] 
AGNewsMetric: acc=0.8377631578947369, hinge=3.7570991370552465, ce=8.005439984171014
Local test acc @ epoch 220: 0.8378
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 9.536680067867565e-07
Local loss @ local epoch 2: 0.044696275144815445
Local loss @ local epoch 3: 1.5646214990283625e-07
Local loss @ local epoch 4: 1.4156094607642444e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.97 seconds!
[tester] 
AGNewsMetric: acc=0.8311842105263157, hinge=3.5570240748556037, ce=8.513876001458419
Local test acc @ epoch 220: 0.8312
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.2665974225001264e-07
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 5.215405707303944e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.98 seconds!
[tester] 
AGNewsMetric: acc=0.8367105263157895, hinge=3.656988881261725, ce=8.17724933021947
Local test acc @ epoch 220: 0.8367
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 8.195632972274325e-08
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.48 seconds!
[tester] 
AGNewsMetric: acc=0.8421052631578947, hinge=3.467279287890384, ce=8.182022791410747
Local test acc @ epoch 220: 0.8421
Global evaluate on test data...
Evaluate data in 130.57 seconds!
[tester] 
AGNewsMetric: acc=0.8423684210526315, hinge=3.6178685599879215, ce=8.12337362590589
Global test acc @ epoch 220: 0.8424
Global epoch 221...
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 3.725289587919178e-08
Local loss @ local epoch 3: 2.2351740014414645e-08
Local loss @ local epoch 4: 1.1175863079415649e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.02 seconds!
[tester] 
AGNewsMetric: acc=0.8236842105263158, hinge=4.139407448015715, ce=8.738716023093776
Local test acc @ epoch 221: 0.8237
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 1.4901159417490817e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.85 seconds!
[tester] 
AGNewsMetric: acc=0.8282894736842106, hinge=4.000365860587672, ce=8.443298243472452
Local test acc @ epoch 221: 0.8283
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 3.725289943190546e-08
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.98 seconds!
[tester] 
AGNewsMetric: acc=0.8452631578947368, hinge=3.494265530485856, ce=7.926606770565635
Local test acc @ epoch 221: 0.8453
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 4.4703469370688254e-08
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 5.215405707303944e-08
Local loss @ local epoch 3: 2.2351740014414645e-08
Local loss @ local epoch 4: 4.884186637355015e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.91 seconds!
[tester] 
AGNewsMetric: acc=0.815921052631579, hinge=4.138405741892363, ce=8.53956517671284
Local test acc @ epoch 221: 0.8159
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.15 seconds!
[tester] 
AGNewsMetric: acc=0.8417105263157895, hinge=3.5881926372176722, ce=8.191763672075773
Local test acc @ epoch 221: 0.8417
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 2.2351740014414645e-08
Local loss @ local epoch 1: 2.9802318834981634e-08
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 4.470347292340193e-08
Local loss @ local epoch 4: 2.2351738238057806e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.61 seconds!
[tester] 
AGNewsMetric: acc=0.8328947368421052, hinge=3.952864119630111, ce=8.335371746264006
Local test acc @ epoch 221: 0.8329
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 4.470348002882929e-08
Local loss @ local epoch 1: 1.192092469182171e-07
Local loss @ local epoch 2: 7.450579175838357e-08
Local loss @ local epoch 3: 1.4901159417490817e-08
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.71 seconds!
[tester] 
AGNewsMetric: acc=0.8369736842105263, hinge=3.648726289146825, ce=8.101849666394685
Local test acc @ epoch 221: 0.837
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 2.9802320611338473e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.4901159417490817e-08
Local loss @ local epoch 4: 8.940690321423972e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.24 seconds!
[tester] 
AGNewsMetric: acc=0.8351315789473684, hinge=3.766814707705849, ce=8.091055143255936
Local test acc @ epoch 221: 0.8351
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 2.9802318834981634e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.4901159417490817e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.97 seconds!
[tester] 
AGNewsMetric: acc=0.8430263157894737, hinge=3.6087021983297247, ce=8.236860029320967
Local test acc @ epoch 221: 0.843
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 2.9802315282267955e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 8.19558579223667e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.8 seconds!
[tester] 
AGNewsMetric: acc=0.8338157894736842, hinge=3.782680904990748, ce=8.06637146297254
Local test acc @ epoch 221: 0.8338
Global evaluate on test data...
Evaluate data in 130.59 seconds!
[tester] 
AGNewsMetric: acc=0.8427631578947369, hinge=3.63918112328178, ce=8.080054163681833
Global test acc @ epoch 221: 0.8428
Global epoch 222...
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 2.2351740014414645e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.72 seconds!
[tester] 
AGNewsMetric: acc=0.8451315789473685, hinge=3.5717254267240826, ce=8.066102065036171
Local test acc @ epoch 222: 0.8451
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.4901159417490817e-08
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.64 seconds!
[tester] 
AGNewsMetric: acc=0.8425, hinge=3.6408494294317144, ce=8.183850750170256
Local test acc @ epoch 222: 0.8425
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 3.7252892326478104e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 0.6322305202484131
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.01 seconds!
[tester] 
AGNewsMetric: acc=0.7396052631578948, hinge=5.996918928246749, ce=10.145141179938065
Local test acc @ epoch 222: 0.7396
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 4.470347292340193e-08
Local loss @ local epoch 2: 3.725289943190546e-08
Local loss @ local epoch 3: 2.9802318834981634e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.97 seconds!
[tester] 
AGNewsMetric: acc=0.8480263157894737, hinge=3.4907416820526125, ce=8.123720659958689
Local test acc @ epoch 222: 0.848
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 1.4901159417490817e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.79 seconds!
[tester] 
AGNewsMetric: acc=0.8438157894736842, hinge=3.575516329815513, ce=8.094344320799175
Local test acc @ epoch 222: 0.8438
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901159417490817e-08
Local loss @ local epoch 1: 2.1606649625027785e-07
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 2.7194030280952575e-06
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.27 seconds!
[tester] 
AGNewsMetric: acc=0.7806578947368421, hinge=5.010584000286303, ce=8.955754948666222
Local test acc @ epoch 222: 0.7807
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.9802315282267955e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.9802320611338473e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.25 seconds!
[tester] 
AGNewsMetric: acc=0.85, hinge=3.492084046163057, ce=8.284964508257413
Local test acc @ epoch 222: 0.85
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 3.203671667506569e-06
Local loss @ local epoch 1: 2.9802320611338473e-08
Local loss @ local epoch 2: 1.3706316947937012
Local loss @ local epoch 3: 0.1287534385919571
Local loss @ local epoch 4: 0.3977071940898895
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.15 seconds!
[tester] 
AGNewsMetric: acc=0.7780263157894737, hinge=3.099869700732984, ce=9.106209689692447
Local test acc @ epoch 222: 0.778
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.1175862368872913e-07
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.2351738238057806e-08
Local loss @ local epoch 4: 1.4901159417490817e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.25 seconds!
[tester] 
AGNewsMetric: acc=0.8244736842105264, hinge=4.080963717008892, ce=8.837353491532175
Local test acc @ epoch 222: 0.8245
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 2.9802318834981634e-08
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.3 seconds!
[tester] 
AGNewsMetric: acc=0.799078947368421, hinge=4.601671109199524, ce=8.905533621938606
Local test acc @ epoch 222: 0.7991
Global evaluate on test data...
Evaluate data in 130.8 seconds!
[tester] 
AGNewsMetric: acc=0.8325, hinge=3.8429080390930177, ce=8.274906239760549
Global test acc @ epoch 222: 0.8325
Global epoch 223...
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 5.9604616353681195e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 2.9057196115900297e-07
Local loss @ local epoch 4: 6.705519695060502e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.63 seconds!
[tester] 
AGNewsMetric: acc=0.8356578947368422, hinge=3.6680152539203044, ce=8.200928814536647
Local test acc @ epoch 223: 0.8357
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901159417490817e-08
Local loss @ local epoch 1: 1.4901159417490817e-08
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.79 seconds!
[tester] 
AGNewsMetric: acc=0.8457894736842105, hinge=3.6182996817639, ce=8.126888768045525
Local test acc @ epoch 223: 0.8458
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 8.195632972274325e-08
Local loss @ local epoch 4: 2.9802318834981634e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.76 seconds!
[tester] 
AGNewsMetric: acc=0.795921052631579, hinge=4.7630015704506325, ce=8.865721766823217
Local test acc @ epoch 223: 0.7959
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.2351740014414645e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 6.70552182668871e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.51 seconds!
[tester] 
AGNewsMetric: acc=0.8278947368421052, hinge=3.984894413446125, ce=8.349795484040913
Local test acc @ epoch 223: 0.8279
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 8.098258149402682e-06
Local loss @ local epoch 1: 3.567086605471559e-05
Local loss @ local epoch 2: 9.803460125112906e-05
Local loss @ local epoch 3: 0.4752940535545349
Local loss @ local epoch 4: 1.4901038412062917e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.52 seconds!
[tester] 
AGNewsMetric: acc=0.8063157894736842, hinge=3.8577947087036937, ce=8.571249664708187
Local test acc @ epoch 223: 0.8063
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 8.195635814445268e-08
Local loss @ local epoch 1: 1.1920923981278975e-07
Local loss @ local epoch 2: 3.725289587919178e-08
Local loss @ local epoch 3: 5.960463056453591e-08
Local loss @ local epoch 4: 2.3841505480959313e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.73 seconds!
[tester] 
AGNewsMetric: acc=0.8206578947368421, hinge=4.112588684182418, ce=8.296902013075979
Local test acc @ epoch 223: 0.8207
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 1.616755412214843e-06
Local loss @ local epoch 1: 2.8186783310957253e-05
Local loss @ local epoch 2: 2.756712547125062e-07
Local loss @ local epoch 3: 1.6987228264042642e-06
Local loss @ local epoch 4: 2.8665879653999582e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.11 seconds!
[tester] 
AGNewsMetric: acc=0.8439473684210527, hinge=2.987146056827746, ce=8.373556193301551
Local test acc @ epoch 223: 0.8439
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 3.7252892326478104e-08
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 1.7881373537420586e-07
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 131.13 seconds!
[tester] 
AGNewsMetric: acc=0.8297368421052631, hinge=3.926866598882173, ce=8.350837300953112
Local test acc @ epoch 223: 0.8297
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 5.8186324167763814e-06
Local loss @ local epoch 3: 3.725289943190546e-08
Local loss @ local epoch 4: 0.7142876982688904
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.44 seconds!
[tester] 
AGNewsMetric: acc=0.8507894736842105, hinge=3.191312463534506, ce=7.83854077690526
Local test acc @ epoch 223: 0.8508
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 2.3096757217899722e-07
Local loss @ local epoch 1: 8.195632972274325e-08
Local loss @ local epoch 2: 4.3958368678431725e-07
Local loss @ local epoch 3: 2.45868676529426e-07
Local loss @ local epoch 4: 1.1175867342672063e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.93 seconds!
[tester] 
AGNewsMetric: acc=0.7621052631578947, hinge=5.499211665203696, ce=9.56224435103567
Local test acc @ epoch 223: 0.7621
Global evaluate on test data...
Evaluate data in 130.27 seconds!
[tester] 
AGNewsMetric: acc=0.8468421052631578, hinge=3.4965668600483943, ce=7.908914090206749
Global test acc @ epoch 223: 0.8468
Global epoch 224...
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 6.705520405603238e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 4.470347292340193e-08
Local loss @ local epoch 3: 1.4901159417490817e-08
Local loss @ local epoch 4: 1.4901159417490817e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.68 seconds!
[tester] 
AGNewsMetric: acc=0.843421052631579, hinge=3.490698856554533, ce=8.146671025125604
Local test acc @ epoch 224: 0.8434
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 5.215405707303944e-08
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.4901159417490817e-08
Local loss @ local epoch 4: 3.725289587919178e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 131.0 seconds!
[tester] 
AGNewsMetric: acc=0.8294736842105264, hinge=3.9114579386460155, ce=8.103285494352642
Local test acc @ epoch 224: 0.8295
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 5.215405707303944e-08
Local loss @ local epoch 2: 1.8626425912771083e-07
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 3.725289943190546e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.4 seconds!
[tester] 
AGNewsMetric: acc=0.8309210526315789, hinge=3.7837964968932303, ce=8.475489160638107
Local test acc @ epoch 224: 0.8309
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.31 seconds!
[tester] 
AGNewsMetric: acc=0.8481578947368421, hinge=3.465402999175222, ce=7.98536140241121
Local test acc @ epoch 224: 0.8482
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 8.370338036911562e-05
Local loss @ local epoch 1: 1.6218085289001465
Local loss @ local epoch 2: 1.2591372069437057e-06
Local loss @ local epoch 3: 0.001054145977832377
Local loss @ local epoch 4: 0.00019784785399679095
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.23 seconds!
[tester] 
AGNewsMetric: acc=0.7886842105263158, hinge=4.6676888586345475, ce=9.745693505939684
Local test acc @ epoch 224: 0.7887
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901159417490817e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 2.9802315282267955e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.66 seconds!
[tester] 
AGNewsMetric: acc=0.849078947368421, hinge=3.4446648359298706, ce=7.91063127618087
Local test acc @ epoch 224: 0.8491
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.2351740014414645e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.39 seconds!
[tester] 
AGNewsMetric: acc=0.835, hinge=3.768131456375122, ce=8.090135359513132
Local test acc @ epoch 224: 0.835
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 2.9802318834981634e-08
Local loss @ local epoch 1: 4.6193460434551525e-07
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 4.470338410555996e-07
Local loss @ local epoch 4: 4.172317176198703e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.75 seconds!
[tester] 
AGNewsMetric: acc=0.7936842105263158, hinge=5.099658450578389, ce=8.83502043473093
Local test acc @ epoch 224: 0.7937
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 9.68574909165909e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.14 seconds!
[tester] 
AGNewsMetric: acc=0.8343421052631579, hinge=3.8641470093476147, ce=7.986804498371325
Local test acc @ epoch 224: 0.8343
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.06 seconds!
[tester] 
AGNewsMetric: acc=0.8348684210526316, hinge=3.819922954157779, ce=8.47477199755217
Local test acc @ epoch 224: 0.8349
Global evaluate on test data...
Evaluate data in 130.27 seconds!
[tester] 
AGNewsMetric: acc=0.8469736842105263, hinge=3.5187147843210322, ce=7.921272587023283
Global test acc @ epoch 224: 0.847
Global epoch 225...
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 3.7252812035148963e-07
Local loss @ local epoch 1: 1.0430809993522416e-07
Local loss @ local epoch 2: 1.8608836398925632e-05
Local loss @ local epoch 3: 2.9802318834981634e-08
Local loss @ local epoch 4: 1.4677552826469764e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 131.06 seconds!
[tester] 
AGNewsMetric: acc=0.7530263157894737, hinge=5.481184790259913, ce=9.290851428383275
Local test acc @ epoch 225: 0.753
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901159417490817e-08
Local loss @ local epoch 1: 4.4703469370688254e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.0861595828591817e-07
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.91 seconds!
[tester] 
AGNewsMetric: acc=0.8443421052631579, hinge=3.6794255816309076, ce=7.7617121857091
Local test acc @ epoch 225: 0.8443
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 5.2154042862184724e-08
Local loss @ local epoch 1: 2.3841832330617763e-07
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 6.705521116145974e-08
Local loss @ local epoch 4: 2.6822067411558237e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.68 seconds!
[tester] 
AGNewsMetric: acc=0.8065789473684211, hinge=4.528478900507877, ce=8.475669876901726
Local test acc @ epoch 225: 0.8066
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.23 seconds!
[tester] 
AGNewsMetric: acc=0.8472368421052632, hinge=3.4931496961493242, ce=7.89301543386359
Local test acc @ epoch 225: 0.8472
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 1.4901159417490817e-08
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.4 seconds!
[tester] 
AGNewsMetric: acc=0.843421052631579, hinge=3.673189068593477, ce=7.960217539134779
Local test acc @ epoch 225: 0.8434
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.19 seconds!
[tester] 
AGNewsMetric: acc=0.8482894736842105, hinge=3.4182498706014535, ce=7.90139131345247
Local test acc @ epoch 225: 0.8483
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 8.940692453052179e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.07 seconds!
[tester] 
AGNewsMetric: acc=0.8452631578947368, hinge=3.4786804530495092, ce=7.833726223393491
Local test acc @ epoch 225: 0.8453
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 8.940692453052179e-08
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.9802320611338473e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.64 seconds!
[tester] 
AGNewsMetric: acc=0.85, hinge=3.5228399685809486, ce=8.029630839699193
Local test acc @ epoch 225: 0.85
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.61 seconds!
[tester] 
AGNewsMetric: acc=0.8476315789473684, hinge=3.4879829406738283, ce=7.954600174552516
Local test acc @ epoch 225: 0.8476
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 3.725289587919178e-08
Local loss @ local epoch 1: 2.2351738238057806e-08
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.4901159417490817e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.84 seconds!
[tester] 
AGNewsMetric: acc=0.8447368421052631, hinge=3.395118652770394, ce=7.708218330584074
Local test acc @ epoch 225: 0.8447
Global evaluate on test data...
Evaluate data in 130.09 seconds!
[tester] 
AGNewsMetric: acc=0.8446052631578947, hinge=3.6379123013897945, ce=7.890974027734054
Global test acc @ epoch 225: 0.8446
Global epoch 226...
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 4.470348002882929e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.2351740014414645e-08
Local loss @ local epoch 4: 2.9802320611338473e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.89 seconds!
[tester] 
AGNewsMetric: acc=0.8476315789473684, hinge=3.5003448206500005, ce=7.851820310291491
Local test acc @ epoch 226: 0.8476
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.4901159417490817e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.22 seconds!
[tester] 
AGNewsMetric: acc=0.8457894736842105, hinge=3.5405750703811645, ce=8.010421553160015
Local test acc @ epoch 226: 0.8458
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901144140821998e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.9802320611338473e-08
Local loss @ local epoch 3: 7.450578465295621e-08
Local loss @ local epoch 4: 6.705521116145974e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.25 seconds!
[tester] 
AGNewsMetric: acc=0.8393421052631579, hinge=3.4155432618291752, ce=8.006485736244603
Local test acc @ epoch 226: 0.8393
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 4.4703469370688254e-08
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 2.2351738238057806e-08
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.34 seconds!
[tester] 
AGNewsMetric: acc=0.8367105263157895, hinge=3.7120261430740356, ce=8.105727309176796
Local test acc @ epoch 226: 0.8367
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 2.2351740014414645e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.44 seconds!
[tester] 
AGNewsMetric: acc=0.8393421052631579, hinge=3.7638724746202166, ce=7.997416584617214
Local test acc @ epoch 226: 0.8393
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 3.725289943190546e-08
Local loss @ local epoch 1: 2.9802318834981634e-08
Local loss @ local epoch 2: 3.7252892326478104e-08
Local loss @ local epoch 3: 5.960462345910855e-08
Local loss @ local epoch 4: 4.470347647611561e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.5 seconds!
[tester] 
AGNewsMetric: acc=0.8405263157894737, hinge=3.7044165653931467, ce=8.005217557204396
Local test acc @ epoch 226: 0.8405
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 3.2782472203507496e-07
Local loss @ local epoch 1: 3.2781717891339213e-06
Local loss @ local epoch 2: 1.2665982751514093e-07
Local loss @ local epoch 3: 1.0247807502746582
Local loss @ local epoch 4: 3.725289943190546e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.52 seconds!
[tester] 
AGNewsMetric: acc=0.7755263157894737, hinge=4.889824208711323, ce=9.022901258970561
Local test acc @ epoch 226: 0.7755
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.9802318834981634e-08
Local loss @ local epoch 3: 5.2154042862184724e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.68 seconds!
[tester] 
AGNewsMetric: acc=0.8472368421052632, hinge=3.560437807785837, ce=7.855972506874486
Local test acc @ epoch 226: 0.8472
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.92 seconds!
[tester] 
AGNewsMetric: acc=0.8446052631578947, hinge=3.639306340092107, ce=7.972057058434737
Local test acc @ epoch 226: 0.8446
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.89 seconds!
[tester] 
AGNewsMetric: acc=0.8413157894736842, hinge=3.6945357312654195, ce=7.984138120350085
Local test acc @ epoch 226: 0.8413
Global evaluate on test data...
Evaluate data in 131.19 seconds!
[tester] 
AGNewsMetric: acc=0.8435526315789473, hinge=3.6276587636847246, ce=7.917964483562269
Global test acc @ epoch 226: 0.8436
Global epoch 227...
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 5.215405352032576e-08
Local loss @ local epoch 1: 7.450577044210149e-08
Local loss @ local epoch 2: 3.725289587919178e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.2351740014414645e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.79 seconds!
[tester] 
AGNewsMetric: acc=0.8306578947368422, hinge=3.8530760283219188, ce=8.51914850335372
Local test acc @ epoch 227: 0.8307
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.2351738238057806e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.98 seconds!
[tester] 
AGNewsMetric: acc=0.848421052631579, hinge=3.4932536491594814, ce=7.891170425415039
Local test acc @ epoch 227: 0.8484
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 1.4901159417490817e-08
Local loss @ local epoch 2: 1.4901149825163884e-07
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.96 seconds!
[tester] 
AGNewsMetric: acc=0.84, hinge=3.6609969861883864, ce=7.83621348832783
Local test acc @ epoch 227: 0.84
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 1.0430805019723266e-07
Local loss @ local epoch 1: 5.9604616353681195e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.9802320611338473e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.35 seconds!
[tester] 
AGNewsMetric: acc=0.8125, hinge=4.253529925597341, ce=8.390465085882889
Local test acc @ epoch 227: 0.8125
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901159417490817e-08
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 2.9802320611338473e-08
Local loss @ local epoch 3: 8.940690321423972e-08
Local loss @ local epoch 4: 2.682206172721635e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.14 seconds!
[tester] 
AGNewsMetric: acc=0.8477631578947369, hinge=3.1265237012662386, ce=7.511882702676873
Local test acc @ epoch 227: 0.8478
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 1.4901159417490817e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 1.1175862368872913e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.26 seconds!
[tester] 
AGNewsMetric: acc=0.8457894736842105, hinge=3.5022328805923464, ce=8.029445671282316
Local test acc @ epoch 227: 0.8458
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 1.2665975646086736e-07
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 1.1175863079415649e-07
Local loss @ local epoch 3: 5.215405352032576e-08
Local loss @ local epoch 4: 2.3841815277592104e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.12 seconds!
[tester] 
AGNewsMetric: acc=0.8027631578947368, hinge=4.35900731814535, ce=8.636116461502878
Local test acc @ epoch 227: 0.8028
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 1.4901159417490817e-08
Local loss @ local epoch 3: 4.4703469370688254e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.47 seconds!
[tester] 
AGNewsMetric: acc=0.8431578947368421, hinge=3.6088628811585277, ce=7.7278216532657025
Local test acc @ epoch 227: 0.8432
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.9802318834981634e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.4901159417490817e-08
Local loss @ local epoch 4: 1.221883280777547e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.9 seconds!
[tester] 
AGNewsMetric: acc=0.8389473684210527, hinge=3.7629756726716694, ce=7.976764924902665
Local test acc @ epoch 227: 0.8389
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 2.2351738238057806e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 3.7252892326478104e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.7 seconds!
[tester] 
AGNewsMetric: acc=0.8378947368421052, hinge=3.7620716431266383, ce=8.010702428315815
Local test acc @ epoch 227: 0.8379
Global evaluate on test data...
Evaluate data in 130.8 seconds!
[tester] 
AGNewsMetric: acc=0.8421052631578947, hinge=3.6660081704039325, ce=7.93212225462261
Global test acc @ epoch 227: 0.8421
Global epoch 228...
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 4.470347292340193e-08
Local loss @ local epoch 1: 3.874290257499524e-07
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 2.3841815277592104e-07
Local loss @ local epoch 4: 2.9802318834981634e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.19 seconds!
[tester] 
AGNewsMetric: acc=0.8486842105263158, hinge=3.3921054857655575, ce=7.304680801190828
Local test acc @ epoch 228: 0.8487
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 4.470347647611561e-08
Local loss @ local epoch 3: 2.2351740014414645e-08
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.06 seconds!
[tester] 
AGNewsMetric: acc=0.8378947368421052, hinge=3.8319415059842563, ce=8.24208872544138
Local test acc @ epoch 228: 0.8379
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 2.2351740014414645e-08
Local loss @ local epoch 1: 7.152521561692993e-07
Local loss @ local epoch 2: 9.83471068138897e-07
Local loss @ local epoch 3: 2.369255298617645e-06
Local loss @ local epoch 4: 1.1813006401062012
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.98 seconds!
[tester] 
AGNewsMetric: acc=0.8344736842105264, hinge=3.431868053862923, ce=7.491212422220331
Local test acc @ epoch 228: 0.8345
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.37 seconds!
[tester] 
AGNewsMetric: acc=0.8471052631578947, hinge=3.5176233469812495, ce=7.906367418389571
Local test acc @ epoch 228: 0.8471
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.92 seconds!
[tester] 
AGNewsMetric: acc=0.8419736842105263, hinge=3.618146976420754, ce=7.981175026140715
Local test acc @ epoch 228: 0.842
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901159417490817e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.607697808798548e-07
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 4.4703469370688254e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.31 seconds!
[tester] 
AGNewsMetric: acc=0.7753947368421052, hinge=5.370051252967433, ce=8.657078518114592
Local test acc @ epoch 228: 0.7754
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 3.725289943190546e-08
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.8 seconds!
[tester] 
AGNewsMetric: acc=0.7969736842105263, hinge=4.806362144821569, ce=8.532933070534154
Local test acc @ epoch 228: 0.797
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 2.9802318834981634e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.639126594454865e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.57 seconds!
[tester] 
AGNewsMetric: acc=0.848421052631579, hinge=3.570039005279541, ce=8.180202363666735
Local test acc @ epoch 228: 0.8484
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 5.2154042862184724e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.378343199576193e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.82 seconds!
[tester] 
AGNewsMetric: acc=0.7953947368421053, hinge=4.863011241461101, ce=8.605055529945774
Local test acc @ epoch 228: 0.7954
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 3.725289587919178e-08
Local loss @ local epoch 2: 2.8312146582720743e-07
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.0430805019723266e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.69 seconds!
[tester] 
AGNewsMetric: acc=0.7968421052631579, hinge=4.847713513123361, ce=9.026534538269043
Local test acc @ epoch 228: 0.7968
Global evaluate on test data...
Evaluate data in 130.35 seconds!
[tester] 
AGNewsMetric: acc=0.8447368421052631, hinge=3.668881963930632, ce=7.782235273060046
Global test acc @ epoch 228: 0.8447
Global epoch 229...
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 6.556477387675841e-07
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.24 seconds!
[tester] 
AGNewsMetric: acc=0.8011842105263158, hinge=4.374924605018214, ce=8.773308474892064
Local test acc @ epoch 229: 0.8012
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.0058203088192386e-06
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 1.030493140220642
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.83 seconds!
[tester] 
AGNewsMetric: acc=0.8192105263157895, hinge=4.227852087773774, ce=8.81639909242329
Local test acc @ epoch 229: 0.8192
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 7.897566547399038e-07
Local loss @ local epoch 2: 0.1893516480922699
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 0.5939902067184448
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.03 seconds!
[tester] 
AGNewsMetric: acc=0.790921052631579, hinge=4.443237328780325, ce=8.450258078324167
Local test acc @ epoch 229: 0.7909
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 1.0430806440808738e-07
Local loss @ local epoch 1: 4.470347292340193e-08
Local loss @ local epoch 2: 1.4901159417490817e-08
Local loss @ local epoch 3: 3.7252892326478104e-08
Local loss @ local epoch 4: 5.9604616353681195e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.06 seconds!
[tester] 
AGNewsMetric: acc=0.8293421052631579, hinge=4.082972424406754, ce=8.285109058179353
Local test acc @ epoch 229: 0.8293
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 3.7252892326478104e-08
Local loss @ local epoch 1: 2.9802318834981634e-08
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 2.2351740014414645e-08
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.43 seconds!
[tester] 
AGNewsMetric: acc=0.7685526315789474, hinge=5.477485535521256, ce=9.252801973443283
Local test acc @ epoch 229: 0.7686
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.4901159417490817e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 2.2351740014414645e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.97 seconds!
[tester] 
AGNewsMetric: acc=0.8430263157894737, hinge=3.645272142259698, ce=7.895738243303801
Local test acc @ epoch 229: 0.843
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.62 seconds!
[tester] 
AGNewsMetric: acc=0.8389473684210527, hinge=3.7858579956857783, ce=7.965316594776354
Local test acc @ epoch 229: 0.8389
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.4901159417490817e-08
Local loss @ local epoch 3: 1.9956918549723923e-05
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.1 seconds!
[tester] 
AGNewsMetric: acc=0.7989473684210526, hinge=4.590355495904621, ce=8.599694403598184
Local test acc @ epoch 229: 0.7989
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 2.9802318834981634e-08
Local loss @ local epoch 1: 9.685751933830034e-08
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 2.2351738238057806e-08
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.62 seconds!
[tester] 
AGNewsMetric: acc=0.8303947368421053, hinge=3.7933132156572844, ce=7.7822277380290785
Local test acc @ epoch 229: 0.8304
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 2.9802318834981634e-08
Local loss @ local epoch 1: 5.215404996761208e-08
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 131.35 seconds!
[tester] 
AGNewsMetric: acc=0.8523684210526316, hinge=3.396308711955422, ce=7.803846358249062
Local test acc @ epoch 229: 0.8524
Global evaluate on test data...
Evaluate data in 129.95 seconds!
[tester] 
AGNewsMetric: acc=0.8388157894736842, hinge=3.8052090280934383, ce=7.956960598795037
Global test acc @ epoch 229: 0.8388
Global epoch 230...
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 5.215405352032576e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.17 seconds!
[tester] 
AGNewsMetric: acc=0.8423684210526315, hinge=3.7170249125832004, ce=8.009617767333985
Local test acc @ epoch 230: 0.8424
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.4901159417490817e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.2351738238057806e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.9 seconds!
[tester] 
AGNewsMetric: acc=0.8405263157894737, hinge=3.731651938338029, ce=7.946644244946931
Local test acc @ epoch 230: 0.8405
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.3 seconds!
[tester] 
AGNewsMetric: acc=0.8393421052631579, hinge=3.7873008322715758, ce=7.9362803388896745
Local test acc @ epoch 230: 0.8393
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 8.940691031966708e-08
Local loss @ local epoch 1: 3.7624433844030136e-06
Local loss @ local epoch 2: 6.705520405603238e-08
Local loss @ local epoch 3: 3.799790988523455e-07
Local loss @ local epoch 4: 0.14543724060058594
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.56 seconds!
[tester] 
AGNewsMetric: acc=0.8397368421052631, hinge=3.369351164165296, ce=7.573582861047042
Local test acc @ epoch 230: 0.8397
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 2.9802315282267955e-08
Local loss @ local epoch 4: 1.4901159417490817e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.4 seconds!
[tester] 
AGNewsMetric: acc=0.8392105263157895, hinge=3.785423494138216, ce=7.973200193706312
Local test acc @ epoch 230: 0.8392
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 4.094987525604665e-05
Local loss @ local epoch 1: 6.407470891645062e-07
Local loss @ local epoch 2: 0.9534973502159119
Local loss @ local epoch 3: 0.010231895372271538
Local loss @ local epoch 4: 0.0003325519210193306
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.37 seconds!
[tester] 
AGNewsMetric: acc=0.8580263157894736, hinge=2.359153877810428, ce=7.960325662713302
Local test acc @ epoch 230: 0.858
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.4901159417490817e-08
Local loss @ local epoch 3: 0.06709255278110504
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.56 seconds!
[tester] 
AGNewsMetric: acc=0.8144736842105263, hinge=4.067964511043147, ce=8.742935787000155
Local test acc @ epoch 230: 0.8145
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 2.9802318834981634e-08
Local loss @ local epoch 1: 2.6822036147677863e-07
Local loss @ local epoch 2: 2.9802320611338473e-08
Local loss @ local epoch 3: 9.238656843990611e-07
Local loss @ local epoch 4: 5.215405707303944e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.13 seconds!
[tester] 
AGNewsMetric: acc=0.8207894736842105, hinge=4.0026881335911, ce=8.691938872086375
Local test acc @ epoch 230: 0.8208
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 5.215405707303944e-08
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 1.4901159417490817e-08
Local loss @ local epoch 3: 7.450579175838357e-08
Local loss @ local epoch 4: 2.9802318834981634e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.27 seconds!
[tester] 
AGNewsMetric: acc=0.825921052631579, hinge=4.145953334005255, ce=8.030106958088123
Local test acc @ epoch 230: 0.8259
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.95 seconds!
[tester] 
AGNewsMetric: acc=0.8380263157894737, hinge=3.8076429835118746, ce=8.013607024142617
Local test acc @ epoch 230: 0.838
Global evaluate on test data...
Evaluate data in 130.1 seconds!
[tester] 
AGNewsMetric: acc=0.8531578947368421, hinge=3.43467224346964, ce=7.686947033530787
Global test acc @ epoch 230: 0.8532
Global epoch 231...
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 4.619343485501304e-07
Local loss @ local epoch 1: 2.9802318834981634e-08
Local loss @ local epoch 2: 1.2740448482873035e-06
Local loss @ local epoch 3: 6.780007879569894e-07
Local loss @ local epoch 4: 1.0877811291720718e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.77 seconds!
[tester] 
AGNewsMetric: acc=0.8035526315789474, hinge=3.8449329044944363, ce=8.157793209678248
Local test acc @ epoch 231: 0.8036
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 1.4901159417490817e-08
Local loss @ local epoch 3: 2.2351740014414645e-08
Local loss @ local epoch 4: 2.2351740014414645e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.06 seconds!
[tester] 
AGNewsMetric: acc=0.8532894736842105, hinge=3.439874398833827, ce=7.829800205230713
Local test acc @ epoch 231: 0.8533
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 2.2351740014414645e-08
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 1.4901159417490817e-08
Local loss @ local epoch 4: 1.4901159417490817e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.8 seconds!
[tester] 
AGNewsMetric: acc=0.829078947368421, hinge=4.033828841761538, ce=8.226002721284566
Local test acc @ epoch 231: 0.8291
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901159417490817e-08
Local loss @ local epoch 1: 3.7252892326478104e-08
Local loss @ local epoch 2: 2.9802318834981634e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.27 seconds!
[tester] 
AGNewsMetric: acc=0.8503947368421053, hinge=3.490336933386953, ce=7.8067215527986225
Local test acc @ epoch 231: 0.8504
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901159417490817e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 4.470347647611561e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.34 seconds!
[tester] 
AGNewsMetric: acc=0.8403947368421053, hinge=3.764318157999139, ce=7.92873769258198
Local test acc @ epoch 231: 0.8404
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 4.470347292340193e-08
Local loss @ local epoch 1: 3.725289943190546e-08
Local loss @ local epoch 2: 5.215405707303944e-08
Local loss @ local epoch 3: 3.725289943190546e-08
Local loss @ local epoch 4: 1.4901159417490817e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.62 seconds!
[tester] 
AGNewsMetric: acc=0.8331578947368421, hinge=3.939022476296676, ce=8.209512873197857
Local test acc @ epoch 231: 0.8332
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 2.2351738238057806e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.41 seconds!
[tester] 
AGNewsMetric: acc=0.8507894736842105, hinge=3.469505760293258, ce=7.779812660217285
Local test acc @ epoch 231: 0.8508
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 8.195636524988004e-08
Local loss @ local epoch 2: 2.2351738238057806e-08
Local loss @ local epoch 3: 1.4901159417490817e-08
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.21 seconds!
[tester] 
AGNewsMetric: acc=0.7660526315789473, hinge=5.42037856980374, ce=9.26284712942023
Local test acc @ epoch 231: 0.7661
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 2.9802315282267955e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 2.831215510923357e-07
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.76 seconds!
[tester] 
AGNewsMetric: acc=0.8492105263157895, hinge=3.4481191941311486, ce=7.678997331920423
Local test acc @ epoch 231: 0.8492
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 2.2351740014414645e-08
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 2.2351738238057806e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.27 seconds!
[tester] 
AGNewsMetric: acc=0.8339473684210527, hinge=3.938667293975228, ce=7.735277423858642
Local test acc @ epoch 231: 0.8339
Global evaluate on test data...
Evaluate data in 129.94 seconds!
[tester] 
AGNewsMetric: acc=0.8406578947368422, hinge=3.7408902200899625, ce=7.87793048657869
Global test acc @ epoch 231: 0.8407
Global epoch 232...
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.6449010874785017e-06
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.06 seconds!
[tester] 
AGNewsMetric: acc=0.6993421052631579, hinge=6.90301118850708, ce=10.457495273790862
Local test acc @ epoch 232: 0.6993
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.49 seconds!
[tester] 
AGNewsMetric: acc=0.8421052631578947, hinge=3.7184272219005385, ce=7.877761078884727
Local test acc @ epoch 232: 0.8421
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 2.9802315282267955e-08
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 3.725289943190546e-08
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.93 seconds!
[tester] 
AGNewsMetric: acc=0.8321052631578948, hinge=3.811894241383201, ce=8.287742913898668
Local test acc @ epoch 232: 0.8321
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 131.18 seconds!
[tester] 
AGNewsMetric: acc=0.8444736842105263, hinge=3.625304260504873, ce=7.887699346040424
Local test acc @ epoch 232: 0.8445
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 2.2351740014414645e-08
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.14 seconds!
[tester] 
AGNewsMetric: acc=0.8273684210526315, hinge=4.159969117264999, ce=8.34673994967812
Local test acc @ epoch 232: 0.8274
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 4.4703469370688254e-08
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.5 seconds!
[tester] 
AGNewsMetric: acc=0.8346052631578947, hinge=3.7588625260403283, ce=7.846050050635087
Local test acc @ epoch 232: 0.8346
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 2.6076983772327367e-07
Local loss @ local epoch 1: 2.2351740014414645e-08
Local loss @ local epoch 2: 2.9802320611338473e-08
Local loss @ local epoch 3: 5.215396754465473e-07
Local loss @ local epoch 4: 0.0006264551775529981
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.29 seconds!
[tester] 
AGNewsMetric: acc=0.7869736842105263, hinge=4.2677453876796525, ce=8.161485700105366
Local test acc @ epoch 232: 0.787
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 2.9802318834981634e-08
Local loss @ local epoch 1: 4.470347647611561e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 2.2351740014414645e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 131.03 seconds!
[tester] 
AGNewsMetric: acc=0.8419736842105263, hinge=3.644139316207484, ce=7.886059003127249
Local test acc @ epoch 232: 0.842
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 1.4901159417490817e-08
Local loss @ local epoch 4: 7.450579175838357e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.29 seconds!
[tester] 
AGNewsMetric: acc=0.8356578947368422, hinge=3.7945542977985585, ce=8.03201066167731
Local test acc @ epoch 232: 0.8357
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.99 seconds!
[tester] 
AGNewsMetric: acc=0.8475, hinge=3.4894857582293057, ce=7.973044947574013
Local test acc @ epoch 232: 0.8475
Global evaluate on test data...
Evaluate data in 130.3 seconds!
[tester] 
AGNewsMetric: acc=0.841842105263158, hinge=3.7073655223846433, ce=7.871727254767167
Global test acc @ epoch 232: 0.8418
Global epoch 233...
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 1.7881369274164172e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 2.1606646782856842e-07
Local loss @ local epoch 4: 8.195635814445268e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.55 seconds!
[tester] 
AGNewsMetric: acc=0.8510526315789474, hinge=3.0648472133435702, ce=8.964608722485995
Local test acc @ epoch 233: 0.8511
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0002896323858294636
Local loss @ local epoch 1: 0.0001378970337100327
Local loss @ local epoch 2: 1.2539904117584229
Local loss @ local epoch 3: 5.2971554396208376e-06
Local loss @ local epoch 4: 0.00027336226776242256
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.84 seconds!
[tester] 
AGNewsMetric: acc=0.7676315789473684, hinge=5.058302384175752, ce=8.751330753125643
Local test acc @ epoch 233: 0.7676
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 2.9802315282267955e-08
Local loss @ local epoch 1: 2.607699514101114e-07
Local loss @ local epoch 2: 0.0008669145172461867
Local loss @ local epoch 3: 3.725289587919178e-08
Local loss @ local epoch 4: 2.6449072265677387e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.56 seconds!
[tester] 
AGNewsMetric: acc=0.7359210526315789, hinge=5.6060274237080625, ce=9.850679273103413
Local test acc @ epoch 233: 0.7359
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.2040175348520279
Local loss @ local epoch 1: 6.40746748103993e-07
Local loss @ local epoch 2: 0.7191230058670044
Local loss @ local epoch 3: 0.05840494483709335
Local loss @ local epoch 4: 0.9244061708450317
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.17 seconds!
[tester] 
AGNewsMetric: acc=0.7521052631578947, hinge=4.497041524585924, ce=9.804793365880062
Local test acc @ epoch 233: 0.7521
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 2.2351740014414645e-08
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.52 seconds!
[tester] 
AGNewsMetric: acc=0.845, hinge=3.5982469696747628, ce=7.899639441841527
Local test acc @ epoch 233: 0.845
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 6.705519695060502e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.9 seconds!
[tester] 
AGNewsMetric: acc=0.8409210526315789, hinge=3.730352019008837, ce=7.893933969798841
Local test acc @ epoch 233: 0.8409
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.008799780160188675
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0001357585861114785
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.18 seconds!
[tester] 
AGNewsMetric: acc=0.8119736842105263, hinge=3.785303593309302, ce=8.579839674297132
Local test acc @ epoch 233: 0.812
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 2.9802318834981634e-08
Local loss @ local epoch 1: 2.2351738238057806e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 2.2351740014414645e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.18 seconds!
[tester] 
AGNewsMetric: acc=0.8213157894736842, hinge=4.279726895031176, ce=8.555008878205951
Local test acc @ epoch 233: 0.8213
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 8.195632972274325e-08
Local loss @ local epoch 1: 6.705521116145974e-08
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 1.1920921849650767e-07
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.37 seconds!
[tester] 
AGNewsMetric: acc=0.8225, hinge=4.197059080475255, ce=8.13503208762721
Local test acc @ epoch 233: 0.8225
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 1.4901159417490817e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.03 seconds!
[tester] 
AGNewsMetric: acc=0.8278947368421052, hinge=4.052629178950661, ce=8.106550023932206
Local test acc @ epoch 233: 0.8279
Global evaluate on test data...
Evaluate data in 129.99 seconds!
[tester] 
AGNewsMetric: acc=0.8415789473684211, hinge=3.7192479339398834, ce=7.949392486371492
Global test acc @ epoch 233: 0.8416
Global epoch 234...
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.2351740014414645e-08
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.43 seconds!
[tester] 
AGNewsMetric: acc=0.8432894736842105, hinge=3.649669690634075, ce=8.026694779647023
Local test acc @ epoch 234: 0.8433
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.59 seconds!
[tester] 
AGNewsMetric: acc=0.8488157894736842, hinge=3.515046702435142, ce=8.07616694801732
Local test acc @ epoch 234: 0.8488
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 2.9802318834981634e-08
Local loss @ local epoch 4: 8.195632972274325e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.44 seconds!
[tester] 
AGNewsMetric: acc=0.8455263157894737, hinge=3.5889310983607645, ce=7.858203698208458
Local test acc @ epoch 234: 0.8455
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 2.2351740014414645e-08
Local loss @ local epoch 1: 1.4901159417490817e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.09 seconds!
[tester] 
AGNewsMetric: acc=0.8351315789473684, hinge=3.887588845554151, ce=8.352546316448011
Local test acc @ epoch 234: 0.8351
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 5.2154042862184724e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.07 seconds!
[tester] 
AGNewsMetric: acc=0.8425, hinge=3.66426621010429, ce=7.934906597137451
Local test acc @ epoch 234: 0.8425
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901159417490817e-08
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 131.1 seconds!
[tester] 
AGNewsMetric: acc=0.8386842105263158, hinge=3.8475671170887193, ce=8.046236975820442
Local test acc @ epoch 234: 0.8387
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.2351740014414645e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.43 seconds!
[tester] 
AGNewsMetric: acc=0.8380263157894737, hinge=3.7291482330623427, ce=8.1061197491696
Local test acc @ epoch 234: 0.838
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 3.352753878971271e-07
Local loss @ local epoch 1: 5.2154042862184724e-08
Local loss @ local epoch 2: 6.929021196810936e-07
Local loss @ local epoch 3: 8.19563723553074e-08
Local loss @ local epoch 4: 3.032339009223506e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.58 seconds!
[tester] 
AGNewsMetric: acc=0.8432894736842105, hinge=3.4599436684658653, ce=7.767013460460462
Local test acc @ epoch 234: 0.8433
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.83 seconds!
[tester] 
AGNewsMetric: acc=0.8396052631578947, hinge=3.7067472779123407, ce=8.016935460943925
Local test acc @ epoch 234: 0.8396
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.9802315282267955e-08
Local loss @ local epoch 3: 1.1920917586394353e-07
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.81 seconds!
[tester] 
AGNewsMetric: acc=0.8326315789473684, hinge=3.9942663953178807, ce=8.459353405801874
Local test acc @ epoch 234: 0.8326
Global evaluate on test data...
Evaluate data in 130.09 seconds!
[tester] 
AGNewsMetric: acc=0.8444736842105263, hinge=3.660403895754563, ce=7.9804801378752055
Global test acc @ epoch 234: 0.8445
Global epoch 235...
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.29 seconds!
[tester] 
AGNewsMetric: acc=0.8409210526315789, hinge=3.710363397096333, ce=8.093058884269313
Local test acc @ epoch 235: 0.8409
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 5.2154042862184724e-08
Local loss @ local epoch 1: 2.6076980930156424e-07
Local loss @ local epoch 2: 1.7657627040534862e-06
Local loss @ local epoch 3: 2.1606669520224386e-07
Local loss @ local epoch 4: 3.0064125061035156
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.92 seconds!
[tester] 
AGNewsMetric: acc=0.7481578947368421, hinge=6.0629448017321135, ce=9.399670084903114
Local test acc @ epoch 235: 0.7482
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 2.2351740014414645e-08
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.23 seconds!
[tester] 
AGNewsMetric: acc=0.845, hinge=3.614532585896944, ce=8.154638586546245
Local test acc @ epoch 235: 0.845
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.9802315282267955e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.58 seconds!
[tester] 
AGNewsMetric: acc=0.8442105263157895, hinge=3.7216978818491886, ce=8.055696978318064
Local test acc @ epoch 235: 0.8442
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 4.470347292340193e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.45 seconds!
[tester] 
AGNewsMetric: acc=0.8110526315789474, hinge=4.432147333245529, ce=8.758029473957263
Local test acc @ epoch 235: 0.8111
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901159417490817e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 6.705518984517767e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.28 seconds!
[tester] 
AGNewsMetric: acc=0.8480263157894737, hinge=3.557283994398619, ce=8.465753025255705
Local test acc @ epoch 235: 0.848
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.9802320611338473e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 132.61 seconds!
[tester] 
AGNewsMetric: acc=0.8414473684210526, hinge=3.66599330952293, ce=8.014016142393414
Local test acc @ epoch 235: 0.8414
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.58 seconds!
[tester] 
AGNewsMetric: acc=0.8443421052631579, hinge=3.58319896660353, ce=7.926116142272949
Local test acc @ epoch 235: 0.8443
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 1.1175862368872913e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 9.685753354915505e-08
Local loss @ local epoch 3: 4.470347647611561e-08
Local loss @ local epoch 4: 5.803866770293098e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.13 seconds!
[tester] 
AGNewsMetric: acc=0.8047368421052632, hinge=4.3741591262817385, ce=8.558242786809018
Local test acc @ epoch 235: 0.8047
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 2.2351738238057806e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.98 seconds!
[tester] 
AGNewsMetric: acc=0.8426315789473684, hinge=3.6893984433224327, ce=8.03952236175537
Local test acc @ epoch 235: 0.8426
Global evaluate on test data...
Evaluate data in 129.81 seconds!
[tester] 
AGNewsMetric: acc=0.835, hinge=3.91302032031511, ce=8.201452732086182
Global test acc @ epoch 235: 0.835
Global epoch 236...
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.2665975646086736e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.33 seconds!
[tester] 
AGNewsMetric: acc=0.8356578947368422, hinge=3.832304248056914, ce=8.120041051161916
Local test acc @ epoch 236: 0.8357
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.25 seconds!
[tester] 
AGNewsMetric: acc=0.8338157894736842, hinge=3.885899939788015, ce=8.229015544088263
Local test acc @ epoch 236: 0.8338
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.63 seconds!
[tester] 
AGNewsMetric: acc=0.8205263157894737, hinge=4.2972642717863385, ce=8.671284278066535
Local test acc @ epoch 236: 0.8205
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.35 seconds!
[tester] 
AGNewsMetric: acc=0.8322368421052632, hinge=3.949330043792725, ce=8.273752814845034
Local test acc @ epoch 236: 0.8322
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 5.215404996761208e-08
Local loss @ local epoch 3: 8.940690321423972e-08
Local loss @ local epoch 4: 2.533192287046404e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.14 seconds!
[tester] 
AGNewsMetric: acc=0.8323684210526315, hinge=3.8839687628495065, ce=8.349781715995388
Local test acc @ epoch 236: 0.8324
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.1101266181867686e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 131.22 seconds!
[tester] 
AGNewsMetric: acc=0.84, hinge=3.726140936299374, ce=8.352005651373613
Local test acc @ epoch 236: 0.84
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 3.725289943190546e-08
Local loss @ local epoch 2: 2.2351740014414645e-08
Local loss @ local epoch 3: 4.4703469370688254e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.35 seconds!
[tester] 
AGNewsMetric: acc=0.8309210526315789, hinge=3.8869133325626977, ce=8.142308345593904
Local test acc @ epoch 236: 0.8309
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901159417490817e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 5.215405707303944e-08
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.72 seconds!
[tester] 
AGNewsMetric: acc=0.8293421052631579, hinge=3.9698043174492685, ce=8.447642156701338
Local test acc @ epoch 236: 0.8293
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.9802318834981634e-08
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 2.2351740014414645e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.04 seconds!
[tester] 
AGNewsMetric: acc=0.8414473684210526, hinge=3.6924165273967544, ce=8.10748378352115
Local test acc @ epoch 236: 0.8414
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.32 seconds!
[tester] 
AGNewsMetric: acc=0.8355263157894737, hinge=3.8787238020645947, ce=8.198457906622636
Local test acc @ epoch 236: 0.8355
Global evaluate on test data...
Evaluate data in 129.92 seconds!
[tester] 
AGNewsMetric: acc=0.8367105263157895, hinge=3.823166812846535, ce=8.21225927453292
Global test acc @ epoch 236: 0.8367
Global epoch 237...
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.2351740014414645e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.4901159417490817e-08
Local loss @ local epoch 4: 5.9604616353681195e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.23 seconds!
[tester] 
AGNewsMetric: acc=0.8142105263157895, hinge=4.28042793826053, ce=8.683258946067408
Local test acc @ epoch 237: 0.8142
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 8.940692453052179e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 2.2351721895574883e-07
Local loss @ local epoch 4: 2.2351740014414645e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.57 seconds!
[tester] 
AGNewsMetric: acc=0.8359210526315789, hinge=3.9168532313798603, ce=8.724139600051076
Local test acc @ epoch 237: 0.8359
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 2.9802320611338473e-08
Local loss @ local epoch 2: 1.4901159417490817e-08
Local loss @ local epoch 3: 2.9802318834981634e-08
Local loss @ local epoch 4: 2.2351740014414645e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.78 seconds!
[tester] 
AGNewsMetric: acc=0.8357894736842105, hinge=3.604025712013245, ce=8.212846299221642
Local test acc @ epoch 237: 0.8358
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 2.9802318834981634e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.49 seconds!
[tester] 
AGNewsMetric: acc=0.8385526315789473, hinge=3.764517516085976, ce=8.130291948820416
Local test acc @ epoch 237: 0.8386
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 1.4901159417490817e-08
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.69 seconds!
[tester] 
AGNewsMetric: acc=0.8311842105263157, hinge=3.95638143840589, ce=8.456322977166426
Local test acc @ epoch 237: 0.8312
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 4.4703469370688254e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.43 seconds!
[tester] 
AGNewsMetric: acc=0.8353947368421053, hinge=3.8937462964810825, ce=8.255905366194876
Local test acc @ epoch 237: 0.8354
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 4.470347292340193e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.9802315282267955e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.87 seconds!
[tester] 
AGNewsMetric: acc=0.84, hinge=3.8410916875538073, ce=8.223185516156649
Local test acc @ epoch 237: 0.84
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 2.2351740014414645e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 3.725289587919178e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.9802315282267955e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.4 seconds!
[tester] 
AGNewsMetric: acc=0.8357894736842105, hinge=3.823861104061729, ce=8.450538981588263
Local test acc @ epoch 237: 0.8358
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 2.2351738238057806e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.4901159417490817e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.43 seconds!
[tester] 
AGNewsMetric: acc=0.8425, hinge=3.6634215959749725, ce=8.065759034407765
Local test acc @ epoch 237: 0.8425
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.9802315282267955e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.4156093186556973e-07
Local loss @ local epoch 4: 2.8758579446730437e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.24 seconds!
[tester] 
AGNewsMetric: acc=0.8248684210526316, hinge=4.079565481386687, ce=8.23217226229216
Local test acc @ epoch 237: 0.8249
Global evaluate on test data...
Evaluate data in 129.42 seconds!
[tester] 
AGNewsMetric: acc=0.841842105263158, hinge=3.722049305313512, ce=8.165787694830643
Global test acc @ epoch 237: 0.8418
Global epoch 238...
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 2.2351740014414645e-08
Local loss @ local epoch 3: 6.705521116145974e-08
Local loss @ local epoch 4: 0.012444021180272102
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.92 seconds!
[tester] 
AGNewsMetric: acc=0.8397368421052631, hinge=3.8101929232948706, ce=8.256914767215127
Local test acc @ epoch 238: 0.8397
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.94 seconds!
[tester] 
AGNewsMetric: acc=0.8411842105263158, hinge=3.6983761270422684, ce=8.062873117547285
Local test acc @ epoch 238: 0.8412
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.63 seconds!
[tester] 
AGNewsMetric: acc=0.8409210526315789, hinge=3.6953843168208476, ce=8.182640262402986
Local test acc @ epoch 238: 0.8409
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 2.9802315282267955e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 3.687930302476161e-06
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.5258064270019531
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.49 seconds!
[tester] 
AGNewsMetric: acc=0.7869736842105263, hinge=4.732014953462701, ce=9.194608887120298
Local test acc @ epoch 238: 0.787
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 131.04 seconds!
[tester] 
AGNewsMetric: acc=0.8419736842105263, hinge=3.7177764142187018, ce=8.244249194295783
Local test acc @ epoch 238: 0.842
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 3.725289943190546e-08
Local loss @ local epoch 2: 2.9802318834981634e-08
Local loss @ local epoch 3: 2.9802318834981634e-08
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.77 seconds!
[tester] 
AGNewsMetric: acc=0.8227631578947369, hinge=4.085864814457141, ce=8.443279540413304
Local test acc @ epoch 238: 0.8228
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901159417490817e-08
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 2.384183801495965e-07
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 2.7567094207370246e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.92 seconds!
[tester] 
AGNewsMetric: acc=0.8347368421052631, hinge=3.7916206691139624, ce=8.179977426026996
Local test acc @ epoch 238: 0.8347
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901159417490817e-08
Local loss @ local epoch 1: 1.3364920050662477e-05
Local loss @ local epoch 2: 0.00017800887871999294
Local loss @ local epoch 3: 1.0430808572436945e-07
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.93 seconds!
[tester] 
AGNewsMetric: acc=0.7797368421052632, hinge=4.909250028258875, ce=8.49829397703472
Local test acc @ epoch 238: 0.7797
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 6.705519695060502e-08
Local loss @ local epoch 3: 4.4703469370688254e-08
Local loss @ local epoch 4: 2.9802318834981634e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.38 seconds!
[tester] 
AGNewsMetric: acc=0.8396052631578947, hinge=3.8007669973373415, ce=8.208086823915181
Local test acc @ epoch 238: 0.8396
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 1.4901159417490817e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.9802318834981634e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.01 seconds!
[tester] 
AGNewsMetric: acc=0.8394736842105263, hinge=3.7386792737559267, ce=8.211806477998433
Local test acc @ epoch 238: 0.8395
Global evaluate on test data...
Evaluate data in 130.36 seconds!
[tester] 
AGNewsMetric: acc=0.835, hinge=3.927436576642488, ce=8.197554789091411
Global test acc @ epoch 238: 0.835
Global epoch 239...
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.14 seconds!
[tester] 
AGNewsMetric: acc=0.8302631578947368, hinge=3.9329474836901617, ce=8.343997321881746
Local test acc @ epoch 239: 0.8303
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.97 seconds!
[tester] 
AGNewsMetric: acc=0.8303947368421053, hinge=3.999028986629687, ce=8.3727145205046
Local test acc @ epoch 239: 0.8304
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 1.4901159417490817e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.1920917586394353e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.94 seconds!
[tester] 
AGNewsMetric: acc=0.8343421052631579, hinge=3.876615642497414, ce=8.464498102288497
Local test acc @ epoch 239: 0.8343
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 4.2468184346944327e-07
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.2351740014414645e-08
Local loss @ local epoch 4: 1.0245026350021362
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.96 seconds!
[tester] 
AGNewsMetric: acc=0.8265789473684211, hinge=3.983989285167895, ce=8.73603001644737
Local test acc @ epoch 239: 0.8266
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 5.215404996761208e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.6391260260206764e-07
Local loss @ local epoch 3: 8.195636524988004e-08
Local loss @ local epoch 4: 2.2351711947976582e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 131.04 seconds!
[tester] 
AGNewsMetric: acc=0.7873684210526316, hinge=5.4006416052266175, ce=8.971417501349197
Local test acc @ epoch 239: 0.7874
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.47 seconds!
[tester] 
AGNewsMetric: acc=0.8346052631578947, hinge=3.9596050071716307, ce=8.27241354590968
Local test acc @ epoch 239: 0.8346
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.011653492672849e-07
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 2.9802318834981634e-08
Local loss @ local epoch 4: 4.470347647611561e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 131.03 seconds!
[tester] 
AGNewsMetric: acc=0.8307894736842105, hinge=3.7124793833180476, ce=8.761614666988976
Local test acc @ epoch 239: 0.8308
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.24 seconds!
[tester] 
AGNewsMetric: acc=0.8298684210526316, hinge=3.976464621142337, ce=8.37580541510331
Local test acc @ epoch 239: 0.8299
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 2.9802315282267955e-08
Local loss @ local epoch 3: 2.9802318834981634e-08
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.26 seconds!
[tester] 
AGNewsMetric: acc=0.8367105263157895, hinge=3.8219393541938382, ce=8.142579506321956
Local test acc @ epoch 239: 0.8367
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.53 seconds!
[tester] 
AGNewsMetric: acc=0.8339473684210527, hinge=3.889680145665219, ce=8.233418742731997
Local test acc @ epoch 239: 0.8339
Global evaluate on test data...
Evaluate data in 129.6 seconds!
[tester] 
AGNewsMetric: acc=0.8353947368421053, hinge=3.9250058056178845, ce=8.272457787363154
Global test acc @ epoch 239: 0.8354
Global epoch 240...
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 1.2665974225001264e-07
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 2.2351740014414645e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.76 seconds!
[tester] 
AGNewsMetric: acc=0.8332894736842106, hinge=3.806088879986813, ce=7.8605084860952275
Local test acc @ epoch 240: 0.8333
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 4.470347647611561e-08
Local loss @ local epoch 2: 1.2665975646086736e-07
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.65 seconds!
[tester] 
AGNewsMetric: acc=0.7753947368421052, hinge=5.176273773343939, ce=9.686880645751954
Local test acc @ epoch 240: 0.7754
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.96 seconds!
[tester] 
AGNewsMetric: acc=0.8405263157894737, hinge=3.7978918339076797, ce=8.134100631914642
Local test acc @ epoch 240: 0.8405
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 2.2351740014414645e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.71 seconds!
[tester] 
AGNewsMetric: acc=0.828421052631579, hinge=4.146135088770013, ce=8.508164560418379
Local test acc @ epoch 240: 0.8284
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.4901159417490817e-08
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 1.1920917586394353e-07
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.57 seconds!
[tester] 
AGNewsMetric: acc=0.8323684210526315, hinge=4.014388455340737, ce=8.266697526229056
Local test acc @ epoch 240: 0.8324
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.1382807062764186e-06
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.73 seconds!
[tester] 
AGNewsMetric: acc=0.7890789473684211, hinge=5.2192824835526315, ce=8.97040661862022
Local test acc @ epoch 240: 0.7891
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 5.2154042862184724e-08
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.1457308321259916e-06
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.05 seconds!
[tester] 
AGNewsMetric: acc=0.7772368421052631, hinge=5.204179734179848, ce=9.464400692989951
Local test acc @ epoch 240: 0.7772
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 2.9802318834981634e-08
Local loss @ local epoch 1: 4.4703469370688254e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.5643802285194397
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.93 seconds!
[tester] 
AGNewsMetric: acc=0.84, hinge=3.615006381586978, ce=8.357548611289577
Local test acc @ epoch 240: 0.84
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.4901159417490817e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.18 seconds!
[tester] 
AGNewsMetric: acc=0.8389473684210527, hinge=3.7641726107346383, ce=8.307853416643646
Local test acc @ epoch 240: 0.8389
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 1.0243708857160527e-05
Local loss @ local epoch 4: 5.2154042862184724e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.44 seconds!
[tester] 
AGNewsMetric: acc=0.6413157894736842, hinge=8.994788123682925, ce=12.190677458110608
Local test acc @ epoch 240: 0.6413
Global evaluate on test data...
Evaluate data in 130.44 seconds!
[tester] 
AGNewsMetric: acc=0.8325, hinge=4.018211976352491, ce=8.359860805712248
Global test acc @ epoch 240: 0.8325
Global epoch 241...
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 3.7252892326478104e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.76 seconds!
[tester] 
AGNewsMetric: acc=0.8301315789473684, hinge=3.9457367300987243, ce=8.268071233849776
Local test acc @ epoch 241: 0.8301
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 2.2351740014414645e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 3.87428997328243e-07
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.1885969340801239
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.75 seconds!
[tester] 
AGNewsMetric: acc=0.8303947368421053, hinge=4.112187174495898, ce=8.152746704503109
Local test acc @ epoch 241: 0.8304
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 2.9802315282267955e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 3.3527547316225537e-07
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.19 seconds!
[tester] 
AGNewsMetric: acc=0.8236842105263158, hinge=3.9089534276410154, ce=8.921777560585424
Local test acc @ epoch 241: 0.8237
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 5.140879579812463e-07
Local loss @ local epoch 1: 2.8460613066272344e-06
Local loss @ local epoch 2: 3.576274423267023e-07
Local loss @ local epoch 3: 0.0027312960010021925
Local loss @ local epoch 4: 8.272821287391707e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.92 seconds!
[tester] 
AGNewsMetric: acc=0.8060526315789474, hinge=4.038522228190773, ce=9.232560097543816
Local test acc @ epoch 241: 0.8061
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.44 seconds!
[tester] 
AGNewsMetric: acc=0.833421052631579, hinge=3.9415368233228985, ce=8.326318386479429
Local test acc @ epoch 241: 0.8334
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.06 seconds!
[tester] 
AGNewsMetric: acc=0.8326315789473684, hinge=3.987718425298992, ce=8.35289070832102
Local test acc @ epoch 241: 0.8326
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 9.685746960030883e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 9.685748381116355e-08
Local loss @ local epoch 4: 2.2351740014414645e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.12 seconds!
[tester] 
AGNewsMetric: acc=0.8315789473684211, hinge=3.7306148591794464, ce=7.988579246119449
Local test acc @ epoch 241: 0.8316
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 2.2351740014414645e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.9802315282267955e-08
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.19 seconds!
[tester] 
AGNewsMetric: acc=0.8319736842105263, hinge=3.9813994366244265, ce=8.587852672777679
Local test acc @ epoch 241: 0.832
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.18 seconds!
[tester] 
AGNewsMetric: acc=0.8331578947368421, hinge=3.948554222960221, ce=8.38170076470626
Local test acc @ epoch 241: 0.8332
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.62 seconds!
[tester] 
AGNewsMetric: acc=0.828421052631579, hinge=4.109655163162633, ce=8.464816707811858
Local test acc @ epoch 241: 0.8284
Global evaluate on test data...
Evaluate data in 130.35 seconds!
[tester] 
AGNewsMetric: acc=0.8365789473684211, hinge=3.8708046639593023, ce=8.259135407899555
Global test acc @ epoch 241: 0.8366
Global epoch 242...
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 1.0430807151351473e-07
Local loss @ local epoch 1: 9.68574909165909e-08
Local loss @ local epoch 2: 1.862644154471127e-07
Local loss @ local epoch 3: 1.9371502446574596e-07
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.13 seconds!
[tester] 
AGNewsMetric: acc=0.8067105263157894, hinge=4.286801740997716, ce=8.568257875944438
Local test acc @ epoch 242: 0.8067
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 1.266597990934315e-07
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 2.2351740014414645e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.12 seconds!
[tester] 
AGNewsMetric: acc=0.8305263157894737, hinge=3.7973214110575224, ce=8.950314483642579
Local test acc @ epoch 242: 0.8305
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901159417490817e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.28 seconds!
[tester] 
AGNewsMetric: acc=0.8346052631578947, hinge=3.9144670904310126, ce=8.154323371084113
Local test acc @ epoch 242: 0.8346
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450576333667414e-08
Local loss @ local epoch 3: 3.7252892326478104e-08
Local loss @ local epoch 4: 2.2351740014414645e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.61 seconds!
[tester] 
AGNewsMetric: acc=0.8388157894736842, hinge=3.878916241495233, ce=8.7154068896645
Local test acc @ epoch 242: 0.8388
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.05 seconds!
[tester] 
AGNewsMetric: acc=0.8405263157894737, hinge=3.7763966196461727, ce=8.118440571835167
Local test acc @ epoch 242: 0.8405
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.2351740014414645e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.9802315282267955e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.24 seconds!
[tester] 
AGNewsMetric: acc=0.8355263157894737, hinge=3.8551389290157116, ce=8.319612208918521
Local test acc @ epoch 242: 0.8355
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.4901159417490817e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.67 seconds!
[tester] 
AGNewsMetric: acc=0.8298684210526316, hinge=3.99578930478347, ce=8.308791763907985
Local test acc @ epoch 242: 0.8299
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.87 seconds!
[tester] 
AGNewsMetric: acc=0.8389473684210527, hinge=3.73768753892497, ce=8.21571601767289
Local test acc @ epoch 242: 0.8389
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.2351740014414645e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.96 seconds!
[tester] 
AGNewsMetric: acc=0.8365789473684211, hinge=3.8911132062108895, ce=8.286661331779078
Local test acc @ epoch 242: 0.8366
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 2.2351738238057806e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.74 seconds!
[tester] 
AGNewsMetric: acc=0.841842105263158, hinge=3.770008450558311, ce=8.376003001363653
Local test acc @ epoch 242: 0.8418
Global evaluate on test data...
Evaluate data in 129.77 seconds!
[tester] 
AGNewsMetric: acc=0.8369736842105263, hinge=3.847038428657933, ce=8.323627895555997
Global test acc @ epoch 242: 0.837
Global epoch 243...
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 4.4703469370688254e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.13 seconds!
[tester] 
AGNewsMetric: acc=0.8442105263157895, hinge=3.5932935129968744, ce=8.528282026993601
Local test acc @ epoch 243: 0.8442
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.2351740014414645e-08
Local loss @ local epoch 4: 8.195635103902532e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 131.06 seconds!
[tester] 
AGNewsMetric: acc=0.8389473684210527, hinge=3.742304874972293, ce=8.263680027409604
Local test acc @ epoch 243: 0.8389
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 2.2351738238057806e-08
Local loss @ local epoch 1: 1.4901159417490817e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 8.940690321423972e-08
Local loss @ local epoch 4: 3.7252892326478104e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.29 seconds!
[tester] 
AGNewsMetric: acc=0.8173684210526316, hinge=4.560459620576156, ce=9.046487713863975
Local test acc @ epoch 243: 0.8174
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.9802315282267955e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.12 seconds!
[tester] 
AGNewsMetric: acc=0.8339473684210527, hinge=3.836373312347814, ce=8.402632524590743
Local test acc @ epoch 243: 0.8339
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 2.9802320611338473e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.64 seconds!
[tester] 
AGNewsMetric: acc=0.834078947368421, hinge=3.8893317988044336, ce=8.391324223970113
Local test acc @ epoch 243: 0.8341
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 3.7252892326478104e-08
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 2.2351740014414645e-08
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 2.3096760060070665e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.68 seconds!
[tester] 
AGNewsMetric: acc=0.8467105263157895, hinge=3.684702438053332, ce=8.368911752198871
Local test acc @ epoch 243: 0.8467
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.24 seconds!
[tester] 
AGNewsMetric: acc=0.8372368421052632, hinge=3.8229708392996535, ce=8.315067515122264
Local test acc @ epoch 243: 0.8372
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 5.2154042862184724e-08
Local loss @ local epoch 1: 2.9802320611338473e-08
Local loss @ local epoch 2: 1.810466301321867e-06
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.5646213569198153e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.99 seconds!
[tester] 
AGNewsMetric: acc=0.8128947368421052, hinge=3.9861215491043893, ce=8.445328339024593
Local test acc @ epoch 243: 0.8129
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.09 seconds!
[tester] 
AGNewsMetric: acc=0.833421052631579, hinge=3.8958481944234746, ce=8.378357785877428
Local test acc @ epoch 243: 0.8334
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.4901159417490817e-08
Local loss @ local epoch 2: 1.4901159417490817e-08
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.49 seconds!
[tester] 
AGNewsMetric: acc=0.8139473684210526, hinge=4.439023045113212, ce=8.912830910933645
Local test acc @ epoch 243: 0.8139
Global evaluate on test data...
Evaluate data in 130.43 seconds!
[tester] 
AGNewsMetric: acc=0.8346052631578947, hinge=3.909784207093088, ce=8.457181288066662
Global test acc @ epoch 243: 0.8346
Global epoch 244...
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 8.940690321423972e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.8 seconds!
[tester] 
AGNewsMetric: acc=0.8382894736842105, hinge=3.8980248682122483, ce=8.620180870859247
Local test acc @ epoch 244: 0.8383
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901159417490817e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 2.2351738238057806e-08
Local loss @ local epoch 4: 2.2351738238057806e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.37 seconds!
[tester] 
AGNewsMetric: acc=0.8373684210526315, hinge=3.860548872445759, ce=8.535677888769852
Local test acc @ epoch 244: 0.8374
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.03 seconds!
[tester] 
AGNewsMetric: acc=0.8353947368421053, hinge=3.88088917305595, ce=8.490008063065378
Local test acc @ epoch 244: 0.8354
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 1.1920921139108032e-07
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 6.70552182668871e-08
Local loss @ local epoch 3: 7.450579175838357e-08
Local loss @ local epoch 4: 2.9802318834981634e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.84 seconds!
[tester] 
AGNewsMetric: acc=0.8343421052631579, hinge=3.7865187426617273, ce=8.052133471840307
Local test acc @ epoch 244: 0.8343
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 3.7252892326478104e-08
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.43 seconds!
[tester] 
AGNewsMetric: acc=0.8344736842105264, hinge=3.7943349656305814, ce=8.513878425798918
Local test acc @ epoch 244: 0.8345
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.24 seconds!
[tester] 
AGNewsMetric: acc=0.8327631578947369, hinge=3.9362140035629274, ce=8.471992330049213
Local test acc @ epoch 244: 0.8328
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.66 seconds!
[tester] 
AGNewsMetric: acc=0.8375, hinge=3.884282296833239, ce=8.499222347861842
Local test acc @ epoch 244: 0.8375
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 7.5544330684351735e-06
Local loss @ local epoch 1: 0.0721513107419014
Local loss @ local epoch 2: 8.717119612811075e-07
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 1.055153727531433
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.32 seconds!
[tester] 
AGNewsMetric: acc=0.7735526315789474, hinge=5.255337876771626, ce=9.090136646471526
Local test acc @ epoch 244: 0.7736
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.12 seconds!
[tester] 
AGNewsMetric: acc=0.8246052631578947, hinge=4.08765166106977, ce=8.699137504979184
Local test acc @ epoch 244: 0.8246
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.04 seconds!
[tester] 
AGNewsMetric: acc=0.8330263157894737, hinge=3.900318297085009, ce=8.521425087577418
Local test acc @ epoch 244: 0.833
Global evaluate on test data...
Evaluate data in 129.99 seconds!
[tester] 
AGNewsMetric: acc=0.8355263157894737, hinge=3.883557692452481, ce=8.383377340216386
Global test acc @ epoch 244: 0.8355
Global epoch 245...
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 2.2351740014414645e-08
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 131.15 seconds!
[tester] 
AGNewsMetric: acc=0.8206578947368421, hinge=4.134304984368776, ce=8.570293974625438
Local test acc @ epoch 245: 0.8207
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901159417490817e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.94 seconds!
[tester] 
AGNewsMetric: acc=0.8236842105263158, hinge=4.068405457170386, ce=8.764133965341669
Local test acc @ epoch 245: 0.8237
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.4901159417490817e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.12 seconds!
[tester] 
AGNewsMetric: acc=0.8376315789473684, hinge=3.7966455996663946, ce=8.305159455349571
Local test acc @ epoch 245: 0.8376
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 2.9802320611338473e-08
Local loss @ local epoch 3: 7.450577044210149e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.34 seconds!
[tester] 
AGNewsMetric: acc=0.8323684210526315, hinge=3.824510750017668, ce=8.400021875281084
Local test acc @ epoch 245: 0.8324
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 6.407468617908307e-07
Local loss @ local epoch 1: 1.783766269683838
Local loss @ local epoch 2: 2.9802320611338473e-08
Local loss @ local epoch 3: 1.7192132472991943
Local loss @ local epoch 4: 0.7681532502174377
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.61 seconds!
[tester] 
AGNewsMetric: acc=0.7373684210526316, hinge=5.037255430974459, ce=9.80135993756746
Local test acc @ epoch 245: 0.7374
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.74 seconds!
[tester] 
AGNewsMetric: acc=0.8388157894736842, hinge=3.753210862310309, ce=8.290982802541633
Local test acc @ epoch 245: 0.8388
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 1.4901159417490817e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.65 seconds!
[tester] 
AGNewsMetric: acc=0.8318421052631579, hinge=3.9607716876582097, ce=8.527811120685778
Local test acc @ epoch 245: 0.8318
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.4901159417490817e-08
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.62 seconds!
[tester] 
AGNewsMetric: acc=0.8351315789473684, hinge=3.8706636954608715, ce=8.519066663039357
Local test acc @ epoch 245: 0.8351
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 6.705521116145974e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.9802315282267955e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.2 seconds!
[tester] 
AGNewsMetric: acc=0.825921052631579, hinge=3.9837816552111978, ce=8.60755876842298
Local test acc @ epoch 245: 0.8259
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 1.4901159417490817e-08
Local loss @ local epoch 2: 4.4703469370688254e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.63 seconds!
[tester] 
AGNewsMetric: acc=0.8409210526315789, hinge=3.6607931699250873, ce=8.213188126212673
Local test acc @ epoch 245: 0.8409
Global evaluate on test data...
Evaluate data in 130.66 seconds!
[tester] 
AGNewsMetric: acc=0.8443421052631579, hinge=3.6076334014691804, ce=8.116646000711542
Global test acc @ epoch 245: 0.8443
Global epoch 246...
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.2351738238057806e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 131.09 seconds!
[tester] 
AGNewsMetric: acc=0.8443421052631579, hinge=3.650444369567068, ce=8.133877168956555
Local test acc @ epoch 246: 0.8443
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 2.9802320611338473e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.2351740014414645e-08
Local loss @ local epoch 3: 0.3329853117465973
Local loss @ local epoch 4: 0.9579499363899231
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.6 seconds!
[tester] 
AGNewsMetric: acc=0.6661842105263158, hinge=7.7918993387724225, ce=11.745574264526367
Local test acc @ epoch 246: 0.6662
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 8.940690321423972e-08
Local loss @ local epoch 1: 2.2351738238057806e-08
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 4.5448376795320655e-07
Local loss @ local epoch 4: 0.18976011872291565
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.09 seconds!
[tester] 
AGNewsMetric: acc=0.8535526315789473, hinge=3.2709114267951565, ce=8.2552392578125
Local test acc @ epoch 246: 0.8536
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.97 seconds!
[tester] 
AGNewsMetric: acc=0.8451315789473685, hinge=3.546004422840319, ce=8.160590815293162
Local test acc @ epoch 246: 0.8451
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.38 seconds!
[tester] 
AGNewsMetric: acc=0.8423684210526315, hinge=3.6898602909790843, ce=8.094914163288317
Local test acc @ epoch 246: 0.8424
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 2.533193139697687e-07
Local loss @ local epoch 1: 4.470347292340193e-08
Local loss @ local epoch 2: 5.215405707303944e-08
Local loss @ local epoch 3: 3.278248357219127e-07
Local loss @ local epoch 4: 4.470347647611561e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.06 seconds!
[tester] 
AGNewsMetric: acc=0.8201315789473684, hinge=4.209238211983129, ce=8.853537599663985
Local test acc @ epoch 246: 0.8201
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 1.1920919007479824e-07
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 3.725289587919178e-08
Local loss @ local epoch 3: 2.980225701776362e-07
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.63 seconds!
[tester] 
AGNewsMetric: acc=0.8317105263157895, hinge=3.7854428626361645, ce=8.285055810024863
Local test acc @ epoch 246: 0.8317
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 8.940694584680386e-08
Local loss @ local epoch 1: 1.4901159417490817e-08
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 1.2982568740844727
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.21 seconds!
[tester] 
AGNewsMetric: acc=0.8257894736842105, hinge=4.103424340047335, ce=7.935188786356073
Local test acc @ epoch 246: 0.8258
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 8.940690321423972e-08
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 7.450577754752885e-08
Local loss @ local epoch 3: 0.02695457637310028
Local loss @ local epoch 4: 2.6822067411558237e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.02 seconds!
[tester] 
AGNewsMetric: acc=0.8380263157894737, hinge=3.329484151288083, ce=8.583333869733309
Local test acc @ epoch 246: 0.838
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.71 seconds!
[tester] 
AGNewsMetric: acc=0.8426315789473684, hinge=3.6318952462547704, ce=8.132318205582468
Local test acc @ epoch 246: 0.8426
Global evaluate on test data...
Evaluate data in 130.64 seconds!
[tester] 
AGNewsMetric: acc=0.8421052631578947, hinge=3.724970739515204, ce=8.23006128411544
Global test acc @ epoch 246: 0.8421
Global epoch 247...
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 6.705519695060502e-08
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.04 seconds!
[tester] 
AGNewsMetric: acc=0.8373684210526315, hinge=3.7788465818605923, ce=8.483072603125322
Local test acc @ epoch 247: 0.8374
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.93 seconds!
[tester] 
AGNewsMetric: acc=0.8447368421052631, hinge=3.6558524869617663, ce=8.147815128125643
Local test acc @ epoch 247: 0.8447
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.72 seconds!
[tester] 
AGNewsMetric: acc=0.8421052631578947, hinge=3.7185496177171404, ce=8.220362257706492
Local test acc @ epoch 247: 0.8421
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.85 seconds!
[tester] 
AGNewsMetric: acc=0.8398684210526316, hinge=3.8258618394952073, ce=8.263249888169138
Local test acc @ epoch 247: 0.8399
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 6.705518984517767e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 3.7252892326478104e-08
Local loss @ local epoch 4: 2.9802318834981634e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.88 seconds!
[tester] 
AGNewsMetric: acc=0.8367105263157895, hinge=3.7724661824577734, ce=8.134900232616223
Local test acc @ epoch 247: 0.8367
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.713631121447179e-07
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.29 seconds!
[tester] 
AGNewsMetric: acc=0.8427631578947369, hinge=3.5225885948381928, ce=8.162696937761808
Local test acc @ epoch 247: 0.8428
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 1.4901159417490817e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.97 seconds!
[tester] 
AGNewsMetric: acc=0.8335526315789473, hinge=3.9192479382063214, ce=8.3564973108392
Local test acc @ epoch 247: 0.8336
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.25 seconds!
[tester] 
AGNewsMetric: acc=0.8439473684210527, hinge=3.678147390390697, ce=8.140493786460475
Local test acc @ epoch 247: 0.8439
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.48 seconds!
[tester] 
AGNewsMetric: acc=0.8423684210526315, hinge=3.6991293641140586, ce=8.172576161434776
Local test acc @ epoch 247: 0.8424
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.2351740014414645e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.98 seconds!
[tester] 
AGNewsMetric: acc=0.8425, hinge=3.719812230310942, ce=8.288728420859888
Local test acc @ epoch 247: 0.8425
Global evaluate on test data...
Evaluate data in 130.35 seconds!
[tester] 
AGNewsMetric: acc=0.8421052631578947, hinge=3.7189318599198993, ce=8.223142708226254
Global test acc @ epoch 247: 0.8421
Global epoch 248...
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 5.960463056453591e-08
Local loss @ local epoch 2: 2.9802318834981634e-08
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.17 seconds!
[tester] 
AGNewsMetric: acc=0.8467105263157895, hinge=3.627405932075099, ce=8.125230419761257
Local test acc @ epoch 248: 0.8467
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.6 seconds!
[tester] 
AGNewsMetric: acc=0.8392105263157895, hinge=3.788926416698255, ce=8.409664958150763
Local test acc @ epoch 248: 0.8392
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.2351738238057806e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.42 seconds!
[tester] 
AGNewsMetric: acc=0.8382894736842105, hinge=3.8556216990320307, ce=8.272510494432952
Local test acc @ epoch 248: 0.8383
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 1.937147970920705e-07
Local loss @ local epoch 1: 1.0430805019723266e-07
Local loss @ local epoch 2: 1.2740372312691761e-06
Local loss @ local epoch 3: 6.705518984517767e-08
Local loss @ local epoch 4: 1.5646203621599852e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.88 seconds!
[tester] 
AGNewsMetric: acc=0.7764473684210527, hinge=5.270069337142141, ce=9.34816164719431
Local test acc @ epoch 248: 0.7764
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 2.9802315282267955e-08
Local loss @ local epoch 1: 3.725289587919178e-08
Local loss @ local epoch 2: 2.9802315282267955e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0036579978186637163
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.28 seconds!
[tester] 
AGNewsMetric: acc=0.7852631578947369, hinge=5.167129332266356, ce=9.365795470789859
Local test acc @ epoch 248: 0.7853
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.2351740014414645e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.63 seconds!
[tester] 
AGNewsMetric: acc=0.8426315789473684, hinge=3.630475792884827, ce=8.098942545840615
Local test acc @ epoch 248: 0.8426
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.27 seconds!
[tester] 
AGNewsMetric: acc=0.8422368421052632, hinge=3.7129852104187013, ce=8.304894847869873
Local test acc @ epoch 248: 0.8422
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.68 seconds!
[tester] 
AGNewsMetric: acc=0.8465789473684211, hinge=3.6284010111658196, ce=8.223100477519788
Local test acc @ epoch 248: 0.8466
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901159417490817e-08
Local loss @ local epoch 1: 2.9802320611338473e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.1920919007479824e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.99 seconds!
[tester] 
AGNewsMetric: acc=0.7982894736842105, hinge=4.74228855434217, ce=8.933315672623484
Local test acc @ epoch 248: 0.7983
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.86 seconds!
[tester] 
AGNewsMetric: acc=0.8197368421052632, hinge=4.286462794856021, ce=8.444068890621788
Local test acc @ epoch 248: 0.8197
Global evaluate on test data...
Evaluate data in 130.05 seconds!
[tester] 
AGNewsMetric: acc=0.8347368421052631, hinge=3.9227740947823775, ce=8.321464139034873
Global test acc @ epoch 248: 0.8347
Global epoch 249...
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 1.0545742511749268
Local loss @ local epoch 1: 3.463545560836792
Local loss @ local epoch 2: 1.1035858392715454
Local loss @ local epoch 3: 0.5351111888885498
Local loss @ local epoch 4: 2.710091575863771e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.01 seconds!
[tester] 
AGNewsMetric: acc=0.7994736842105263, hinge=3.09263397329732, ce=8.933475634926245
Local test acc @ epoch 249: 0.7995
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.4901159417490817e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.4 seconds!
[tester] 
AGNewsMetric: acc=0.8343421052631579, hinge=3.91922452499992, ce=8.341738711909244
Local test acc @ epoch 249: 0.8343
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.35 seconds!
[tester] 
AGNewsMetric: acc=0.8378947368421052, hinge=3.8210885603804337, ce=8.273972930908203
Local test acc @ epoch 249: 0.8379
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.2351740014414645e-08
Local loss @ local epoch 2: 1.341103512686459e-07
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.2351740014414645e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.53 seconds!
[tester] 
AGNewsMetric: acc=0.8425, hinge=3.631633247074328, ce=8.582785891482704
Local test acc @ epoch 249: 0.8425
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.2351740014414645e-08
Local loss @ local epoch 3: 5.215405707303944e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.62 seconds!
[tester] 
AGNewsMetric: acc=0.8230263157894737, hinge=4.289365190204821, ce=8.630395194605777
Local test acc @ epoch 249: 0.823
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.83 seconds!
[tester] 
AGNewsMetric: acc=0.8397368421052631, hinge=3.7946227299539665, ce=8.285035805953177
Local test acc @ epoch 249: 0.8397
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.15 seconds!
[tester] 
AGNewsMetric: acc=0.8388157894736842, hinge=3.747771527139764, ce=8.25288675609388
Local test acc @ epoch 249: 0.8388
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.102676378650358e-06
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.3023941218852997
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.0 seconds!
[tester] 
AGNewsMetric: acc=0.8210526315789474, hinge=4.430034456002085, ce=8.645930932697498
Local test acc @ epoch 249: 0.8211
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 2.2608423023484647e-05
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 5.215405352032576e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.21 seconds!
[tester] 
AGNewsMetric: acc=0.7772368421052631, hinge=5.243219426054703, ce=10.107752651415373
Local test acc @ epoch 249: 0.7772
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 5.215404996761208e-08
Local loss @ local epoch 1: 3.725289943190546e-08
Local loss @ local epoch 2: 2.6822036147677863e-07
Local loss @ local epoch 3: 3.725289943190546e-08
Local loss @ local epoch 4: 9.685748381116355e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.39 seconds!
[tester] 
AGNewsMetric: acc=0.8328947368421052, hinge=3.5977888223999424, ce=7.939439822749088
Local test acc @ epoch 249: 0.8329
Global evaluate on test data...
Evaluate data in 129.88 seconds!
[tester] 
AGNewsMetric: acc=0.845, hinge=3.665273914337158, ce=8.177054577877646
Global test acc @ epoch 249: 0.845
Global epoch 250...
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.4901159417490817e-08
Local loss @ local epoch 4: 2.9802318834981634e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.92 seconds!
[tester] 
AGNewsMetric: acc=0.8411842105263158, hinge=3.737090454478013, ce=8.333330547935084
Local test acc @ epoch 250: 0.8412
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.33 seconds!
[tester] 
AGNewsMetric: acc=0.845657894736842, hinge=3.6091731401493674, ce=8.14135885439421
Local test acc @ epoch 250: 0.8457
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901159417490817e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.73 seconds!
[tester] 
AGNewsMetric: acc=0.8444736842105263, hinge=3.72155518556896, ce=8.295845681240683
Local test acc @ epoch 250: 0.8445
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.9802318834981634e-08
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 5.5355403674184345e-06
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.87 seconds!
[tester] 
AGNewsMetric: acc=0.844078947368421, hinge=3.332802974424864, ce=8.463994265104596
Local test acc @ epoch 250: 0.8441
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 1.4901159417490817e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.97 seconds!
[tester] 
AGNewsMetric: acc=0.8438157894736842, hinge=3.6189817262950696, ce=8.18617898137946
Local test acc @ epoch 250: 0.8438
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 2.9802318834981634e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.36 seconds!
[tester] 
AGNewsMetric: acc=0.8472368421052632, hinge=3.7085037457315546, ce=8.344035056264778
Local test acc @ epoch 250: 0.8472
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.33 seconds!
[tester] 
AGNewsMetric: acc=0.8447368421052631, hinge=3.64185654903713, ce=8.245968991329795
Local test acc @ epoch 250: 0.8447
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 5.9604616353681195e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 4.470347647611561e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.16 seconds!
[tester] 
AGNewsMetric: acc=0.8267105263157895, hinge=4.186169871405552, ce=8.826371241117778
Local test acc @ epoch 250: 0.8267
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 2.9802318834981634e-08
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.37 seconds!
[tester] 
AGNewsMetric: acc=0.8409210526315789, hinge=3.7394509747153832, ce=8.299314163609555
Local test acc @ epoch 250: 0.8409
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.0131968338100705e-05
Local loss @ local epoch 2: 4.3764299334725365e-05
Local loss @ local epoch 3: 1.8626435860369384e-07
Local loss @ local epoch 4: 1.3411039390121005e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.45 seconds!
[tester] 
AGNewsMetric: acc=0.8031578947368421, hinge=4.23216369001489, ce=8.91319716804906
Local test acc @ epoch 250: 0.8032
Global evaluate on test data...
Evaluate data in 130.92 seconds!
[tester] 
AGNewsMetric: acc=0.8488157894736842, hinge=3.5990963551872657, ce=8.182124646839343
Global test acc @ epoch 250: 0.8488
Global epoch 251...
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 2.9802315282267955e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.4901159417490817e-08
Local loss @ local epoch 4: 3.583626948966412e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.42 seconds!
[tester] 
AGNewsMetric: acc=0.8222368421052632, hinge=4.245524399656999, ce=8.68606731414795
Local test acc @ epoch 251: 0.8222
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.87 seconds!
[tester] 
AGNewsMetric: acc=0.8488157894736842, hinge=3.5798776930256895, ce=8.182931786587364
Local test acc @ epoch 251: 0.8488
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 3.427258548072132e-07
Local loss @ local epoch 4: 9.685746960030883e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.8 seconds!
[tester] 
AGNewsMetric: acc=0.8064473684210526, hinge=4.763993945121765, ce=8.965721284966719
Local test acc @ epoch 251: 0.8064
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 1.4901159417490817e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.95 seconds!
[tester] 
AGNewsMetric: acc=0.8475, hinge=3.617164925525063, ce=8.339961540824488
Local test acc @ epoch 251: 0.8475
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.0116537768899434e-07
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.2351740014414645e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.15 seconds!
[tester] 
AGNewsMetric: acc=0.7951315789473684, hinge=4.95370937272122, ce=9.228863625777395
Local test acc @ epoch 251: 0.7951
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.612745463848114
Local loss @ local epoch 1: 0.014553146436810493
Local loss @ local epoch 2: 0.5704514980316162
Local loss @ local epoch 3: 0.9841041564941406
Local loss @ local epoch 4: 0.03757370635867119
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.08 seconds!
[tester] 
AGNewsMetric: acc=0.7918421052631579, hinge=2.8823191936392534, ce=10.067630601180227
Local test acc @ epoch 251: 0.7918
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 8.940691031966708e-08
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 1.6391264523463178e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.6 seconds!
[tester] 
AGNewsMetric: acc=0.8313157894736842, hinge=3.885433712256582, ce=8.230282534549112
Local test acc @ epoch 251: 0.8313
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.9802318834981634e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.02 seconds!
[tester] 
AGNewsMetric: acc=0.8453947368421053, hinge=3.672707502967433, ce=8.143414935061806
Local test acc @ epoch 251: 0.8454
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 3.7252892326478104e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 8.195632972274325e-08
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.97 seconds!
[tester] 
AGNewsMetric: acc=0.8306578947368422, hinge=4.0602942361329735, ce=8.188711796810752
Local test acc @ epoch 251: 0.8307
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901159417490817e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 5.9604616353681195e-08
Local loss @ local epoch 4: 1.043080430918053e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.08 seconds!
[tester] 
AGNewsMetric: acc=0.8451315789473685, hinge=3.8181608040709243, ce=8.600922814419395
Local test acc @ epoch 251: 0.8451
Global evaluate on test data...
Evaluate data in 129.64 seconds!
[tester] 
AGNewsMetric: acc=0.8368421052631579, hinge=3.9229152521334196, ce=8.374574222564696
Global test acc @ epoch 251: 0.8368
Global epoch 252...
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.96 seconds!
[tester] 
AGNewsMetric: acc=0.8403947368421053, hinge=3.8327854029755843, ce=8.484672109704269
Local test acc @ epoch 252: 0.8404
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 5.960436055829632e-07
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 5.960462345910855e-08
Local loss @ local epoch 4: 3.0547315077456005e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.31 seconds!
[tester] 
AGNewsMetric: acc=0.8335526315789473, hinge=3.633311044040479, ce=7.940641975402832
Local test acc @ epoch 252: 0.8336
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.19 seconds!
[tester] 
AGNewsMetric: acc=0.833421052631579, hinge=3.854509223385861, ce=8.502013254667583
Local test acc @ epoch 252: 0.8334
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 2.9802318834981634e-08
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 3.7252892326478104e-08
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.25 seconds!
[tester] 
AGNewsMetric: acc=0.8482894736842105, hinge=3.610766873861614, ce=8.188886266005667
Local test acc @ epoch 252: 0.8483
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.9802315282267955e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.2351740014414645e-08
Local loss @ local epoch 4: 8.940690321423972e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.62 seconds!
[tester] 
AGNewsMetric: acc=0.8211842105263157, hinge=4.248198114821785, ce=8.754023736652575
Local test acc @ epoch 252: 0.8212
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.4901159417490817e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.78 seconds!
[tester] 
AGNewsMetric: acc=0.8389473684210527, hinge=3.8557113734044526, ce=8.320643030467787
Local test acc @ epoch 252: 0.8389
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 3.7252892326478104e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.2351740014414645e-08
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.08 seconds!
[tester] 
AGNewsMetric: acc=0.8298684210526316, hinge=4.012365772347701, ce=8.020835815228914
Local test acc @ epoch 252: 0.8299
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 9.685746960030883e-08
Local loss @ local epoch 1: 2.2351740014414645e-08
Local loss @ local epoch 2: 1.512452399765607e-06
Local loss @ local epoch 3: 0.00022640005045104772
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.44 seconds!
[tester] 
AGNewsMetric: acc=0.7422368421052632, hinge=6.79751603891975, ce=10.655165497629266
Local test acc @ epoch 252: 0.7422
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 3.725289587919178e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.69 seconds!
[tester] 
AGNewsMetric: acc=0.8376315789473684, hinge=3.8106612273266443, ce=8.320037888978657
Local test acc @ epoch 252: 0.8376
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 5.2154042862184724e-08
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 2.9802315282267955e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.15 seconds!
[tester] 
AGNewsMetric: acc=0.8201315789473684, hinge=3.88957527286128, ce=8.654172119341398
Local test acc @ epoch 252: 0.8201
Global evaluate on test data...
Evaluate data in 130.28 seconds!
[tester] 
AGNewsMetric: acc=0.8351315789473684, hinge=3.934907106098376, ce=8.366695774479917
Global test acc @ epoch 252: 0.8351
Global epoch 253...
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.23 seconds!
[tester] 
AGNewsMetric: acc=0.8338157894736842, hinge=3.940380163192749, ce=8.429138979660838
Local test acc @ epoch 253: 0.8338
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 5.215405707303944e-08
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.69 seconds!
[tester] 
AGNewsMetric: acc=0.8401315789473685, hinge=3.8252722373761627, ce=8.180319765994422
Local test acc @ epoch 253: 0.8401
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 8.19563723553074e-08
Local loss @ local epoch 1: 2.9802315282267955e-08
Local loss @ local epoch 2: 2.2351740014414645e-08
Local loss @ local epoch 3: 3.725289587919178e-08
Local loss @ local epoch 4: 7.450579175838357e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.76 seconds!
[tester] 
AGNewsMetric: acc=0.8289473684210527, hinge=3.9616800397320797, ce=8.811165324763248
Local test acc @ epoch 253: 0.8289
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 4.470347647611561e-08
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 3.7252892326478104e-08
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.16 seconds!
[tester] 
AGNewsMetric: acc=0.8267105263157895, hinge=4.248842430114746, ce=8.39956712421618
Local test acc @ epoch 253: 0.8267
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 5.215404996761208e-08
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.00048044705181382596
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.34 seconds!
[tester] 
AGNewsMetric: acc=0.6219736842105263, hinge=9.481027083396912, ce=12.417903914200632
Local test acc @ epoch 253: 0.622
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.84 seconds!
[tester] 
AGNewsMetric: acc=0.815921052631579, hinge=4.314839505898325, ce=8.764375744869835
Local test acc @ epoch 253: 0.8159
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.41 seconds!
[tester] 
AGNewsMetric: acc=0.8315789473684211, hinge=3.973323944493344, ce=8.461279013784308
Local test acc @ epoch 253: 0.8316
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 1.1175862368872913e-07
Local loss @ local epoch 4: 2.9802318834981634e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.7 seconds!
[tester] 
AGNewsMetric: acc=0.8368421052631579, hinge=3.9035934119475515, ce=8.590293139407509
Local test acc @ epoch 253: 0.8368
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.09 seconds!
[tester] 
AGNewsMetric: acc=0.8342105263157895, hinge=3.8615848543769435, ce=8.38448345284713
Local test acc @ epoch 253: 0.8342
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.84 seconds!
[tester] 
AGNewsMetric: acc=0.8342105263157895, hinge=3.916576534948851, ce=8.380173686178107
Local test acc @ epoch 253: 0.8342
Global evaluate on test data...
Evaluate data in 130.53 seconds!
[tester] 
AGNewsMetric: acc=0.8286842105263158, hinge=4.129519337352954, ce=8.497333771555047
Global test acc @ epoch 253: 0.8287
Global epoch 254...
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.4901159417490817e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.39 seconds!
[tester] 
AGNewsMetric: acc=0.8301315789473684, hinge=4.024053004917346, ce=8.4944712668971
Local test acc @ epoch 254: 0.8301
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 5.2154042862184724e-08
Local loss @ local epoch 2: 2.2351740014414645e-08
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.33 seconds!
[tester] 
AGNewsMetric: acc=0.8482894736842105, hinge=3.6730236066015145, ce=8.153934104317113
Local test acc @ epoch 254: 0.8483
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 2.9802318834981634e-08
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 2.2351738238057806e-08
Local loss @ local epoch 4: 0.0008753502042964101
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.35 seconds!
[tester] 
AGNewsMetric: acc=0.8365789473684211, hinge=3.941826728896091, ce=8.369299755096435
Local test acc @ epoch 254: 0.8366
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 3.829481102002319e-06
Local loss @ local epoch 1: 1.1920920428565296e-07
Local loss @ local epoch 2: 1.9669373614306096e-06
Local loss @ local epoch 3: 0.36267128586769104
Local loss @ local epoch 4: 1.0742881386249792e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.24 seconds!
[tester] 
AGNewsMetric: acc=0.8175, hinge=3.667676107005069, ce=9.473365984464946
Local test acc @ epoch 254: 0.8175
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 2.2351738238057806e-08
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.82 seconds!
[tester] 
AGNewsMetric: acc=0.83, hinge=4.039474405740437, ce=8.294182627828498
Local test acc @ epoch 254: 0.83
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 2.2351740014414645e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.87 seconds!
[tester] 
AGNewsMetric: acc=0.8226315789473684, hinge=4.162016687393188, ce=8.751135215759277
Local test acc @ epoch 254: 0.8226
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.51 seconds!
[tester] 
AGNewsMetric: acc=0.8210526315789474, hinge=4.332467037125638, ce=8.604946732772024
Local test acc @ epoch 254: 0.8211
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.4901159417490817e-08
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.91 seconds!
[tester] 
AGNewsMetric: acc=0.8256578947368421, hinge=4.15885950414758, ce=8.545409592076352
Local test acc @ epoch 254: 0.8257
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.2351740014414645e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.03 seconds!
[tester] 
AGNewsMetric: acc=0.8331578947368421, hinge=3.909885298201912, ce=8.624298679954128
Local test acc @ epoch 254: 0.8332
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 128.97 seconds!
[tester] 
AGNewsMetric: acc=0.8181578947368421, hinge=4.254275233620091, ce=8.746710078590795
Local test acc @ epoch 254: 0.8182
Global evaluate on test data...
Evaluate data in 130.54 seconds!
[tester] 
AGNewsMetric: acc=0.8421052631578947, hinge=3.832475853719209, ce=8.31340078755429
Global test acc @ epoch 254: 0.8421
Global epoch 255...
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.2351738238057806e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 4.470347647611561e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.28 seconds!
[tester] 
AGNewsMetric: acc=0.8165789473684211, hinge=4.4342188513906375, ce=8.656315215261358
Local test acc @ epoch 255: 0.8166
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.4901159417490817e-08
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 1.4901159417490817e-08
Local loss @ local epoch 4: 2.9802318834981634e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.48 seconds!
[tester] 
AGNewsMetric: acc=0.8460526315789474, hinge=3.7410019904688787, ce=8.424623782509252
Local test acc @ epoch 255: 0.8461
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.66 seconds!
[tester] 
AGNewsMetric: acc=0.8413157894736842, hinge=3.7867764401435853, ce=8.38732078552246
Local test acc @ epoch 255: 0.8413
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.36 seconds!
[tester] 
AGNewsMetric: acc=0.8401315789473685, hinge=3.8256692639150116, ce=8.412462041754472
Local test acc @ epoch 255: 0.8401
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.15 seconds!
[tester] 
AGNewsMetric: acc=0.8264473684210526, hinge=4.1164101988390875, ce=8.577549725582726
Local test acc @ epoch 255: 0.8264
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 2.2351738238057806e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.4901159417490817e-08
Local loss @ local epoch 4: 2.7567091365199303e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.43 seconds!
[tester] 
AGNewsMetric: acc=0.8401315789473685, hinge=3.8186156596635517, ce=8.412834273890445
Local test acc @ epoch 255: 0.8401
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.65 seconds!
[tester] 
AGNewsMetric: acc=0.8413157894736842, hinge=3.7969019773131922, ce=8.318884933873226
Local test acc @ epoch 255: 0.8413
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.9802315282267955e-08
Local loss @ local epoch 3: 2.2351738238057806e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.99 seconds!
[tester] 
AGNewsMetric: acc=0.8268421052631579, hinge=4.186800983328569, ce=8.695845563788163
Local test acc @ epoch 255: 0.8268
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 4.4703469370688254e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 1.564620220051438e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.41 seconds!
[tester] 
AGNewsMetric: acc=0.8332894736842106, hinge=4.232379921110053, ce=8.644018673143888
Local test acc @ epoch 255: 0.8333
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 2.2351738238057806e-08
Local loss @ local epoch 1: 2.9802318834981634e-08
Local loss @ local epoch 2: 1.1175865211043856e-07
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 131.06 seconds!
[tester] 
AGNewsMetric: acc=0.833421052631579, hinge=3.828489097670505, ce=8.430502801192434
Local test acc @ epoch 255: 0.8334
Global evaluate on test data...
Evaluate data in 130.98 seconds!
[tester] 
AGNewsMetric: acc=0.8430263157894737, hinge=3.7990143020529494, ce=8.340927260549446
Global test acc @ epoch 255: 0.843
Global epoch 256...
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.4901159417490817e-08
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.22 seconds!
[tester] 
AGNewsMetric: acc=0.8468421052631578, hinge=3.6712568373429146, ce=8.346444405003599
Local test acc @ epoch 256: 0.8468
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.35 seconds!
[tester] 
AGNewsMetric: acc=0.8363157894736842, hinge=3.8907687014027648, ce=8.366732613412957
Local test acc @ epoch 256: 0.8363
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.19 seconds!
[tester] 
AGNewsMetric: acc=0.841842105263158, hinge=3.7772343234012, ce=8.34145919699418
Local test acc @ epoch 256: 0.8418
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 1.4901159417490817e-08
Local loss @ local epoch 3: 2.2351740014414645e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.85 seconds!
[tester] 
AGNewsMetric: acc=0.8428947368421053, hinge=3.7826114561683255, ce=8.206868739881013
Local test acc @ epoch 256: 0.8429
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.2351738238057806e-08
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 2.2351740014414645e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.79 seconds!
[tester] 
AGNewsMetric: acc=0.8488157894736842, hinge=3.599411751847518, ce=8.215973960474917
Local test acc @ epoch 256: 0.8488
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 2.2351740014414645e-08
Local loss @ local epoch 1: 3.725289943190546e-08
Local loss @ local epoch 2: 1.3411039390121005e-07
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 131.07 seconds!
[tester] 
AGNewsMetric: acc=0.8157894736842105, hinge=4.18300646079214, ce=8.728835158097116
Local test acc @ epoch 256: 0.8158
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.2351738238057806e-08
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.25 seconds!
[tester] 
AGNewsMetric: acc=0.8378947368421052, hinge=3.9059958430340416, ce=8.420349157232987
Local test acc @ epoch 256: 0.8379
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 2.9802315282267955e-08
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.19 seconds!
[tester] 
AGNewsMetric: acc=0.8439473684210527, hinge=3.7685883911032425, ce=8.442933564437062
Local test acc @ epoch 256: 0.8439
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 1.1920917586394353e-07
Local loss @ local epoch 1: 3.725289587919178e-08
Local loss @ local epoch 2: 2.2351740014414645e-08
Local loss @ local epoch 3: 6.705520405603238e-08
Local loss @ local epoch 4: 5.882445111637935e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.14 seconds!
[tester] 
AGNewsMetric: acc=0.8476315789473684, hinge=3.419807486534119, ce=8.805157721670051
Local test acc @ epoch 256: 0.8476
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.6 seconds!
[tester] 
AGNewsMetric: acc=0.8375, hinge=3.902738024184578, ce=8.469879321048134
Local test acc @ epoch 256: 0.8375
Global evaluate on test data...
Evaluate data in 129.93 seconds!
[tester] 
AGNewsMetric: acc=0.8447368421052631, hinge=3.747571395572863, ce=8.342521804006477
Global test acc @ epoch 256: 0.8447
Global epoch 257...
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.94 seconds!
[tester] 
AGNewsMetric: acc=0.8435526315789473, hinge=3.77497161815041, ce=8.356459884643554
Local test acc @ epoch 257: 0.8436
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 5.662416242557811e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.15251871952205e-07
Local loss @ local epoch 3: 8.940695295223122e-08
Local loss @ local epoch 4: 5.088541911391076e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.24 seconds!
[tester] 
AGNewsMetric: acc=0.7998684210526316, hinge=4.725539450394479, ce=9.33754561775609
Local test acc @ epoch 257: 0.7999
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 4.470347292340193e-08
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 6.705521116145974e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 3.7252892326478104e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.95 seconds!
[tester] 
AGNewsMetric: acc=0.825921052631579, hinge=3.9377786054109274, ce=8.574781287343878
Local test acc @ epoch 257: 0.8259
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.84 seconds!
[tester] 
AGNewsMetric: acc=0.8419736842105263, hinge=3.776075143312153, ce=8.458025643198114
Local test acc @ epoch 257: 0.842
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 2.9802318834981634e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.81 seconds!
[tester] 
AGNewsMetric: acc=0.8426315789473684, hinge=3.8197380363313775, ce=8.216741475557026
Local test acc @ epoch 257: 0.8426
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.4901159417490817e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.72 seconds!
[tester] 
AGNewsMetric: acc=0.8427631578947369, hinge=3.691187466069272, ce=8.56097292849892
Local test acc @ epoch 257: 0.8428
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 131.49 seconds!
[tester] 
AGNewsMetric: acc=0.8417105263157895, hinge=3.8191998459163465, ce=8.399181279634174
Local test acc @ epoch 257: 0.8417
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.71 seconds!
[tester] 
AGNewsMetric: acc=0.8421052631578947, hinge=3.754927581736916, ce=8.343407327752365
Local test acc @ epoch 257: 0.8421
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.68 seconds!
[tester] 
AGNewsMetric: acc=0.8448684210526316, hinge=3.7569153961382415, ce=8.321022900029233
Local test acc @ epoch 257: 0.8449
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 1.4901159417490817e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.62 seconds!
[tester] 
AGNewsMetric: acc=0.8397368421052631, hinge=3.870352795500504, ce=8.430922313489411
Local test acc @ epoch 257: 0.8397
Global evaluate on test data...
Evaluate data in 130.07 seconds!
[tester] 
AGNewsMetric: acc=0.8407894736842105, hinge=3.854779591560364, ce=8.425144024899131
Global test acc @ epoch 257: 0.8408
Global epoch 258...
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.97 seconds!
[tester] 
AGNewsMetric: acc=0.8398684210526316, hinge=3.8625462632430225, ce=8.391857745521946
Local test acc @ epoch 258: 0.8399
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.4901159417490817e-08
Local loss @ local epoch 3: 2.6822036147677863e-07
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.29 seconds!
[tester] 
AGNewsMetric: acc=0.8207894736842105, hinge=4.429981014728546, ce=9.121325667531867
Local test acc @ epoch 258: 0.8208
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.4 seconds!
[tester] 
AGNewsMetric: acc=0.8397368421052631, hinge=3.85379791636216, ce=8.493236473485043
Local test acc @ epoch 258: 0.8397
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 4.4703469370688254e-08
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 8.34459626730677e-07
Local loss @ local epoch 4: 2.9802318834981634e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 131.3 seconds!
[tester] 
AGNewsMetric: acc=0.729078947368421, hinge=6.748448974709762, ce=11.28048960033216
Local test acc @ epoch 258: 0.7291
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450576333667414e-08
Local loss @ local epoch 1: 1.4901159417490817e-08
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 4.470348002882929e-08
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.58 seconds!
[tester] 
AGNewsMetric: acc=0.8332894736842106, hinge=3.7845561760350277, ce=8.05863583514565
Local test acc @ epoch 258: 0.8333
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.4901159417490817e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.69 seconds!
[tester] 
AGNewsMetric: acc=0.8417105263157895, hinge=3.8044565017599807, ce=8.37846629895662
Local test acc @ epoch 258: 0.8417
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.53 seconds!
[tester] 
AGNewsMetric: acc=0.8439473684210527, hinge=3.7640744836706865, ce=8.494023863139905
Local test acc @ epoch 258: 0.8439
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.19 seconds!
[tester] 
AGNewsMetric: acc=0.8405263157894737, hinge=3.8193803945340608, ce=8.466688812657406
Local test acc @ epoch 258: 0.8405
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.27 seconds!
[tester] 
AGNewsMetric: acc=0.8407894736842105, hinge=3.8298466471621864, ce=8.419021134627492
Local test acc @ epoch 258: 0.8408
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.88 seconds!
[tester] 
AGNewsMetric: acc=0.8402631578947368, hinge=3.770480386081495, ce=8.398652837652909
Local test acc @ epoch 258: 0.8403
Global evaluate on test data...
Evaluate data in 130.28 seconds!
[tester] 
AGNewsMetric: acc=0.8439473684210527, hinge=3.765290473134894, ce=8.383647772136488
Global test acc @ epoch 258: 0.8439
Global epoch 259...
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 1.4901159417490817e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.69 seconds!
[tester] 
AGNewsMetric: acc=0.8482894736842105, hinge=3.594021876987658, ce=8.35419494327746
Local test acc @ epoch 259: 0.8483
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 2.2351738238057806e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.56 seconds!
[tester] 
AGNewsMetric: acc=0.8315789473684211, hinge=3.999056735415208, ce=8.568254609358938
Local test acc @ epoch 259: 0.8316
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.48 seconds!
[tester] 
AGNewsMetric: acc=0.8444736842105263, hinge=3.7276892072276064, ce=8.410047607421875
Local test acc @ epoch 259: 0.8445
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 5.9604616353681195e-08
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.81 seconds!
[tester] 
AGNewsMetric: acc=0.8331578947368421, hinge=3.9282316575552287, ce=8.437552925912957
Local test acc @ epoch 259: 0.8332
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 2.2351740014414645e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 131.1 seconds!
[tester] 
AGNewsMetric: acc=0.8415789473684211, hinge=3.7986828467720435, ce=8.312993876808568
Local test acc @ epoch 259: 0.8416
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 128.99 seconds!
[tester] 
AGNewsMetric: acc=0.8392105263157895, hinge=3.843805295542667, ce=8.441860624614515
Local test acc @ epoch 259: 0.8392
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 5.960463056453591e-08
Local loss @ local epoch 1: 1.862642307060014e-07
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.5591626763343811
Local loss @ local epoch 4: 1.4901159417490817e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.62 seconds!
[tester] 
AGNewsMetric: acc=0.8189473684210526, hinge=3.817619518229836, ce=8.582942932530454
Local test acc @ epoch 259: 0.8189
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.4901159417490817e-08
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.55 seconds!
[tester] 
AGNewsMetric: acc=0.8436842105263158, hinge=3.6812818303861117, ce=8.40913591686048
Local test acc @ epoch 259: 0.8437
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.69 seconds!
[tester] 
AGNewsMetric: acc=0.8442105263157895, hinge=3.7048663287413746, ce=8.27774196524369
Local test acc @ epoch 259: 0.8442
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.24 seconds!
[tester] 
AGNewsMetric: acc=0.8352631578947368, hinge=3.8980218167054024, ce=8.662351970672608
Local test acc @ epoch 259: 0.8353
Global evaluate on test data...
Evaluate data in 130.16 seconds!
[tester] 
AGNewsMetric: acc=0.8451315789473685, hinge=3.6915375473624783, ce=8.322825473986175
Global test acc @ epoch 259: 0.8451
Global epoch 260...
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 5.9604616353681195e-08
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 8.195632972274325e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.46 seconds!
[tester] 
AGNewsMetric: acc=0.8431578947368421, hinge=3.7742479281676444, ce=8.160593946356522
Local test acc @ epoch 260: 0.8432
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 1.2665974225001264e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.09 seconds!
[tester] 
AGNewsMetric: acc=0.8451315789473685, hinge=3.6679020668330944, ce=8.411337106604325
Local test acc @ epoch 260: 0.8451
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.74 seconds!
[tester] 
AGNewsMetric: acc=0.8425, hinge=3.72495708314996, ce=8.21612107728657
Local test acc @ epoch 260: 0.8425
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 131.36 seconds!
[tester] 
AGNewsMetric: acc=0.8439473684210527, hinge=3.6567474435505116, ce=8.309267836119
Local test acc @ epoch 260: 0.8439
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 3.725289587919178e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.56 seconds!
[tester] 
AGNewsMetric: acc=0.839078947368421, hinge=3.7965811485993233, ce=8.491467099440726
Local test acc @ epoch 260: 0.8391
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 2.2351740014414645e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.72 seconds!
[tester] 
AGNewsMetric: acc=0.8405263157894737, hinge=3.829463444634488, ce=8.482951211427388
Local test acc @ epoch 260: 0.8405
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.86 seconds!
[tester] 
AGNewsMetric: acc=0.8423684210526315, hinge=3.7235005042427463, ce=8.21367014533595
Local test acc @ epoch 260: 0.8424
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.9802318834981634e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.54 seconds!
[tester] 
AGNewsMetric: acc=0.8492105263157895, hinge=3.6283066676792344, ce=8.185157378347297
Local test acc @ epoch 260: 0.8492
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901159417490817e-08
Local loss @ local epoch 1: 2.9802318834981634e-08
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.2351740014414645e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 131.12 seconds!
[tester] 
AGNewsMetric: acc=0.8376315789473684, hinge=3.607266019143556, ce=8.428529052734374
Local test acc @ epoch 260: 0.8376
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 3.7252892326478104e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.34 seconds!
[tester] 
AGNewsMetric: acc=0.8315789473684211, hinge=4.013928292676022, ce=8.735346822236714
Local test acc @ epoch 260: 0.8316
Global evaluate on test data...
Evaluate data in 130.43 seconds!
[tester] 
AGNewsMetric: acc=0.8438157894736842, hinge=3.7266009918012117, ce=8.349250722182424
Global test acc @ epoch 260: 0.8438
Global epoch 261...
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 1.639126594454865e-07
Local loss @ local epoch 1: 1.4901159417490817e-08
Local loss @ local epoch 2: 9.685751933830034e-08
Local loss @ local epoch 3: 2.2351740014414645e-08
Local loss @ local epoch 4: 1.4901159417490817e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.09 seconds!
[tester] 
AGNewsMetric: acc=0.7934210526315789, hinge=4.869133446593033, ce=9.716274624874718
Local test acc @ epoch 261: 0.7934
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901159417490817e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.4156088923300558e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.05 seconds!
[tester] 
AGNewsMetric: acc=0.8475, hinge=3.5645095544112357, ce=8.14308053468403
Local test acc @ epoch 261: 0.8475
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.4901159417490817e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.61 seconds!
[tester] 
AGNewsMetric: acc=0.8430263157894737, hinge=3.7667355519846866, ce=8.390899510634572
Local test acc @ epoch 261: 0.843
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.9802318834981634e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.49 seconds!
[tester] 
AGNewsMetric: acc=0.8447368421052631, hinge=3.6971861364966943, ce=8.277435878954435
Local test acc @ epoch 261: 0.8447
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 5.960462345910855e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.1175863079415649e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.14 seconds!
[tester] 
AGNewsMetric: acc=0.8289473684210527, hinge=4.097876000906291, ce=8.730556732980828
Local test acc @ epoch 261: 0.8289
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 3.278247504567844e-07
Local loss @ local epoch 1: 0.0001202342173201032
Local loss @ local epoch 2: 8.195635814445268e-08
Local loss @ local epoch 3: 2.8833228498115204e-06
Local loss @ local epoch 4: 0.0001260436838492751
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.7 seconds!
[tester] 
AGNewsMetric: acc=0.8286842105263158, hinge=3.7194054116700825, ce=8.030827026367188
Local test acc @ epoch 261: 0.8287
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 2.2351740014414645e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.44 seconds!
[tester] 
AGNewsMetric: acc=0.7938157894736843, hinge=5.076358658640008, ce=9.432966846666838
Local test acc @ epoch 261: 0.7938
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 3.7252892326478104e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 5.215404996761208e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.49 seconds!
[tester] 
AGNewsMetric: acc=0.7259210526315789, hinge=7.038072363200941, ce=10.937542296961734
Local test acc @ epoch 261: 0.7259
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 2.2351740014414645e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.9802315282267955e-08
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.03 seconds!
[tester] 
AGNewsMetric: acc=0.8101315789473684, hinge=4.7834178563168175, ce=9.177022596660413
Local test acc @ epoch 261: 0.8101
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.18 seconds!
[tester] 
AGNewsMetric: acc=0.8447368421052631, hinge=3.6895074934708445, ce=8.335537478798313
Local test acc @ epoch 261: 0.8447
Global evaluate on test data...
Evaluate data in 130.1 seconds!
[tester] 
AGNewsMetric: acc=0.8364473684210526, hinge=4.009669503663716, ce=8.471389975296823
Global test acc @ epoch 261: 0.8364
Global epoch 262...
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 1.4901159417490817e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.92 seconds!
[tester] 
AGNewsMetric: acc=0.8388157894736842, hinge=3.9041622859553287, ce=8.408140826978181
Local test acc @ epoch 262: 0.8388
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 3.725289587919178e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.85 seconds!
[tester] 
AGNewsMetric: acc=0.8206578947368421, hinge=4.453194327354431, ce=8.643592073540939
Local test acc @ epoch 262: 0.8207
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.4901159417490817e-08
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.72 seconds!
[tester] 
AGNewsMetric: acc=0.8351315789473684, hinge=3.9395092519960904, ce=8.383957971271716
Local test acc @ epoch 262: 0.8351
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 3.7252892326478104e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.4 seconds!
[tester] 
AGNewsMetric: acc=0.8331578947368421, hinge=4.1060346748954375, ce=8.477637804934853
Local test acc @ epoch 262: 0.8332
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 4.321321682709822e-07
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 5.289895739224448e-07
Local loss @ local epoch 3: 1.4901159417490817e-08
Local loss @ local epoch 4: 7.733240636298433e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.74 seconds!
[tester] 
AGNewsMetric: acc=0.8310526315789474, hinge=3.6044587165430975, ce=8.188182429263467
Local test acc @ epoch 262: 0.8311
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.03 seconds!
[tester] 
AGNewsMetric: acc=0.8402631578947368, hinge=3.8923975746255173, ce=8.286715152138157
Local test acc @ epoch 262: 0.8403
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 9.685746960030883e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.48 seconds!
[tester] 
AGNewsMetric: acc=0.8238157894736842, hinge=4.335129847275583, ce=8.652629039162084
Local test acc @ epoch 262: 0.8238
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 2.2351738238057806e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.61 seconds!
[tester] 
AGNewsMetric: acc=0.8313157894736842, hinge=4.1326385545730595, ce=8.531625546907124
Local test acc @ epoch 262: 0.8313
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 5.2154042862184724e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.4901159417490817e-08
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.54 seconds!
[tester] 
AGNewsMetric: acc=0.8364473684210526, hinge=4.027735278982865, ce=8.841451080723813
Local test acc @ epoch 262: 0.8364
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 3.725289587919178e-08
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.52 seconds!
[tester] 
AGNewsMetric: acc=0.8376315789473684, hinge=3.8658661061839052, ce=8.600415802001953
Local test acc @ epoch 262: 0.8376
Global evaluate on test data...
Evaluate data in 131.28 seconds!
[tester] 
AGNewsMetric: acc=0.8389473684210527, hinge=3.889605783161364, ce=8.35802437430934
Global test acc @ epoch 262: 0.8389
Global epoch 263...
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901159417490817e-08
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 8.940690321423972e-08
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 3.725289587919178e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.91 seconds!
[tester] 
AGNewsMetric: acc=0.8443421052631579, hinge=3.6356791122336136, ce=8.511823161275764
Local test acc @ epoch 263: 0.8443
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 1.4901159417490817e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.96 seconds!
[tester] 
AGNewsMetric: acc=0.8375, hinge=3.8939110824936316, ce=8.38809560273823
Local test acc @ epoch 263: 0.8375
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.06 seconds!
[tester] 
AGNewsMetric: acc=0.8389473684210527, hinge=3.881261736970199, ce=8.344617883782638
Local test acc @ epoch 263: 0.8389
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450577754752885e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.17 seconds!
[tester] 
AGNewsMetric: acc=0.8423684210526315, hinge=3.762337437428926, ce=8.309343957399067
Local test acc @ epoch 263: 0.8424
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.4901159417490817e-08
Local loss @ local epoch 3: 1.4901159417490817e-08
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.4 seconds!
[tester] 
AGNewsMetric: acc=0.8427631578947369, hinge=3.780512497299596, ce=8.28865365379735
Local test acc @ epoch 263: 0.8428
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.4901159417490817e-08
Local loss @ local epoch 3: 2.2351702000378282e-07
Local loss @ local epoch 4: 8.195634393359796e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.91 seconds!
[tester] 
AGNewsMetric: acc=0.8326315789473684, hinge=3.9336221177954425, ce=8.878223702280145
Local test acc @ epoch 263: 0.8326
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.9802320611338473e-08
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.89 seconds!
[tester] 
AGNewsMetric: acc=0.8403947368421053, hinge=3.8775910437734504, ce=8.338594085291811
Local test acc @ epoch 263: 0.8404
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 5.215404996761208e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.02 seconds!
[tester] 
AGNewsMetric: acc=0.8403947368421053, hinge=3.859899098747655, ce=8.467998555835925
Local test acc @ epoch 263: 0.8404
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.65 seconds!
[tester] 
AGNewsMetric: acc=0.8388157894736842, hinge=3.8958578538894653, ce=8.35925099924991
Local test acc @ epoch 263: 0.8388
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.61 seconds!
[tester] 
AGNewsMetric: acc=0.8397368421052631, hinge=3.856420798678147, ce=8.418839994731702
Local test acc @ epoch 263: 0.8397
Global evaluate on test data...
Evaluate data in 130.42 seconds!
[tester] 
AGNewsMetric: acc=0.8409210526315789, hinge=3.827907790761245, ce=8.409170660721628
Global test acc @ epoch 263: 0.8409
Global epoch 264...
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 3.7252892326478104e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 9.68568429016159e-07
Local loss @ local epoch 3: 1.5646212148112681e-07
Local loss @ local epoch 4: 4.470347647611561e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.61 seconds!
[tester] 
AGNewsMetric: acc=0.8335526315789473, hinge=3.789661871759515, ce=8.48320484161377
Local test acc @ epoch 264: 0.8336
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 131.04 seconds!
[tester] 
AGNewsMetric: acc=0.8402631578947368, hinge=3.8421951945204484, ce=8.407706975434955
Local test acc @ epoch 264: 0.8403
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 4.470347292340193e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.22 seconds!
[tester] 
AGNewsMetric: acc=0.8134210526315789, hinge=4.559666023254395, ce=9.01602780191522
Local test acc @ epoch 264: 0.8134
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.2351738238057806e-08
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.61 seconds!
[tester] 
AGNewsMetric: acc=0.8438157894736842, hinge=3.788493978349786, ce=8.348049318413985
Local test acc @ epoch 264: 0.8438
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.0 seconds!
[tester] 
AGNewsMetric: acc=0.8438157894736842, hinge=3.761378371841029, ce=8.391527827413459
Local test acc @ epoch 264: 0.8438
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 131.29 seconds!
[tester] 
AGNewsMetric: acc=0.8403947368421053, hinge=3.7805045115320306, ce=8.426138038635253
Local test acc @ epoch 264: 0.8404
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.25 seconds!
[tester] 
AGNewsMetric: acc=0.8407894736842105, hinge=3.859428366861845, ce=8.43027307911923
Local test acc @ epoch 264: 0.8408
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.28 seconds!
[tester] 
AGNewsMetric: acc=0.8407894736842105, hinge=3.8034838875971344, ce=8.40518815793489
Local test acc @ epoch 264: 0.8408
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.4901159417490817e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.69 seconds!
[tester] 
AGNewsMetric: acc=0.845657894736842, hinge=3.7579853060371, ce=8.291302978114079
Local test acc @ epoch 264: 0.8457
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.14 seconds!
[tester] 
AGNewsMetric: acc=0.8411842105263158, hinge=3.7689368875403155, ce=8.38252749292474
Local test acc @ epoch 264: 0.8412
Global evaluate on test data...
Evaluate data in 130.17 seconds!
[tester] 
AGNewsMetric: acc=0.8411842105263158, hinge=3.844619003722542, ce=8.42808285863776
Global test acc @ epoch 264: 0.8412
Global epoch 265...
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901159417490817e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.76 seconds!
[tester] 
AGNewsMetric: acc=0.8381578947368421, hinge=3.874768373966217, ce=8.406187520278127
Local test acc @ epoch 265: 0.8382
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.2351740014414645e-08
Local loss @ local epoch 4: 5.215404996761208e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.05 seconds!
[tester] 
AGNewsMetric: acc=0.8371052631578947, hinge=3.8339524936676024, ce=8.478429905740839
Local test acc @ epoch 265: 0.8371
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901159417490817e-08
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.38 seconds!
[tester] 
AGNewsMetric: acc=0.8392105263157895, hinge=3.8399488070136623, ce=8.661831726274992
Local test acc @ epoch 265: 0.8392
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.67 seconds!
[tester] 
AGNewsMetric: acc=0.8409210526315789, hinge=3.8238425169493024, ce=8.448349290145071
Local test acc @ epoch 265: 0.8409
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.69 seconds!
[tester] 
AGNewsMetric: acc=0.8389473684210527, hinge=3.8717667233316524, ce=8.408811946668123
Local test acc @ epoch 265: 0.8389
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.49 seconds!
[tester] 
AGNewsMetric: acc=0.8423684210526315, hinge=3.7951089471264887, ce=8.384203423951801
Local test acc @ epoch 265: 0.8424
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.68 seconds!
[tester] 
AGNewsMetric: acc=0.8335526315789473, hinge=3.954373651303743, ce=8.475187078777113
Local test acc @ epoch 265: 0.8336
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 1.4901159417490817e-08
Local loss @ local epoch 3: 4.4703469370688254e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.43 seconds!
[tester] 
AGNewsMetric: acc=0.8386842105263158, hinge=3.9254826679982635, ce=8.62645970796284
Local test acc @ epoch 265: 0.8387
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.94 seconds!
[tester] 
AGNewsMetric: acc=0.8372368421052632, hinge=3.8728662108120164, ce=8.466496523806923
Local test acc @ epoch 265: 0.8372
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 3.7252892326478104e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 7.450579175838357e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.51 seconds!
[tester] 
AGNewsMetric: acc=0.7961842105263158, hinge=5.026850681806866, ce=9.455416133278295
Local test acc @ epoch 265: 0.7962
Global evaluate on test data...
Evaluate data in 130.18 seconds!
[tester] 
AGNewsMetric: acc=0.8402631578947368, hinge=3.834922951397143, ce=8.467921373467696
Global test acc @ epoch 265: 0.8403
Global epoch 266...
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.2351740014414645e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.73 seconds!
[tester] 
AGNewsMetric: acc=0.8393421052631579, hinge=3.79937380665227, ce=8.477877229389392
Local test acc @ epoch 266: 0.8393
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.38 seconds!
[tester] 
AGNewsMetric: acc=0.8401315789473685, hinge=3.7882360091962313, ce=8.517246454138505
Local test acc @ epoch 266: 0.8401
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 1.9445715224719606e-06
Local loss @ local epoch 1: 0.12086503952741623
Local loss @ local epoch 2: 2.384182096193399e-07
Local loss @ local epoch 3: 1.178628921508789
Local loss @ local epoch 4: 0.2418520450592041
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.39 seconds!
[tester] 
AGNewsMetric: acc=0.7923684210526316, hinge=4.3509906457599845, ce=9.233419695402446
Local test acc @ epoch 266: 0.7924
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 9.462165735385497e-07
Local loss @ local epoch 3: 1.4901159417490817e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.16 seconds!
[tester] 
AGNewsMetric: acc=0.8393421052631579, hinge=3.6185908169495433, ce=8.123920823147422
Local test acc @ epoch 266: 0.8393
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 4.4703469370688254e-08
Local loss @ local epoch 1: 5.2154042862184724e-08
Local loss @ local epoch 2: 2.2351740014414645e-08
Local loss @ local epoch 3: 5.848434284416726e-06
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.44 seconds!
[tester] 
AGNewsMetric: acc=0.7490789473684211, hinge=6.152644658841585, ce=9.909986570257889
Local test acc @ epoch 266: 0.7491
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.4901159417490817e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.98 seconds!
[tester] 
AGNewsMetric: acc=0.8396052631578947, hinge=3.7554279252102503, ce=8.33515429747732
Local test acc @ epoch 266: 0.8396
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.77 seconds!
[tester] 
AGNewsMetric: acc=0.8453947368421053, hinge=3.738344341202786, ce=8.481276644656532
Local test acc @ epoch 266: 0.8454
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.89 seconds!
[tester] 
AGNewsMetric: acc=0.841842105263158, hinge=3.757712864248376, ce=8.414649088006271
Local test acc @ epoch 266: 0.8418
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.81 seconds!
[tester] 
AGNewsMetric: acc=0.8444736842105263, hinge=3.724621429317876, ce=8.187313520531905
Local test acc @ epoch 266: 0.8445
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.48 seconds!
[tester] 
AGNewsMetric: acc=0.8323684210526315, hinge=4.047632061933216, ce=8.617324405469393
Local test acc @ epoch 266: 0.8324
Global evaluate on test data...
Evaluate data in 129.99 seconds!
[tester] 
AGNewsMetric: acc=0.8378947368421052, hinge=3.837920476762872, ce=8.439575011604711
Global test acc @ epoch 266: 0.8379
Global epoch 267...
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 1.043080430918053e-07
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 5.960463411724959e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.96 seconds!
[tester] 
AGNewsMetric: acc=0.8382894736842105, hinge=3.74812822705821, ce=8.458625136927555
Local test acc @ epoch 267: 0.8383
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.92 seconds!
[tester] 
AGNewsMetric: acc=0.839078947368421, hinge=3.7564427624250714, ce=8.417808827851948
Local test acc @ epoch 267: 0.8391
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 3.7252892326478104e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.76 seconds!
[tester] 
AGNewsMetric: acc=0.8422368421052632, hinge=3.765852793015932, ce=8.311873179987858
Local test acc @ epoch 267: 0.8422
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 2.2351738238057806e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.4 seconds!
[tester] 
AGNewsMetric: acc=0.8439473684210527, hinge=3.742672083879772, ce=8.487179233149478
Local test acc @ epoch 267: 0.8439
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.45 seconds!
[tester] 
AGNewsMetric: acc=0.8378947368421052, hinge=3.8161722459291156, ce=8.47345498335989
Local test acc @ epoch 267: 0.8379
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.26 seconds!
[tester] 
AGNewsMetric: acc=0.8380263157894737, hinge=3.809606646989521, ce=8.433941537957443
Local test acc @ epoch 267: 0.838
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 5.215405352032576e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.2351738238057806e-08
Local loss @ local epoch 3: 4.395827204461966e-07
Local loss @ local epoch 4: 4.4703469370688254e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.25 seconds!
[tester] 
AGNewsMetric: acc=0.8077631578947368, hinge=4.304143774634913, ce=9.028226802223607
Local test acc @ epoch 267: 0.8078
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.82 seconds!
[tester] 
AGNewsMetric: acc=0.8368421052631579, hinge=3.7924409906487715, ce=8.510207689184892
Local test acc @ epoch 267: 0.8368
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.4901159417490817e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.62 seconds!
[tester] 
AGNewsMetric: acc=0.8342105263157895, hinge=3.8768165262121905, ce=8.426964483763042
Local test acc @ epoch 267: 0.8342
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 1.1175866632129328e-07
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.1175866632129328e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.58 seconds!
[tester] 
AGNewsMetric: acc=0.8359210526315789, hinge=3.591369875104804, ce=8.42824892244841
Local test acc @ epoch 267: 0.8359
Global evaluate on test data...
Evaluate data in 130.92 seconds!
[tester] 
AGNewsMetric: acc=0.8397368421052631, hinge=3.766432679075944, ce=8.433849055641575
Global test acc @ epoch 267: 0.8397
Global epoch 268...
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 8.195634393359796e-08
Local loss @ local epoch 2: 6.705518984517767e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 3.725289943190546e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.92 seconds!
[tester] 
AGNewsMetric: acc=0.8076315789473684, hinge=4.5305436036461275, ce=9.22697544700221
Local test acc @ epoch 268: 0.8076
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 2.2351740014414645e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.73 seconds!
[tester] 
AGNewsMetric: acc=0.8421052631578947, hinge=3.6580858904437017, ce=8.65069499266775
Local test acc @ epoch 268: 0.8421
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.33 seconds!
[tester] 
AGNewsMetric: acc=0.8396052631578947, hinge=3.7879505629288523, ce=8.504699094671953
Local test acc @ epoch 268: 0.8396
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.71 seconds!
[tester] 
AGNewsMetric: acc=0.8403947368421053, hinge=3.7475067367051778, ce=8.515171110253585
Local test acc @ epoch 268: 0.8404
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.22 seconds!
[tester] 
AGNewsMetric: acc=0.8409210526315789, hinge=3.6933438240854364, ce=8.425859645040411
Local test acc @ epoch 268: 0.8409
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.2351738238057806e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.04 seconds!
[tester] 
AGNewsMetric: acc=0.8413157894736842, hinge=3.7303827978435318, ce=8.377715374796015
Local test acc @ epoch 268: 0.8413
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450577754752885e-08
Local loss @ local epoch 1: 5.960462345910855e-08
Local loss @ local epoch 2: 6.705521116145974e-08
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 1.3187393506086664e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.16 seconds!
[tester] 
AGNewsMetric: acc=0.8169736842105263, hinge=4.1076356837624, ce=9.464554443359376
Local test acc @ epoch 268: 0.817
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 131.4 seconds!
[tester] 
AGNewsMetric: acc=0.8397368421052631, hinge=3.7940360872369063, ce=8.117879499134265
Local test acc @ epoch 268: 0.8397
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 131.73 seconds!
[tester] 
AGNewsMetric: acc=0.8392105263157895, hinge=3.764325311058446, ce=8.43709147302728
Local test acc @ epoch 268: 0.8392
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.44 seconds!
[tester] 
AGNewsMetric: acc=0.8401315789473685, hinge=3.749815706453825, ce=8.379455603549355
Local test acc @ epoch 268: 0.8401
Global evaluate on test data...
Evaluate data in 130.23 seconds!
[tester] 
AGNewsMetric: acc=0.8375, hinge=3.848604010029843, ce=8.55706765726993
Global test acc @ epoch 268: 0.8375
Global epoch 269...
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.4901159417490817e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.8 seconds!
[tester] 
AGNewsMetric: acc=0.8398684210526316, hinge=3.8060507525895773, ce=8.282122843892951
Local test acc @ epoch 269: 0.8399
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.18 seconds!
[tester] 
AGNewsMetric: acc=0.8377631578947369, hinge=3.8275747356916727, ce=8.552242183685303
Local test acc @ epoch 269: 0.8378
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 1.2665974225001264e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.3671434223651886
Local loss @ local epoch 3: 4.246824403253413e-07
Local loss @ local epoch 4: 6.965984084672527e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.8 seconds!
[tester] 
AGNewsMetric: acc=0.7351315789473685, hinge=5.457803013450221, ce=10.233720181113796
Local test acc @ epoch 269: 0.7351
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901159417490817e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.4901159417490817e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.71 seconds!
[tester] 
AGNewsMetric: acc=0.833421052631579, hinge=3.873034109818308, ce=8.480469162589625
Local test acc @ epoch 269: 0.8334
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 1.7583124645170756e-06
Local loss @ local epoch 1: 1.7359718640364008e-06
Local loss @ local epoch 2: 0.11073407530784607
Local loss @ local epoch 3: 2.458690460116486e-07
Local loss @ local epoch 4: 2.3672103881835938
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.37 seconds!
[tester] 
AGNewsMetric: acc=0.6828947368421052, hinge=7.012114473644056, ce=10.903570853785464
Local test acc @ epoch 269: 0.6829
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.39 seconds!
[tester] 
AGNewsMetric: acc=0.8380263157894737, hinge=3.8345289443668564, ce=8.522911701202393
Local test acc @ epoch 269: 0.838
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 1.4901159417490817e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.05 seconds!
[tester] 
AGNewsMetric: acc=0.8367105263157895, hinge=3.863213167441519, ce=8.611700513739335
Local test acc @ epoch 269: 0.8367
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.63 seconds!
[tester] 
AGNewsMetric: acc=0.8427631578947369, hinge=3.6446832282919632, ce=8.446197159415798
Local test acc @ epoch 269: 0.8428
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.49 seconds!
[tester] 
AGNewsMetric: acc=0.8378947368421052, hinge=3.8393152342344585, ce=8.508696202729878
Local test acc @ epoch 269: 0.8379
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 3.7252892326478104e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.45 seconds!
[tester] 
AGNewsMetric: acc=0.8439473684210527, hinge=3.7499550523256002, ce=8.334492635224995
Local test acc @ epoch 269: 0.8439
Global evaluate on test data...
Evaluate data in 129.83 seconds!
[tester] 
AGNewsMetric: acc=0.8428947368421053, hinge=3.7194031218478556, ce=8.293873473719547
Global test acc @ epoch 269: 0.8429
Global epoch 270...
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.31 seconds!
[tester] 
AGNewsMetric: acc=0.8405263157894737, hinge=3.801831544951389, ce=8.28317714691162
Local test acc @ epoch 270: 0.8405
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901159417490817e-08
Local loss @ local epoch 1: 2.9802318834981634e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.9802318834981634e-08
Local loss @ local epoch 4: 2.9802315282267955e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.82 seconds!
[tester] 
AGNewsMetric: acc=0.8348684210526316, hinge=3.800902775714272, ce=8.51267091148778
Local test acc @ epoch 270: 0.8349
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.73 seconds!
[tester] 
AGNewsMetric: acc=0.8414473684210526, hinge=3.7272679901123045, ce=8.3331134565253
Local test acc @ epoch 270: 0.8414
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 128.17 seconds!
[tester] 
AGNewsMetric: acc=0.8425, hinge=3.7432534327005085, ce=8.394582477368807
Local test acc @ epoch 270: 0.8425
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.4901159417490817e-08
Local loss @ local epoch 4: 2.9802318834981634e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.4 seconds!
[tester] 
AGNewsMetric: acc=0.8409210526315789, hinge=3.780462309686761, ce=8.325326874381618
Local test acc @ epoch 270: 0.8409
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.4901159417490817e-08
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.26 seconds!
[tester] 
AGNewsMetric: acc=0.8426315789473684, hinge=3.7155392547657615, ce=8.233225925847103
Local test acc @ epoch 270: 0.8426
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 5.9604616353681195e-08
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.0 seconds!
[tester] 
AGNewsMetric: acc=0.815921052631579, hinge=3.969182116734354, ce=9.614535646940533
Local test acc @ epoch 270: 0.8159
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.36 seconds!
[tester] 
AGNewsMetric: acc=0.839078947368421, hinge=3.7632185254598918, ce=8.24678228378296
Local test acc @ epoch 270: 0.8391
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.0058208772534272e-06
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.32444900274276733
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.61 seconds!
[tester] 
AGNewsMetric: acc=0.8230263157894737, hinge=4.184118765529833, ce=8.4931390019467
Local test acc @ epoch 270: 0.823
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 6.705518984517767e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 5.215405352032576e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.43 seconds!
[tester] 
AGNewsMetric: acc=0.8315789473684211, hinge=4.023141035029763, ce=8.288948874222605
Local test acc @ epoch 270: 0.8316
Global evaluate on test data...
Evaluate data in 129.72 seconds!
[tester] 
AGNewsMetric: acc=0.8402631578947368, hinge=3.805723942330009, ce=8.390484408328408
Global test acc @ epoch 270: 0.8403
Global epoch 271...
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.64 seconds!
[tester] 
AGNewsMetric: acc=0.84, hinge=3.7430776056490447, ce=8.350782585144042
Local test acc @ epoch 271: 0.84
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.4901159417490817e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 128.43 seconds!
[tester] 
AGNewsMetric: acc=0.8396052631578947, hinge=3.8489374514629966, ce=8.365748626307438
Local test acc @ epoch 271: 0.8396
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.07 seconds!
[tester] 
AGNewsMetric: acc=0.8397368421052631, hinge=3.787441813318353, ce=8.337105115589342
Local test acc @ epoch 271: 0.8397
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 7.450577754752885e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.02 seconds!
[tester] 
AGNewsMetric: acc=0.8075, hinge=4.718881534275256, ce=8.899607943484657
Local test acc @ epoch 271: 0.8075
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 128.27 seconds!
[tester] 
AGNewsMetric: acc=0.8405263157894737, hinge=3.765812414947309, ce=8.28933134781687
Local test acc @ epoch 271: 0.8405
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 128.46 seconds!
[tester] 
AGNewsMetric: acc=0.8364473684210526, hinge=3.84754173329002, ce=8.49995660882247
Local test acc @ epoch 271: 0.8364
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.2351740014414645e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 128.78 seconds!
[tester] 
AGNewsMetric: acc=0.8411842105263158, hinge=3.7305086960290605, ce=8.35261719151547
Local test acc @ epoch 271: 0.8412
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 128.24 seconds!
[tester] 
AGNewsMetric: acc=0.8402631578947368, hinge=3.7981458288744876, ce=8.45041599574842
Local test acc @ epoch 271: 0.8403
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.2351740014414645e-08
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.36 seconds!
[tester] 
AGNewsMetric: acc=0.829078947368421, hinge=4.0263275352277255, ce=8.585637096605803
Local test acc @ epoch 271: 0.8291
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 128.92 seconds!
[tester] 
AGNewsMetric: acc=0.8355263157894737, hinge=3.904184708846243, ce=8.493514410320081
Local test acc @ epoch 271: 0.8355
Global evaluate on test data...
Evaluate data in 128.12 seconds!
[tester] 
AGNewsMetric: acc=0.8361842105263158, hinge=3.885754742998826, ce=8.432352933381733
Global test acc @ epoch 271: 0.8362
Global epoch 272...
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 128.93 seconds!
[tester] 
AGNewsMetric: acc=0.8325, hinge=3.978498523988222, ce=8.382999232442755
Local test acc @ epoch 272: 0.8325
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 5.960463056453591e-08
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.7881383485018887e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 128.51 seconds!
[tester] 
AGNewsMetric: acc=0.8118421052631579, hinge=4.191869310956252, ce=8.891807467811986
Local test acc @ epoch 272: 0.8118
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 9.215688805852551e-06
Local loss @ local epoch 4: 1.341103512686459e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 127.97 seconds!
[tester] 
AGNewsMetric: acc=0.7092105263157895, hinge=7.823691866021408, ce=11.3567786367316
Local test acc @ epoch 272: 0.7092
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.4901159417490817e-08
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.15 seconds!
[tester] 
AGNewsMetric: acc=0.8373684210526315, hinge=3.8550925237254092, ce=8.437571162173622
Local test acc @ epoch 272: 0.8374
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450576333667414e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 2.2351738238057806e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 128.85 seconds!
[tester] 
AGNewsMetric: acc=0.8172368421052632, hinge=4.21719405124062, ce=8.477824170965897
Local test acc @ epoch 272: 0.8172
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.57 seconds!
[tester] 
AGNewsMetric: acc=0.8389473684210527, hinge=3.8012793431783978, ce=8.435360993837055
Local test acc @ epoch 272: 0.8389
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.4901159417490817e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 128.75 seconds!
[tester] 
AGNewsMetric: acc=0.8419736842105263, hinge=3.8451430897963674, ce=8.235126718219957
Local test acc @ epoch 272: 0.842
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.4901159417490817e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.51 seconds!
[tester] 
AGNewsMetric: acc=0.8351315789473684, hinge=3.89773286819458, ce=8.334153797751979
Local test acc @ epoch 272: 0.8351
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.4901159417490817e-08
Local loss @ local epoch 2: 5.9604616353681195e-08
Local loss @ local epoch 3: 7.971613740664907e-06
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.74 seconds!
[tester] 
AGNewsMetric: acc=0.7894736842105263, hinge=4.802368957243468, ce=8.993004325063605
Local test acc @ epoch 272: 0.7895
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.2351738238057806e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 127.88 seconds!
[tester] 
AGNewsMetric: acc=0.8365789473684211, hinge=3.92826491355896, ce=8.35799015948647
Local test acc @ epoch 272: 0.8366
Global evaluate on test data...
Evaluate data in 128.61 seconds!
[tester] 
AGNewsMetric: acc=0.8369736842105263, hinge=3.901431600043648, ce=8.311380233764648
Global test acc @ epoch 272: 0.837
Global epoch 273...
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.4901159417490817e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.26 seconds!
[tester] 
AGNewsMetric: acc=0.8405263157894737, hinge=3.783039261667352, ce=8.114760608673096
Local test acc @ epoch 273: 0.8405
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 8.940692453052179e-08
Local loss @ local epoch 4: 1.7881369274164172e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.35 seconds!
[tester] 
AGNewsMetric: acc=0.8307894736842105, hinge=4.005312069717206, ce=8.279520285756965
Local test acc @ epoch 273: 0.8308
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.9802318834981634e-08
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.84 seconds!
[tester] 
AGNewsMetric: acc=0.8396052631578947, hinge=3.879248500623201, ce=8.359934476551256
Local test acc @ epoch 273: 0.8396
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.09 seconds!
[tester] 
AGNewsMetric: acc=0.8381578947368421, hinge=3.846063931866696, ce=8.22879345542506
Local test acc @ epoch 273: 0.8382
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 5.811428422930476e-07
Local loss @ local epoch 1: 1.4901159417490817e-08
Local loss @ local epoch 2: 0.6441173553466797
Local loss @ local epoch 3: 3.3527584264447796e-07
Local loss @ local epoch 4: 0.32604366540908813
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 128.9 seconds!
[tester] 
AGNewsMetric: acc=0.8288157894736842, hinge=3.156144058955343, ce=8.394632088510614
Local test acc @ epoch 273: 0.8288
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.4901159417490817e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.2 seconds!
[tester] 
AGNewsMetric: acc=0.8378947368421052, hinge=3.8832604041852448, ce=8.32926836415341
Local test acc @ epoch 273: 0.8379
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 9.760184411788941e-07
Local loss @ local epoch 1: 2.2351740014414645e-08
Local loss @ local epoch 2: 1.3944547176361084
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.8149061799049377
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.84 seconds!
[tester] 
AGNewsMetric: acc=0.7238157894736842, hinge=5.812846296711972, ce=11.006912755464253
Local test acc @ epoch 273: 0.7238
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.89 seconds!
[tester] 
AGNewsMetric: acc=0.8348684210526316, hinge=3.898979741397657, ce=8.257378983748586
Local test acc @ epoch 273: 0.8349
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 2.9802315282267955e-08
Local loss @ local epoch 2: 1.4901159417490817e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.2351738238057806e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.99 seconds!
[tester] 
AGNewsMetric: acc=0.8421052631578947, hinge=3.727259583096755, ce=8.296578960418701
Local test acc @ epoch 273: 0.8421
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 2.2351738238057806e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.66 seconds!
[tester] 
AGNewsMetric: acc=0.8381578947368421, hinge=3.9401450818463375, ce=8.293292255401612
Local test acc @ epoch 273: 0.8382
Global evaluate on test data...
Evaluate data in 129.78 seconds!
[tester] 
AGNewsMetric: acc=0.8414473684210526, hinge=3.681744247737684, ce=8.146718932703921
Global test acc @ epoch 273: 0.8414
Global epoch 274...
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 5.2154042862184724e-08
Local loss @ local epoch 2: 3.278248641436221e-07
Local loss @ local epoch 3: 2.2351740014414645e-08
Local loss @ local epoch 4: 1.4901159417490817e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.53 seconds!
[tester] 
AGNewsMetric: acc=0.720657894736842, hinge=7.38810884074161, ce=11.328845443725585
Local test acc @ epoch 274: 0.7207
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 1.4901159417490817e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.55 seconds!
[tester] 
AGNewsMetric: acc=0.8305263157894737, hinge=3.919790673381404, ce=8.281686237736752
Local test acc @ epoch 274: 0.8305
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.2 seconds!
[tester] 
AGNewsMetric: acc=0.8402631578947368, hinge=3.7089874741905615, ce=8.110325187883879
Local test acc @ epoch 274: 0.8403
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 3.7252892326478104e-08
Local loss @ local epoch 2: 5.9604616353681195e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.04 seconds!
[tester] 
AGNewsMetric: acc=0.8388157894736842, hinge=3.8422513474916156, ce=8.126164494564659
Local test acc @ epoch 274: 0.8388
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.14 seconds!
[tester] 
AGNewsMetric: acc=0.8419736842105263, hinge=3.6549507521328173, ce=8.049720694893285
Local test acc @ epoch 274: 0.842
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.2351740014414645e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.84 seconds!
[tester] 
AGNewsMetric: acc=0.8142105263157895, hinge=4.459867912342673, ce=8.74696916680587
Local test acc @ epoch 274: 0.8142
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 3.251332600484602e-05
Local loss @ local epoch 1: 6.726208209991455
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 7.748574262222974e-07
Local loss @ local epoch 4: 2.9697773456573486
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.48 seconds!
[tester] 
AGNewsMetric: acc=0.7501315789473684, hinge=4.895978760091882, ce=10.439049901460347
Local test acc @ epoch 274: 0.7501
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.72 seconds!
[tester] 
AGNewsMetric: acc=0.8481578947368421, hinge=3.563682326768574, ce=7.982766928421824
Local test acc @ epoch 274: 0.8482
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.61 seconds!
[tester] 
AGNewsMetric: acc=0.8460526315789474, hinge=3.649816407153481, ce=8.17453386607923
Local test acc @ epoch 274: 0.8461
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 1.1920917586394353e-07
Local loss @ local epoch 1: 7.55032742745243e-05
Local loss @ local epoch 2: 2.3841815277592104e-07
Local loss @ local epoch 3: 1.1771873005272937e-06
Local loss @ local epoch 4: 0.03846250846982002
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.81 seconds!
[tester] 
AGNewsMetric: acc=0.805, hinge=4.23447999929127, ce=8.413571693018863
Local test acc @ epoch 274: 0.805
Global evaluate on test data...
Evaluate data in 129.86 seconds!
[tester] 
AGNewsMetric: acc=0.8482894736842105, hinge=3.540581074513887, ce=7.968551620684172
Global test acc @ epoch 274: 0.8483
Global epoch 275...
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 5.215405707303944e-08
Local loss @ local epoch 1: 5.215384817347513e-07
Local loss @ local epoch 2: 2.533194845000253e-07
Local loss @ local epoch 3: 2.0597470211214386e-05
Local loss @ local epoch 4: 2.533192287046404e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.68 seconds!
[tester] 
AGNewsMetric: acc=0.8385526315789473, hinge=3.7343103047421105, ce=8.525508446944388
Local test acc @ epoch 275: 0.8386
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 3.352752173668705e-07
Local loss @ local epoch 3: 2.9802318834981634e-08
Local loss @ local epoch 4: 2.2351738238057806e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.95 seconds!
[tester] 
AGNewsMetric: acc=0.8219736842105263, hinge=4.306640066473108, ce=8.619051907188014
Local test acc @ epoch 275: 0.822
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 2.2351740014414645e-08
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.61 seconds!
[tester] 
AGNewsMetric: acc=0.85, hinge=3.5059716337605527, ce=7.897387160251015
Local test acc @ epoch 275: 0.85
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.4901159417490817e-08
Local loss @ local epoch 2: 2.2351740014414645e-08
Local loss @ local epoch 3: 3.725289943190546e-08
Local loss @ local epoch 4: 8.195635814445268e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.73 seconds!
[tester] 
AGNewsMetric: acc=0.8428947368421053, hinge=3.6849279732453195, ce=7.897568578218159
Local test acc @ epoch 275: 0.8429
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.78 seconds!
[tester] 
AGNewsMetric: acc=0.8488157894736842, hinge=3.50231150727523, ce=7.963154979505037
Local test acc @ epoch 275: 0.8488
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 3.725289587919178e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.09 seconds!
[tester] 
AGNewsMetric: acc=0.8468421052631578, hinge=3.5456439925494947, ce=7.874830914547569
Local test acc @ epoch 275: 0.8468
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.1175862368872913e-07
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 4.4703469370688254e-08
Local loss @ local epoch 4: 5.066380595053488e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.31 seconds!
[tester] 
AGNewsMetric: acc=0.8452631578947368, hinge=3.533947500053205, ce=8.249134193219637
Local test acc @ epoch 275: 0.8453
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 2.2351738238057806e-08
Local loss @ local epoch 2: 2.2351740014414645e-08
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.41 seconds!
[tester] 
AGNewsMetric: acc=0.8363157894736842, hinge=3.9310721840356524, ce=8.050766848513955
Local test acc @ epoch 275: 0.8363
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.76 seconds!
[tester] 
AGNewsMetric: acc=0.8435526315789473, hinge=3.6161200983900774, ce=8.057494520890085
Local test acc @ epoch 275: 0.8436
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 4.280382563592866e-05
Local loss @ local epoch 1: 1.4847118854522705
Local loss @ local epoch 2: 4.887421710009221e-06
Local loss @ local epoch 3: 1.2957619428634644
Local loss @ local epoch 4: 0.8857765197753906
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.05 seconds!
[tester] 
AGNewsMetric: acc=0.7826315789473685, hinge=4.5781748899660615, ce=9.834194857948704
Local test acc @ epoch 275: 0.7826
Global evaluate on test data...
Evaluate data in 129.72 seconds!
[tester] 
AGNewsMetric: acc=0.8482894736842105, hinge=3.5598367591908104, ce=8.033476420954655
Global test acc @ epoch 275: 0.8483
Global epoch 276...
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.79 seconds!
[tester] 
AGNewsMetric: acc=0.8405263157894737, hinge=3.6495197690160652, ce=8.014653057299162
Local test acc @ epoch 276: 0.8405
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 2.9802318834981634e-08
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 6.705520405603238e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.66 seconds!
[tester] 
AGNewsMetric: acc=0.8389473684210527, hinge=3.8211201158322785, ce=7.971590155551308
Local test acc @ epoch 276: 0.8389
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901159417490817e-08
Local loss @ local epoch 1: 1.4901159417490817e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.2351738238057806e-08
Local loss @ local epoch 4: 1.4901159417490817e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.85 seconds!
[tester] 
AGNewsMetric: acc=0.8480263157894737, hinge=3.563839080961127, ce=7.804073082773309
Local test acc @ epoch 276: 0.848
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.2351738238057806e-08
Local loss @ local epoch 2: 2.2351738238057806e-08
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.7 seconds!
[tester] 
AGNewsMetric: acc=0.8094736842105263, hinge=4.568409121162013, ce=8.891775974474456
Local test acc @ epoch 276: 0.8095
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 5.960462345910855e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 5.2154042862184724e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.99 seconds!
[tester] 
AGNewsMetric: acc=0.8215789473684211, hinge=4.2942240436453565, ce=8.61991699620297
Local test acc @ epoch 276: 0.8216
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.05 seconds!
[tester] 
AGNewsMetric: acc=0.8467105263157895, hinge=3.588015920990392, ce=8.03369849857531
Local test acc @ epoch 276: 0.8467
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 6.705521116145974e-08
Local loss @ local epoch 2: 2.2351740014414645e-08
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.75 seconds!
[tester] 
AGNewsMetric: acc=0.8348684210526316, hinge=3.883503021190041, ce=8.27161337199964
Local test acc @ epoch 276: 0.8349
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.69 seconds!
[tester] 
AGNewsMetric: acc=0.8486842105263158, hinge=3.5313749073681078, ce=7.953937505420885
Local test acc @ epoch 276: 0.8487
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 3.7252892326478104e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.16 seconds!
[tester] 
AGNewsMetric: acc=0.8498684210526316, hinge=3.5269455106634844, ce=7.963664622055857
Local test acc @ epoch 276: 0.8499
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.06 seconds!
[tester] 
AGNewsMetric: acc=0.8435526315789473, hinge=3.609231945840936, ce=8.138837802284643
Local test acc @ epoch 276: 0.8436
Global evaluate on test data...
Evaluate data in 130.03 seconds!
[tester] 
AGNewsMetric: acc=0.8436842105263158, hinge=3.69071807710748, ce=8.013421576650519
Global test acc @ epoch 276: 0.8437
Global epoch 277...
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.4896586537361145
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.47 seconds!
[tester] 
AGNewsMetric: acc=0.8414473684210526, hinge=3.8988013079291894, ce=8.255992812106484
Local test acc @ epoch 277: 0.8414
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.43 seconds!
[tester] 
AGNewsMetric: acc=0.8439473684210527, hinge=3.6278010210238003, ce=7.990774305243241
Local test acc @ epoch 277: 0.8439
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.17 seconds!
[tester] 
AGNewsMetric: acc=0.844078947368421, hinge=3.661956820487976, ce=7.915791825746235
Local test acc @ epoch 277: 0.8441
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.9802315282267955e-08
Local loss @ local epoch 3: 1.4901159417490817e-08
Local loss @ local epoch 4: 2.2351740014414645e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.14 seconds!
[tester] 
AGNewsMetric: acc=0.8447368421052631, hinge=3.697052722228201, ce=8.011530092138994
Local test acc @ epoch 277: 0.8447
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.3 seconds!
[tester] 
AGNewsMetric: acc=0.8427631578947369, hinge=3.68217007712314, ce=8.008740471287778
Local test acc @ epoch 277: 0.8428
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.2351740014414645e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.2 seconds!
[tester] 
AGNewsMetric: acc=0.8475, hinge=3.6097202583363184, ce=8.056057718176591
Local test acc @ epoch 277: 0.8475
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.47 seconds!
[tester] 
AGNewsMetric: acc=0.8443421052631579, hinge=3.610506422896134, ce=8.034305448030171
Local test acc @ epoch 277: 0.8443
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.78 seconds!
[tester] 
AGNewsMetric: acc=0.8381578947368421, hinge=3.7864910785775434, ce=8.22934439709312
Local test acc @ epoch 277: 0.8382
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 1.1175860947787442e-07
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.84 seconds!
[tester] 
AGNewsMetric: acc=0.8305263157894737, hinge=3.89662543660716, ce=7.969498125377454
Local test acc @ epoch 277: 0.8305
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.1 seconds!
[tester] 
AGNewsMetric: acc=0.8428947368421053, hinge=3.6435383621015047, ce=7.94378649460642
Local test acc @ epoch 277: 0.8429
Global evaluate on test data...
Evaluate data in 130.49 seconds!
[tester] 
AGNewsMetric: acc=0.8472368421052632, hinge=3.598609975513659, ce=7.934070816040039
Global test acc @ epoch 277: 0.8472
Global epoch 278...
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.9802318834981634e-08
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.82 seconds!
[tester] 
AGNewsMetric: acc=0.8403947368421053, hinge=3.8108612665377164, ce=8.096420473801462
Local test acc @ epoch 278: 0.8404
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 3.725289587919178e-08
Local loss @ local epoch 1: 4.470347292340193e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.11 seconds!
[tester] 
AGNewsMetric: acc=0.848421052631579, hinge=3.5457230596793323, ce=8.224175855736984
Local test acc @ epoch 278: 0.8484
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 8.940690321423972e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.28 seconds!
[tester] 
AGNewsMetric: acc=0.8402631578947368, hinge=3.735850116077222, ce=8.114497091393721
Local test acc @ epoch 278: 0.8403
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.862643159711297e-07
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.4391734302043915
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.09 seconds!
[tester] 
AGNewsMetric: acc=0.8142105263157895, hinge=4.385041158952211, ce=8.713068297536749
Local test acc @ epoch 278: 0.8142
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 5.2154042862184724e-08
Local loss @ local epoch 1: 9.685751933830034e-08
Local loss @ local epoch 2: 1.2889424851891818e-06
Local loss @ local epoch 3: 1.9967442312918138e-06
Local loss @ local epoch 4: 0.006854334846138954
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.16 seconds!
[tester] 
AGNewsMetric: acc=0.8172368421052632, hinge=4.056688839259901, ce=8.367397647656892
Local test acc @ epoch 278: 0.8172
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 1.1920923981278975e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 4.4703469370688254e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.89 seconds!
[tester] 
AGNewsMetric: acc=0.8342105263157895, hinge=3.526977836332823, ce=9.009474728232936
Local test acc @ epoch 278: 0.8342
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 3.7252892326478104e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.74 seconds!
[tester] 
AGNewsMetric: acc=0.8475, hinge=3.5915421940151013, ce=7.914626008083946
Local test acc @ epoch 278: 0.8475
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.13 seconds!
[tester] 
AGNewsMetric: acc=0.8465789473684211, hinge=3.5643694049433656, ce=7.920570471914191
Local test acc @ epoch 278: 0.8466
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 3.725289587919178e-08
Local loss @ local epoch 3: 2.9802315282267955e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.87 seconds!
[tester] 
AGNewsMetric: acc=0.8398684210526316, hinge=3.720958188458493, ce=8.10872989252994
Local test acc @ epoch 278: 0.8399
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.18 seconds!
[tester] 
AGNewsMetric: acc=0.8438157894736842, hinge=3.7159113133581063, ce=7.919020356630024
Local test acc @ epoch 278: 0.8438
Global evaluate on test data...
Evaluate data in 130.15 seconds!
[tester] 
AGNewsMetric: acc=0.8435526315789473, hinge=3.7112786323145817, ce=8.115039941888107
Global test acc @ epoch 278: 0.8436
Global epoch 279...
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.07 seconds!
[tester] 
AGNewsMetric: acc=0.838421052631579, hinge=3.767303306554493, ce=8.251058374706068
Local test acc @ epoch 279: 0.8384
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 1.4901159417490817e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.25 seconds!
[tester] 
AGNewsMetric: acc=0.841842105263158, hinge=3.7252790754719785, ce=8.122408379002621
Local test acc @ epoch 279: 0.8418
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 5.2154042862184724e-08
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.15 seconds!
[tester] 
AGNewsMetric: acc=0.7819736842105263, hinge=5.346533235248766, ce=9.50162503292686
Local test acc @ epoch 279: 0.782
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.05 seconds!
[tester] 
AGNewsMetric: acc=0.8423684210526315, hinge=3.691861813570324, ce=8.14802624752647
Local test acc @ epoch 279: 0.8424
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 1.4901159417490817e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.74 seconds!
[tester] 
AGNewsMetric: acc=0.8411842105263158, hinge=3.764660771771481, ce=8.144210254267643
Local test acc @ epoch 279: 0.8412
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901159417490817e-08
Local loss @ local epoch 1: 5.960463056453591e-08
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.05 seconds!
[tester] 
AGNewsMetric: acc=0.8463157894736842, hinge=3.6448303285397983, ce=8.067079214798778
Local test acc @ epoch 279: 0.8463
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 6.705519695060502e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.84 seconds!
[tester] 
AGNewsMetric: acc=0.8242105263157895, hinge=4.241895700002972, ce=8.636032560248124
Local test acc @ epoch 279: 0.8242
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 3.151516466459725e-06
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.41 seconds!
[tester] 
AGNewsMetric: acc=0.8210526315789474, hinge=4.376333050853328, ce=8.82362051813226
Local test acc @ epoch 279: 0.8211
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 2.3096760060070665e-07
Local loss @ local epoch 2: 1.6391261681292235e-07
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.73 seconds!
[tester] 
AGNewsMetric: acc=0.820921052631579, hinge=3.9554032077287373, ce=8.968411501834266
Local test acc @ epoch 279: 0.8209
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.07 seconds!
[tester] 
AGNewsMetric: acc=0.8417105263157895, hinge=3.6958726034666363, ce=8.106452253241288
Local test acc @ epoch 279: 0.8417
Global evaluate on test data...
Evaluate data in 129.65 seconds!
[tester] 
AGNewsMetric: acc=0.8427631578947369, hinge=3.703429176932887, ce=8.190221488350316
Global test acc @ epoch 279: 0.8428
Global epoch 280...
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.4901159417490817e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.45 seconds!
[tester] 
AGNewsMetric: acc=0.8442105263157895, hinge=3.638117828996558, ce=8.13986497577868
Local test acc @ epoch 280: 0.8442
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.92 seconds!
[tester] 
AGNewsMetric: acc=0.8411842105263158, hinge=3.7145491701678224, ce=8.136481030112819
Local test acc @ epoch 280: 0.8412
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 1.3783429722025176e-06
Local loss @ local epoch 1: 1.7508621112938272e-06
Local loss @ local epoch 2: 1.564621072702721e-07
Local loss @ local epoch 3: 6.332975317491218e-07
Local loss @ local epoch 4: 9.685753354915505e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.37 seconds!
[tester] 
AGNewsMetric: acc=0.8307894736842105, hinge=3.345600085007517, ce=9.22029516521253
Local test acc @ epoch 280: 0.8308
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.17 seconds!
[tester] 
AGNewsMetric: acc=0.8423684210526315, hinge=3.6645188961530986, ce=8.235423648231908
Local test acc @ epoch 280: 0.8424
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 2.9802315282267955e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.2351740014414645e-08
Local loss @ local epoch 3: 2.2351740014414645e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.47 seconds!
[tester] 
AGNewsMetric: acc=0.8438157894736842, hinge=3.568779391865981, ce=7.996483547813014
Local test acc @ epoch 280: 0.8438
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.67 seconds!
[tester] 
AGNewsMetric: acc=0.841842105263158, hinge=3.698513057733837, ce=8.196951166454115
Local test acc @ epoch 280: 0.8418
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.66 seconds!
[tester] 
AGNewsMetric: acc=0.8423684210526315, hinge=3.6791742772805063, ce=8.254647331237793
Local test acc @ epoch 280: 0.8424
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.17 seconds!
[tester] 
AGNewsMetric: acc=0.8436842105263158, hinge=3.618742451291335, ce=8.234706575494064
Local test acc @ epoch 280: 0.8437
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.91 seconds!
[tester] 
AGNewsMetric: acc=0.8417105263157895, hinge=3.7553555360593296, ce=8.282150169171786
Local test acc @ epoch 280: 0.8417
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.5646212148112681e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.74 seconds!
[tester] 
AGNewsMetric: acc=0.8428947368421053, hinge=3.7635292654288444, ce=8.236860853496351
Local test acc @ epoch 280: 0.8429
Global evaluate on test data...
Evaluate data in 129.49 seconds!
[tester] 
AGNewsMetric: acc=0.8423684210526315, hinge=3.7094284593431572, ce=8.273962294929905
Global test acc @ epoch 280: 0.8424
Global epoch 281...
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.14 seconds!
[tester] 
AGNewsMetric: acc=0.8425, hinge=3.6555665938477766, ce=8.235305690765381
Local test acc @ epoch 281: 0.8425
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.85 seconds!
[tester] 
AGNewsMetric: acc=0.8403947368421053, hinge=3.7267546004998056, ce=8.332317591215435
Local test acc @ epoch 281: 0.8404
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.78 seconds!
[tester] 
AGNewsMetric: acc=0.8409210526315789, hinge=3.7498652700374002, ce=8.303065727635433
Local test acc @ epoch 281: 0.8409
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 131.54 seconds!
[tester] 
AGNewsMetric: acc=0.8403947368421053, hinge=3.699023798766889, ce=8.220332483994333
Local test acc @ epoch 281: 0.8404
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.4901159417490817e-08
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 2.2351738238057806e-08
Local loss @ local epoch 4: 1.4901159417490817e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.22 seconds!
[tester] 
AGNewsMetric: acc=0.84, hinge=3.701852912400898, ce=8.109054407822459
Local test acc @ epoch 281: 0.84
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.4 seconds!
[tester] 
AGNewsMetric: acc=0.8425, hinge=3.7118188016038194, ce=8.240029596027576
Local test acc @ epoch 281: 0.8425
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.31 seconds!
[tester] 
AGNewsMetric: acc=0.8421052631578947, hinge=3.7124993985577635, ce=8.289957785355417
Local test acc @ epoch 281: 0.8421
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901159417490817e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.043080430918053e-07
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.04 seconds!
[tester] 
AGNewsMetric: acc=0.7671052631578947, hinge=5.460726806615528, ce=9.992024154663087
Local test acc @ epoch 281: 0.7671
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.54 seconds!
[tester] 
AGNewsMetric: acc=0.8435526315789473, hinge=3.630530155332465, ce=8.272880390568783
Local test acc @ epoch 281: 0.8436
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.473544100212166e-06
Local loss @ local epoch 2: 2.2351740014414645e-08
Local loss @ local epoch 3: 0.013974600471556187
Local loss @ local epoch 4: 3.889082563546253e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.31 seconds!
[tester] 
AGNewsMetric: acc=0.7935526315789474, hinge=4.818236094775953, ce=8.950117771751001
Local test acc @ epoch 281: 0.7936
Global evaluate on test data...
Evaluate data in 130.71 seconds!
[tester] 
AGNewsMetric: acc=0.8348684210526316, hinge=3.8708344472082037, ce=8.38215683184172
Global test acc @ epoch 281: 0.8349
Global epoch 282...
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.05 seconds!
[tester] 
AGNewsMetric: acc=0.8357894736842105, hinge=3.812089375320234, ce=8.352597337020072
Local test acc @ epoch 282: 0.8358
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.02 seconds!
[tester] 
AGNewsMetric: acc=0.8336842105263158, hinge=3.8926306075798838, ce=8.386911202480919
Local test acc @ epoch 282: 0.8337
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.9802315282267955e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.29 seconds!
[tester] 
AGNewsMetric: acc=0.8276315789473684, hinge=4.0001417163798685, ce=8.542412031073319
Local test acc @ epoch 282: 0.8276
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901159417490817e-08
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 131.24 seconds!
[tester] 
AGNewsMetric: acc=0.8386842105263158, hinge=3.7966863343590185, ce=8.201183218705026
Local test acc @ epoch 282: 0.8387
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.9802315282267955e-08
Local loss @ local epoch 3: 2.2351740014414645e-08
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.26 seconds!
[tester] 
AGNewsMetric: acc=0.8330263157894737, hinge=3.8464027714729307, ce=8.29179891485917
Local test acc @ epoch 282: 0.833
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 3.725289587919178e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.91 seconds!
[tester] 
AGNewsMetric: acc=0.8451315789473685, hinge=3.734796444114886, ce=8.056067149513646
Local test acc @ epoch 282: 0.8451
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901159417490817e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.33 seconds!
[tester] 
AGNewsMetric: acc=0.8286842105263158, hinge=3.931224975460454, ce=8.750011793437757
Local test acc @ epoch 282: 0.8287
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.52 seconds!
[tester] 
AGNewsMetric: acc=0.8332894736842106, hinge=3.849955702957354, ce=8.370580066881681
Local test acc @ epoch 282: 0.8333
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 3.7252892326478104e-08
Local loss @ local epoch 3: 2.2351738238057806e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.86 seconds!
[tester] 
AGNewsMetric: acc=0.8375, hinge=3.7834233158513118, ce=8.40984328721699
Local test acc @ epoch 282: 0.8375
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.3411039390121005e-07
Local loss @ local epoch 4: 2.9802315282267955e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.24 seconds!
[tester] 
AGNewsMetric: acc=0.8143421052631579, hinge=4.411594116813258, ce=8.590999121414988
Local test acc @ epoch 282: 0.8143
Global evaluate on test data...
Evaluate data in 130.89 seconds!
[tester] 
AGNewsMetric: acc=0.8356578947368422, hinge=3.8551125272951627, ce=8.306111607802542
Global test acc @ epoch 282: 0.8357
Global epoch 283...
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.14 seconds!
[tester] 
AGNewsMetric: acc=0.8425, hinge=3.732278779431393, ce=8.180898600126568
Local test acc @ epoch 283: 0.8425
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450577754752885e-08
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 5.9604616353681195e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.15 seconds!
[tester] 
AGNewsMetric: acc=0.8331578947368421, hinge=3.9316983268135473, ce=8.236395319888466
Local test acc @ epoch 283: 0.8332
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.07 seconds!
[tester] 
AGNewsMetric: acc=0.8351315789473684, hinge=3.787686370548449, ce=8.447502310903449
Local test acc @ epoch 283: 0.8351
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 2.2351740014414645e-08
Local loss @ local epoch 1: 2.831217216225923e-07
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.9802318834981634e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.47 seconds!
[tester] 
AGNewsMetric: acc=0.8342105263157895, hinge=3.6098559237781322, ce=8.262924683219508
Local test acc @ epoch 283: 0.8342
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 5.215404996761208e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.25 seconds!
[tester] 
AGNewsMetric: acc=0.8435526315789473, hinge=3.6821500995284633, ce=7.938315971776059
Local test acc @ epoch 283: 0.8436
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 1.78813678530787e-07
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.13 seconds!
[tester] 
AGNewsMetric: acc=0.8361842105263158, hinge=3.9125591062244616, ce=8.40267548008969
Local test acc @ epoch 283: 0.8362
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 3.725289587919178e-08
Local loss @ local epoch 4: 2.9802318834981634e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.28 seconds!
[tester] 
AGNewsMetric: acc=0.8386842105263158, hinge=3.8212922736218102, ce=8.309561587885806
Local test acc @ epoch 283: 0.8387
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 5.2154042862184724e-08
Local loss @ local epoch 2: 7.450576333667414e-08
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 5.662415674123622e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.61 seconds!
[tester] 
AGNewsMetric: acc=0.7864473684210527, hinge=4.606246573046634, ce=8.98479278162906
Local test acc @ epoch 283: 0.7864
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 2.9802315282267955e-08
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.74 seconds!
[tester] 
AGNewsMetric: acc=0.8409210526315789, hinge=3.662636492503317, ce=8.459428269235712
Local test acc @ epoch 283: 0.8409
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 2.9802315282267955e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.07 seconds!
[tester] 
AGNewsMetric: acc=0.8409210526315789, hinge=3.7195300431000557, ce=8.326989698911968
Local test acc @ epoch 283: 0.8409
Global evaluate on test data...
Evaluate data in 130.17 seconds!
[tester] 
AGNewsMetric: acc=0.8368421052631579, hinge=3.809578766320881, ce=8.242062952142012
Global test acc @ epoch 283: 0.8368
Global epoch 284...
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.9802318834981634e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.4 seconds!
[tester] 
AGNewsMetric: acc=0.8352631578947368, hinge=3.725473159614362, ce=8.322622487921464
Local test acc @ epoch 284: 0.8353
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.9 seconds!
[tester] 
AGNewsMetric: acc=0.8369736842105263, hinge=3.8025468919151706, ce=8.238238329636424
Local test acc @ epoch 284: 0.837
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.89 seconds!
[tester] 
AGNewsMetric: acc=0.8356578947368422, hinge=3.8221087709226107, ce=8.26388412475586
Local test acc @ epoch 284: 0.8357
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 3.725289587919178e-08
Local loss @ local epoch 3: 3.7252892326478104e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.33 seconds!
[tester] 
AGNewsMetric: acc=0.8053947368421053, hinge=4.715377429660998, ce=8.99626811178107
Local test acc @ epoch 284: 0.8054
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.3411030863608175e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.9 seconds!
[tester] 
AGNewsMetric: acc=0.8353947368421053, hinge=3.846695001752753, ce=8.193000803495709
Local test acc @ epoch 284: 0.8354
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.22 seconds!
[tester] 
AGNewsMetric: acc=0.8361842105263158, hinge=3.802217588048232, ce=8.380914491352282
Local test acc @ epoch 284: 0.8362
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.2351740014414645e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.07 seconds!
[tester] 
AGNewsMetric: acc=0.8426315789473684, hinge=3.6253895942788374, ce=8.142299947236713
Local test acc @ epoch 284: 0.8426
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 2.2351738238057806e-08
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 1.4901159417490817e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.95 seconds!
[tester] 
AGNewsMetric: acc=0.828421052631579, hinge=3.9191910512823807, ce=8.428860419423957
Local test acc @ epoch 284: 0.8284
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 8.195632972274325e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 5.2154042862184724e-08
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.38 seconds!
[tester] 
AGNewsMetric: acc=0.8497368421052631, hinge=3.77352749899814, ce=8.153037010995964
Local test acc @ epoch 284: 0.8497
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.43 seconds!
[tester] 
AGNewsMetric: acc=0.8369736842105263, hinge=3.8215693481344926, ce=8.30302172711021
Local test acc @ epoch 284: 0.837
Global evaluate on test data...
Evaluate data in 130.26 seconds!
[tester] 
AGNewsMetric: acc=0.8378947368421052, hinge=3.821372614910728, ce=8.251078999167994
Global test acc @ epoch 284: 0.8379
Global epoch 285...
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 5.215404996761208e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.2351738238057806e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 131.17 seconds!
[tester] 
AGNewsMetric: acc=0.8498684210526316, hinge=3.555795127969039, ce=7.936099869577508
Local test acc @ epoch 285: 0.8499
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 131.2 seconds!
[tester] 
AGNewsMetric: acc=0.8386842105263158, hinge=3.7711985339616474, ce=8.363540574123984
Local test acc @ epoch 285: 0.8387
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.29 seconds!
[tester] 
AGNewsMetric: acc=0.8307894736842105, hinge=3.8944463904280413, ce=8.38787096726267
Local test acc @ epoch 285: 0.8308
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901159417490817e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.63 seconds!
[tester] 
AGNewsMetric: acc=0.845657894736842, hinge=3.709570875795264, ce=8.152098276238693
Local test acc @ epoch 285: 0.8457
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.19 seconds!
[tester] 
AGNewsMetric: acc=0.8360526315789474, hinge=3.8028185447893645, ce=8.289427398882415
Local test acc @ epoch 285: 0.8361
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.2351740014414645e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.75 seconds!
[tester] 
AGNewsMetric: acc=0.8355263157894737, hinge=3.8372152061211438, ce=8.162848012823808
Local test acc @ epoch 285: 0.8355
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 2.2351738238057806e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.4901159417490817e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.4 seconds!
[tester] 
AGNewsMetric: acc=0.8394736842105263, hinge=3.8439034618829426, ce=8.201347126207853
Local test acc @ epoch 285: 0.8395
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.4901159417490817e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.63 seconds!
[tester] 
AGNewsMetric: acc=0.8322368421052632, hinge=4.000052271642183, ce=8.436833353544536
Local test acc @ epoch 285: 0.8322
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 3.725289943190546e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.36 seconds!
[tester] 
AGNewsMetric: acc=0.8356578947368422, hinge=3.7913819393358734, ce=8.212600318507144
Local test acc @ epoch 285: 0.8357
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901159417490817e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.16 seconds!
[tester] 
AGNewsMetric: acc=0.8373684210526315, hinge=3.623966851987337, ce=8.180652056242291
Local test acc @ epoch 285: 0.8374
Global evaluate on test data...
Evaluate data in 130.08 seconds!
[tester] 
AGNewsMetric: acc=0.8388157894736842, hinge=3.7573638524507222, ce=8.174041475998727
Global test acc @ epoch 285: 0.8388
Global epoch 286...
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.36 seconds!
[tester] 
AGNewsMetric: acc=0.8375, hinge=3.784553138833297, ce=8.244710393202933
Local test acc @ epoch 286: 0.8375
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 2.2351738238057806e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.2351740014414645e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.7 seconds!
[tester] 
AGNewsMetric: acc=0.8442105263157895, hinge=3.6700780498354058, ce=8.124022973713123
Local test acc @ epoch 286: 0.8442
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.4901159417490817e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.75 seconds!
[tester] 
AGNewsMetric: acc=0.8393421052631579, hinge=3.718379455365633, ce=8.194296325884368
Local test acc @ epoch 286: 0.8393
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 4.4703469370688254e-08
Local loss @ local epoch 1: 2.9802320611338473e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.1175860947787442e-07
Local loss @ local epoch 4: 2.9802315282267955e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.11 seconds!
[tester] 
AGNewsMetric: acc=0.7882894736842105, hinge=5.1020407071866485, ce=9.165147197121067
Local test acc @ epoch 286: 0.7883
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.35 seconds!
[tester] 
AGNewsMetric: acc=0.8376315789473684, hinge=3.7249795567361934, ce=8.284702854156494
Local test acc @ epoch 286: 0.8376
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.2351738238057806e-08
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.28 seconds!
[tester] 
AGNewsMetric: acc=0.8376315789473684, hinge=3.79319082774614, ce=8.116352118441933
Local test acc @ epoch 286: 0.8376
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.15 seconds!
[tester] 
AGNewsMetric: acc=0.838421052631579, hinge=3.7578053267378557, ce=8.278222012770803
Local test acc @ epoch 286: 0.8384
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.21 seconds!
[tester] 
AGNewsMetric: acc=0.8401315789473685, hinge=3.7383590567739384, ce=8.276932793667442
Local test acc @ epoch 286: 0.8401
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 3.725289587919178e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.4901159417490817e-08
Local loss @ local epoch 4: 8.940693163594915e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.79 seconds!
[tester] 
AGNewsMetric: acc=0.8373684210526315, hinge=3.709120001918391, ce=8.144861640930175
Local test acc @ epoch 286: 0.8374
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 3.7252892326478104e-08
Local loss @ local epoch 4: 3.7252892326478104e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.15 seconds!
[tester] 
AGNewsMetric: acc=0.8380263157894737, hinge=3.775870261192322, ce=8.240076966536673
Local test acc @ epoch 286: 0.838
Global evaluate on test data...
Evaluate data in 130.05 seconds!
[tester] 
AGNewsMetric: acc=0.8435526315789473, hinge=3.670419541660108, ce=8.078636461559094
Global test acc @ epoch 286: 0.8436
Global epoch 287...
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4156088923300558e-07
Local loss @ local epoch 1: 2.2351738238057806e-08
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 2.2351738238057806e-08
Local loss @ local epoch 4: 1.41560917654715e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.55 seconds!
[tester] 
AGNewsMetric: acc=0.8353947368421053, hinge=3.6372240116721706, ce=8.014158847206517
Local test acc @ epoch 287: 0.8354
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 6.705519695060502e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.2351740014414645e-08
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 4.6193449065867753e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.33 seconds!
[tester] 
AGNewsMetric: acc=0.8501315789473685, hinge=3.3550505890344318, ce=8.386374831952546
Local test acc @ epoch 287: 0.8501
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.05 seconds!
[tester] 
AGNewsMetric: acc=0.8444736842105263, hinge=3.6082872937854966, ce=8.141074597208123
Local test acc @ epoch 287: 0.8445
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.9802318834981634e-08
Local loss @ local epoch 2: 1.4901159417490817e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.61 seconds!
[tester] 
AGNewsMetric: acc=0.8205263157894737, hinge=4.294496422566866, ce=8.796312077170924
Local test acc @ epoch 287: 0.8205
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.4901144140821998e-07
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.2351740014414645e-08
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.87 seconds!
[tester] 
AGNewsMetric: acc=0.8273684210526315, hinge=3.90661797322725, ce=7.634171505978233
Local test acc @ epoch 287: 0.8274
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 2.2351740014414645e-08
Local loss @ local epoch 1: 2.2351740014414645e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.8312183530943e-07
Local loss @ local epoch 4: 0.37427929043769836
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.08 seconds!
[tester] 
AGNewsMetric: acc=0.8014473684210527, hinge=4.576611171270672, ce=8.637615753976922
Local test acc @ epoch 287: 0.8014
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.62 seconds!
[tester] 
AGNewsMetric: acc=0.8436842105263158, hinge=3.6774274585121556, ce=8.092201793068334
Local test acc @ epoch 287: 0.8437
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.6822036147677863e-07
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.2887372076511383
Local loss @ local epoch 4: 1.2591403901751619e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.01 seconds!
[tester] 
AGNewsMetric: acc=0.8459210526315789, hinge=3.670120390465385, ce=8.124672042445132
Local test acc @ epoch 287: 0.8459
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 5.960463056453591e-08
Local loss @ local epoch 2: 3.725289587919178e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.05479263886809349
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.03 seconds!
[tester] 
AGNewsMetric: acc=0.8378947368421052, hinge=3.8858197023994046, ce=8.609788075497276
Local test acc @ epoch 287: 0.8379
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 2.2351740014414645e-08
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 4.4703469370688254e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.16 seconds!
[tester] 
AGNewsMetric: acc=0.8348684210526316, hinge=3.889142014352899, ce=8.252030580420243
Local test acc @ epoch 287: 0.8349
Global evaluate on test data...
Evaluate data in 130.28 seconds!
[tester] 
AGNewsMetric: acc=0.845657894736842, hinge=3.705783726290653, ce=7.969737216547916
Global test acc @ epoch 287: 0.8457
Global epoch 288...
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.2 seconds!
[tester] 
AGNewsMetric: acc=0.8455263157894737, hinge=3.684160358278375, ce=7.992976992757697
Local test acc @ epoch 288: 0.8455
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.89 seconds!
[tester] 
AGNewsMetric: acc=0.8459210526315789, hinge=3.658955463484714, ce=8.021822300961142
Local test acc @ epoch 288: 0.8459
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.37 seconds!
[tester] 
AGNewsMetric: acc=0.8471052631578947, hinge=3.697417929172516, ce=7.8461258275885335
Local test acc @ epoch 288: 0.8471
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 1.2665975646086736e-07
Local loss @ local epoch 1: 1.4901159417490817e-08
Local loss @ local epoch 2: 6.929012101863918e-07
Local loss @ local epoch 3: 4.894887297268724e-06
Local loss @ local epoch 4: 2.2351740014414645e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.68 seconds!
[tester] 
AGNewsMetric: acc=0.8155263157894737, hinge=4.097073245048523, ce=8.336870940359015
Local test acc @ epoch 288: 0.8155
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.77 seconds!
[tester] 
AGNewsMetric: acc=0.8452631578947368, hinge=3.678137210544787, ce=7.981595519216437
Local test acc @ epoch 288: 0.8453
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 3.725289587919178e-08
Local loss @ local epoch 1: 2.2351740014414645e-08
Local loss @ local epoch 2: 2.2351740014414645e-08
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 3.352754163188365e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.37 seconds!
[tester] 
AGNewsMetric: acc=0.8211842105263157, hinge=4.189494623510461, ce=8.45441076981394
Local test acc @ epoch 288: 0.8212
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 5.9604616353681195e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.43 seconds!
[tester] 
AGNewsMetric: acc=0.7861842105263158, hinge=5.353610479706212, ce=9.222538000407972
Local test acc @ epoch 288: 0.7862
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.2351740014414645e-08
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 1.4901159417490817e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.6 seconds!
[tester] 
AGNewsMetric: acc=0.8394736842105263, hinge=3.7676870831690334, ce=8.309782630518862
Local test acc @ epoch 288: 0.8395
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.78813678530787e-07
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.06 seconds!
[tester] 
AGNewsMetric: acc=0.843421052631579, hinge=3.671386137259634, ce=8.17930722587987
Local test acc @ epoch 288: 0.8434
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.99 seconds!
[tester] 
AGNewsMetric: acc=0.8377631578947369, hinge=3.8550100773259213, ce=8.162409097771896
Local test acc @ epoch 288: 0.8378
Global evaluate on test data...
Evaluate data in 130.44 seconds!
[tester] 
AGNewsMetric: acc=0.8386842105263158, hinge=3.874917565521441, ce=8.089450139497457
Global test acc @ epoch 288: 0.8387
Global epoch 289...
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.2351738238057806e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.35 seconds!
[tester] 
AGNewsMetric: acc=0.8406578947368422, hinge=3.7999708779234633, ce=8.020526235480057
Local test acc @ epoch 289: 0.8407
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 2.9802315282267955e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.86 seconds!
[tester] 
AGNewsMetric: acc=0.8413157894736842, hinge=3.780785368241762, ce=8.808449901781584
Local test acc @ epoch 289: 0.8413
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.59 seconds!
[tester] 
AGNewsMetric: acc=0.8376315789473684, hinge=3.8280239302233645, ce=8.196010473150956
Local test acc @ epoch 289: 0.8376
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.08 seconds!
[tester] 
AGNewsMetric: acc=0.8353947368421053, hinge=3.8784834377389203, ce=8.225416587026496
Local test acc @ epoch 289: 0.8354
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 2.9802315282267955e-08
Local loss @ local epoch 1: 2.4139430934155826e-06
Local loss @ local epoch 2: 0.5488045811653137
Local loss @ local epoch 3: 3.725289587919178e-08
Local loss @ local epoch 4: 7.476691826013848e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.94 seconds!
[tester] 
AGNewsMetric: acc=0.7085526315789473, hinge=7.254556021439401, ce=10.66724119286788
Local test acc @ epoch 289: 0.7086
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.13 seconds!
[tester] 
AGNewsMetric: acc=0.8327631578947369, hinge=3.8347797702488147, ce=8.475538675408615
Local test acc @ epoch 289: 0.8328
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901159417490817e-08
Local loss @ local epoch 1: 2.2351740014414645e-08
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.57 seconds!
[tester] 
AGNewsMetric: acc=0.8326315789473684, hinge=3.9237431654177213, ce=8.061186964135421
Local test acc @ epoch 289: 0.8326
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.2351738238057806e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.47 seconds!
[tester] 
AGNewsMetric: acc=0.8392105263157895, hinge=3.8319686904706454, ce=8.166408185456929
Local test acc @ epoch 289: 0.8392
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.2351702000378282e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.87 seconds!
[tester] 
AGNewsMetric: acc=0.8347368421052631, hinge=3.9672777790772287, ce=8.146313803823372
Local test acc @ epoch 289: 0.8347
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 3.7252892326478104e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.21 seconds!
[tester] 
AGNewsMetric: acc=0.8376315789473684, hinge=3.8905534400438007, ce=8.127991767682527
Local test acc @ epoch 289: 0.8376
Global evaluate on test data...
Evaluate data in 129.65 seconds!
[tester] 
AGNewsMetric: acc=0.8409210526315789, hinge=3.7830986420731794, ce=8.071391674844842
Global test acc @ epoch 289: 0.8409
Global epoch 290...
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 2.2351740014414645e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.03 seconds!
[tester] 
AGNewsMetric: acc=0.8455263157894737, hinge=3.6555232327862788, ce=8.291465125836824
Local test acc @ epoch 290: 0.8455
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 3.7252892326478104e-08
Local loss @ local epoch 1: 1.1920926112907182e-07
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.51 seconds!
[tester] 
AGNewsMetric: acc=0.8272368421052632, hinge=3.890149826752512, ce=8.656797338786879
Local test acc @ epoch 290: 0.8272
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.21 seconds!
[tester] 
AGNewsMetric: acc=0.8402631578947368, hinge=3.7805674103686684, ce=8.157532132801256
Local test acc @ epoch 290: 0.8403
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.72 seconds!
[tester] 
AGNewsMetric: acc=0.8338157894736842, hinge=3.9955894388650592, ce=8.350405122857344
Local test acc @ epoch 290: 0.8338
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901159417490817e-08
Local loss @ local epoch 1: 2.9802315282267955e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.74 seconds!
[tester] 
AGNewsMetric: acc=0.8371052631578947, hinge=3.9116242811554356, ce=8.227235815148605
Local test acc @ epoch 290: 0.8371
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.1920921849650767e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.73 seconds!
[tester] 
AGNewsMetric: acc=0.8415789473684211, hinge=3.720554647194712, ce=8.294191774067126
Local test acc @ epoch 290: 0.8416
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.13 seconds!
[tester] 
AGNewsMetric: acc=0.8414473684210526, hinge=3.7834584426879885, ce=8.15399033697028
Local test acc @ epoch 290: 0.8414
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 8.1727539509302e-06
Local loss @ local epoch 1: 1.0695480108261108
Local loss @ local epoch 2: 0.010222695767879486
Local loss @ local epoch 3: 0.889303982257843
Local loss @ local epoch 4: 7.844971150916535e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.83 seconds!
[tester] 
AGNewsMetric: acc=0.8193421052631579, hinge=3.7229982027254604, ce=8.572614065471448
Local test acc @ epoch 290: 0.8193
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.07 seconds!
[tester] 
AGNewsMetric: acc=0.8414473684210526, hinge=3.7823325500990217, ce=8.103032966412997
Local test acc @ epoch 290: 0.8414
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 3.7252892326478104e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 131.04 seconds!
[tester] 
AGNewsMetric: acc=0.8376315789473684, hinge=3.8582478588505795, ce=8.273445628316779
Local test acc @ epoch 290: 0.8376
Global evaluate on test data...
Evaluate data in 130.15 seconds!
[tester] 
AGNewsMetric: acc=0.8401315789473685, hinge=3.784239800854733, ce=8.133993672822651
Global test acc @ epoch 290: 0.8401
Global epoch 291...
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.09 seconds!
[tester] 
AGNewsMetric: acc=0.8380263157894737, hinge=3.8694974040985106, ce=8.344286965821919
Local test acc @ epoch 291: 0.838
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 2.8237061542313313e-06
Local loss @ local epoch 1: 2.2351740014414645e-08
Local loss @ local epoch 2: 1.238767385482788
Local loss @ local epoch 3: 1.1175869474300271e-07
Local loss @ local epoch 4: 0.0036531679797917604
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.35 seconds!
[tester] 
AGNewsMetric: acc=0.8048684210526316, hinge=3.778259590550473, ce=9.46546889857242
Local test acc @ epoch 291: 0.8049
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 1.713631121447179e-07
Local loss @ local epoch 2: 2.9057196115900297e-07
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.42016303539276123
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.9 seconds!
[tester] 
AGNewsMetric: acc=0.7848684210526315, hinge=4.924029607019927, ce=9.486347660265471
Local test acc @ epoch 291: 0.7849
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.2351740014414645e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.4 seconds!
[tester] 
AGNewsMetric: acc=0.8439473684210527, hinge=3.704035738643847, ce=8.195063976488616
Local test acc @ epoch 291: 0.8439
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.67 seconds!
[tester] 
AGNewsMetric: acc=0.8431578947368421, hinge=3.6654205937134594, ce=8.208979225158691
Local test acc @ epoch 291: 0.8432
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 2.2351738238057806e-08
Local loss @ local epoch 3: 8.195634393359796e-08
Local loss @ local epoch 4: 1.862643159711297e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 128.83 seconds!
[tester] 
AGNewsMetric: acc=0.7901315789473684, hinge=5.140238814353943, ce=9.07333486055073
Local test acc @ epoch 291: 0.7901
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 1.080324864233262e-06
Local loss @ local epoch 2: 0.00023386036627925932
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.6782582402229309
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 128.62 seconds!
[tester] 
AGNewsMetric: acc=0.8203947368421053, hinge=4.191125190007059, ce=8.566822997645328
Local test acc @ epoch 291: 0.8204
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.4901159417490817e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.57 seconds!
[tester] 
AGNewsMetric: acc=0.8336842105263158, hinge=3.9434911568541278, ce=8.4098033945184
Local test acc @ epoch 291: 0.8337
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 1.862642307060014e-07
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.002890926320105791
Local loss @ local epoch 3: 1.862642307060014e-07
Local loss @ local epoch 4: 1.4901159417490817e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.5 seconds!
[tester] 
AGNewsMetric: acc=0.8280263157894737, hinge=3.751628233257093, ce=8.248494903162905
Local test acc @ epoch 291: 0.828
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 5.2154042862184724e-08
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.71 seconds!
[tester] 
AGNewsMetric: acc=0.8425, hinge=3.6815779451320045, ce=8.263147835982473
Local test acc @ epoch 291: 0.8425
Global evaluate on test data...
Evaluate data in 129.86 seconds!
[tester] 
AGNewsMetric: acc=0.8401315789473685, hinge=3.811372753444471, ce=8.106554141797517
Global test acc @ epoch 291: 0.8401
Global epoch 292...
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.83 seconds!
[tester] 
AGNewsMetric: acc=0.8386842105263158, hinge=3.814663432773791, ce=8.324453147085089
Local test acc @ epoch 292: 0.8387
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901159417490817e-08
Local loss @ local epoch 1: 2.2351740014414645e-08
Local loss @ local epoch 2: 2.2351740014414645e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.4901159417490817e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.6 seconds!
[tester] 
AGNewsMetric: acc=0.8330263157894737, hinge=4.040372527273077, ce=8.135834105642218
Local test acc @ epoch 292: 0.833
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 8.195635103902532e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.9802318834981634e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.2665975646086736e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.9 seconds!
[tester] 
AGNewsMetric: acc=0.8386842105263158, hinge=3.687509667998866, ce=8.090193235497726
Local test acc @ epoch 292: 0.8387
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 2.2351738238057806e-08
Local loss @ local epoch 1: 1.7881379221762472e-07
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.2351738238057806e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.78 seconds!
[tester] 
AGNewsMetric: acc=0.7964473684210527, hinge=4.7439854604319525, ce=8.464309288827996
Local test acc @ epoch 292: 0.7964
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 3.725289587919178e-08
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 2.2351740014414645e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.08 seconds!
[tester] 
AGNewsMetric: acc=0.8351315789473684, hinge=3.9217704082790172, ce=8.192961398676822
Local test acc @ epoch 292: 0.8351
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.0430805019723266e-07
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.8 seconds!
[tester] 
AGNewsMetric: acc=0.8393421052631579, hinge=3.82495800796308, ce=8.2949836048327
Local test acc @ epoch 292: 0.8393
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 2.2351738238057806e-08
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 6.705520405603238e-08
Local loss @ local epoch 4: 3.725289587919178e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.71 seconds!
[tester] 
AGNewsMetric: acc=0.841842105263158, hinge=3.696262226857637, ce=8.056458923942165
Local test acc @ epoch 292: 0.8418
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 6.571066478500143e-06
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.747395932674408
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.53 seconds!
[tester] 
AGNewsMetric: acc=0.8326315789473684, hinge=3.800519501786483, ce=8.413782392802991
Local test acc @ epoch 292: 0.8326
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901159417490817e-08
Local loss @ local epoch 1: 2.2351738238057806e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 131.22 seconds!
[tester] 
AGNewsMetric: acc=0.7707894736842106, hinge=5.717585126977218, ce=9.830634994506836
Local test acc @ epoch 292: 0.7708
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 2.9802318834981634e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 131.07 seconds!
[tester] 
AGNewsMetric: acc=0.8428947368421053, hinge=3.6266413671091984, ce=8.070594551688746
Local test acc @ epoch 292: 0.8429
Global evaluate on test data...
Evaluate data in 130.4 seconds!
[tester] 
AGNewsMetric: acc=0.8364473684210526, hinge=3.9374136292307003, ce=8.121284196753251
Global test acc @ epoch 292: 0.8364
Global epoch 293...
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 1.2665974225001264e-07
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 5.4684869610355236e-06
Local loss @ local epoch 4: 9.685746960030883e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.24 seconds!
[tester] 
AGNewsMetric: acc=0.8101315789473684, hinge=4.370820846306651, ce=9.368759056894403
Local test acc @ epoch 293: 0.8101
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.2351740014414645e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.54 seconds!
[tester] 
AGNewsMetric: acc=0.8377631578947369, hinge=3.8912677594235068, ce=8.072646909011038
Local test acc @ epoch 293: 0.8378
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.99 seconds!
[tester] 
AGNewsMetric: acc=0.8382894736842105, hinge=3.8370366752775094, ce=8.242555018977114
Local test acc @ epoch 293: 0.8383
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 2.9802315282267955e-08
Local loss @ local epoch 1: 2.9802318834981634e-08
Local loss @ local epoch 2: 1.4901151246249356e-07
Local loss @ local epoch 3: 5.960463056453591e-08
Local loss @ local epoch 4: 8.195634393359796e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.06 seconds!
[tester] 
AGNewsMetric: acc=0.8332894736842106, hinge=3.8364947037947807, ce=8.086912862878096
Local test acc @ epoch 293: 0.8333
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 2.9802315282267955e-08
Local loss @ local epoch 1: 5.215405352032576e-08
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 3.7252803508636134e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.14 seconds!
[tester] 
AGNewsMetric: acc=0.8071052631578948, hinge=4.916313422353644, ce=8.909856410779451
Local test acc @ epoch 293: 0.8071
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 2.2351702000378282e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.38941678404808044
Local loss @ local epoch 3: 0.41705334186553955
Local loss @ local epoch 4: 0.9889180660247803
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.08 seconds!
[tester] 
AGNewsMetric: acc=0.8332894736842106, hinge=3.5151325927282633, ce=8.311589548211348
Local test acc @ epoch 293: 0.8333
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 2.2351740014414645e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.84 seconds!
[tester] 
AGNewsMetric: acc=0.8352631578947368, hinge=3.976147501343175, ce=8.180582216162431
Local test acc @ epoch 293: 0.8353
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.13 seconds!
[tester] 
AGNewsMetric: acc=0.8359210526315789, hinge=4.008327861334148, ce=8.120040029224597
Local test acc @ epoch 293: 0.8359
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 6.705518984517767e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.05 seconds!
[tester] 
AGNewsMetric: acc=0.8388157894736842, hinge=3.844327469875938, ce=8.071146928887618
Local test acc @ epoch 293: 0.8388
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.9802318834981634e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.2351740014414645e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.29 seconds!
[tester] 
AGNewsMetric: acc=0.8373684210526315, hinge=3.867375754306191, ce=8.114246554123728
Local test acc @ epoch 293: 0.8374
Global evaluate on test data...
Evaluate data in 130.2 seconds!
[tester] 
AGNewsMetric: acc=0.8432894736842105, hinge=3.77113946086482, ce=8.024738108986302
Global test acc @ epoch 293: 0.8433
Global epoch 294...
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 5.2154042862184724e-08
Local loss @ local epoch 3: 2.9802320611338473e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.2 seconds!
[tester] 
AGNewsMetric: acc=0.8373684210526315, hinge=3.8335983370479783, ce=8.098561220671002
Local test acc @ epoch 294: 0.8374
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 3.7252892326478104e-08
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.4901159417490817e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.08 seconds!
[tester] 
AGNewsMetric: acc=0.8471052631578947, hinge=3.639223777369449, ce=8.042715763292815
Local test acc @ epoch 294: 0.8471
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 2.2351707684720168e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 5.215404996761208e-08
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 1.7136319740984618e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.15 seconds!
[tester] 
AGNewsMetric: acc=0.8451315789473685, hinge=3.1314332307012456, ce=8.755043116117779
Local test acc @ epoch 294: 0.8451
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.49 seconds!
[tester] 
AGNewsMetric: acc=0.8428947368421053, hinge=3.7921219331339784, ce=8.103196382020649
Local test acc @ epoch 294: 0.8429
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.9802315282267955e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 9.68574909165909e-08
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.54 seconds!
[tester] 
AGNewsMetric: acc=0.8289473684210527, hinge=4.061144710339998, ce=8.274591873570492
Local test acc @ epoch 294: 0.8289
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 2.2351740014414645e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.32 seconds!
[tester] 
AGNewsMetric: acc=0.8453947368421053, hinge=3.7017759257868716, ce=8.030544484791003
Local test acc @ epoch 294: 0.8454
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 2.9802318834981634e-08
Local loss @ local epoch 1: 6.705520405603238e-08
Local loss @ local epoch 2: 3.3094165701186284e-05
Local loss @ local epoch 3: 4.470347292340193e-08
Local loss @ local epoch 4: 0.5814352631568909
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.25 seconds!
[tester] 
AGNewsMetric: acc=0.833421052631579, hinge=3.879029561343946, ce=8.379055238021047
Local test acc @ epoch 294: 0.8334
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.2351740014414645e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.29 seconds!
[tester] 
AGNewsMetric: acc=0.8467105263157895, hinge=3.6528527214652615, ce=8.129535863775956
Local test acc @ epoch 294: 0.8467
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.63 seconds!
[tester] 
AGNewsMetric: acc=0.8432894736842105, hinge=3.7292435791617944, ce=8.149376529894377
Local test acc @ epoch 294: 0.8433
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 3.725289587919178e-08
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.51 seconds!
[tester] 
AGNewsMetric: acc=0.8415789473684211, hinge=3.809874241226598, ce=8.191127122577868
Local test acc @ epoch 294: 0.8416
Global evaluate on test data...
Evaluate data in 129.14 seconds!
[tester] 
AGNewsMetric: acc=0.8430263157894737, hinge=3.7583887755243404, ce=8.115949277375874
Global test acc @ epoch 294: 0.843
Global epoch 295...
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 6.705521116145974e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.23 seconds!
[tester] 
AGNewsMetric: acc=0.8386842105263158, hinge=3.7497508356445715, ce=8.147678533855238
Local test acc @ epoch 295: 0.8387
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.59 seconds!
[tester] 
AGNewsMetric: acc=0.8446052631578947, hinge=3.697761730520349, ce=8.149348370401484
Local test acc @ epoch 295: 0.8446
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.58 seconds!
[tester] 
AGNewsMetric: acc=0.8375, hinge=3.8230980185458536, ce=8.355692510102925
Local test acc @ epoch 295: 0.8375
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 3.7252892326478104e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.97 seconds!
[tester] 
AGNewsMetric: acc=0.8430263157894737, hinge=3.7431698546911543, ce=8.099473820736534
Local test acc @ epoch 295: 0.843
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.57 seconds!
[tester] 
AGNewsMetric: acc=0.8493421052631579, hinge=3.6441362163895055, ce=8.013071876325105
Local test acc @ epoch 295: 0.8493
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 3.7252892326478104e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.36 seconds!
[tester] 
AGNewsMetric: acc=0.8428947368421053, hinge=3.777063392087033, ce=8.271672934481971
Local test acc @ epoch 295: 0.8429
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.2351738238057806e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 131.51 seconds!
[tester] 
AGNewsMetric: acc=0.8413157894736842, hinge=3.803205521357687, ce=8.067418110496119
Local test acc @ epoch 295: 0.8413
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 5.960462345910855e-08
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 2.2351740014414645e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.89 seconds!
[tester] 
AGNewsMetric: acc=0.8101315789473684, hinge=4.8412636746858295, ce=9.109302703455874
Local test acc @ epoch 295: 0.8101
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.39 seconds!
[tester] 
AGNewsMetric: acc=0.8489473684210527, hinge=3.64622309923172, ce=8.119375704715127
Local test acc @ epoch 295: 0.8489
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 5.215405352032576e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450577754752885e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.81 seconds!
[tester] 
AGNewsMetric: acc=0.8343421052631579, hinge=3.947429316671271, ce=8.294183815403988
Local test acc @ epoch 295: 0.8343
Global evaluate on test data...
Evaluate data in 130.05 seconds!
[tester] 
AGNewsMetric: acc=0.8465789473684211, hinge=3.701943676722677, ce=8.08977438173796
Global test acc @ epoch 295: 0.8466
Global epoch 296...
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 2.2351740014414645e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 4.4703469370688254e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.5 seconds!
[tester] 
AGNewsMetric: acc=0.8301315789473684, hinge=4.087992919495231, ce=8.286544771696391
Local test acc @ epoch 296: 0.8301
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.32 seconds!
[tester] 
AGNewsMetric: acc=0.8455263157894737, hinge=3.7320967171066686, ce=8.028920095343338
Local test acc @ epoch 296: 0.8455
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.86 seconds!
[tester] 
AGNewsMetric: acc=0.844078947368421, hinge=3.72995303128895, ce=8.132995809253893
Local test acc @ epoch 296: 0.8441
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.97 seconds!
[tester] 
AGNewsMetric: acc=0.8476315789473684, hinge=3.6967216853091593, ce=8.117208628403514
Local test acc @ epoch 296: 0.8476
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 2.2351738238057806e-08
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.07 seconds!
[tester] 
AGNewsMetric: acc=0.8475, hinge=3.6540577395338762, ce=8.191284516987048
Local test acc @ epoch 296: 0.8475
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.14 seconds!
[tester] 
AGNewsMetric: acc=0.8461842105263158, hinge=3.6880592997450576, ce=8.106909276058799
Local test acc @ epoch 296: 0.8462
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.4901159417490817e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.98 seconds!
[tester] 
AGNewsMetric: acc=0.8401315789473685, hinge=3.7447335683672054, ce=8.252487375359786
Local test acc @ epoch 296: 0.8401
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.4901159417490817e-08
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.44 seconds!
[tester] 
AGNewsMetric: acc=0.833421052631579, hinge=3.931729330012673, ce=8.40408248098273
Local test acc @ epoch 296: 0.8334
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.7460120916366577
Local loss @ local epoch 1: 2.9802315282267955e-08
Local loss @ local epoch 2: 1.5692172050476074
Local loss @ local epoch 3: 1.4901156930591242e-07
Local loss @ local epoch 4: 2.0265488274162635e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.01 seconds!
[tester] 
AGNewsMetric: acc=0.8303947368421053, hinge=2.748756608712046, ce=8.32467082073814
Local test acc @ epoch 296: 0.8304
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.4901159417490817e-08
Local loss @ local epoch 2: 1.4901159417490817e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.94 seconds!
[tester] 
AGNewsMetric: acc=0.8428947368421053, hinge=3.8277626481809115, ce=7.973698264674137
Local test acc @ epoch 296: 0.8429
Global evaluate on test data...
Evaluate data in 130.29 seconds!
[tester] 
AGNewsMetric: acc=0.8431578947368421, hinge=3.7322840349297772, ce=7.987934280194734
Global test acc @ epoch 296: 0.8432
Global epoch 297...
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.4 seconds!
[tester] 
AGNewsMetric: acc=0.8380263157894737, hinge=3.7941169599482887, ce=8.193556147123639
Local test acc @ epoch 297: 0.838
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 5.215385385781701e-07
Local loss @ local epoch 1: 2.9802318834981634e-08
Local loss @ local epoch 2: 3.725289943190546e-08
Local loss @ local epoch 3: 0.2588328421115875
Local loss @ local epoch 4: 1.881803291325923e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.17 seconds!
[tester] 
AGNewsMetric: acc=0.8171052631578948, hinge=3.3498140637498155, ce=9.257638017754806
Local test acc @ epoch 297: 0.8171
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.19 seconds!
[tester] 
AGNewsMetric: acc=0.8494736842105263, hinge=3.6248838824974863, ce=8.145018051549007
Local test acc @ epoch 297: 0.8495
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.4901159417490817e-08
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 128.53 seconds!
[tester] 
AGNewsMetric: acc=0.8446052631578947, hinge=3.644994195385983, ce=8.116052815286737
Local test acc @ epoch 297: 0.8446
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901159417490817e-08
Local loss @ local epoch 1: 6.705521116145974e-08
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 1.713632258315556e-07
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.11 seconds!
[tester] 
AGNewsMetric: acc=0.8281578947368421, hinge=4.304121392651608, ce=8.347558700159976
Local test acc @ epoch 297: 0.8282
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 5.215404996761208e-08
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.74 seconds!
[tester] 
AGNewsMetric: acc=0.8475, hinge=3.57690858753104, ce=8.173155701285914
Local test acc @ epoch 297: 0.8475
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.99 seconds!
[tester] 
AGNewsMetric: acc=0.8430263157894737, hinge=3.702680066008317, ce=7.983658988350316
Local test acc @ epoch 297: 0.843
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901159417490817e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.68 seconds!
[tester] 
AGNewsMetric: acc=0.8411842105263158, hinge=3.8689056971198634, ce=8.180672877462287
Local test acc @ epoch 297: 0.8412
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 3.725289587919178e-08
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.22 seconds!
[tester] 
AGNewsMetric: acc=0.8422368421052632, hinge=3.6631378586668717, ce=8.055325872521651
Local test acc @ epoch 297: 0.8422
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 5.2154042862184724e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 5.2154042862184724e-08
Local loss @ local epoch 3: 2.9802318834981634e-08
Local loss @ local epoch 4: 1.4901159417490817e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.86 seconds!
[tester] 
AGNewsMetric: acc=0.8310526315789474, hinge=4.127321389097917, ce=8.277636104382967
Local test acc @ epoch 297: 0.8311
Global evaluate on test data...
Evaluate data in 130.62 seconds!
[tester] 
AGNewsMetric: acc=0.8444736842105263, hinge=3.6801525177453693, ce=8.03496028297826
Global test acc @ epoch 297: 0.8445
Global epoch 298...
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.48 seconds!
[tester] 
AGNewsMetric: acc=0.8442105263157895, hinge=3.6320977666503507, ce=8.16626051651804
Local test acc @ epoch 298: 0.8442
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.9802318834981634e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.02 seconds!
[tester] 
AGNewsMetric: acc=0.8485526315789473, hinge=3.597705659866333, ce=8.094071499673944
Local test acc @ epoch 298: 0.8486
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 2.2351740014414645e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.44 seconds!
[tester] 
AGNewsMetric: acc=0.8422368421052632, hinge=3.7066563498346428, ce=8.142065218875283
Local test acc @ epoch 298: 0.8422
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901159417490817e-08
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.2 seconds!
[tester] 
AGNewsMetric: acc=0.8421052631578947, hinge=3.832730076187535, ce=8.144577771237023
Local test acc @ epoch 298: 0.8421
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 8.195632972274325e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.28 seconds!
[tester] 
AGNewsMetric: acc=0.8448684210526316, hinge=3.5798657257933364, ce=8.224633646513286
Local test acc @ epoch 298: 0.8449
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.4901159417490817e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 4.4703469370688254e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 131.06 seconds!
[tester] 
AGNewsMetric: acc=0.8325, hinge=4.00732117213701, ce=8.211457195281982
Local test acc @ epoch 298: 0.8325
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 6.705521116145974e-08
Local loss @ local epoch 2: 3.725289943190546e-08
Local loss @ local epoch 3: 1.4901159417490817e-08
Local loss @ local epoch 4: 4.4703338630824874e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.41 seconds!
[tester] 
AGNewsMetric: acc=0.8306578947368422, hinge=4.026108388900757, ce=8.242344595256604
Local test acc @ epoch 298: 0.8307
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.39 seconds!
[tester] 
AGNewsMetric: acc=0.8448684210526316, hinge=3.6586411338103444, ce=8.148895052859658
Local test acc @ epoch 298: 0.8449
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.23 seconds!
[tester] 
AGNewsMetric: acc=0.845, hinge=3.6709486520917793, ce=8.071196834162661
Local test acc @ epoch 298: 0.845
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.2351740014414645e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.1 seconds!
[tester] 
AGNewsMetric: acc=0.8225, hinge=4.203468826068075, ce=8.38471617648476
Local test acc @ epoch 298: 0.8225
Global evaluate on test data...
Evaluate data in 130.07 seconds!
[tester] 
AGNewsMetric: acc=0.8410526315789474, hinge=3.7543714160668222, ce=8.099720669796593
Global test acc @ epoch 298: 0.8411
Global epoch 299...
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 2.2351738238057806e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.4901159417490817e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.6 seconds!
[tester] 
AGNewsMetric: acc=0.8310526315789474, hinge=3.99887666865399, ce=8.130644835421913
Local test acc @ epoch 299: 0.8311
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 2.2351738238057806e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.45 seconds!
[tester] 
AGNewsMetric: acc=0.8419736842105263, hinge=3.734868969917297, ce=7.930792603743703
Local test acc @ epoch 299: 0.842
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.13 seconds!
[tester] 
AGNewsMetric: acc=0.8326315789473684, hinge=4.007408107079958, ce=8.213370428587261
Local test acc @ epoch 299: 0.8326
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.88 seconds!
[tester] 
AGNewsMetric: acc=0.8427631578947369, hinge=3.7164742447200574, ce=8.126655476218776
Local test acc @ epoch 299: 0.8428
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 3.725289587919178e-08
Local loss @ local epoch 1: 4.097805970104673e-07
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 2.756711410256685e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.34 seconds!
[tester] 
AGNewsMetric: acc=0.8414473684210526, hinge=3.364802231537668, ce=8.621189589249461
Local test acc @ epoch 299: 0.8414
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 3.725289587919178e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.61 seconds!
[tester] 
AGNewsMetric: acc=0.8207894736842105, hinge=4.243888496599699, ce=8.418117746051989
Local test acc @ epoch 299: 0.8208
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.25 seconds!
[tester] 
AGNewsMetric: acc=0.844078947368421, hinge=3.6851185924128482, ce=8.19196962958888
Local test acc @ epoch 299: 0.8441
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.04315831512212753
Local loss @ local epoch 3: 0.39433780312538147
Local loss @ local epoch 4: 0.16236397624015808
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.58 seconds!
[tester] 
AGNewsMetric: acc=0.8396052631578947, hinge=3.3597940296875803, ce=8.721484259555215
Local test acc @ epoch 299: 0.8396
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.49 seconds!
[tester] 
AGNewsMetric: acc=0.8436842105263158, hinge=3.6595846474798104, ce=8.190768054159063
Local test acc @ epoch 299: 0.8437
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901159417490817e-08
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 9.68574909165909e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.2351738238057806e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.69 seconds!
[tester] 
AGNewsMetric: acc=0.7723684210526316, hinge=5.865211816085012, ce=9.361616694801732
Local test acc @ epoch 299: 0.7724
Global evaluate on test data...
Evaluate data in 129.36 seconds!
[tester] 
AGNewsMetric: acc=0.8414473684210526, hinge=3.7660364567606073, ce=8.152543413262618
Global test acc @ epoch 299: 0.8414
Global epoch 300...
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.07 seconds!
[tester] 
AGNewsMetric: acc=0.8415789473684211, hinge=3.758402471667842, ce=8.205689859892193
Local test acc @ epoch 300: 0.8416
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 4.4703469370688254e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.16 seconds!
[tester] 
AGNewsMetric: acc=0.8421052631578947, hinge=3.812811917254799, ce=8.39705979999743
Local test acc @ epoch 300: 0.8421
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.62 seconds!
[tester] 
AGNewsMetric: acc=0.8438157894736842, hinge=3.676114497561204, ce=8.34388510754234
Local test acc @ epoch 300: 0.8438
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.26 seconds!
[tester] 
AGNewsMetric: acc=0.8401315789473685, hinge=3.792179198641526, ce=8.257459567220588
Local test acc @ epoch 300: 0.8401
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 2.2351740014414645e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 5.140880148246652e-07
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.14 seconds!
[tester] 
AGNewsMetric: acc=0.8367105263157895, hinge=3.8068924002898368, ce=8.452640860708136
Local test acc @ epoch 300: 0.8367
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.42 seconds!
[tester] 
AGNewsMetric: acc=0.8403947368421053, hinge=3.7411578296360215, ce=8.247503832766885
Local test acc @ epoch 300: 0.8404
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 2.2351738238057806e-08
Local loss @ local epoch 1: 1.4901144140821998e-07
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 8.940690321423972e-08
Local loss @ local epoch 4: 3.725289587919178e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.51 seconds!
[tester] 
AGNewsMetric: acc=0.8360526315789474, hinge=3.828475039130763, ce=8.36598543267501
Local test acc @ epoch 300: 0.8361
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 3.725289943190546e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.08 seconds!
[tester] 
AGNewsMetric: acc=0.8309210526315789, hinge=4.006523605898807, ce=8.232443902868974
Local test acc @ epoch 300: 0.8309
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.2351738238057806e-08
Local loss @ local epoch 3: 1.4901159417490817e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.17 seconds!
[tester] 
AGNewsMetric: acc=0.8196052631578947, hinge=4.270596212587859, ce=8.607657173558286
Local test acc @ epoch 300: 0.8196
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.53 seconds!
[tester] 
AGNewsMetric: acc=0.8397368421052631, hinge=3.7661866617202757, ce=8.219003869106896
Local test acc @ epoch 300: 0.8397
Global evaluate on test data...
Evaluate data in 129.1 seconds!
[tester] 
AGNewsMetric: acc=0.8394736842105263, hinge=3.8061074762595326, ce=8.19877618689286
Global test acc @ epoch 300: 0.8395
Global epoch 301...
Client 1 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.34 seconds!
[tester] 
AGNewsMetric: acc=0.8414473684210526, hinge=3.766065453353681, ce=8.177784344522577
Local test acc @ epoch 301: 0.8414
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.42 seconds!
[tester] 
AGNewsMetric: acc=0.8388157894736842, hinge=3.7568257850094846, ce=8.273532702797338
Local test acc @ epoch 301: 0.8388
Client 7 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 2.2351738238057806e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.53 seconds!
[tester] 
AGNewsMetric: acc=0.8471052631578947, hinge=3.6254353687637733, ce=8.180051594784386
Local test acc @ epoch 301: 0.8471
Client 5 execute local training on 16 samples...
Local loss @ local epoch 0: 2.2351738238057806e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 128.2 seconds!
[tester] 
AGNewsMetric: acc=0.8461842105263158, hinge=3.676031061348162, ce=8.231962675797313
Local test acc @ epoch 301: 0.8462
Client 6 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 1.4901159417490817e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.9802315282267955e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 127.54 seconds!
[tester] 
AGNewsMetric: acc=0.8402631578947368, hinge=3.744971803740451, ce=8.229367089522512
Local test acc @ epoch 301: 0.8403
Client 3 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 127.62 seconds!
[tester] 
AGNewsMetric: acc=0.8368421052631579, hinge=3.8211366152763366, ce=8.394128530401932
Local test acc @ epoch 301: 0.8368
Client 8 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.4901159417490817e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 127.61 seconds!
[tester] 
AGNewsMetric: acc=0.8407894736842105, hinge=3.6916220403972426, ce=8.285108397634406
Local test acc @ epoch 301: 0.8408
Client 2 execute local training on 16 samples...
Local loss @ local epoch 0: 6.705518984517767e-08
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 6.206029411259806e-06
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 128.57 seconds!
[tester] 
AGNewsMetric: acc=0.8103947368421053, hinge=4.468939293434746, ce=8.622201263026188
Local test acc @ epoch 301: 0.8104
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 130.23 seconds!
[tester] 
AGNewsMetric: acc=0.8422368421052632, hinge=3.7283381485939024, ce=8.202019344129061
Local test acc @ epoch 301: 0.8422
Client 4 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.2351740014414645e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.34 seconds!
[tester] 
AGNewsMetric: acc=0.8406578947368422, hinge=3.7905765928720174, ce=8.11581075668335
Local test acc @ epoch 301: 0.8407
Global evaluate on test data...
Evaluate data in 129.65 seconds!
[tester] 
AGNewsMetric: acc=0.8457894736842105, hinge=3.6921321754706535, ce=8.085560902043392
Global test acc @ epoch 301: 0.8458
Global epoch 302...
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901159417490817e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450576333667414e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 129.95 seconds!
[tester] 
AGNewsMetric: acc=0.8393421052631579, hinge=3.9058582032354257, ce=8.112052624351099
Local test acc @ epoch 302: 0.8393
Client 0 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.5646206463770795e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
