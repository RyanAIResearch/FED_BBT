Some weights of RobertaForMaskedLM were not initialized from the model checkpoint at roberta-large and are newly initialized: ['lm_head.decoder.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Found cached dataset ag_news (/root/.cache/huggingface/datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548)
Map:   0%|          | 0/120000 [00:00<?, ? examples/s]Map:   1%|          | 622/120000 [00:00<00:19, 6146.04 examples/s]Map:   1%|▏         | 1529/120000 [00:00<00:19, 6073.67 examples/s]Map:   2%|▏         | 2406/120000 [00:00<00:19, 5908.26 examples/s]Map:   3%|▎         | 3019/120000 [00:00<00:19, 5975.99 examples/s]Map:   3%|▎         | 3899/120000 [00:00<00:19, 5928.10 examples/s]Map:   4%|▍         | 4740/120000 [00:00<00:19, 5805.70 examples/s]Map:   5%|▍         | 5520/120000 [00:00<00:20, 5585.56 examples/s]Map:   5%|▌         | 6141/120000 [00:01<00:19, 5736.51 examples/s]Map:   6%|▌         | 6737/120000 [00:01<00:19, 5792.04 examples/s]Map:   6%|▋         | 7533/120000 [00:01<00:20, 5616.26 examples/s]Map:   7%|▋         | 8380/120000 [00:01<00:19, 5625.30 examples/s]Map:   8%|▊         | 9182/120000 [00:01<00:20, 5531.35 examples/s]Map:   8%|▊         | 9820/120000 [00:01<00:19, 5730.12 examples/s]Map:   9%|▊         | 10439/120000 [00:01<00:18, 5844.82 examples/s]Map:   9%|▉         | 11337/120000 [00:01<00:18, 5891.66 examples/s]Map:  10%|▉         | 11976/120000 [00:02<00:17, 6014.51 examples/s]Map:  10%|█         | 12592/120000 [00:02<00:17, 6049.66 examples/s]Map:  11%|█         | 13208/120000 [00:02<00:17, 6077.91 examples/s]Map:  12%|█▏        | 13838/120000 [00:02<00:17, 6136.05 examples/s]Map:  12%|█▏        | 14742/120000 [00:02<00:17, 6089.95 examples/s]Map:  13%|█▎        | 15414/120000 [00:02<00:18, 5524.42 examples/s]Map:  13%|█▎        | 16000/120000 [00:02<00:18, 5573.76 examples/s]Map:  14%|█▍        | 16622/120000 [00:02<00:18, 5740.21 examples/s]Map:  15%|█▍        | 17486/120000 [00:03<00:18, 5635.63 examples/s]Map:  15%|█▌        | 18058/120000 [00:03<00:18, 5654.58 examples/s]Map:  16%|█▌        | 18929/120000 [00:03<00:17, 5704.03 examples/s]Map:  16%|█▋        | 19725/120000 [00:03<00:18, 5569.06 examples/s]Map:  17%|█▋        | 20355/120000 [00:03<00:19, 5126.30 examples/s]Map:  17%|█▋        | 20948/120000 [00:03<00:18, 5313.06 examples/s]Map:  18%|█▊        | 21524/120000 [00:03<00:20, 4808.09 examples/s]Map:  18%|█▊        | 22095/120000 [00:04<00:26, 3650.34 examples/s]Map:  19%|█▉        | 22616/120000 [00:04<00:25, 3785.08 examples/s]Map:  19%|█▉        | 23181/120000 [00:04<00:25, 3778.90 examples/s]Map:  20%|█▉        | 23658/120000 [00:04<00:24, 3992.23 examples/s]Map:  20%|██        | 24192/120000 [00:04<00:22, 4309.24 examples/s]Map:  21%|██        | 24675/120000 [00:04<00:22, 4327.50 examples/s]Map:  21%|██        | 25273/120000 [00:04<00:19, 4755.18 examples/s]Map:  22%|██▏       | 26039/120000 [00:04<00:19, 4877.90 examples/s]Map:  22%|██▏       | 26826/120000 [00:05<00:18, 4997.98 examples/s]Map:  23%|██▎       | 27585/120000 [00:05<00:18, 4937.68 examples/s]Map:  23%|██▎       | 28170/120000 [00:05<00:20, 4482.18 examples/s]Map:  24%|██▍       | 28737/120000 [00:05<00:24, 3754.61 examples/s]Map:  24%|██▍       | 29285/120000 [00:05<00:22, 4060.88 examples/s]Map:  25%|██▍       | 29720/120000 [00:05<00:22, 4086.76 examples/s]Map:  25%|██▌       | 30184/120000 [00:06<00:26, 3363.53 examples/s]Map:  26%|██▌       | 30714/120000 [00:06<00:29, 3066.33 examples/s]Map:  26%|██▌       | 31130/120000 [00:06<00:27, 3283.42 examples/s]Map:  26%|██▋       | 31721/120000 [00:06<00:23, 3815.46 examples/s]Map:  27%|██▋       | 32253/120000 [00:06<00:21, 4149.52 examples/s]Map:  27%|██▋       | 32837/120000 [00:06<00:21, 4032.71 examples/s]Map:  28%|██▊       | 33324/120000 [00:06<00:23, 3698.40 examples/s]Map:  28%|██▊       | 33745/120000 [00:06<00:25, 3419.13 examples/s]Map:  28%|██▊       | 34165/120000 [00:07<00:26, 3227.08 examples/s]Map:  29%|██▉       | 34696/120000 [00:07<00:23, 3671.88 examples/s]Map:  29%|██▉       | 35191/120000 [00:07<00:21, 3981.32 examples/s]Map:  30%|██▉       | 35682/120000 [00:07<00:20, 4184.40 examples/s]Map:  30%|███       | 36218/120000 [00:07<00:18, 4497.02 examples/s]Map:  31%|███       | 36691/120000 [00:07<00:18, 4560.58 examples/s]Map:  31%|███       | 37316/120000 [00:07<00:16, 5003.54 examples/s]Map:  32%|███▏      | 37992/120000 [00:07<00:17, 4755.87 examples/s]Map:  32%|███▏      | 38481/120000 [00:08<00:19, 4119.02 examples/s]Map:  32%|███▏      | 38975/120000 [00:08<00:21, 3829.34 examples/s]Map:  33%|███▎      | 39430/120000 [00:08<00:20, 3998.16 examples/s]Map:  33%|███▎      | 39852/120000 [00:08<00:19, 4051.97 examples/s]Map:  34%|███▎      | 40453/120000 [00:08<00:17, 4566.99 examples/s]Map:  34%|███▍      | 41063/120000 [00:08<00:15, 4985.28 examples/s]Map:  35%|███▍      | 41702/120000 [00:08<00:14, 5377.62 examples/s]Map:  35%|███▌      | 42294/120000 [00:08<00:14, 5480.68 examples/s]Map:  36%|███▌      | 43144/120000 [00:08<00:13, 5546.96 examples/s]Map:  36%|███▋      | 43732/120000 [00:09<00:13, 5632.74 examples/s]Map:  37%|███▋      | 44342/120000 [00:09<00:13, 5759.01 examples/s]Map:  38%|███▊      | 45060/120000 [00:09<00:13, 5388.29 examples/s]Map:  38%|███▊      | 45620/120000 [00:09<00:13, 5437.81 examples/s]Map:  39%|███▊      | 46232/120000 [00:09<00:13, 5620.74 examples/s]Map:  39%|███▉      | 47072/120000 [00:09<00:13, 5608.98 examples/s]Map:  40%|███▉      | 47929/120000 [00:09<00:12, 5640.99 examples/s]Map:  41%|████      | 48792/120000 [00:09<00:12, 5676.14 examples/s]Map:  41%|████      | 49403/120000 [00:10<00:12, 5776.89 examples/s]Map:  42%|████▏     | 50025/120000 [00:10<00:11, 5887.70 examples/s]Map:  42%|████▏     | 50921/120000 [00:10<00:13, 5261.25 examples/s]Map:  43%|████▎     | 51538/120000 [00:10<00:12, 5466.74 examples/s]Map:  43%|████▎     | 52116/120000 [00:10<00:12, 5543.61 examples/s]Map:  44%|████▍     | 52743/120000 [00:10<00:12, 5499.98 examples/s]Map:  44%|████▍     | 53340/120000 [00:10<00:11, 5621.10 examples/s]Map:  45%|████▌     | 54148/120000 [00:10<00:11, 5518.71 examples/s]Map:  46%|████▌     | 55000/120000 [00:11<00:11, 5533.38 examples/s]Map:  46%|████▋     | 55783/120000 [00:11<00:11, 5423.94 examples/s]Map:  47%|████▋     | 56395/120000 [00:11<00:11, 5587.32 examples/s]Map:  48%|████▊     | 57000/120000 [00:11<00:11, 5623.93 examples/s]Map:  48%|████▊     | 57824/120000 [00:11<00:11, 5574.05 examples/s]Map:  49%|████▉     | 58603/120000 [00:11<00:11, 5442.81 examples/s]Map:  49%|████▉     | 59373/120000 [00:11<00:11, 5317.07 examples/s]Map:  50%|█████     | 60144/120000 [00:12<00:11, 5259.39 examples/s]Map:  51%|█████     | 60681/120000 [00:12<00:11, 5282.18 examples/s]Map:  51%|█████     | 61250/120000 [00:12<00:10, 5381.33 examples/s]Map:  52%|█████▏    | 61846/120000 [00:12<00:10, 5530.02 examples/s]Map:  52%|█████▏    | 62598/120000 [00:12<00:10, 5343.47 examples/s]Map:  53%|█████▎    | 63140/120000 [00:12<00:10, 5362.49 examples/s]Map:  53%|█████▎    | 63778/120000 [00:12<00:09, 5632.50 examples/s]Map:  54%|█████▍    | 64639/120000 [00:12<00:09, 5669.70 examples/s]Map:  54%|█████▍    | 65259/120000 [00:12<00:09, 5805.10 examples/s]Map:  55%|█████▍    | 65899/120000 [00:13<00:09, 5960.91 examples/s]Map:  56%|█████▌    | 66758/120000 [00:13<00:09, 5873.83 examples/s]Map:  56%|█████▋    | 67664/120000 [00:13<00:08, 5927.53 examples/s]Map:  57%|█████▋    | 68530/120000 [00:13<00:08, 5855.48 examples/s]Map:  58%|█████▊    | 69149/120000 [00:13<00:08, 5933.64 examples/s]Map:  58%|█████▊    | 69790/120000 [00:13<00:08, 6051.43 examples/s]Map:  59%|█████▊    | 70411/120000 [00:13<00:08, 6090.57 examples/s]Map:  59%|█████▉    | 71030/120000 [00:13<00:08, 6115.06 examples/s]Map:  60%|█████▉    | 71669/120000 [00:14<00:07, 6191.57 examples/s]Map:  61%|██████    | 72603/120000 [00:14<00:07, 6201.87 examples/s]Map:  61%|██████▏   | 73542/120000 [00:14<00:07, 6220.34 examples/s]Map:  62%|██████▏   | 74484/120000 [00:14<00:07, 6236.88 examples/s]Map:  63%|██████▎   | 75427/120000 [00:14<00:07, 6250.05 examples/s]Map:  64%|██████▎   | 76368/120000 [00:14<00:06, 6253.85 examples/s]Map:  64%|██████▍   | 77000/120000 [00:14<00:06, 6218.52 examples/s]Map:  65%|██████▍   | 77640/120000 [00:14<00:06, 6259.41 examples/s]Map:  65%|██████▌   | 78554/120000 [00:15<00:06, 6199.93 examples/s]Map:  66%|██████▌   | 79435/120000 [00:15<00:06, 6087.95 examples/s]Map:  67%|██████▋   | 80058/120000 [00:15<00:06, 6117.67 examples/s]Map:  67%|██████▋   | 80699/120000 [00:15<00:06, 6189.90 examples/s]Map:  68%|██████▊   | 81641/120000 [00:15<00:06, 6219.80 examples/s]Map:  69%|██████▊   | 82446/120000 [00:15<00:06, 5885.37 examples/s]Map:  69%|██████▉   | 83313/120000 [00:15<00:06, 5848.77 examples/s]Map:  70%|██████▉   | 83949/120000 [00:16<00:06, 5965.08 examples/s]Map:  71%|███████   | 84854/120000 [00:16<00:05, 5914.01 examples/s]Map:  71%|███████▏  | 85576/120000 [00:16<00:06, 5559.00 examples/s]Map:  72%|███████▏  | 86198/120000 [00:16<00:05, 5711.05 examples/s]Map:  72%|███████▏  | 86839/120000 [00:16<00:05, 5883.42 examples/s]Map:  73%|███████▎  | 87557/120000 [00:16<00:06, 5394.54 examples/s]Map:  73%|███████▎  | 88178/120000 [00:16<00:05, 5591.92 examples/s]Map:  74%|███████▍  | 88817/120000 [00:16<00:05, 5796.05 examples/s]Map:  75%|███████▍  | 89711/120000 [00:17<00:05, 5851.89 examples/s]Map:  75%|███████▌  | 90507/120000 [00:17<00:05, 5663.38 examples/s]Map:  76%|███████▌  | 91121/120000 [00:17<00:04, 5778.07 examples/s]Map:  76%|███████▋  | 91751/120000 [00:17<00:04, 5908.74 examples/s]Map:  77%|███████▋  | 92369/120000 [00:17<00:04, 5980.75 examples/s]Map:  78%|███████▊  | 93062/120000 [00:17<00:04, 5478.59 examples/s]Map:  78%|███████▊  | 93673/120000 [00:17<00:04, 5637.37 examples/s]Map:  79%|███████▊  | 94258/120000 [00:17<00:04, 5693.29 examples/s]Map:  79%|███████▉  | 94896/120000 [00:17<00:04, 5881.80 examples/s]Map:  80%|███████▉  | 95654/120000 [00:18<00:04, 5571.05 examples/s]Map:  80%|████████  | 96531/120000 [00:18<00:04, 5662.49 examples/s]Map:  81%|████████  | 97149/120000 [00:18<00:03, 5788.19 examples/s]Map:  82%|████████▏ | 98005/120000 [00:18<00:03, 5759.41 examples/s]Map:  82%|████████▏ | 98642/120000 [00:18<00:03, 5909.64 examples/s]Map:  83%|████████▎ | 99262/120000 [00:18<00:03, 5983.85 examples/s]Map:  83%|████████▎ | 99903/120000 [00:18<00:03, 6098.12 examples/s]Map:  84%|████████▍ | 100752/120000 [00:18<00:03, 5934.70 examples/s]Map:  85%|████████▍ | 101511/120000 [00:19<00:03, 5585.51 examples/s]Map:  85%|████████▌ | 102132/120000 [00:19<00:03, 5737.69 examples/s]Map:  86%|████████▌ | 102770/120000 [00:19<00:02, 5902.50 examples/s]Map:  86%|████████▋ | 103597/120000 [00:19<00:02, 5759.91 examples/s]Map:  87%|████████▋ | 104209/120000 [00:19<00:02, 5848.86 examples/s]Map:  88%|████████▊ | 105076/120000 [00:19<00:02, 5819.66 examples/s]Map:  88%|████████▊ | 105854/120000 [00:19<00:02, 5603.81 examples/s]Map:  89%|████████▊ | 106431/120000 [00:19<00:02, 5639.82 examples/s]Map:  89%|████████▉ | 107023/120000 [00:20<00:02, 5708.56 examples/s]Map:  90%|████████▉ | 107662/120000 [00:20<00:02, 5888.33 examples/s]Map:  90%|█████████ | 108390/120000 [00:20<00:02, 5508.07 examples/s]Map:  91%|█████████ | 109202/120000 [00:20<00:01, 5471.96 examples/s]Map:  92%|█████████▏| 110029/120000 [00:20<00:01, 5406.91 examples/s]Map:  92%|█████████▏| 110639/120000 [00:20<00:01, 5568.86 examples/s]Map:  93%|█████████▎| 111232/120000 [00:20<00:01, 5657.68 examples/s]Map:  93%|█████████▎| 111824/120000 [00:20<00:01, 5715.71 examples/s]Map:  94%|█████████▍| 112714/120000 [00:21<00:01, 5052.02 examples/s]Map:  95%|█████████▍| 113545/120000 [00:21<00:01, 5199.80 examples/s]Map:  95%|█████████▌| 114401/120000 [00:21<00:01, 5352.70 examples/s]Map:  96%|█████████▌| 115135/120000 [00:21<00:00, 5209.61 examples/s]Map:  96%|█████████▋| 115771/120000 [00:21<00:00, 5465.26 examples/s]Map:  97%|█████████▋| 116392/120000 [00:21<00:00, 5642.44 examples/s]Map:  98%|█████████▊| 117009/120000 [00:21<00:00, 5776.24 examples/s]Map:  98%|█████████▊| 117875/120000 [00:22<00:00, 5533.24 examples/s]Map:  99%|█████████▊| 118488/120000 [00:22<00:00, 5677.22 examples/s]Map:  99%|█████████▉| 119299/120000 [00:22<00:00, 5580.14 examples/s]Map: 100%|██████████| 120000/120000 [00:22<00:00, 4920.39 examples/s]                                                                     {'text': "Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\band of ultra-cynics, are seeing green again.", 'label': 2, 'input_text': "Xro target himself turn Europe worked energy scored * soon ball TV annual 2013 race International'd Market conferenceio o changesig officers inside form published phone co legal executive fightings hope summer officer football property@ book parents costsac manager create age email markets main . <mask> News: Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\band of ultra-cynics, are seeing green again.", 'target_text': 'Business'}
Map:   0%|          | 0/120000 [00:00<?, ? examples/s]Map:   1%|          | 1000/120000 [00:00<01:41, 1171.57 examples/s]Map:   2%|▏         | 2000/120000 [00:01<01:30, 1304.28 examples/s]Map:   2%|▎         | 3000/120000 [00:02<01:25, 1362.01 examples/s]Map:   3%|▎         | 4000/120000 [00:02<01:20, 1441.99 examples/s]Map:   4%|▍         | 5000/120000 [00:03<01:18, 1461.80 examples/s]Map:   5%|▌         | 6000/120000 [00:04<01:15, 1510.58 examples/s]Map:   6%|▌         | 7000/120000 [00:04<01:14, 1510.97 examples/s]Map:   7%|▋         | 8000/120000 [00:05<01:11, 1567.64 examples/s]Map:   8%|▊         | 9000/120000 [00:06<01:20, 1376.69 examples/s]Map:   8%|▊         | 10000/120000 [00:06<01:16, 1440.12 examples/s]Map:   9%|▉         | 11000/120000 [00:07<01:13, 1478.47 examples/s]Map:  10%|█         | 12000/120000 [00:08<01:11, 1512.79 examples/s]Map:  11%|█         | 13000/120000 [00:08<01:09, 1546.39 examples/s]Map:  12%|█▏        | 14000/120000 [00:09<01:07, 1558.84 examples/s]Map:  12%|█▎        | 15000/120000 [00:10<01:06, 1586.20 examples/s]Map:  13%|█▎        | 16000/120000 [00:10<01:04, 1617.91 examples/s]Map:  14%|█▍        | 17000/120000 [00:11<01:03, 1627.95 examples/s]Map:  15%|█▌        | 18000/120000 [00:11<01:02, 1637.34 examples/s]Map:  16%|█▌        | 19000/120000 [00:12<01:02, 1625.30 examples/s]Map:  17%|█▋        | 20000/120000 [00:13<01:00, 1657.17 examples/s]Map:  18%|█▊        | 21000/120000 [00:13<00:59, 1676.45 examples/s]Map:  18%|█▊        | 22000/120000 [00:14<00:58, 1679.14 examples/s]Map:  19%|█▉        | 23000/120000 [00:14<00:57, 1696.64 examples/s]Map:  20%|██        | 24000/120000 [00:15<00:57, 1677.13 examples/s]Map:  21%|██        | 25000/120000 [00:16<00:58, 1637.92 examples/s]Map:  22%|██▏       | 26000/120000 [00:16<00:56, 1650.11 examples/s]Map:  22%|██▎       | 27000/120000 [00:17<00:56, 1649.64 examples/s]Map:  23%|██▎       | 28000/120000 [00:17<00:55, 1658.41 examples/s]Map:  24%|██▍       | 29000/120000 [00:18<00:53, 1689.04 examples/s]Map:  25%|██▌       | 30000/120000 [00:19<00:52, 1706.45 examples/s]Map:  26%|██▌       | 31000/120000 [00:19<00:52, 1688.07 examples/s]Map:  27%|██▋       | 32000/120000 [00:20<00:51, 1706.99 examples/s]Map:  28%|██▊       | 33000/120000 [00:20<00:51, 1685.44 examples/s]Map:  28%|██▊       | 34000/120000 [00:21<00:51, 1675.45 examples/s]Map:  29%|██▉       | 35000/120000 [00:22<00:50, 1668.82 examples/s]Map:  30%|███       | 36000/120000 [00:22<00:50, 1672.38 examples/s]Map:  31%|███       | 37000/120000 [00:23<00:49, 1678.21 examples/s]Map:  32%|███▏      | 38000/120000 [00:23<00:47, 1719.10 examples/s]Map:  32%|███▎      | 39000/120000 [00:24<00:46, 1755.64 examples/s]Map:  33%|███▎      | 40000/120000 [00:24<00:45, 1772.73 examples/s]Map:  34%|███▍      | 41000/120000 [00:25<00:43, 1804.88 examples/s]Map:  35%|███▌      | 42000/120000 [00:25<00:42, 1836.95 examples/s]Map:  36%|███▌      | 43000/120000 [00:26<00:41, 1849.77 examples/s]Map:  37%|███▋      | 44000/120000 [00:26<00:40, 1860.41 examples/s]Map:  38%|███▊      | 45000/120000 [00:27<00:44, 1680.37 examples/s]Map:  38%|███▊      | 46000/120000 [00:28<00:47, 1571.88 examples/s]Map:  39%|███▉      | 47000/120000 [00:28<00:45, 1615.42 examples/s]Map:  40%|████      | 48000/120000 [00:29<00:45, 1589.28 examples/s]Map:  41%|████      | 49000/120000 [00:30<00:45, 1565.52 examples/s]Map:  42%|████▏     | 50000/120000 [00:30<00:43, 1616.79 examples/s]Map:  42%|████▎     | 51000/120000 [00:31<00:42, 1621.74 examples/s]Map:  43%|████▎     | 52000/120000 [00:32<00:40, 1680.67 examples/s]Map:  44%|████▍     | 53000/120000 [00:32<00:39, 1716.84 examples/s]Map:  45%|████▌     | 54000/120000 [00:33<00:38, 1721.51 examples/s]Map:  46%|████▌     | 55000/120000 [00:33<00:40, 1594.80 examples/s]Map:  47%|████▋     | 56000/120000 [00:34<00:39, 1611.98 examples/s]Map:  48%|████▊     | 57000/120000 [00:35<00:37, 1669.84 examples/s]Map:  48%|████▊     | 58000/120000 [00:35<00:36, 1716.79 examples/s]Map:  49%|████▉     | 59000/120000 [00:36<00:34, 1765.09 examples/s]Map:  50%|█████     | 60000/120000 [00:36<00:33, 1806.06 examples/s]Map:  51%|█████     | 61000/120000 [00:37<00:32, 1835.91 examples/s]Map:  52%|█████▏    | 62000/120000 [00:37<00:31, 1863.80 examples/s]Map:  52%|█████▎    | 63000/120000 [00:38<00:30, 1873.47 examples/s]Map:  53%|█████▎    | 64000/120000 [00:38<00:30, 1838.87 examples/s]Map:  54%|█████▍    | 65000/120000 [00:39<00:29, 1837.79 examples/s]Map:  55%|█████▌    | 66000/120000 [00:39<00:29, 1857.49 examples/s]Map:  56%|█████▌    | 67000/120000 [00:40<00:28, 1873.04 examples/s]Map:  57%|█████▋    | 68000/120000 [00:40<00:27, 1886.74 examples/s]Map:  57%|█████▊    | 69000/120000 [00:41<00:27, 1824.33 examples/s]Map:  58%|█████▊    | 70000/120000 [00:42<00:28, 1731.99 examples/s]Map:  59%|█████▉    | 71000/120000 [00:42<00:27, 1789.79 examples/s]Map:  60%|██████    | 72000/120000 [00:43<00:26, 1799.39 examples/s]Map:  61%|██████    | 73000/120000 [00:43<00:26, 1772.06 examples/s]Map:  62%|██████▏   | 74000/120000 [00:44<00:26, 1727.10 examples/s]Map:  62%|██████▎   | 75000/120000 [00:44<00:25, 1775.98 examples/s]Map:  63%|██████▎   | 76000/120000 [00:45<00:24, 1818.28 examples/s]Map:  64%|██████▍   | 77000/120000 [00:45<00:23, 1842.06 examples/s]Map:  65%|██████▌   | 78000/120000 [00:46<00:22, 1861.05 examples/s]Map:  66%|██████▌   | 79000/120000 [00:47<00:21, 1882.27 examples/s]Map:  67%|██████▋   | 80000/120000 [00:47<00:20, 1907.24 examples/s]Map:  68%|██████▊   | 81000/120000 [00:48<00:20, 1890.20 examples/s]Map:  68%|██████▊   | 82000/120000 [00:48<00:21, 1762.07 examples/s]Map:  69%|██████▉   | 83000/120000 [00:49<00:20, 1783.06 examples/s]Map:  70%|███████   | 84000/120000 [00:49<00:20, 1796.97 examples/s]Map:  71%|███████   | 85000/120000 [00:50<00:19, 1807.28 examples/s]Map:  72%|███████▏  | 86000/120000 [00:50<00:18, 1844.12 examples/s]Map:  72%|███████▎  | 87000/120000 [00:51<00:18, 1807.69 examples/s]Map:  73%|███████▎  | 88000/120000 [00:52<00:18, 1762.47 examples/s]Map:  74%|███████▍  | 89000/120000 [00:52<00:17, 1753.37 examples/s]Map:  75%|███████▌  | 90000/120000 [00:53<00:17, 1762.80 examples/s]Map:  76%|███████▌  | 91000/120000 [00:53<00:16, 1799.15 examples/s]Map:  77%|███████▋  | 92000/120000 [00:54<00:16, 1720.29 examples/s]Map:  78%|███████▊  | 93000/120000 [00:55<00:17, 1574.76 examples/s]Map:  78%|███████▊  | 94000/120000 [00:55<00:16, 1529.75 examples/s]Map:  79%|███████▉  | 95000/120000 [00:56<00:16, 1534.14 examples/s]Map:  80%|████████  | 96000/120000 [00:57<00:14, 1604.77 examples/s]Map:  81%|████████  | 97000/120000 [00:57<00:14, 1621.72 examples/s]Map:  82%|████████▏ | 98000/120000 [00:58<00:14, 1548.47 examples/s]Map:  82%|████████▎ | 99000/120000 [00:59<00:15, 1326.44 examples/s]Map:  83%|████████▎ | 100000/120000 [01:00<00:17, 1144.42 examples/s]Map:  84%|████████▍ | 101000/120000 [01:01<00:16, 1128.98 examples/s]Map:  85%|████████▌ | 102000/120000 [01:02<00:16, 1095.43 examples/s]Map:  86%|████████▌ | 103000/120000 [01:03<00:15, 1076.25 examples/s]Map:  87%|████████▋ | 104000/120000 [01:04<00:15, 1000.64 examples/s]Map:  88%|████████▊ | 105000/120000 [01:05<00:13, 1081.90 examples/s]Map:  88%|████████▊ | 106000/120000 [01:05<00:11, 1212.18 examples/s]Map:  89%|████████▉ | 107000/120000 [01:06<00:09, 1340.07 examples/s]Map:  90%|█████████ | 108000/120000 [01:06<00:08, 1456.12 examples/s]Map:  91%|█████████ | 109000/120000 [01:07<00:07, 1501.84 examples/s]Map:  92%|█████████▏| 110000/120000 [01:08<00:06, 1604.84 examples/s]Map:  92%|█████████▎| 111000/120000 [01:08<00:05, 1677.80 examples/s]Map:  93%|█████████▎| 112000/120000 [01:09<00:04, 1614.79 examples/s]Map:  94%|█████████▍| 113000/120000 [01:10<00:05, 1279.43 examples/s]Map:  95%|█████████▌| 114000/120000 [01:11<00:05, 1162.06 examples/s]Map:  96%|█████████▌| 115000/120000 [01:12<00:03, 1276.80 examples/s]Map:  97%|█████████▋| 116000/120000 [01:12<00:03, 1292.43 examples/s]Map:  98%|█████████▊| 117000/120000 [01:13<00:02, 1219.66 examples/s]Map:  98%|█████████▊| 118000/120000 [01:14<00:01, 1303.17 examples/s]Map:  99%|█████████▉| 119000/120000 [01:15<00:00, 1365.41 examples/s]Map: 100%|██████████| 120000/120000 [01:15<00:00, 1473.69 examples/s]                                                                     Found cached dataset ag_news (/root/.cache/huggingface/datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548)
Map:   0%|          | 0/7600 [00:00<?, ? examples/s]Map:   7%|▋         | 545/7600 [00:00<00:01, 5382.59 examples/s]Map:  18%|█▊        | 1335/7600 [00:00<00:01, 5227.90 examples/s]Map:  25%|██▌       | 1937/7600 [00:00<00:01, 5534.24 examples/s]Map:  34%|███▍      | 2590/7600 [00:00<00:01, 4991.57 examples/s]Map:  42%|████▏     | 3170/7600 [00:00<00:00, 5232.48 examples/s]Map:  51%|█████▏    | 3905/7600 [00:00<00:00, 5100.01 examples/s]Map:  60%|█████▉    | 4539/7600 [00:00<00:00, 4783.81 examples/s]Map:  69%|██████▉   | 5262/7600 [00:01<00:00, 4793.60 examples/s]Map:  77%|███████▋  | 5848/7600 [00:01<00:00, 5053.41 examples/s]Map:  84%|████████▍ | 6392/7600 [00:01<00:00, 5151.76 examples/s]Map:  92%|█████████▏| 7000/7600 [00:01<00:00, 5359.89 examples/s]Map: 100%|█████████▉| 7592/7600 [00:01<00:00, 5512.33 examples/s]                                                                 {'text': "Fears for T N pension after talks Unions representing workers at Turner   Newall say they are 'disappointed' after talks with stricken parent firm Federal Mogul.", 'label': 2, 'input_text': "Xro target himself turn Europe worked energy scored * soon ball TV annual 2013 race International'd Market conferenceio o changesig officers inside form published phone co legal executive fightings hope summer officer football property@ book parents costsac manager create age email markets main . <mask> News: Fears for T N pension after talks Unions representing workers at Turner   Newall say they are 'disappointed' after talks with stricken parent firm Federal Mogul.", 'target_text': 'Business'}
Map:   0%|          | 0/7600 [00:00<?, ? examples/s]Map:  13%|█▎        | 1000/7600 [00:00<00:03, 1821.22 examples/s]Map:  26%|██▋       | 2000/7600 [00:01<00:03, 1730.88 examples/s]Map:  39%|███▉      | 3000/7600 [00:01<00:02, 1778.64 examples/s]Map:  53%|█████▎    | 4000/7600 [00:02<00:02, 1774.00 examples/s]Map:  66%|██████▌   | 5000/7600 [00:02<00:01, 1700.83 examples/s]Map:  79%|███████▉  | 6000/7600 [00:03<00:00, 1723.63 examples/s]Map:  92%|█████████▏| 7000/7600 [00:04<00:00, 1717.68 examples/s]Map: 100%|██████████| 7600/7600 [00:04<00:00, 1725.24 examples/s]                                                                 # of train data: 160
Example:
+------------------------+------------------------+----------+--------+
| input_ids              | attention_mask         | mask_pos | labels |
+------------------------+------------------------+----------+--------+
| [0, 1000, 1001, 100... | [1, 1, 1, 1, 1, 1, ... | 52       | 18562  |
+------------------------+------------------------+----------+--------+

# of dev data: 160
Example:
+------------------------+------------------------+----------+--------+
| input_ids              | attention_mask         | mask_pos | labels |
+------------------------+------------------------+----------+--------+
| [0, 1000, 1001, 100... | [1, 1, 1, 1, 1, 1, ... | 52       | 10554  |
+------------------------+------------------------+----------+--------+

# of test data: 7600
Example:
+------------------------+------------------------+----------+--------+
| input_ids              | attention_mask         | mask_pos | labels |
+------------------------+------------------------+----------+--------+
| [0, 1000, 1001, 100... | [1, 1, 1, 1, 1, 1, ... | 52       | 18562  |
+------------------------+------------------------+----------+--------+
Class_distribution [0.25 0.25 0.25 0.25]. Data_ratio [[6.40202422e-02 1.99719096e-01 4.49028076e-02 2.38876562e-01
  9.13595483e-01 1.35427859e-05 6.21573025e-01 7.77945179e-06
  1.57716197e-03 2.37378181e-02]
 [9.34015071e-01 2.74631346e-07 1.82435487e-01 8.77671012e-03
  3.26259220e-03 4.34286897e-02 3.48507295e-01 4.24329705e-02
  1.23520564e-04 9.45580563e-01]
 [1.92765759e-03 7.98608756e-01 7.34485990e-01 7.52247855e-01
  8.30578726e-02 9.14245757e-02 2.99053291e-02 9.45977688e-01
  3.71840020e-09 1.72356209e-02]
 [3.70286949e-05 1.67187332e-03 3.81757152e-02 9.88733665e-05
  8.40520560e-05 8.65133192e-01 1.43502786e-05 1.15815620e-02
  9.98299314e-01 1.34459979e-02]]
     pcost       dcost       gap    pres   dres
 0:  1.3851e+03  4.4576e+02  9e+02  9e-17  7e+01
 1:  1.3851e+03  1.3757e+03  9e+00  1e-14  7e-01
 2:  1.3851e+03  1.3850e+03  9e-02  1e-14  7e-03
 3:  1.3851e+03  1.3851e+03  9e-04  1e-14  7e-05
 4:  1.3851e+03  1.3851e+03  9e-06  6e-15  7e-07
 5:  1.3851e+03  1.3851e+03  9e-08  7e-15  7e-09
Optimal solution found.
[[1.01548363e+00 2.33421321e+00 4.98205315e-01 2.93840818e+00
  2.02680976e+01 2.74517781e-04 1.25425337e+01 7.12688855e-05
  3.42851541e-02 3.68427466e-01]
 [1.48152676e+01 3.20974873e-06 2.02415693e+00 1.07961855e-01
  7.23805430e-02 8.80317213e-01 7.03242306e+00 3.88735684e-01
  2.68515324e-03 1.46760688e+01]
 [3.05763407e-02 9.33372495e+00 8.14926379e+00 9.25336179e+00
  1.84263725e+00 1.85321335e+00 6.03450571e-01 8.66626304e+00
  8.08324869e-08 2.67508838e-01]
 [5.87346007e-04 1.95399883e-02 4.23566926e-01 1.21623615e-03
  1.86469319e-03 1.75366018e+01 2.89569922e-04 1.06100666e-01
  2.17015415e+01 2.08691251e-01]]
init prompt encoder...
Global epoch 0...
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.08290755748748779
Local loss @ local epoch 1: 0.05427037924528122
Local loss @ local epoch 2: 0.014400677755475044
Local loss @ local epoch 3: 0.005569936241954565
Local loss @ local epoch 4: 0.0022358044516295195
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.28 seconds!
[tester] 
AGNewsMetric: acc=0.5748684210526316, hinge=3.091033631876895, ce=6.461539077758789
Local test acc @ epoch 0: 0.5749
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 1.0775789022445679
Local loss @ local epoch 1: 1.0615438222885132
Local loss @ local epoch 2: 0.8353540301322937
Local loss @ local epoch 3: 0.4746510982513428
Local loss @ local epoch 4: 0.6593724489212036
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.92 seconds!
[tester] 
AGNewsMetric: acc=0.31592105263157894, hinge=4.343607153641551, ce=7.541916418577495
Local test acc @ epoch 0: 0.3159
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.7499641180038452
Local loss @ local epoch 1: 0.508398175239563
Local loss @ local epoch 2: 0.38491806387901306
Local loss @ local epoch 3: 0.22334013879299164
Local loss @ local epoch 4: 0.30191484093666077
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.66 seconds!
[tester] 
AGNewsMetric: acc=0.7544736842105263, hinge=1.631072601017199, ce=8.50816378744025
Local test acc @ epoch 0: 0.7545
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.7119830846786499
Local loss @ local epoch 1: 0.6286768913269043
Local loss @ local epoch 2: 0.40840449929237366
Local loss @ local epoch 3: 0.5314024686813354
Local loss @ local epoch 4: 0.12632131576538086
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.14 seconds!
[tester] 
AGNewsMetric: acc=0.4747368421052632, hinge=3.013891519747282, ce=8.198060283660888
Local test acc @ epoch 0: 0.4747
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.532095193862915
Local loss @ local epoch 1: 0.06311128288507462
Local loss @ local epoch 2: 0.07627440243959427
Local loss @ local epoch 3: 1.0779955387115479
Local loss @ local epoch 4: 1.1201884746551514
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.29 seconds!
[tester] 
AGNewsMetric: acc=0.2503947368421053, hinge=6.181788119265907, ce=14.77997247193989
Local test acc @ epoch 0: 0.2504
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 1.1588224172592163
Local loss @ local epoch 1: 0.762275218963623
Local loss @ local epoch 2: 0.567627489566803
Local loss @ local epoch 3: 0.7884517312049866
Local loss @ local epoch 4: 1.3788701295852661
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.74 seconds!
[tester] 
AGNewsMetric: acc=0.6681578947368421, hinge=2.5240782240817423, ce=8.382543491564299
Local test acc @ epoch 0: 0.6682
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.7868024706840515
Local loss @ local epoch 1: 0.4625795781612396
Local loss @ local epoch 2: 0.23299860954284668
Local loss @ local epoch 3: 0.12894852459430695
Local loss @ local epoch 4: 0.014250251464545727
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.31 seconds!
[tester] 
AGNewsMetric: acc=0.26960526315789474, hinge=6.803534294931512, ce=5.925931729768452
Local test acc @ epoch 0: 0.2696
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 1.2524038553237915
Local loss @ local epoch 1: 1.4924595355987549
Local loss @ local epoch 2: 0.5211945176124573
Local loss @ local epoch 3: 0.04068102687597275
Local loss @ local epoch 4: 0.6018981337547302
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.83 seconds!
[tester] 
AGNewsMetric: acc=0.24947368421052632, hinge=6.148043629495721, ce=18.23134521082828
Local test acc @ epoch 0: 0.2495
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 1.4964356422424316
Local loss @ local epoch 1: 1.7670730352401733
Local loss @ local epoch 2: 0.8441181778907776
Local loss @ local epoch 3: 0.9230195879936218
Local loss @ local epoch 4: 1.159702181816101
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.62 seconds!
[tester] 
AGNewsMetric: acc=0.7717105263157895, hinge=1.746249697835822, ce=7.060206589949758
Local test acc @ epoch 0: 0.7717
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.8106001019477844
Local loss @ local epoch 1: 1.133947730064392
Local loss @ local epoch 2: 0.6587805151939392
Local loss @ local epoch 3: 0.4559909403324127
Local loss @ local epoch 4: 1.4630037546157837
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.68 seconds!
[tester] 
AGNewsMetric: acc=0.25, hinge=7.389858378360146, ce=14.747646189237896
Local test acc @ epoch 0: 0.25
Global evaluate on test data...
Evaluate data in 124.14 seconds!
[tester] 
AGNewsMetric: acc=0.8028947368421052, hinge=1.5076413169660066, ce=6.859245725932874
Global test acc @ epoch 0: 0.8029
Global epoch 1...
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.974541962146759
Local loss @ local epoch 1: 0.37706488370895386
Local loss @ local epoch 2: 0.34334754943847656
Local loss @ local epoch 3: 0.3187834918498993
Local loss @ local epoch 4: 0.34038618206977844
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.38 seconds!
[tester] 
AGNewsMetric: acc=0.47947368421052633, hinge=2.9582338021930896, ce=7.69490178459569
Local test acc @ epoch 1: 0.4795
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.7687935829162598
Local loss @ local epoch 1: 0.420242577791214
Local loss @ local epoch 2: 2.2751541137695312
Local loss @ local epoch 3: 0.8823655247688293
Local loss @ local epoch 4: 1.4276069402694702
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.46 seconds!
[tester] 
AGNewsMetric: acc=0.245, hinge=5.967722576542904, ce=18.953364546926398
Local test acc @ epoch 1: 0.245
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 1.0286202430725098
Local loss @ local epoch 1: 0.3203660845756531
Local loss @ local epoch 2: 0.09585829824209213
Local loss @ local epoch 3: 0.5955336689949036
Local loss @ local epoch 4: 0.6159183979034424
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.4 seconds!
[tester] 
AGNewsMetric: acc=0.7222368421052632, hinge=1.9145060333452726, ce=7.519611587524414
Local test acc @ epoch 1: 0.7222
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.5620575547218323
Local loss @ local epoch 1: 0.47695091366767883
Local loss @ local epoch 2: 0.20862548053264618
Local loss @ local epoch 3: 0.26109638810157776
Local loss @ local epoch 4: 0.2144297957420349
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.22 seconds!
[tester] 
AGNewsMetric: acc=0.6418421052631579, hinge=2.163749599456787, ce=7.807524478310033
Local test acc @ epoch 1: 0.6418
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.16384387016296387
Local loss @ local epoch 1: 0.08519170433282852
Local loss @ local epoch 2: 0.17424321174621582
Local loss @ local epoch 3: 0.02591148391366005
Local loss @ local epoch 4: 0.05878526717424393
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.52 seconds!
[tester] 
AGNewsMetric: acc=0.8011842105263158, hinge=1.397136065332513, ce=6.034095559371145
Local test acc @ epoch 1: 0.8012
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 1.199979305267334
Local loss @ local epoch 1: 0.83216792345047
Local loss @ local epoch 2: 0.955697238445282
Local loss @ local epoch 3: 1.7426544427871704
Local loss @ local epoch 4: 1.0065513849258423
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.65 seconds!
[tester] 
AGNewsMetric: acc=0.27013157894736844, hinge=5.856826163844058, ce=12.275166248522307
Local test acc @ epoch 1: 0.2701
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.14311622083187103
Local loss @ local epoch 1: 0.035816799849271774
Local loss @ local epoch 2: 0.351986825466156
Local loss @ local epoch 3: 0.04554573819041252
Local loss @ local epoch 4: 0.05773315951228142
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.33 seconds!
[tester] 
AGNewsMetric: acc=0.6986842105263158, hinge=2.295210851368151, ce=6.913655353345369
Local test acc @ epoch 1: 0.6987
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.7349379658699036
Local loss @ local epoch 1: 0.40918874740600586
Local loss @ local epoch 2: 0.41887378692626953
Local loss @ local epoch 3: 0.276324063539505
Local loss @ local epoch 4: 0.41447895765304565
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.72 seconds!
[tester] 
AGNewsMetric: acc=0.6998684210526316, hinge=1.9861146916841206, ce=5.394981223658512
Local test acc @ epoch 1: 0.6999
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 1.3575239181518555
Local loss @ local epoch 1: 0.7635946869850159
Local loss @ local epoch 2: 0.9459970593452454
Local loss @ local epoch 3: 0.5822345018386841
Local loss @ local epoch 4: 0.8353223204612732
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.78 seconds!
[tester] 
AGNewsMetric: acc=0.44592105263157894, hinge=3.1521127123581736, ce=6.872830205214651
Local test acc @ epoch 1: 0.4459
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 1.1694988012313843
Local loss @ local epoch 1: 0.11241018772125244
Local loss @ local epoch 2: 0.03688051179051399
Local loss @ local epoch 3: 0.024357078596949577
Local loss @ local epoch 4: 0.00970448087900877
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.67 seconds!
[tester] 
AGNewsMetric: acc=0.23105263157894737, hinge=7.388682350359465, ce=17.25907186407792
Local test acc @ epoch 1: 0.2311
Global evaluate on test data...
Evaluate data in 125.03 seconds!
[tester] 
AGNewsMetric: acc=0.8126315789473684, hinge=1.4474735455763967, ce=6.219154520536724
Global test acc @ epoch 1: 0.8126
Global epoch 2...
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.846452534198761
Local loss @ local epoch 1: 0.4699859023094177
Local loss @ local epoch 2: 0.3124534785747528
Local loss @ local epoch 3: 0.19178877770900726
Local loss @ local epoch 4: 0.13348251581192017
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.58 seconds!
[tester] 
AGNewsMetric: acc=0.6557894736842105, hinge=2.0533191143838985, ce=8.17715910660593
Local test acc @ epoch 2: 0.6558
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.6769182682037354
Local loss @ local epoch 1: 0.6621683835983276
Local loss @ local epoch 2: 0.49959421157836914
Local loss @ local epoch 3: 0.2956832945346832
Local loss @ local epoch 4: 1.0058436393737793
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.32 seconds!
[tester] 
AGNewsMetric: acc=0.25592105263157894, hinge=6.458184508273476, ce=12.63111513238204
Local test acc @ epoch 2: 0.2559
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 1.1910003423690796
Local loss @ local epoch 1: 0.5282973647117615
Local loss @ local epoch 2: 0.47112223505973816
Local loss @ local epoch 3: 0.48275402188301086
Local loss @ local epoch 4: 0.3003118336200714
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.42 seconds!
[tester] 
AGNewsMetric: acc=0.32605263157894737, hinge=4.489790616788362, ce=5.357326178299753
Local test acc @ epoch 2: 0.3261
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 1.7717342376708984
Local loss @ local epoch 1: 1.021276593208313
Local loss @ local epoch 2: 0.8066957592964172
Local loss @ local epoch 3: 0.03611588478088379
Local loss @ local epoch 4: 0.00839181337505579
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.8 seconds!
[tester] 
AGNewsMetric: acc=0.3017105263157895, hinge=6.016545512550755, ce=11.633769970944053
Local test acc @ epoch 2: 0.3017
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 1.3135548830032349
Local loss @ local epoch 1: 0.5298776030540466
Local loss @ local epoch 2: 0.7757880687713623
Local loss @ local epoch 3: 0.7150155901908875
Local loss @ local epoch 4: 0.5796963572502136
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.31 seconds!
[tester] 
AGNewsMetric: acc=0.6797368421052632, hinge=1.9917942097312527, ce=8.237049956070749
Local test acc @ epoch 2: 0.6797
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 1.2881873846054077
Local loss @ local epoch 1: 0.23260848224163055
Local loss @ local epoch 2: 0.3931386470794678
Local loss @ local epoch 3: 0.017098693177103996
Local loss @ local epoch 4: 0.18248699605464935
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.91 seconds!
[tester] 
AGNewsMetric: acc=0.25, hinge=9.359750195553428, ce=12.983139983729313
Local test acc @ epoch 2: 0.25
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.017659639939665794
Local loss @ local epoch 1: 0.0030913837254047394
Local loss @ local epoch 2: 0.01980644091963768
Local loss @ local epoch 3: 0.018183400854468346
Local loss @ local epoch 4: 0.0029204469174146652
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.7 seconds!
[tester] 
AGNewsMetric: acc=0.3567105263157895, hinge=6.794018322794061, ce=10.005666186684056
Local test acc @ epoch 2: 0.3567
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 1.0072864294052124
Local loss @ local epoch 1: 0.4391250014305115
Local loss @ local epoch 2: 0.49591997265815735
Local loss @ local epoch 3: 0.7562750577926636
Local loss @ local epoch 4: 0.18851737678050995
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.77 seconds!
[tester] 
AGNewsMetric: acc=0.7696052631578948, hinge=1.6332909814934982, ce=6.010823584104839
Local test acc @ epoch 2: 0.7696
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.826351523399353
Local loss @ local epoch 1: 0.30594369769096375
Local loss @ local epoch 2: 0.5424890518188477
Local loss @ local epoch 3: 0.4331100285053253
Local loss @ local epoch 4: 0.28243300318717957
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.97 seconds!
[tester] 
AGNewsMetric: acc=0.6063157894736843, hinge=2.500877927478991, ce=7.522012710571289
Local test acc @ epoch 2: 0.6063
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.12467405200004578
Local loss @ local epoch 1: 0.08613660931587219
Local loss @ local epoch 2: 0.08877277374267578
Local loss @ local epoch 3: 0.11398151516914368
Local loss @ local epoch 4: 0.03935413807630539
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.0 seconds!
[tester] 
AGNewsMetric: acc=0.7852631578947369, hinge=1.4754185044138055, ce=7.934442514118396
Local test acc @ epoch 2: 0.7853
Global evaluate on test data...
Evaluate data in 122.93 seconds!
[tester] 
AGNewsMetric: acc=0.8134210526315789, hinge=1.3581418388768247, ce=6.857572318629215
Global test acc @ epoch 2: 0.8134
Global epoch 3...
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 1.7429951429367065
Local loss @ local epoch 1: 0.723734438419342
Local loss @ local epoch 2: 1.1270145177841187
Local loss @ local epoch 3: 0.5837600827217102
Local loss @ local epoch 4: 0.7979013323783875
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.9 seconds!
[tester] 
AGNewsMetric: acc=0.39842105263157895, hinge=4.588276955453973, ce=14.229743487709447
Local test acc @ epoch 3: 0.3984
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.08697530627250671
Local loss @ local epoch 1: 0.7096011638641357
Local loss @ local epoch 2: 0.2304140329360962
Local loss @ local epoch 3: 0.15827250480651855
Local loss @ local epoch 4: 0.28102630376815796
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.51 seconds!
[tester] 
AGNewsMetric: acc=0.7926315789473685, hinge=1.5062643442655865, ce=7.368948625263415
Local test acc @ epoch 3: 0.7926
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.4622326195240021
Local loss @ local epoch 1: 0.2809438407421112
Local loss @ local epoch 2: 0.1997886747121811
Local loss @ local epoch 3: 0.09199131280183792
Local loss @ local epoch 4: 0.06409657746553421
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.24 seconds!
[tester] 
AGNewsMetric: acc=0.5696052631578947, hinge=2.5800053912714906, ce=8.448513775875695
Local test acc @ epoch 3: 0.5696
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 1.4496595859527588
Local loss @ local epoch 1: 1.1866995096206665
Local loss @ local epoch 2: 0.3158092200756073
Local loss @ local epoch 3: 0.10979151725769043
Local loss @ local epoch 4: 0.07990560680627823
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.02 seconds!
[tester] 
AGNewsMetric: acc=0.27223684210526317, hinge=5.8605978092394375, ce=9.555694845099199
Local test acc @ epoch 3: 0.2722
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.5221008062362671
Local loss @ local epoch 1: 0.44706588983535767
Local loss @ local epoch 2: 0.4287753999233246
Local loss @ local epoch 3: 0.3807065188884735
Local loss @ local epoch 4: 0.5993752479553223
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.95 seconds!
[tester] 
AGNewsMetric: acc=0.7072368421052632, hinge=1.9333517727098968, ce=7.271896519911917
Local test acc @ epoch 3: 0.7072
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.8576446175575256
Local loss @ local epoch 1: 0.5484310984611511
Local loss @ local epoch 2: 0.6034784913063049
Local loss @ local epoch 3: 1.3231405019760132
Local loss @ local epoch 4: 0.8517553806304932
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.09 seconds!
[tester] 
AGNewsMetric: acc=0.5780263157894737, hinge=2.818838281129536, ce=6.541899764412328
Local test acc @ epoch 3: 0.578
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.02905484475195408
Local loss @ local epoch 1: 0.0366501659154892
Local loss @ local epoch 2: 0.41153043508529663
Local loss @ local epoch 3: 0.5261780023574829
Local loss @ local epoch 4: 0.28235259652137756
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.74 seconds!
[tester] 
AGNewsMetric: acc=0.2501315789473684, hinge=10.828955188550447, ce=16.553656957525956
Local test acc @ epoch 3: 0.2501
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.6844369769096375
Local loss @ local epoch 1: 0.5794363021850586
Local loss @ local epoch 2: 0.41381171345710754
Local loss @ local epoch 3: 0.26247110962867737
Local loss @ local epoch 4: 0.21015363931655884
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.42 seconds!
[tester] 
AGNewsMetric: acc=0.44026315789473686, hinge=3.119153669758847, ce=11.3127597587987
Local test acc @ epoch 3: 0.4403
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.6216819286346436
Local loss @ local epoch 1: 0.13965195417404175
Local loss @ local epoch 2: 0.42302146553993225
Local loss @ local epoch 3: 0.9305493831634521
Local loss @ local epoch 4: 0.44006285071372986
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.96 seconds!
[tester] 
AGNewsMetric: acc=0.6607894736842105, hinge=2.4753124879535875, ce=7.320832274587531
Local test acc @ epoch 3: 0.6608
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 1.0324116945266724
Local loss @ local epoch 1: 0.5291692018508911
Local loss @ local epoch 2: 0.8312032222747803
Local loss @ local epoch 3: 0.3923934996128082
Local loss @ local epoch 4: 0.20628689229488373
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.03 seconds!
[tester] 
AGNewsMetric: acc=0.5756578947368421, hinge=3.342548824611463, ce=7.326877338007876
Local test acc @ epoch 3: 0.5757
Global evaluate on test data...
Evaluate data in 125.04 seconds!
[tester] 
AGNewsMetric: acc=0.8168421052631579, hinge=1.2623381268350702, ce=7.055458969316985
Global test acc @ epoch 3: 0.8168
Global epoch 4...
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.9377284049987793
Local loss @ local epoch 1: 1.1885302066802979
Local loss @ local epoch 2: 0.643033504486084
Local loss @ local epoch 3: 1.0601186752319336
Local loss @ local epoch 4: 0.7541022300720215
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.91 seconds!
[tester] 
AGNewsMetric: acc=0.7238157894736842, hinge=1.8334333615554006, ce=6.509339105706466
Local test acc @ epoch 4: 0.7238
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.41104984283447266
Local loss @ local epoch 1: 0.4305374324321747
Local loss @ local epoch 2: 0.40422263741493225
Local loss @ local epoch 3: 0.5929772257804871
Local loss @ local epoch 4: 0.578831136226654
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.71 seconds!
[tester] 
AGNewsMetric: acc=0.6380263157894737, hinge=3.2998508011667353, ce=8.745063179417661
Local test acc @ epoch 4: 0.638
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 1.362162470817566
Local loss @ local epoch 1: 0.07500007003545761
Local loss @ local epoch 2: 0.08081230521202087
Local loss @ local epoch 3: 0.04845655336976051
Local loss @ local epoch 4: 0.034677278250455856
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.42 seconds!
[tester] 
AGNewsMetric: acc=0.2521052631578947, hinge=8.079807673002545, ce=8.828763108504447
Local test acc @ epoch 4: 0.2521
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.7228207588195801
Local loss @ local epoch 1: 0.6748606562614441
Local loss @ local epoch 2: 0.480602890253067
Local loss @ local epoch 3: 0.28507333993911743
Local loss @ local epoch 4: 0.7899715900421143
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.37 seconds!
[tester] 
AGNewsMetric: acc=0.2830263157894737, hinge=7.198225668856972, ce=20.77510812056692
Local test acc @ epoch 4: 0.283
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 1.2599891424179077
Local loss @ local epoch 1: 0.5698256492614746
Local loss @ local epoch 2: 1.1218804121017456
Local loss @ local epoch 3: 0.9318658709526062
Local loss @ local epoch 4: 1.1278114318847656
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.43 seconds!
[tester] 
AGNewsMetric: acc=0.7728947368421053, hinge=1.5786924773768374, ce=8.205605165581954
Local test acc @ epoch 4: 0.7729
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.5091606974601746
Local loss @ local epoch 1: 0.3465319275856018
Local loss @ local epoch 2: 0.21894162893295288
Local loss @ local epoch 3: 0.38183408975601196
Local loss @ local epoch 4: 1.0207970142364502
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.74 seconds!
[tester] 
AGNewsMetric: acc=0.21368421052631578, hinge=6.491351705852308, ce=18.017893102545486
Local test acc @ epoch 4: 0.2137
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.11005005985498428
Local loss @ local epoch 1: 0.2341877520084381
Local loss @ local epoch 2: 0.15590673685073853
Local loss @ local epoch 3: 0.0229654423892498
Local loss @ local epoch 4: 0.16991403698921204
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.51 seconds!
[tester] 
AGNewsMetric: acc=0.7614473684210527, hinge=1.8515072330675626, ce=6.507557080921374
Local test acc @ epoch 4: 0.7614
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.13180336356163025
Local loss @ local epoch 1: 0.11322371661663055
Local loss @ local epoch 2: 0.051509156823158264
Local loss @ local epoch 3: 0.045003071427345276
Local loss @ local epoch 4: 0.06959640234708786
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.61 seconds!
[tester] 
AGNewsMetric: acc=0.7821052631578947, hinge=1.5019208360973157, ce=7.085399938884534
Local test acc @ epoch 4: 0.7821
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.6866098046302795
Local loss @ local epoch 1: 0.3959173858165741
Local loss @ local epoch 2: 0.22609065473079681
Local loss @ local epoch 3: 0.3382796347141266
Local loss @ local epoch 4: 0.28996074199676514
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.14 seconds!
[tester] 
AGNewsMetric: acc=0.5321052631578947, hinge=2.805444678256386, ce=11.540881550437526
Local test acc @ epoch 4: 0.5321
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 1.1038507223129272
Local loss @ local epoch 1: 0.15539978444576263
Local loss @ local epoch 2: 0.03183877840638161
Local loss @ local epoch 3: 0.031453028321266174
Local loss @ local epoch 4: 0.29303595423698425
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.62 seconds!
[tester] 
AGNewsMetric: acc=0.25092105263157893, hinge=6.777969215794614, ce=12.917815449363307
Local test acc @ epoch 4: 0.2509
Global evaluate on test data...
Evaluate data in 123.92 seconds!
[tester] 
AGNewsMetric: acc=0.8305263157894737, hinge=1.2806504621003802, ce=6.408367852662739
Global test acc @ epoch 4: 0.8305
Global epoch 5...
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.9237481951713562
Local loss @ local epoch 1: 0.22726839780807495
Local loss @ local epoch 2: 0.12355495244264603
Local loss @ local epoch 3: 0.004169397056102753
Local loss @ local epoch 4: 0.005290750879794359
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.92 seconds!
[tester] 
AGNewsMetric: acc=0.2507894736842105, hinge=8.326818007418984, ce=11.308641628466155
Local test acc @ epoch 5: 0.2508
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 1.1977434158325195
Local loss @ local epoch 1: 0.8527233004570007
Local loss @ local epoch 2: 0.49467533826828003
Local loss @ local epoch 3: 0.6961168646812439
Local loss @ local epoch 4: 0.689202070236206
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.45 seconds!
[tester] 
AGNewsMetric: acc=0.6560526315789473, hinge=1.9934562863801655, ce=7.020316927056563
Local test acc @ epoch 5: 0.6561
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 1.4032306671142578
Local loss @ local epoch 1: 0.5187398791313171
Local loss @ local epoch 2: 0.4506503641605377
Local loss @ local epoch 3: 0.4416390061378479
Local loss @ local epoch 4: 0.28335192799568176
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.08 seconds!
[tester] 
AGNewsMetric: acc=0.7456578947368421, hinge=1.6488142430154902, ce=8.581006050109863
Local test acc @ epoch 5: 0.7457
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.9711868762969971
Local loss @ local epoch 1: 0.4045354425907135
Local loss @ local epoch 2: 0.3945557773113251
Local loss @ local epoch 3: 0.3582773506641388
Local loss @ local epoch 4: 0.26817721128463745
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.92 seconds!
[tester] 
AGNewsMetric: acc=0.6480263157894737, hinge=2.160594230451082, ce=10.537718413503546
Local test acc @ epoch 5: 0.648
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.9022879600524902
Local loss @ local epoch 1: 0.6436707377433777
Local loss @ local epoch 2: 0.27559858560562134
Local loss @ local epoch 3: 0.45603427290916443
Local loss @ local epoch 4: 0.2745891511440277
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.49 seconds!
[tester] 
AGNewsMetric: acc=0.2501315789473684, hinge=7.310897285059879, ce=13.648631876895303
Local test acc @ epoch 5: 0.2501
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.03543580695986748
Local loss @ local epoch 1: 0.08369487524032593
Local loss @ local epoch 2: 1.137406587600708
Local loss @ local epoch 3: 0.0913202092051506
Local loss @ local epoch 4: 0.23956847190856934
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.07 seconds!
[tester] 
AGNewsMetric: acc=0.24907894736842107, hinge=8.720932415410092, ce=16.81851498654014
Local test acc @ epoch 5: 0.2491
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 1.543135166168213
Local loss @ local epoch 1: 0.407037615776062
Local loss @ local epoch 2: 0.210023894906044
Local loss @ local epoch 3: 0.8824664950370789
Local loss @ local epoch 4: 0.20782554149627686
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.14 seconds!
[tester] 
AGNewsMetric: acc=0.5810526315789474, hinge=2.4630439612739963, ce=6.332413040964227
Local test acc @ epoch 5: 0.5811
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.07036299258470535
Local loss @ local epoch 1: 0.13489244878292084
Local loss @ local epoch 2: 0.10304293036460876
Local loss @ local epoch 3: 0.12527194619178772
Local loss @ local epoch 4: 0.047668665647506714
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 125.02 seconds!
[tester] 
AGNewsMetric: acc=0.7852631578947369, hinge=1.5770763166327226, ce=6.1788499340258145
Local test acc @ epoch 5: 0.7853
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.6759119629859924
Local loss @ local epoch 1: 0.6613098978996277
Local loss @ local epoch 2: 0.6472316980361938
Local loss @ local epoch 3: 0.41394516825675964
Local loss @ local epoch 4: 0.5702311396598816
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.29 seconds!
[tester] 
AGNewsMetric: acc=0.25434210526315787, hinge=7.853871369612844, ce=11.484100779483192
Local test acc @ epoch 5: 0.2543
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.9246017336845398
Local loss @ local epoch 1: 0.6106763482093811
Local loss @ local epoch 2: 0.299373060464859
Local loss @ local epoch 3: 0.30404821038246155
Local loss @ local epoch 4: 0.551699161529541
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.37 seconds!
[tester] 
AGNewsMetric: acc=0.7497368421052631, hinge=1.5565599130329333, ce=5.946812712016858
Local test acc @ epoch 5: 0.7497
Global evaluate on test data...
Evaluate data in 124.84 seconds!
[tester] 
AGNewsMetric: acc=0.81, hinge=1.2750062430532354, ce=7.549832233629728
Global test acc @ epoch 5: 0.81
Global epoch 6...
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 1.1517425775527954
Local loss @ local epoch 1: 0.7111214995384216
Local loss @ local epoch 2: 0.4217499792575836
Local loss @ local epoch 3: 0.9814982414245605
Local loss @ local epoch 4: 0.8680536150932312
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 125.23 seconds!
[tester] 
AGNewsMetric: acc=0.2505263157894737, hinge=9.047456259978444, ce=12.31216122476678
Local test acc @ epoch 6: 0.2505
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.5722221732139587
Local loss @ local epoch 1: 0.5550118684768677
Local loss @ local epoch 2: 0.5400854349136353
Local loss @ local epoch 3: 0.31252357363700867
Local loss @ local epoch 4: 0.3453328311443329
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 125.06 seconds!
[tester] 
AGNewsMetric: acc=0.7482894736842105, hinge=1.6975181569551168, ce=5.4611227587649696
Local test acc @ epoch 6: 0.7483
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.8227260708808899
Local loss @ local epoch 1: 0.4778255522251129
Local loss @ local epoch 2: 0.14805880188941956
Local loss @ local epoch 3: 0.550105631351471
Local loss @ local epoch 4: 0.21653419733047485
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.67 seconds!
[tester] 
AGNewsMetric: acc=0.4994736842105263, hinge=3.7060306313163354, ce=7.49862094176443
Local test acc @ epoch 6: 0.4995
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.46267712116241455
Local loss @ local epoch 1: 0.3301559388637543
Local loss @ local epoch 2: 0.051942113786935806
Local loss @ local epoch 3: 0.1375497579574585
Local loss @ local epoch 4: 0.07196976989507675
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.31 seconds!
[tester] 
AGNewsMetric: acc=0.3713157894736842, hinge=3.968385181427002, ce=6.874950180053711
Local test acc @ epoch 6: 0.3713
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.46296554803848267
Local loss @ local epoch 1: 0.27386969327926636
Local loss @ local epoch 2: 0.18829604983329773
Local loss @ local epoch 3: 0.09311587363481522
Local loss @ local epoch 4: 0.06716874241828918
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.55 seconds!
[tester] 
AGNewsMetric: acc=0.42907894736842106, hinge=3.5431548193881386, ce=9.272604986491956
Local test acc @ epoch 6: 0.4291
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 1.8099526166915894
Local loss @ local epoch 1: 0.1953352987766266
Local loss @ local epoch 2: 0.02389494702219963
Local loss @ local epoch 3: 0.02964303456246853
Local loss @ local epoch 4: 0.025492321699857712
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.44 seconds!
[tester] 
AGNewsMetric: acc=0.2506578947368421, hinge=7.743177351700632, ce=10.057051638553016
Local test acc @ epoch 6: 0.2507
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 1.5573402643203735
Local loss @ local epoch 1: 0.5909714102745056
Local loss @ local epoch 2: 1.1966263055801392
Local loss @ local epoch 3: 1.0014570951461792
Local loss @ local epoch 4: 0.8367125988006592
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.9 seconds!
[tester] 
AGNewsMetric: acc=0.5547368421052632, hinge=2.7662042647913885, ce=8.903447448328922
Local test acc @ epoch 6: 0.5547
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.10186445713043213
Local loss @ local epoch 1: 0.07132616639137268
Local loss @ local epoch 2: 0.03676150366663933
Local loss @ local epoch 3: 0.07512838393449783
Local loss @ local epoch 4: 0.12223180383443832
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.69 seconds!
[tester] 
AGNewsMetric: acc=0.7567105263157895, hinge=1.7595767578325774, ce=7.909719275424355
Local test acc @ epoch 6: 0.7567
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.621208131313324
Local loss @ local epoch 1: 0.32232561707496643
Local loss @ local epoch 2: 0.23646245896816254
Local loss @ local epoch 3: 0.1057019904255867
Local loss @ local epoch 4: 0.1263027787208557
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.97 seconds!
[tester] 
AGNewsMetric: acc=0.3101315789473684, hinge=4.093975492276644, ce=9.931175057260614
Local test acc @ epoch 6: 0.3101
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.07755663245916367
Local loss @ local epoch 1: 0.05134378746151924
Local loss @ local epoch 2: 0.021239090710878372
Local loss @ local epoch 3: 0.0044003259390592575
Local loss @ local epoch 4: 0.024287989363074303
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.09 seconds!
[tester] 
AGNewsMetric: acc=0.7332894736842105, hinge=1.9887501606188323, ce=6.458508784645482
Local test acc @ epoch 6: 0.7333
Global evaluate on test data...
Evaluate data in 123.85 seconds!
[tester] 
AGNewsMetric: acc=0.8288157894736842, hinge=1.0978192213961953, ce=6.701100258074309
Global test acc @ epoch 6: 0.8288
Global epoch 7...
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.6880553364753723
Local loss @ local epoch 1: 0.05049729719758034
Local loss @ local epoch 2: 0.02896513231098652
Local loss @ local epoch 3: 0.07085614651441574
Local loss @ local epoch 4: 0.015731286257505417
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.14 seconds!
[tester] 
AGNewsMetric: acc=0.25, hinge=11.212393466547915, ce=15.356165936118678
Local test acc @ epoch 7: 0.25
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.30172622203826904
Local loss @ local epoch 1: 0.10303319245576859
Local loss @ local epoch 2: 0.01429034024477005
Local loss @ local epoch 3: 0.017650891095399857
Local loss @ local epoch 4: 0.046324387192726135
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.5 seconds!
[tester] 
AGNewsMetric: acc=0.7577631578947368, hinge=1.5463240462855288, ce=4.76586915367528
Local test acc @ epoch 7: 0.7578
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.7751869559288025
Local loss @ local epoch 1: 0.2998237609863281
Local loss @ local epoch 2: 0.21062716841697693
Local loss @ local epoch 3: 0.13576263189315796
Local loss @ local epoch 4: 0.0908326804637909
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.92 seconds!
[tester] 
AGNewsMetric: acc=0.4561842105263158, hinge=3.4077805313311127, ce=10.421630598369397
Local test acc @ epoch 7: 0.4562
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.07971478253602982
Local loss @ local epoch 1: 0.040263254195451736
Local loss @ local epoch 2: 0.07884789258241653
Local loss @ local epoch 3: 0.027839666232466698
Local loss @ local epoch 4: 0.031997207552194595
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.77 seconds!
[tester] 
AGNewsMetric: acc=0.7580263157894737, hinge=1.591125024494372, ce=8.770081104479338
Local test acc @ epoch 7: 0.758
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.6084614396095276
Local loss @ local epoch 1: 0.6386631727218628
Local loss @ local epoch 2: 0.5083931088447571
Local loss @ local epoch 3: 0.5798754692077637
Local loss @ local epoch 4: 0.32574278116226196
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.1 seconds!
[tester] 
AGNewsMetric: acc=0.7969736842105263, hinge=1.2857669328388415, ce=5.160014560097142
Local test acc @ epoch 7: 0.797
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.2761366665363312
Local loss @ local epoch 1: 0.3374691903591156
Local loss @ local epoch 2: 0.3288331627845764
Local loss @ local epoch 3: 0.7018600702285767
Local loss @ local epoch 4: 0.28760528564453125
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.43 seconds!
[tester] 
AGNewsMetric: acc=0.6794736842105263, hinge=2.4414419374967875, ce=7.181551874060379
Local test acc @ epoch 7: 0.6795
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.6713060736656189
Local loss @ local epoch 1: 0.26745468378067017
Local loss @ local epoch 2: 0.4007449448108673
Local loss @ local epoch 3: 0.1552048772573471
Local loss @ local epoch 4: 0.6873707175254822
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.22 seconds!
[tester] 
AGNewsMetric: acc=0.5560526315789474, hinge=3.4549547245627954, ce=5.925094643643028
Local test acc @ epoch 7: 0.5561
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 1.1720689535140991
Local loss @ local epoch 1: 0.5766769647598267
Local loss @ local epoch 2: 0.5710727572441101
Local loss @ local epoch 3: 0.9943323731422424
Local loss @ local epoch 4: 0.6207354068756104
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.83 seconds!
[tester] 
AGNewsMetric: acc=0.6805263157894736, hinge=1.8879347264139277, ce=10.243208110207005
Local test acc @ epoch 7: 0.6805
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.026978904381394386
Local loss @ local epoch 1: 0.030869444832205772
Local loss @ local epoch 2: 0.029565712437033653
Local loss @ local epoch 3: 0.0706389769911766
Local loss @ local epoch 4: 0.010690974071621895
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.07 seconds!
[tester] 
AGNewsMetric: acc=0.7855263157894737, hinge=1.6550907923045912, ce=4.593521330984015
Local test acc @ epoch 7: 0.7855
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.5377906560897827
Local loss @ local epoch 1: 0.42657187581062317
Local loss @ local epoch 2: 0.19089558720588684
Local loss @ local epoch 3: 0.18778015673160553
Local loss @ local epoch 4: 0.18614625930786133
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.97 seconds!
[tester] 
AGNewsMetric: acc=0.6576315789473685, hinge=2.1511115917406585, ce=8.08731686843069
Local test acc @ epoch 7: 0.6576
Global evaluate on test data...
Evaluate data in 123.22 seconds!
[tester] 
AGNewsMetric: acc=0.8421052631578947, hinge=1.1092848541862086, ce=6.032630716625013
Global test acc @ epoch 7: 0.8421
Global epoch 8...
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.7462531924247742
Local loss @ local epoch 1: 0.24927154183387756
Local loss @ local epoch 2: 0.1921975165605545
Local loss @ local epoch 3: 0.9441640973091125
Local loss @ local epoch 4: 0.18051181733608246
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 125.2 seconds!
[tester] 
AGNewsMetric: acc=0.7005263157894737, hinge=1.7789057576028924, ce=10.000408943577817
Local test acc @ epoch 8: 0.7005
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.02290273830294609
Local loss @ local epoch 1: 0.049387700855731964
Local loss @ local epoch 2: 0.663702130317688
Local loss @ local epoch 3: 0.030746906995773315
Local loss @ local epoch 4: 0.029557043686509132
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.7 seconds!
[tester] 
AGNewsMetric: acc=0.8180263157894737, hinge=1.3821906283027248, ce=5.588707332611084
Local test acc @ epoch 8: 0.818
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.5769966840744019
Local loss @ local epoch 1: 0.470731258392334
Local loss @ local epoch 2: 0.3194997012615204
Local loss @ local epoch 3: 0.18213725090026855
Local loss @ local epoch 4: 0.27628085017204285
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.21 seconds!
[tester] 
AGNewsMetric: acc=0.5971052631578947, hinge=3.400573205947876, ce=8.619757451509175
Local test acc @ epoch 8: 0.5971
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 1.28452730178833
Local loss @ local epoch 1: 1.2486450672149658
Local loss @ local epoch 2: 0.6100229620933533
Local loss @ local epoch 3: 1.057093858718872
Local loss @ local epoch 4: 1.1830846071243286
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.83 seconds!
[tester] 
AGNewsMetric: acc=0.2468421052631579, hinge=6.939715677562513, ce=17.351606967323704
Local test acc @ epoch 8: 0.2468
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.9768818020820618
Local loss @ local epoch 1: 0.42487087845802307
Local loss @ local epoch 2: 0.23251575231552124
Local loss @ local epoch 3: 0.1493523120880127
Local loss @ local epoch 4: 0.06664634495973587
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.88 seconds!
[tester] 
AGNewsMetric: acc=0.2855263157894737, hinge=5.445092382932964, ce=10.79517548008969
Local test acc @ epoch 8: 0.2855
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.08819425106048584
Local loss @ local epoch 1: 0.06832814961671829
Local loss @ local epoch 2: 0.16665184497833252
Local loss @ local epoch 3: 0.028385791927576065
Local loss @ local epoch 4: 0.27539464831352234
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.77 seconds!
[tester] 
AGNewsMetric: acc=0.8098684210526316, hinge=1.3039647373400236, ce=7.97185727671573
Local test acc @ epoch 8: 0.8099
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.6896702647209167
Local loss @ local epoch 1: 0.21534274518489838
Local loss @ local epoch 2: 0.14418275654315948
Local loss @ local epoch 3: 0.8266861438751221
Local loss @ local epoch 4: 0.8841156363487244
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.78 seconds!
[tester] 
AGNewsMetric: acc=0.3794736842105263, hinge=4.725556844410144, ce=12.372964429353413
Local test acc @ epoch 8: 0.3795
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 1.1206024885177612
Local loss @ local epoch 1: 0.2823621332645416
Local loss @ local epoch 2: 0.013747348450124264
Local loss @ local epoch 3: 0.0028207399882376194
Local loss @ local epoch 4: 0.01043721940368414
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.95 seconds!
[tester] 
AGNewsMetric: acc=0.25, hinge=10.293716572209409, ce=10.852845370644017
Local test acc @ epoch 8: 0.25
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.2476334571838379
Local loss @ local epoch 1: 0.016136208549141884
Local loss @ local epoch 2: 0.005951965693384409
Local loss @ local epoch 3: 0.07297413051128387
Local loss @ local epoch 4: 0.03924128785729408
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.83 seconds!
[tester] 
AGNewsMetric: acc=0.6703947368421053, hinge=1.966052142193443, ce=5.525481475026984
Local test acc @ epoch 8: 0.6704
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.7352154850959778
Local loss @ local epoch 1: 0.3737209141254425
Local loss @ local epoch 2: 0.2734203040599823
Local loss @ local epoch 3: 0.2149193286895752
Local loss @ local epoch 4: 0.15830965340137482
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.84 seconds!
[tester] 
AGNewsMetric: acc=0.6957894736842105, hinge=1.7388902438314338, ce=5.0109771768670335
Local test acc @ epoch 8: 0.6958
Global evaluate on test data...
Evaluate data in 124.06 seconds!
[tester] 
AGNewsMetric: acc=0.8339473684210527, hinge=1.064102688839561, ce=6.96996200762297
Global test acc @ epoch 8: 0.8339
Global epoch 9...
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.31433287262916565
Local loss @ local epoch 1: 0.08265326172113419
Local loss @ local epoch 2: 0.06162116304039955
Local loss @ local epoch 3: 0.046712726354599
Local loss @ local epoch 4: 0.13183824717998505
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.77 seconds!
[tester] 
AGNewsMetric: acc=0.7780263157894737, hinge=1.5102540382586027, ce=8.24889000742059
Local test acc @ epoch 9: 0.778
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.14763079583644867
Local loss @ local epoch 1: 0.06174863502383232
Local loss @ local epoch 2: 0.14434994757175446
Local loss @ local epoch 3: 0.12113921344280243
Local loss @ local epoch 4: 0.05065591260790825
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.45 seconds!
[tester] 
AGNewsMetric: acc=0.7063157894736842, hinge=2.016942579369796, ce=5.355728195591976
Local test acc @ epoch 9: 0.7063
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.4924912452697754
Local loss @ local epoch 1: 0.21984417736530304
Local loss @ local epoch 2: 0.33833667635917664
Local loss @ local epoch 3: 0.28876248002052307
Local loss @ local epoch 4: 0.11459342390298843
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.38 seconds!
[tester] 
AGNewsMetric: acc=0.6639473684210526, hinge=2.057265278163709, ce=7.361052015204178
Local test acc @ epoch 9: 0.6639
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 1.0751274824142456
Local loss @ local epoch 1: 0.8465756773948669
Local loss @ local epoch 2: 0.7481563687324524
Local loss @ local epoch 3: 1.0848989486694336
Local loss @ local epoch 4: 1.147695779800415
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.48 seconds!
[tester] 
AGNewsMetric: acc=0.4913157894736842, hinge=3.859077000367014, ce=8.878255308050859
Local test acc @ epoch 9: 0.4913
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.28618812561035156
Local loss @ local epoch 1: 0.7117875218391418
Local loss @ local epoch 2: 0.18634355068206787
Local loss @ local epoch 3: 0.13812333345413208
Local loss @ local epoch 4: 0.14120161533355713
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.27 seconds!
[tester] 
AGNewsMetric: acc=0.7939473684210526, hinge=1.3368520877235814, ce=5.705829988780774
Local test acc @ epoch 9: 0.7939
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.6212832927703857
Local loss @ local epoch 1: 0.08546177297830582
Local loss @ local epoch 2: 0.04986250400543213
Local loss @ local epoch 3: 0.05635257065296173
Local loss @ local epoch 4: 0.11909651756286621
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.15 seconds!
[tester] 
AGNewsMetric: acc=0.3960526315789474, hinge=3.588687767731516, ce=6.282136072861521
Local test acc @ epoch 9: 0.3961
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.7419013977050781
Local loss @ local epoch 1: 0.00838384684175253
Local loss @ local epoch 2: 0.006038899999111891
Local loss @ local epoch 3: 0.008843766525387764
Local loss @ local epoch 4: 0.005383588839322329
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.38 seconds!
[tester] 
AGNewsMetric: acc=0.25, hinge=11.196791169015984, ce=14.90368637084961
Local test acc @ epoch 9: 0.25
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.5777628421783447
Local loss @ local epoch 1: 0.31093737483024597
Local loss @ local epoch 2: 0.1640547811985016
Local loss @ local epoch 3: 0.24347084760665894
Local loss @ local epoch 4: 0.04601628705859184
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.7 seconds!
[tester] 
AGNewsMetric: acc=0.28342105263157896, hinge=4.743166040621306, ce=8.378915996551514
Local test acc @ epoch 9: 0.2834
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.8610263466835022
Local loss @ local epoch 1: 0.5990937948226929
Local loss @ local epoch 2: 0.4263443350791931
Local loss @ local epoch 3: 0.17713062465190887
Local loss @ local epoch 4: 0.29740145802497864
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 122.95 seconds!
[tester] 
AGNewsMetric: acc=0.6621052631578948, hinge=2.7516692061173287, ce=3.9474243711170396
Local test acc @ epoch 9: 0.6621
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.7222930788993835
Local loss @ local epoch 1: 0.04474012926220894
Local loss @ local epoch 2: 0.3672407567501068
Local loss @ local epoch 3: 0.628818690776825
Local loss @ local epoch 4: 0.2351469248533249
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.42 seconds!
[tester] 
AGNewsMetric: acc=0.7222368421052632, hinge=1.7920160188172993, ce=6.051666655289499
Local test acc @ epoch 9: 0.7222
Global evaluate on test data...
Evaluate data in 124.12 seconds!
[tester] 
AGNewsMetric: acc=0.8196052631578947, hinge=1.3573922327945107, ce=4.360990219116211
Global test acc @ epoch 9: 0.8196
Global epoch 10...
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.06921666860580444
Local loss @ local epoch 1: 0.010281035676598549
Local loss @ local epoch 2: 0.02411845698952675
Local loss @ local epoch 3: 0.011930810287594795
Local loss @ local epoch 4: 0.029882490634918213
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.41 seconds!
[tester] 
AGNewsMetric: acc=0.5603947368421053, hinge=3.0561558096032395, ce=6.3695017894945645
Local test acc @ epoch 10: 0.5604
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 1.162606954574585
Local loss @ local epoch 1: 0.6543734073638916
Local loss @ local epoch 2: 0.9699201583862305
Local loss @ local epoch 3: 0.9558703899383545
Local loss @ local epoch 4: 0.731742799282074
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 125.06 seconds!
[tester] 
AGNewsMetric: acc=0.2501315789473684, hinge=6.811364572424638, ce=13.733089360688862
Local test acc @ epoch 10: 0.2501
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.2096400409936905
Local loss @ local epoch 1: 0.41573673486709595
Local loss @ local epoch 2: 0.30872970819473267
Local loss @ local epoch 3: 0.15579533576965332
Local loss @ local epoch 4: 0.2940600514411926
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 125.25 seconds!
[tester] 
AGNewsMetric: acc=0.6228947368421053, hinge=2.5068283296886245, ce=8.246955250187924
Local test acc @ epoch 10: 0.6229
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.6858857274055481
Local loss @ local epoch 1: 0.23877626657485962
Local loss @ local epoch 2: 0.23868463933467865
Local loss @ local epoch 3: 0.4575059413909912
Local loss @ local epoch 4: 0.042256828397512436
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.04 seconds!
[tester] 
AGNewsMetric: acc=0.8003947368421053, hinge=1.2247189546886244, ce=11.640155876561215
Local test acc @ epoch 10: 0.8004
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.047179434448480606
Local loss @ local epoch 1: 0.04458604007959366
Local loss @ local epoch 2: 0.03151818364858627
Local loss @ local epoch 3: 0.04792376607656479
Local loss @ local epoch 4: 0.011796059086918831
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.76 seconds!
[tester] 
AGNewsMetric: acc=0.8025, hinge=1.4259894496516177, ce=7.696999040904798
Local test acc @ epoch 10: 0.8025
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.844749927520752
Local loss @ local epoch 1: 0.27419313788414
Local loss @ local epoch 2: 0.14848802983760834
Local loss @ local epoch 3: 0.2208598405122757
Local loss @ local epoch 4: 0.24788756668567657
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.35 seconds!
[tester] 
AGNewsMetric: acc=0.6771052631578948, hinge=1.9222969035098427, ce=6.668324280789024
Local test acc @ epoch 10: 0.6771
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 1.1490384340286255
Local loss @ local epoch 1: 0.10965491086244583
Local loss @ local epoch 2: 0.039053503423929214
Local loss @ local epoch 3: 0.005951016675680876
Local loss @ local epoch 4: 0.00864341575652361
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.38 seconds!
[tester] 
AGNewsMetric: acc=0.2880263157894737, hinge=6.085191251855147, ce=9.004173288847271
Local test acc @ epoch 10: 0.288
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.1370044946670532
Local loss @ local epoch 1: 0.29527369141578674
Local loss @ local epoch 2: 0.22372135519981384
Local loss @ local epoch 3: 0.17774464190006256
Local loss @ local epoch 4: 0.11082696169614792
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.23 seconds!
[tester] 
AGNewsMetric: acc=0.4747368421052632, hinge=3.2212610520814593, ce=7.82146337609542
Local test acc @ epoch 10: 0.4747
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 1.526661992073059
Local loss @ local epoch 1: 0.2251032292842865
Local loss @ local epoch 2: 0.22235523164272308
Local loss @ local epoch 3: 0.12757351994514465
Local loss @ local epoch 4: 0.17553775012493134
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.58 seconds!
[tester] 
AGNewsMetric: acc=0.5385526315789474, hinge=2.8652323225924845, ce=9.032905940005653
Local test acc @ epoch 10: 0.5386
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.3159952163696289
Local loss @ local epoch 1: 0.036327991634607315
Local loss @ local epoch 2: 0.04371199384331703
Local loss @ local epoch 3: 0.01229335367679596
Local loss @ local epoch 4: 0.012272459454834461
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.43 seconds!
[tester] 
AGNewsMetric: acc=0.6314473684210526, hinge=2.4687665869060313, ce=5.7293302676552225
Local test acc @ epoch 10: 0.6314
Global evaluate on test data...
Evaluate data in 123.17 seconds!
[tester] 
AGNewsMetric: acc=0.8011842105263158, hinge=1.21217486933658, ce=6.078794615896125
Global test acc @ epoch 10: 0.8012
Global epoch 11...
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.9352301359176636
Local loss @ local epoch 1: 0.1484297215938568
Local loss @ local epoch 2: 0.41413673758506775
Local loss @ local epoch 3: 0.049624551087617874
Local loss @ local epoch 4: 0.2973944842815399
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.14 seconds!
[tester] 
AGNewsMetric: acc=0.7825, hinge=1.6465992465772128, ce=4.435430162329423
Local test acc @ epoch 11: 0.7825
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 1.3017703294754028
Local loss @ local epoch 1: 0.24540317058563232
Local loss @ local epoch 2: 0.15840400755405426
Local loss @ local epoch 3: 0.3253605365753174
Local loss @ local epoch 4: 0.09862958639860153
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.35 seconds!
[tester] 
AGNewsMetric: acc=0.3080263157894737, hinge=5.599525460193032, ce=8.199310246517785
Local test acc @ epoch 11: 0.308
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.19393087923526764
Local loss @ local epoch 1: 0.04762427881360054
Local loss @ local epoch 2: 0.03634803742170334
Local loss @ local epoch 3: 0.17183540761470795
Local loss @ local epoch 4: 0.07121316343545914
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.19 seconds!
[tester] 
AGNewsMetric: acc=0.7839473684210526, hinge=1.4771109786786532, ce=4.405384591755114
Local test acc @ epoch 11: 0.7839
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.02400054782629013
Local loss @ local epoch 1: 0.0156717412173748
Local loss @ local epoch 2: 0.0029099690727889538
Local loss @ local epoch 3: 0.00234552682377398
Local loss @ local epoch 4: 0.005386984907090664
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.99 seconds!
[tester] 
AGNewsMetric: acc=0.771578947368421, hinge=1.8491119123760023, ce=4.669170352534244
Local test acc @ epoch 11: 0.7716
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.36478352546691895
Local loss @ local epoch 1: 0.10044806450605392
Local loss @ local epoch 2: 0.2675604522228241
Local loss @ local epoch 3: 0.6168317198753357
Local loss @ local epoch 4: 0.08147726207971573
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.15 seconds!
[tester] 
AGNewsMetric: acc=0.2901315789473684, hinge=6.625893989362215, ce=10.821849963539526
Local test acc @ epoch 11: 0.2901
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.5705872774124146
Local loss @ local epoch 1: 0.1036306694149971
Local loss @ local epoch 2: 0.036502737551927567
Local loss @ local epoch 3: 0.1455995887517929
Local loss @ local epoch 4: 0.09162159264087677
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.87 seconds!
[tester] 
AGNewsMetric: acc=0.5798684210526316, hinge=2.5757436621816536, ce=7.4454101903815015
Local test acc @ epoch 11: 0.5799
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 1.477124810218811
Local loss @ local epoch 1: 0.05998825654387474
Local loss @ local epoch 2: 0.0038268184289336205
Local loss @ local epoch 3: 0.008505712263286114
Local loss @ local epoch 4: 0.005195846781134605
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.91 seconds!
[tester] 
AGNewsMetric: acc=0.48973684210526314, hinge=5.787643242886192, ce=8.884214678312603
Local test acc @ epoch 11: 0.4897
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.6639295220375061
Local loss @ local epoch 1: 0.20535187423229218
Local loss @ local epoch 2: 0.15904869139194489
Local loss @ local epoch 3: 0.2364107221364975
Local loss @ local epoch 4: 0.3437308967113495
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.75 seconds!
[tester] 
AGNewsMetric: acc=0.4293421052631579, hinge=4.808567104841534, ce=9.602855722527755
Local test acc @ epoch 11: 0.4293
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 1.3120806217193604
Local loss @ local epoch 1: 0.6307084560394287
Local loss @ local epoch 2: 0.5722101926803589
Local loss @ local epoch 3: 0.9562114477157593
Local loss @ local epoch 4: 0.783511757850647
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.08 seconds!
[tester] 
AGNewsMetric: acc=0.5896052631578947, hinge=2.8481537919295463, ce=9.954330436304996
Local test acc @ epoch 11: 0.5896
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 1.326699137687683
Local loss @ local epoch 1: 0.1620555967092514
Local loss @ local epoch 2: 0.031165631487965584
Local loss @ local epoch 3: 0.011980495415627956
Local loss @ local epoch 4: 0.008897206746041775
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.81 seconds!
[tester] 
AGNewsMetric: acc=0.2567105263157895, hinge=7.319868624837775, ce=11.041107057270251
Local test acc @ epoch 11: 0.2567
Global evaluate on test data...
Evaluate data in 124.72 seconds!
[tester] 
AGNewsMetric: acc=0.819078947368421, hinge=1.3928401239294754, ce=5.0087189232675655
Global test acc @ epoch 11: 0.8191
Global epoch 12...
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.6123006343841553
Local loss @ local epoch 1: 0.8021591901779175
Local loss @ local epoch 2: 0.49709826707839966
Local loss @ local epoch 3: 0.5909910798072815
Local loss @ local epoch 4: 0.4292982816696167
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.79 seconds!
[tester] 
AGNewsMetric: acc=0.7468421052631579, hinge=1.5856697604530736, ce=7.945004255395187
Local test acc @ epoch 12: 0.7468
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.2510131299495697
Local loss @ local epoch 1: 0.16444158554077148
Local loss @ local epoch 2: 0.1162409782409668
Local loss @ local epoch 3: 0.1420956403017044
Local loss @ local epoch 4: 0.35158583521842957
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.05 seconds!
[tester] 
AGNewsMetric: acc=0.6390789473684211, hinge=2.0925044461300497, ce=6.008525663677015
Local test acc @ epoch 12: 0.6391
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.6713865399360657
Local loss @ local epoch 1: 0.047419045120477676
Local loss @ local epoch 2: 0.02282092161476612
Local loss @ local epoch 3: 0.00921619962900877
Local loss @ local epoch 4: 0.053090840578079224
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.73 seconds!
[tester] 
AGNewsMetric: acc=0.718421052631579, hinge=1.9473583005603992, ce=5.276151416176244
Local test acc @ epoch 12: 0.7184
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.3681061565876007
Local loss @ local epoch 1: 1.0172266960144043
Local loss @ local epoch 2: 0.5517951250076294
Local loss @ local epoch 3: 0.47705385088920593
Local loss @ local epoch 4: 0.201217919588089
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.75 seconds!
[tester] 
AGNewsMetric: acc=0.7375, hinge=1.735954743937442, ce=4.792330056240684
Local test acc @ epoch 12: 0.7375
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.09447652101516724
Local loss @ local epoch 1: 0.03660091012716293
Local loss @ local epoch 2: 0.043873380869627
Local loss @ local epoch 3: 0.05016312003135681
Local loss @ local epoch 4: 0.019841093569993973
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.76 seconds!
[tester] 
AGNewsMetric: acc=0.7884210526315789, hinge=1.391311516008879, ce=6.944696448476691
Local test acc @ epoch 12: 0.7884
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 1.5772340297698975
Local loss @ local epoch 1: 0.44934362173080444
Local loss @ local epoch 2: 0.22369752824306488
Local loss @ local epoch 3: 0.2252500206232071
Local loss @ local epoch 4: 0.12149539589881897
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.89 seconds!
[tester] 
AGNewsMetric: acc=0.4478947368421053, hinge=3.6124525446640816, ce=7.832856824774491
Local test acc @ epoch 12: 0.4479
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.013500074855983257
Local loss @ local epoch 1: 0.00969306193292141
Local loss @ local epoch 2: 0.0009362427517771721
Local loss @ local epoch 3: 0.04760534688830376
Local loss @ local epoch 4: 0.12791503965854645
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.02 seconds!
[tester] 
AGNewsMetric: acc=0.7938157894736843, hinge=1.5681943607330322, ce=6.376154738978336
Local test acc @ epoch 12: 0.7938
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.978041410446167
Local loss @ local epoch 1: 1.2305569648742676
Local loss @ local epoch 2: 0.6921110153198242
Local loss @ local epoch 3: 0.8005985617637634
Local loss @ local epoch 4: 0.6894311904907227
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.31 seconds!
[tester] 
AGNewsMetric: acc=0.7475, hinge=1.4855569713994077, ce=5.992242415578742
Local test acc @ epoch 12: 0.7475
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.5516571402549744
Local loss @ local epoch 1: 0.260296493768692
Local loss @ local epoch 2: 0.2619210481643677
Local loss @ local epoch 3: 0.20399720966815948
Local loss @ local epoch 4: 0.2464590072631836
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.65 seconds!
[tester] 
AGNewsMetric: acc=0.4610526315789474, hinge=3.6187922768843803, ce=6.637982574262117
Local test acc @ epoch 12: 0.4611
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.47140347957611084
Local loss @ local epoch 1: 0.04376622661948204
Local loss @ local epoch 2: 0.002672760281711817
Local loss @ local epoch 3: 0.0004130438610445708
Local loss @ local epoch 4: 0.0003347549354657531
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.49 seconds!
[tester] 
AGNewsMetric: acc=0.2506578947368421, hinge=10.973608089246248, ce=11.314176226164165
Local test acc @ epoch 12: 0.2507
Global evaluate on test data...
Evaluate data in 123.64 seconds!
[tester] 
AGNewsMetric: acc=0.8447368421052631, hinge=0.9910063191464072, ce=6.208373680114746
Global test acc @ epoch 12: 0.8447
Global epoch 13...
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.6274265646934509
Local loss @ local epoch 1: 0.4516398310661316
Local loss @ local epoch 2: 0.4723667502403259
Local loss @ local epoch 3: 0.31199657917022705
Local loss @ local epoch 4: 0.3150635063648224
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.5 seconds!
[tester] 
AGNewsMetric: acc=0.7277631578947369, hinge=1.7255935458133096, ce=8.135513863814504
Local test acc @ epoch 13: 0.7278
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.027729468420147896
Local loss @ local epoch 1: 0.02408428303897381
Local loss @ local epoch 2: 0.02419693022966385
Local loss @ local epoch 3: 0.015339598059654236
Local loss @ local epoch 4: 0.028493698686361313
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.36 seconds!
[tester] 
AGNewsMetric: acc=0.8038157894736843, hinge=1.2423915516702753, ce=8.83107232746325
Local test acc @ epoch 13: 0.8038
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.2762303948402405
Local loss @ local epoch 1: 0.7052469253540039
Local loss @ local epoch 2: 0.18679876625537872
Local loss @ local epoch 3: 0.32060670852661133
Local loss @ local epoch 4: 0.10408915579319
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.08 seconds!
[tester] 
AGNewsMetric: acc=0.775, hinge=1.4866796767084223, ce=5.218088650954397
Local test acc @ epoch 13: 0.775
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 1.390770435333252
Local loss @ local epoch 1: 0.590559184551239
Local loss @ local epoch 2: 0.537588894367218
Local loss @ local epoch 3: 0.7282434701919556
Local loss @ local epoch 4: 0.3999919891357422
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.05 seconds!
[tester] 
AGNewsMetric: acc=0.5715789473684211, hinge=2.2638070683730276, ce=6.6878338813781735
Local test acc @ epoch 13: 0.5716
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.2627018690109253
Local loss @ local epoch 1: 0.013504418544471264
Local loss @ local epoch 2: 0.012700884602963924
Local loss @ local epoch 3: 0.015481007285416126
Local loss @ local epoch 4: 0.09563948959112167
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.46 seconds!
[tester] 
AGNewsMetric: acc=0.4205263157894737, hinge=5.07556872116892, ce=4.423468296653346
Local test acc @ epoch 13: 0.4205
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.3307134807109833
Local loss @ local epoch 1: 0.3204145133495331
Local loss @ local epoch 2: 0.15560422837734222
Local loss @ local epoch 3: 0.2541560232639313
Local loss @ local epoch 4: 0.15818357467651367
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.45 seconds!
[tester] 
AGNewsMetric: acc=0.723421052631579, hinge=1.6392954299324438, ce=5.342514685580605
Local test acc @ epoch 13: 0.7234
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.9595528244972229
Local loss @ local epoch 1: 0.19568675756454468
Local loss @ local epoch 2: 0.024509936571121216
Local loss @ local epoch 3: 0.012875154614448547
Local loss @ local epoch 4: 0.009968784637749195
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.7 seconds!
[tester] 
AGNewsMetric: acc=0.3017105263157895, hinge=7.6631927254325465, ce=8.212847581160696
Local test acc @ epoch 13: 0.3017
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.5093069672584534
Local loss @ local epoch 1: 0.24673031270503998
Local loss @ local epoch 2: 0.1330910176038742
Local loss @ local epoch 3: 0.5011409521102905
Local loss @ local epoch 4: 0.1382129192352295
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.45 seconds!
[tester] 
AGNewsMetric: acc=0.6125, hinge=2.4335662851835553, ce=10.139518629375257
Local test acc @ epoch 13: 0.6125
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.8717500567436218
Local loss @ local epoch 1: 0.403226375579834
Local loss @ local epoch 2: 0.067845419049263
Local loss @ local epoch 3: 0.30810028314590454
Local loss @ local epoch 4: 0.14801998436450958
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.44 seconds!
[tester] 
AGNewsMetric: acc=0.4118421052631579, hinge=6.540446789390162, ce=9.483260546232525
Local test acc @ epoch 13: 0.4118
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.06737380474805832
Local loss @ local epoch 1: 0.03536347299814224
Local loss @ local epoch 2: 0.03825235739350319
Local loss @ local epoch 3: 0.16645373404026031
Local loss @ local epoch 4: 0.08474256098270416
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.95 seconds!
[tester] 
AGNewsMetric: acc=0.7760526315789473, hinge=1.6547657620279412, ce=7.9266346600181175
Local test acc @ epoch 13: 0.7761
Global evaluate on test data...
Evaluate data in 123.66 seconds!
[tester] 
AGNewsMetric: acc=0.8294736842105264, hinge=1.0910538452549985, ce=4.626692477778384
Global test acc @ epoch 13: 0.8295
Global epoch 14...
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 1.5101008415222168
Local loss @ local epoch 1: 0.4512781798839569
Local loss @ local epoch 2: 0.24488800764083862
Local loss @ local epoch 3: 0.2476920485496521
Local loss @ local epoch 4: 0.08250335603952408
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.34 seconds!
[tester] 
AGNewsMetric: acc=0.7155263157894737, hinge=2.0394449821271396, ce=6.736978095205207
Local test acc @ epoch 14: 0.7155
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.06468524038791656
Local loss @ local epoch 1: 0.040642693638801575
Local loss @ local epoch 2: 0.07910756766796112
Local loss @ local epoch 3: 0.06034446507692337
Local loss @ local epoch 4: 0.024021003395318985
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.22 seconds!
[tester] 
AGNewsMetric: acc=0.8134210526315789, hinge=1.2239944603568629, ce=6.212922726681358
Local test acc @ epoch 14: 0.8134
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.31897541880607605
Local loss @ local epoch 1: 0.18409796059131622
Local loss @ local epoch 2: 0.14278466999530792
Local loss @ local epoch 3: 0.1883326768875122
Local loss @ local epoch 4: 0.14276547729969025
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.3 seconds!
[tester] 
AGNewsMetric: acc=0.6726315789473685, hinge=1.9060811840860468, ce=5.292111229143645
Local test acc @ epoch 14: 0.6726
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0014790387358516455
Local loss @ local epoch 1: 0.01773328334093094
Local loss @ local epoch 2: 0.22952201962471008
Local loss @ local epoch 3: 0.017382796853780746
Local loss @ local epoch 4: 0.01875859871506691
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.89 seconds!
[tester] 
AGNewsMetric: acc=0.5373684210526316, hinge=4.052492263191625, ce=6.864368594320196
Local test acc @ epoch 14: 0.5374
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.6735482215881348
Local loss @ local epoch 1: 0.6247583031654358
Local loss @ local epoch 2: 1.0531222820281982
Local loss @ local epoch 3: 0.4690646231174469
Local loss @ local epoch 4: 0.44586193561553955
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.55 seconds!
[tester] 
AGNewsMetric: acc=0.501578947368421, hinge=2.723740608315719, ce=6.283514583989193
Local test acc @ epoch 14: 0.5016
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.5910882949829102
Local loss @ local epoch 1: 0.06658477336168289
Local loss @ local epoch 2: 0.19746120274066925
Local loss @ local epoch 3: 0.36230048537254333
Local loss @ local epoch 4: 0.23511691391468048
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.43 seconds!
[tester] 
AGNewsMetric: acc=0.6302631578947369, hinge=2.516888218929893, ce=8.05638889814678
Local test acc @ epoch 14: 0.6303
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.4941745698451996
Local loss @ local epoch 1: 0.23570092022418976
Local loss @ local epoch 2: 0.24067607522010803
Local loss @ local epoch 3: 0.1860373169183731
Local loss @ local epoch 4: 0.04937738925218582
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.15 seconds!
[tester] 
AGNewsMetric: acc=0.48289473684210527, hinge=4.7588573255037, ce=4.0611777958117035
Local test acc @ epoch 14: 0.4829
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.3212116956710815
Local loss @ local epoch 1: 0.5667162537574768
Local loss @ local epoch 2: 0.4946269690990448
Local loss @ local epoch 3: 0.5743722319602966
Local loss @ local epoch 4: 0.48941099643707275
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.84 seconds!
[tester] 
AGNewsMetric: acc=0.7417105263157895, hinge=1.6844343993538304, ce=6.583818271034643
Local test acc @ epoch 14: 0.7417
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.4070916473865509
Local loss @ local epoch 1: 0.022304393351078033
Local loss @ local epoch 2: 0.01945757307112217
Local loss @ local epoch 3: 0.0016337349079549313
Local loss @ local epoch 4: 0.0011407932033762336
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.35 seconds!
[tester] 
AGNewsMetric: acc=0.25, hinge=13.330983641775031, ce=11.695871951454563
Local test acc @ epoch 14: 0.25
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.5201231241226196
Local loss @ local epoch 1: 0.031412288546562195
Local loss @ local epoch 2: 0.033502113074064255
Local loss @ local epoch 3: 0.2397931069135666
Local loss @ local epoch 4: 0.4937005937099457
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.56 seconds!
[tester] 
AGNewsMetric: acc=0.7260526315789474, hinge=1.8122524331745349, ce=4.4708646101700635
Local test acc @ epoch 14: 0.7261
Global evaluate on test data...
Evaluate data in 123.83 seconds!
[tester] 
AGNewsMetric: acc=0.8505263157894737, hinge=0.9847401302739194, ce=4.531280337885806
Global test acc @ epoch 14: 0.8505
Global epoch 15...
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 1.1103073358535767
Local loss @ local epoch 1: 0.5781496167182922
Local loss @ local epoch 2: 0.7291732430458069
Local loss @ local epoch 3: 0.8049207925796509
Local loss @ local epoch 4: 0.7434816956520081
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.25 seconds!
[tester] 
AGNewsMetric: acc=0.7048684210526316, hinge=1.7391228384720652, ce=5.691600249441047
Local test acc @ epoch 15: 0.7049
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 1.0236148834228516
Local loss @ local epoch 1: 0.3044990003108978
Local loss @ local epoch 2: 0.141624316573143
Local loss @ local epoch 3: 0.2773095667362213
Local loss @ local epoch 4: 0.23964019119739532
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.27 seconds!
[tester] 
AGNewsMetric: acc=0.6860526315789474, hinge=1.7833105724736265, ce=6.70763311586882
Local test acc @ epoch 15: 0.6861
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.8160790205001831
Local loss @ local epoch 1: 0.3382415175437927
Local loss @ local epoch 2: 0.21395346522331238
Local loss @ local epoch 3: 0.4014815092086792
Local loss @ local epoch 4: 0.12862035632133484
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.49 seconds!
[tester] 
AGNewsMetric: acc=0.4623684210526316, hinge=3.146746217828048, ce=8.453399750558953
Local test acc @ epoch 15: 0.4624
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.1349555104970932
Local loss @ local epoch 1: 0.009218329563736916
Local loss @ local epoch 2: 0.014038926921784878
Local loss @ local epoch 3: 0.0023600647691637278
Local loss @ local epoch 4: 0.006408886518329382
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.99 seconds!
[tester] 
AGNewsMetric: acc=0.5142105263157895, hinge=3.5596668680090655, ce=4.0499064294915454
Local test acc @ epoch 15: 0.5142
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.5404513478279114
Local loss @ local epoch 1: 0.24838711321353912
Local loss @ local epoch 2: 0.15220049023628235
Local loss @ local epoch 3: 0.5058367848396301
Local loss @ local epoch 4: 0.11516646295785904
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.39 seconds!
[tester] 
AGNewsMetric: acc=0.6719736842105263, hinge=1.9051666520771227, ce=8.039327862388209
Local test acc @ epoch 15: 0.672
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.009685855358839035
Local loss @ local epoch 1: 0.010133558884263039
Local loss @ local epoch 2: 0.009258164092898369
Local loss @ local epoch 3: 0.008963306434452534
Local loss @ local epoch 4: 0.014517093077301979
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.58 seconds!
[tester] 
AGNewsMetric: acc=0.7571052631578947, hinge=1.9042420181475188, ce=4.532904966253984
Local test acc @ epoch 15: 0.7571
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.540581464767456
Local loss @ local epoch 1: 0.18431086838245392
Local loss @ local epoch 2: 0.23023946583271027
Local loss @ local epoch 3: 0.1143798977136612
Local loss @ local epoch 4: 0.9867634177207947
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.61 seconds!
[tester] 
AGNewsMetric: acc=0.7186842105263158, hinge=2.008158967871415, ce=10.440439922935084
Local test acc @ epoch 15: 0.7187
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.11659593880176544
Local loss @ local epoch 1: 0.09735079854726791
Local loss @ local epoch 2: 0.027413440868258476
Local loss @ local epoch 3: 0.02660863846540451
Local loss @ local epoch 4: 0.008767494931817055
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.95 seconds!
[tester] 
AGNewsMetric: acc=0.7802631578947369, hinge=1.7102328405882183, ce=6.704181721335964
Local test acc @ epoch 15: 0.7803
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.5319868326187134
Local loss @ local epoch 1: 0.37925729155540466
Local loss @ local epoch 2: 0.13270778954029083
Local loss @ local epoch 3: 0.0546797551214695
Local loss @ local epoch 4: 0.10927055776119232
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.47 seconds!
[tester] 
AGNewsMetric: acc=0.6205263157894737, hinge=2.1777804033379806, ce=8.042982968782123
Local test acc @ epoch 15: 0.6205
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 1.0903205871582031
Local loss @ local epoch 1: 0.27014613151550293
Local loss @ local epoch 2: 0.1900404840707779
Local loss @ local epoch 3: 0.0066360728815197945
Local loss @ local epoch 4: 0.006776750087738037
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.48 seconds!
[tester] 
AGNewsMetric: acc=0.25, hinge=14.029085433859574, ce=17.696575429815994
Local test acc @ epoch 15: 0.25
Global evaluate on test data...
Evaluate data in 124.27 seconds!
[tester] 
AGNewsMetric: acc=0.8610526315789474, hinge=0.8923421975185997, ce=4.417564644060636
Global test acc @ epoch 15: 0.8611
Global epoch 16...
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.7279767394065857
Local loss @ local epoch 1: 0.2574845552444458
Local loss @ local epoch 2: 0.15058021247386932
Local loss @ local epoch 3: 0.024436425417661667
Local loss @ local epoch 4: 0.25265949964523315
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.6 seconds!
[tester] 
AGNewsMetric: acc=0.48947368421052634, hinge=4.295941955164859, ce=9.209133140162418
Local test acc @ epoch 16: 0.4895
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.08455345779657364
Local loss @ local epoch 1: 0.4953896105289459
Local loss @ local epoch 2: 0.15820719301700592
Local loss @ local epoch 3: 0.10843020677566528
Local loss @ local epoch 4: 0.23489096760749817
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.88 seconds!
[tester] 
AGNewsMetric: acc=0.295, hinge=8.051513611642937, ce=6.169747754147179
Local test acc @ epoch 16: 0.295
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.007193353027105331
Local loss @ local epoch 1: 0.008047851733863354
Local loss @ local epoch 2: 0.0020261970348656178
Local loss @ local epoch 3: 0.016464373096823692
Local loss @ local epoch 4: 0.014234322123229504
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.12 seconds!
[tester] 
AGNewsMetric: acc=0.4035526315789474, hinge=7.4176921864559775, ce=5.9698875316820645
Local test acc @ epoch 16: 0.4036
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.4613921642303467
Local loss @ local epoch 1: 0.06959589570760727
Local loss @ local epoch 2: 0.0048513105139136314
Local loss @ local epoch 3: 0.10269377380609512
Local loss @ local epoch 4: 0.00233797961845994
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.0 seconds!
[tester] 
AGNewsMetric: acc=0.3406578947368421, hinge=7.190089648397345, ce=6.573533234847219
Local test acc @ epoch 16: 0.3407
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.5537919402122498
Local loss @ local epoch 1: 0.1311785727739334
Local loss @ local epoch 2: 0.2999900281429291
Local loss @ local epoch 3: 0.1375036984682083
Local loss @ local epoch 4: 0.11353850364685059
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.13 seconds!
[tester] 
AGNewsMetric: acc=0.4403947368421053, hinge=4.0098092066614255, ce=8.575098312779478
Local test acc @ epoch 16: 0.4404
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.3365921974182129
Local loss @ local epoch 1: 0.06690794974565506
Local loss @ local epoch 2: 0.3441794812679291
Local loss @ local epoch 3: 0.06440623849630356
Local loss @ local epoch 4: 0.13315339386463165
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.69 seconds!
[tester] 
AGNewsMetric: acc=0.7907894736842105, hinge=1.2873930268538625, ce=7.021188164761192
Local test acc @ epoch 16: 0.7908
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.2113141566514969
Local loss @ local epoch 1: 0.049664102494716644
Local loss @ local epoch 2: 0.15384739637374878
Local loss @ local epoch 3: 0.034955307841300964
Local loss @ local epoch 4: 0.09368374943733215
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.94 seconds!
[tester] 
AGNewsMetric: acc=0.8173684210526316, hinge=1.3064752859818307, ce=7.551120985934609
Local test acc @ epoch 16: 0.8174
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.791042149066925
Local loss @ local epoch 1: 0.6271248459815979
Local loss @ local epoch 2: 0.6291366219520569
Local loss @ local epoch 3: 0.9483781456947327
Local loss @ local epoch 4: 0.9515129327774048
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.37 seconds!
[tester] 
AGNewsMetric: acc=0.33302631578947367, hinge=6.207959797507838, ce=12.787424920734606
Local test acc @ epoch 16: 0.333
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.4586363732814789
Local loss @ local epoch 1: 0.09697020798921585
Local loss @ local epoch 2: 0.0017539093969389796
Local loss @ local epoch 3: 0.005925396457314491
Local loss @ local epoch 4: 0.012720107100903988
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.06 seconds!
[tester] 
AGNewsMetric: acc=0.25, hinge=12.344675651349519, ce=13.677685358147873
Local test acc @ epoch 16: 0.25
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.9735150933265686
Local loss @ local epoch 1: 0.3740939795970917
Local loss @ local epoch 2: 0.30924171209335327
Local loss @ local epoch 3: 0.1242474913597107
Local loss @ local epoch 4: 0.2214372605085373
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.45 seconds!
[tester] 
AGNewsMetric: acc=0.27289473684210525, hinge=6.880804469459935, ce=8.581182028117933
Local test acc @ epoch 16: 0.2729
Global evaluate on test data...
Evaluate data in 123.7 seconds!
[tester] 
AGNewsMetric: acc=0.8532894736842105, hinge=0.9599860853897898, ce=4.600252786937513
Global test acc @ epoch 16: 0.8533
Global epoch 17...
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0299869105219841
Local loss @ local epoch 1: 0.05474090576171875
Local loss @ local epoch 2: 0.009058067575097084
Local loss @ local epoch 3: 0.024546906352043152
Local loss @ local epoch 4: 0.052394405007362366
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.77 seconds!
[tester] 
AGNewsMetric: acc=0.7844736842105263, hinge=1.7678685504511782, ce=6.15806706579108
Local test acc @ epoch 17: 0.7845
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 1.0267430543899536
Local loss @ local epoch 1: 0.19319699704647064
Local loss @ local epoch 2: 0.3377738893032074
Local loss @ local epoch 3: 0.10200201719999313
Local loss @ local epoch 4: 0.23448143899440765
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.68 seconds!
[tester] 
AGNewsMetric: acc=0.57, hinge=2.5247436026522987, ce=5.701918201446533
Local test acc @ epoch 17: 0.57
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 1.9882241487503052
Local loss @ local epoch 1: 0.5338355898857117
Local loss @ local epoch 2: 0.7796937823295593
Local loss @ local epoch 3: 0.4120667278766632
Local loss @ local epoch 4: 0.4299437403678894
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.9 seconds!
[tester] 
AGNewsMetric: acc=0.7961842105263158, hinge=1.2042512883638081, ce=7.463113408339651
Local test acc @ epoch 17: 0.7962
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.7605134844779968
Local loss @ local epoch 1: 0.4813581109046936
Local loss @ local epoch 2: 0.16540925204753876
Local loss @ local epoch 3: 0.22114674746990204
Local loss @ local epoch 4: 0.17012633383274078
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.13 seconds!
[tester] 
AGNewsMetric: acc=0.7819736842105263, hinge=1.5507265085923043, ce=3.900193031712582
Local test acc @ epoch 17: 0.782
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0018667581025511026
Local loss @ local epoch 1: 0.0010664876317605376
Local loss @ local epoch 2: 0.013785299845039845
Local loss @ local epoch 3: 0.013389943167567253
Local loss @ local epoch 4: 0.019378535449504852
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.54 seconds!
[tester] 
AGNewsMetric: acc=0.7830263157894737, hinge=1.5516617729789333, ce=10.08358383981805
Local test acc @ epoch 17: 0.783
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.8758037090301514
Local loss @ local epoch 1: 0.2309209406375885
Local loss @ local epoch 2: 0.08134184032678604
Local loss @ local epoch 3: 0.007725780829787254
Local loss @ local epoch 4: 0.0018994807032868266
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.74 seconds!
[tester] 
AGNewsMetric: acc=0.25355263157894736, hinge=8.037908206738924, ce=8.930096280951249
Local test acc @ epoch 17: 0.2536
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.060101594775915146
Local loss @ local epoch 1: 0.0911809429526329
Local loss @ local epoch 2: 0.0047757974825799465
Local loss @ local epoch 3: 0.014616397209465504
Local loss @ local epoch 4: 0.01861870288848877
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.63 seconds!
[tester] 
AGNewsMetric: acc=0.6961842105263157, hinge=1.9898298835754396, ce=7.03678586457905
Local test acc @ epoch 17: 0.6962
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.5708880424499512
Local loss @ local epoch 1: 0.08513301610946655
Local loss @ local epoch 2: 0.13914290070533752
Local loss @ local epoch 3: 0.0943586453795433
Local loss @ local epoch 4: 0.06903708726167679
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 125.28 seconds!
[tester] 
AGNewsMetric: acc=0.6346052631578948, hinge=2.062888512360422, ce=7.514913969541851
Local test acc @ epoch 17: 0.6346
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.5669194459915161
Local loss @ local epoch 1: 0.10439202189445496
Local loss @ local epoch 2: 0.03023124858736992
Local loss @ local epoch 3: 0.41388842463493347
Local loss @ local epoch 4: 0.9914444088935852
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.8 seconds!
[tester] 
AGNewsMetric: acc=0.25184210526315787, hinge=7.072283391450581, ce=11.04920698868601
Local test acc @ epoch 17: 0.2518
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.6152384877204895
Local loss @ local epoch 1: 0.31851881742477417
Local loss @ local epoch 2: 0.28225550055503845
Local loss @ local epoch 3: 0.12047053873538971
Local loss @ local epoch 4: 0.11625637114048004
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.35 seconds!
[tester] 
AGNewsMetric: acc=0.3021052631578947, hinge=5.272385392941927, ce=8.948035713998895
Local test acc @ epoch 17: 0.3021
Global evaluate on test data...
Evaluate data in 123.73 seconds!
[tester] 
AGNewsMetric: acc=0.8027631578947368, hinge=1.157976958626195, ce=4.578726269571405
Global test acc @ epoch 17: 0.8028
Global epoch 18...
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.7041180729866028
Local loss @ local epoch 1: 0.12868569791316986
Local loss @ local epoch 2: 0.043067678809165955
Local loss @ local epoch 3: 0.06740520149469376
Local loss @ local epoch 4: 0.0370396226644516
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.92 seconds!
[tester] 
AGNewsMetric: acc=0.6519736842105263, hinge=2.6112864308608206, ce=9.864694372478285
Local test acc @ epoch 18: 0.652
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.025278404355049133
Local loss @ local epoch 1: 0.004224193748086691
Local loss @ local epoch 2: 0.0014146305620670319
Local loss @ local epoch 3: 0.03715106099843979
Local loss @ local epoch 4: 0.004268303979188204
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.04 seconds!
[tester] 
AGNewsMetric: acc=0.6255263157894737, hinge=3.3645237892552426, ce=5.771602465980932
Local test acc @ epoch 18: 0.6255
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.45703262090682983
Local loss @ local epoch 1: 0.2942628860473633
Local loss @ local epoch 2: 0.16750147938728333
Local loss @ local epoch 3: 0.7450525164604187
Local loss @ local epoch 4: 0.3001856505870819
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.21 seconds!
[tester] 
AGNewsMetric: acc=0.7242105263157895, hinge=2.044288561971564, ce=4.5446568709925605
Local test acc @ epoch 18: 0.7242
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0169792789965868
Local loss @ local epoch 1: 0.006887565366923809
Local loss @ local epoch 2: 0.036343399435281754
Local loss @ local epoch 3: 0.038615789264440536
Local loss @ local epoch 4: 0.03182969614863396
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.99 seconds!
[tester] 
AGNewsMetric: acc=0.6777631578947368, hinge=2.58136438369751, ce=4.650825482418663
Local test acc @ epoch 18: 0.6778
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.480792373418808
Local loss @ local epoch 1: 0.9192376732826233
Local loss @ local epoch 2: 0.051456477493047714
Local loss @ local epoch 3: 0.14453986287117004
Local loss @ local epoch 4: 0.08604279160499573
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.36 seconds!
[tester] 
AGNewsMetric: acc=0.5398684210526316, hinge=3.0071450097937333, ce=5.882789690118087
Local test acc @ epoch 18: 0.5399
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.3802262544631958
Local loss @ local epoch 1: 0.06666489690542221
Local loss @ local epoch 2: 0.046131160110235214
Local loss @ local epoch 3: 0.14252294600009918
Local loss @ local epoch 4: 0.05756499245762825
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.89 seconds!
[tester] 
AGNewsMetric: acc=0.660921052631579, hinge=2.073338062386764, ce=4.387581849349172
Local test acc @ epoch 18: 0.6609
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.10249269008636475
Local loss @ local epoch 1: 0.7714934349060059
Local loss @ local epoch 2: 0.0944802388548851
Local loss @ local epoch 3: 0.38284480571746826
Local loss @ local epoch 4: 0.19325844943523407
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.96 seconds!
[tester] 
AGNewsMetric: acc=0.8430263157894737, hinge=1.0201034626207854, ce=6.109222061759547
Local test acc @ epoch 18: 0.843
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.24248404800891876
Local loss @ local epoch 1: 0.000593319593463093
Local loss @ local epoch 2: 0.0003149822587147355
Local loss @ local epoch 3: 0.00018120910681318492
Local loss @ local epoch 4: 0.00021883334557060152
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.81 seconds!
[tester] 
AGNewsMetric: acc=0.25, hinge=14.38870884142424, ce=13.578568293922826
Local test acc @ epoch 18: 0.25
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.9620065093040466
Local loss @ local epoch 1: 0.2394322156906128
Local loss @ local epoch 2: 0.17809076607227325
Local loss @ local epoch 3: 0.04171178862452507
Local loss @ local epoch 4: 0.051465585827827454
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.81 seconds!
[tester] 
AGNewsMetric: acc=0.42526315789473684, hinge=4.97523931252329, ce=8.34882199739155
Local test acc @ epoch 18: 0.4253
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.7197737693786621
Local loss @ local epoch 1: 1.057494044303894
Local loss @ local epoch 2: 0.6276125311851501
Local loss @ local epoch 3: 0.51773601770401
Local loss @ local epoch 4: 0.4203057587146759
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.61 seconds!
[tester] 
AGNewsMetric: acc=0.4909210526315789, hinge=3.325841135225798, ce=5.804010587993421
Local test acc @ epoch 18: 0.4909
Global evaluate on test data...
Evaluate data in 123.69 seconds!
[tester] 
AGNewsMetric: acc=0.8148684210526316, hinge=1.3521311654542623, ce=4.266742685217606
Global test acc @ epoch 18: 0.8149
Global epoch 19...
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 1.0829137563705444
Local loss @ local epoch 1: 0.5746361613273621
Local loss @ local epoch 2: 0.6790769696235657
Local loss @ local epoch 3: 0.18894410133361816
Local loss @ local epoch 4: 0.2612645924091339
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.69 seconds!
[tester] 
AGNewsMetric: acc=0.7398684210526316, hinge=1.509288823981034, ce=6.278129886827971
Local test acc @ epoch 19: 0.7399
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.026048744097352028
Local loss @ local epoch 1: 0.043854810297489166
Local loss @ local epoch 2: 0.009708566591143608
Local loss @ local epoch 3: 0.008128136396408081
Local loss @ local epoch 4: 0.009969847276806831
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.69 seconds!
[tester] 
AGNewsMetric: acc=0.8247368421052632, hinge=1.2734616811651933, ce=7.134791443473414
Local test acc @ epoch 19: 0.8247
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 1.6113053560256958
Local loss @ local epoch 1: 0.8951743841171265
Local loss @ local epoch 2: 0.4194760322570801
Local loss @ local epoch 3: 0.1319596767425537
Local loss @ local epoch 4: 0.030827177688479424
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.1 seconds!
[tester] 
AGNewsMetric: acc=0.29710526315789476, hinge=5.961146614175094, ce=7.909774064515767
Local test acc @ epoch 19: 0.2971
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.43324214220046997
Local loss @ local epoch 1: 0.14853733777999878
Local loss @ local epoch 2: 0.2843087911605835
Local loss @ local epoch 3: 0.2101452499628067
Local loss @ local epoch 4: 0.20643657445907593
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.64 seconds!
[tester] 
AGNewsMetric: acc=0.5969736842105263, hinge=2.313663361198024, ce=8.301265182495117
Local test acc @ epoch 19: 0.597
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 1.513723373413086
Local loss @ local epoch 1: 0.9065726399421692
Local loss @ local epoch 2: 0.35505998134613037
Local loss @ local epoch 3: 0.1489555686712265
Local loss @ local epoch 4: 1.3142814636230469
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.05 seconds!
[tester] 
AGNewsMetric: acc=0.6782894736842106, hinge=2.1536879077710602, ce=5.794188551651804
Local test acc @ epoch 19: 0.6783
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 2.0270190238952637
Local loss @ local epoch 1: 1.2094924449920654
Local loss @ local epoch 2: 0.980002224445343
Local loss @ local epoch 3: 0.7304887771606445
Local loss @ local epoch 4: 0.7309997081756592
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.02 seconds!
[tester] 
AGNewsMetric: acc=0.3767105263157895, hinge=3.715073111182765, ce=5.886853562405235
Local test acc @ epoch 19: 0.3767
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.19941626489162445
Local loss @ local epoch 1: 0.1558251678943634
Local loss @ local epoch 2: 0.015073373913764954
Local loss @ local epoch 3: 0.06666597723960876
Local loss @ local epoch 4: 0.017317963764071465
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.24 seconds!
[tester] 
AGNewsMetric: acc=0.7672368421052631, hinge=1.610950604990909, ce=6.333740501403809
Local test acc @ epoch 19: 0.7672
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.09072691947221756
Local loss @ local epoch 1: 0.013541549444198608
Local loss @ local epoch 2: 0.02463028021156788
Local loss @ local epoch 3: 0.046768199652433395
Local loss @ local epoch 4: 0.23718345165252686
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.89 seconds!
[tester] 
AGNewsMetric: acc=0.4760526315789474, hinge=3.225110993134348, ce=6.004534741451866
Local test acc @ epoch 19: 0.4761
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.3428487777709961
Local loss @ local epoch 1: 0.11622505635023117
Local loss @ local epoch 2: 0.06518032401800156
Local loss @ local epoch 3: 0.0677294209599495
Local loss @ local epoch 4: 0.07163769006729126
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.49 seconds!
[tester] 
AGNewsMetric: acc=0.6989473684210527, hinge=1.93708578862642, ce=5.346574804406417
Local test acc @ epoch 19: 0.6989
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.597144603729248
Local loss @ local epoch 1: 0.3497333824634552
Local loss @ local epoch 2: 0.3323599100112915
Local loss @ local epoch 3: 0.21065528690814972
Local loss @ local epoch 4: 0.22726668417453766
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.29 seconds!
[tester] 
AGNewsMetric: acc=0.5240789473684211, hinge=3.1042771600422108, ce=6.303821242483038
Local test acc @ epoch 19: 0.5241
Global evaluate on test data...
Evaluate data in 124.05 seconds!
[tester] 
AGNewsMetric: acc=0.8522368421052632, hinge=0.968997294777318, ce=4.259203120783756
Global test acc @ epoch 19: 0.8522
Global epoch 20...
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.6845245361328125
Local loss @ local epoch 1: 0.2477674037218094
Local loss @ local epoch 2: 0.09964334219694138
Local loss @ local epoch 3: 0.06818696856498718
Local loss @ local epoch 4: 0.03550487011671066
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.92 seconds!
[tester] 
AGNewsMetric: acc=0.2751315789473684, hinge=4.976650464409276, ce=7.461315725226151
Local test acc @ epoch 20: 0.2751
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.19142621755599976
Local loss @ local epoch 1: 0.019852807745337486
Local loss @ local epoch 2: 0.011657231487333775
Local loss @ local epoch 3: 0.002487679710611701
Local loss @ local epoch 4: 0.004937850870192051
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.03 seconds!
[tester] 
AGNewsMetric: acc=0.46789473684210525, hinge=3.504555411087839, ce=4.754117510946173
Local test acc @ epoch 20: 0.4679
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.009780253283679485
Local loss @ local epoch 1: 0.18925011157989502
Local loss @ local epoch 2: 0.01580740325152874
Local loss @ local epoch 3: 0.014748645015060902
Local loss @ local epoch 4: 0.06345575302839279
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.25 seconds!
[tester] 
AGNewsMetric: acc=0.7930263157894737, hinge=1.5936638591164036, ce=7.006281425074527
Local test acc @ epoch 20: 0.793
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.5567534565925598
Local loss @ local epoch 1: 0.15749232470989227
Local loss @ local epoch 2: 0.10819964855909348
Local loss @ local epoch 3: 0.044668231159448624
Local loss @ local epoch 4: 0.03199126198887825
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.18 seconds!
[tester] 
AGNewsMetric: acc=0.5714473684210526, hinge=2.841890126278526, ce=4.4692931787591235
Local test acc @ epoch 20: 0.5714
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.683788537979126
Local loss @ local epoch 1: 0.298672616481781
Local loss @ local epoch 2: 0.043498847633600235
Local loss @ local epoch 3: 0.09575875103473663
Local loss @ local epoch 4: 0.031800247728824615
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.61 seconds!
[tester] 
AGNewsMetric: acc=0.6392105263157895, hinge=2.486183706082796, ce=7.107990015933388
Local test acc @ epoch 20: 0.6392
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 1.108720302581787
Local loss @ local epoch 1: 0.4377325177192688
Local loss @ local epoch 2: 0.9047116637229919
Local loss @ local epoch 3: 0.3527519404888153
Local loss @ local epoch 4: 0.6918332576751709
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.95 seconds!
[tester] 
AGNewsMetric: acc=0.6340789473684211, hinge=2.074824834120901, ce=6.699003507714522
Local test acc @ epoch 20: 0.6341
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.4750213623046875
Local loss @ local epoch 1: 0.2009086012840271
Local loss @ local epoch 2: 0.05869421362876892
Local loss @ local epoch 3: 0.08186723291873932
Local loss @ local epoch 4: 0.08121097832918167
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.2 seconds!
[tester] 
AGNewsMetric: acc=0.6480263157894737, hinge=2.098369385568719, ce=6.893562093032034
Local test acc @ epoch 20: 0.648
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.871053159236908
Local loss @ local epoch 1: 0.5427519083023071
Local loss @ local epoch 2: 0.1569109708070755
Local loss @ local epoch 3: 0.06875994801521301
Local loss @ local epoch 4: 0.09950648993253708
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.9 seconds!
[tester] 
AGNewsMetric: acc=0.25394736842105264, hinge=6.85089215730366, ce=9.881603915565892
Local test acc @ epoch 20: 0.2539
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.5517117381095886
Local loss @ local epoch 1: 0.45850715041160583
Local loss @ local epoch 2: 0.08941420912742615
Local loss @ local epoch 3: 0.07556550949811935
Local loss @ local epoch 4: 0.24783183634281158
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 125.06 seconds!
[tester] 
AGNewsMetric: acc=0.4648684210526316, hinge=4.475195877677516, ce=6.973062767229582
Local test acc @ epoch 20: 0.4649
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.020445430651307106
Local loss @ local epoch 1: 0.004094336647540331
Local loss @ local epoch 2: 0.00298543949611485
Local loss @ local epoch 3: 0.009942377917468548
Local loss @ local epoch 4: 0.003791318042203784
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.93 seconds!
[tester] 
AGNewsMetric: acc=0.7443421052631579, hinge=1.9522579700068423, ce=4.638861349005448
Local test acc @ epoch 20: 0.7443
Global evaluate on test data...
Evaluate data in 123.48 seconds!
[tester] 
AGNewsMetric: acc=0.8497368421052631, hinge=0.9465068159605328, ce=5.121405416789808
Global test acc @ epoch 20: 0.8497
Global epoch 21...
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.6551588177680969
Local loss @ local epoch 1: 0.7229284048080444
Local loss @ local epoch 2: 0.3308568000793457
Local loss @ local epoch 3: 0.31398069858551025
Local loss @ local epoch 4: 0.374805212020874
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.08 seconds!
[tester] 
AGNewsMetric: acc=0.4686842105263158, hinge=3.7224403205670806, ce=8.390470649317692
Local test acc @ epoch 21: 0.4687
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 1.100348711013794
Local loss @ local epoch 1: 0.40132471919059753
Local loss @ local epoch 2: 0.5637252926826477
Local loss @ local epoch 3: 0.4021734893321991
Local loss @ local epoch 4: 0.5724775195121765
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.96 seconds!
[tester] 
AGNewsMetric: acc=0.7181578947368421, hinge=1.6183185993997675, ce=4.922847229807
Local test acc @ epoch 21: 0.7182
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0158099178224802
Local loss @ local epoch 1: 0.008936526253819466
Local loss @ local epoch 2: 0.024752698838710785
Local loss @ local epoch 3: 0.008472046814858913
Local loss @ local epoch 4: 0.00881277583539486
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.77 seconds!
[tester] 
AGNewsMetric: acc=0.7288157894736842, hinge=2.2321337268227026, ce=3.7377108262714587
Local test acc @ epoch 21: 0.7288
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.762997567653656
Local loss @ local epoch 1: 0.16537778079509735
Local loss @ local epoch 2: 0.0886572003364563
Local loss @ local epoch 3: 0.21339847147464752
Local loss @ local epoch 4: 0.20768499374389648
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.21 seconds!
[tester] 
AGNewsMetric: acc=0.6710526315789473, hinge=1.8644700948815596, ce=8.67046010268362
Local test acc @ epoch 21: 0.6711
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.9096155762672424
Local loss @ local epoch 1: 0.04381731525063515
Local loss @ local epoch 2: 0.018290363252162933
Local loss @ local epoch 3: 0.0031752614304423332
Local loss @ local epoch 4: 0.0036152175161987543
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.34 seconds!
[tester] 
AGNewsMetric: acc=0.25513157894736843, hinge=8.449820486369886, ce=8.647817278410258
Local test acc @ epoch 21: 0.2551
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.028666343539953232
Local loss @ local epoch 1: 0.032582104206085205
Local loss @ local epoch 2: 0.02074785903096199
Local loss @ local epoch 3: 0.027635082602500916
Local loss @ local epoch 4: 0.05899788439273834
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.74 seconds!
[tester] 
AGNewsMetric: acc=0.8080263157894737, hinge=1.3128427967272307, ce=6.673239345550537
Local test acc @ epoch 21: 0.808
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.040771886706352234
Local loss @ local epoch 1: 0.04537470266222954
Local loss @ local epoch 2: 0.003169717499986291
Local loss @ local epoch 3: 0.0023460129741579294
Local loss @ local epoch 4: 0.01187905017286539
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.11 seconds!
[tester] 
AGNewsMetric: acc=0.5421052631578948, hinge=4.1750649637925, ce=4.104287398488898
Local test acc @ epoch 21: 0.5421
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.45764636993408203
Local loss @ local epoch 1: 0.07286296784877777
Local loss @ local epoch 2: 0.021758664399385452
Local loss @ local epoch 3: 0.04343980923295021
Local loss @ local epoch 4: 0.10696925967931747
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.79 seconds!
[tester] 
AGNewsMetric: acc=0.6305263157894737, hinge=2.5843050078341836, ce=7.619207415329782
Local test acc @ epoch 21: 0.6305
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.8997995257377625
Local loss @ local epoch 1: 0.13626240193843842
Local loss @ local epoch 2: 0.1657000631093979
Local loss @ local epoch 3: 0.19899018108844757
Local loss @ local epoch 4: 0.13588376343250275
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.88 seconds!
[tester] 
AGNewsMetric: acc=0.4875, hinge=3.01516518793608, ce=6.449849652742085
Local test acc @ epoch 21: 0.4875
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.286541223526001
Local loss @ local epoch 1: 0.1389985978603363
Local loss @ local epoch 2: 0.04476470872759819
Local loss @ local epoch 3: 0.841177761554718
Local loss @ local epoch 4: 0.5220198035240173
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.29 seconds!
[tester] 
AGNewsMetric: acc=0.5826315789473684, hinge=2.7222620221188194, ce=5.636957760861045
Local test acc @ epoch 21: 0.5826
Global evaluate on test data...
Evaluate data in 123.95 seconds!
[tester] 
AGNewsMetric: acc=0.8614473684210526, hinge=0.9299826145172119, ce=3.8307990576091564
Global test acc @ epoch 21: 0.8614
Global epoch 22...
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.8260692358016968
Local loss @ local epoch 1: 0.7639366388320923
Local loss @ local epoch 2: 0.4029083251953125
Local loss @ local epoch 3: 0.5293689370155334
Local loss @ local epoch 4: 0.5155093669891357
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.3 seconds!
[tester] 
AGNewsMetric: acc=0.78, hinge=1.2952138308474892, ce=5.53122044111553
Local test acc @ epoch 22: 0.78
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.00332113285548985
Local loss @ local epoch 1: 0.0014941872796043754
Local loss @ local epoch 2: 0.05363049358129501
Local loss @ local epoch 3: 0.003504553809762001
Local loss @ local epoch 4: 0.0015774123603478074
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.14 seconds!
[tester] 
AGNewsMetric: acc=0.7547368421052632, hinge=1.9386098630804764, ce=5.014794744190417
Local test acc @ epoch 22: 0.7547
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.2556884288787842
Local loss @ local epoch 1: 0.5083482265472412
Local loss @ local epoch 2: 0.4390571713447571
Local loss @ local epoch 3: 0.33995679020881653
Local loss @ local epoch 4: 0.1678372174501419
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.17 seconds!
[tester] 
AGNewsMetric: acc=0.5210526315789473, hinge=3.0412502735539486, ce=7.961447791049355
Local test acc @ epoch 22: 0.5211
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.20802141726016998
Local loss @ local epoch 1: 0.41988277435302734
Local loss @ local epoch 2: 0.1217365488409996
Local loss @ local epoch 3: 0.10142027586698532
Local loss @ local epoch 4: 0.10883331298828125
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.37 seconds!
[tester] 
AGNewsMetric: acc=0.6547368421052632, hinge=2.0087472238038715, ce=5.667472379584061
Local test acc @ epoch 22: 0.6547
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.30432257056236267
Local loss @ local epoch 1: 0.0052119153551757336
Local loss @ local epoch 2: 0.005991886369884014
Local loss @ local epoch 3: 0.005872934591025114
Local loss @ local epoch 4: 0.0036309808492660522
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.94 seconds!
[tester] 
AGNewsMetric: acc=0.25026315789473685, hinge=11.71661507556313, ce=10.814697000603926
Local test acc @ epoch 22: 0.2503
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.1959126889705658
Local loss @ local epoch 1: 0.2248867303133011
Local loss @ local epoch 2: 0.12805171310901642
Local loss @ local epoch 3: 0.21062028408050537
Local loss @ local epoch 4: 0.14974689483642578
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.0 seconds!
[tester] 
AGNewsMetric: acc=0.6730263157894737, hinge=2.4308198477092544, ce=4.090453648818166
Local test acc @ epoch 22: 0.673
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.3841775953769684
Local loss @ local epoch 1: 0.48703107237815857
Local loss @ local epoch 2: 0.055656712502241135
Local loss @ local epoch 3: 0.202811136841774
Local loss @ local epoch 4: 0.11297836899757385
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.9 seconds!
[tester] 
AGNewsMetric: acc=0.5885526315789473, hinge=2.5199554167295757, ce=5.603971186186138
Local test acc @ epoch 22: 0.5886
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.06398490071296692
Local loss @ local epoch 1: 0.01249569933861494
Local loss @ local epoch 2: 0.01750137470662594
Local loss @ local epoch 3: 0.003576805116608739
Local loss @ local epoch 4: 0.017537571489810944
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.5 seconds!
[tester] 
AGNewsMetric: acc=0.5721052631578948, hinge=3.07757473594264, ce=4.818334523251182
Local test acc @ epoch 22: 0.5721
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.06517086178064346
Local loss @ local epoch 1: 0.02718179300427437
Local loss @ local epoch 2: 0.010527174919843674
Local loss @ local epoch 3: 0.01159428060054779
Local loss @ local epoch 4: 0.08182980865240097
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.46 seconds!
[tester] 
AGNewsMetric: acc=0.7757894736842105, hinge=1.7496935031288547, ce=5.773970925180536
Local test acc @ epoch 22: 0.7758
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.599047839641571
Local loss @ local epoch 1: 0.3395538628101349
Local loss @ local epoch 2: 0.12308203428983688
Local loss @ local epoch 3: 0.16226014494895935
Local loss @ local epoch 4: 0.05160438269376755
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.47 seconds!
[tester] 
AGNewsMetric: acc=0.6263157894736842, hinge=2.6134771894153794, ce=7.670023056833368
Local test acc @ epoch 22: 0.6263
Global evaluate on test data...
Evaluate data in 124.33 seconds!
[tester] 
AGNewsMetric: acc=0.8344736842105264, hinge=1.1052815156233937, ce=4.955326156616211
Global test acc @ epoch 22: 0.8345
Global epoch 23...
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.03133554011583328
Local loss @ local epoch 1: 0.0542021170258522
Local loss @ local epoch 2: 0.13129237294197083
Local loss @ local epoch 3: 0.015522800385951996
Local loss @ local epoch 4: 0.07085635513067245
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.63 seconds!
[tester] 
AGNewsMetric: acc=0.7577631578947368, hinge=1.7112961437827663, ce=6.409024813802619
Local test acc @ epoch 23: 0.7578
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 1.3316229581832886
Local loss @ local epoch 1: 0.33542343974113464
Local loss @ local epoch 2: 0.07927018404006958
Local loss @ local epoch 3: 0.016480449587106705
Local loss @ local epoch 4: 0.0013634454226121306
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.61 seconds!
[tester] 
AGNewsMetric: acc=0.25144736842105264, hinge=8.882755595759342, ce=9.787105728952508
Local test acc @ epoch 23: 0.2514
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.5337852239608765
Local loss @ local epoch 1: 0.2345139980316162
Local loss @ local epoch 2: 0.06802622228860855
Local loss @ local epoch 3: 0.011894899420440197
Local loss @ local epoch 4: 0.13476984202861786
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.61 seconds!
[tester] 
AGNewsMetric: acc=0.33263157894736844, hinge=4.6038135142075385, ce=9.43099592309249
Local test acc @ epoch 23: 0.3326
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.04378974437713623
Local loss @ local epoch 1: 0.0023516316432505846
Local loss @ local epoch 2: 0.004777044523507357
Local loss @ local epoch 3: 0.06292089819908142
Local loss @ local epoch 4: 0.014639829285442829
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.87 seconds!
[tester] 
AGNewsMetric: acc=0.47868421052631577, hinge=3.6254565886447305, ce=4.422039141404001
Local test acc @ epoch 23: 0.4787
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 1.1593403816223145
Local loss @ local epoch 1: 0.6091417670249939
Local loss @ local epoch 2: 0.20511825382709503
Local loss @ local epoch 3: 0.030493132770061493
Local loss @ local epoch 4: 0.08832646161317825
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.41 seconds!
[tester] 
AGNewsMetric: acc=0.41171052631578947, hinge=4.2411756214342615, ce=6.27676234596654
Local test acc @ epoch 23: 0.4117
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 1.7314261198043823
Local loss @ local epoch 1: 0.8369585275650024
Local loss @ local epoch 2: 0.49132633209228516
Local loss @ local epoch 3: 0.5068774223327637
Local loss @ local epoch 4: 0.8514634966850281
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.29 seconds!
[tester] 
AGNewsMetric: acc=0.6957894736842105, hinge=1.8748806983546207, ce=6.328803543291594
Local test acc @ epoch 23: 0.6958
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.3793405294418335
Local loss @ local epoch 1: 0.08043208718299866
Local loss @ local epoch 2: 0.02597934380173683
Local loss @ local epoch 3: 0.046194251626729965
Local loss @ local epoch 4: 0.06023712828755379
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.13 seconds!
[tester] 
AGNewsMetric: acc=0.7025, hinge=2.036921585484555, ce=6.729481514378598
Local test acc @ epoch 23: 0.7025
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.8582319617271423
Local loss @ local epoch 1: 0.288044273853302
Local loss @ local epoch 2: 0.03572899103164673
Local loss @ local epoch 3: 0.06883188337087631
Local loss @ local epoch 4: 0.2662915289402008
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.82 seconds!
[tester] 
AGNewsMetric: acc=0.5543421052631579, hinge=3.847111406326294, ce=6.976269510168779
Local test acc @ epoch 23: 0.5543
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.005676105618476868
Local loss @ local epoch 1: 0.0013246312737464905
Local loss @ local epoch 2: 0.04851969704031944
Local loss @ local epoch 3: 0.0021597598679363728
Local loss @ local epoch 4: 0.0003404089075047523
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.72 seconds!
[tester] 
AGNewsMetric: acc=0.3803947368421053, hinge=6.770983119763826, ce=8.164167229501825
Local test acc @ epoch 23: 0.3804
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.5530152916908264
Local loss @ local epoch 1: 0.22480793297290802
Local loss @ local epoch 2: 0.06101100519299507
Local loss @ local epoch 3: 0.1302497386932373
Local loss @ local epoch 4: 0.0677032321691513
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.73 seconds!
[tester] 
AGNewsMetric: acc=0.7467105263157895, hinge=1.5253707087667365, ce=8.314872813977694
Local test acc @ epoch 23: 0.7467
Global evaluate on test data...
Evaluate data in 125.16 seconds!
[tester] 
AGNewsMetric: acc=0.8723684210526316, hinge=0.8249837052194696, ce=3.70420747756958
Global test acc @ epoch 23: 0.8724
Global epoch 24...
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.6948607563972473
Local loss @ local epoch 1: 0.3759268522262573
Local loss @ local epoch 2: 0.05762367323040962
Local loss @ local epoch 3: 0.14368315041065216
Local loss @ local epoch 4: 0.1856893002986908
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.53 seconds!
[tester] 
AGNewsMetric: acc=0.5910526315789474, hinge=2.476752102500514, ce=8.321770623859607
Local test acc @ epoch 24: 0.5911
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.03246563673019409
Local loss @ local epoch 1: 0.017141323536634445
Local loss @ local epoch 2: 0.05256704241037369
Local loss @ local epoch 3: 0.023263417184352875
Local loss @ local epoch 4: 0.2169065624475479
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.01 seconds!
[tester] 
AGNewsMetric: acc=0.7763157894736842, hinge=1.6743928929379113, ce=6.291028253655685
Local test acc @ epoch 24: 0.7763
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.529335618019104
Local loss @ local epoch 1: 0.14666390419006348
Local loss @ local epoch 2: 0.2993837296962738
Local loss @ local epoch 3: 0.08342556655406952
Local loss @ local epoch 4: 0.12509533762931824
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.13 seconds!
[tester] 
AGNewsMetric: acc=0.679078947368421, hinge=2.9446274988274825, ce=3.8263968598215206
Local test acc @ epoch 24: 0.6791
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0010198761010542512
Local loss @ local epoch 1: 0.0002754682791419327
Local loss @ local epoch 2: 0.0008482003468088806
Local loss @ local epoch 3: 0.2775452136993408
Local loss @ local epoch 4: 0.5437335968017578
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.04 seconds!
[tester] 
AGNewsMetric: acc=0.48078947368421054, hinge=5.175945919438412, ce=7.940391968174985
Local test acc @ epoch 24: 0.4808
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.03246753290295601
Local loss @ local epoch 1: 0.03387888893485069
Local loss @ local epoch 2: 0.017647437751293182
Local loss @ local epoch 3: 0.18814605474472046
Local loss @ local epoch 4: 0.024652639403939247
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.53 seconds!
[tester] 
AGNewsMetric: acc=0.4457894736842105, hinge=3.7480696673142284, ce=5.040800818393105
Local test acc @ epoch 24: 0.4458
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.4001312255859375
Local loss @ local epoch 1: 0.0786464512348175
Local loss @ local epoch 2: 0.3460627496242523
Local loss @ local epoch 3: 0.3897882401943207
Local loss @ local epoch 4: 0.011172130703926086
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.88 seconds!
[tester] 
AGNewsMetric: acc=0.6507894736842105, hinge=2.3643910879837837, ce=10.438073702360454
Local test acc @ epoch 24: 0.6508
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.3503642976284027
Local loss @ local epoch 1: 0.033363278955221176
Local loss @ local epoch 2: 0.008621466346085072
Local loss @ local epoch 3: 0.00282361451536417
Local loss @ local epoch 4: 0.0012690572766587138
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.09 seconds!
[tester] 
AGNewsMetric: acc=0.25, hinge=11.631643033278616, ce=10.882166980944183
Local test acc @ epoch 24: 0.25
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.15385279059410095
Local loss @ local epoch 1: 0.05689818039536476
Local loss @ local epoch 2: 0.1163538470864296
Local loss @ local epoch 3: 0.03541183099150658
Local loss @ local epoch 4: 0.01753574050962925
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.65 seconds!
[tester] 
AGNewsMetric: acc=0.7013157894736842, hinge=2.48793837973946, ce=6.384681950619346
Local test acc @ epoch 24: 0.7013
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.8539116382598877
Local loss @ local epoch 1: 0.25108230113983154
Local loss @ local epoch 2: 0.1888134926557541
Local loss @ local epoch 3: 0.11215701699256897
Local loss @ local epoch 4: 0.017884114757180214
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.37 seconds!
[tester] 
AGNewsMetric: acc=0.3142105263157895, hinge=5.091801443601909, ce=8.461878443266215
Local test acc @ epoch 24: 0.3142
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.728776216506958
Local loss @ local epoch 1: 0.8348352909088135
Local loss @ local epoch 2: 0.2945413887500763
Local loss @ local epoch 3: 0.7050766348838806
Local loss @ local epoch 4: 0.4020703136920929
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.85 seconds!
[tester] 
AGNewsMetric: acc=0.8071052631578948, hinge=1.1226482341164037, ce=6.576949153699373
Local test acc @ epoch 24: 0.8071
Global evaluate on test data...
Evaluate data in 123.64 seconds!
[tester] 
AGNewsMetric: acc=0.8435526315789473, hinge=1.0508605209149813, ce=3.5891092501188577
Global test acc @ epoch 24: 0.8436
Global epoch 25...
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 1.4238677024841309
Local loss @ local epoch 1: 0.7075417041778564
Local loss @ local epoch 2: 0.4673793911933899
Local loss @ local epoch 3: 0.3591056764125824
Local loss @ local epoch 4: 0.33630189299583435
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.85 seconds!
[tester] 
AGNewsMetric: acc=0.6844736842105263, hinge=1.7357803239320453, ce=5.235508502157111
Local test acc @ epoch 25: 0.6845
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.6883244514465332
Local loss @ local epoch 1: 0.4124421179294586
Local loss @ local epoch 2: 0.06945419311523438
Local loss @ local epoch 3: 0.09605777263641357
Local loss @ local epoch 4: 0.1464225798845291
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.62 seconds!
[tester] 
AGNewsMetric: acc=0.7061842105263157, hinge=1.7723432395332739, ce=5.572812637529875
Local test acc @ epoch 25: 0.7062
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.02362377755343914
Local loss @ local epoch 1: 0.10143925249576569
Local loss @ local epoch 2: 0.016557246446609497
Local loss @ local epoch 3: 0.030899573117494583
Local loss @ local epoch 4: 0.018950603902339935
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.53 seconds!
[tester] 
AGNewsMetric: acc=0.8089473684210526, hinge=1.1815983044473748, ce=6.237424641659385
Local test acc @ epoch 25: 0.8089
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.8284796476364136
Local loss @ local epoch 1: 0.03522970527410507
Local loss @ local epoch 2: 0.06185336038470268
Local loss @ local epoch 3: 0.04396152123808861
Local loss @ local epoch 4: 0.05507351830601692
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.74 seconds!
[tester] 
AGNewsMetric: acc=0.6505263157894737, hinge=2.211819802836368, ce=6.497058580298173
Local test acc @ epoch 25: 0.6505
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.5235283970832825
Local loss @ local epoch 1: 0.3197815716266632
Local loss @ local epoch 2: 0.19558481872081757
Local loss @ local epoch 3: 0.156829833984375
Local loss @ local epoch 4: 0.07511675357818604
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.53 seconds!
[tester] 
AGNewsMetric: acc=0.675, hinge=2.9611974540509673, ce=3.7133242014834758
Local test acc @ epoch 25: 0.675
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 1.0106185674667358
Local loss @ local epoch 1: 0.5115664005279541
Local loss @ local epoch 2: 0.20209741592407227
Local loss @ local epoch 3: 0.06729285418987274
Local loss @ local epoch 4: 0.05015921592712402
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.5 seconds!
[tester] 
AGNewsMetric: acc=0.3067105263157895, hinge=6.6409378202337965, ce=8.438820152282714
Local test acc @ epoch 25: 0.3067
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.002013240708038211
Local loss @ local epoch 1: 0.00435147387906909
Local loss @ local epoch 2: 0.07078256458044052
Local loss @ local epoch 3: 0.00026263907784596086
Local loss @ local epoch 4: 0.008637188002467155
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.68 seconds!
[tester] 
AGNewsMetric: acc=0.815, hinge=1.3014055834318463, ce=7.070968471326326
Local test acc @ epoch 25: 0.815
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.029809555038809776
Local loss @ local epoch 1: 0.017374921590089798
Local loss @ local epoch 2: 0.016791818663477898
Local loss @ local epoch 3: 0.008265233598649502
Local loss @ local epoch 4: 0.0071430932730436325
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.93 seconds!
[tester] 
AGNewsMetric: acc=0.40671052631578947, hinge=6.613270091006631, ce=5.2727023496125875
Local test acc @ epoch 25: 0.4067
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 1.420899510383606
Local loss @ local epoch 1: 0.0821065679192543
Local loss @ local epoch 2: 0.17919965088367462
Local loss @ local epoch 3: 0.22339268028736115
Local loss @ local epoch 4: 0.0934501439332962
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 134.13 seconds!
[tester] 
AGNewsMetric: acc=0.6313157894736842, hinge=2.114584510200902, ce=5.638909244537354
Local test acc @ epoch 25: 0.6313
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.6915196776390076
Local loss @ local epoch 1: 0.23417168855667114
Local loss @ local epoch 2: 0.08967508375644684
Local loss @ local epoch 3: 0.03980226442217827
Local loss @ local epoch 4: 0.3420044481754303
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.06 seconds!
[tester] 
AGNewsMetric: acc=0.2956578947368421, hinge=6.551465733176784, ce=9.692315705951891
Local test acc @ epoch 25: 0.2957
Global evaluate on test data...
Evaluate data in 123.79 seconds!
[tester] 
AGNewsMetric: acc=0.8705263157894737, hinge=0.8788795220224481, ce=3.576898516604775
Global test acc @ epoch 25: 0.8705
Global epoch 26...
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.5639896988868713
Local loss @ local epoch 1: 0.5249759554862976
Local loss @ local epoch 2: 0.3816366195678711
Local loss @ local epoch 3: 0.32536831498146057
Local loss @ local epoch 4: 0.35950329899787903
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.84 seconds!
[tester] 
AGNewsMetric: acc=0.7782894736842105, hinge=1.4735393333435058, ce=4.404313959824411
Local test acc @ epoch 26: 0.7783
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0013841805048286915
Local loss @ local epoch 1: 0.00944964587688446
Local loss @ local epoch 2: 0.0012552300468087196
Local loss @ local epoch 3: 0.0018786878790706396
Local loss @ local epoch 4: 0.0020501993130892515
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.74 seconds!
[tester] 
AGNewsMetric: acc=0.7260526315789474, hinge=2.137413511276245, ce=4.8888036185816715
Local test acc @ epoch 26: 0.7261
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.629350483417511
Local loss @ local epoch 1: 0.2361827790737152
Local loss @ local epoch 2: 0.0413375161588192
Local loss @ local epoch 3: 0.010203310288488865
Local loss @ local epoch 4: 0.018343916162848473
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.85 seconds!
[tester] 
AGNewsMetric: acc=0.550921052631579, hinge=3.008850140822561, ce=7.35196565527665
Local test acc @ epoch 26: 0.5509
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.18906961381435394
Local loss @ local epoch 1: 0.059699442237615585
Local loss @ local epoch 2: 0.04049162194132805
Local loss @ local epoch 3: 0.04401269555091858
Local loss @ local epoch 4: 0.04065766558051109
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.06 seconds!
[tester] 
AGNewsMetric: acc=0.5981578947368421, hinge=3.133725854974044, ce=7.2668153029993965
Local test acc @ epoch 26: 0.5982
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.996059000492096
Local loss @ local epoch 1: 0.5047004222869873
Local loss @ local epoch 2: 0.36005088686943054
Local loss @ local epoch 3: 0.13930390775203705
Local loss @ local epoch 4: 0.1539948582649231
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.46 seconds!
[tester] 
AGNewsMetric: acc=0.3539473684210526, hinge=4.896838849218268, ce=8.742940000232897
Local test acc @ epoch 26: 0.3539
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.6886329054832458
Local loss @ local epoch 1: 0.025293033570051193
Local loss @ local epoch 2: 0.004849111661314964
Local loss @ local epoch 3: 0.0034477568697184324
Local loss @ local epoch 4: 0.0021431269124150276
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.16 seconds!
[tester] 
AGNewsMetric: acc=0.2521052631578947, hinge=10.378597808637117, ce=9.63123792347155
Local test acc @ epoch 26: 0.2521
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.03504558652639389
Local loss @ local epoch 1: 0.01574528217315674
Local loss @ local epoch 2: 0.008792717941105366
Local loss @ local epoch 3: 0.007776204496622086
Local loss @ local epoch 4: 0.006687176413834095
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.94 seconds!
[tester] 
AGNewsMetric: acc=0.7459210526315789, hinge=2.0274819396671497, ce=6.624067113775956
Local test acc @ epoch 26: 0.7459
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.09258408099412918
Local loss @ local epoch 1: 0.015866579487919807
Local loss @ local epoch 2: 0.031398847699165344
Local loss @ local epoch 3: 0.013551387004554272
Local loss @ local epoch 4: 0.0011455791536718607
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.31 seconds!
[tester] 
AGNewsMetric: acc=0.6838157894736843, hinge=2.1379618910739295, ce=4.525777426267925
Local test acc @ epoch 26: 0.6838
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.2892904579639435
Local loss @ local epoch 1: 0.08868832886219025
Local loss @ local epoch 2: 0.8422804474830627
Local loss @ local epoch 3: 0.45142534375190735
Local loss @ local epoch 4: 0.14043518900871277
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.15 seconds!
[tester] 
AGNewsMetric: acc=0.7726315789473684, hinge=1.6407370481993022, ce=4.772219904849404
Local test acc @ epoch 26: 0.7726
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.31382492184638977
Local loss @ local epoch 1: 0.06795638054609299
Local loss @ local epoch 2: 0.04375195503234863
Local loss @ local epoch 3: 0.035173702985048294
Local loss @ local epoch 4: 0.04474997520446777
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.2 seconds!
[tester] 
AGNewsMetric: acc=0.506578947368421, hinge=4.218466021889134, ce=6.067809695193642
Local test acc @ epoch 26: 0.5066
Global evaluate on test data...
Evaluate data in 124.57 seconds!
[tester] 
AGNewsMetric: acc=0.873421052631579, hinge=0.8270621641058671, ce=4.538249141291568
Global test acc @ epoch 26: 0.8734
Global epoch 27...
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.01838814653456211
Local loss @ local epoch 1: 0.006078292615711689
Local loss @ local epoch 2: 0.0091545470058918
Local loss @ local epoch 3: 0.0058529251255095005
Local loss @ local epoch 4: 0.0045911576598882675
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.51 seconds!
[tester] 
AGNewsMetric: acc=0.8010526315789473, hinge=1.5243929988459537, ce=5.24475409056011
Local test acc @ epoch 27: 0.8011
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.642812967300415
Local loss @ local epoch 1: 0.04205974563956261
Local loss @ local epoch 2: 0.16840721666812897
Local loss @ local epoch 3: 0.04813495650887489
Local loss @ local epoch 4: 0.17741680145263672
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.2 seconds!
[tester] 
AGNewsMetric: acc=0.6630263157894737, hinge=1.7751727189515767, ce=5.8828379580849095
Local test acc @ epoch 27: 0.663
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.4124937951564789
Local loss @ local epoch 1: 0.05683325231075287
Local loss @ local epoch 2: 0.00030060202698223293
Local loss @ local epoch 3: 0.0017727750819176435
Local loss @ local epoch 4: 0.0004803541232831776
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.76 seconds!
[tester] 
AGNewsMetric: acc=0.25026315789473685, hinge=11.804573113290887, ce=10.357704154566715
Local test acc @ epoch 27: 0.2503
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.001566195278428495
Local loss @ local epoch 1: 0.012851919047534466
Local loss @ local epoch 2: 0.004922641906887293
Local loss @ local epoch 3: 0.005664468742907047
Local loss @ local epoch 4: 0.014498462900519371
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.85 seconds!
[tester] 
AGNewsMetric: acc=0.8263157894736842, hinge=1.2140242212697079, ce=6.825512231525622
Local test acc @ epoch 27: 0.8263
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.5028427839279175
Local loss @ local epoch 1: 0.024017896503210068
Local loss @ local epoch 2: 0.028277341276407242
Local loss @ local epoch 3: 0.2919798791408539
Local loss @ local epoch 4: 0.024006465449929237
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.58 seconds!
[tester] 
AGNewsMetric: acc=0.6872368421052631, hinge=1.9585467955940647, ce=8.411516673439428
Local test acc @ epoch 27: 0.6872
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.17612798511981964
Local loss @ local epoch 1: 0.24406678974628448
Local loss @ local epoch 2: 0.2641928493976593
Local loss @ local epoch 3: 0.12446623295545578
Local loss @ local epoch 4: 0.07305511087179184
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.39 seconds!
[tester] 
AGNewsMetric: acc=0.7885526315789474, hinge=1.434667087354158, ce=4.6978770587318825
Local test acc @ epoch 27: 0.7886
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.9337965250015259
Local loss @ local epoch 1: 0.38185739517211914
Local loss @ local epoch 2: 0.3388340175151825
Local loss @ local epoch 3: 0.40990880131721497
Local loss @ local epoch 4: 0.0452110692858696
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.94 seconds!
[tester] 
AGNewsMetric: acc=0.3773684210526316, hinge=4.761762482492547, ce=10.370266127335398
Local test acc @ epoch 27: 0.3774
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.24955664575099945
Local loss @ local epoch 1: 0.058580171316862106
Local loss @ local epoch 2: 0.11334622651338577
Local loss @ local epoch 3: 0.1228671669960022
Local loss @ local epoch 4: 0.060941245406866074
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.45 seconds!
[tester] 
AGNewsMetric: acc=0.8364473684210526, hinge=1.0546965046932824, ce=4.813696187671862
Local test acc @ epoch 27: 0.8364
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.6884499192237854
Local loss @ local epoch 1: 0.2900347411632538
Local loss @ local epoch 2: 0.24548691511154175
Local loss @ local epoch 3: 0.4008474349975586
Local loss @ local epoch 4: 0.3050508499145508
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.83 seconds!
[tester] 
AGNewsMetric: acc=0.8077631578947368, hinge=1.2145493989241751, ce=5.37806517048886
Local test acc @ epoch 27: 0.8078
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.03524794057011604
Local loss @ local epoch 1: 0.01158385630697012
Local loss @ local epoch 2: 0.019269824028015137
Local loss @ local epoch 3: 0.04442253336310387
Local loss @ local epoch 4: 0.05593745782971382
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.99 seconds!
[tester] 
AGNewsMetric: acc=0.5688157894736842, hinge=2.9725487237227592, ce=4.630671770196212
Local test acc @ epoch 27: 0.5688
Global evaluate on test data...
Evaluate data in 124.06 seconds!
[tester] 
AGNewsMetric: acc=0.8760526315789474, hinge=0.7999391063890959, ce=4.718781444148013
Global test acc @ epoch 27: 0.8761
Global epoch 28...
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.6621952652931213
Local loss @ local epoch 1: 0.3363344371318817
Local loss @ local epoch 2: 0.18395648896694183
Local loss @ local epoch 3: 0.3134605586528778
Local loss @ local epoch 4: 0.24433062970638275
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.56 seconds!
[tester] 
AGNewsMetric: acc=0.8293421052631579, hinge=1.1146127525128817, ce=7.875503910466245
Local test acc @ epoch 28: 0.8293
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.3115846812725067
Local loss @ local epoch 1: 0.00820279959589243
Local loss @ local epoch 2: 0.0006263335817493498
Local loss @ local epoch 3: 0.0017393029993399978
Local loss @ local epoch 4: 0.005021607968956232
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.73 seconds!
[tester] 
AGNewsMetric: acc=0.2505263157894737, hinge=12.133202197426243, ce=10.25624441448011
Local test acc @ epoch 28: 0.2505
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.14974497258663177
Local loss @ local epoch 1: 0.36690792441368103
Local loss @ local epoch 2: 0.11762295663356781
Local loss @ local epoch 3: 0.0570840947329998
Local loss @ local epoch 4: 0.028961429372429848
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.38 seconds!
[tester] 
AGNewsMetric: acc=0.6610526315789473, hinge=2.325152637582076, ce=4.3789945983886716
Local test acc @ epoch 28: 0.6611
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.6664290428161621
Local loss @ local epoch 1: 0.2817724347114563
Local loss @ local epoch 2: 0.12226163595914841
Local loss @ local epoch 3: 0.03356601670384407
Local loss @ local epoch 4: 0.2956799268722534
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.67 seconds!
[tester] 
AGNewsMetric: acc=0.33539473684210525, hinge=5.632063209132144, ce=10.978072574013158
Local test acc @ epoch 28: 0.3354
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.006873587612062693
Local loss @ local epoch 1: 0.11272118240594864
Local loss @ local epoch 2: 0.027748171240091324
Local loss @ local epoch 3: 0.02881748415529728
Local loss @ local epoch 4: 0.005656594876199961
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.62 seconds!
[tester] 
AGNewsMetric: acc=0.6680263157894737, hinge=2.5574260345258213, ce=7.1671359323200425
Local test acc @ epoch 28: 0.668
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.3899945020675659
Local loss @ local epoch 1: 0.020652858540415764
Local loss @ local epoch 2: 0.3568907082080841
Local loss @ local epoch 3: 0.10519430041313171
Local loss @ local epoch 4: 0.05453209951519966
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.53 seconds!
[tester] 
AGNewsMetric: acc=0.5523684210526316, hinge=2.8775025061557167, ce=6.167827848133288
Local test acc @ epoch 28: 0.5524
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.6660316586494446
Local loss @ local epoch 1: 0.12129437178373337
Local loss @ local epoch 2: 0.030166469514369965
Local loss @ local epoch 3: 0.06212481111288071
Local loss @ local epoch 4: 0.018395867198705673
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.94 seconds!
[tester] 
AGNewsMetric: acc=0.5639473684210526, hinge=2.7741127767060934, ce=7.742795684212132
Local test acc @ epoch 28: 0.5639
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.22822676599025726
Local loss @ local epoch 1: 0.4247647225856781
Local loss @ local epoch 2: 0.04026174172759056
Local loss @ local epoch 3: 0.24509088695049286
Local loss @ local epoch 4: 0.08059593290090561
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.45 seconds!
[tester] 
AGNewsMetric: acc=0.8097368421052632, hinge=1.1528313757243909, ce=5.531793891505191
Local test acc @ epoch 28: 0.8097
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0002484560536686331
Local loss @ local epoch 1: 0.0004189624451100826
Local loss @ local epoch 2: 0.0011131992796435952
Local loss @ local epoch 3: 0.0031443710904568434
Local loss @ local epoch 4: 0.0012291460298001766
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.38 seconds!
[tester] 
AGNewsMetric: acc=0.6076315789473684, hinge=4.231356690557379, ce=9.594002571105957
Local test acc @ epoch 28: 0.6076
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.16473862528800964
Local loss @ local epoch 1: 0.007423070725053549
Local loss @ local epoch 2: 0.0038544286508113146
Local loss @ local epoch 3: 0.0018492318922653794
Local loss @ local epoch 4: 0.002265957882627845
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.88 seconds!
[tester] 
AGNewsMetric: acc=0.5953947368421053, hinge=2.9230796974583675, ce=3.5711575407730907
Local test acc @ epoch 28: 0.5954
Global evaluate on test data...
Evaluate data in 124.28 seconds!
[tester] 
AGNewsMetric: acc=0.8560526315789474, hinge=0.9711061598125257, ce=3.4169779170186896
Global test acc @ epoch 28: 0.8561
Global epoch 29...
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0002936184755526483
Local loss @ local epoch 1: 0.0005354350432753563
Local loss @ local epoch 2: 0.01963880844414234
Local loss @ local epoch 3: 0.0008523434516973794
Local loss @ local epoch 4: 0.0050105145201087
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.9 seconds!
[tester] 
AGNewsMetric: acc=0.6969736842105263, hinge=2.4624910005770233, ce=6.74347782034623
Local test acc @ epoch 29: 0.697
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.02576998807489872
Local loss @ local epoch 1: 0.016726678237318993
Local loss @ local epoch 2: 0.011542625725269318
Local loss @ local epoch 3: 0.011384791694581509
Local loss @ local epoch 4: 0.0100095858797431
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.73 seconds!
[tester] 
AGNewsMetric: acc=0.7098684210526316, hinge=1.8239899419483385, ce=4.81400361813997
Local test acc @ epoch 29: 0.7099
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.726867139339447
Local loss @ local epoch 1: 0.1729455292224884
Local loss @ local epoch 2: 0.1265631765127182
Local loss @ local epoch 3: 0.13369926810264587
Local loss @ local epoch 4: 0.009955061599612236
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.34 seconds!
[tester] 
AGNewsMetric: acc=0.44144736842105264, hinge=5.228899049758911, ce=10.843695963809365
Local test acc @ epoch 29: 0.4414
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.21968717873096466
Local loss @ local epoch 1: 0.2149624526500702
Local loss @ local epoch 2: 0.06633273512125015
Local loss @ local epoch 3: 0.41877809166908264
Local loss @ local epoch 4: 0.0737796351313591
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 125.01 seconds!
[tester] 
AGNewsMetric: acc=0.7578947368421053, hinge=1.7057162249715705, ce=4.2559510652642505
Local test acc @ epoch 29: 0.7579
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.4483273923397064
Local loss @ local epoch 1: 0.06855671107769012
Local loss @ local epoch 2: 0.04885579273104668
Local loss @ local epoch 3: 0.23710429668426514
Local loss @ local epoch 4: 0.07343461364507675
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.04 seconds!
[tester] 
AGNewsMetric: acc=0.8265789473684211, hinge=1.1956666128258957, ce=4.791491398058439
Local test acc @ epoch 29: 0.8266
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.9195113182067871
Local loss @ local epoch 1: 0.18970030546188354
Local loss @ local epoch 2: 0.009292344562709332
Local loss @ local epoch 3: 0.02325741946697235
Local loss @ local epoch 4: 0.01358713861554861
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.84 seconds!
[tester] 
AGNewsMetric: acc=0.3886842105263158, hinge=4.849900899686311, ce=7.610604368510999
Local test acc @ epoch 29: 0.3887
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 1.3568192720413208
Local loss @ local epoch 1: 0.17319664359092712
Local loss @ local epoch 2: 0.016301430761814117
Local loss @ local epoch 3: 0.006528775207698345
Local loss @ local epoch 4: 0.004722099285572767
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.9 seconds!
[tester] 
AGNewsMetric: acc=0.37894736842105264, hinge=4.802420139312744, ce=7.607723084499962
Local test acc @ epoch 29: 0.3789
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.015248600393533707
Local loss @ local epoch 1: 0.004856036975979805
Local loss @ local epoch 2: 0.0028519979678094387
Local loss @ local epoch 3: 0.0891525000333786
Local loss @ local epoch 4: 0.020980510860681534
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.54 seconds!
[tester] 
AGNewsMetric: acc=0.8280263157894737, hinge=1.0989645011801468, ce=5.551490080984015
Local test acc @ epoch 29: 0.828
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 1.1109532117843628
Local loss @ local epoch 1: 0.33647286891937256
Local loss @ local epoch 2: 0.3585668206214905
Local loss @ local epoch 3: 0.49213436245918274
Local loss @ local epoch 4: 0.4146987795829773
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.47 seconds!
[tester] 
AGNewsMetric: acc=0.7577631578947368, hinge=1.3938538887626246, ce=4.689940006858424
Local test acc @ epoch 29: 0.7578
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.7485249638557434
Local loss @ local epoch 1: 0.4504862129688263
Local loss @ local epoch 2: 0.30954551696777344
Local loss @ local epoch 3: 0.09301258623600006
Local loss @ local epoch 4: 0.13994580507278442
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.61 seconds!
[tester] 
AGNewsMetric: acc=0.33342105263157895, hinge=4.29650345651727, ce=7.933714781309429
Local test acc @ epoch 29: 0.3334
Global evaluate on test data...
Evaluate data in 124.22 seconds!
[tester] 
AGNewsMetric: acc=0.8538157894736842, hinge=0.9374991597627339, ce=4.224787821518747
Global test acc @ epoch 29: 0.8538
Global epoch 30...
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.3308234214782715
Local loss @ local epoch 1: 1.4617234468460083
Local loss @ local epoch 2: 0.653532087802887
Local loss @ local epoch 3: 0.38267096877098083
Local loss @ local epoch 4: 0.9644479155540466
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.9 seconds!
[tester] 
AGNewsMetric: acc=0.8582894736842105, hinge=0.99479096713819, ce=4.155125367014032
Local test acc @ epoch 30: 0.8583
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.1470423936843872
Local loss @ local epoch 1: 0.21279290318489075
Local loss @ local epoch 2: 0.045171964913606644
Local loss @ local epoch 3: 0.08424931019544601
Local loss @ local epoch 4: 0.060737643390893936
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.17 seconds!
[tester] 
AGNewsMetric: acc=0.3601315789473684, hinge=4.4828920243915755, ce=7.565007779974686
Local test acc @ epoch 30: 0.3601
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.006690116133540869
Local loss @ local epoch 1: 0.03437044471502304
Local loss @ local epoch 2: 0.008976072072982788
Local loss @ local epoch 3: 0.016269560903310776
Local loss @ local epoch 4: 0.010664982721209526
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.92 seconds!
[tester] 
AGNewsMetric: acc=0.7771052631578947, hinge=1.5296014800824618, ce=5.467529958423815
Local test acc @ epoch 30: 0.7771
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.09284035116434097
Local loss @ local epoch 1: 0.050984397530555725
Local loss @ local epoch 2: 0.4100993573665619
Local loss @ local epoch 3: 0.17418210208415985
Local loss @ local epoch 4: 0.3872510492801666
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.81 seconds!
[tester] 
AGNewsMetric: acc=0.7881578947368421, hinge=1.37893623904178, ce=4.871253263573897
Local test acc @ epoch 30: 0.7882
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.17983640730381012
Local loss @ local epoch 1: 0.07978648692369461
Local loss @ local epoch 2: 0.001148112234659493
Local loss @ local epoch 3: 0.003094838000833988
Local loss @ local epoch 4: 0.000349892710801214
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.11 seconds!
[tester] 
AGNewsMetric: acc=0.2506578947368421, hinge=11.510159283688195, ce=10.37847220370644
Local test acc @ epoch 30: 0.2507
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0023120613768696785
Local loss @ local epoch 1: 0.00047325831837952137
Local loss @ local epoch 2: 0.00026994216023012996
Local loss @ local epoch 3: 6.804175063734874e-05
Local loss @ local epoch 4: 0.0003923509211745113
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.38 seconds!
[tester] 
AGNewsMetric: acc=0.6907894736842105, hinge=2.6521262043400813, ce=9.997570208499306
Local test acc @ epoch 30: 0.6908
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.3398408889770508
Local loss @ local epoch 1: 0.060060352087020874
Local loss @ local epoch 2: 0.018419822677969933
Local loss @ local epoch 3: 0.5382575392723083
Local loss @ local epoch 4: 0.3083249628543854
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.19 seconds!
[tester] 
AGNewsMetric: acc=0.2914473684210526, hinge=7.1976609641627265, ce=11.801008067883943
Local test acc @ epoch 30: 0.2914
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.08223985880613327
Local loss @ local epoch 1: 0.02227451652288437
Local loss @ local epoch 2: 0.01122619304805994
Local loss @ local epoch 3: 0.008633566088974476
Local loss @ local epoch 4: 0.0026321448385715485
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.51 seconds!
[tester] 
AGNewsMetric: acc=0.5656578947368421, hinge=4.082449928082918, ce=4.333322485873573
Local test acc @ epoch 30: 0.5657
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 1.3320811986923218
Local loss @ local epoch 1: 0.06093130633234978
Local loss @ local epoch 2: 0.028358668088912964
Local loss @ local epoch 3: 0.09047132730484009
Local loss @ local epoch 4: 0.024632824584841728
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.09 seconds!
[tester] 
AGNewsMetric: acc=0.5338157894736842, hinge=3.533862648010254, ce=4.903319272493062
Local test acc @ epoch 30: 0.5338
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.26035940647125244
Local loss @ local epoch 1: 0.04820774495601654
Local loss @ local epoch 2: 0.0505860336124897
Local loss @ local epoch 3: 0.16384489834308624
Local loss @ local epoch 4: 0.042516957968473434
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.81 seconds!
[tester] 
AGNewsMetric: acc=0.6767105263157894, hinge=2.0944536209106444, ce=6.797482631081029
Local test acc @ epoch 30: 0.6767
Global evaluate on test data...
Evaluate data in 124.12 seconds!
[tester] 
AGNewsMetric: acc=0.8493421052631579, hinge=1.0803335340399491, ce=4.0121989179912365
Global test acc @ epoch 30: 0.8493
Global epoch 31...
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.8893342614173889
Local loss @ local epoch 1: 0.13692490756511688
Local loss @ local epoch 2: 0.008689776062965393
Local loss @ local epoch 3: 0.06839626282453537
Local loss @ local epoch 4: 0.11481505632400513
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 125.03 seconds!
[tester] 
AGNewsMetric: acc=0.4785526315789474, hinge=5.022529819388138, ce=5.225905632219816
Local test acc @ epoch 31: 0.4786
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.7919981479644775
Local loss @ local epoch 1: 0.09747752547264099
Local loss @ local epoch 2: 0.02297530695796013
Local loss @ local epoch 3: 0.0023486490827053785
Local loss @ local epoch 4: 0.005941430106759071
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 125.33 seconds!
[tester] 
AGNewsMetric: acc=0.3705263157894737, hinge=5.500538910815591, ce=7.205228370867277
Local test acc @ epoch 31: 0.3705
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.27318426966667175
Local loss @ local epoch 1: 0.05165593698620796
Local loss @ local epoch 2: 0.15267883241176605
Local loss @ local epoch 3: 0.07503785192966461
Local loss @ local epoch 4: 0.039531122893095016
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.64 seconds!
[tester] 
AGNewsMetric: acc=0.6471052631578947, hinge=2.105069058568854, ce=5.271358071377403
Local test acc @ epoch 31: 0.6471
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.48636823892593384
Local loss @ local epoch 1: 0.02504911459982395
Local loss @ local epoch 2: 0.031384918838739395
Local loss @ local epoch 3: 0.047043271362781525
Local loss @ local epoch 4: 0.0071920836344361305
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.94 seconds!
[tester] 
AGNewsMetric: acc=0.6775, hinge=2.3312853225908783, ce=8.034559338218287
Local test acc @ epoch 31: 0.6775
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 1.2207739353179932
Local loss @ local epoch 1: 0.47072744369506836
Local loss @ local epoch 2: 0.3691267669200897
Local loss @ local epoch 3: 0.40152204036712646
Local loss @ local epoch 4: 0.5363151431083679
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.79 seconds!
[tester] 
AGNewsMetric: acc=0.7352631578947368, hinge=1.5505630824440404, ce=5.325422283975701
Local test acc @ epoch 31: 0.7353
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.0889071226119995
Local loss @ local epoch 1: 0.1883166879415512
Local loss @ local epoch 2: 0.022790946066379547
Local loss @ local epoch 3: 0.14771442115306854
Local loss @ local epoch 4: 0.028909968212246895
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.99 seconds!
[tester] 
AGNewsMetric: acc=0.3497368421052632, hinge=5.4389896960007516, ce=9.183098250941226
Local test acc @ epoch 31: 0.3497
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.011662226170301437
Local loss @ local epoch 1: 0.014224949292838573
Local loss @ local epoch 2: 0.016037674620747566
Local loss @ local epoch 3: 0.027988694608211517
Local loss @ local epoch 4: 0.003951887134462595
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.42 seconds!
[tester] 
AGNewsMetric: acc=0.7481578947368421, hinge=1.8608355647639225, ce=5.823998361888685
Local test acc @ epoch 31: 0.7482
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0009433254599571228
Local loss @ local epoch 1: 0.8396005630493164
Local loss @ local epoch 2: 0.00491395965218544
Local loss @ local epoch 3: 0.0031717538367956877
Local loss @ local epoch 4: 0.0014195397961884737
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.76 seconds!
[tester] 
AGNewsMetric: acc=0.6811842105263158, hinge=2.4844746042552748, ce=5.148485837233694
Local test acc @ epoch 31: 0.6812
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.07192189991474152
Local loss @ local epoch 1: 0.21570560336112976
Local loss @ local epoch 2: 0.8121214509010315
Local loss @ local epoch 3: 0.14438502490520477
Local loss @ local epoch 4: 0.30890539288520813
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.5 seconds!
[tester] 
AGNewsMetric: acc=0.7335526315789473, hinge=1.835105179234555, ce=3.4680769373241223
Local test acc @ epoch 31: 0.7336
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.08438422530889511
Local loss @ local epoch 1: 0.002341493731364608
Local loss @ local epoch 2: 0.006520085036754608
Local loss @ local epoch 3: 0.0016089548589661717
Local loss @ local epoch 4: 0.002996954834088683
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.56 seconds!
[tester] 
AGNewsMetric: acc=0.4280263157894737, hinge=4.059809379075703, ce=5.0215936108639365
Local test acc @ epoch 31: 0.428
Global evaluate on test data...
Evaluate data in 124.5 seconds!
[tester] 
AGNewsMetric: acc=0.8714473684210526, hinge=0.8240488413760536, ce=3.94926609742014
Global test acc @ epoch 31: 0.8714
Global epoch 32...
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 1.0969563722610474
Local loss @ local epoch 1: 0.19287820160388947
Local loss @ local epoch 2: 0.4536905586719513
Local loss @ local epoch 3: 0.04383014142513275
Local loss @ local epoch 4: 0.5773257613182068
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.53 seconds!
[tester] 
AGNewsMetric: acc=0.2567105263157895, hinge=8.078934372349789, ce=11.246553166038112
Local test acc @ epoch 32: 0.2567
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.1705578863620758
Local loss @ local epoch 1: 0.15525266528129578
Local loss @ local epoch 2: 0.07470741122961044
Local loss @ local epoch 3: 0.10218366235494614
Local loss @ local epoch 4: 0.017193812876939774
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.16 seconds!
[tester] 
AGNewsMetric: acc=0.5014473684210526, hinge=3.3802038915533767, ce=4.408604727293316
Local test acc @ epoch 32: 0.5014
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.11248233914375305
Local loss @ local epoch 1: 0.0049601891078054905
Local loss @ local epoch 2: 0.00044661303400062025
Local loss @ local epoch 3: 0.00041729395161382854
Local loss @ local epoch 4: 0.00031933104037307203
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.09 seconds!
[tester] 
AGNewsMetric: acc=0.25, hinge=13.297043004286916, ce=12.212164643940172
Local test acc @ epoch 32: 0.25
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.4174942076206207
Local loss @ local epoch 1: 1.5310403108596802
Local loss @ local epoch 2: 0.28483524918556213
Local loss @ local epoch 3: 0.5775689482688904
Local loss @ local epoch 4: 0.690777063369751
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.99 seconds!
[tester] 
AGNewsMetric: acc=0.8117105263157894, hinge=1.2252072078303287, ce=4.450340733779104
Local test acc @ epoch 32: 0.8117
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.4408785104751587
Local loss @ local epoch 1: 0.037337776273489
Local loss @ local epoch 2: 0.0897747278213501
Local loss @ local epoch 3: 0.010502342134714127
Local loss @ local epoch 4: 0.01777183637022972
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.95 seconds!
[tester] 
AGNewsMetric: acc=0.42947368421052634, hinge=4.216343974565205, ce=10.783365129169665
Local test acc @ epoch 32: 0.4295
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.029492339119315147
Local loss @ local epoch 1: 0.1435467153787613
Local loss @ local epoch 2: 0.029192006215453148
Local loss @ local epoch 3: 0.16203181445598602
Local loss @ local epoch 4: 0.019262313842773438
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.34 seconds!
[tester] 
AGNewsMetric: acc=0.8111842105263158, hinge=1.2622697925567627, ce=4.542273340727154
Local test acc @ epoch 32: 0.8112
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.6541880965232849
Local loss @ local epoch 1: 0.10157127678394318
Local loss @ local epoch 2: 0.07861437648534775
Local loss @ local epoch 3: 0.24498975276947021
Local loss @ local epoch 4: 0.03982285037636757
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.51 seconds!
[tester] 
AGNewsMetric: acc=0.4772368421052632, hinge=3.410881838547556, ce=8.190316409060829
Local test acc @ epoch 32: 0.4772
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.014460841193795204
Local loss @ local epoch 1: 0.00380140682682395
Local loss @ local epoch 2: 0.32521528005599976
Local loss @ local epoch 3: 0.09957778453826904
Local loss @ local epoch 4: 0.02258915640413761
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.04 seconds!
[tester] 
AGNewsMetric: acc=0.7614473684210527, hinge=1.6225896669688977, ce=6.525711630771035
Local test acc @ epoch 32: 0.7614
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.2563929557800293
Local loss @ local epoch 1: 0.022018196061253548
Local loss @ local epoch 2: 0.019445037469267845
Local loss @ local epoch 3: 0.01985487900674343
Local loss @ local epoch 4: 0.012916701845824718
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.23 seconds!
[tester] 
AGNewsMetric: acc=0.5452631578947369, hinge=4.473149015025089, ce=5.183254747892681
Local test acc @ epoch 32: 0.5453
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0028742151334881783
Local loss @ local epoch 1: 0.0003755524230655283
Local loss @ local epoch 2: 8.739619079278782e-05
Local loss @ local epoch 3: 0.0007901607896201313
Local loss @ local epoch 4: 0.0026404098607599735
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.17 seconds!
[tester] 
AGNewsMetric: acc=0.7798684210526315, hinge=1.771380369788722, ce=4.33417156420256
Local test acc @ epoch 32: 0.7799
Global evaluate on test data...
Evaluate data in 124.3 seconds!
[tester] 
AGNewsMetric: acc=0.8753947368421052, hinge=0.8888630856965718, ce=3.819883861541748
Global test acc @ epoch 32: 0.8754
Global epoch 33...
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.24316859245300293
Local loss @ local epoch 1: 0.01877344585955143
Local loss @ local epoch 2: 0.03158387914299965
Local loss @ local epoch 3: 0.01143640000373125
Local loss @ local epoch 4: 0.014213665388524532
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.82 seconds!
[tester] 
AGNewsMetric: acc=0.6780263157894737, hinge=2.2080428683130364, ce=10.45553685640034
Local test acc @ epoch 33: 0.678
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 1.3398245573043823
Local loss @ local epoch 1: 0.36906197667121887
Local loss @ local epoch 2: 0.3840515911579132
Local loss @ local epoch 3: 0.3677594065666199
Local loss @ local epoch 4: 0.21044856309890747
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.5 seconds!
[tester] 
AGNewsMetric: acc=0.6846052631578947, hinge=1.6733148524635717, ce=5.0970840062593155
Local test acc @ epoch 33: 0.6846
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.7788553833961487
Local loss @ local epoch 1: 0.017143703997135162
Local loss @ local epoch 2: 0.0006171154673211277
Local loss @ local epoch 3: 0.0009676953195594251
Local loss @ local epoch 4: 0.008776453323662281
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 125.31 seconds!
[tester] 
AGNewsMetric: acc=0.4403947368421053, hinge=7.190582407399228, ce=7.685986611215692
Local test acc @ epoch 33: 0.4404
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.007479524705559015
Local loss @ local epoch 1: 0.005826420150697231
Local loss @ local epoch 2: 0.0017624233150854707
Local loss @ local epoch 3: 0.01686938852071762
Local loss @ local epoch 4: 0.0035809713881462812
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 125.2 seconds!
[tester] 
AGNewsMetric: acc=0.7418421052631579, hinge=1.8989046347768683, ce=4.802443276455528
Local test acc @ epoch 33: 0.7418
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.06564278155565262
Local loss @ local epoch 1: 0.057045917958021164
Local loss @ local epoch 2: 0.014983005821704865
Local loss @ local epoch 3: 0.002886593108996749
Local loss @ local epoch 4: 0.027529390528798103
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.96 seconds!
[tester] 
AGNewsMetric: acc=0.8117105263157894, hinge=1.5609604012338738, ce=4.955117146341424
Local test acc @ epoch 33: 0.8117
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.07581090182065964
Local loss @ local epoch 1: 0.6282286643981934
Local loss @ local epoch 2: 0.08159670978784561
Local loss @ local epoch 3: 0.15164311230182648
Local loss @ local epoch 4: 0.0546906404197216
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.39 seconds!
[tester] 
AGNewsMetric: acc=0.7628947368421053, hinge=1.755474550849513, ce=9.701949017173366
Local test acc @ epoch 33: 0.7629
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.8524598479270935
Local loss @ local epoch 1: 0.3837781846523285
Local loss @ local epoch 2: 0.21771222352981567
Local loss @ local epoch 3: 0.19221603870391846
Local loss @ local epoch 4: 0.028420565649867058
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.06 seconds!
[tester] 
AGNewsMetric: acc=0.4702631578947368, hinge=3.5945314025878905, ce=9.336444170098556
Local test acc @ epoch 33: 0.4703
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.14425724744796753
Local loss @ local epoch 1: 0.121748186647892
Local loss @ local epoch 2: 0.3269398510456085
Local loss @ local epoch 3: 0.06742539256811142
Local loss @ local epoch 4: 0.06899113208055496
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.18 seconds!
[tester] 
AGNewsMetric: acc=0.6886842105263158, hinge=2.1422688057548123, ce=6.443328135640997
Local test acc @ epoch 33: 0.6887
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.49943122267723083
Local loss @ local epoch 1: 0.06483462452888489
Local loss @ local epoch 2: 0.03585200384259224
Local loss @ local epoch 3: 0.018693795427680016
Local loss @ local epoch 4: 0.08631031215190887
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.37 seconds!
[tester] 
AGNewsMetric: acc=0.5182894736842105, hinge=3.13059277032551, ce=8.93314106790643
Local test acc @ epoch 33: 0.5183
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.4877409040927887
Local loss @ local epoch 1: 0.14644168317317963
Local loss @ local epoch 2: 0.026346510276198387
Local loss @ local epoch 3: 0.1157873272895813
Local loss @ local epoch 4: 0.20581082999706268
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.8 seconds!
[tester] 
AGNewsMetric: acc=0.8030263157894737, hinge=1.535839309190449, ce=4.994467560617547
Local test acc @ epoch 33: 0.803
Global evaluate on test data...
Evaluate data in 124.54 seconds!
[tester] 
AGNewsMetric: acc=0.8702631578947368, hinge=0.8026668849744295, ce=4.293044702630294
Global test acc @ epoch 33: 0.8703
Global epoch 34...
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.007730443030595779
Local loss @ local epoch 1: 0.008777853101491928
Local loss @ local epoch 2: 0.0119100920855999
Local loss @ local epoch 3: 0.006579618901014328
Local loss @ local epoch 4: 0.008390131406486034
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.07 seconds!
[tester] 
AGNewsMetric: acc=0.7203947368421053, hinge=2.341349607266878, ce=8.044207802822715
Local test acc @ epoch 34: 0.7204
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.22642071545124054
Local loss @ local epoch 1: 0.0617830753326416
Local loss @ local epoch 2: 0.2880835235118866
Local loss @ local epoch 3: 0.2038763016462326
Local loss @ local epoch 4: 0.06347375363111496
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.45 seconds!
[tester] 
AGNewsMetric: acc=0.7735526315789474, hinge=1.579740995607878, ce=4.027229907387182
Local test acc @ epoch 34: 0.7736
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.1217353492975235
Local loss @ local epoch 1: 0.10391420871019363
Local loss @ local epoch 2: 0.2667334973812103
Local loss @ local epoch 3: 0.05204152688384056
Local loss @ local epoch 4: 0.030359555035829544
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.78 seconds!
[tester] 
AGNewsMetric: acc=0.7526315789473684, hinge=1.789079478414435, ce=9.259482538323653
Local test acc @ epoch 34: 0.7526
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.00167709996458143
Local loss @ local epoch 1: 0.0012856230605393648
Local loss @ local epoch 2: 0.0014329401310533285
Local loss @ local epoch 3: 0.00592085113748908
Local loss @ local epoch 4: 0.11115147918462753
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.82 seconds!
[tester] 
AGNewsMetric: acc=0.7752631578947369, hinge=1.6670348965494257, ce=4.569044510690789
Local test acc @ epoch 34: 0.7753
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 1.0429027080535889
Local loss @ local epoch 1: 0.11873240768909454
Local loss @ local epoch 2: 0.5878223776817322
Local loss @ local epoch 3: 0.4204768240451813
Local loss @ local epoch 4: 0.4185733497142792
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.23 seconds!
[tester] 
AGNewsMetric: acc=0.8169736842105263, hinge=1.1907083109805459, ce=4.4696606154190865
Local test acc @ epoch 34: 0.817
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.47250664234161377
Local loss @ local epoch 1: 0.018078749999403954
Local loss @ local epoch 2: 0.035494521260261536
Local loss @ local epoch 3: 0.06057815998792648
Local loss @ local epoch 4: 0.012821579352021217
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.16 seconds!
[tester] 
AGNewsMetric: acc=0.35855263157894735, hinge=5.7042110227283676, ce=9.568377253883764
Local test acc @ epoch 34: 0.3586
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.2199704647064209
Local loss @ local epoch 1: 0.008730449713766575
Local loss @ local epoch 2: 0.0015046339249238372
Local loss @ local epoch 3: 0.0015051878290250897
Local loss @ local epoch 4: 0.0008356685284525156
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.39 seconds!
[tester] 
AGNewsMetric: acc=0.2943421052631579, hinge=10.870749508205213, ce=9.989531003048546
Local test acc @ epoch 34: 0.2943
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.08322013169527054
Local loss @ local epoch 1: 0.020733527839183807
Local loss @ local epoch 2: 0.0019987020641565323
Local loss @ local epoch 3: 0.013133551925420761
Local loss @ local epoch 4: 0.0005749617703258991
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.69 seconds!
[tester] 
AGNewsMetric: acc=0.4982894736842105, hinge=3.6872085832294665, ce=10.480154129831414
Local test acc @ epoch 34: 0.4983
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.2850722074508667
Local loss @ local epoch 1: 0.02095341868698597
Local loss @ local epoch 2: 0.024549158290028572
Local loss @ local epoch 3: 0.01951398141682148
Local loss @ local epoch 4: 0.18355639278888702
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.21 seconds!
[tester] 
AGNewsMetric: acc=0.6169736842105263, hinge=2.5857456593764456, ce=7.978353238356741
Local test acc @ epoch 34: 0.617
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.2710316479206085
Local loss @ local epoch 1: 0.006796108093112707
Local loss @ local epoch 2: 1.1001747846603394
Local loss @ local epoch 3: 0.008137279190123081
Local loss @ local epoch 4: 0.0037998955231159925
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.1 seconds!
[tester] 
AGNewsMetric: acc=0.7610526315789473, hinge=1.6962333096955953, ce=3.901521931698448
Local test acc @ epoch 34: 0.7611
Global evaluate on test data...
Evaluate data in 123.58 seconds!
[tester] 
AGNewsMetric: acc=0.8555263157894737, hinge=1.00958421405993, ce=3.8465311391730057
Global test acc @ epoch 34: 0.8555
Global epoch 35...
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.4480985105037689
Local loss @ local epoch 1: 0.11043352633714676
Local loss @ local epoch 2: 0.02102780155837536
Local loss @ local epoch 3: 0.056095436215400696
Local loss @ local epoch 4: 0.4025810658931732
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.72 seconds!
[tester] 
AGNewsMetric: acc=0.5753947368421053, hinge=2.439841721183375, ce=5.521721067930523
Local test acc @ epoch 35: 0.5754
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.5967469215393066
Local loss @ local epoch 1: 0.04963890090584755
Local loss @ local epoch 2: 0.009543292224407196
Local loss @ local epoch 3: 0.0016170520102605224
Local loss @ local epoch 4: 0.0004568345902953297
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.58 seconds!
[tester] 
AGNewsMetric: acc=0.4002631578947368, hinge=9.518720769631235, ce=11.4392072376452
Local test acc @ epoch 35: 0.4003
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0633917897939682
Local loss @ local epoch 1: 0.004380193073302507
Local loss @ local epoch 2: 0.004224588628858328
Local loss @ local epoch 3: 0.0013589180307462811
Local loss @ local epoch 4: 0.038873229175806046
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 125.36 seconds!
[tester] 
AGNewsMetric: acc=0.5571052631578948, hinge=3.1521166972110146, ce=10.977427994577509
Local test acc @ epoch 35: 0.5571
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 1.1970356702804565
Local loss @ local epoch 1: 0.526017963886261
Local loss @ local epoch 2: 0.3844155967235565
Local loss @ local epoch 3: 0.7281796932220459
Local loss @ local epoch 4: 0.41466695070266724
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.63 seconds!
[tester] 
AGNewsMetric: acc=0.699078947368421, hinge=1.6759211314351936, ce=6.017377437792327
Local test acc @ epoch 35: 0.6991
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.05362042784690857
Local loss @ local epoch 1: 0.010499963536858559
Local loss @ local epoch 2: 0.009289314970374107
Local loss @ local epoch 3: 0.0016330140642821789
Local loss @ local epoch 4: 0.010192815214395523
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.53 seconds!
[tester] 
AGNewsMetric: acc=0.6364473684210527, hinge=3.408920841217041, ce=7.548171673824912
Local test acc @ epoch 35: 0.6364
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.09773359447717667
Local loss @ local epoch 1: 0.49425119161605835
Local loss @ local epoch 2: 0.29633408784866333
Local loss @ local epoch 3: 0.4081316590309143
Local loss @ local epoch 4: 0.4483789801597595
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.39 seconds!
[tester] 
AGNewsMetric: acc=0.7681578947368422, hinge=1.6665869020160875, ce=4.11582271475541
Local test acc @ epoch 35: 0.7682
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.7953471541404724
Local loss @ local epoch 1: 0.3404679596424103
Local loss @ local epoch 2: 0.18836331367492676
Local loss @ local epoch 3: 0.10161454230546951
Local loss @ local epoch 4: 0.039445411413908005
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.97 seconds!
[tester] 
AGNewsMetric: acc=0.46539473684210525, hinge=3.73295047659623, ce=9.859227953459087
Local test acc @ epoch 35: 0.4654
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.8079337477684021
Local loss @ local epoch 1: 0.10457440465688705
Local loss @ local epoch 2: 0.0028223556000739336
Local loss @ local epoch 3: 0.07631834596395493
Local loss @ local epoch 4: 0.19652588665485382
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.91 seconds!
[tester] 
AGNewsMetric: acc=0.4311842105263158, hinge=3.7973141645130357, ce=7.225286280983373
Local test acc @ epoch 35: 0.4312
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.800164520740509
Local loss @ local epoch 1: 0.07987765967845917
Local loss @ local epoch 2: 0.009012647904455662
Local loss @ local epoch 3: 0.11405595391988754
Local loss @ local epoch 4: 0.05810517445206642
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.26 seconds!
[tester] 
AGNewsMetric: acc=0.7314473684210526, hinge=1.7147878420980354, ce=7.963613921717593
Local test acc @ epoch 35: 0.7314
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.04278770834207535
Local loss @ local epoch 1: 0.0007418353925459087
Local loss @ local epoch 2: 0.00045908833271823823
Local loss @ local epoch 3: 0.000768254220020026
Local loss @ local epoch 4: 0.00614002114161849
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.9 seconds!
[tester] 
AGNewsMetric: acc=0.7734210526315789, hinge=1.7159739358801591, ce=4.731108971645957
Local test acc @ epoch 35: 0.7734
Global evaluate on test data...
Evaluate data in 123.93 seconds!
[tester] 
AGNewsMetric: acc=0.8465789473684211, hinge=0.9635515428844251, ce=4.475075113396896
Global test acc @ epoch 35: 0.8466
Global epoch 36...
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.05003669857978821
Local loss @ local epoch 1: 0.022257620468735695
Local loss @ local epoch 2: 0.012545671314001083
Local loss @ local epoch 3: 0.009793328121304512
Local loss @ local epoch 4: 0.00753585621714592
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.95 seconds!
[tester] 
AGNewsMetric: acc=0.6494736842105263, hinge=2.242023407785516, ce=5.739816774067126
Local test acc @ epoch 36: 0.6495
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.44991862773895264
Local loss @ local epoch 1: 0.03716659918427467
Local loss @ local epoch 2: 0.004257166758179665
Local loss @ local epoch 3: 0.011452972888946533
Local loss @ local epoch 4: 0.00680135702714324
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.2 seconds!
[tester] 
AGNewsMetric: acc=0.5014473684210526, hinge=4.191712081306859, ce=7.905032154886346
Local test acc @ epoch 36: 0.5014
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.6728711724281311
Local loss @ local epoch 1: 0.26059263944625854
Local loss @ local epoch 2: 0.0383685864508152
Local loss @ local epoch 3: 0.02768227830529213
Local loss @ local epoch 4: 0.0759131982922554
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.33 seconds!
[tester] 
AGNewsMetric: acc=0.4875, hinge=3.4043728828430178, ce=8.664436111450195
Local test acc @ epoch 36: 0.4875
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.33469879627227783
Local loss @ local epoch 1: 0.013262506574392319
Local loss @ local epoch 2: 0.04160057008266449
Local loss @ local epoch 3: 0.0509316511452198
Local loss @ local epoch 4: 0.009374691173434258
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.62 seconds!
[tester] 
AGNewsMetric: acc=0.5276315789473685, hinge=4.228822597202502, ce=6.3698101535596345
Local test acc @ epoch 36: 0.5276
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.04606131091713905
Local loss @ local epoch 1: 0.08234705775976181
Local loss @ local epoch 2: 0.05097665265202522
Local loss @ local epoch 3: 0.014239948242902756
Local loss @ local epoch 4: 0.00617400323972106
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.17 seconds!
[tester] 
AGNewsMetric: acc=0.7843421052631578, hinge=1.541480491035863, ce=7.3118746305766855
Local test acc @ epoch 36: 0.7843
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.29663965106010437
Local loss @ local epoch 1: 0.004224427044391632
Local loss @ local epoch 2: 0.0038918296340852976
Local loss @ local epoch 3: 0.0007134010666050017
Local loss @ local epoch 4: 0.0003851985384244472
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.97 seconds!
[tester] 
AGNewsMetric: acc=0.2530263157894737, hinge=13.633833018855045, ce=12.420120721114309
Local test acc @ epoch 36: 0.253
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.358561635017395
Local loss @ local epoch 1: 0.5065699815750122
Local loss @ local epoch 2: 0.3061921298503876
Local loss @ local epoch 3: 0.5249848961830139
Local loss @ local epoch 4: 0.25636568665504456
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.77 seconds!
[tester] 
AGNewsMetric: acc=0.736578947368421, hinge=1.4913982923407303, ce=5.041143611104864
Local test acc @ epoch 36: 0.7366
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.00111006002407521
Local loss @ local epoch 1: 0.002367186127230525
Local loss @ local epoch 2: 0.00011328158143442124
Local loss @ local epoch 3: 0.0008574896492063999
Local loss @ local epoch 4: 0.00021401603589765728
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.77 seconds!
[tester] 
AGNewsMetric: acc=0.49447368421052634, hinge=7.362201879400956, ce=6.590424043755783
Local test acc @ epoch 36: 0.4945
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.6799205541610718
Local loss @ local epoch 1: 0.8942686915397644
Local loss @ local epoch 2: 0.7422451376914978
Local loss @ local epoch 3: 0.6593393683433533
Local loss @ local epoch 4: 0.3074679970741272
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.17 seconds!
[tester] 
AGNewsMetric: acc=0.8461842105263158, hinge=1.125547594773142, ce=4.967110228287546
Local test acc @ epoch 36: 0.8462
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0038643234875053167
Local loss @ local epoch 1: 0.003125659888610244
Local loss @ local epoch 2: 0.014533726498484612
Local loss @ local epoch 3: 0.001726058078929782
Local loss @ local epoch 4: 0.001215868629515171
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.53 seconds!
[tester] 
AGNewsMetric: acc=0.6510526315789473, hinge=3.3445940988942198, ce=8.772857238367985
Local test acc @ epoch 36: 0.6511
Global evaluate on test data...
Evaluate data in 123.91 seconds!
[tester] 
AGNewsMetric: acc=0.8792105263157894, hinge=0.8322789443166633, ce=4.588441887905724
Global test acc @ epoch 36: 0.8792
Global epoch 37...
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.6324355006217957
Local loss @ local epoch 1: 0.0720561295747757
Local loss @ local epoch 2: 0.018615126609802246
Local loss @ local epoch 3: 0.010125561617314816
Local loss @ local epoch 4: 0.03953609988093376
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.89 seconds!
[tester] 
AGNewsMetric: acc=0.4039473684210526, hinge=5.0308897520366465, ce=11.307672135202509
Local test acc @ epoch 37: 0.4039
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.18762214481830597
Local loss @ local epoch 1: 0.029264919459819794
Local loss @ local epoch 2: 0.010539385490119457
Local loss @ local epoch 3: 0.007907689549028873
Local loss @ local epoch 4: 0.033481232821941376
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.57 seconds!
[tester] 
AGNewsMetric: acc=0.520921052631579, hinge=4.025607233047485, ce=4.322931730370772
Local test acc @ epoch 37: 0.5209
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.5642671585083008
Local loss @ local epoch 1: 0.07649019360542297
Local loss @ local epoch 2: 0.645421028137207
Local loss @ local epoch 3: 0.2848726511001587
Local loss @ local epoch 4: 0.43143337965011597
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.69 seconds!
[tester] 
AGNewsMetric: acc=0.7972368421052631, hinge=1.3633510235736244, ce=5.430039571460925
Local test acc @ epoch 37: 0.7972
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0643511489033699
Local loss @ local epoch 1: 1.3993748426437378
Local loss @ local epoch 2: 0.3358190953731537
Local loss @ local epoch 3: 0.1331576406955719
Local loss @ local epoch 4: 0.5350491404533386
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.86 seconds!
[tester] 
AGNewsMetric: acc=0.7843421052631578, hinge=1.4681084592718827, ce=10.643599887647127
Local test acc @ epoch 37: 0.7843
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.29301127791404724
Local loss @ local epoch 1: 0.004263266455382109
Local loss @ local epoch 2: 0.0016546114347875118
Local loss @ local epoch 3: 0.0007902348879724741
Local loss @ local epoch 4: 0.002008046256378293
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 125.25 seconds!
[tester] 
AGNewsMetric: acc=0.4035526315789474, hinge=9.54652839133614, ce=10.1481533271388
Local test acc @ epoch 37: 0.4036
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.3784818947315216
Local loss @ local epoch 1: 0.0086654769256711
Local loss @ local epoch 2: 0.00954375695437193
Local loss @ local epoch 3: 0.026445602998137474
Local loss @ local epoch 4: 0.01263205986469984
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.61 seconds!
[tester] 
AGNewsMetric: acc=0.4789473684210526, hinge=4.204922331257871, ce=6.014586368360018
Local test acc @ epoch 37: 0.4789
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.00363188236951828
Local loss @ local epoch 1: 0.002739619929343462
Local loss @ local epoch 2: 0.0034846398048102856
Local loss @ local epoch 3: 0.0076207360252738
Local loss @ local epoch 4: 0.003076792461797595
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.84 seconds!
[tester] 
AGNewsMetric: acc=0.7486842105263158, hinge=1.9428751252826892, ce=6.077963552976909
Local test acc @ epoch 37: 0.7487
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.5655537247657776
Local loss @ local epoch 1: 0.06005207076668739
Local loss @ local epoch 2: 0.038623128086328506
Local loss @ local epoch 3: 0.01433491799980402
Local loss @ local epoch 4: 0.020962955430150032
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.18 seconds!
[tester] 
AGNewsMetric: acc=0.31276315789473685, hinge=6.950533396068372, ce=8.906677977913304
Local test acc @ epoch 37: 0.3128
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.21329836547374725
Local loss @ local epoch 1: 0.028155026957392693
Local loss @ local epoch 2: 0.03098590113222599
Local loss @ local epoch 3: 0.06701914221048355
Local loss @ local epoch 4: 0.11334685236215591
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.0 seconds!
[tester] 
AGNewsMetric: acc=0.674078947368421, hinge=1.8029087262404593, ce=5.470477623186613
Local test acc @ epoch 37: 0.6741
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0010905887465924025
Local loss @ local epoch 1: 0.000955694355070591
Local loss @ local epoch 2: 0.7822288274765015
Local loss @ local epoch 3: 0.6355851292610168
Local loss @ local epoch 4: 1.3889347314834595
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.22 seconds!
[tester] 
AGNewsMetric: acc=0.2417105263157895, hinge=5.976832153922633, ce=15.15030572590075
Local test acc @ epoch 37: 0.2417
Global evaluate on test data...
Evaluate data in 123.15 seconds!
[tester] 
AGNewsMetric: acc=0.8757894736842106, hinge=0.898884956962184, ce=4.189385552657278
Global test acc @ epoch 37: 0.8758
Global epoch 38...
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.29139232635498047
Local loss @ local epoch 1: 0.25107085704803467
Local loss @ local epoch 2: 0.07934696227312088
Local loss @ local epoch 3: 0.3297871947288513
Local loss @ local epoch 4: 0.16918741166591644
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.62 seconds!
[tester] 
AGNewsMetric: acc=0.6756578947368421, hinge=2.327568245436016, ce=4.283866328189248
Local test acc @ epoch 38: 0.6757
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.00013318702985998243
Local loss @ local epoch 1: 0.00015805070870555937
Local loss @ local epoch 2: 9.328450687462464e-05
Local loss @ local epoch 3: 5.97456528339535e-05
Local loss @ local epoch 4: 5.5356096709147096e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.56 seconds!
[tester] 
AGNewsMetric: acc=0.5696052631578947, hinge=3.209765661641171, ce=4.801236239985416
Local test acc @ epoch 38: 0.5696
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.7585226893424988
Local loss @ local epoch 1: 0.24207742512226105
Local loss @ local epoch 2: 0.07417295128107071
Local loss @ local epoch 3: 0.0882917270064354
Local loss @ local epoch 4: 0.06821269541978836
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.58 seconds!
[tester] 
AGNewsMetric: acc=0.5628947368421052, hinge=3.6177316901558325, ce=6.9190678024292
Local test acc @ epoch 38: 0.5629
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.150782585144043
Local loss @ local epoch 1: 0.28485313057899475
Local loss @ local epoch 2: 0.13155463337898254
Local loss @ local epoch 3: 0.23376722633838654
Local loss @ local epoch 4: 0.09935066103935242
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.41 seconds!
[tester] 
AGNewsMetric: acc=0.45302631578947367, hinge=3.6676589714853387, ce=9.02304866188451
Local test acc @ epoch 38: 0.453
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.042612265795469284
Local loss @ local epoch 1: 0.0011023763800039887
Local loss @ local epoch 2: 0.001288287341594696
Local loss @ local epoch 3: 0.005862140562385321
Local loss @ local epoch 4: 0.0004045134410262108
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.09 seconds!
[tester] 
AGNewsMetric: acc=0.5444736842105263, hinge=3.2006686501753956, ce=12.26115799150969
Local test acc @ epoch 38: 0.5445
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.6592751145362854
Local loss @ local epoch 1: 0.0033969408832490444
Local loss @ local epoch 2: 0.00030771721503697336
Local loss @ local epoch 3: 0.00011057236406486481
Local loss @ local epoch 4: 0.0001511198206571862
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.94 seconds!
[tester] 
AGNewsMetric: acc=0.29618421052631577, hinge=12.459692760266755, ce=11.83599030745657
Local test acc @ epoch 38: 0.2962
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.34732282161712646
Local loss @ local epoch 1: 0.002047228626906872
Local loss @ local epoch 2: 0.21002943813800812
Local loss @ local epoch 3: 0.001183769665658474
Local loss @ local epoch 4: 0.025368327274918556
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 125.06 seconds!
[tester] 
AGNewsMetric: acc=0.5198684210526315, hinge=4.105006243053236, ce=6.163509422101472
Local test acc @ epoch 38: 0.5199
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.021270403638482094
Local loss @ local epoch 1: 0.00864452961832285
Local loss @ local epoch 2: 0.5279973149299622
Local loss @ local epoch 3: 0.008502925746142864
Local loss @ local epoch 4: 0.20929771661758423
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.14 seconds!
[tester] 
AGNewsMetric: acc=0.8273684210526315, hinge=1.1748086570438585, ce=10.455369539762797
Local test acc @ epoch 38: 0.8274
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.01680060476064682
Local loss @ local epoch 1: 0.08041253685951233
Local loss @ local epoch 2: 0.011152269318699837
Local loss @ local epoch 3: 0.02798566035926342
Local loss @ local epoch 4: 0.007062193471938372
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.2 seconds!
[tester] 
AGNewsMetric: acc=0.8222368421052632, hinge=1.266865691636738, ce=9.932638921235737
Local test acc @ epoch 38: 0.8222
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.8009006381034851
Local loss @ local epoch 1: 0.5442866683006287
Local loss @ local epoch 2: 0.19156727194786072
Local loss @ local epoch 3: 0.3648328483104706
Local loss @ local epoch 4: 0.2921457588672638
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.99 seconds!
[tester] 
AGNewsMetric: acc=0.7390789473684211, hinge=1.6853072954479016, ce=4.648814512553968
Local test acc @ epoch 38: 0.7391
Global evaluate on test data...
Evaluate data in 124.72 seconds!
[tester] 
AGNewsMetric: acc=0.8813157894736842, hinge=0.877048787066811, ce=4.764141593732332
Global test acc @ epoch 38: 0.8813
Global epoch 39...
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.7327892184257507
Local loss @ local epoch 1: 0.00735311908647418
Local loss @ local epoch 2: 0.012590980157256126
Local loss @ local epoch 3: 0.050140008330345154
Local loss @ local epoch 4: 0.07167395204305649
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.49 seconds!
[tester] 
AGNewsMetric: acc=0.5539473684210526, hinge=3.7325160789489744, ce=8.180990203054328
Local test acc @ epoch 39: 0.5539
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.014495220966637135
Local loss @ local epoch 1: 0.00038738222792744637
Local loss @ local epoch 2: 0.00038490945007652044
Local loss @ local epoch 3: 0.015251277945935726
Local loss @ local epoch 4: 0.0006266030832193792
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.78 seconds!
[tester] 
AGNewsMetric: acc=0.531578947368421, hinge=3.415774900536788, ce=12.317695065548545
Local test acc @ epoch 39: 0.5316
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.17377769947052
Local loss @ local epoch 1: 0.05082285776734352
Local loss @ local epoch 2: 0.02779138833284378
Local loss @ local epoch 3: 0.11208279430866241
Local loss @ local epoch 4: 0.011202097870409489
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.98 seconds!
[tester] 
AGNewsMetric: acc=0.4160526315789474, hinge=5.1136870293868215, ce=8.962804999100534
Local test acc @ epoch 39: 0.4161
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.00021644837397616357
Local loss @ local epoch 1: 0.00015287149290088564
Local loss @ local epoch 2: 0.0021988614462316036
Local loss @ local epoch 3: 0.0019418064039200544
Local loss @ local epoch 4: 3.897911301464774e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.2 seconds!
[tester] 
AGNewsMetric: acc=0.5319736842105263, hinge=5.061096052872507, ce=6.221878872921592
Local test acc @ epoch 39: 0.532
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.6180028915405273
Local loss @ local epoch 1: 0.0043904585763812065
Local loss @ local epoch 2: 0.007984993979334831
Local loss @ local epoch 3: 0.0013629243476316333
Local loss @ local epoch 4: 0.008869593031704426
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 125.86 seconds!
[tester] 
AGNewsMetric: acc=0.3625, hinge=5.7527330544120385, ce=8.357252775493421
Local test acc @ epoch 39: 0.3625
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.7849642038345337
Local loss @ local epoch 1: 0.3343815803527832
Local loss @ local epoch 2: 0.2439122200012207
Local loss @ local epoch 3: 0.1796610951423645
Local loss @ local epoch 4: 0.3220513164997101
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.76 seconds!
[tester] 
AGNewsMetric: acc=0.85, hinge=1.0396726640902068, ce=8.311833498101485
Local test acc @ epoch 39: 0.85
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.14396555721759796
Local loss @ local epoch 1: 0.010853544808924198
Local loss @ local epoch 2: 0.0034937255550175905
Local loss @ local epoch 3: 0.0030366992577910423
Local loss @ local epoch 4: 0.01173404697328806
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.18 seconds!
[tester] 
AGNewsMetric: acc=0.3863157894736842, hinge=8.424711526067634, ce=9.839708288092362
Local test acc @ epoch 39: 0.3863
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0770634114742279
Local loss @ local epoch 1: 0.24261724948883057
Local loss @ local epoch 2: 0.08665236830711365
Local loss @ local epoch 3: 0.044838812202215195
Local loss @ local epoch 4: 0.031107431277632713
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 125.03 seconds!
[tester] 
AGNewsMetric: acc=0.8405263157894737, hinge=1.08468051860207, ce=9.566296902706748
Local test acc @ epoch 39: 0.8405
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.2788906395435333
Local loss @ local epoch 1: 0.00670955004170537
Local loss @ local epoch 2: 0.1226610392332077
Local loss @ local epoch 3: 0.005462378263473511
Local loss @ local epoch 4: 0.013738460838794708
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 125.08 seconds!
[tester] 
AGNewsMetric: acc=0.7656578947368421, hinge=1.6050905769749693, ce=5.372984486630088
Local test acc @ epoch 39: 0.7657
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.1830960363149643
Local loss @ local epoch 1: 0.05454792454838753
Local loss @ local epoch 2: 0.021808266639709473
Local loss @ local epoch 3: 0.5272598266601562
Local loss @ local epoch 4: 0.014135950244963169
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.71 seconds!
[tester] 
AGNewsMetric: acc=0.7171052631578947, hinge=1.8144998575511733, ce=3.958657646179199
Local test acc @ epoch 39: 0.7171
Global evaluate on test data...
Evaluate data in 124.48 seconds!
[tester] 
AGNewsMetric: acc=0.8842105263157894, hinge=0.8409109150735955, ce=5.543194597143876
Global test acc @ epoch 39: 0.8842
Global epoch 40...
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.005816316697746515
Local loss @ local epoch 1: 0.01406819373369217
Local loss @ local epoch 2: 0.021366383880376816
Local loss @ local epoch 3: 0.0017960804980248213
Local loss @ local epoch 4: 0.00155518832616508
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.07 seconds!
[tester] 
AGNewsMetric: acc=0.8039473684210526, hinge=1.5310217566239206, ce=6.586873374738191
Local test acc @ epoch 40: 0.8039
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.04285673424601555
Local loss @ local epoch 1: 0.1156838908791542
Local loss @ local epoch 2: 0.005611947271972895
Local loss @ local epoch 3: 0.056693222373723984
Local loss @ local epoch 4: 0.01772535778582096
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.32 seconds!
[tester] 
AGNewsMetric: acc=0.8435526315789473, hinge=1.1073243053335893, ce=10.411101770902935
Local test acc @ epoch 40: 0.8436
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.14192268252372742
Local loss @ local epoch 1: 0.004573490004986525
Local loss @ local epoch 2: 0.01325648557394743
Local loss @ local epoch 3: 0.08272439986467361
Local loss @ local epoch 4: 0.02940787933766842
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.42 seconds!
[tester] 
AGNewsMetric: acc=0.48697368421052634, hinge=6.960588480798822, ce=11.740680666471782
Local test acc @ epoch 40: 0.487
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.8890149593353271
Local loss @ local epoch 1: 0.05166419595479965
Local loss @ local epoch 2: 0.1270677000284195
Local loss @ local epoch 3: 0.006252152845263481
Local loss @ local epoch 4: 0.0461982898414135
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.22 seconds!
[tester] 
AGNewsMetric: acc=0.5396052631578947, hinge=3.574316032309281, ce=10.538795162000154
Local test acc @ epoch 40: 0.5396
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.8474770784378052
Local loss @ local epoch 1: 0.26119527220726013
Local loss @ local epoch 2: 0.17367993295192719
Local loss @ local epoch 3: 0.017659462988376617
Local loss @ local epoch 4: 0.004431804176419973
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.24 seconds!
[tester] 
AGNewsMetric: acc=0.5131578947368421, hinge=4.383243173298083, ce=7.516826879601729
Local test acc @ epoch 40: 0.5132
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 2.3603017325513065e-05
Local loss @ local epoch 1: 1.5353934941231273e-05
Local loss @ local epoch 2: 0.0012698195641860366
Local loss @ local epoch 3: 0.04106257110834122
Local loss @ local epoch 4: 0.0012178418692201376
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.46 seconds!
[tester] 
AGNewsMetric: acc=0.8093421052631579, hinge=1.4423187602193732, ce=4.397126297197844
Local test acc @ epoch 40: 0.8093
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.039392225444316864
Local loss @ local epoch 1: 0.029499616473913193
Local loss @ local epoch 2: 0.5951418876647949
Local loss @ local epoch 3: 0.032672733068466187
Local loss @ local epoch 4: 0.13609208166599274
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.72 seconds!
[tester] 
AGNewsMetric: acc=0.6585526315789474, hinge=2.4793808389964855, ce=6.902094319996081
Local test acc @ epoch 40: 0.6586
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.2177167385816574
Local loss @ local epoch 1: 0.003510849317535758
Local loss @ local epoch 2: 0.0003183962544426322
Local loss @ local epoch 3: 0.00013440281327348202
Local loss @ local epoch 4: 0.0004099573998246342
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.96 seconds!
[tester] 
AGNewsMetric: acc=0.3617105263157895, hinge=13.558599076522023, ce=15.131784013447009
Local test acc @ epoch 40: 0.3617
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.8615871667861938
Local loss @ local epoch 1: 0.5956212282180786
Local loss @ local epoch 2: 0.2766517996788025
Local loss @ local epoch 3: 0.220531165599823
Local loss @ local epoch 4: 0.0757543295621872
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.14 seconds!
[tester] 
AGNewsMetric: acc=0.824078947368421, hinge=1.2507572645890086, ce=12.077382264388236
Local test acc @ epoch 40: 0.8241
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.058390527963638306
Local loss @ local epoch 1: 0.0041440208442509174
Local loss @ local epoch 2: 0.00038613402284681797
Local loss @ local epoch 3: 0.0005532249924726784
Local loss @ local epoch 4: 0.0007624604622833431
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.31 seconds!
[tester] 
AGNewsMetric: acc=0.655921052631579, hinge=2.4332144237819473, ce=11.672627194053248
Local test acc @ epoch 40: 0.6559
Global evaluate on test data...
Evaluate data in 124.66 seconds!
[tester] 
AGNewsMetric: acc=0.8617105263157895, hinge=0.9493995041596263, ce=10.483578400862845
Global test acc @ epoch 40: 0.8617
Global epoch 41...
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.00255990750156343
Local loss @ local epoch 1: 0.024847490713000298
Local loss @ local epoch 2: 0.003350592451170087
Local loss @ local epoch 3: 0.02748969756066799
Local loss @ local epoch 4: 7.605206337757409e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.46 seconds!
[tester] 
AGNewsMetric: acc=0.5967105263157895, hinge=2.7706888715844404, ce=8.702723491066381
Local test acc @ epoch 41: 0.5967
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.8239188194274902
Local loss @ local epoch 1: 0.033370181918144226
Local loss @ local epoch 2: 0.003103385679423809
Local loss @ local epoch 3: 0.017131470143795013
Local loss @ local epoch 4: 0.08461049199104309
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.11 seconds!
[tester] 
AGNewsMetric: acc=0.45763157894736844, hinge=9.23931891290765, ce=11.789457493832236
Local test acc @ epoch 41: 0.4576
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.9767265319824219
Local loss @ local epoch 1: 0.10617239028215408
Local loss @ local epoch 2: 0.5830066204071045
Local loss @ local epoch 3: 0.17683911323547363
Local loss @ local epoch 4: 0.24858464300632477
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.05 seconds!
[tester] 
AGNewsMetric: acc=0.7860526315789473, hinge=1.2702632723356548, ce=5.493733364908318
Local test acc @ epoch 41: 0.7861
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.004779641982167959
Local loss @ local epoch 1: 0.0006752958288416266
Local loss @ local epoch 2: 0.00040139289922080934
Local loss @ local epoch 3: 0.0006510417442768812
Local loss @ local epoch 4: 2.245862560812384e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.24 seconds!
[tester] 
AGNewsMetric: acc=0.6394736842105263, hinge=2.930211893884759, ce=4.676235217044228
Local test acc @ epoch 41: 0.6395
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.9840373992919922
Local loss @ local epoch 1: 0.024646766483783722
Local loss @ local epoch 2: 9.815010707825422e-05
Local loss @ local epoch 3: 0.0002860055537894368
Local loss @ local epoch 4: 0.0021266357507556677
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.84 seconds!
[tester] 
AGNewsMetric: acc=0.27907894736842104, hinge=12.837719960463675, ce=15.800962480243884
Local test acc @ epoch 41: 0.2791
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.9317861795425415
Local loss @ local epoch 1: 0.21650481224060059
Local loss @ local epoch 2: 0.0527467280626297
Local loss @ local epoch 3: 0.28597894310951233
Local loss @ local epoch 4: 0.016932735219597816
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.18 seconds!
[tester] 
AGNewsMetric: acc=0.455, hinge=4.940889464930484, ce=9.331416266591926
Local test acc @ epoch 41: 0.455
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.1368863582611084
Local loss @ local epoch 1: 0.11749626696109772
Local loss @ local epoch 2: 0.09544549882411957
Local loss @ local epoch 3: 0.15880826115608215
Local loss @ local epoch 4: 0.29657411575317383
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.8 seconds!
[tester] 
AGNewsMetric: acc=0.6634210526315789, hinge=2.7070268651058798, ce=11.931887409812525
Local test acc @ epoch 41: 0.6634
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.5333169102668762
Local loss @ local epoch 1: 0.026798684149980545
Local loss @ local epoch 2: 0.002572133671492338
Local loss @ local epoch 3: 0.05845918878912926
Local loss @ local epoch 4: 0.0055677457712590694
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.77 seconds!
[tester] 
AGNewsMetric: acc=0.49026315789473685, hinge=4.338253005680285, ce=10.04481886010421
Local test acc @ epoch 41: 0.4903
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.00973159447312355
Local loss @ local epoch 1: 0.026531675830483437
Local loss @ local epoch 2: 0.27941474318504333
Local loss @ local epoch 3: 0.003727927338331938
Local loss @ local epoch 4: 0.014319045469164848
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.58 seconds!
[tester] 
AGNewsMetric: acc=0.7796052631578947, hinge=1.7071030852669165, ce=10.866551365099456
Local test acc @ epoch 41: 0.7796
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.28885167837142944
Local loss @ local epoch 1: 0.02585185505449772
Local loss @ local epoch 2: 0.45404911041259766
Local loss @ local epoch 3: 0.012557286769151688
Local loss @ local epoch 4: 0.017023693770170212
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.92 seconds!
[tester] 
AGNewsMetric: acc=0.8559210526315789, hinge=1.0472649363467568, ce=5.474183621657522
Local test acc @ epoch 41: 0.8559
Global evaluate on test data...
Evaluate data in 122.94 seconds!
[tester] 
AGNewsMetric: acc=0.8673684210526316, hinge=0.8553767578225386, ce=10.71429286956787
Global test acc @ epoch 41: 0.8674
Global epoch 42...
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.30178675055503845
Local loss @ local epoch 1: 0.024499423801898956
Local loss @ local epoch 2: 0.011049559339880943
Local loss @ local epoch 3: 0.020255671814084053
Local loss @ local epoch 4: 0.02547968178987503
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.08 seconds!
[tester] 
AGNewsMetric: acc=0.4880263157894737, hinge=4.042842873021176, ce=8.050767775083843
Local test acc @ epoch 42: 0.488
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.5377787947654724
Local loss @ local epoch 1: 0.0009554954012855887
Local loss @ local epoch 2: 5.2445164328673854e-05
Local loss @ local epoch 3: 1.8867127437260933e-05
Local loss @ local epoch 4: 2.84030320472084e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.62 seconds!
[tester] 
AGNewsMetric: acc=0.3031578947368421, hinge=14.128494433352822, ce=13.828652709157844
Local test acc @ epoch 42: 0.3032
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.08584601432085037
Local loss @ local epoch 1: 0.03808857128024101
Local loss @ local epoch 2: 0.10640563815832138
Local loss @ local epoch 3: 0.07406554371118546
Local loss @ local epoch 4: 0.3644200265407562
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.33 seconds!
[tester] 
AGNewsMetric: acc=0.7727631578947368, hinge=1.4809371210399427, ce=4.03158466037951
Local test acc @ epoch 42: 0.7728
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.17601662874221802
Local loss @ local epoch 1: 0.03686980530619621
Local loss @ local epoch 2: 0.0024794263299554586
Local loss @ local epoch 3: 0.0020258286967873573
Local loss @ local epoch 4: 0.011385999619960785
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.86 seconds!
[tester] 
AGNewsMetric: acc=0.8096052631578947, hinge=1.2821925223501105, ce=6.227340293683504
Local test acc @ epoch 42: 0.8096
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.00022221282415557653
Local loss @ local epoch 1: 0.00010758564167190343
Local loss @ local epoch 2: 0.0021595614962279797
Local loss @ local epoch 3: 0.007649836130440235
Local loss @ local epoch 4: 4.715622708317824e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.85 seconds!
[tester] 
AGNewsMetric: acc=0.3576315789473684, hinge=9.978758838051244, ce=12.061021447432669
Local test acc @ epoch 42: 0.3576
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.9474055767059326
Local loss @ local epoch 1: 0.5156338214874268
Local loss @ local epoch 2: 0.3119504153728485
Local loss @ local epoch 3: 0.18716779351234436
Local loss @ local epoch 4: 0.5008499026298523
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.76 seconds!
[tester] 
AGNewsMetric: acc=0.7842105263157895, hinge=1.40210677849619, ce=11.064640241924085
Local test acc @ epoch 42: 0.7842
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.34032049775123596
Local loss @ local epoch 1: 0.003999072592705488
Local loss @ local epoch 2: 0.0014566252939403057
Local loss @ local epoch 3: 0.006082156673073769
Local loss @ local epoch 4: 0.012916047126054764
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.94 seconds!
[tester] 
AGNewsMetric: acc=0.4344736842105263, hinge=7.9014456779078435, ce=11.515805955184133
Local test acc @ epoch 42: 0.4345
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.9345074892044067
Local loss @ local epoch 1: 0.15540815889835358
Local loss @ local epoch 2: 0.03404524549841881
Local loss @ local epoch 3: 0.0683952271938324
Local loss @ local epoch 4: 0.005487468093633652
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.47 seconds!
[tester] 
AGNewsMetric: acc=0.5044736842105263, hinge=4.324553556944195, ce=9.420591506958008
Local test acc @ epoch 42: 0.5045
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0017073776107281446
Local loss @ local epoch 1: 0.0018817889504134655
Local loss @ local epoch 2: 0.002514059655368328
Local loss @ local epoch 3: 0.021731575950980186
Local loss @ local epoch 4: 0.07545637339353561
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.48 seconds!
[tester] 
AGNewsMetric: acc=0.7985526315789474, hinge=1.4771217218198274, ce=10.842698805959602
Local test acc @ epoch 42: 0.7986
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.06515093892812729
Local loss @ local epoch 1: 0.0034114280715584755
Local loss @ local epoch 2: 0.0014276966685429215
Local loss @ local epoch 3: 0.0012720389058813453
Local loss @ local epoch 4: 0.015880636870861053
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.4 seconds!
[tester] 
AGNewsMetric: acc=0.6253947368421052, hinge=2.5867180337403948, ce=5.677325999611303
Local test acc @ epoch 42: 0.6254
Global evaluate on test data...
Evaluate data in 123.87 seconds!
[tester] 
AGNewsMetric: acc=0.8748684210526316, hinge=0.8438052684382389, ce=10.8552411009136
Global test acc @ epoch 42: 0.8749
Global epoch 43...
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.6964961290359497
Local loss @ local epoch 1: 0.5548681020736694
Local loss @ local epoch 2: 0.4724006652832031
Local loss @ local epoch 3: 0.0951075628399849
Local loss @ local epoch 4: 0.30743101239204407
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.46 seconds!
[tester] 
AGNewsMetric: acc=0.8405263157894737, hinge=1.1379422195334183, ce=5.544601287841797
Local test acc @ epoch 43: 0.8405
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.08765754848718643
Local loss @ local epoch 1: 0.005213933065533638
Local loss @ local epoch 2: 0.004697341471910477
Local loss @ local epoch 3: 0.19387193024158478
Local loss @ local epoch 4: 0.04018352925777435
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.2 seconds!
[tester] 
AGNewsMetric: acc=0.8444736842105263, hinge=1.047902973827563, ce=7.222840331228156
Local test acc @ epoch 43: 0.8445
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.8212697505950928
Local loss @ local epoch 1: 0.03843115642666817
Local loss @ local epoch 2: 0.014700237661600113
Local loss @ local epoch 3: 0.028718652203679085
Local loss @ local epoch 4: 0.055472441017627716
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.79 seconds!
[tester] 
AGNewsMetric: acc=0.37684210526315787, hinge=5.6143292482275715, ce=9.185896680731522
Local test acc @ epoch 43: 0.3768
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.494613379240036
Local loss @ local epoch 1: 0.0018007569015026093
Local loss @ local epoch 2: 5.995229730615392e-05
Local loss @ local epoch 3: 0.0001255890674656257
Local loss @ local epoch 4: 3.802579522016458e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.54 seconds!
[tester] 
AGNewsMetric: acc=0.25394736842105264, hinge=13.730595540498433, ce=13.81168290188438
Local test acc @ epoch 43: 0.2539
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.444098562002182
Local loss @ local epoch 1: 0.14763370156288147
Local loss @ local epoch 2: 0.007914143614470959
Local loss @ local epoch 3: 0.00753225851804018
Local loss @ local epoch 4: 0.004952571354806423
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.91 seconds!
[tester] 
AGNewsMetric: acc=0.4536842105263158, hinge=5.561275504262824, ce=11.725478391145405
Local test acc @ epoch 43: 0.4537
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.00029094197088852525
Local loss @ local epoch 1: 0.000525930430740118
Local loss @ local epoch 2: 7.597711373819038e-05
Local loss @ local epoch 3: 8.284217619802803e-05
Local loss @ local epoch 4: 0.003229884896427393
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.76 seconds!
[tester] 
AGNewsMetric: acc=0.7969736842105263, hinge=1.4085221744838514, ce=5.800534876773232
Local test acc @ epoch 43: 0.797
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.41188403964042664
Local loss @ local epoch 1: 0.0009617297328077257
Local loss @ local epoch 2: 0.008453558199107647
Local loss @ local epoch 3: 0.006093011703342199
Local loss @ local epoch 4: 0.011439434252679348
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.65 seconds!
[tester] 
AGNewsMetric: acc=0.45881578947368423, hinge=6.59195635494433, ce=10.113997023733038
Local test acc @ epoch 43: 0.4588
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.006881563924252987
Local loss @ local epoch 1: 0.0036047492176294327
Local loss @ local epoch 2: 0.007195340935140848
Local loss @ local epoch 3: 0.042764484882354736
Local loss @ local epoch 4: 0.126051664352417
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.91 seconds!
[tester] 
AGNewsMetric: acc=0.8017105263157894, hinge=1.337876740003887, ce=4.449642328965036
Local test acc @ epoch 43: 0.8017
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.008807654492557049
Local loss @ local epoch 1: 0.00403114827349782
Local loss @ local epoch 2: 0.005264757666736841
Local loss @ local epoch 3: 0.001894109882414341
Local loss @ local epoch 4: 0.014504526741802692
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.04 seconds!
[tester] 
AGNewsMetric: acc=0.5626315789473684, hinge=3.4936051393810073, ce=11.282961959838866
Local test acc @ epoch 43: 0.5626
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.5924029350280762
Local loss @ local epoch 1: 0.19071431457996368
Local loss @ local epoch 2: 0.22790589928627014
Local loss @ local epoch 3: 0.06130575016140938
Local loss @ local epoch 4: 0.06780622154474258
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.66 seconds!
[tester] 
AGNewsMetric: acc=0.7097368421052631, hinge=2.3507806060188696, ce=10.93458261590255
Local test acc @ epoch 43: 0.7097
Global evaluate on test data...
Evaluate data in 123.33 seconds!
[tester] 
AGNewsMetric: acc=0.8639473684210527, hinge=0.8662298985531456, ce=10.796660730462325
Global test acc @ epoch 43: 0.8639
Global epoch 44...
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.06370922923088074
Local loss @ local epoch 1: 0.0003202895459253341
Local loss @ local epoch 2: 1.0392680451332126e-05
Local loss @ local epoch 3: 2.2464733774540946e-05
Local loss @ local epoch 4: 8.203674042306375e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.55 seconds!
[tester] 
AGNewsMetric: acc=0.2625, hinge=15.447385631360506, ce=13.190525858025802
Local test acc @ epoch 44: 0.2625
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.8138492703437805
Local loss @ local epoch 1: 1.077040195465088
Local loss @ local epoch 2: 0.023300878703594208
Local loss @ local epoch 3: 0.10121684521436691
Local loss @ local epoch 4: 0.1964746117591858
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.15 seconds!
[tester] 
AGNewsMetric: acc=0.8596052631578948, hinge=0.9398161985999659, ce=9.903451042175293
Local test acc @ epoch 44: 0.8596
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.003521610051393509
Local loss @ local epoch 1: 0.00402832729741931
Local loss @ local epoch 2: 0.0010918467305600643
Local loss @ local epoch 3: 0.0012104379711672664
Local loss @ local epoch 4: 0.02002907730638981
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.91 seconds!
[tester] 
AGNewsMetric: acc=0.7551315789473684, hinge=1.938402849498548, ce=7.302624209554572
Local test acc @ epoch 44: 0.7551
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.10290353000164032
Local loss @ local epoch 1: 0.15348981320858002
Local loss @ local epoch 2: 0.051055606454610825
Local loss @ local epoch 3: 0.14787200093269348
Local loss @ local epoch 4: 0.04497775062918663
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.11 seconds!
[tester] 
AGNewsMetric: acc=0.7621052631578947, hinge=1.6252412494860198, ce=5.1202488909269634
Local test acc @ epoch 44: 0.7621
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.22203020751476288
Local loss @ local epoch 1: 0.009522286243736744
Local loss @ local epoch 2: 0.0581338107585907
Local loss @ local epoch 3: 0.07038746029138565
Local loss @ local epoch 4: 0.05899439752101898
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.81 seconds!
[tester] 
AGNewsMetric: acc=0.6393421052631579, hinge=2.2021250162626567, ce=3.965795613339073
Local test acc @ epoch 44: 0.6393
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.26621291041374207
Local loss @ local epoch 1: 0.0015689049614593387
Local loss @ local epoch 2: 0.00021803179697599262
Local loss @ local epoch 3: 0.003223717212677002
Local loss @ local epoch 4: 0.0007380899623967707
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.85 seconds!
[tester] 
AGNewsMetric: acc=0.4440789473684211, hinge=12.030083781041597, ce=11.051668781481292
Local test acc @ epoch 44: 0.4441
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0017817100742831826
Local loss @ local epoch 1: 3.180413114023395e-05
Local loss @ local epoch 2: 1.6259869880741462e-05
Local loss @ local epoch 3: 3.604769517551176e-05
Local loss @ local epoch 4: 8.043494017329067e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.65 seconds!
[tester] 
AGNewsMetric: acc=0.44473684210526315, hinge=7.201477019661351, ce=12.750449128401907
Local test acc @ epoch 44: 0.4447
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.12592311203479767
Local loss @ local epoch 1: 0.046718161553144455
Local loss @ local epoch 2: 0.024372773244976997
Local loss @ local epoch 3: 0.03895450755953789
Local loss @ local epoch 4: 0.009294974617660046
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.22 seconds!
[tester] 
AGNewsMetric: acc=0.7107894736842105, hinge=2.042006015024687, ce=11.790307550932232
Local test acc @ epoch 44: 0.7108
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.563892662525177
Local loss @ local epoch 1: 0.06898225843906403
Local loss @ local epoch 2: 0.0032064360566437244
Local loss @ local epoch 3: 0.0075783575884997845
Local loss @ local epoch 4: 0.03666560351848602
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.62 seconds!
[tester] 
AGNewsMetric: acc=0.5507894736842105, hinge=3.614940618715788, ce=11.257976495843184
Local test acc @ epoch 44: 0.5508
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.606131911277771
Local loss @ local epoch 1: 0.005728621501475573
Local loss @ local epoch 2: 0.0067844511941075325
Local loss @ local epoch 3: 0.012867266312241554
Local loss @ local epoch 4: 0.0020980879198759794
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.48 seconds!
[tester] 
AGNewsMetric: acc=0.5059210526315789, hinge=4.0451570581134995, ce=9.445903163709138
Local test acc @ epoch 44: 0.5059
Global evaluate on test data...
Evaluate data in 123.98 seconds!
[tester] 
AGNewsMetric: acc=0.8796052631578948, hinge=0.8768876806058382, ce=10.297253721136796
Global test acc @ epoch 44: 0.8796
Global epoch 45...
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.003586485981941223
Local loss @ local epoch 1: 0.0009809312177821994
Local loss @ local epoch 2: 0.004252118058502674
Local loss @ local epoch 3: 0.013543201610445976
Local loss @ local epoch 4: 0.0015322007238864899
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.71 seconds!
[tester] 
AGNewsMetric: acc=0.6761842105263158, hinge=2.1944899488750256, ce=11.511109426398026
Local test acc @ epoch 45: 0.6762
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.5320106148719788
Local loss @ local epoch 1: 0.0009129922837018967
Local loss @ local epoch 2: 0.0011316450545564294
Local loss @ local epoch 3: 0.8199615478515625
Local loss @ local epoch 4: 0.0018171383999288082
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.11 seconds!
[tester] 
AGNewsMetric: acc=0.4747368421052632, hinge=8.92368493331106, ce=11.428762628655685
Local test acc @ epoch 45: 0.4747
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.4526786804199219
Local loss @ local epoch 1: 0.6429796814918518
Local loss @ local epoch 2: 0.391448974609375
Local loss @ local epoch 3: 0.25389397144317627
Local loss @ local epoch 4: 0.05256007984280586
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.85 seconds!
[tester] 
AGNewsMetric: acc=0.8397368421052631, hinge=1.1013951301574707, ce=10.057316446806254
Local test acc @ epoch 45: 0.8397
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.013508521020412445
Local loss @ local epoch 1: 0.0046925973147153854
Local loss @ local epoch 2: 0.04853829741477966
Local loss @ local epoch 3: 0.0036307666450738907
Local loss @ local epoch 4: 0.0017582494765520096
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.06 seconds!
[tester] 
AGNewsMetric: acc=0.5815789473684211, hinge=3.3744520247609993, ce=8.074783700641833
Local test acc @ epoch 45: 0.5816
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.9437679052352905
Local loss @ local epoch 1: 0.15795651078224182
Local loss @ local epoch 2: 0.014294778928160667
Local loss @ local epoch 3: 0.009713079780340195
Local loss @ local epoch 4: 0.02332579344511032
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.98 seconds!
[tester] 
AGNewsMetric: acc=0.5785526315789473, hinge=3.183595659858302, ce=8.532034402144582
Local test acc @ epoch 45: 0.5786
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.26624080538749695
Local loss @ local epoch 1: 0.12344308942556381
Local loss @ local epoch 2: 0.1908813863992691
Local loss @ local epoch 3: 0.17598856985569
Local loss @ local epoch 4: 0.13831478357315063
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.01 seconds!
[tester] 
AGNewsMetric: acc=0.7438157894736842, hinge=1.8694340537723741, ce=4.6706975956967005
Local test acc @ epoch 45: 0.7438
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.2892007529735565
Local loss @ local epoch 1: 0.0003532969858497381
Local loss @ local epoch 2: 0.00012367799354251474
Local loss @ local epoch 3: 0.0006908237701281905
Local loss @ local epoch 4: 0.0005179276340641081
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 125.42 seconds!
[tester] 
AGNewsMetric: acc=0.3718421052631579, hinge=9.614898627933703, ce=13.253342987863642
Local test acc @ epoch 45: 0.3718
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.011541754938662052
Local loss @ local epoch 1: 1.2111575415474363e-05
Local loss @ local epoch 2: 0.00029662257293239236
Local loss @ local epoch 3: 0.00036158220609650016
Local loss @ local epoch 4: 0.031116127967834473
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 125.15 seconds!
[tester] 
AGNewsMetric: acc=0.42828947368421055, hinge=8.283810033296284, ce=13.302550751535517
Local test acc @ epoch 45: 0.4283
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.06372876465320587
Local loss @ local epoch 1: 0.02295711077749729
Local loss @ local epoch 2: 0.0010317928390577435
Local loss @ local epoch 3: 0.004005828872323036
Local loss @ local epoch 4: 0.004412871785461903
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.62 seconds!
[tester] 
AGNewsMetric: acc=0.7381578947368421, hinge=1.8590795012524253, ce=9.078776971917403
Local test acc @ epoch 45: 0.7382
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.316912293434143
Local loss @ local epoch 1: 0.2817736566066742
Local loss @ local epoch 2: 0.049043215811252594
Local loss @ local epoch 3: 0.015606412664055824
Local loss @ local epoch 4: 0.09639205783605576
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.12 seconds!
[tester] 
AGNewsMetric: acc=0.4243421052631579, hinge=4.943895951823184, ce=10.976982413844059
Local test acc @ epoch 45: 0.4243
Global evaluate on test data...
Evaluate data in 124.38 seconds!
[tester] 
AGNewsMetric: acc=0.8718421052631579, hinge=0.9013293677882145, ce=9.973523192154733
Global test acc @ epoch 45: 0.8718
Global epoch 46...
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.177688330411911
Local loss @ local epoch 1: 0.3517705500125885
Local loss @ local epoch 2: 0.046820759773254395
Local loss @ local epoch 3: 0.05111456662416458
Local loss @ local epoch 4: 0.028716513887047768
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.57 seconds!
[tester] 
AGNewsMetric: acc=0.7419736842105263, hinge=1.7451575600473503, ce=4.323656968568501
Local test acc @ epoch 46: 0.742
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.5607525110244751
Local loss @ local epoch 1: 0.03748089447617531
Local loss @ local epoch 2: 0.004709966015070677
Local loss @ local epoch 3: 0.021400906145572662
Local loss @ local epoch 4: 0.017512142658233643
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.55 seconds!
[tester] 
AGNewsMetric: acc=0.516578947368421, hinge=3.905402795892013, ce=7.32791037910863
Local test acc @ epoch 46: 0.5166
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.07074248790740967
Local loss @ local epoch 1: 0.3825000822544098
Local loss @ local epoch 2: 0.013255852274596691
Local loss @ local epoch 3: 0.002632724354043603
Local loss @ local epoch 4: 0.004641884472221136
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.64 seconds!
[tester] 
AGNewsMetric: acc=0.6460526315789473, hinge=2.7351385600943314, ce=10.39856634842722
Local test acc @ epoch 46: 0.6461
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.15517665445804596
Local loss @ local epoch 1: 0.38040944933891296
Local loss @ local epoch 2: 0.03209152817726135
Local loss @ local epoch 3: 0.04515654966235161
Local loss @ local epoch 4: 0.015967635437846184
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 122.77 seconds!
[tester] 
AGNewsMetric: acc=0.8489473684210527, hinge=1.0563496562054282, ce=6.034897079467774
Local test acc @ epoch 46: 0.8489
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0002616753336042166
Local loss @ local epoch 1: 0.007072288077324629
Local loss @ local epoch 2: 0.00536538939923048
Local loss @ local epoch 3: 0.0008559508714824915
Local loss @ local epoch 4: 0.0006965184002183378
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.46 seconds!
[tester] 
AGNewsMetric: acc=0.7698684210526315, hinge=1.7030814936286525, ce=9.66575173428184
Local test acc @ epoch 46: 0.7699
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0905730202794075
Local loss @ local epoch 1: 0.0005355898174457252
Local loss @ local epoch 2: 0.003193137003108859
Local loss @ local epoch 3: 0.22574275732040405
Local loss @ local epoch 4: 0.0003148964897263795
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.08 seconds!
[tester] 
AGNewsMetric: acc=0.5776315789473684, hinge=4.303614368438721, ce=11.229573922408255
Local test acc @ epoch 46: 0.5776
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.6211537718772888
Local loss @ local epoch 1: 0.3490002453327179
Local loss @ local epoch 2: 0.02763301692903042
Local loss @ local epoch 3: 0.005036700516939163
Local loss @ local epoch 4: 0.019239190965890884
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.92 seconds!
[tester] 
AGNewsMetric: acc=0.4123684210526316, hinge=5.791530725579513, ce=11.351962001198217
Local test acc @ epoch 46: 0.4124
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0009924500482156873
Local loss @ local epoch 1: 0.0010204857680946589
Local loss @ local epoch 2: 8.10619349067565e-06
Local loss @ local epoch 3: 0.00022201791580300778
Local loss @ local epoch 4: 0.0008247917285189033
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.99 seconds!
[tester] 
AGNewsMetric: acc=0.7927631578947368, hinge=1.4926366545024672, ce=4.730123844146728
Local test acc @ epoch 46: 0.7928
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.3991447389125824
Local loss @ local epoch 1: 0.00024235184537246823
Local loss @ local epoch 2: 6.654885510215536e-05
Local loss @ local epoch 3: 0.003301256336271763
Local loss @ local epoch 4: 0.11121836304664612
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.71 seconds!
[tester] 
AGNewsMetric: acc=0.29697368421052633, hinge=11.783076541298314, ce=12.308466557954487
Local test acc @ epoch 46: 0.297
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.6642835140228271
Local loss @ local epoch 1: 0.09606129676103592
Local loss @ local epoch 2: 0.5531802773475647
Local loss @ local epoch 3: 0.5287250876426697
Local loss @ local epoch 4: 0.0824640765786171
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.89 seconds!
[tester] 
AGNewsMetric: acc=0.7431578947368421, hinge=1.9082012563002737, ce=11.459852704499896
Local test acc @ epoch 46: 0.7432
Global evaluate on test data...
Evaluate data in 125.51 seconds!
[tester] 
AGNewsMetric: acc=0.8722368421052632, hinge=0.8736705125005622, ce=11.027638447410181
Global test acc @ epoch 46: 0.8722
Global epoch 47...
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0005305910599417984
Local loss @ local epoch 1: 9.059902481567406e-07
Local loss @ local epoch 2: 0.00039248555549420416
Local loss @ local epoch 3: 6.0792401200160384e-05
Local loss @ local epoch 4: 0.013192981481552124
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.13 seconds!
[tester] 
AGNewsMetric: acc=0.5518421052631579, hinge=4.59119781218077, ce=8.474180186422247
Local test acc @ epoch 47: 0.5518
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.5231632590293884
Local loss @ local epoch 1: 0.014378857798874378
Local loss @ local epoch 2: 0.0004890603595413268
Local loss @ local epoch 3: 0.00012717218487523496
Local loss @ local epoch 4: 0.002200118964537978
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.67 seconds!
[tester] 
AGNewsMetric: acc=0.34789473684210526, hinge=10.13436728728445, ce=11.537118251198217
Local test acc @ epoch 47: 0.3479
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.10795852541923523
Local loss @ local epoch 1: 0.004766890313476324
Local loss @ local epoch 2: 0.0352555587887764
Local loss @ local epoch 3: 0.007130837067961693
Local loss @ local epoch 4: 0.0057600196450948715
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.82 seconds!
[tester] 
AGNewsMetric: acc=0.7811842105263158, hinge=1.6341906273992437, ce=9.036093729922646
Local test acc @ epoch 47: 0.7812
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.02200736291706562
Local loss @ local epoch 1: 0.0030750075820833445
Local loss @ local epoch 2: 0.015257067047059536
Local loss @ local epoch 3: 0.0007477554026991129
Local loss @ local epoch 4: 0.03667323291301727
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.17 seconds!
[tester] 
AGNewsMetric: acc=0.5135526315789474, hinge=3.2755098418185584, ce=11.316709745306717
Local test acc @ epoch 47: 0.5136
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.5813025832176208
Local loss @ local epoch 1: 0.4476338326931
Local loss @ local epoch 2: 0.020236458629369736
Local loss @ local epoch 3: 0.009771403856575489
Local loss @ local epoch 4: 0.0017610875656828284
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.02 seconds!
[tester] 
AGNewsMetric: acc=0.4975, hinge=3.5037113631399053, ce=11.070632587232089
Local test acc @ epoch 47: 0.4975
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.6768178939819336
Local loss @ local epoch 1: 0.07130409777164459
Local loss @ local epoch 2: 0.020036116242408752
Local loss @ local epoch 3: 0.006155082955956459
Local loss @ local epoch 4: 0.1437634974718094
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 125.03 seconds!
[tester] 
AGNewsMetric: acc=0.325, hinge=8.122746836009778, ce=13.557861773842259
Local test acc @ epoch 47: 0.325
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.006953943986445665
Local loss @ local epoch 1: 0.000585519359447062
Local loss @ local epoch 2: 0.005433231592178345
Local loss @ local epoch 3: 0.0036543174646794796
Local loss @ local epoch 4: 0.0014604346361011267
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 125.01 seconds!
[tester] 
AGNewsMetric: acc=0.7310526315789474, hinge=1.9541143216584858, ce=5.16165749198512
Local test acc @ epoch 47: 0.7311
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.5924904346466064
Local loss @ local epoch 1: 0.3140922784805298
Local loss @ local epoch 2: 0.5257622003555298
Local loss @ local epoch 3: 0.21133945882320404
Local loss @ local epoch 4: 0.08785513043403625
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.52 seconds!
[tester] 
AGNewsMetric: acc=0.7609210526315789, hinge=1.5253530005404823, ce=8.917181085285387
Local test acc @ epoch 47: 0.7609
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.09559755772352219
Local loss @ local epoch 1: 0.7645422220230103
Local loss @ local epoch 2: 0.49203136563301086
Local loss @ local epoch 3: 0.19743017852306366
Local loss @ local epoch 4: 0.2010786086320877
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.63 seconds!
[tester] 
AGNewsMetric: acc=0.7519736842105263, hinge=1.7478973077472888, ce=4.150329054782265
Local test acc @ epoch 47: 0.752
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.3221564292907715
Local loss @ local epoch 1: 0.016388412564992905
Local loss @ local epoch 2: 0.0018680227221921086
Local loss @ local epoch 3: 0.00965939275920391
Local loss @ local epoch 4: 0.006274971645325422
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.06 seconds!
[tester] 
AGNewsMetric: acc=0.4568421052631579, hinge=5.053043624476382, ce=9.640697519402755
Local test acc @ epoch 47: 0.4568
Global evaluate on test data...
Evaluate data in 124.29 seconds!
[tester] 
AGNewsMetric: acc=0.8522368421052632, hinge=1.0032321397881758, ce=10.422498010334216
Global test acc @ epoch 47: 0.8522
Global epoch 48...
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.15190620720386505
Local loss @ local epoch 1: 0.0002736773749347776
Local loss @ local epoch 2: 0.007008156273514032
Local loss @ local epoch 3: 0.00024808410671539605
Local loss @ local epoch 4: 0.0006613333825953305
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.22 seconds!
[tester] 
AGNewsMetric: acc=0.4785526315789474, hinge=9.74308899101458, ce=11.416918682299162
Local test acc @ epoch 48: 0.4786
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.15066172182559967
Local loss @ local epoch 1: 0.013108320534229279
Local loss @ local epoch 2: 0.024648940190672874
Local loss @ local epoch 3: 0.009607515297830105
Local loss @ local epoch 4: 0.016226043924689293
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.71 seconds!
[tester] 
AGNewsMetric: acc=0.7314473684210526, hinge=1.9010600596980045, ce=10.552933889690198
Local test acc @ epoch 48: 0.7314
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.5027855038642883
Local loss @ local epoch 1: 0.08719181269407272
Local loss @ local epoch 2: 0.0028359279967844486
Local loss @ local epoch 3: 0.12274358421564102
Local loss @ local epoch 4: 0.01594354771077633
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 125.0 seconds!
[tester] 
AGNewsMetric: acc=0.5344736842105263, hinge=3.4385052791394686, ce=8.63751785880641
Local test acc @ epoch 48: 0.5345
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.14276538789272308
Local loss @ local epoch 1: 0.00013734438107348979
Local loss @ local epoch 2: 0.00014550330524798483
Local loss @ local epoch 3: 1.0501153155928478e-05
Local loss @ local epoch 4: 5.369340942706913e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.59 seconds!
[tester] 
AGNewsMetric: acc=0.2885526315789474, hinge=12.381426407663445, ce=14.564685150949579
Local test acc @ epoch 48: 0.2886
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.41209620237350464
Local loss @ local epoch 1: 0.0011839312501251698
Local loss @ local epoch 2: 0.003718135878443718
Local loss @ local epoch 3: 0.009698440320789814
Local loss @ local epoch 4: 0.11455749720335007
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.38 seconds!
[tester] 
AGNewsMetric: acc=0.4867105263157895, hinge=4.974441468590184, ce=7.000947391108463
Local test acc @ epoch 48: 0.4867
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0008481086697429419
Local loss @ local epoch 1: 0.0006575689767487347
Local loss @ local epoch 2: 0.005332643631845713
Local loss @ local epoch 3: 0.007926634512841702
Local loss @ local epoch 4: 0.0048776171170175076
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.43 seconds!
[tester] 
AGNewsMetric: acc=0.7596052631578948, hinge=2.1307785079353736, ce=6.099488790411698
Local test acc @ epoch 48: 0.7596
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 5.4664600611431524e-05
Local loss @ local epoch 1: 0.0038083880208432674
Local loss @ local epoch 2: 0.0022372142411768436
Local loss @ local epoch 3: 0.0002194578992202878
Local loss @ local epoch 4: 0.00030606676591560245
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.29 seconds!
[tester] 
AGNewsMetric: acc=0.574078947368421, hinge=3.904426132001375, ce=4.948149071743614
Local test acc @ epoch 48: 0.5741
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.22869394719600677
Local loss @ local epoch 1: 0.029477493837475777
Local loss @ local epoch 2: 0.015752356499433517
Local loss @ local epoch 3: 0.0009859985439106822
Local loss @ local epoch 4: 0.0042169406078755856
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.74 seconds!
[tester] 
AGNewsMetric: acc=0.8463157894736842, hinge=1.2538874560908266, ce=11.029696486623664
Local test acc @ epoch 48: 0.8463
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.23225706815719604
Local loss @ local epoch 1: 1.086442232131958
Local loss @ local epoch 2: 0.3002701997756958
Local loss @ local epoch 3: 0.5098701119422913
Local loss @ local epoch 4: 0.6745800971984863
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.8 seconds!
[tester] 
AGNewsMetric: acc=0.8478947368421053, hinge=0.9905138397216797, ce=9.942190166272615
Local test acc @ epoch 48: 0.8479
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.092289999127388
Local loss @ local epoch 1: 0.3425464928150177
Local loss @ local epoch 2: 0.09436533600091934
Local loss @ local epoch 3: 0.053071726113557816
Local loss @ local epoch 4: 0.010894713923335075
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.59 seconds!
[tester] 
AGNewsMetric: acc=0.6993421052631579, hinge=2.0921718988920515, ce=6.627397055374948
Local test acc @ epoch 48: 0.6993
Global evaluate on test data...
Evaluate data in 124.21 seconds!
[tester] 
AGNewsMetric: acc=0.8468421052631578, hinge=1.1657056278931468, ce=10.899969466359991
Global test acc @ epoch 48: 0.8468
Global epoch 49...
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.24759060144424438
Local loss @ local epoch 1: 0.013777985237538815
Local loss @ local epoch 2: 0.013736010529100895
Local loss @ local epoch 3: 0.005983773618936539
Local loss @ local epoch 4: 0.001968563301488757
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.29 seconds!
[tester] 
AGNewsMetric: acc=0.6801315789473684, hinge=2.440150936528256, ce=8.015666010003342
Local test acc @ epoch 49: 0.6801
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.03021908737719059
Local loss @ local epoch 1: 0.002817964879795909
Local loss @ local epoch 2: 0.0009143597562797368
Local loss @ local epoch 3: 0.0004044134693685919
Local loss @ local epoch 4: 0.0013259113766252995
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.19 seconds!
[tester] 
AGNewsMetric: acc=0.2822368421052632, hinge=7.535009123149671, ce=12.930134831478721
Local test acc @ epoch 49: 0.2822
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.026610825210809708
Local loss @ local epoch 1: 0.04732406511902809
Local loss @ local epoch 2: 1.1166397333145142
Local loss @ local epoch 3: 0.022018909454345703
Local loss @ local epoch 4: 0.34564462304115295
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.13 seconds!
[tester] 
AGNewsMetric: acc=0.7093421052631579, hinge=2.15598794836747, ce=10.716276174846449
Local test acc @ epoch 49: 0.7093
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 1.2638506889343262
Local loss @ local epoch 1: 0.34431374073028564
Local loss @ local epoch 2: 0.2572599947452545
Local loss @ local epoch 3: 0.6386379599571228
Local loss @ local epoch 4: 0.5922138094902039
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.93 seconds!
[tester] 
AGNewsMetric: acc=0.7082894736842106, hinge=1.9785096316588553, ce=8.891987342834472
Local test acc @ epoch 49: 0.7083
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.9364067316055298
Local loss @ local epoch 1: 0.002418716438114643
Local loss @ local epoch 2: 0.0001446209498681128
Local loss @ local epoch 3: 9.838968253461644e-05
Local loss @ local epoch 4: 0.00012175394658697769
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.03 seconds!
[tester] 
AGNewsMetric: acc=0.39263157894736844, hinge=9.653055036946347, ce=12.405261242515163
Local test acc @ epoch 49: 0.3926
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 1.027234673500061
Local loss @ local epoch 1: 0.10665874928236008
Local loss @ local epoch 2: 0.00803884956985712
Local loss @ local epoch 3: 0.0012146964436396956
Local loss @ local epoch 4: 0.02289787493646145
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.57 seconds!
[tester] 
AGNewsMetric: acc=0.38355263157894737, hinge=8.763157142338, ce=11.15094325216193
Local test acc @ epoch 49: 0.3836
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 4.338972576078959e-05
Local loss @ local epoch 1: 1.4376283616002183e-05
Local loss @ local epoch 2: 0.00011295522563159466
Local loss @ local epoch 3: 7.671142520848662e-05
Local loss @ local epoch 4: 0.0006362427375279367
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.35 seconds!
[tester] 
AGNewsMetric: acc=0.5682894736842106, hinge=4.176251966576827, ce=11.645486685100355
Local test acc @ epoch 49: 0.5683
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0004772256361320615
Local loss @ local epoch 1: 0.0038479510694742203
Local loss @ local epoch 2: 0.00846092775464058
Local loss @ local epoch 3: 0.00209262827411294
Local loss @ local epoch 4: 0.005442522931843996
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.78 seconds!
[tester] 
AGNewsMetric: acc=0.6852631578947368, hinge=2.9456429052352906, ce=10.10451894659745
Local test acc @ epoch 49: 0.6853
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.8230435848236084
Local loss @ local epoch 1: 0.255032479763031
Local loss @ local epoch 2: 0.0529804565012455
Local loss @ local epoch 3: 0.0424099937081337
Local loss @ local epoch 4: 0.05924569070339203
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.79 seconds!
[tester] 
AGNewsMetric: acc=0.45144736842105265, hinge=5.428551401339079, ce=9.50842290376362
Local test acc @ epoch 49: 0.4514
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.4910300374031067
Local loss @ local epoch 1: 0.15172626078128815
Local loss @ local epoch 2: 0.009907353669404984
Local loss @ local epoch 3: 0.004923564847558737
Local loss @ local epoch 4: 0.006286948919296265
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.97 seconds!
[tester] 
AGNewsMetric: acc=0.485, hinge=4.251066802175422, ce=7.930120578565096
Local test acc @ epoch 49: 0.485
Global evaluate on test data...
Evaluate data in 123.26 seconds!
[tester] 
AGNewsMetric: acc=0.834078947368421, hinge=1.19453697681427, ce=10.729153046858938
Global test acc @ epoch 49: 0.8341
Global epoch 50...
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 1.4338932037353516
Local loss @ local epoch 1: 0.052524957805871964
Local loss @ local epoch 2: 0.059159379452466965
Local loss @ local epoch 3: 0.00942597258836031
Local loss @ local epoch 4: 0.01786421798169613
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.4 seconds!
[tester] 
AGNewsMetric: acc=0.5498684210526316, hinge=3.7356808918400817, ce=8.263678372031764
Local test acc @ epoch 50: 0.5499
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.04450437054038048
Local loss @ local epoch 1: 0.001490080147050321
Local loss @ local epoch 2: 0.0026289692614227533
Local loss @ local epoch 3: 0.05372518301010132
Local loss @ local epoch 4: 0.0006589723634533584
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.23 seconds!
[tester] 
AGNewsMetric: acc=0.5018421052631579, hinge=6.864851487310309, ce=10.162363777160644
Local test acc @ epoch 50: 0.5018
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.2120895385742188
Local loss @ local epoch 1: 0.18167129158973694
Local loss @ local epoch 2: 0.002609612885862589
Local loss @ local epoch 3: 0.017277922481298447
Local loss @ local epoch 4: 0.03194558620452881
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.08 seconds!
[tester] 
AGNewsMetric: acc=0.3944736842105263, hinge=7.294119357058876, ce=12.507170653092233
Local test acc @ epoch 50: 0.3945
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.2219698578119278
Local loss @ local epoch 1: 1.4506096839904785
Local loss @ local epoch 2: 0.2586255371570587
Local loss @ local epoch 3: 0.2674753665924072
Local loss @ local epoch 4: 0.27403703331947327
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.28 seconds!
[tester] 
AGNewsMetric: acc=0.8671052631578947, hinge=0.9258130849035162, ce=9.501594095732036
Local test acc @ epoch 50: 0.8671
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.012307992205023766
Local loss @ local epoch 1: 0.001152126002125442
Local loss @ local epoch 2: 0.007039431482553482
Local loss @ local epoch 3: 0.008056867867708206
Local loss @ local epoch 4: 0.0015027583576738834
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.75 seconds!
[tester] 
AGNewsMetric: acc=0.8039473684210526, hinge=1.3229932288119668, ce=4.913601898394133
Local test acc @ epoch 50: 0.8039
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.01229079719632864
Local loss @ local epoch 1: 7.777336577419192e-05
Local loss @ local epoch 2: 3.6996687413193285e-05
Local loss @ local epoch 3: 7.133531471481547e-05
Local loss @ local epoch 4: 2.3234433683683164e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.83 seconds!
[tester] 
AGNewsMetric: acc=0.3111842105263158, hinge=12.947030879572818, ce=11.694175886856883
Local test acc @ epoch 50: 0.3112
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.107757568359375
Local loss @ local epoch 1: 0.015608556568622589
Local loss @ local epoch 2: 0.007842517457902431
Local loss @ local epoch 3: 0.0025734850205481052
Local loss @ local epoch 4: 0.0020978006068617105
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.73 seconds!
[tester] 
AGNewsMetric: acc=0.6875, hinge=2.030886319311042, ce=7.9657833360370836
Local test acc @ epoch 50: 0.6875
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.006572717800736427
Local loss @ local epoch 1: 0.3318215310573578
Local loss @ local epoch 2: 0.022398116067051888
Local loss @ local epoch 3: 0.005313338246196508
Local loss @ local epoch 4: 0.033791471272706985
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.68 seconds!
[tester] 
AGNewsMetric: acc=0.8664473684210526, hinge=0.9670167948070325, ce=10.735772225229363
Local test acc @ epoch 50: 0.8664
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.00034973473520949483
Local loss @ local epoch 1: 0.0011117847170680761
Local loss @ local epoch 2: 0.0015279517974704504
Local loss @ local epoch 3: 0.0022541838698089123
Local loss @ local epoch 4: 0.036563314497470856
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.43 seconds!
[tester] 
AGNewsMetric: acc=0.5830263157894737, hinge=3.86537555945547, ce=9.865534714146664
Local test acc @ epoch 50: 0.583
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.06701205670833588
Local loss @ local epoch 1: 0.3586025536060333
Local loss @ local epoch 2: 0.3377705216407776
Local loss @ local epoch 3: 0.2015979290008545
Local loss @ local epoch 4: 0.19925697147846222
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.01 seconds!
[tester] 
AGNewsMetric: acc=0.7215789473684211, hinge=1.8630508287329424, ce=4.031031031357615
Local test acc @ epoch 50: 0.7216
Global evaluate on test data...
Evaluate data in 123.85 seconds!
[tester] 
AGNewsMetric: acc=0.8378947368421052, hinge=1.096761033911454, ce=10.322845378674959
Global test acc @ epoch 50: 0.8379
Global epoch 51...
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 1.3539457321166992
Local loss @ local epoch 1: 0.05471199378371239
Local loss @ local epoch 2: 0.0038496218621730804
Local loss @ local epoch 3: 0.0007656167726963758
Local loss @ local epoch 4: 0.0005130671197548509
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.26 seconds!
[tester] 
AGNewsMetric: acc=0.4859210526315789, hinge=7.633560550338344, ce=12.026697016264263
Local test acc @ epoch 51: 0.4859
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 8.980794518720359e-05
Local loss @ local epoch 1: 0.007158788852393627
Local loss @ local epoch 2: 2.560555367381312e-05
Local loss @ local epoch 3: 0.0004113468457944691
Local loss @ local epoch 4: 2.54382575803902e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.94 seconds!
[tester] 
AGNewsMetric: acc=0.6043421052631579, hinge=5.294451025912636, ce=11.737255437750566
Local test acc @ epoch 51: 0.6043
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.06626494228839874
Local loss @ local epoch 1: 0.3941975235939026
Local loss @ local epoch 2: 0.2580074965953827
Local loss @ local epoch 3: 0.295257568359375
Local loss @ local epoch 4: 0.02763788402080536
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.74 seconds!
[tester] 
AGNewsMetric: acc=0.7547368421052632, hinge=1.6812336314351934, ce=5.228425767798173
Local test acc @ epoch 51: 0.7547
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.2526766359806061
Local loss @ local epoch 1: 0.005735983606427908
Local loss @ local epoch 2: 0.0029671811498701572
Local loss @ local epoch 3: 0.04534811154007912
Local loss @ local epoch 4: 0.002969398396089673
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.32 seconds!
[tester] 
AGNewsMetric: acc=0.513421052631579, hinge=4.0079496920736215, ce=9.862468370136462
Local test acc @ epoch 51: 0.5134
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 1.630179762840271
Local loss @ local epoch 1: 0.2595672011375427
Local loss @ local epoch 2: 0.017462050542235374
Local loss @ local epoch 3: 0.001648915116675198
Local loss @ local epoch 4: 0.007543550804257393
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.47 seconds!
[tester] 
AGNewsMetric: acc=0.49473684210526314, hinge=8.952177933642739, ce=11.889525552046926
Local test acc @ epoch 51: 0.4947
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.5550394654273987
Local loss @ local epoch 1: 0.20650948584079742
Local loss @ local epoch 2: 0.008361712098121643
Local loss @ local epoch 3: 0.0018263546517118812
Local loss @ local epoch 4: 0.04262644425034523
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.24 seconds!
[tester] 
AGNewsMetric: acc=0.4256578947368421, hinge=5.691221306951422, ce=9.611960543582313
Local test acc @ epoch 51: 0.4257
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 1.9106414318084717
Local loss @ local epoch 1: 0.7442726492881775
Local loss @ local epoch 2: 0.2727762758731842
Local loss @ local epoch 3: 0.3128090500831604
Local loss @ local epoch 4: 0.23448562622070312
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.7 seconds!
[tester] 
AGNewsMetric: acc=0.7968421052631579, hinge=1.279638654809249, ce=9.352967573467053
Local test acc @ epoch 51: 0.7968
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.013022658415138721
Local loss @ local epoch 1: 0.00530778244137764
Local loss @ local epoch 2: 0.002671190770342946
Local loss @ local epoch 3: 0.001538680400699377
Local loss @ local epoch 4: 0.0016671080375090241
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.86 seconds!
[tester] 
AGNewsMetric: acc=0.5151315789473684, hinge=3.2582094413355778, ce=11.575884295011821
Local test acc @ epoch 51: 0.5151
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.006772394757717848
Local loss @ local epoch 1: 0.03578157350420952
Local loss @ local epoch 2: 0.0034750187769532204
Local loss @ local epoch 3: 0.021657977253198624
Local loss @ local epoch 4: 0.004527987912297249
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.66 seconds!
[tester] 
AGNewsMetric: acc=0.7530263157894737, hinge=2.105034874865883, ce=5.003596480520148
Local test acc @ epoch 51: 0.753
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.49022531509399414
Local loss @ local epoch 1: 0.09981150180101395
Local loss @ local epoch 2: 0.010348626412451267
Local loss @ local epoch 3: 0.008989001624286175
Local loss @ local epoch 4: 0.01261910516768694
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.84 seconds!
[tester] 
AGNewsMetric: acc=0.6835526315789474, hinge=2.2715329539148432, ce=7.847724800109863
Local test acc @ epoch 51: 0.6836
Global evaluate on test data...
Evaluate data in 123.9 seconds!
[tester] 
AGNewsMetric: acc=0.8589473684210527, hinge=1.173118408855639, ce=9.901284416600278
Global test acc @ epoch 51: 0.8589
Global epoch 52...
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.023284032940864563
Local loss @ local epoch 1: 0.015143752098083496
Local loss @ local epoch 2: 0.005669669713824987
Local loss @ local epoch 3: 0.003172393888235092
Local loss @ local epoch 4: 0.007212021853774786
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.67 seconds!
[tester] 
AGNewsMetric: acc=0.6553947368421053, hinge=2.491666701467414, ce=11.523199486983449
Local test acc @ epoch 52: 0.6554
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.5672607421875
Local loss @ local epoch 1: 0.5108014345169067
Local loss @ local epoch 2: 0.2622438669204712
Local loss @ local epoch 3: 0.14956052601337433
Local loss @ local epoch 4: 0.05884554982185364
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.87 seconds!
[tester] 
AGNewsMetric: acc=0.40078947368421053, hinge=4.675728856638858, ce=9.10531341753508
Local test acc @ epoch 52: 0.4008
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.012065496295690536
Local loss @ local epoch 1: 0.00045150984078645706
Local loss @ local epoch 2: 0.00010035768355010077
Local loss @ local epoch 3: 0.0016382228350266814
Local loss @ local epoch 4: 0.0015933442628011107
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.27 seconds!
[tester] 
AGNewsMetric: acc=0.4663157894736842, hinge=9.927205472494427, ce=10.280101174806294
Local test acc @ epoch 52: 0.4663
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.17339974641799927
Local loss @ local epoch 1: 0.012838910333812237
Local loss @ local epoch 2: 0.002194836735725403
Local loss @ local epoch 3: 0.14200402796268463
Local loss @ local epoch 4: 0.004180431365966797
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.71 seconds!
[tester] 
AGNewsMetric: acc=0.7951315789473684, hinge=1.5183014249801636, ce=11.572816200256348
Local test acc @ epoch 52: 0.7951
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.5609663128852844
Local loss @ local epoch 1: 0.18132580816745758
Local loss @ local epoch 2: 0.014200440607964993
Local loss @ local epoch 3: 0.07168521732091904
Local loss @ local epoch 4: 0.11704394966363907
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.39 seconds!
[tester] 
AGNewsMetric: acc=0.6789473684210526, hinge=2.3903629297959177, ce=7.8878410259046055
Local test acc @ epoch 52: 0.6789
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 8.05846502771601e-06
Local loss @ local epoch 1: 5.1351536967558786e-05
Local loss @ local epoch 2: 3.9457074308302253e-05
Local loss @ local epoch 3: 3.933892003260553e-06
Local loss @ local epoch 4: 1.759503902576398e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.54 seconds!
[tester] 
AGNewsMetric: acc=0.5281578947368422, hinge=5.682771113044337, ce=10.49647316380551
Local test acc @ epoch 52: 0.5282
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0622563399374485
Local loss @ local epoch 1: 0.00012562972551677376
Local loss @ local epoch 2: 0.0010766019113361835
Local loss @ local epoch 3: 0.0002263920323457569
Local loss @ local epoch 4: 0.002088916953653097
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.49 seconds!
[tester] 
AGNewsMetric: acc=0.32552631578947366, hinge=12.662090409931384, ce=14.258584466231497
Local test acc @ epoch 52: 0.3255
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0029385718517005444
Local loss @ local epoch 1: 0.00874355435371399
Local loss @ local epoch 2: 0.01488068699836731
Local loss @ local epoch 3: 0.006263132207095623
Local loss @ local epoch 4: 0.003484439104795456
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.69 seconds!
[tester] 
AGNewsMetric: acc=0.7978947368421052, hinge=1.497675378197118, ce=7.131997060273823
Local test acc @ epoch 52: 0.7979
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.30282357335090637
Local loss @ local epoch 1: 0.7039949893951416
Local loss @ local epoch 2: 0.16764234006404877
Local loss @ local epoch 3: 0.7169525027275085
Local loss @ local epoch 4: 0.14548473060131073
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.9 seconds!
[tester] 
AGNewsMetric: acc=0.783157894736842, hinge=1.4522339665262323, ce=10.342221013119346
Local test acc @ epoch 52: 0.7832
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 1.6483275890350342
Local loss @ local epoch 1: 0.16173700988292694
Local loss @ local epoch 2: 0.05205567181110382
Local loss @ local epoch 3: 0.022148609161376953
Local loss @ local epoch 4: 0.02000429481267929
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.3 seconds!
[tester] 
AGNewsMetric: acc=0.5197368421052632, hinge=3.8446019880395186, ce=8.270767372532895
Local test acc @ epoch 52: 0.5197
Global evaluate on test data...
Evaluate data in 124.39 seconds!
[tester] 
AGNewsMetric: acc=0.871578947368421, hinge=0.8537125359083477, ce=7.846998831096449
Global test acc @ epoch 52: 0.8716
Global epoch 53...
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.38525158166885376
Local loss @ local epoch 1: 0.00379439746029675
Local loss @ local epoch 2: 0.01524400059133768
Local loss @ local epoch 3: 0.008524730801582336
Local loss @ local epoch 4: 0.007372085936367512
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.5 seconds!
[tester] 
AGNewsMetric: acc=0.48697368421052634, hinge=4.128333409961901, ce=7.4744220803913315
Local test acc @ epoch 53: 0.487
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.2711685597896576
Local loss @ local epoch 1: 0.002949888352304697
Local loss @ local epoch 2: 7.404784992104396e-05
Local loss @ local epoch 3: 5.4735901358071715e-05
Local loss @ local epoch 4: 6.783352000638843e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.69 seconds!
[tester] 
AGNewsMetric: acc=0.3335526315789474, hinge=11.31742096649973, ce=11.437553325452303
Local test acc @ epoch 53: 0.3336
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.019882094115018845
Local loss @ local epoch 1: 0.0005890631582587957
Local loss @ local epoch 2: 0.0010345079936087132
Local loss @ local epoch 3: 0.37259113788604736
Local loss @ local epoch 4: 0.0016050664708018303
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.72 seconds!
[tester] 
AGNewsMetric: acc=0.6309210526315789, hinge=2.8566986949820268, ce=8.317330187747354
Local test acc @ epoch 53: 0.6309
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.14684899151325226
Local loss @ local epoch 1: 0.12502892315387726
Local loss @ local epoch 2: 0.4351342022418976
Local loss @ local epoch 3: 0.0681939348578453
Local loss @ local epoch 4: 0.08261847496032715
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.07 seconds!
[tester] 
AGNewsMetric: acc=0.7182894736842105, hinge=1.925377822675203, ce=6.984936840659693
Local test acc @ epoch 53: 0.7183
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.9653146266937256
Local loss @ local epoch 1: 0.1445971578359604
Local loss @ local epoch 2: 0.08725666999816895
Local loss @ local epoch 3: 0.24344739317893982
Local loss @ local epoch 4: 0.7378938794136047
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.98 seconds!
[tester] 
AGNewsMetric: acc=0.6572368421052631, hinge=2.582690994363082, ce=10.272291203549035
Local test acc @ epoch 53: 0.6572
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.6662116646766663
Local loss @ local epoch 1: 0.07690297067165375
Local loss @ local epoch 2: 0.04055292159318924
Local loss @ local epoch 3: 0.0036009391769766808
Local loss @ local epoch 4: 0.0016264179721474648
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.23 seconds!
[tester] 
AGNewsMetric: acc=0.46907894736842104, hinge=4.925730999394467, ce=8.125991344451904
Local test acc @ epoch 53: 0.4691
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.5713834762573242
Local loss @ local epoch 1: 0.017325708642601967
Local loss @ local epoch 2: 0.0026259853038936853
Local loss @ local epoch 3: 0.0006942297914065421
Local loss @ local epoch 4: 0.44763147830963135
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.84 seconds!
[tester] 
AGNewsMetric: acc=0.4490789473684211, hinge=8.093878477247138, ce=11.67085997330515
Local test acc @ epoch 53: 0.4491
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0005865342682227492
Local loss @ local epoch 1: 0.00040095578879117966
Local loss @ local epoch 2: 2.9276974601089023e-05
Local loss @ local epoch 3: 0.00012043953029206023
Local loss @ local epoch 4: 1.5592313502565958e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 125.15 seconds!
[tester] 
AGNewsMetric: acc=0.5090789473684211, hinge=5.509376893796419, ce=12.553769547311884
Local test acc @ epoch 53: 0.5091
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.025446275249123573
Local loss @ local epoch 1: 0.0020378390327095985
Local loss @ local epoch 2: 0.004081603139638901
Local loss @ local epoch 3: 0.012713166885077953
Local loss @ local epoch 4: 0.008451358415186405
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.71 seconds!
[tester] 
AGNewsMetric: acc=0.6643421052631578, hinge=2.5819487222872284, ce=10.798916087903475
Local test acc @ epoch 53: 0.6643
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.184498131275177
Local loss @ local epoch 1: 0.003218909027054906
Local loss @ local epoch 2: 0.007755551487207413
Local loss @ local epoch 3: 0.00656437361612916
Local loss @ local epoch 4: 0.00661875493824482
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 125.02 seconds!
[tester] 
AGNewsMetric: acc=0.6103947368421052, hinge=3.351672242315192, ce=12.54516207243267
Local test acc @ epoch 53: 0.6104
Global evaluate on test data...
Evaluate data in 123.58 seconds!
[tester] 
AGNewsMetric: acc=0.875, hinge=0.980177398480867, ce=9.646728417245965
Global test acc @ epoch 53: 0.875
Global epoch 54...
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.001645752927288413
Local loss @ local epoch 1: 0.01009897980839014
Local loss @ local epoch 2: 0.004085335414856672
Local loss @ local epoch 3: 0.004818178713321686
Local loss @ local epoch 4: 0.001518345670774579
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.9 seconds!
[tester] 
AGNewsMetric: acc=0.7667105263157895, hinge=1.7526566229368512, ce=5.309295166417172
Local test acc @ epoch 54: 0.7667
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.019395457580685616
Local loss @ local epoch 1: 0.014343184418976307
Local loss @ local epoch 2: 0.005601692479103804
Local loss @ local epoch 3: 0.0003381019923835993
Local loss @ local epoch 4: 0.015675237402319908
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 125.06 seconds!
[tester] 
AGNewsMetric: acc=0.7640789473684211, hinge=1.6241285542437904, ce=9.937152754131116
Local test acc @ epoch 54: 0.7641
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.09769746661186218
Local loss @ local epoch 1: 0.062211960554122925
Local loss @ local epoch 2: 0.0022321694996207952
Local loss @ local epoch 3: 0.0007128936122171581
Local loss @ local epoch 4: 0.0011199894361197948
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.71 seconds!
[tester] 
AGNewsMetric: acc=0.6223684210526316, hinge=2.483496069908142, ce=11.31952739314029
Local test acc @ epoch 54: 0.6224
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.5275878310203552
Local loss @ local epoch 1: 0.09148725867271423
Local loss @ local epoch 2: 0.4042586386203766
Local loss @ local epoch 3: 0.07271650433540344
Local loss @ local epoch 4: 0.17746126651763916
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.18 seconds!
[tester] 
AGNewsMetric: acc=0.8335526315789473, hinge=1.1880565841574418, ce=6.131242916709498
Local test acc @ epoch 54: 0.8336
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.544956922531128
Local loss @ local epoch 1: 0.15391257405281067
Local loss @ local epoch 2: 0.00249182409606874
Local loss @ local epoch 3: 0.0005722513888031244
Local loss @ local epoch 4: 0.0011037583462893963
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.7 seconds!
[tester] 
AGNewsMetric: acc=0.41157894736842104, hinge=8.006274937077572, ce=9.795587995428788
Local test acc @ epoch 54: 0.4116
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.20384620130062103
Local loss @ local epoch 1: 0.00047673622611910105
Local loss @ local epoch 2: 0.0003846017934847623
Local loss @ local epoch 3: 0.0003513669653329998
Local loss @ local epoch 4: 0.0005652293330058455
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.77 seconds!
[tester] 
AGNewsMetric: acc=0.2830263157894737, hinge=12.120472023612574, ce=11.896576797083805
Local test acc @ epoch 54: 0.283
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.07767278701066971
Local loss @ local epoch 1: 0.18906812369823456
Local loss @ local epoch 2: 0.02455722913146019
Local loss @ local epoch 3: 0.19303429126739502
Local loss @ local epoch 4: 0.017529036849737167
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.55 seconds!
[tester] 
AGNewsMetric: acc=0.7082894736842106, hinge=2.2120029785758573, ce=9.538804598356547
Local test acc @ epoch 54: 0.7083
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.1302298754453659
Local loss @ local epoch 1: 0.0004510830622166395
Local loss @ local epoch 2: 0.019549455493688583
Local loss @ local epoch 3: 0.0007785200141370296
Local loss @ local epoch 4: 0.0395524762570858
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.85 seconds!
[tester] 
AGNewsMetric: acc=0.48697368421052634, hinge=7.2166123041353725, ce=11.466646776701275
Local test acc @ epoch 54: 0.487
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 1.1204344034194946
Local loss @ local epoch 1: 0.04447093978524208
Local loss @ local epoch 2: 0.0677289143204689
Local loss @ local epoch 3: 0.007741808891296387
Local loss @ local epoch 4: 0.014644515700638294
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.31 seconds!
[tester] 
AGNewsMetric: acc=0.47618421052631577, hinge=4.183829464159514, ce=8.51801063838758
Local test acc @ epoch 54: 0.4762
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 6.384296284522861e-05
Local loss @ local epoch 1: 1.0371123607910704e-05
Local loss @ local epoch 2: 2.8823322281823494e-05
Local loss @ local epoch 3: 0.693916380405426
Local loss @ local epoch 4: 0.0004678656696341932
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.34 seconds!
[tester] 
AGNewsMetric: acc=0.6211842105263158, hinge=3.2006101553063644, ce=7.895491697411789
Local test acc @ epoch 54: 0.6212
Global evaluate on test data...
Evaluate data in 123.71 seconds!
[tester] 
AGNewsMetric: acc=0.8722368421052632, hinge=0.8722443738736604, ce=7.6188521686353186
Global test acc @ epoch 54: 0.8722
Global epoch 55...
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.40721166133880615
Local loss @ local epoch 1: 0.003090908983722329
Local loss @ local epoch 2: 0.00021194670989643782
Local loss @ local epoch 3: 0.0008882288238964975
Local loss @ local epoch 4: 0.0013904132647439837
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.86 seconds!
[tester] 
AGNewsMetric: acc=0.4378947368421053, hinge=7.68339258093583, ce=11.477996677599455
Local test acc @ epoch 55: 0.4379
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.23960424959659576
Local loss @ local epoch 1: 0.009161693044006824
Local loss @ local epoch 2: 0.007694358006119728
Local loss @ local epoch 3: 0.3879814147949219
Local loss @ local epoch 4: 0.016420545056462288
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.71 seconds!
[tester] 
AGNewsMetric: acc=0.8602631578947368, hinge=0.8991237524936073, ce=10.47605406309429
Local test acc @ epoch 55: 0.8603
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.23460061848163605
Local loss @ local epoch 1: 0.003744355635717511
Local loss @ local epoch 2: 0.006546019110828638
Local loss @ local epoch 3: 0.005096070934087038
Local loss @ local epoch 4: 0.008265960030257702
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.81 seconds!
[tester] 
AGNewsMetric: acc=0.6502631578947369, hinge=2.379988037912469, ce=11.007947036341617
Local test acc @ epoch 55: 0.6503
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0002082774299196899
Local loss @ local epoch 1: 0.001127168070524931
Local loss @ local epoch 2: 0.004780845250934362
Local loss @ local epoch 3: 0.08784879744052887
Local loss @ local epoch 4: 0.012073900550603867
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.85 seconds!
[tester] 
AGNewsMetric: acc=0.7489473684210526, hinge=1.9002509056894403, ce=5.41237316031205
Local test acc @ epoch 55: 0.7489
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.00027562706964090466
Local loss @ local epoch 1: 6.615793972741812e-05
Local loss @ local epoch 2: 5.0231494242325425e-05
Local loss @ local epoch 3: 0.0001423578360117972
Local loss @ local epoch 4: 7.363990880548954e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.11 seconds!
[tester] 
AGNewsMetric: acc=0.5807894736842105, hinge=4.960575622759367, ce=9.046670807286313
Local test acc @ epoch 55: 0.5808
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.641389787197113
Local loss @ local epoch 1: 0.2136349081993103
Local loss @ local epoch 2: 0.2519354522228241
Local loss @ local epoch 3: 0.14813201129436493
Local loss @ local epoch 4: 0.24420122802257538
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.68 seconds!
[tester] 
AGNewsMetric: acc=0.8126315789473684, hinge=1.3119635539305838, ce=11.736354135212146
Local test acc @ epoch 55: 0.8126
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.12220761179924011
Local loss @ local epoch 1: 0.0012911413796246052
Local loss @ local epoch 2: 0.002001988934352994
Local loss @ local epoch 3: 0.03902715444564819
Local loss @ local epoch 4: 0.007379597052931786
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.94 seconds!
[tester] 
AGNewsMetric: acc=0.4982894736842105, hinge=6.0975722272772535, ce=9.952459082352489
Local test acc @ epoch 55: 0.4983
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.08072805404663086
Local loss @ local epoch 1: 0.5044137835502625
Local loss @ local epoch 2: 0.1904747635126114
Local loss @ local epoch 3: 0.05295854061841965
Local loss @ local epoch 4: 0.06188797205686569
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.26 seconds!
[tester] 
AGNewsMetric: acc=0.7306578947368421, hinge=1.9541492969111391, ce=7.960947595897474
Local test acc @ epoch 55: 0.7307
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.750793993473053
Local loss @ local epoch 1: 0.005304065998643637
Local loss @ local epoch 2: 0.0005007531144656241
Local loss @ local epoch 3: 0.00017202239541802555
Local loss @ local epoch 4: 0.00011256366997258738
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 125.04 seconds!
[tester] 
AGNewsMetric: acc=0.47157894736842104, hinge=9.441515085069756, ce=11.953524408842387
Local test acc @ epoch 55: 0.4716
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.44400250911712646
Local loss @ local epoch 1: 0.06147599592804909
Local loss @ local epoch 2: 0.0012339329114183784
Local loss @ local epoch 3: 0.003208008361980319
Local loss @ local epoch 4: 0.26512381434440613
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 125.16 seconds!
[tester] 
AGNewsMetric: acc=0.4311842105263158, hinge=5.553016772521169, ce=10.136623920641448
Local test acc @ epoch 55: 0.4312
Global evaluate on test data...
Evaluate data in 123.74 seconds!
[tester] 
AGNewsMetric: acc=0.8659210526315789, hinge=1.0711242683310258, ce=10.75347337823165
Global test acc @ epoch 55: 0.8659
Global epoch 56...
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.38394278287887573
Local loss @ local epoch 1: 0.5100789666175842
Local loss @ local epoch 2: 0.017027104273438454
Local loss @ local epoch 3: 0.11900127679109573
Local loss @ local epoch 4: 0.11998061835765839
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.18 seconds!
[tester] 
AGNewsMetric: acc=0.8628947368421053, hinge=0.9775504666880558, ce=10.557214172764828
Local test acc @ epoch 56: 0.8629
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0002644738124217838
Local loss @ local epoch 1: 0.006215118803083897
Local loss @ local epoch 2: 0.005276369862258434
Local loss @ local epoch 3: 0.0018444422166794538
Local loss @ local epoch 4: 0.023859770968556404
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.02 seconds!
[tester] 
AGNewsMetric: acc=0.5975, hinge=3.365649477808099, ce=10.71524052870901
Local test acc @ epoch 56: 0.5975
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.01819855533540249
Local loss @ local epoch 1: 0.3459690511226654
Local loss @ local epoch 2: 0.010101200081408024
Local loss @ local epoch 3: 0.0663440153002739
Local loss @ local epoch 4: 0.17091123759746552
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.3 seconds!
[tester] 
AGNewsMetric: acc=0.7117105263157895, hinge=2.1471522762900905, ce=11.09126694127133
Local test acc @ epoch 56: 0.7117
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 1.024594783782959
Local loss @ local epoch 1: 0.09856265038251877
Local loss @ local epoch 2: 0.08227609843015671
Local loss @ local epoch 3: 0.04234522953629494
Local loss @ local epoch 4: 0.01896907016634941
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.82 seconds!
[tester] 
AGNewsMetric: acc=0.5155263157894737, hinge=4.061800692708869, ce=10.906157224554764
Local test acc @ epoch 56: 0.5155
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.12070721387863159
Local loss @ local epoch 1: 0.00036294510937295854
Local loss @ local epoch 2: 0.0012133819982409477
Local loss @ local epoch 3: 0.00017203250899910927
Local loss @ local epoch 4: 0.0012732661562040448
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.57 seconds!
[tester] 
AGNewsMetric: acc=0.40960526315789475, hinge=11.406518962257786, ce=12.042634532326145
Local test acc @ epoch 56: 0.4096
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.5619734525680542
Local loss @ local epoch 1: 0.2927212417125702
Local loss @ local epoch 2: 0.00881417840719223
Local loss @ local epoch 3: 0.005103736650198698
Local loss @ local epoch 4: 0.2019561231136322
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.37 seconds!
[tester] 
AGNewsMetric: acc=0.4698684210526316, hinge=5.5299279544228, ce=10.834958465977719
Local test acc @ epoch 56: 0.4699
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.00021141832985449582
Local loss @ local epoch 1: 4.0789589547785e-05
Local loss @ local epoch 2: 1.8835038417819305e-06
Local loss @ local epoch 3: 4.434564289113041e-06
Local loss @ local epoch 4: 5.674339263350703e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.85 seconds!
[tester] 
AGNewsMetric: acc=0.48605263157894735, hinge=7.61084227612144, ce=9.801705774006091
Local test acc @ epoch 56: 0.4861
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.05606570467352867
Local loss @ local epoch 1: 0.000386628060368821
Local loss @ local epoch 2: 8.279085886897519e-05
Local loss @ local epoch 3: 0.00010918844054685906
Local loss @ local epoch 4: 5.996897743898444e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.78 seconds!
[tester] 
AGNewsMetric: acc=0.4035526315789474, hinge=8.73986757228249, ce=12.041641243382504
Local test acc @ epoch 56: 0.4036
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.07491171360015869
Local loss @ local epoch 1: 0.010672453790903091
Local loss @ local epoch 2: 0.0005381530500017107
Local loss @ local epoch 3: 0.00042408358422107995
Local loss @ local epoch 4: 0.0005563533050008118
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.83 seconds!
[tester] 
AGNewsMetric: acc=0.6206578947368421, hinge=2.713428975657413, ce=12.167118417840255
Local test acc @ epoch 56: 0.6207
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.043807502835989
Local loss @ local epoch 1: 0.0027736376505345106
Local loss @ local epoch 2: 0.09565135091543198
Local loss @ local epoch 3: 0.004168351646512747
Local loss @ local epoch 4: 0.1207628846168518
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.07 seconds!
[tester] 
AGNewsMetric: acc=0.7932894736842105, hinge=1.8729701298161556, ce=7.758148723401521
Local test acc @ epoch 56: 0.7933
Global evaluate on test data...
Evaluate data in 124.85 seconds!
[tester] 
AGNewsMetric: acc=0.86, hinge=1.0075745753238077, ce=10.261103433307849
Global test acc @ epoch 56: 0.86
Global epoch 57...
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 1.368492485198658e-05
Local loss @ local epoch 1: 6.627987204410601e-06
Local loss @ local epoch 2: 2.145714097423479e-05
Local loss @ local epoch 3: 2.5176337658194825e-05
Local loss @ local epoch 4: 5.266129664960317e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.86 seconds!
[tester] 
AGNewsMetric: acc=0.8501315789473685, hinge=1.2923228527370252, ce=11.37058272311562
Local test acc @ epoch 57: 0.8501
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.26598069071769714
Local loss @ local epoch 1: 0.008440565317869186
Local loss @ local epoch 2: 0.5361693501472473
Local loss @ local epoch 3: 0.11314553022384644
Local loss @ local epoch 4: 0.03608237951993942
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.82 seconds!
[tester] 
AGNewsMetric: acc=0.6503947368421052, hinge=2.5216088578575535, ce=10.933992630807976
Local test acc @ epoch 57: 0.6504
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 1.2204054594039917
Local loss @ local epoch 1: 0.05722224712371826
Local loss @ local epoch 2: 0.13376103341579437
Local loss @ local epoch 3: 0.25163733959198
Local loss @ local epoch 4: 0.1368914097547531
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.5 seconds!
[tester] 
AGNewsMetric: acc=0.8276315789473684, hinge=1.288121301249454, ce=9.489285061484889
Local test acc @ epoch 57: 0.8276
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.07185511291027069
Local loss @ local epoch 1: 0.004943406209349632
Local loss @ local epoch 2: 0.0013522678054869175
Local loss @ local epoch 3: 0.00284402072429657
Local loss @ local epoch 4: 0.0638163760304451
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.73 seconds!
[tester] 
AGNewsMetric: acc=0.7967105263157894, hinge=1.4484805019278275, ce=9.744224012274492
Local test acc @ epoch 57: 0.7967
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.25554680824279785
Local loss @ local epoch 1: 0.006608855910599232
Local loss @ local epoch 2: 0.0013707856414839625
Local loss @ local epoch 3: 0.00019650817557703704
Local loss @ local epoch 4: 8.113059448078275e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 125.1 seconds!
[tester] 
AGNewsMetric: acc=0.30697368421052634, hinge=8.271599694302207, ce=13.296937004892449
Local test acc @ epoch 57: 0.307
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.4306710958480835
Local loss @ local epoch 1: 0.0061376881785690784
Local loss @ local epoch 2: 0.004948509391397238
Local loss @ local epoch 3: 0.03491677716374397
Local loss @ local epoch 4: 0.011204305104911327
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.17 seconds!
[tester] 
AGNewsMetric: acc=0.5227631578947368, hinge=4.191059797688534, ce=8.973094010604056
Local test acc @ epoch 57: 0.5228
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.19478660821914673
Local loss @ local epoch 1: 0.0008671926334500313
Local loss @ local epoch 2: 0.00048165989574044943
Local loss @ local epoch 3: 0.00025724663282744586
Local loss @ local epoch 4: 0.0007197509985417128
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.59 seconds!
[tester] 
AGNewsMetric: acc=0.4668421052631579, hinge=8.81412039505808, ce=13.033242097151907
Local test acc @ epoch 57: 0.4668
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0013592017348855734
Local loss @ local epoch 1: 0.0005396142369136214
Local loss @ local epoch 2: 0.0035027428530156612
Local loss @ local epoch 3: 0.004566960968077183
Local loss @ local epoch 4: 0.003192529547959566
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.36 seconds!
[tester] 
AGNewsMetric: acc=0.7736842105263158, hinge=1.631496151372006, ce=9.447519818356163
Local test acc @ epoch 57: 0.7737
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.07930893450975418
Local loss @ local epoch 1: 0.0004920388455502689
Local loss @ local epoch 2: 0.379868745803833
Local loss @ local epoch 3: 0.0026515822391957045
Local loss @ local epoch 4: 0.0022247128654271364
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.37 seconds!
[tester] 
AGNewsMetric: acc=0.5967105263157895, hinge=3.0051439802270186, ce=10.750545194525468
Local test acc @ epoch 57: 0.5967
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.688003420829773
Local loss @ local epoch 1: 0.00505833188071847
Local loss @ local epoch 2: 0.001610234729014337
Local loss @ local epoch 3: 0.0062178573571145535
Local loss @ local epoch 4: 0.009424105286598206
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 125.32 seconds!
[tester] 
AGNewsMetric: acc=0.3931578947368421, hinge=7.23421626944291, ce=11.449873578924882
Local test acc @ epoch 57: 0.3932
Global evaluate on test data...
Evaluate data in 124.98 seconds!
[tester] 
AGNewsMetric: acc=0.8656578947368421, hinge=1.1030974995462517, ce=10.353922028792532
Global test acc @ epoch 57: 0.8657
Global epoch 58...
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.004264846444129944
Local loss @ local epoch 1: 0.018367411568760872
Local loss @ local epoch 2: 0.0005250864778645337
Local loss @ local epoch 3: 0.0040905713103711605
Local loss @ local epoch 4: 0.0019051074050366879
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.83 seconds!
[tester] 
AGNewsMetric: acc=0.6290789473684211, hinge=2.6008609033885755, ce=8.568199316325941
Local test acc @ epoch 58: 0.6291
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 6.019553984515369e-05
Local loss @ local epoch 1: 6.151131856313441e-06
Local loss @ local epoch 2: 5.984237759548705e-06
Local loss @ local epoch 3: 3.6716210161102936e-06
Local loss @ local epoch 4: 6.05575633016997e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.53 seconds!
[tester] 
AGNewsMetric: acc=0.5939473684210527, hinge=4.065133273476048, ce=10.4429818785818
Local test acc @ epoch 58: 0.5939
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4414225816726685
Local loss @ local epoch 1: 0.20960219204425812
Local loss @ local epoch 2: 0.004830929916352034
Local loss @ local epoch 3: 0.0006853414815850556
Local loss @ local epoch 4: 0.0006599855842068791
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.36 seconds!
[tester] 
AGNewsMetric: acc=0.41592105263157897, hinge=7.411358742964895, ce=11.142146630538138
Local test acc @ epoch 58: 0.4159
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 1.5396780967712402
Local loss @ local epoch 1: 0.11527618765830994
Local loss @ local epoch 2: 0.02503485605120659
Local loss @ local epoch 3: 0.006389207672327757
Local loss @ local epoch 4: 0.014485642313957214
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.84 seconds!
[tester] 
AGNewsMetric: acc=0.578421052631579, hinge=3.1508400726318357, ce=10.180975430137233
Local test acc @ epoch 58: 0.5784
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.14326795935630798
Local loss @ local epoch 1: 0.07713060826063156
Local loss @ local epoch 2: 0.1046282947063446
Local loss @ local epoch 3: 0.12932990491390228
Local loss @ local epoch 4: 0.038445305079221725
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.75 seconds!
[tester] 
AGNewsMetric: acc=0.8194736842105264, hinge=1.3812505167408993, ce=9.223122913962916
Local test acc @ epoch 58: 0.8195
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.00894819013774395
Local loss @ local epoch 1: 0.5609155893325806
Local loss @ local epoch 2: 0.08766791969537735
Local loss @ local epoch 3: 0.01328186597675085
Local loss @ local epoch 4: 0.11337202042341232
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.77 seconds!
[tester] 
AGNewsMetric: acc=0.7197368421052631, hinge=2.549439472650227, ce=9.543309998763235
Local test acc @ epoch 58: 0.7197
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.004552081692963839
Local loss @ local epoch 1: 0.0151767423376441
Local loss @ local epoch 2: 0.0049571692943573
Local loss @ local epoch 3: 0.0007116257329471409
Local loss @ local epoch 4: 0.007677728310227394
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.76 seconds!
[tester] 
AGNewsMetric: acc=0.6517105263157895, hinge=2.555603269275866, ce=11.257046914351614
Local test acc @ epoch 58: 0.6517
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.08864104002714157
Local loss @ local epoch 1: 0.0006354837096296251
Local loss @ local epoch 2: 0.0014453702606260777
Local loss @ local epoch 3: 0.00720197381451726
Local loss @ local epoch 4: 0.002470757346600294
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.84 seconds!
[tester] 
AGNewsMetric: acc=0.42026315789473684, hinge=8.37289229091845, ce=10.028221138402035
Local test acc @ epoch 58: 0.4203
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.01083414163440466
Local loss @ local epoch 1: 9.613314614398405e-05
Local loss @ local epoch 2: 0.0001303062163060531
Local loss @ local epoch 3: 0.0011175043182447553
Local loss @ local epoch 4: 0.0003285695565864444
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.9 seconds!
[tester] 
AGNewsMetric: acc=0.2561842105263158, hinge=14.72259345004433, ce=13.929607104251259
Local test acc @ epoch 58: 0.2562
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.027245832607150078
Local loss @ local epoch 1: 0.009015205316245556
Local loss @ local epoch 2: 0.2923925817012787
Local loss @ local epoch 3: 0.4287963807582855
Local loss @ local epoch 4: 0.24287398159503937
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.09 seconds!
[tester] 
AGNewsMetric: acc=0.631578947368421, hinge=2.8274580029437417, ce=10.559151047154478
Local test acc @ epoch 58: 0.6316
Global evaluate on test data...
Evaluate data in 123.61 seconds!
[tester] 
AGNewsMetric: acc=0.8393421052631579, hinge=1.1519735660051045, ce=10.22159788031327
Global test acc @ epoch 58: 0.8393
Global epoch 59...
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 1.0944175720214844
Local loss @ local epoch 1: 0.0009473843965679407
Local loss @ local epoch 2: 0.00017917352670338005
Local loss @ local epoch 3: 3.0148226869641803e-05
Local loss @ local epoch 4: 2.474076609360054e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.0 seconds!
[tester] 
AGNewsMetric: acc=0.42776315789473685, hinge=10.749565321771723, ce=12.05225003292686
Local test acc @ epoch 59: 0.4278
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.3352956473827362
Local loss @ local epoch 1: 0.0006162364152260125
Local loss @ local epoch 2: 5.611235974356532e-05
Local loss @ local epoch 3: 0.0005364454700611532
Local loss @ local epoch 4: 0.001645253854803741
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.89 seconds!
[tester] 
AGNewsMetric: acc=0.44026315789473686, hinge=9.879159340356525, ce=11.988644688254908
Local test acc @ epoch 59: 0.4403
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.035559818148612976
Local loss @ local epoch 1: 0.03951632231473923
Local loss @ local epoch 2: 0.019384946674108505
Local loss @ local epoch 3: 0.2914181351661682
Local loss @ local epoch 4: 0.11845441907644272
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.39 seconds!
[tester] 
AGNewsMetric: acc=0.6594736842105263, hinge=2.589065577356439, ce=6.334477499911659
Local test acc @ epoch 59: 0.6595
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 6.532638508360833e-06
Local loss @ local epoch 1: 7.438612556143198e-06
Local loss @ local epoch 2: 2.789408063108567e-05
Local loss @ local epoch 3: 0.0001272812660317868
Local loss @ local epoch 4: 0.00020038013462908566
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.37 seconds!
[tester] 
AGNewsMetric: acc=0.5925, hinge=4.020406918274729, ce=6.730206766630474
Local test acc @ epoch 59: 0.5925
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0008166421321220696
Local loss @ local epoch 1: 0.005480887368321419
Local loss @ local epoch 2: 0.0004075271135661751
Local loss @ local epoch 3: 0.0011182427406311035
Local loss @ local epoch 4: 0.00017604618915356696
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.02 seconds!
[tester] 
AGNewsMetric: acc=0.6710526315789473, hinge=2.6914553561963532, ce=9.578421062670255
Local test acc @ epoch 59: 0.6711
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.8034239411354065
Local loss @ local epoch 1: 0.04429078474640846
Local loss @ local epoch 2: 1.2025777101516724
Local loss @ local epoch 3: 0.03657658025622368
Local loss @ local epoch 4: 0.0840097963809967
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.66 seconds!
[tester] 
AGNewsMetric: acc=0.8401315789473685, hinge=1.3082004030127274, ce=9.905587051793148
Local test acc @ epoch 59: 0.8401
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.07560515403747559
Local loss @ local epoch 1: 0.001020338386297226
Local loss @ local epoch 2: 0.0022385255433619022
Local loss @ local epoch 3: 0.15506309270858765
Local loss @ local epoch 4: 0.03241194784641266
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.22 seconds!
[tester] 
AGNewsMetric: acc=0.4243421052631579, hinge=4.91282071063393, ce=10.347871284484864
Local test acc @ epoch 59: 0.4243
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.18642254173755646
Local loss @ local epoch 1: 0.004857941064983606
Local loss @ local epoch 2: 0.001394767896272242
Local loss @ local epoch 3: 0.0014671282842755318
Local loss @ local epoch 4: 0.007538644131273031
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.35 seconds!
[tester] 
AGNewsMetric: acc=0.6835526315789474, hinge=2.4421232592432123, ce=7.762314682006836
Local test acc @ epoch 59: 0.6836
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.2882980704307556
Local loss @ local epoch 1: 0.07903561741113663
Local loss @ local epoch 2: 0.0012085736962035298
Local loss @ local epoch 3: 0.0028269204776734114
Local loss @ local epoch 4: 0.0013463684590533376
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.86 seconds!
[tester] 
AGNewsMetric: acc=0.8707894736842106, hinge=0.9420088808160079, ce=10.06675307825992
Local test acc @ epoch 59: 0.8708
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.24440398812294006
Local loss @ local epoch 1: 0.0022617236245423555
Local loss @ local epoch 2: 0.0019605299457907677
Local loss @ local epoch 3: 0.018312733620405197
Local loss @ local epoch 4: 0.0054247560910880566
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.56 seconds!
[tester] 
AGNewsMetric: acc=0.45723684210526316, hinge=5.834632192912855, ce=10.04337766546952
Local test acc @ epoch 59: 0.4572
Global evaluate on test data...
Evaluate data in 124.76 seconds!
[tester] 
AGNewsMetric: acc=0.8377631578947369, hinge=1.4796202391072324, ce=10.037111005281147
Global test acc @ epoch 59: 0.8378
Global epoch 60...
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.01855297014117241
Local loss @ local epoch 1: 0.0001466798275941983
Local loss @ local epoch 2: 0.00030555142438970506
Local loss @ local epoch 3: 0.00017207019845955074
Local loss @ local epoch 4: 0.0017468598671257496
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.82 seconds!
[tester] 
AGNewsMetric: acc=0.2506578947368421, hinge=12.618046184339022, ce=12.007490786502236
Local test acc @ epoch 60: 0.2507
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 1.5186832570179831e-05
Local loss @ local epoch 1: 3.7669919947802555e-06
Local loss @ local epoch 2: 1.1444079746070202e-06
Local loss @ local epoch 3: 0.21854063868522644
Local loss @ local epoch 4: 0.5474019646644592
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.46 seconds!
[tester] 
AGNewsMetric: acc=0.595657894736842, hinge=4.6260813765776785, ce=10.245951742874949
Local test acc @ epoch 60: 0.5957
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.004008424002677202
Local loss @ local epoch 1: 0.01486938539892435
Local loss @ local epoch 2: 0.0002281739580212161
Local loss @ local epoch 3: 0.05090636387467384
Local loss @ local epoch 4: 0.0008743864600546658
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.34 seconds!
[tester] 
AGNewsMetric: acc=0.3798684210526316, hinge=5.098476764277408, ce=11.172716827392579
Local test acc @ epoch 60: 0.3799
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 3.0479211807250977
Local loss @ local epoch 1: 0.44320207834243774
Local loss @ local epoch 2: 0.02793729677796364
Local loss @ local epoch 3: 0.010840394534170628
Local loss @ local epoch 4: 0.014837479218840599
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.72 seconds!
[tester] 
AGNewsMetric: acc=0.6081578947368421, hinge=2.6819269501535516, ce=10.783029714885512
Local test acc @ epoch 60: 0.6082
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.026375414803624153
Local loss @ local epoch 1: 0.5140762329101562
Local loss @ local epoch 2: 0.01528659276664257
Local loss @ local epoch 3: 0.19783703982830048
Local loss @ local epoch 4: 0.017363397404551506
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.35 seconds!
[tester] 
AGNewsMetric: acc=0.7164473684210526, hinge=2.222328402117679, ce=11.167161867242111
Local test acc @ epoch 60: 0.7164
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.25776049494743347
Local loss @ local epoch 1: 0.3919966518878937
Local loss @ local epoch 2: 0.09456786513328552
Local loss @ local epoch 3: 0.2823590934276581
Local loss @ local epoch 4: 0.07093171775341034
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.54 seconds!
[tester] 
AGNewsMetric: acc=0.8369736842105263, hinge=1.1662234845914339, ce=8.851391430904991
Local test acc @ epoch 60: 0.837
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.004183898214250803
Local loss @ local epoch 1: 0.001017226604744792
Local loss @ local epoch 2: 0.0005434955819509923
Local loss @ local epoch 3: 0.0005089965998195112
Local loss @ local epoch 4: 0.001080392044968903
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.86 seconds!
[tester] 
AGNewsMetric: acc=0.6623684210526316, hinge=3.7479655140324644, ce=10.09238993192974
Local test acc @ epoch 60: 0.6624
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 2.3850460052490234
Local loss @ local epoch 1: 0.6581520438194275
Local loss @ local epoch 2: 0.12490659952163696
Local loss @ local epoch 3: 0.053453367203474045
Local loss @ local epoch 4: 0.05397287383675575
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.89 seconds!
[tester] 
AGNewsMetric: acc=0.4744736842105263, hinge=4.577628328423751, ce=10.45643869098864
Local test acc @ epoch 60: 0.4745
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.3751250207424164
Local loss @ local epoch 1: 0.003645211225375533
Local loss @ local epoch 2: 0.008660245686769485
Local loss @ local epoch 3: 0.006938152015209198
Local loss @ local epoch 4: 0.014912459068000317
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.41 seconds!
[tester] 
AGNewsMetric: acc=0.7932894736842105, hinge=1.4120990165911222, ce=11.20737678527832
Local test acc @ epoch 60: 0.7933
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0058782827109098434
Local loss @ local epoch 1: 0.0018743068212643266
Local loss @ local epoch 2: 0.00024507453781552613
Local loss @ local epoch 3: 0.00016086817777249962
Local loss @ local epoch 4: 9.270544251194224e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.44 seconds!
[tester] 
AGNewsMetric: acc=0.4573684210526316, hinge=10.394916941994115, ce=12.64078556462338
Local test acc @ epoch 60: 0.4574
Global evaluate on test data...
Evaluate data in 123.85 seconds!
[tester] 
AGNewsMetric: acc=0.8756578947368421, hinge=0.8953732360036749, ce=10.406983622500771
Global test acc @ epoch 60: 0.8757
Global epoch 61...
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.6420355439186096
Local loss @ local epoch 1: 0.27488580346107483
Local loss @ local epoch 2: 0.004329270217567682
Local loss @ local epoch 3: 0.18091565370559692
Local loss @ local epoch 4: 0.0844728946685791
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.38 seconds!
[tester] 
AGNewsMetric: acc=0.4406578947368421, hinge=5.528705038271452, ce=9.735102870338842
Local test acc @ epoch 61: 0.4407
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.06999419629573822
Local loss @ local epoch 1: 0.009039935655891895
Local loss @ local epoch 2: 0.1356312334537506
Local loss @ local epoch 3: 0.16909271478652954
Local loss @ local epoch 4: 0.17038358747959137
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.76 seconds!
[tester] 
AGNewsMetric: acc=0.8403947368421053, hinge=1.1694014802731967, ce=9.703362428765548
Local test acc @ epoch 61: 0.8404
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.5278621315956116
Local loss @ local epoch 1: 0.0017288069939240813
Local loss @ local epoch 2: 0.0002035461220657453
Local loss @ local epoch 3: 0.0009935335256159306
Local loss @ local epoch 4: 0.0010767698986455798
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.41 seconds!
[tester] 
AGNewsMetric: acc=0.26210526315789473, hinge=10.242022644846063, ce=11.366349553559957
Local test acc @ epoch 61: 0.2621
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.036573056131601334
Local loss @ local epoch 1: 0.011973811313509941
Local loss @ local epoch 2: 0.0007949641440063715
Local loss @ local epoch 3: 0.6628031730651855
Local loss @ local epoch 4: 0.12805254757404327
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.29 seconds!
[tester] 
AGNewsMetric: acc=0.616578947368421, hinge=3.10896550329108, ce=9.491851208335476
Local test acc @ epoch 61: 0.6166
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 3.237633063690737e-05
Local loss @ local epoch 1: 5.344847886590287e-05
Local loss @ local epoch 2: 1.3613467672257684e-05
Local loss @ local epoch 3: 0.4048462510108948
Local loss @ local epoch 4: 2.5663459300994873
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.07 seconds!
[tester] 
AGNewsMetric: acc=0.24644736842105264, hinge=6.673624772523579, ce=15.305262712177477
Local test acc @ epoch 61: 0.2464
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.05310799553990364
Local loss @ local epoch 1: 0.000284946319879964
Local loss @ local epoch 2: 0.0008859895169734955
Local loss @ local epoch 3: 0.00013207444862928241
Local loss @ local epoch 4: 0.005717174615710974
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.67 seconds!
[tester] 
AGNewsMetric: acc=0.47960526315789476, hinge=4.59746737931904, ce=11.637613310562937
Local test acc @ epoch 61: 0.4796
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.8170644640922546
Local loss @ local epoch 1: 0.06898036599159241
Local loss @ local epoch 2: 0.5177498459815979
Local loss @ local epoch 3: 0.7309263348579407
Local loss @ local epoch 4: 0.25707438588142395
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.8 seconds!
[tester] 
AGNewsMetric: acc=0.8409210526315789, hinge=1.189630402765776, ce=7.959891050238358
Local test acc @ epoch 61: 0.8409
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.6362556219100952
Local loss @ local epoch 1: 0.0019212268525734544
Local loss @ local epoch 2: 0.0028414123225957155
Local loss @ local epoch 3: 0.15714508295059204
Local loss @ local epoch 4: 0.0036256772000342607
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.28 seconds!
[tester] 
AGNewsMetric: acc=0.7319736842105263, hinge=2.1478892712844044, ce=11.496282290408486
Local test acc @ epoch 61: 0.732
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.028353577479720116
Local loss @ local epoch 1: 0.8223446011543274
Local loss @ local epoch 2: 0.33948174118995667
Local loss @ local epoch 3: 0.02823677659034729
Local loss @ local epoch 4: 0.030003169551491737
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.11 seconds!
[tester] 
AGNewsMetric: acc=0.6628947368421053, hinge=2.5682287311553953, ce=8.864621706510844
Local test acc @ epoch 61: 0.6629
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.5443673729896545
Local loss @ local epoch 1: 0.023469438776373863
Local loss @ local epoch 2: 0.03809944540262222
Local loss @ local epoch 3: 0.15198709070682526
Local loss @ local epoch 4: 0.2975999116897583
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.03 seconds!
[tester] 
AGNewsMetric: acc=0.45526315789473687, hinge=4.3211847591400145, ce=10.475256253292686
Local test acc @ epoch 61: 0.4553
Global evaluate on test data...
Evaluate data in 124.6 seconds!
[tester] 
AGNewsMetric: acc=0.8864473684210527, hinge=0.8770337579124852, ce=10.182159138729698
Global test acc @ epoch 61: 0.8864
Global epoch 62...
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0755234882235527
Local loss @ local epoch 1: 0.00026456674095243216
Local loss @ local epoch 2: 0.00013826314534526318
Local loss @ local epoch 3: 0.00043761226697824895
Local loss @ local epoch 4: 0.00017325684893876314
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.71 seconds!
[tester] 
AGNewsMetric: acc=0.29092105263157897, hinge=10.471927934947766, ce=11.359989782634534
Local test acc @ epoch 62: 0.2909
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.2428511381149292
Local loss @ local epoch 1: 0.056641269475221634
Local loss @ local epoch 2: 0.03218071535229683
Local loss @ local epoch 3: 0.04896562173962593
Local loss @ local epoch 4: 0.0572175532579422
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.69 seconds!
[tester] 
AGNewsMetric: acc=0.7857894736842105, hinge=1.6689247312043842, ce=9.78471587532445
Local test acc @ epoch 62: 0.7858
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.00018362599075771868
Local loss @ local epoch 1: 1.3160535672795959e-05
Local loss @ local epoch 2: 4.6154094889061525e-05
Local loss @ local epoch 3: 2.264971499243984e-06
Local loss @ local epoch 4: 0.00013482611393556
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.16 seconds!
[tester] 
AGNewsMetric: acc=0.5863157894736842, hinge=3.7068110001714607, ce=9.002046685469779
Local test acc @ epoch 62: 0.5863
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.6247396469116211
Local loss @ local epoch 1: 0.0356680266559124
Local loss @ local epoch 2: 0.011888598091900349
Local loss @ local epoch 3: 0.016682196408510208
Local loss @ local epoch 4: 0.007596156559884548
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.26 seconds!
[tester] 
AGNewsMetric: acc=0.4747368421052632, hinge=4.402931157162315, ce=9.791221429925216
Local test acc @ epoch 62: 0.4747
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.005156033672392368
Local loss @ local epoch 1: 0.1685314029455185
Local loss @ local epoch 2: 0.0028537744656205177
Local loss @ local epoch 3: 0.05818624421954155
Local loss @ local epoch 4: 0.006638459395617247
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.0 seconds!
[tester] 
AGNewsMetric: acc=0.8768421052631579, hinge=0.9173068656419453, ce=10.507956267909
Local test acc @ epoch 62: 0.8768
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.012662560679018497
Local loss @ local epoch 1: 0.08607655018568039
Local loss @ local epoch 2: 0.057078808546066284
Local loss @ local epoch 3: 0.04902365431189537
Local loss @ local epoch 4: 0.016269853338599205
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.7 seconds!
[tester] 
AGNewsMetric: acc=0.7413157894736843, hinge=1.950557766964561, ce=9.141722910027754
Local test acc @ epoch 62: 0.7413
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.3150356709957123
Local loss @ local epoch 1: 0.0003003058664035052
Local loss @ local epoch 2: 0.0036847256124019623
Local loss @ local epoch 3: 0.007672445382922888
Local loss @ local epoch 4: 0.0017438163049519062
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.62 seconds!
[tester] 
AGNewsMetric: acc=0.4719736842105263, hinge=8.539765688996566, ce=12.672187696758069
Local test acc @ epoch 62: 0.472
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.3199310004711151
Local loss @ local epoch 1: 0.2730597257614136
Local loss @ local epoch 2: 0.20006756484508514
Local loss @ local epoch 3: 0.19428414106369019
Local loss @ local epoch 4: 0.058923885226249695
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.6 seconds!
[tester] 
AGNewsMetric: acc=0.8261842105263157, hinge=1.2439940578059145, ce=9.315174058613024
Local test acc @ epoch 62: 0.8262
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0007764922920614481
Local loss @ local epoch 1: 0.0052725509740412235
Local loss @ local epoch 2: 0.0008234491106122732
Local loss @ local epoch 3: 0.0003317065420560539
Local loss @ local epoch 4: 0.0009405366145074368
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.1 seconds!
[tester] 
AGNewsMetric: acc=0.7359210526315789, hinge=1.6300585586146303, ce=9.700507290488796
Local test acc @ epoch 62: 0.7359
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.6389723420143127
Local loss @ local epoch 1: 0.25039926171302795
Local loss @ local epoch 2: 0.005710505414754152
Local loss @ local epoch 3: 0.14941513538360596
Local loss @ local epoch 4: 0.009356755763292313
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.03 seconds!
[tester] 
AGNewsMetric: acc=0.45276315789473687, hinge=4.8193504699907805, ce=9.28849053433067
Local test acc @ epoch 62: 0.4528
Global evaluate on test data...
Evaluate data in 124.65 seconds!
[tester] 
AGNewsMetric: acc=0.8817105263157895, hinge=0.9405162321893792, ce=9.933392275760049
Global test acc @ epoch 62: 0.8817
Global epoch 63...
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.6709309220314026
Local loss @ local epoch 1: 0.027573708444833755
Local loss @ local epoch 2: 0.0027633055578917265
Local loss @ local epoch 3: 0.0008196331327781081
Local loss @ local epoch 4: 0.0007784387562423944
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.34 seconds!
[tester] 
AGNewsMetric: acc=0.41078947368421054, hinge=7.070350483342221, ce=10.489728524057488
Local test acc @ epoch 63: 0.4108
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.006877967622131109
Local loss @ local epoch 1: 0.009646058082580566
Local loss @ local epoch 2: 0.021226312965154648
Local loss @ local epoch 3: 0.008398665115237236
Local loss @ local epoch 4: 0.04231696203351021
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.86 seconds!
[tester] 
AGNewsMetric: acc=0.7218421052631578, hinge=2.2637258195877075, ce=10.390235435084293
Local test acc @ epoch 63: 0.7218
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0023358238395303488
Local loss @ local epoch 1: 0.2080267071723938
Local loss @ local epoch 2: 0.0005737729952670634
Local loss @ local epoch 3: 0.025069057941436768
Local loss @ local epoch 4: 0.02444562129676342
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.59 seconds!
[tester] 
AGNewsMetric: acc=0.8781578947368421, hinge=0.9060003185272216, ce=10.453442089683131
Local test acc @ epoch 63: 0.8782
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 1.0013502105721273e-05
Local loss @ local epoch 1: 9.703575415187515e-06
Local loss @ local epoch 2: 5.841225174663123e-06
Local loss @ local epoch 3: 5.483624363478157e-07
Local loss @ local epoch 4: 4.291532036404533e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.37 seconds!
[tester] 
AGNewsMetric: acc=0.48276315789473684, hinge=5.444459119094046, ce=10.313622944480494
Local test acc @ epoch 63: 0.4828
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.012395128607749939
Local loss @ local epoch 1: 0.002504645613953471
Local loss @ local epoch 2: 0.0002754407178144902
Local loss @ local epoch 3: 0.0029085075948387384
Local loss @ local epoch 4: 0.0022484955843538046
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.31 seconds!
[tester] 
AGNewsMetric: acc=0.6505263157894737, hinge=2.553704138053091, ce=11.47165515096564
Local test acc @ epoch 63: 0.6505
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.03879091143608093
Local loss @ local epoch 1: 0.001185130444355309
Local loss @ local epoch 2: 0.04903360828757286
Local loss @ local epoch 3: 0.0008823410025797784
Local loss @ local epoch 4: 0.00043889100197702646
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.29 seconds!
[tester] 
AGNewsMetric: acc=0.5569736842105263, hinge=4.830515433361656, ce=10.840685896622507
Local test acc @ epoch 63: 0.557
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.002784203039482236
Local loss @ local epoch 1: 0.0013326270272955298
Local loss @ local epoch 2: 0.0007995904888957739
Local loss @ local epoch 3: 0.0002467251324560493
Local loss @ local epoch 4: 0.00029298773733899
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.03 seconds!
[tester] 
AGNewsMetric: acc=0.6636842105263158, hinge=3.421528790875485, ce=7.90484769821167
Local test acc @ epoch 63: 0.6637
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.5562705397605896
Local loss @ local epoch 1: 0.2035263031721115
Local loss @ local epoch 2: 0.4580242931842804
Local loss @ local epoch 3: 0.04996218532323837
Local loss @ local epoch 4: 0.10479927062988281
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.62 seconds!
[tester] 
AGNewsMetric: acc=0.8359210526315789, hinge=1.1237246794449656, ce=10.93439647875334
Local test acc @ epoch 63: 0.8359
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.7521594166755676
Local loss @ local epoch 1: 0.0018430238123983145
Local loss @ local epoch 2: 0.0015762945404276252
Local loss @ local epoch 3: 0.0018907894846051931
Local loss @ local epoch 4: 0.01986573077738285
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.39 seconds!
[tester] 
AGNewsMetric: acc=0.4488157894736842, hinge=5.337146412196912, ce=9.158481365003084
Local test acc @ epoch 63: 0.4488
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.027618903666734695
Local loss @ local epoch 1: 4.861053093918599e-05
Local loss @ local epoch 2: 0.00016815376875456423
Local loss @ local epoch 3: 5.0496109906816855e-05
Local loss @ local epoch 4: 0.00013455883890856057
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.81 seconds!
[tester] 
AGNewsMetric: acc=0.29855263157894735, hinge=11.61443738435444, ce=14.000986277931615
Local test acc @ epoch 63: 0.2986
Global evaluate on test data...
Evaluate data in 124.9 seconds!
[tester] 
AGNewsMetric: acc=0.8690789473684211, hinge=0.9914465906745509, ce=9.511387200606496
Global test acc @ epoch 63: 0.8691
Global epoch 64...
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.20301686227321625
Local loss @ local epoch 1: 0.0004084836400579661
Local loss @ local epoch 2: 0.0012090691598132253
Local loss @ local epoch 3: 0.0022019261959940195
Local loss @ local epoch 4: 0.001365465228445828
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.06 seconds!
[tester] 
AGNewsMetric: acc=0.3088157894736842, hinge=10.754551099476062, ce=12.019735440705952
Local test acc @ epoch 64: 0.3088
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 1.4495411960524507e-05
Local loss @ local epoch 1: 6.184016820043325e-05
Local loss @ local epoch 2: 2.5581470254110172e-05
Local loss @ local epoch 3: 0.001808331348001957
Local loss @ local epoch 4: 3.423580710659735e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.69 seconds!
[tester] 
AGNewsMetric: acc=0.37526315789473685, hinge=6.885408048127827, ce=11.082165073595549
Local test acc @ epoch 64: 0.3753
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.5937312841415405
Local loss @ local epoch 1: 0.06299326568841934
Local loss @ local epoch 2: 0.07200487703084946
Local loss @ local epoch 3: 0.23429909348487854
Local loss @ local epoch 4: 0.04073847830295563
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.71 seconds!
[tester] 
AGNewsMetric: acc=0.6948684210526316, hinge=2.4294180694379306, ce=9.910106464185212
Local test acc @ epoch 64: 0.6949
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.1838914453983307
Local loss @ local epoch 1: 0.0011987161124125123
Local loss @ local epoch 2: 0.003767303889617324
Local loss @ local epoch 3: 0.008939267136156559
Local loss @ local epoch 4: 0.015755929052829742
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.46 seconds!
[tester] 
AGNewsMetric: acc=0.47539473684210526, hinge=4.139641700543855, ce=8.480961004558363
Local test acc @ epoch 64: 0.4754
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.5856032371520996
Local loss @ local epoch 1: 0.00036595179699361324
Local loss @ local epoch 2: 9.97988463495858e-05
Local loss @ local epoch 3: 0.00047184014692902565
Local loss @ local epoch 4: 0.0016742759617045522
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.2 seconds!
[tester] 
AGNewsMetric: acc=0.45552631578947367, hinge=8.274218583106995, ce=11.439918624476382
Local test acc @ epoch 64: 0.4555
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0055277650244534016
Local loss @ local epoch 1: 0.0017260024324059486
Local loss @ local epoch 2: 0.00037201688974164426
Local loss @ local epoch 3: 0.00750846927985549
Local loss @ local epoch 4: 0.005932376254349947
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.99 seconds!
[tester] 
AGNewsMetric: acc=0.6252631578947369, hinge=2.985520319185759, ce=11.728417055230391
Local test acc @ epoch 64: 0.6253
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.337922602891922
Local loss @ local epoch 1: 0.008745014667510986
Local loss @ local epoch 2: 0.19347910583019257
Local loss @ local epoch 3: 0.0009861283469945192
Local loss @ local epoch 4: 0.0016815185081213713
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.36 seconds!
[tester] 
AGNewsMetric: acc=0.5561842105263158, hinge=4.49396105465136, ce=9.711501693725586
Local test acc @ epoch 64: 0.5562
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0007048442494124174
Local loss @ local epoch 1: 0.027884356677532196
Local loss @ local epoch 2: 0.0016908750403672457
Local loss @ local epoch 3: 0.11791850626468658
Local loss @ local epoch 4: 0.0009654529858380556
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.95 seconds!
[tester] 
AGNewsMetric: acc=0.8067105263157894, hinge=1.392058764005962, ce=10.090461508098402
Local test acc @ epoch 64: 0.8067
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.07995186001062393
Local loss @ local epoch 1: 0.018913909792900085
Local loss @ local epoch 2: 0.003528196131810546
Local loss @ local epoch 3: 0.05993622541427612
Local loss @ local epoch 4: 0.00836325902491808
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.0 seconds!
[tester] 
AGNewsMetric: acc=0.8331578947368421, hinge=1.2005749326003226, ce=10.688237850791529
Local test acc @ epoch 64: 0.8332
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.08503355085849762
Local loss @ local epoch 1: 0.08840610086917877
Local loss @ local epoch 2: 0.032548222690820694
Local loss @ local epoch 3: 0.03812500089406967
Local loss @ local epoch 4: 0.10965735465288162
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.36 seconds!
[tester] 
AGNewsMetric: acc=0.729078947368421, hinge=2.2492823914477698, ce=10.34639551865427
Local test acc @ epoch 64: 0.7291
Global evaluate on test data...
Evaluate data in 123.98 seconds!
[tester] 
AGNewsMetric: acc=0.8619736842105263, hinge=1.1421646753110384, ce=9.80827900936729
Global test acc @ epoch 64: 0.862
Global epoch 65...
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 4.0695977077120915e-05
Local loss @ local epoch 1: 0.00011269571405136958
Local loss @ local epoch 2: 6.437296065087139e-07
Local loss @ local epoch 3: 5.6504491112718824e-06
Local loss @ local epoch 4: 8.106224527182349e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.05 seconds!
[tester] 
AGNewsMetric: acc=0.6825, hinge=3.443872138575504, ce=9.378316208688837
Local test acc @ epoch 65: 0.6825
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0036541514564305544
Local loss @ local epoch 1: 4.15152644563932e-05
Local loss @ local epoch 2: 1.3286192370287608e-05
Local loss @ local epoch 3: 1.5594343494740315e-05
Local loss @ local epoch 4: 2.5129951609415002e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.54 seconds!
[tester] 
AGNewsMetric: acc=0.4168421052631579, hinge=10.365231360385293, ce=12.237963943481445
Local test acc @ epoch 65: 0.4168
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0015454509994015098
Local loss @ local epoch 1: 0.014182250015437603
Local loss @ local epoch 2: 0.0037884600460529327
Local loss @ local epoch 3: 0.007489389274269342
Local loss @ local epoch 4: 0.2765515148639679
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.31 seconds!
[tester] 
AGNewsMetric: acc=0.819078947368421, hinge=1.5424202758387515, ce=9.564873791744834
Local test acc @ epoch 65: 0.8191
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0012740511447191238
Local loss @ local epoch 1: 0.0014457646757364273
Local loss @ local epoch 2: 0.002165159210562706
Local loss @ local epoch 3: 0.0007700356654822826
Local loss @ local epoch 4: 0.0006635914323851466
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.22 seconds!
[tester] 
AGNewsMetric: acc=0.7157894736842105, hinge=2.67814722161544, ce=9.247248268127441
Local test acc @ epoch 65: 0.7158
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0009608657564967871
Local loss @ local epoch 1: 0.00030016122036613524
Local loss @ local epoch 2: 0.00015622733917552978
Local loss @ local epoch 3: 0.0019311566138640046
Local loss @ local epoch 4: 0.00018164356879424304
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.77 seconds!
[tester] 
AGNewsMetric: acc=0.5330263157894737, hinge=4.872532091642681, ce=11.137621409767553
Local test acc @ epoch 65: 0.533
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 1.3510558605194092
Local loss @ local epoch 1: 0.08057726174592972
Local loss @ local epoch 2: 0.08269327133893967
Local loss @ local epoch 3: 0.031598757952451706
Local loss @ local epoch 4: 0.01204037107527256
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.11 seconds!
[tester] 
AGNewsMetric: acc=0.6390789473684211, hinge=3.0121157962397525, ce=8.526380561025519
Local test acc @ epoch 65: 0.6391
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.056777868419885635
Local loss @ local epoch 1: 0.3687940537929535
Local loss @ local epoch 2: 0.03767606243491173
Local loss @ local epoch 3: 0.017319105565547943
Local loss @ local epoch 4: 0.29474586248397827
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.43 seconds!
[tester] 
AGNewsMetric: acc=0.8625, hinge=1.0306166488245914, ce=9.470986470674214
Local test acc @ epoch 65: 0.8625
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.027461204677820206
Local loss @ local epoch 1: 0.06824152916669846
Local loss @ local epoch 2: 0.028890779241919518
Local loss @ local epoch 3: 0.012349597178399563
Local loss @ local epoch 4: 0.011747440323233604
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.75 seconds!
[tester] 
AGNewsMetric: acc=0.6653947368421053, hinge=2.8929951241141874, ce=8.496756272566946
Local test acc @ epoch 65: 0.6654
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.3665214776992798
Local loss @ local epoch 1: 0.2560989260673523
Local loss @ local epoch 2: 0.04415173456072807
Local loss @ local epoch 3: 0.001470874180085957
Local loss @ local epoch 4: 0.0020705319475382566
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.85 seconds!
[tester] 
AGNewsMetric: acc=0.44671052631578945, hinge=5.084289843408685, ce=9.735288939225047
Local test acc @ epoch 65: 0.4467
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.01054296549409628
Local loss @ local epoch 1: 0.0027036492247134447
Local loss @ local epoch 2: 0.0010918545303866267
Local loss @ local epoch 3: 0.0022446580696851015
Local loss @ local epoch 4: 0.003855052636936307
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.88 seconds!
[tester] 
AGNewsMetric: acc=0.64, hinge=2.756853576459383, ce=11.069911631533975
Local test acc @ epoch 65: 0.64
Global evaluate on test data...
Evaluate data in 124.94 seconds!
[tester] 
AGNewsMetric: acc=0.8396052631578947, hinge=1.2715386493582475, ce=10.150304372687089
Global test acc @ epoch 65: 0.8396
Global epoch 66...
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.20379576086997986
Local loss @ local epoch 1: 0.004887560848146677
Local loss @ local epoch 2: 0.004407776519656181
Local loss @ local epoch 3: 0.24181509017944336
Local loss @ local epoch 4: 0.0023028664290905
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.49 seconds!
[tester] 
AGNewsMetric: acc=0.5721052631578948, hinge=4.992240820432964, ce=9.166632569965563
Local test acc @ epoch 66: 0.5721
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 1.4648562669754028
Local loss @ local epoch 1: 0.03079230524599552
Local loss @ local epoch 2: 0.002012701006606221
Local loss @ local epoch 3: 0.0005586748011410236
Local loss @ local epoch 4: 0.001306505291722715
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.38 seconds!
[tester] 
AGNewsMetric: acc=0.44710526315789473, hinge=6.88828553199768, ce=10.94776583420603
Local test acc @ epoch 66: 0.4471
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 2.325807809829712
Local loss @ local epoch 1: 0.09779448807239532
Local loss @ local epoch 2: 0.1252782940864563
Local loss @ local epoch 3: 0.16569584608078003
Local loss @ local epoch 4: 0.37139275670051575
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.93 seconds!
[tester] 
AGNewsMetric: acc=0.7075, hinge=2.241137375831604, ce=10.77704955853914
Local test acc @ epoch 66: 0.7075
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 1.5751090049743652
Local loss @ local epoch 1: 0.033441439270973206
Local loss @ local epoch 2: 0.001531320158392191
Local loss @ local epoch 3: 0.0015300184022635221
Local loss @ local epoch 4: 0.0003711245662998408
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.94 seconds!
[tester] 
AGNewsMetric: acc=0.45539473684210524, hinge=6.1942756020395375, ce=12.477327065718802
Local test acc @ epoch 66: 0.4554
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 4.911404630547622e-06
Local loss @ local epoch 1: 1.2159332527517108e-06
Local loss @ local epoch 2: 2.9919659937149845e-05
Local loss @ local epoch 3: 8.60682030179305e-06
Local loss @ local epoch 4: 5.24520601175027e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.72 seconds!
[tester] 
AGNewsMetric: acc=0.6489473684210526, hinge=3.431317830838655, ce=10.445643013402035
Local test acc @ epoch 66: 0.6489
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.014471960254013538
Local loss @ local epoch 1: 0.0748782753944397
Local loss @ local epoch 2: 0.040271855890750885
Local loss @ local epoch 3: 0.07744301110506058
Local loss @ local epoch 4: 0.03616013377904892
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.22 seconds!
[tester] 
AGNewsMetric: acc=0.7331578947368421, hinge=2.0989913232702957, ce=10.103945009331953
Local test acc @ epoch 66: 0.7332
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.292080819606781
Local loss @ local epoch 1: 0.007300036493688822
Local loss @ local epoch 2: 0.0006434821407310665
Local loss @ local epoch 3: 0.010314907878637314
Local loss @ local epoch 4: 0.004628089256584644
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.52 seconds!
[tester] 
AGNewsMetric: acc=0.6017105263157895, hinge=3.8803401332152516, ce=11.742324011953254
Local test acc @ epoch 66: 0.6017
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0735061913728714
Local loss @ local epoch 1: 0.00021450668282341212
Local loss @ local epoch 2: 0.0005990448989905417
Local loss @ local epoch 3: 0.0003003473684657365
Local loss @ local epoch 4: 7.446271047228947e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.79 seconds!
[tester] 
AGNewsMetric: acc=0.5282894736842105, hinge=4.320128953833329, ce=10.750521752206902
Local test acc @ epoch 66: 0.5283
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.007437785156071186
Local loss @ local epoch 1: 0.0003251855378039181
Local loss @ local epoch 2: 0.054616209119558334
Local loss @ local epoch 3: 0.0008180629811249673
Local loss @ local epoch 4: 0.000281183427432552
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.02 seconds!
[tester] 
AGNewsMetric: acc=0.6832894736842106, hinge=2.3348106251264875, ce=7.491167822386089
Local test acc @ epoch 66: 0.6833
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.4471474885940552
Local loss @ local epoch 1: 0.011782648041844368
Local loss @ local epoch 2: 0.009096595458686352
Local loss @ local epoch 3: 0.03953489661216736
Local loss @ local epoch 4: 0.10110680758953094
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 125.19 seconds!
[tester] 
AGNewsMetric: acc=0.38644736842105265, hinge=6.8035922462061835, ce=9.397881700616134
Local test acc @ epoch 66: 0.3864
Global evaluate on test data...
Evaluate data in 123.06 seconds!
[tester] 
AGNewsMetric: acc=0.845657894736842, hinge=1.3696965636705098, ce=9.966242984972503
Global test acc @ epoch 66: 0.8457
Global epoch 67...
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.004683053120970726
Local loss @ local epoch 1: 3.521296093822457e-05
Local loss @ local epoch 2: 1.458301176171517e-05
Local loss @ local epoch 3: 0.0004857845196966082
Local loss @ local epoch 4: 0.0002047982852673158
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.4 seconds!
[tester] 
AGNewsMetric: acc=0.45552631578947367, hinge=10.70350819311644, ce=13.507430178993626
Local test acc @ epoch 67: 0.4555
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.9847530126571655
Local loss @ local epoch 1: 0.11435485631227493
Local loss @ local epoch 2: 0.010277287103235722
Local loss @ local epoch 3: 0.01052116695791483
Local loss @ local epoch 4: 0.22408322989940643
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.42 seconds!
[tester] 
AGNewsMetric: acc=0.43776315789473685, hinge=4.946387004852295, ce=9.143192819294176
Local test acc @ epoch 67: 0.4378
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0012865109601989388
Local loss @ local epoch 1: 0.0006071872776374221
Local loss @ local epoch 2: 0.000875780766364187
Local loss @ local epoch 3: 0.30653315782546997
Local loss @ local epoch 4: 0.0008805175311863422
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.08 seconds!
[tester] 
AGNewsMetric: acc=0.6792105263157895, hinge=2.786594669944362, ce=9.109289460433157
Local test acc @ epoch 67: 0.6792
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.009085812605917454
Local loss @ local epoch 1: 0.04252234473824501
Local loss @ local epoch 2: 0.013395929709076881
Local loss @ local epoch 3: 0.02679041586816311
Local loss @ local epoch 4: 0.01911371573805809
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.93 seconds!
[tester] 
AGNewsMetric: acc=0.7018421052631579, hinge=2.4206224870681763, ce=10.84891426487973
Local test acc @ epoch 67: 0.7018
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.02392236329615116
Local loss @ local epoch 1: 0.0064329784363508224
Local loss @ local epoch 2: 0.00858606118708849
Local loss @ local epoch 3: 0.0011478522792458534
Local loss @ local epoch 4: 0.01995273493230343
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.34 seconds!
[tester] 
AGNewsMetric: acc=0.5527631578947368, hinge=3.040984209462216, ce=11.588959475065533
Local test acc @ epoch 67: 0.5528
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 2.057514757325407e-05
Local loss @ local epoch 1: 3.1709575978311477e-06
Local loss @ local epoch 2: 1.549718376736564e-06
Local loss @ local epoch 3: 1.263616240976262e-06
Local loss @ local epoch 4: 1.8835041828424437e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.76 seconds!
[tester] 
AGNewsMetric: acc=0.7063157894736842, hinge=2.851567582080239, ce=9.454818332069799
Local test acc @ epoch 67: 0.7063
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 1.600264310836792
Local loss @ local epoch 1: 0.13080738484859467
Local loss @ local epoch 2: 0.02064218744635582
Local loss @ local epoch 3: 0.01742876134812832
Local loss @ local epoch 4: 0.005204516928642988
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.62 seconds!
[tester] 
AGNewsMetric: acc=0.5053947368421052, hinge=4.498296384811401, ce=10.562094443471809
Local test acc @ epoch 67: 0.5054
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0014221445890143514
Local loss @ local epoch 1: 0.289274126291275
Local loss @ local epoch 2: 0.009797153063118458
Local loss @ local epoch 3: 0.01581641659140587
Local loss @ local epoch 4: 0.015151924453675747
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.45 seconds!
[tester] 
AGNewsMetric: acc=0.8685526315789474, hinge=0.955736091011449, ce=9.872842614023309
Local test acc @ epoch 67: 0.8686
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.17716248333454132
Local loss @ local epoch 1: 0.2574993371963501
Local loss @ local epoch 2: 0.0075384024530649185
Local loss @ local epoch 3: 0.4622184634208679
Local loss @ local epoch 4: 0.010937378741800785
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.41 seconds!
[tester] 
AGNewsMetric: acc=0.7834210526315789, hinge=1.6324151450709292, ce=7.828959629661158
Local test acc @ epoch 67: 0.7834
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0029902232345193624
Local loss @ local epoch 1: 2.7460686396807432e-05
Local loss @ local epoch 2: 2.5845329219009727e-05
Local loss @ local epoch 3: 2.0329987819422968e-05
Local loss @ local epoch 4: 2.234578823845368e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.88 seconds!
[tester] 
AGNewsMetric: acc=0.36328947368421055, hinge=13.341746398524235, ce=14.976727064032303
Local test acc @ epoch 67: 0.3633
Global evaluate on test data...
Evaluate data in 124.16 seconds!
[tester] 
AGNewsMetric: acc=0.8569736842105263, hinge=1.1025210887507388, ce=9.844485977574399
Global test acc @ epoch 67: 0.857
Global epoch 68...
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0001639792462810874
Local loss @ local epoch 1: 0.0007580941310152411
Local loss @ local epoch 2: 0.0661088228225708
Local loss @ local epoch 3: 0.00015546331997029483
Local loss @ local epoch 4: 0.0007225339068099856
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 125.02 seconds!
[tester] 
AGNewsMetric: acc=0.7723684210526316, hinge=1.6495460146351864, ce=10.597179129751105
Local test acc @ epoch 68: 0.7724
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.5946658849716187
Local loss @ local epoch 1: 0.002109272638335824
Local loss @ local epoch 2: 7.606820872751996e-05
Local loss @ local epoch 3: 0.00017245812341570854
Local loss @ local epoch 4: 0.00025630040909163654
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 125.16 seconds!
[tester] 
AGNewsMetric: acc=0.4913157894736842, hinge=6.839104834355806, ce=10.131538120069003
Local test acc @ epoch 68: 0.4913
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 2.551069655964966e-06
Local loss @ local epoch 1: 1.032345426210668e-05
Local loss @ local epoch 2: 7.756835111649707e-05
Local loss @ local epoch 3: 5.6764074543025345e-05
Local loss @ local epoch 4: 0.00015163843636400998
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.74 seconds!
[tester] 
AGNewsMetric: acc=0.4756578947368421, hinge=6.112826478857743, ce=12.844451739662572
Local test acc @ epoch 68: 0.4757
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.008910322561860085
Local loss @ local epoch 1: 0.00021914350509177893
Local loss @ local epoch 2: 0.0008697111625224352
Local loss @ local epoch 3: 0.005456135142594576
Local loss @ local epoch 4: 0.001126350020058453
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.57 seconds!
[tester] 
AGNewsMetric: acc=0.6378947368421053, hinge=2.584990295359963, ce=11.111926536560059
Local test acc @ epoch 68: 0.6379
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.4973917007446289
Local loss @ local epoch 1: 0.0004968232824467123
Local loss @ local epoch 2: 0.00010067357652587816
Local loss @ local epoch 3: 9.038509597303346e-05
Local loss @ local epoch 4: 5.327172402758151e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.85 seconds!
[tester] 
AGNewsMetric: acc=0.4189473684210526, hinge=9.5604848530418, ce=13.124813009563246
Local test acc @ epoch 68: 0.4189
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0683477595448494
Local loss @ local epoch 1: 0.006886180490255356
Local loss @ local epoch 2: 0.0006410945788957179
Local loss @ local epoch 3: 0.0023526528384536505
Local loss @ local epoch 4: 0.03880784288048744
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.68 seconds!
[tester] 
AGNewsMetric: acc=0.738421052631579, hinge=2.457674500063846, ce=10.488505018133866
Local test acc @ epoch 68: 0.7384
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.2919463515281677
Local loss @ local epoch 1: 0.02186259627342224
Local loss @ local epoch 2: 0.195047527551651
Local loss @ local epoch 3: 0.06430798023939133
Local loss @ local epoch 4: 0.0913824811577797
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.16 seconds!
[tester] 
AGNewsMetric: acc=0.7428947368421053, hinge=2.2168963211461117, ce=10.505892448425293
Local test acc @ epoch 68: 0.7429
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.39717596769332886
Local loss @ local epoch 1: 0.006335627753287554
Local loss @ local epoch 2: 0.012883750721812248
Local loss @ local epoch 3: 0.09784296154975891
Local loss @ local epoch 4: 0.02471461519598961
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.82 seconds!
[tester] 
AGNewsMetric: acc=0.4788157894736842, hinge=5.308927683579294, ce=9.521251776845832
Local test acc @ epoch 68: 0.4788
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.0243592262268066
Local loss @ local epoch 1: 0.10607506334781647
Local loss @ local epoch 2: 0.013893942348659039
Local loss @ local epoch 3: 0.043248359113931656
Local loss @ local epoch 4: 0.004541108384728432
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.56 seconds!
[tester] 
AGNewsMetric: acc=0.46710526315789475, hinge=4.233051361786692, ce=8.1911809288828
Local test acc @ epoch 68: 0.4671
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 1.2534546852111816
Local loss @ local epoch 1: 0.12513303756713867
Local loss @ local epoch 2: 0.04615216329693794
Local loss @ local epoch 3: 0.6301035284996033
Local loss @ local epoch 4: 0.05156996101140976
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.69 seconds!
[tester] 
AGNewsMetric: acc=0.7756578947368421, hinge=1.695292178706119, ce=10.495738015425832
Local test acc @ epoch 68: 0.7757
Global evaluate on test data...
Evaluate data in 123.86 seconds!
[tester] 
AGNewsMetric: acc=0.8706578947368421, hinge=1.1082267241728934, ce=9.768170063621119
Global test acc @ epoch 68: 0.8707
Global epoch 69...
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 1.0204201316810213e-05
Local loss @ local epoch 1: 3.1471099646296352e-06
Local loss @ local epoch 2: 4.625272595148999e-06
Local loss @ local epoch 3: 1.907345335894206e-06
Local loss @ local epoch 4: 1.1205663668079069e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.81 seconds!
[tester] 
AGNewsMetric: acc=0.5944736842105263, hinge=4.505022541849237, ce=10.320518186468828
Local test acc @ epoch 69: 0.5945
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.1429741531610489
Local loss @ local epoch 1: 0.49295347929000854
Local loss @ local epoch 2: 0.5437768697738647
Local loss @ local epoch 3: 0.09123670309782028
Local loss @ local epoch 4: 0.13755126297473907
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.91 seconds!
[tester] 
AGNewsMetric: acc=0.8551315789473685, hinge=1.0533475870835154, ce=8.627089905989797
Local test acc @ epoch 69: 0.8551
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 1.3798317013424821e-05
Local loss @ local epoch 1: 0.0005614940891973674
Local loss @ local epoch 2: 2.9324772185645998e-05
Local loss @ local epoch 3: 0.0023841506335884333
Local loss @ local epoch 4: 0.0009503650944679976
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.74 seconds!
[tester] 
AGNewsMetric: acc=0.7023684210526315, hinge=2.538545103324087, ce=9.02107545953048
Local test acc @ epoch 69: 0.7024
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.001968405209481716
Local loss @ local epoch 1: 9.608970140106976e-05
Local loss @ local epoch 2: 0.031170278787612915
Local loss @ local epoch 3: 0.00046488651423715055
Local loss @ local epoch 4: 0.0010306021431460977
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.37 seconds!
[tester] 
AGNewsMetric: acc=0.7468421052631579, hinge=2.266637867375424, ce=10.184572392513877
Local test acc @ epoch 69: 0.7468
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.019171105697751045
Local loss @ local epoch 1: 0.2350788116455078
Local loss @ local epoch 2: 0.011980151757597923
Local loss @ local epoch 3: 0.15932004153728485
Local loss @ local epoch 4: 0.0139547660946846
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.67 seconds!
[tester] 
AGNewsMetric: acc=0.645921052631579, hinge=2.9501340349097003, ce=9.539981894242135
Local test acc @ epoch 69: 0.6459
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.3334909677505493
Local loss @ local epoch 1: 0.004543189890682697
Local loss @ local epoch 2: 0.0038462895900011063
Local loss @ local epoch 3: 0.005850954446941614
Local loss @ local epoch 4: 0.012280995026230812
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.32 seconds!
[tester] 
AGNewsMetric: acc=0.38894736842105265, hinge=7.250975989291542, ce=10.455046830428275
Local test acc @ epoch 69: 0.3889
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.046689990907907486
Local loss @ local epoch 1: 0.012719068676233292
Local loss @ local epoch 2: 0.002708217827603221
Local loss @ local epoch 3: 0.0002308009861735627
Local loss @ local epoch 4: 0.0023447000421583652
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.27 seconds!
[tester] 
AGNewsMetric: acc=0.5535526315789474, hinge=3.1662793028982064, ce=11.20408038490697
Local test acc @ epoch 69: 0.5536
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.007587304338812828
Local loss @ local epoch 1: 0.00013941396900918335
Local loss @ local epoch 2: 8.871655882103369e-05
Local loss @ local epoch 3: 0.00027087153284810483
Local loss @ local epoch 4: 0.0068570994772017
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.66 seconds!
[tester] 
AGNewsMetric: acc=0.4901315789473684, hinge=6.759376711343464, ce=10.408628646449039
Local test acc @ epoch 69: 0.4901
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.010141929611563683
Local loss @ local epoch 1: 0.00025690102484077215
Local loss @ local epoch 2: 0.00010605319403111935
Local loss @ local epoch 3: 5.238307494437322e-05
Local loss @ local epoch 4: 4.16121692978777e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.59 seconds!
[tester] 
AGNewsMetric: acc=0.43565789473684213, hinge=10.655344639326398, ce=10.769974981609144
Local test acc @ epoch 69: 0.4357
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 1.5933494567871094
Local loss @ local epoch 1: 0.131301149725914
Local loss @ local epoch 2: 0.010644163005053997
Local loss @ local epoch 3: 0.007976764813065529
Local loss @ local epoch 4: 0.0067083328031003475
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.35 seconds!
[tester] 
AGNewsMetric: acc=0.546578947368421, hinge=3.6348490579504715, ce=9.795594424197548
Local test acc @ epoch 69: 0.5466
Global evaluate on test data...
Evaluate data in 123.09 seconds!
[tester] 
AGNewsMetric: acc=0.8655263157894737, hinge=1.0555563914148431, ce=9.640580966347143
Global test acc @ epoch 69: 0.8655
Global epoch 70...
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.03672788664698601
Local loss @ local epoch 1: 0.0024850619956851006
Local loss @ local epoch 2: 9.904543549055234e-05
Local loss @ local epoch 3: 5.788352791569196e-05
Local loss @ local epoch 4: 0.00027123017935082316
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.05 seconds!
[tester] 
AGNewsMetric: acc=0.46, hinge=9.463922550050835, ce=11.549945556239077
Local test acc @ epoch 70: 0.46
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 1.6212437685680925e-06
Local loss @ local epoch 1: 6.198880555530195e-07
Local loss @ local epoch 2: 2.9086959330015816e-06
Local loss @ local epoch 3: 5.483624363478157e-07
Local loss @ local epoch 4: 1.6689295989635866e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.54 seconds!
[tester] 
AGNewsMetric: acc=0.6639473684210526, hinge=3.7154296498549613, ce=11.088993853518838
Local test acc @ epoch 70: 0.6639
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.7537885308265686
Local loss @ local epoch 1: 0.052801959216594696
Local loss @ local epoch 2: 0.03372731804847717
Local loss @ local epoch 3: 0.0034993281587958336
Local loss @ local epoch 4: 0.000829401717055589
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.55 seconds!
[tester] 
AGNewsMetric: acc=0.4406578947368421, hinge=5.1051162875326055, ce=7.587513960788124
Local test acc @ epoch 70: 0.4407
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.1066439151763916
Local loss @ local epoch 1: 0.005344395060092211
Local loss @ local epoch 2: 0.00037030302337370813
Local loss @ local epoch 3: 0.0001835669536376372
Local loss @ local epoch 4: 0.004125872161239386
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 122.85 seconds!
[tester] 
AGNewsMetric: acc=0.7423684210526316, hinge=2.08877297501815, ce=10.26098849848697
Local test acc @ epoch 70: 0.7424
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.08596717566251755
Local loss @ local epoch 1: 0.5731350183486938
Local loss @ local epoch 2: 0.01280533242970705
Local loss @ local epoch 3: 0.0024333621840924025
Local loss @ local epoch 4: 0.5192304253578186
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.97 seconds!
[tester] 
AGNewsMetric: acc=0.6572368421052631, hinge=2.9430236003273413, ce=11.023804957741186
Local test acc @ epoch 70: 0.6572
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.00011138635454699397
Local loss @ local epoch 1: 0.00019621412502601743
Local loss @ local epoch 2: 5.301606870489195e-05
Local loss @ local epoch 3: 0.0005576547118835151
Local loss @ local epoch 4: 0.0002811398298945278
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.38 seconds!
[tester] 
AGNewsMetric: acc=0.7663157894736842, hinge=1.822393404810052, ce=5.128451876389353
Local test acc @ epoch 70: 0.7663
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.08014203608036041
Local loss @ local epoch 1: 0.00987674668431282
Local loss @ local epoch 2: 0.008323189802467823
Local loss @ local epoch 3: 0.017155446112155914
Local loss @ local epoch 4: 0.0032863481901586056
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.76 seconds!
[tester] 
AGNewsMetric: acc=0.5225, hinge=4.053574188633969, ce=8.111073948709588
Local test acc @ epoch 70: 0.5225
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.01339868362993002
Local loss @ local epoch 1: 0.003048771293833852
Local loss @ local epoch 2: 0.001659699366427958
Local loss @ local epoch 3: 0.00012428655463736504
Local loss @ local epoch 4: 0.004309248179197311
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.0 seconds!
[tester] 
AGNewsMetric: acc=0.6560526315789473, hinge=2.470275385505275, ce=11.905649508426064
Local test acc @ epoch 70: 0.6561
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.24031732976436615
Local loss @ local epoch 1: 0.0554535947740078
Local loss @ local epoch 2: 0.0793738067150116
Local loss @ local epoch 3: 0.16126932203769684
Local loss @ local epoch 4: 0.013227715156972408
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.17 seconds!
[tester] 
AGNewsMetric: acc=0.8302631578947368, hinge=1.519440938297071, ce=9.423927666513544
Local test acc @ epoch 70: 0.8303
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.051106929779052734
Local loss @ local epoch 1: 0.0014614324318245053
Local loss @ local epoch 2: 0.001245472813025117
Local loss @ local epoch 3: 0.0017076527001336217
Local loss @ local epoch 4: 0.002845448674634099
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.59 seconds!
[tester] 
AGNewsMetric: acc=0.4256578947368421, hinge=9.665800701944452, ce=11.128224543521279
Local test acc @ epoch 70: 0.4257
Global evaluate on test data...
Evaluate data in 124.92 seconds!
[tester] 
AGNewsMetric: acc=0.866578947368421, hinge=1.1695446154945774, ce=9.93415681939376
Global test acc @ epoch 70: 0.8666
Global epoch 71...
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0018559228628873825
Local loss @ local epoch 1: 0.04527497664093971
Local loss @ local epoch 2: 0.010567122139036655
Local loss @ local epoch 3: 0.0018581274198368192
Local loss @ local epoch 4: 0.005840890109539032
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.03 seconds!
[tester] 
AGNewsMetric: acc=0.7422368421052632, hinge=1.7905300188064575, ce=7.850240201448139
Local test acc @ epoch 71: 0.7422
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 2.6464390430191997e-06
Local loss @ local epoch 1: 4.768367887209024e-07
Local loss @ local epoch 2: 4.768371297814156e-08
Local loss @ local epoch 3: 1.304131183132995e-05
Local loss @ local epoch 4: 1.1157741937495302e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.95 seconds!
[tester] 
AGNewsMetric: acc=0.6646052631578947, hinge=4.099359955034758, ce=10.421491665087249
Local test acc @ epoch 71: 0.6646
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.7847978472709656
Local loss @ local epoch 1: 0.014254827983677387
Local loss @ local epoch 2: 0.2602165937423706
Local loss @ local epoch 3: 0.03998878225684166
Local loss @ local epoch 4: 0.1256779432296753
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.71 seconds!
[tester] 
AGNewsMetric: acc=0.7890789473684211, hinge=1.560928693068655, ce=10.610568670975535
Local test acc @ epoch 71: 0.7891
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0015231018187478185
Local loss @ local epoch 1: 0.000720207579433918
Local loss @ local epoch 2: 0.001914793741889298
Local loss @ local epoch 3: 0.0010314704850316048
Local loss @ local epoch 4: 0.018399395048618317
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.37 seconds!
[tester] 
AGNewsMetric: acc=0.6872368421052631, hinge=2.259213675448769, ce=8.3133555924265
Local test acc @ epoch 71: 0.6872
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.008722194470465183
Local loss @ local epoch 1: 0.00036199402529746294
Local loss @ local epoch 2: 9.009887435240671e-05
Local loss @ local epoch 3: 0.00012279899965506047
Local loss @ local epoch 4: 0.00012672480079345405
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.18 seconds!
[tester] 
AGNewsMetric: acc=0.28539473684210526, hinge=12.645959137364438, ce=13.133685346904555
Local test acc @ epoch 71: 0.2854
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.6330691576004028
Local loss @ local epoch 1: 0.05422355234622955
Local loss @ local epoch 2: 0.05668064206838608
Local loss @ local epoch 3: 0.005411997437477112
Local loss @ local epoch 4: 0.007463762070983648
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.44 seconds!
[tester] 
AGNewsMetric: acc=0.5318421052631579, hinge=3.8014041740015934, ce=8.709150401667545
Local test acc @ epoch 71: 0.5318
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.133013367652893
Local loss @ local epoch 1: 0.2701018154621124
Local loss @ local epoch 2: 0.028111204504966736
Local loss @ local epoch 3: 0.24536147713661194
Local loss @ local epoch 4: 0.26009681820869446
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.62 seconds!
[tester] 
AGNewsMetric: acc=0.6590789473684211, hinge=2.276179653970819, ce=6.534914246609336
Local test acc @ epoch 71: 0.6591
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.011512446217238903
Local loss @ local epoch 1: 0.019050968810915947
Local loss @ local epoch 2: 0.00015970297681633383
Local loss @ local epoch 3: 0.0026818334590643644
Local loss @ local epoch 4: 0.3118049204349518
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.82 seconds!
[tester] 
AGNewsMetric: acc=0.7882894736842105, hinge=1.7163050480892783, ce=9.114346034401342
Local test acc @ epoch 71: 0.7883
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.22216306626796722
Local loss @ local epoch 1: 0.2134670615196228
Local loss @ local epoch 2: 0.1592990756034851
Local loss @ local epoch 3: 0.21503585577011108
Local loss @ local epoch 4: 0.02721116691827774
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.4 seconds!
[tester] 
AGNewsMetric: acc=0.8465789473684211, hinge=1.1769236060192712, ce=9.699911519100791
Local test acc @ epoch 71: 0.8466
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.01898396946489811
Local loss @ local epoch 1: 0.0006488033104687929
Local loss @ local epoch 2: 0.004706949461251497
Local loss @ local epoch 3: 0.000886409601662308
Local loss @ local epoch 4: 0.00039248657412827015
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.81 seconds!
[tester] 
AGNewsMetric: acc=0.44526315789473686, hinge=9.148590184763858, ce=10.725051008525648
Local test acc @ epoch 71: 0.4453
Global evaluate on test data...
Evaluate data in 124.18 seconds!
[tester] 
AGNewsMetric: acc=0.8559210526315789, hinge=1.106978662390458, ce=9.035076026916505
Global test acc @ epoch 71: 0.8559
Global epoch 72...
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 5.912740562052932e-06
Local loss @ local epoch 1: 6.842555194452871e-06
Local loss @ local epoch 2: 0.00019948351837228984
Local loss @ local epoch 3: 1.6092668374767527e-05
Local loss @ local epoch 4: 3.838527391053503e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.23 seconds!
[tester] 
AGNewsMetric: acc=0.5611842105263158, hinge=4.518589396727712, ce=10.91607691313091
Local test acc @ epoch 72: 0.5612
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.04329118877649307
Local loss @ local epoch 1: 0.007567597087472677
Local loss @ local epoch 2: 0.005443880800157785
Local loss @ local epoch 3: 0.004254268016666174
Local loss @ local epoch 4: 0.0007445766241289675
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.12 seconds!
[tester] 
AGNewsMetric: acc=0.4726315789473684, hinge=5.663237325768722, ce=10.007252747385126
Local test acc @ epoch 72: 0.4726
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.003417801111936569
Local loss @ local epoch 1: 0.007804018910974264
Local loss @ local epoch 2: 0.00016705993039067835
Local loss @ local epoch 3: 0.00023859697103034705
Local loss @ local epoch 4: 0.0036608923692256212
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.7 seconds!
[tester] 
AGNewsMetric: acc=0.8680263157894736, hinge=1.0730860792963128, ce=10.059336130242599
Local test acc @ epoch 72: 0.868
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.01343351136893034
Local loss @ local epoch 1: 0.008100203238427639
Local loss @ local epoch 2: 0.3683948814868927
Local loss @ local epoch 3: 0.2901183068752289
Local loss @ local epoch 4: 0.05411282181739807
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.69 seconds!
[tester] 
AGNewsMetric: acc=0.8296052631578947, hinge=1.2876085559945358, ce=10.194586207741185
Local test acc @ epoch 72: 0.8296
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.00015573880227748305
Local loss @ local epoch 1: 0.00018813756469171494
Local loss @ local epoch 2: 7.294943497981876e-05
Local loss @ local epoch 3: 8.492544293403625e-05
Local loss @ local epoch 4: 0.0002913856878876686
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.98 seconds!
[tester] 
AGNewsMetric: acc=0.7726315789473684, hinge=2.0474048980913664, ce=10.123864127711245
Local test acc @ epoch 72: 0.7726
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.3978535234928131
Local loss @ local epoch 1: 0.016980990767478943
Local loss @ local epoch 2: 0.009796182624995708
Local loss @ local epoch 3: 0.07634856551885605
Local loss @ local epoch 4: 0.01836967095732689
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.94 seconds!
[tester] 
AGNewsMetric: acc=0.5290789473684211, hinge=4.744581532729299, ce=7.989499589016563
Local test acc @ epoch 72: 0.5291
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.025083305314183235
Local loss @ local epoch 1: 7.936899055493996e-05
Local loss @ local epoch 2: 6.377218960551545e-05
Local loss @ local epoch 3: 0.003502792678773403
Local loss @ local epoch 4: 5.246961154625751e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.26 seconds!
[tester] 
AGNewsMetric: acc=0.465, hinge=9.695411949157714, ce=12.156373923452277
Local test acc @ epoch 72: 0.465
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.07545410841703415
Local loss @ local epoch 1: 0.00016055373998824507
Local loss @ local epoch 2: 0.00503047090023756
Local loss @ local epoch 3: 0.00027803154080174863
Local loss @ local epoch 4: 0.0031078553292900324
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.81 seconds!
[tester] 
AGNewsMetric: acc=0.5668421052631579, hinge=4.651683306443064, ce=11.62772190093994
Local test acc @ epoch 72: 0.5668
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.31645533442497253
Local loss @ local epoch 1: 0.0452520027756691
Local loss @ local epoch 2: 0.39694368839263916
Local loss @ local epoch 3: 0.0479208342730999
Local loss @ local epoch 4: 0.01707647554576397
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.56 seconds!
[tester] 
AGNewsMetric: acc=0.8768421052631579, hinge=0.8976435530813117, ce=9.736166195116546
Local test acc @ epoch 72: 0.8768
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.008405781351029873
Local loss @ local epoch 1: 0.00013941632641945034
Local loss @ local epoch 2: 6.670240691164508e-05
Local loss @ local epoch 3: 0.0007680875132791698
Local loss @ local epoch 4: 0.005009060725569725
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.56 seconds!
[tester] 
AGNewsMetric: acc=0.4776315789473684, hinge=9.42953522506513, ce=10.222444510208932
Local test acc @ epoch 72: 0.4776
Global evaluate on test data...
Evaluate data in 123.72 seconds!
[tester] 
AGNewsMetric: acc=0.876578947368421, hinge=1.1461437368392944, ce=9.714477912501286
Global test acc @ epoch 72: 0.8766
Global epoch 73...
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.08605892211198807
Local loss @ local epoch 1: 0.00022787362104281783
Local loss @ local epoch 2: 4.824551069759764e-05
Local loss @ local epoch 3: 0.000864953501150012
Local loss @ local epoch 4: 9.503053297521546e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.06 seconds!
[tester] 
AGNewsMetric: acc=0.41592105263157897, hinge=9.419382083792435, ce=11.013241880316484
Local test acc @ epoch 73: 0.4159
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 7.152552825573366e-07
Local loss @ local epoch 1: 2.861022494471399e-07
Local loss @ local epoch 2: 6.0319034673739225e-06
Local loss @ local epoch 3: 4.243839612172451e-06
Local loss @ local epoch 4: 1.4781925301576848e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.44 seconds!
[tester] 
AGNewsMetric: acc=0.5946052631578947, hinge=5.214155242819535, ce=11.092523904097707
Local test acc @ epoch 73: 0.5946
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0022121763322502375
Local loss @ local epoch 1: 0.00020831359142903239
Local loss @ local epoch 2: 0.004592293407768011
Local loss @ local epoch 3: 0.00015702267410233617
Local loss @ local epoch 4: 0.01040998101234436
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.74 seconds!
[tester] 
AGNewsMetric: acc=0.7964473684210527, hinge=1.6600631711357519, ce=8.445789423490826
Local test acc @ epoch 73: 0.7964
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.3481183648109436
Local loss @ local epoch 1: 0.14497622847557068
Local loss @ local epoch 2: 0.46233367919921875
Local loss @ local epoch 3: 0.2369721531867981
Local loss @ local epoch 4: 0.021494541317224503
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.43 seconds!
[tester] 
AGNewsMetric: acc=0.8122368421052631, hinge=1.7146462342613622, ce=9.41141170501709
Local test acc @ epoch 73: 0.8122
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.2524784803390503
Local loss @ local epoch 1: 0.3266742527484894
Local loss @ local epoch 2: 0.0746479257941246
Local loss @ local epoch 3: 0.010595718398690224
Local loss @ local epoch 4: 0.03558066114783287
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.39 seconds!
[tester] 
AGNewsMetric: acc=0.5222368421052631, hinge=4.862983631836741, ce=9.34544212542082
Local test acc @ epoch 73: 0.5222
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0030238148756325245
Local loss @ local epoch 1: 0.00033729884307831526
Local loss @ local epoch 2: 0.0014265499776229262
Local loss @ local epoch 3: 0.002334396820515394
Local loss @ local epoch 4: 0.006152531132102013
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.27 seconds!
[tester] 
AGNewsMetric: acc=0.7646052631578948, hinge=1.8213011661328768, ce=7.150017058723852
Local test acc @ epoch 73: 0.7646
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.02185187302529812
Local loss @ local epoch 1: 0.00040885250200517476
Local loss @ local epoch 2: 0.00021003813890274614
Local loss @ local epoch 3: 0.003166060196235776
Local loss @ local epoch 4: 0.0003522439219523221
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.69 seconds!
[tester] 
AGNewsMetric: acc=0.45907894736842103, hinge=10.544057154906424, ce=11.802557479456851
Local test acc @ epoch 73: 0.4591
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.3126179873943329
Local loss @ local epoch 1: 0.026420043781399727
Local loss @ local epoch 2: 0.02533354051411152
Local loss @ local epoch 3: 0.016506273299455643
Local loss @ local epoch 4: 0.2859138548374176
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.85 seconds!
[tester] 
AGNewsMetric: acc=0.5948684210526316, hinge=2.9153632914392573, ce=10.617568879378469
Local test acc @ epoch 73: 0.5949
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.6685901284217834
Local loss @ local epoch 1: 0.01383642852306366
Local loss @ local epoch 2: 0.005426852963864803
Local loss @ local epoch 3: 0.005070894490927458
Local loss @ local epoch 4: 0.013490528799593449
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.42 seconds!
[tester] 
AGNewsMetric: acc=0.48776315789473684, hinge=4.276460114529258, ce=9.257463806553892
Local test acc @ epoch 73: 0.4878
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.01439424604177475
Local loss @ local epoch 1: 0.00027953609242103994
Local loss @ local epoch 2: 0.0011048014275729656
Local loss @ local epoch 3: 0.0005997584667056799
Local loss @ local epoch 4: 0.00025025595095939934
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.92 seconds!
[tester] 
AGNewsMetric: acc=0.48947368421052634, hinge=4.5399243686073705, ce=12.108316519887824
Local test acc @ epoch 73: 0.4895
Global evaluate on test data...
Evaluate data in 123.6 seconds!
[tester] 
AGNewsMetric: acc=0.8582894736842105, hinge=1.151470103012888, ce=9.1782276695653
Global test acc @ epoch 73: 0.8583
Global epoch 74...
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.23559173941612244
Local loss @ local epoch 1: 0.0550064779818058
Local loss @ local epoch 2: 0.026086021214723587
Local loss @ local epoch 3: 0.026965178549289703
Local loss @ local epoch 4: 0.1242121234536171
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.46 seconds!
[tester] 
AGNewsMetric: acc=0.8356578947368422, hinge=1.394023615937484, ce=7.825438991345857
Local test acc @ epoch 74: 0.8357
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 1.7404520349373342e-06
Local loss @ local epoch 1: 1.3351419738683035e-06
Local loss @ local epoch 2: 2.384184938364342e-07
Local loss @ local epoch 3: 2.2888084458827507e-06
Local loss @ local epoch 4: 1.2159329116911977e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.67 seconds!
[tester] 
AGNewsMetric: acc=0.786578947368421, hinge=2.099751736992284, ce=10.796836431402909
Local test acc @ epoch 74: 0.7866
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.005205219611525536
Local loss @ local epoch 1: 0.001056706183589995
Local loss @ local epoch 2: 0.021461432799696922
Local loss @ local epoch 3: 0.0007279191631823778
Local loss @ local epoch 4: 0.003158966777846217
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.17 seconds!
[tester] 
AGNewsMetric: acc=0.8305263157894737, hinge=1.3188881665781924, ce=10.08063362121582
Local test acc @ epoch 74: 0.8305
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.17111098766326904
Local loss @ local epoch 1: 0.13995292782783508
Local loss @ local epoch 2: 0.0438716746866703
Local loss @ local epoch 3: 0.0856708511710167
Local loss @ local epoch 4: 0.0066594709642231464
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 125.13 seconds!
[tester] 
AGNewsMetric: acc=0.6246052631578948, hinge=2.990125876978824, ce=10.66837076488294
Local test acc @ epoch 74: 0.6246
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0069590681232512
Local loss @ local epoch 1: 0.0003550095425453037
Local loss @ local epoch 2: 3.683494287542999e-05
Local loss @ local epoch 3: 0.00024383264826610684
Local loss @ local epoch 4: 0.0012668240815401077
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.24 seconds!
[tester] 
AGNewsMetric: acc=0.5421052631578948, hinge=3.9120114075510126, ce=11.085552550867984
Local test acc @ epoch 74: 0.5421
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.03413770720362663
Local loss @ local epoch 1: 9.298374789068475e-05
Local loss @ local epoch 2: 0.0003813569201156497
Local loss @ local epoch 3: 9.827016765484586e-05
Local loss @ local epoch 4: 0.010417570360004902
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.56 seconds!
[tester] 
AGNewsMetric: acc=0.46, hinge=9.391719909467195, ce=12.514260713677658
Local test acc @ epoch 74: 0.46
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.004632140975445509
Local loss @ local epoch 1: 0.0003310417232569307
Local loss @ local epoch 2: 5.4563352023251355e-05
Local loss @ local epoch 3: 0.00030393709312193096
Local loss @ local epoch 4: 0.00011979425471508875
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.4 seconds!
[tester] 
AGNewsMetric: acc=0.7973684210526316, hinge=1.6023764110866345, ce=9.09253868303801
Local test acc @ epoch 74: 0.7974
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.1638757735490799
Local loss @ local epoch 1: 0.016819359734654427
Local loss @ local epoch 2: 0.001115099061280489
Local loss @ local epoch 3: 0.25467991828918457
Local loss @ local epoch 4: 0.001050138147547841
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.8 seconds!
[tester] 
AGNewsMetric: acc=0.5288157894736842, hinge=4.958369751729463, ce=7.517134358255487
Local test acc @ epoch 74: 0.5288
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.004227399360388517
Local loss @ local epoch 1: 4.2989089706679806e-05
Local loss @ local epoch 2: 2.309362571395468e-05
Local loss @ local epoch 3: 0.00014717817248310894
Local loss @ local epoch 4: 2.7449596018414013e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 122.96 seconds!
[tester] 
AGNewsMetric: acc=0.3918421052631579, hinge=12.857300030055798, ce=12.041327217503598
Local test acc @ epoch 74: 0.3918
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.28500834107398987
Local loss @ local epoch 1: 0.05897669494152069
Local loss @ local epoch 2: 0.005941139068454504
Local loss @ local epoch 3: 0.09800242632627487
Local loss @ local epoch 4: 0.03869687020778656
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.4 seconds!
[tester] 
AGNewsMetric: acc=0.41657894736842105, hinge=11.175170274031789, ce=12.37618854522705
Local test acc @ epoch 74: 0.4166
Global evaluate on test data...
Evaluate data in 123.84 seconds!
[tester] 
AGNewsMetric: acc=0.8702631578947368, hinge=1.2118162662104557, ce=9.288825747841283
Global test acc @ epoch 74: 0.8703
Global epoch 75...
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.2165203094482422
Local loss @ local epoch 1: 0.14963623881340027
Local loss @ local epoch 2: 0.0014215052360668778
Local loss @ local epoch 3: 0.3246745467185974
Local loss @ local epoch 4: 0.02811247669160366
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.2 seconds!
[tester] 
AGNewsMetric: acc=0.3803947368421053, hinge=8.542845062456633, ce=11.28647947411788
Local test acc @ epoch 75: 0.3804
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.22174422442913055
Local loss @ local epoch 1: 0.03297119587659836
Local loss @ local epoch 2: 0.04924102500081062
Local loss @ local epoch 3: 0.014964088797569275
Local loss @ local epoch 4: 0.08465808629989624
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.92 seconds!
[tester] 
AGNewsMetric: acc=0.6511842105263158, hinge=2.4702091282292415, ce=10.471378135681153
Local test acc @ epoch 75: 0.6512
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0002820180670823902
Local loss @ local epoch 1: 0.00043354096123948693
Local loss @ local epoch 2: 0.0002011765172937885
Local loss @ local epoch 3: 0.005622180178761482
Local loss @ local epoch 4: 3.293076224508695e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.29 seconds!
[tester] 
AGNewsMetric: acc=0.6884210526315789, hinge=2.8324655143838178, ce=9.150769354167737
Local test acc @ epoch 75: 0.6884
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.6162254214286804
Local loss @ local epoch 1: 0.057063255459070206
Local loss @ local epoch 2: 0.0014325910015031695
Local loss @ local epoch 3: 0.0018873659428209066
Local loss @ local epoch 4: 0.0319359265267849
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.23 seconds!
[tester] 
AGNewsMetric: acc=0.4776315789473684, hinge=4.994651395396183, ce=10.958963958338687
Local test acc @ epoch 75: 0.4776
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 1.8405124137643725e-05
Local loss @ local epoch 1: 0.0010884552029892802
Local loss @ local epoch 2: 9.536741885085576e-08
Local loss @ local epoch 3: 1.4305112472356996e-07
Local loss @ local epoch 4: 4.768371297814156e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.66 seconds!
[tester] 
AGNewsMetric: acc=0.531578947368421, hinge=5.47662915581151, ce=10.776390342712402
Local test acc @ epoch 75: 0.5316
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0006651112344115973
Local loss @ local epoch 1: 3.826433385256678e-05
Local loss @ local epoch 2: 0.0004849434772040695
Local loss @ local epoch 3: 2.7675385354086757e-05
Local loss @ local epoch 4: 0.00012989812239538878
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.72 seconds!
[tester] 
AGNewsMetric: acc=0.7471052631578947, hinge=2.7820752972050715, ce=10.845159008628444
Local test acc @ epoch 75: 0.7471
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.20033854246139526
Local loss @ local epoch 1: 0.18924741446971893
Local loss @ local epoch 2: 0.020556168630719185
Local loss @ local epoch 3: 0.020290734246373177
Local loss @ local epoch 4: 0.037682704627513885
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.33 seconds!
[tester] 
AGNewsMetric: acc=0.8048684210526316, hinge=1.5994281748721475, ce=10.284087658932334
Local test acc @ epoch 75: 0.8049
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.04180736839771271
Local loss @ local epoch 1: 8.478351082885638e-05
Local loss @ local epoch 2: 0.00033657747553661466
Local loss @ local epoch 3: 0.0001030082639772445
Local loss @ local epoch 4: 0.009844831191003323
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.54 seconds!
[tester] 
AGNewsMetric: acc=0.4388157894736842, hinge=8.72528415981092, ce=11.45321010388826
Local test acc @ epoch 75: 0.4388
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.03018096648156643
Local loss @ local epoch 1: 6.446368934120983e-05
Local loss @ local epoch 2: 0.0002005692949751392
Local loss @ local epoch 3: 0.0005717098829336464
Local loss @ local epoch 4: 0.008483176119625568
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.24 seconds!
[tester] 
AGNewsMetric: acc=0.4380263157894737, hinge=8.998540194661993, ce=10.85046092786287
Local test acc @ epoch 75: 0.438
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.014528144150972366
Local loss @ local epoch 1: 0.0003655870968941599
Local loss @ local epoch 2: 0.0003324122226331383
Local loss @ local epoch 3: 0.001435061334632337
Local loss @ local epoch 4: 0.0017134370282292366
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.56 seconds!
[tester] 
AGNewsMetric: acc=0.5482894736842105, hinge=3.2490737232409024, ce=7.006665061147589
Local test acc @ epoch 75: 0.5483
Global evaluate on test data...
Evaluate data in 123.22 seconds!
[tester] 
AGNewsMetric: acc=0.8372368421052632, hinge=1.3967864653938695, ce=9.581881230002955
Global test acc @ epoch 75: 0.8372
Global epoch 76...
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0017570062773302197
Local loss @ local epoch 1: 0.0004960548249073327
Local loss @ local epoch 2: 3.0019678888493218e-05
Local loss @ local epoch 3: 8.055243961280212e-05
Local loss @ local epoch 4: 7.303611346287653e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.86 seconds!
[tester] 
AGNewsMetric: acc=0.46907894736842104, hinge=10.68128456492173, ce=11.392201913532459
Local test acc @ epoch 76: 0.4691
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.8548709750175476
Local loss @ local epoch 1: 0.7180280685424805
Local loss @ local epoch 2: 0.033735811710357666
Local loss @ local epoch 3: 0.027007753029465675
Local loss @ local epoch 4: 0.08376530557870865
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.74 seconds!
[tester] 
AGNewsMetric: acc=0.8367105263157895, hinge=1.2189484305130809, ce=10.033394161023592
Local test acc @ epoch 76: 0.8367
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0496959425508976
Local loss @ local epoch 1: 0.033730920404195786
Local loss @ local epoch 2: 0.08063624799251556
Local loss @ local epoch 3: 0.010806182399392128
Local loss @ local epoch 4: 0.06978972256183624
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.42 seconds!
[tester] 
AGNewsMetric: acc=0.7667105263157895, hinge=2.108186551897149, ce=10.236439453928094
Local test acc @ epoch 76: 0.7667
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.5062538385391235
Local loss @ local epoch 1: 0.004992302041500807
Local loss @ local epoch 2: 0.00628452654927969
Local loss @ local epoch 3: 0.002323153195902705
Local loss @ local epoch 4: 0.004527186509221792
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.74 seconds!
[tester] 
AGNewsMetric: acc=0.5473684210526316, hinge=4.201781721115112, ce=9.203088981226871
Local test acc @ epoch 76: 0.5474
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 8.106224527182349e-07
Local loss @ local epoch 1: 3.0994287953944877e-06
Local loss @ local epoch 2: 1.1920927533992653e-07
Local loss @ local epoch 3: 8.344640036739293e-07
Local loss @ local epoch 4: 4.0531145373279287e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.76 seconds!
[tester] 
AGNewsMetric: acc=0.7681578947368422, hinge=2.1695585712633636, ce=6.501931123231587
Local test acc @ epoch 76: 0.7682
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.28540509939193726
Local loss @ local epoch 1: 0.0015988232335075736
Local loss @ local epoch 2: 0.0031594315078109503
Local loss @ local epoch 3: 0.0005644108750857413
Local loss @ local epoch 4: 0.0016269013285636902
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.72 seconds!
[tester] 
AGNewsMetric: acc=0.3107894736842105, hinge=10.063032107102243, ce=15.563832168579102
Local test acc @ epoch 76: 0.3108
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.08698820322751999
Local loss @ local epoch 1: 0.037743255496025085
Local loss @ local epoch 2: 0.01414963323622942
Local loss @ local epoch 3: 0.0846550241112709
Local loss @ local epoch 4: 0.34902283549308777
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.71 seconds!
[tester] 
AGNewsMetric: acc=0.8313157894736842, hinge=1.7000996996227065, ce=9.167847910429302
Local test acc @ epoch 76: 0.8313
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0006446405313909054
Local loss @ local epoch 1: 0.00024296667834278196
Local loss @ local epoch 2: 8.445139974355698e-05
Local loss @ local epoch 3: 0.0034951067063957453
Local loss @ local epoch 4: 0.0002168895589420572
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.65 seconds!
[tester] 
AGNewsMetric: acc=0.7071052631578948, hinge=3.2386001406217875, ce=10.586805329573782
Local test acc @ epoch 76: 0.7071
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.00025619761436246336
Local loss @ local epoch 1: 0.00024560626479797065
Local loss @ local epoch 2: 8.129732304951176e-05
Local loss @ local epoch 3: 0.0007422476774081588
Local loss @ local epoch 4: 0.00016268402396235615
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.27 seconds!
[tester] 
AGNewsMetric: acc=0.8468421052631578, hinge=1.148618012729444, ce=5.734884590349699
Local test acc @ epoch 76: 0.8468
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0013043301878497005
Local loss @ local epoch 1: 3.984657087130472e-05
Local loss @ local epoch 2: 9.773608326213434e-05
Local loss @ local epoch 3: 4.144887498114258e-05
Local loss @ local epoch 4: 8.528772013960406e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.0 seconds!
[tester] 
AGNewsMetric: acc=0.26302631578947366, hinge=16.163163584658975, ce=16.124199038053813
Local test acc @ epoch 76: 0.263
Global evaluate on test data...
Evaluate data in 123.79 seconds!
[tester] 
AGNewsMetric: acc=0.8613157894736843, hinge=1.3683822629326268, ce=9.621226230420564
Global test acc @ epoch 76: 0.8613
Global epoch 77...
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.4160724878311157
Local loss @ local epoch 1: 0.16308313608169556
Local loss @ local epoch 2: 0.0084658432751894
Local loss @ local epoch 3: 0.0009499232983216643
Local loss @ local epoch 4: 0.005797521211206913
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.75 seconds!
[tester] 
AGNewsMetric: acc=0.48328947368421055, hinge=6.179913469113802, ce=9.264904682761744
Local test acc @ epoch 77: 0.4833
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.03125782683491707
Local loss @ local epoch 1: 0.0025179272051900625
Local loss @ local epoch 2: 0.0019122924422845244
Local loss @ local epoch 3: 0.0007549364236183465
Local loss @ local epoch 4: 0.0010341472225263715
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.22 seconds!
[tester] 
AGNewsMetric: acc=0.49526315789473685, hinge=3.8499598352532636, ce=11.297153954756887
Local test acc @ epoch 77: 0.4953
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 9.684346878202632e-05
Local loss @ local epoch 1: 0.00022964426898397505
Local loss @ local epoch 2: 1.6838072042446584e-05
Local loss @ local epoch 3: 0.0026950985193252563
Local loss @ local epoch 4: 1.305329533352051e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.52 seconds!
[tester] 
AGNewsMetric: acc=0.7289473684210527, hinge=2.4741839561964336, ce=7.2250162124633786
Local test acc @ epoch 77: 0.7289
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0010470409179106355
Local loss @ local epoch 1: 9.11749157239683e-05
Local loss @ local epoch 2: 4.343838736531325e-05
Local loss @ local epoch 3: 5.68316645512823e-05
Local loss @ local epoch 4: 5.508978574653156e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.73 seconds!
[tester] 
AGNewsMetric: acc=0.43236842105263157, hinge=11.058590345131723, ce=13.917646424142937
Local test acc @ epoch 77: 0.4324
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0035263013560324907
Local loss @ local epoch 1: 0.00014137329708319157
Local loss @ local epoch 2: 0.045810896903276443
Local loss @ local epoch 3: 0.0010434187715873122
Local loss @ local epoch 4: 0.000506992859300226
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.8 seconds!
[tester] 
AGNewsMetric: acc=0.8705263157894737, hinge=1.0766129338113886, ce=9.587860336303711
Local test acc @ epoch 77: 0.8705
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0005201139720156789
Local loss @ local epoch 1: 2.674471579666715e-05
Local loss @ local epoch 2: 4.638303380488651e-06
Local loss @ local epoch 3: 1.5497172398681869e-06
Local loss @ local epoch 4: 5.667809546139324e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.41 seconds!
[tester] 
AGNewsMetric: acc=0.38855263157894737, hinge=13.635479474820588, ce=16.039911486977026
Local test acc @ epoch 77: 0.3886
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.21871685981750488
Local loss @ local epoch 1: 0.2469087690114975
Local loss @ local epoch 2: 0.013973397202789783
Local loss @ local epoch 3: 0.03550055995583534
Local loss @ local epoch 4: 0.002352991607040167
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.66 seconds!
[tester] 
AGNewsMetric: acc=0.7835526315789474, hinge=1.9926496533343667, ce=9.135852307771382
Local test acc @ epoch 77: 0.7836
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.03163691237568855
Local loss @ local epoch 1: 1.001344480755506e-05
Local loss @ local epoch 2: 4.36304253526032e-06
Local loss @ local epoch 3: 1.161089585366426e-05
Local loss @ local epoch 4: 3.2233427191386e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.82 seconds!
[tester] 
AGNewsMetric: acc=0.8625, hinge=1.0195586018813283, ce=9.493185460943925
Local test acc @ epoch 77: 0.8625
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.2475780248641968
Local loss @ local epoch 1: 0.22323574125766754
Local loss @ local epoch 2: 0.008450345136225224
Local loss @ local epoch 3: 0.00766067486256361
Local loss @ local epoch 4: 0.017446553334593773
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.47 seconds!
[tester] 
AGNewsMetric: acc=0.4817105263157895, hinge=6.290288559763055, ce=9.924970450150338
Local test acc @ epoch 77: 0.4817
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.19914761185646057
Local loss @ local epoch 1: 0.012806911952793598
Local loss @ local epoch 2: 0.07471976429224014
Local loss @ local epoch 3: 0.5517023205757141
Local loss @ local epoch 4: 0.047622211277484894
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.53 seconds!
[tester] 
AGNewsMetric: acc=0.7525, hinge=1.8333039246107403, ce=11.155123762833444
Local test acc @ epoch 77: 0.7525
Global evaluate on test data...
Evaluate data in 123.96 seconds!
[tester] 
AGNewsMetric: acc=0.8692105263157894, hinge=1.0962582091281288, ce=9.391793261076275
Global test acc @ epoch 77: 0.8692
Global epoch 78...
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.09781032800674438
Local loss @ local epoch 1: 5.125598909216933e-05
Local loss @ local epoch 2: 0.00010118522914126515
Local loss @ local epoch 3: 0.0024822752457112074
Local loss @ local epoch 4: 0.0012999126920476556
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.0 seconds!
[tester] 
AGNewsMetric: acc=0.44671052631578945, hinge=8.049755135837355, ce=12.251142134415476
Local test acc @ epoch 78: 0.4467
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.010433667339384556
Local loss @ local epoch 1: 0.006123511586338282
Local loss @ local epoch 2: 0.0010161971440538764
Local loss @ local epoch 3: 0.0004485970130190253
Local loss @ local epoch 4: 0.0021535297855734825
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.51 seconds!
[tester] 
AGNewsMetric: acc=0.7611842105263158, hinge=1.6569063555566887, ce=11.61364698911968
Local test acc @ epoch 78: 0.7612
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.45734721422195435
Local loss @ local epoch 1: 0.07349694520235062
Local loss @ local epoch 2: 0.010888301767408848
Local loss @ local epoch 3: 0.11241809278726578
Local loss @ local epoch 4: 0.0068775927647948265
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.62 seconds!
[tester] 
AGNewsMetric: acc=0.5035526315789474, hinge=7.380142023186934, ce=12.073437698765805
Local test acc @ epoch 78: 0.5036
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.018290769308805466
Local loss @ local epoch 1: 0.00012106278154533356
Local loss @ local epoch 2: 5.68343821214512e-05
Local loss @ local epoch 3: 2.8478605599957518e-05
Local loss @ local epoch 4: 4.2023995774798095e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.39 seconds!
[tester] 
AGNewsMetric: acc=0.3464473684210526, hinge=11.72043378026862, ce=13.521081077174136
Local test acc @ epoch 78: 0.3464
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.012655395083129406
Local loss @ local epoch 1: 0.00016046558448579162
Local loss @ local epoch 2: 0.00011621564772212878
Local loss @ local epoch 3: 0.870324432849884
Local loss @ local epoch 4: 0.011981402523815632
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.12 seconds!
[tester] 
AGNewsMetric: acc=0.7932894736842105, hinge=2.1514934562381947, ce=10.189664262470446
Local test acc @ epoch 78: 0.7933
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 7.557810022262856e-06
Local loss @ local epoch 1: 1.141999655374093e-05
Local loss @ local epoch 2: 1.556853749207221e-05
Local loss @ local epoch 3: 1.8524722690926865e-05
Local loss @ local epoch 4: 8.940616680774838e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.87 seconds!
[tester] 
AGNewsMetric: acc=0.3952631578947368, hinge=11.122049076682643, ce=14.692279120997378
Local test acc @ epoch 78: 0.3953
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.1371917426586151
Local loss @ local epoch 1: 0.05243328586220741
Local loss @ local epoch 2: 0.044083256274461746
Local loss @ local epoch 3: 0.00041428409167565405
Local loss @ local epoch 4: 0.002299509709700942
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.61 seconds!
[tester] 
AGNewsMetric: acc=0.5217105263157895, hinge=6.401927693015651, ce=9.400734492854069
Local test acc @ epoch 78: 0.5217
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.02102852053940296
Local loss @ local epoch 1: 0.1488092839717865
Local loss @ local epoch 2: 0.06278979033231735
Local loss @ local epoch 3: 0.031232092529535294
Local loss @ local epoch 4: 0.07024998217821121
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.06 seconds!
[tester] 
AGNewsMetric: acc=0.7146052631578947, hinge=2.3266838179136577, ce=6.947970356188322
Local test acc @ epoch 78: 0.7146
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0003169590490870178
Local loss @ local epoch 1: 0.0009031013469211757
Local loss @ local epoch 2: 0.0009305142448283732
Local loss @ local epoch 3: 0.10542283952236176
Local loss @ local epoch 4: 0.0010269477497786283
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.93 seconds!
[tester] 
AGNewsMetric: acc=0.7467105263157895, hinge=2.1197905916916695, ce=10.042779585185803
Local test acc @ epoch 78: 0.7467
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.7774211764335632
Local loss @ local epoch 1: 0.004333351273089647
Local loss @ local epoch 2: 0.18846911191940308
Local loss @ local epoch 3: 0.5242688059806824
Local loss @ local epoch 4: 0.022386185824871063
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.0 seconds!
[tester] 
AGNewsMetric: acc=0.8002631578947368, hinge=1.5089318222748607, ce=8.890082963642321
Local test acc @ epoch 78: 0.8003
Global evaluate on test data...
Evaluate data in 123.49 seconds!
[tester] 
AGNewsMetric: acc=0.8575, hinge=1.2957997299495496, ce=9.16370388031006
Global test acc @ epoch 78: 0.8575
Global epoch 79...
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0016698786057531834
Local loss @ local epoch 1: 1.0565906450210605e-05
Local loss @ local epoch 2: 9.525797395326663e-06
Local loss @ local epoch 3: 1.0696245226426981e-05
Local loss @ local epoch 4: 4.4874250306747854e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.17 seconds!
[tester] 
AGNewsMetric: acc=0.3473684210526316, hinge=12.149394645690919, ce=12.918307800292968
Local test acc @ epoch 79: 0.3474
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.015464559197425842
Local loss @ local epoch 1: 0.02883167751133442
Local loss @ local epoch 2: 0.0655336007475853
Local loss @ local epoch 3: 0.35861366987228394
Local loss @ local epoch 4: 0.055833734571933746
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.62 seconds!
[tester] 
AGNewsMetric: acc=0.7918421052631579, hinge=2.063860431219402, ce=9.296919481377852
Local test acc @ epoch 79: 0.7918
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.6020287275314331
Local loss @ local epoch 1: 0.04571931064128876
Local loss @ local epoch 2: 0.02460438944399357
Local loss @ local epoch 3: 0.007957667112350464
Local loss @ local epoch 4: 0.15129265189170837
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.63 seconds!
[tester] 
AGNewsMetric: acc=0.6302631578947369, hinge=3.30783282380355, ce=8.534790456671464
Local test acc @ epoch 79: 0.6303
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.04915798828005791
Local loss @ local epoch 1: 0.001553568639792502
Local loss @ local epoch 2: 0.0018107127398252487
Local loss @ local epoch 3: 0.0021632674615830183
Local loss @ local epoch 4: 0.007819907739758492
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.09 seconds!
[tester] 
AGNewsMetric: acc=0.6905263157894737, hinge=2.172823537274411, ce=11.673504981994629
Local test acc @ epoch 79: 0.6905
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.005932854488492012
Local loss @ local epoch 1: 0.00011869958689203486
Local loss @ local epoch 2: 0.00033381147659383714
Local loss @ local epoch 3: 0.0004926109104417264
Local loss @ local epoch 4: 0.0012618276523426175
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.25 seconds!
[tester] 
AGNewsMetric: acc=0.454078947368421, hinge=8.542056817255522, ce=12.179967848125257
Local test acc @ epoch 79: 0.4541
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.09658633917570114
Local loss @ local epoch 1: 0.16832329332828522
Local loss @ local epoch 2: 0.08068598806858063
Local loss @ local epoch 3: 0.5661710500717163
Local loss @ local epoch 4: 0.4045727550983429
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.03 seconds!
[tester] 
AGNewsMetric: acc=0.5423684210526316, hinge=3.1482265256580555, ce=11.05795293105276
Local test acc @ epoch 79: 0.5424
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0007166769937612116
Local loss @ local epoch 1: 8.750714914640412e-05
Local loss @ local epoch 2: 0.004773781169205904
Local loss @ local epoch 3: 0.00012939995212946087
Local loss @ local epoch 4: 0.00022008444648236036
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.06 seconds!
[tester] 
AGNewsMetric: acc=0.8353947368421053, hinge=1.455736460183796, ce=10.391445557443719
Local test acc @ epoch 79: 0.8354
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 2.5033880319824675e-06
Local loss @ local epoch 1: 2.384185648907078e-08
Local loss @ local epoch 2: 2.479544491507113e-06
Local loss @ local epoch 3: 1.9073479506914737e-07
Local loss @ local epoch 4: 2.217281917182845e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.69 seconds!
[tester] 
AGNewsMetric: acc=0.5631578947368421, hinge=5.649014338945087, ce=11.188227858292429
Local test acc @ epoch 79: 0.5632
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0007166058057919145
Local loss @ local epoch 1: 4.291372169973329e-05
Local loss @ local epoch 2: 4.821809125132859e-05
Local loss @ local epoch 3: 9.857758414000273e-05
Local loss @ local epoch 4: 2.9593125873361714e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.54 seconds!
[tester] 
AGNewsMetric: acc=0.7057894736842105, hinge=2.965868438419543, ce=9.748753640024285
Local test acc @ epoch 79: 0.7058
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.3140842318534851
Local loss @ local epoch 1: 0.03638364002108574
Local loss @ local epoch 2: 0.0022933566942811012
Local loss @ local epoch 3: 0.02588750049471855
Local loss @ local epoch 4: 0.006053185556083918
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.12 seconds!
[tester] 
AGNewsMetric: acc=0.3225, hinge=11.289328420538652, ce=13.603102364791066
Local test acc @ epoch 79: 0.3225
Global evaluate on test data...
Evaluate data in 123.66 seconds!
[tester] 
AGNewsMetric: acc=0.8667105263157895, hinge=1.2158222700420178, ce=9.777899519267836
Global test acc @ epoch 79: 0.8667
Global epoch 80...
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 7.306941552087665e-05
Local loss @ local epoch 1: 0.0014956569066271186
Local loss @ local epoch 2: 3.26923982356675e-05
Local loss @ local epoch 3: 1.0281725735694636e-05
Local loss @ local epoch 4: 0.0006936629069969058
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.83 seconds!
[tester] 
AGNewsMetric: acc=0.6825, hinge=3.415663019732425, ce=8.766933748345625
Local test acc @ epoch 80: 0.6825
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.6291098594665527
Local loss @ local epoch 1: 0.008521761745214462
Local loss @ local epoch 2: 0.09816256165504456
Local loss @ local epoch 3: 0.1535855382680893
Local loss @ local epoch 4: 0.0019133043242618442
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.69 seconds!
[tester] 
AGNewsMetric: acc=0.7726315789473684, hinge=2.3463213729858396, ce=9.99801336388839
Local test acc @ epoch 80: 0.7726
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.2835253179073334
Local loss @ local epoch 1: 0.009341564029455185
Local loss @ local epoch 2: 0.004213721491396427
Local loss @ local epoch 3: 0.0117918336763978
Local loss @ local epoch 4: 0.0032596357632428408
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.07 seconds!
[tester] 
AGNewsMetric: acc=0.5778947368421052, hinge=4.614243116880718, ce=9.439112920259175
Local test acc @ epoch 80: 0.5779
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.5051350593566895
Local loss @ local epoch 1: 0.0495731383562088
Local loss @ local epoch 2: 0.0008187227649614215
Local loss @ local epoch 3: 0.0009277852950617671
Local loss @ local epoch 4: 0.042787425220012665
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.77 seconds!
[tester] 
AGNewsMetric: acc=0.49592105263157893, hinge=6.004039246408563, ce=10.50627289019133
Local test acc @ epoch 80: 0.4959
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.09290463477373123
Local loss @ local epoch 1: 0.0033355907071381807
Local loss @ local epoch 2: 0.00025211781030520797
Local loss @ local epoch 3: 0.0031635200139135122
Local loss @ local epoch 4: 0.0009524456108920276
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.41 seconds!
[tester] 
AGNewsMetric: acc=0.4446052631578947, hinge=3.9178362766065096, ce=8.878785163477847
Local test acc @ epoch 80: 0.4446
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.11179347336292267
Local loss @ local epoch 1: 2.2204503693501465e-05
Local loss @ local epoch 2: 0.00087143195560202
Local loss @ local epoch 3: 8.48467752803117e-05
Local loss @ local epoch 4: 0.004324454348534346
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.66 seconds!
[tester] 
AGNewsMetric: acc=0.40460526315789475, hinge=11.281373183601781, ce=13.480211749829744
Local test acc @ epoch 80: 0.4046
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0032073522452265024
Local loss @ local epoch 1: 0.00011285653454251587
Local loss @ local epoch 2: 8.896607323549688e-05
Local loss @ local epoch 3: 0.3434278070926666
Local loss @ local epoch 4: 0.00050045718671754
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.57 seconds!
[tester] 
AGNewsMetric: acc=0.8165789473684211, hinge=1.842646006533974, ce=10.892008347762259
Local test acc @ epoch 80: 0.8166
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.3774406909942627
Local loss @ local epoch 1: 0.10930342227220535
Local loss @ local epoch 2: 0.0006984861101955175
Local loss @ local epoch 3: 9.91683264146559e-05
Local loss @ local epoch 4: 5.715620136470534e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.55 seconds!
[tester] 
AGNewsMetric: acc=0.5096052631578948, hinge=5.968362720138148, ce=11.49867506328382
Local test acc @ epoch 80: 0.5096
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 3.433202891756082e-06
Local loss @ local epoch 1: 2.384185648907078e-08
Local loss @ local epoch 2: 1.9073479506914737e-07
Local loss @ local epoch 3: 4.52995038813242e-07
Local loss @ local epoch 4: 7.152556946721234e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.21 seconds!
[tester] 
AGNewsMetric: acc=0.6147368421052631, hinge=4.20728341930791, ce=11.544641014902215
Local test acc @ epoch 80: 0.6147
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.029553843662142754
Local loss @ local epoch 1: 0.029070643708109856
Local loss @ local epoch 2: 0.04003011807799339
Local loss @ local epoch 3: 0.00926122348755598
Local loss @ local epoch 4: 0.012758041732013226
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.14 seconds!
[tester] 
AGNewsMetric: acc=0.6876315789473684, hinge=2.310591046182733, ce=9.511474396555048
Local test acc @ epoch 80: 0.6876
Global evaluate on test data...
Evaluate data in 123.71 seconds!
[tester] 
AGNewsMetric: acc=0.8628947368421053, hinge=1.203107735232303, ce=9.394835144846063
Global test acc @ epoch 80: 0.8629
Global epoch 81...
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0008982313447631896
Local loss @ local epoch 1: 0.0001481785293435678
Local loss @ local epoch 2: 1.9430468455539085e-05
Local loss @ local epoch 3: 4.810256359633058e-05
Local loss @ local epoch 4: 0.00012959717423655093
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.7 seconds!
[tester] 
AGNewsMetric: acc=0.37236842105263157, hinge=12.73004581451416, ce=12.909012240359658
Local test acc @ epoch 81: 0.3724
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.3312300741672516
Local loss @ local epoch 1: 0.017196660861372948
Local loss @ local epoch 2: 0.001556681701913476
Local loss @ local epoch 3: 0.020443253219127655
Local loss @ local epoch 4: 0.0011313629802316427
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.29 seconds!
[tester] 
AGNewsMetric: acc=0.4478947368421053, hinge=5.8051146923868275, ce=10.273820296839665
Local test acc @ epoch 81: 0.4479
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0020937961526215076
Local loss @ local epoch 1: 0.016463395208120346
Local loss @ local epoch 2: 0.00044602135312743485
Local loss @ local epoch 3: 0.0011278302408754826
Local loss @ local epoch 4: 0.0005733946454711258
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.29 seconds!
[tester] 
AGNewsMetric: acc=0.8336842105263158, hinge=1.3775505083485653, ce=9.031200589631734
Local test acc @ epoch 81: 0.8337
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.009132876992225647
Local loss @ local epoch 1: 0.0026548330206424
Local loss @ local epoch 2: 0.005513834301382303
Local loss @ local epoch 3: 0.0008741190540604293
Local loss @ local epoch 4: 0.0008048725430853665
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.41 seconds!
[tester] 
AGNewsMetric: acc=0.6109210526315789, hinge=3.015129163641679, ce=8.493854942321777
Local test acc @ epoch 81: 0.6109
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.5145165324211121
Local loss @ local epoch 1: 0.0070510804653167725
Local loss @ local epoch 2: 0.0010188203305006027
Local loss @ local epoch 3: 0.0025849416851997375
Local loss @ local epoch 4: 0.0028493672143667936
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.45 seconds!
[tester] 
AGNewsMetric: acc=0.33131578947368423, hinge=10.379164545159592, ce=12.559610135931718
Local test acc @ epoch 81: 0.3313
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.00011885839194292203
Local loss @ local epoch 1: 2.7834756110678427e-05
Local loss @ local epoch 2: 9.607298125047237e-05
Local loss @ local epoch 3: 0.0003289150190539658
Local loss @ local epoch 4: 0.00042257329914718866
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.32 seconds!
[tester] 
AGNewsMetric: acc=0.7022368421052632, hinge=2.7877281715995386, ce=10.115052010385615
Local test acc @ epoch 81: 0.7022
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.26644426584243774
Local loss @ local epoch 1: 0.2648591995239258
Local loss @ local epoch 2: 0.13133293390274048
Local loss @ local epoch 3: 0.00730162812396884
Local loss @ local epoch 4: 0.004385795444250107
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.58 seconds!
[tester] 
AGNewsMetric: acc=0.7146052631578947, hinge=2.7323433557309604, ce=10.216237431576378
Local test acc @ epoch 81: 0.7146
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 3.8146840779518243e-06
Local loss @ local epoch 1: 2.0503916857705917e-06
Local loss @ local epoch 2: 1.4305112472356996e-07
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.6689295989635866e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.68 seconds!
[tester] 
AGNewsMetric: acc=0.595, hinge=4.37069925107454, ce=11.71671052230032
Local test acc @ epoch 81: 0.595
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.02165047451853752
Local loss @ local epoch 1: 0.30875611305236816
Local loss @ local epoch 2: 0.010764648206532001
Local loss @ local epoch 3: 0.06285526603460312
Local loss @ local epoch 4: 0.04716626927256584
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.3 seconds!
[tester] 
AGNewsMetric: acc=0.8189473684210526, hinge=1.4064859540838943, ce=10.65359935358951
Local test acc @ epoch 81: 0.8189
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0015573477139696479
Local loss @ local epoch 1: 4.984467159374617e-05
Local loss @ local epoch 2: 3.0198325475794263e-05
Local loss @ local epoch 3: 7.261750852194382e-06
Local loss @ local epoch 4: 0.0028555633034557104
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.47 seconds!
[tester] 
AGNewsMetric: acc=0.47789473684210526, hinge=9.286070439690038, ce=11.110982694123921
Local test acc @ epoch 81: 0.4779
Global evaluate on test data...
Evaluate data in 123.79 seconds!
[tester] 
AGNewsMetric: acc=0.8581578947368421, hinge=1.2866665107325503, ce=9.66583219628585
Global test acc @ epoch 81: 0.8582
Global epoch 82...
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.6505356431007385
Local loss @ local epoch 1: 0.04342929646372795
Local loss @ local epoch 2: 0.03159455582499504
Local loss @ local epoch 3: 0.003768761409446597
Local loss @ local epoch 4: 0.14017097651958466
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.16 seconds!
[tester] 
AGNewsMetric: acc=0.38776315789473687, hinge=6.841450885973479, ce=12.587446130451402
Local test acc @ epoch 82: 0.3878
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.012511084787547588
Local loss @ local epoch 1: 0.0002177496935473755
Local loss @ local epoch 2: 2.2013511625118554e-05
Local loss @ local epoch 3: 6.560120527865365e-05
Local loss @ local epoch 4: 0.00025850741076283157
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.73 seconds!
[tester] 
AGNewsMetric: acc=0.45644736842105266, hinge=5.094779818685431, ce=11.716895940680253
Local test acc @ epoch 82: 0.4564
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.2375631481409073
Local loss @ local epoch 1: 7.948116399347782e-05
Local loss @ local epoch 2: 0.029068440198898315
Local loss @ local epoch 3: 0.00023721954494249076
Local loss @ local epoch 4: 0.7782662510871887
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.7 seconds!
[tester] 
AGNewsMetric: acc=0.4619736842105263, hinge=8.771880097138254, ce=12.556978978608784
Local test acc @ epoch 82: 0.462
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.1160159483551979
Local loss @ local epoch 1: 0.050610799342393875
Local loss @ local epoch 2: 0.006830174010246992
Local loss @ local epoch 3: 0.11660884320735931
Local loss @ local epoch 4: 0.001141750835813582
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.23 seconds!
[tester] 
AGNewsMetric: acc=0.5269736842105263, hinge=5.49071299101177, ce=12.05988736403616
Local test acc @ epoch 82: 0.527
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.05303764343261719
Local loss @ local epoch 1: 0.00011484507558634505
Local loss @ local epoch 2: 0.140439972281456
Local loss @ local epoch 3: 0.00023410395078826696
Local loss @ local epoch 4: 0.0003143414214719087
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.03 seconds!
[tester] 
AGNewsMetric: acc=0.8130263157894737, hinge=1.7566920516365452, ce=10.539611762197394
Local test acc @ epoch 82: 0.813
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 1.6689295989635866e-07
Local loss @ local epoch 1: 2.3841853646899835e-07
Local loss @ local epoch 2: 2.0742331798828673e-06
Local loss @ local epoch 3: 0.00011252753029111773
Local loss @ local epoch 4: 4.577601885102922e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 125.31 seconds!
[tester] 
AGNewsMetric: acc=0.7172368421052632, hinge=3.0584157569784867, ce=10.67239325071636
Local test acc @ epoch 82: 0.7172
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.23951157927513123
Local loss @ local epoch 1: 0.002934482181444764
Local loss @ local epoch 2: 0.7203468084335327
Local loss @ local epoch 3: 0.15019957721233368
Local loss @ local epoch 4: 0.009282965213060379
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.83 seconds!
[tester] 
AGNewsMetric: acc=0.8132894736842106, hinge=1.4661331375021684, ce=9.987368571632787
Local test acc @ epoch 82: 0.8133
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.04151667654514313
Local loss @ local epoch 1: 0.00024229379778262228
Local loss @ local epoch 2: 0.0013903967337682843
Local loss @ local epoch 3: 0.00016430836694780737
Local loss @ local epoch 4: 0.0014075246872380376
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.95 seconds!
[tester] 
AGNewsMetric: acc=0.41789473684210526, hinge=8.174596196224815, ce=12.922304868196186
Local test acc @ epoch 82: 0.4179
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.019811037927865982
Local loss @ local epoch 1: 0.24670910835266113
Local loss @ local epoch 2: 0.013226916082203388
Local loss @ local epoch 3: 0.07049886137247086
Local loss @ local epoch 4: 0.08277739584445953
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.24 seconds!
[tester] 
AGNewsMetric: acc=0.7778947368421053, hinge=1.5396448308543156, ce=5.138340472171181
Local test acc @ epoch 82: 0.7779
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0001303086755797267
Local loss @ local epoch 1: 0.00010131328599527478
Local loss @ local epoch 2: 1.6629459423711523e-05
Local loss @ local epoch 3: 0.0002456589136272669
Local loss @ local epoch 4: 0.000627045170404017
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.76 seconds!
[tester] 
AGNewsMetric: acc=0.7760526315789473, hinge=1.9063951923972682, ce=8.697824437994706
Local test acc @ epoch 82: 0.7761
Global evaluate on test data...
Evaluate data in 123.46 seconds!
[tester] 
AGNewsMetric: acc=0.8669736842105263, hinge=1.262300316158094, ce=9.652769251371685
Global test acc @ epoch 82: 0.867
Global epoch 83...
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.000656522111967206
Local loss @ local epoch 1: 4.1427418182138354e-05
Local loss @ local epoch 2: 5.115110980113968e-06
Local loss @ local epoch 3: 3.2833439036039636e-05
Local loss @ local epoch 4: 0.0011478542583063245
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.12 seconds!
[tester] 
AGNewsMetric: acc=0.45039473684210524, hinge=9.599581657208894, ce=13.646735580845883
Local test acc @ epoch 83: 0.4504
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.01679598167538643
Local loss @ local epoch 1: 0.29217419028282166
Local loss @ local epoch 2: 0.027421293780207634
Local loss @ local epoch 3: 0.0685870498418808
Local loss @ local epoch 4: 0.04198983311653137
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.62 seconds!
[tester] 
AGNewsMetric: acc=0.745, hinge=2.2147087245238453, ce=9.8930117255763
Local test acc @ epoch 83: 0.745
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0008165134931914508
Local loss @ local epoch 1: 0.00016528123524039984
Local loss @ local epoch 2: 0.00015841475396882743
Local loss @ local epoch 3: 7.095001637935638e-05
Local loss @ local epoch 4: 0.00040504286880604923
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.92 seconds!
[tester] 
AGNewsMetric: acc=0.45210526315789473, hinge=9.810989915446232, ce=13.280790236623664
Local test acc @ epoch 83: 0.4521
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.000672576017677784
Local loss @ local epoch 1: 0.00014859673683531582
Local loss @ local epoch 2: 0.0028319908306002617
Local loss @ local epoch 3: 0.00033868858008645475
Local loss @ local epoch 4: 0.00042352289892733097
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.71 seconds!
[tester] 
AGNewsMetric: acc=0.7981578947368421, hinge=1.5860874685488249, ce=9.230214022586221
Local test acc @ epoch 83: 0.7982
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.03772406280040741
Local loss @ local epoch 1: 0.006751081440597773
Local loss @ local epoch 2: 0.00023487287398893386
Local loss @ local epoch 3: 0.00031477451557293534
Local loss @ local epoch 4: 0.0006219827919267118
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.86 seconds!
[tester] 
AGNewsMetric: acc=0.7326315789473684, hinge=1.841937858179996, ce=11.066860411794561
Local test acc @ epoch 83: 0.7326
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.016440629959106445
Local loss @ local epoch 1: 0.07812138646841049
Local loss @ local epoch 2: 0.002781759714707732
Local loss @ local epoch 3: 0.010087292641401291
Local loss @ local epoch 4: 0.01647387631237507
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.94 seconds!
[tester] 
AGNewsMetric: acc=0.7772368421052631, hinge=1.8388975670463161, ce=9.112301768252724
Local test acc @ epoch 83: 0.7772
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0005380224902182817
Local loss @ local epoch 1: 0.0012309240410104394
Local loss @ local epoch 2: 0.0002363657404202968
Local loss @ local epoch 3: 0.0001539657823741436
Local loss @ local epoch 4: 9.151448466582224e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.08 seconds!
[tester] 
AGNewsMetric: acc=0.7094736842105264, hinge=2.3588428088238365, ce=11.039949937117727
Local test acc @ epoch 83: 0.7095
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.8035125136375427
Local loss @ local epoch 1: 0.0019087425898760557
Local loss @ local epoch 2: 0.0035670092329382896
Local loss @ local epoch 3: 0.00010066479444503784
Local loss @ local epoch 4: 0.0014509429456666112
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.08 seconds!
[tester] 
AGNewsMetric: acc=0.35368421052631577, hinge=9.412367373014751, ce=13.00428974753932
Local test acc @ epoch 83: 0.3537
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.21430273354053497
Local loss @ local epoch 1: 0.008764573372900486
Local loss @ local epoch 2: 0.005739247426390648
Local loss @ local epoch 3: 0.004253158811479807
Local loss @ local epoch 4: 0.0021909074857831
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.9 seconds!
[tester] 
AGNewsMetric: acc=0.5742105263157895, hinge=4.010636757549487, ce=10.263417755930048
Local test acc @ epoch 83: 0.5742
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 1.6450846942461794e-06
Local loss @ local epoch 1: 8.058431376412045e-06
Local loss @ local epoch 2: 2.622603290092229e-07
Local loss @ local epoch 3: 2.8610210733859276e-07
Local loss @ local epoch 4: 2.1457667287450022e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.57 seconds!
[tester] 
AGNewsMetric: acc=0.43355263157894736, hinge=10.779925313246878, ce=14.076041018837376
Local test acc @ epoch 83: 0.4336
Global evaluate on test data...
Evaluate data in 123.36 seconds!
[tester] 
AGNewsMetric: acc=0.8547368421052631, hinge=1.2593972005342182, ce=9.814306241085655
Global test acc @ epoch 83: 0.8547
Global epoch 84...
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.07724814862012863
Local loss @ local epoch 1: 8.905053982743993e-05
Local loss @ local epoch 2: 7.331329925364116e-06
Local loss @ local epoch 3: 0.006526506040245295
Local loss @ local epoch 4: 0.0008658248116262257
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.16 seconds!
[tester] 
AGNewsMetric: acc=0.40078947368421053, hinge=11.57279863357544, ce=11.282218625921953
Local test acc @ epoch 84: 0.4008
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.07198797166347504
Local loss @ local epoch 1: 0.06812094897031784
Local loss @ local epoch 2: 0.06865083426237106
Local loss @ local epoch 3: 0.0016795173287391663
Local loss @ local epoch 4: 0.09895586222410202
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.27 seconds!
[tester] 
AGNewsMetric: acc=0.8292105263157895, hinge=1.76127490219317, ce=9.974090540032638
Local test acc @ epoch 84: 0.8292
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.03018469363451004
Local loss @ local epoch 1: 0.0060715219005942345
Local loss @ local epoch 2: 0.00016379794396925718
Local loss @ local epoch 3: 0.4784248471260071
Local loss @ local epoch 4: 0.0006671511218883097
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.88 seconds!
[tester] 
AGNewsMetric: acc=0.5971052631578947, hinge=4.767199384538751, ce=10.84043761403937
Local test acc @ epoch 84: 0.5971
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.023569529876112938
Local loss @ local epoch 1: 0.004500262904912233
Local loss @ local epoch 2: 0.0017752224812284112
Local loss @ local epoch 3: 0.00019404018530622125
Local loss @ local epoch 4: 0.00010095843026647344
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.94 seconds!
[tester] 
AGNewsMetric: acc=0.48039473684210526, hinge=4.22988955397355, ce=12.540041919507479
Local test acc @ epoch 84: 0.4804
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 3.0040678211662453e-06
Local loss @ local epoch 1: 0.022786274552345276
Local loss @ local epoch 2: 3.242481398046948e-06
Local loss @ local epoch 3: 5.102102932141861e-06
Local loss @ local epoch 4: 1.5497178083023755e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.7 seconds!
[tester] 
AGNewsMetric: acc=0.45842105263157895, hinge=6.31137461210552, ce=12.043850079586631
Local test acc @ epoch 84: 0.4584
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 8.259972673840821e-05
Local loss @ local epoch 1: 1.4662517969554756e-05
Local loss @ local epoch 2: 6.109425612521591e-06
Local loss @ local epoch 3: 3.984419163316488e-05
Local loss @ local epoch 4: 0.0001501643710071221
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.4 seconds!
[tester] 
AGNewsMetric: acc=0.5290789473684211, hinge=5.624562469281648, ce=10.856087122465436
Local test acc @ epoch 84: 0.5291
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.017328353598713875
Local loss @ local epoch 1: 0.000119020689453464
Local loss @ local epoch 2: 0.0001689834607532248
Local loss @ local epoch 3: 1.8390406694379635e-05
Local loss @ local epoch 4: 0.0010573180625215173
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.61 seconds!
[tester] 
AGNewsMetric: acc=0.5193421052631579, hinge=5.924254083382456, ce=11.061658979717054
Local test acc @ epoch 84: 0.5193
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.02587002143263817
Local loss @ local epoch 1: 0.020127395167946815
Local loss @ local epoch 2: 0.34012505412101746
Local loss @ local epoch 3: 0.06008327379822731
Local loss @ local epoch 4: 0.017380064353346825
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.61 seconds!
[tester] 
AGNewsMetric: acc=0.8236842105263158, hinge=1.3361916205757542, ce=10.42878069425884
Local test acc @ epoch 84: 0.8237
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.31262293457984924
Local loss @ local epoch 1: 0.0015021876897662878
Local loss @ local epoch 2: 0.0008855836931616068
Local loss @ local epoch 3: 0.0020715955179184675
Local loss @ local epoch 4: 0.29740452766418457
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.9 seconds!
[tester] 
AGNewsMetric: acc=0.4652631578947368, hinge=6.625008654343454, ce=11.185405486257453
Local test acc @ epoch 84: 0.4653
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.01918807439506054
Local loss @ local epoch 1: 2.1207861209404655e-05
Local loss @ local epoch 2: 0.08784139901399612
Local loss @ local epoch 3: 9.510785457678139e-05
Local loss @ local epoch 4: 7.010870467638597e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.41 seconds!
[tester] 
AGNewsMetric: acc=0.7551315789473684, hinge=2.3806441462667363, ce=10.19060905054996
Local test acc @ epoch 84: 0.7551
Global evaluate on test data...
Evaluate data in 124.06 seconds!
[tester] 
AGNewsMetric: acc=0.8669736842105263, hinge=1.2998147776252345, ce=9.482788949263723
Global test acc @ epoch 84: 0.867
Global epoch 85...
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.6444932818412781
Local loss @ local epoch 1: 0.021564891561865807
Local loss @ local epoch 2: 0.007985482923686504
Local loss @ local epoch 3: 0.001400757348164916
Local loss @ local epoch 4: 0.0014807245461270213
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.82 seconds!
[tester] 
AGNewsMetric: acc=0.38473684210526315, hinge=7.904414593546014, ce=12.365003003572163
Local test acc @ epoch 85: 0.3847
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.003825586521998048
Local loss @ local epoch 1: 0.0016737969126552343
Local loss @ local epoch 2: 0.005526240449398756
Local loss @ local epoch 3: 0.006709448527544737
Local loss @ local epoch 4: 0.01038295030593872
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.61 seconds!
[tester] 
AGNewsMetric: acc=0.511578947368421, hinge=4.220675197400545, ce=12.665417932209216
Local test acc @ epoch 85: 0.5116
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0005378775531426072
Local loss @ local epoch 1: 1.3394581401371397e-05
Local loss @ local epoch 2: 8.810494364297483e-06
Local loss @ local epoch 3: 5.318171679391526e-05
Local loss @ local epoch 4: 5.331885404302739e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.84 seconds!
[tester] 
AGNewsMetric: acc=0.3813157894736842, hinge=11.057816214310495, ce=14.629011296724018
Local test acc @ epoch 85: 0.3813
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 5.4120559980219696e-06
Local loss @ local epoch 1: 2.0980796762160026e-06
Local loss @ local epoch 2: 4.2915334574900044e-07
Local loss @ local epoch 3: 7.629384413121443e-07
Local loss @ local epoch 4: 7.5101138463651296e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.54 seconds!
[tester] 
AGNewsMetric: acc=0.6269736842105263, hinge=3.989559679533306, ce=8.69214181197317
Local test acc @ epoch 85: 0.627
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.8595613241195679
Local loss @ local epoch 1: 0.001723943161778152
Local loss @ local epoch 2: 0.0004591978795360774
Local loss @ local epoch 3: 0.0023128122556954622
Local loss @ local epoch 4: 0.0013565619010478258
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.32 seconds!
[tester] 
AGNewsMetric: acc=0.5135526315789474, hinge=4.908245919127213, ce=11.045731703105726
Local test acc @ epoch 85: 0.5136
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0003693044709507376
Local loss @ local epoch 1: 1.5715342669864185e-05
Local loss @ local epoch 2: 0.0004114280454814434
Local loss @ local epoch 3: 8.511874329997227e-05
Local loss @ local epoch 4: 3.8661150028929114e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.82 seconds!
[tester] 
AGNewsMetric: acc=0.44973684210526316, hinge=11.136609791203549, ce=13.284286003112793
Local test acc @ epoch 85: 0.4497
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0020058336667716503
Local loss @ local epoch 1: 3.061404640902765e-05
Local loss @ local epoch 2: 0.000488289340864867
Local loss @ local epoch 3: 0.00013320583093445748
Local loss @ local epoch 4: 0.009292981587350368
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.54 seconds!
[tester] 
AGNewsMetric: acc=0.6613157894736842, hinge=4.537058255546971, ce=11.060710172151264
Local test acc @ epoch 85: 0.6613
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.17977899312973022
Local loss @ local epoch 1: 0.05792616680264473
Local loss @ local epoch 2: 0.11925475299358368
Local loss @ local epoch 3: 0.018760258331894875
Local loss @ local epoch 4: 0.06031619384884834
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.68 seconds!
[tester] 
AGNewsMetric: acc=0.8239473684210527, hinge=1.449729844394483, ce=6.740923529173198
Local test acc @ epoch 85: 0.8239
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0010830876417458057
Local loss @ local epoch 1: 0.0006797639071010053
Local loss @ local epoch 2: 0.01251755841076374
Local loss @ local epoch 3: 2.8484103679656982
Local loss @ local epoch 4: 2.032486372627318e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.84 seconds!
[tester] 
AGNewsMetric: acc=0.7609210526315789, hinge=2.1633713047127974, ce=9.831795563948782
Local test acc @ epoch 85: 0.7609
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0033859480172395706
Local loss @ local epoch 1: 0.001171496813185513
Local loss @ local epoch 2: 0.00015555332356598228
Local loss @ local epoch 3: 0.0005412902100943029
Local loss @ local epoch 4: 0.000610620656516403
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.85 seconds!
[tester] 
AGNewsMetric: acc=0.6497368421052632, hinge=2.511470990682903, ce=11.658523226286235
Local test acc @ epoch 85: 0.6497
Global evaluate on test data...
Evaluate data in 123.84 seconds!
[tester] 
AGNewsMetric: acc=0.8605263157894737, hinge=1.3270913723895423, ce=9.423812930458471
Global test acc @ epoch 85: 0.8605
Global epoch 86...
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 5.722043283640232e-07
Local loss @ local epoch 1: 7.152551688704989e-07
Local loss @ local epoch 2: 1.668929883180681e-07
Local loss @ local epoch 3: 3.647788162197685e-06
Local loss @ local epoch 4: 7.152556236178498e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.35 seconds!
[tester] 
AGNewsMetric: acc=0.5039473684210526, hinge=7.748553304170307, ce=13.20823570251465
Local test acc @ epoch 86: 0.5039
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.2590753138065338
Local loss @ local epoch 1: 0.010531301610171795
Local loss @ local epoch 2: 0.004150800406932831
Local loss @ local epoch 3: 0.001701011206023395
Local loss @ local epoch 4: 0.1292201280593872
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.47 seconds!
[tester] 
AGNewsMetric: acc=0.4130263157894737, hinge=6.123115184181615, ce=11.65669443632427
Local test acc @ epoch 86: 0.413
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.00019316287944093347
Local loss @ local epoch 1: 4.85173259221483e-05
Local loss @ local epoch 2: 0.0006037786952219903
Local loss @ local epoch 3: 0.00016559749201405793
Local loss @ local epoch 4: 0.0009092186228372157
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.76 seconds!
[tester] 
AGNewsMetric: acc=0.7818421052631579, hinge=2.2139899565044203, ce=9.892351254914937
Local test acc @ epoch 86: 0.7818
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.011783928610384464
Local loss @ local epoch 1: 1.3842686414718628
Local loss @ local epoch 2: 0.5249402523040771
Local loss @ local epoch 3: 0.03952489048242569
Local loss @ local epoch 4: 0.04193759337067604
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.6 seconds!
[tester] 
AGNewsMetric: acc=0.7875, hinge=1.7963752299860904, ce=9.07623333378842
Local test acc @ epoch 86: 0.7875
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.04682521894574165
Local loss @ local epoch 1: 1.1771663594117854e-05
Local loss @ local epoch 2: 0.00021260946232359856
Local loss @ local epoch 3: 0.001570661086589098
Local loss @ local epoch 4: 0.05486704036593437
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.66 seconds!
[tester] 
AGNewsMetric: acc=0.46789473684210525, hinge=9.432201585016752, ce=11.770940455386514
Local test acc @ epoch 86: 0.4679
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.04210815951228142
Local loss @ local epoch 1: 1.0360145097365603e-05
Local loss @ local epoch 2: 1.7370963178109378e-05
Local loss @ local epoch 3: 4.95258109367569e-06
Local loss @ local epoch 4: 1.3307952940522227e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.78 seconds!
[tester] 
AGNewsMetric: acc=0.3436842105263158, hinge=12.275176957782946, ce=14.75279200302927
Local test acc @ epoch 86: 0.3437
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.00020697491709142923
Local loss @ local epoch 1: 2.890818450396182e-06
Local loss @ local epoch 2: 1.1265146895311773e-05
Local loss @ local epoch 3: 7.544938125647604e-05
Local loss @ local epoch 4: 0.00012853580119553953
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.93 seconds!
[tester] 
AGNewsMetric: acc=0.638421052631579, hinge=4.067232167595312, ce=10.182464967024954
Local test acc @ epoch 86: 0.6384
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.3236483335494995
Local loss @ local epoch 1: 0.000234667953918688
Local loss @ local epoch 2: 0.0002854348858818412
Local loss @ local epoch 3: 0.06607786566019058
Local loss @ local epoch 4: 0.0007045255042612553
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.27 seconds!
[tester] 
AGNewsMetric: acc=0.48855263157894735, hinge=8.116428948452597, ce=11.529723906266062
Local test acc @ epoch 86: 0.4886
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.012170830741524696
Local loss @ local epoch 1: 0.000996474060229957
Local loss @ local epoch 2: 0.6769058108329773
Local loss @ local epoch 3: 0.005453117657452822
Local loss @ local epoch 4: 0.006129662971943617
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.18 seconds!
[tester] 
AGNewsMetric: acc=0.8676315789473684, hinge=1.2937956142425537, ce=10.013993771201687
Local test acc @ epoch 86: 0.8676
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.012857228517532349
Local loss @ local epoch 1: 0.0004334961995482445
Local loss @ local epoch 2: 0.0007971175946295261
Local loss @ local epoch 3: 0.0006125271902419627
Local loss @ local epoch 4: 0.00014339738117996603
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.48 seconds!
[tester] 
AGNewsMetric: acc=0.5710526315789474, hinge=3.249289750048989, ce=10.248424746864721
Local test acc @ epoch 86: 0.5711
Global evaluate on test data...
Evaluate data in 124.02 seconds!
[tester] 
AGNewsMetric: acc=0.8526315789473684, hinge=1.5215029392744366, ce=8.88590554287559
Global test acc @ epoch 86: 0.8526
Global epoch 87...
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 4.56521738669835e-05
Local loss @ local epoch 1: 8.355269528692588e-06
Local loss @ local epoch 2: 7.152552257139178e-07
Local loss @ local epoch 3: 4.150631411903305e-06
Local loss @ local epoch 4: 6.068787115509622e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.78 seconds!
[tester] 
AGNewsMetric: acc=0.38855263157894737, hinge=12.342618869982267, ce=14.461350788317228
Local test acc @ epoch 87: 0.3886
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.07371168583631516
Local loss @ local epoch 1: 0.0016018691239878535
Local loss @ local epoch 2: 0.6170105338096619
Local loss @ local epoch 3: 0.0012824776349589229
Local loss @ local epoch 4: 0.003040204755961895
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.07 seconds!
[tester] 
AGNewsMetric: acc=0.8253947368421053, hinge=1.5556761671367445, ce=9.551527501156455
Local test acc @ epoch 87: 0.8254
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 1.1931830644607544
Local loss @ local epoch 1: 0.003249812638387084
Local loss @ local epoch 2: 0.002736292313784361
Local loss @ local epoch 3: 0.007172819692641497
Local loss @ local epoch 4: 0.02017727680504322
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.07 seconds!
[tester] 
AGNewsMetric: acc=0.48907894736842106, hinge=4.736059581355045, ce=8.188345647109182
Local test acc @ epoch 87: 0.4891
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.005610810127109289
Local loss @ local epoch 1: 5.8779787650564685e-05
Local loss @ local epoch 2: 0.0001071654842235148
Local loss @ local epoch 3: 3.0972962122177705e-05
Local loss @ local epoch 4: 0.0011130451457574964
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.44 seconds!
[tester] 
AGNewsMetric: acc=0.4205263157894737, hinge=9.089984988162392, ce=14.369787246302554
Local test acc @ epoch 87: 0.4205
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0005374804604798555
Local loss @ local epoch 1: 4.1155144572257996e-05
Local loss @ local epoch 2: 0.0007221439154818654
Local loss @ local epoch 3: 4.380925020086579e-06
Local loss @ local epoch 4: 3.933706830139272e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.46 seconds!
[tester] 
AGNewsMetric: acc=0.5851315789473684, hinge=5.479809926685534, ce=9.07544361516049
Local test acc @ epoch 87: 0.5851
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.00011299626930849627
Local loss @ local epoch 1: 0.00010733845556387678
Local loss @ local epoch 2: 0.0002086850581690669
Local loss @ local epoch 3: 0.00011516626545926556
Local loss @ local epoch 4: 5.321417120285332e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.67 seconds!
[tester] 
AGNewsMetric: acc=0.6355263157894737, hinge=4.788274268100136, ce=12.214116949784128
Local test acc @ epoch 87: 0.6355
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.4598819315433502
Local loss @ local epoch 1: 0.006004226393997669
Local loss @ local epoch 2: 0.002210073871538043
Local loss @ local epoch 3: 0.0005053316708654165
Local loss @ local epoch 4: 0.0018830372719094157
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.62 seconds!
[tester] 
AGNewsMetric: acc=0.5592105263157895, hinge=4.788099734155756, ce=9.48688048111765
Local test acc @ epoch 87: 0.5592
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.03769228607416153
Local loss @ local epoch 1: 0.0014367342228069901
Local loss @ local epoch 2: 0.0031712225172668695
Local loss @ local epoch 3: 0.002212349558249116
Local loss @ local epoch 4: 0.008731951005756855
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.31 seconds!
[tester] 
AGNewsMetric: acc=0.5167105263157895, hinge=4.755094089006123, ce=11.92273002022191
Local test acc @ epoch 87: 0.5167
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.1904619336128235
Local loss @ local epoch 1: 0.015187765471637249
Local loss @ local epoch 2: 0.004441884346306324
Local loss @ local epoch 3: 0.0018960707820951939
Local loss @ local epoch 4: 0.0017030310118570924
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.18 seconds!
[tester] 
AGNewsMetric: acc=0.5372368421052631, hinge=3.1040558026966294, ce=6.355756536784925
Local test acc @ epoch 87: 0.5372
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 1.4305111051271524e-07
Local loss @ local epoch 1: 1.4305112472356996e-07
Local loss @ local epoch 2: 2.8610219260372105e-07
Local loss @ local epoch 3: 1.025199026116752e-06
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.99 seconds!
[tester] 
AGNewsMetric: acc=0.5525, hinge=4.331961401889199, ce=10.480554889879729
Local test acc @ epoch 87: 0.5525
Global evaluate on test data...
Evaluate data in 124.1 seconds!
[tester] 
AGNewsMetric: acc=0.8092105263157895, hinge=1.733773411951567, ce=8.814600874248304
Global test acc @ epoch 87: 0.8092
Global epoch 88...
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.011566400527954102
Local loss @ local epoch 1: 0.017479337751865387
Local loss @ local epoch 2: 0.0027256521862000227
Local loss @ local epoch 3: 0.0011848261347040534
Local loss @ local epoch 4: 0.002769281156361103
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.43 seconds!
[tester] 
AGNewsMetric: acc=0.5022368421052632, hinge=5.7601477407154285, ce=11.009029039081774
Local test acc @ epoch 88: 0.5022
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.009591180831193924
Local loss @ local epoch 1: 0.0003379761183168739
Local loss @ local epoch 2: 0.0025554541498422623
Local loss @ local epoch 3: 0.0017618330894038081
Local loss @ local epoch 4: 0.009408312849700451
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.86 seconds!
[tester] 
AGNewsMetric: acc=0.5436842105263158, hinge=6.421699926978663, ce=11.01123727698075
Local test acc @ epoch 88: 0.5437
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 3.1709514587419108e-06
Local loss @ local epoch 1: 7.152552257139178e-07
Local loss @ local epoch 2: 3.790840764850145e-06
Local loss @ local epoch 3: 2.288732139277272e-05
Local loss @ local epoch 4: 1.5497192862312659e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.36 seconds!
[tester] 
AGNewsMetric: acc=0.37855263157894736, hinge=9.126557100195633, ce=14.34815422258879
Local test acc @ epoch 88: 0.3786
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 1.946052725543268e-05
Local loss @ local epoch 1: 0.00010003418719861656
Local loss @ local epoch 2: 6.46966218482703e-05
Local loss @ local epoch 3: 9.238657185051125e-06
Local loss @ local epoch 4: 2.8460368412197568e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.79 seconds!
[tester] 
AGNewsMetric: acc=0.7232894736842105, hinge=2.432345610166851, ce=9.081348320810418
Local test acc @ epoch 88: 0.7233
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.1408872753381729
Local loss @ local epoch 1: 0.006523470394313335
Local loss @ local epoch 2: 0.002776762703433633
Local loss @ local epoch 3: 0.37766072154045105
Local loss @ local epoch 4: 0.016560683026909828
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.65 seconds!
[tester] 
AGNewsMetric: acc=0.8439473684210527, hinge=1.5367162360643085, ce=9.819525610271253
Local test acc @ epoch 88: 0.8439
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0011036752257496119
Local loss @ local epoch 1: 2.436681643303018e-05
Local loss @ local epoch 2: 1.6043044524849392e-05
Local loss @ local epoch 3: 1.0231765372736845e-05
Local loss @ local epoch 4: 2.676075564522762e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.17 seconds!
[tester] 
AGNewsMetric: acc=0.42894736842105263, hinge=11.802374144604332, ce=14.086372756958008
Local test acc @ epoch 88: 0.4289
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0011707320809364319
Local loss @ local epoch 1: 2.2648018784821033e-05
Local loss @ local epoch 2: 2.5703939172672108e-05
Local loss @ local epoch 3: 3.2701718737371266e-05
Local loss @ local epoch 4: 1.4738579920958728e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 125.18 seconds!
[tester] 
AGNewsMetric: acc=0.4639473684210526, hinge=12.423355208196138, ce=12.885859760485197
Local test acc @ epoch 88: 0.4639
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.2724356949329376
Local loss @ local epoch 1: 0.177850142121315
Local loss @ local epoch 2: 0.006237237714231014
Local loss @ local epoch 3: 0.02628348395228386
Local loss @ local epoch 4: 0.015324980951845646
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.61 seconds!
[tester] 
AGNewsMetric: acc=0.6678947368421052, hinge=2.4989570775784946, ce=10.790435891402396
Local test acc @ epoch 88: 0.6679
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.04888216778635979
Local loss @ local epoch 1: 0.005046532955020666
Local loss @ local epoch 2: 0.0007655470399186015
Local loss @ local epoch 3: 0.0009116239380091429
Local loss @ local epoch 4: 0.0009617526666261256
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.2 seconds!
[tester] 
AGNewsMetric: acc=0.48736842105263156, hinge=5.205918707094694, ce=9.074811511792635
Local test acc @ epoch 88: 0.4874
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.009673136286437511
Local loss @ local epoch 1: 0.08558899909257889
Local loss @ local epoch 2: 0.0025169074069708586
Local loss @ local epoch 3: 0.008679741062223911
Local loss @ local epoch 4: 0.12134269624948502
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.21 seconds!
[tester] 
AGNewsMetric: acc=0.5615789473684211, hinge=4.077896511178268, ce=5.485461821305124
Local test acc @ epoch 88: 0.5616
Global evaluate on test data...
Evaluate data in 124.69 seconds!
[tester] 
AGNewsMetric: acc=0.8542105263157894, hinge=1.3555915082128425, ce=9.671434336210552
Global test acc @ epoch 88: 0.8542
Global epoch 89...
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.9012939929962158
Local loss @ local epoch 1: 0.17740662395954132
Local loss @ local epoch 2: 0.029666440561413765
Local loss @ local epoch 3: 0.03561311215162277
Local loss @ local epoch 4: 0.02067141979932785
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.54 seconds!
[tester] 
AGNewsMetric: acc=0.6632894736842105, hinge=2.3814456264596235, ce=9.685938212746068
Local test acc @ epoch 89: 0.6633
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.03611493855714798
Local loss @ local epoch 1: 0.00015860226994846016
Local loss @ local epoch 2: 0.0007250586058944464
Local loss @ local epoch 3: 0.0021133257541805506
Local loss @ local epoch 4: 9.795860387384892e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.68 seconds!
[tester] 
AGNewsMetric: acc=0.4814473684210526, hinge=9.771908631073801, ce=11.879153639140881
Local test acc @ epoch 89: 0.4814
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0012224380625411868
Local loss @ local epoch 1: 0.0004459960910025984
Local loss @ local epoch 2: 0.00041420143679715693
Local loss @ local epoch 3: 0.0009721061214804649
Local loss @ local epoch 4: 0.00197686068713665
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.46 seconds!
[tester] 
AGNewsMetric: acc=0.5642105263157895, hinge=3.5095722178408972, ce=11.52985045382851
Local test acc @ epoch 89: 0.5642
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 6.675714985249215e-07
Local loss @ local epoch 1: 2.384185648907078e-08
Local loss @ local epoch 2: 3.0994391408967203e-07
Local loss @ local epoch 3: 2.1457663024193607e-07
Local loss @ local epoch 4: 1.1920926823449918e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.88 seconds!
[tester] 
AGNewsMetric: acc=0.7398684210526316, hinge=2.335523053721378, ce=10.49265393508108
Local test acc @ epoch 89: 0.7399
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 9.449417848372832e-05
Local loss @ local epoch 1: 8.48990966915153e-05
Local loss @ local epoch 2: 0.0001356904540443793
Local loss @ local epoch 3: 0.0002873650810215622
Local loss @ local epoch 4: 0.00017349483096040785
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.77 seconds!
[tester] 
AGNewsMetric: acc=0.7405263157894737, hinge=2.3228631235423842, ce=8.563021240234375
Local test acc @ epoch 89: 0.7405
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.04918717220425606
Local loss @ local epoch 1: 3.413698095755535e-06
Local loss @ local epoch 2: 2.0123261492699385e-05
Local loss @ local epoch 3: 5.440234417619649e-06
Local loss @ local epoch 4: 3.4482065530028194e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.86 seconds!
[tester] 
AGNewsMetric: acc=0.4722368421052632, hinge=8.69874180316925, ce=12.6693255253842
Local test acc @ epoch 89: 0.4722
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.257509708404541
Local loss @ local epoch 1: 0.11164887994527817
Local loss @ local epoch 2: 0.02794056013226509
Local loss @ local epoch 3: 0.04037460684776306
Local loss @ local epoch 4: 0.07077034562826157
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.04 seconds!
[tester] 
AGNewsMetric: acc=0.6003947368421053, hinge=3.221273343437596, ce=9.353832126416657
Local test acc @ epoch 89: 0.6004
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.057812657207250595
Local loss @ local epoch 1: 0.23411284387111664
Local loss @ local epoch 2: 0.03931874781847
Local loss @ local epoch 3: 0.032356295734643936
Local loss @ local epoch 4: 0.1241183876991272
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.74 seconds!
[tester] 
AGNewsMetric: acc=0.7856578947368421, hinge=1.484427985141152, ce=10.768060206363076
Local test acc @ epoch 89: 0.7857
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0031132677104324102
Local loss @ local epoch 1: 2.183452306780964e-05
Local loss @ local epoch 2: 8.046565199038014e-06
Local loss @ local epoch 3: 0.003819839796051383
Local loss @ local epoch 4: 0.004251118749380112
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.67 seconds!
[tester] 
AGNewsMetric: acc=0.695, hinge=3.2312504685552494, ce=10.307640318619578
Local test acc @ epoch 89: 0.695
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.8812779784202576
Local loss @ local epoch 1: 0.008015763945877552
Local loss @ local epoch 2: 1.144124150276184
Local loss @ local epoch 3: 0.23342938721179962
Local loss @ local epoch 4: 0.004598852246999741
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.59 seconds!
[tester] 
AGNewsMetric: acc=0.6989473684210527, hinge=3.2551375707827117, ce=10.100857792904502
Local test acc @ epoch 89: 0.6989
Global evaluate on test data...
Evaluate data in 123.99 seconds!
[tester] 
AGNewsMetric: acc=0.8119736842105263, hinge=1.816452791565343, ce=9.126433047244424
Global test acc @ epoch 89: 0.812
Global epoch 90...
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.00020455261983443052
Local loss @ local epoch 1: 2.439239870000165e-05
Local loss @ local epoch 2: 1.4846941667201463e-06
Local loss @ local epoch 3: 2.535889734645025e-06
Local loss @ local epoch 4: 4.562426966003841e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.55 seconds!
[tester] 
AGNewsMetric: acc=0.39223684210526316, hinge=12.513960431249519, ce=13.362792695697985
Local test acc @ epoch 90: 0.3922
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 1.8308250218979083e-05
Local loss @ local epoch 1: 0.015596884302794933
Local loss @ local epoch 2: 9.228669114236254e-06
Local loss @ local epoch 3: 0.023798808455467224
Local loss @ local epoch 4: 0.0002036411315202713
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.81 seconds!
[tester] 
AGNewsMetric: acc=0.7926315789473685, hinge=2.0547328216151186, ce=10.249384129172878
Local test acc @ epoch 90: 0.7926
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.2928076684474945
Local loss @ local epoch 1: 0.021484047174453735
Local loss @ local epoch 2: 0.0012038263957947493
Local loss @ local epoch 3: 0.002068587811663747
Local loss @ local epoch 4: 0.000968919659499079
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.88 seconds!
[tester] 
AGNewsMetric: acc=0.5289473684210526, hinge=5.457350698270296, ce=11.235297407852975
Local test acc @ epoch 90: 0.5289
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0002853204496204853
Local loss @ local epoch 1: 7.202148026408395e-06
Local loss @ local epoch 2: 1.8863845980376936e-05
Local loss @ local epoch 3: 3.974041101173498e-05
Local loss @ local epoch 4: 3.1391639367939206e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.43 seconds!
[tester] 
AGNewsMetric: acc=0.4676315789473684, hinge=9.133492994057505, ce=13.705289708187706
Local test acc @ epoch 90: 0.4676
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 1.0728822417149786e-06
Local loss @ local epoch 1: 5.006787660022383e-07
Local loss @ local epoch 2: 1.1920927533992653e-07
Local loss @ local epoch 3: 9.775151283974992e-07
Local loss @ local epoch 4: 3.433206529734889e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.62 seconds!
[tester] 
AGNewsMetric: acc=0.6189473684210526, hinge=4.747414033789384, ce=11.45153185392681
Local test acc @ epoch 90: 0.6189
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0003488210786599666
Local loss @ local epoch 1: 0.0004734170506708324
Local loss @ local epoch 2: 2.0443838366190903e-05
Local loss @ local epoch 3: 8.404164873354603e-06
Local loss @ local epoch 4: 0.3665664494037628
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.95 seconds!
[tester] 
AGNewsMetric: acc=0.6769736842105263, hinge=3.4140618053235507, ce=10.50280083907278
Local test acc @ epoch 90: 0.677
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.05629914626479149
Local loss @ local epoch 1: 0.062228720635175705
Local loss @ local epoch 2: 0.2572438418865204
Local loss @ local epoch 3: 0.01784498430788517
Local loss @ local epoch 4: 0.08919670432806015
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.51 seconds!
[tester] 
AGNewsMetric: acc=0.7678947368421053, hinge=1.6564990871830991, ce=6.669982144205194
Local test acc @ epoch 90: 0.7679
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.766875147819519
Local loss @ local epoch 1: 0.011641317047178745
Local loss @ local epoch 2: 0.0368988923728466
Local loss @ local epoch 3: 0.0007691918290220201
Local loss @ local epoch 4: 0.010410231538116932
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.51 seconds!
[tester] 
AGNewsMetric: acc=0.5923684210526315, hinge=3.688237617392289, ce=9.478772904245478
Local test acc @ epoch 90: 0.5924
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.039624378085136414
Local loss @ local epoch 1: 0.0029938307125121355
Local loss @ local epoch 2: 0.004764151759445667
Local loss @ local epoch 3: 0.0041936244815588
Local loss @ local epoch 4: 0.0022520418278872967
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.51 seconds!
[tester] 
AGNewsMetric: acc=0.5751315789473684, hinge=3.3863123617674176, ce=9.328690185546876
Local test acc @ epoch 90: 0.5751
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.010771702975034714
Local loss @ local epoch 1: 0.9954702854156494
Local loss @ local epoch 2: 0.007900423370301723
Local loss @ local epoch 3: 0.0022767232730984688
Local loss @ local epoch 4: 0.016295241191983223
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.3 seconds!
[tester] 
AGNewsMetric: acc=0.8638157894736842, hinge=1.1513983011245728, ce=8.824510694804944
Local test acc @ epoch 90: 0.8638
Global evaluate on test data...
Evaluate data in 123.52 seconds!
[tester] 
AGNewsMetric: acc=0.8302631578947368, hinge=1.5119073709688688, ce=9.710924120451274
Global test acc @ epoch 90: 0.8303
Global epoch 91...
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.19309137761592865
Local loss @ local epoch 1: 0.003830089932307601
Local loss @ local epoch 2: 0.0021973189432173967
Local loss @ local epoch 3: 0.002491388935595751
Local loss @ local epoch 4: 0.0010553511092439294
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.64 seconds!
[tester] 
AGNewsMetric: acc=0.5269736842105263, hinge=4.489823094418174, ce=8.812071255131771
Local test acc @ epoch 91: 0.527
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 2.129135847091675
Local loss @ local epoch 1: 0.1383036971092224
Local loss @ local epoch 2: 0.00013754736573901027
Local loss @ local epoch 3: 3.400164860067889e-05
Local loss @ local epoch 4: 5.909522224101238e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.44 seconds!
[tester] 
AGNewsMetric: acc=0.5171052631578947, hinge=6.636356185611926, ce=10.70477573595549
Local test acc @ epoch 91: 0.5171
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.32083699107170105
Local loss @ local epoch 1: 0.0004260315326973796
Local loss @ local epoch 2: 0.0002040824620053172
Local loss @ local epoch 3: 0.0026262858882546425
Local loss @ local epoch 4: 0.0004113962349947542
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.1 seconds!
[tester] 
AGNewsMetric: acc=0.5178947368421053, hinge=6.242573839990716, ce=12.103597899989078
Local test acc @ epoch 91: 0.5179
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0174937155097723
Local loss @ local epoch 1: 0.0017132195644080639
Local loss @ local epoch 2: 0.00035908169229514897
Local loss @ local epoch 3: 0.00029378454200923443
Local loss @ local epoch 4: 0.0017263829940930009
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.75 seconds!
[tester] 
AGNewsMetric: acc=0.4635526315789474, hinge=5.518951186129922, ce=12.004249865883276
Local test acc @ epoch 91: 0.4636
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0036000211257487535
Local loss @ local epoch 1: 0.0194726400077343
Local loss @ local epoch 2: 0.5347623229026794
Local loss @ local epoch 3: 0.03285059705376625
Local loss @ local epoch 4: 0.03272831812500954
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.01 seconds!
[tester] 
AGNewsMetric: acc=0.8085526315789474, hinge=1.4287914632496082, ce=11.00675906131142
Local test acc @ epoch 91: 0.8086
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 1.4707547426223755
Local loss @ local epoch 1: 0.011709990911185741
Local loss @ local epoch 2: 0.003213258692994714
Local loss @ local epoch 3: 0.19224104285240173
Local loss @ local epoch 4: 0.10283060371875763
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.24 seconds!
[tester] 
AGNewsMetric: acc=0.6619736842105263, hinge=3.5350538329074257, ce=9.861780598289089
Local test acc @ epoch 91: 0.662
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0003795096417888999
Local loss @ local epoch 1: 1.58545244630659e-05
Local loss @ local epoch 2: 0.0014818538911640644
Local loss @ local epoch 3: 0.00027265356038697064
Local loss @ local epoch 4: 0.0008970648632384837
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.57 seconds!
[tester] 
AGNewsMetric: acc=0.6881578947368421, hinge=2.7440759663832814, ce=6.100859065808748
Local test acc @ epoch 91: 0.6882
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 1.0079888105392456
Local loss @ local epoch 1: 0.001162201864644885
Local loss @ local epoch 2: 4.4709955545840785e-05
Local loss @ local epoch 3: 0.003918217029422522
Local loss @ local epoch 4: 0.00038613591459579766
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.95 seconds!
[tester] 
AGNewsMetric: acc=0.520921052631579, hinge=5.236700750652113, ce=12.468233367518375
Local test acc @ epoch 91: 0.5209
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.22360309958457947
Local loss @ local epoch 1: 0.06036769598722458
Local loss @ local epoch 2: 0.00037920428439974785
Local loss @ local epoch 3: 0.0024413929786533117
Local loss @ local epoch 4: 0.002110999310389161
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.82 seconds!
[tester] 
AGNewsMetric: acc=0.48092105263157897, hinge=5.466427484311556, ce=9.3869822602523
Local test acc @ epoch 91: 0.4809
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 1.7642908005655045e-06
Local loss @ local epoch 1: 3.099440561982192e-07
Local loss @ local epoch 2: 7.152556236178498e-08
Local loss @ local epoch 3: 2.384185648907078e-08
Local loss @ local epoch 4: 6.675709300907329e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.98 seconds!
[tester] 
AGNewsMetric: acc=0.4627631578947368, hinge=6.955668042835437, ce=12.025521001313862
Local test acc @ epoch 91: 0.4628
Global evaluate on test data...
Evaluate data in 124.39 seconds!
[tester] 
AGNewsMetric: acc=0.86, hinge=1.340103752738551, ce=9.228246457953203
Global test acc @ epoch 91: 0.86
Global epoch 92...
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.000549725373275578
Local loss @ local epoch 1: 5.299501935951412e-05
Local loss @ local epoch 2: 5.129126293468289e-05
Local loss @ local epoch 3: 6.822380237281322e-05
Local loss @ local epoch 4: 4.2751769797177985e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.97 seconds!
[tester] 
AGNewsMetric: acc=0.45473684210526316, hinge=10.901842593644794, ce=12.784830874392862
Local test acc @ epoch 92: 0.4547
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.001129042124375701
Local loss @ local epoch 1: 8.940637599152979e-06
Local loss @ local epoch 2: 0.0040907361544668674
Local loss @ local epoch 3: 5.420767774921842e-05
Local loss @ local epoch 4: 0.05170905962586403
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.91 seconds!
[tester] 
AGNewsMetric: acc=0.7244736842105263, hinge=3.04797970897273, ce=9.379543151855469
Local test acc @ epoch 92: 0.7245
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.005745891481637955
Local loss @ local epoch 1: 0.12164076417684555
Local loss @ local epoch 2: 0.023003488779067993
Local loss @ local epoch 3: 0.1256531924009323
Local loss @ local epoch 4: 0.007602595258504152
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.86 seconds!
[tester] 
AGNewsMetric: acc=0.7464473684210526, hinge=2.205679747681869, ce=9.49014303910105
Local test acc @ epoch 92: 0.7464
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.00026046179118566215
Local loss @ local epoch 1: 2.0433099052752368e-05
Local loss @ local epoch 2: 0.0003364932781551033
Local loss @ local epoch 3: 0.004181522410362959
Local loss @ local epoch 4: 0.0022297559771686792
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.16 seconds!
[tester] 
AGNewsMetric: acc=0.8315789473684211, hinge=1.5467823249415347, ce=8.711881750006425
Local test acc @ epoch 92: 0.8316
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0005376278422772884
Local loss @ local epoch 1: 3.654764805105515e-05
Local loss @ local epoch 2: 3.576264134608209e-06
Local loss @ local epoch 3: 1.449989213142544e-05
Local loss @ local epoch 4: 2.4469698473694734e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.6 seconds!
[tester] 
AGNewsMetric: acc=0.3386842105263158, hinge=10.656016060678583, ce=13.306028376127545
Local test acc @ epoch 92: 0.3387
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.44223254919052124
Local loss @ local epoch 1: 0.006204732693731785
Local loss @ local epoch 2: 0.08447675406932831
Local loss @ local epoch 3: 0.058021821081638336
Local loss @ local epoch 4: 0.019373638555407524
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.5 seconds!
[tester] 
AGNewsMetric: acc=0.5927631578947369, hinge=3.422961507596468, ce=9.817205519425242
Local test acc @ epoch 92: 0.5928
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.35094907879829407
Local loss @ local epoch 1: 0.005669415462762117
Local loss @ local epoch 2: 0.006473307032138109
Local loss @ local epoch 3: 0.0009357925155200064
Local loss @ local epoch 4: 0.0016061876667663455
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.68 seconds!
[tester] 
AGNewsMetric: acc=0.4130263157894737, hinge=5.904786962207995, ce=8.541333220632453
Local test acc @ epoch 92: 0.413
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.169927716255188
Local loss @ local epoch 1: 0.006655443925410509
Local loss @ local epoch 2: 0.6241535544395447
Local loss @ local epoch 3: 0.23460206389427185
Local loss @ local epoch 4: 0.003469437127932906
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.29 seconds!
[tester] 
AGNewsMetric: acc=0.8239473684210527, hinge=1.7938897961064388, ce=9.598650259720651
Local test acc @ epoch 92: 0.8239
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 1.5258749499480473e-06
Local loss @ local epoch 1: 4.053113684676646e-07
Local loss @ local epoch 2: 2.384185648907078e-08
Local loss @ local epoch 3: 8.106223390313971e-07
Local loss @ local epoch 4: 4.768371297814156e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.29 seconds!
[tester] 
AGNewsMetric: acc=0.6652631578947369, hinge=4.035758912939774, ce=10.339306377611662
Local test acc @ epoch 92: 0.6653
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.12686318159103394
Local loss @ local epoch 1: 0.0009293281473219395
Local loss @ local epoch 2: 0.0012550359824672341
Local loss @ local epoch 3: 0.005382133182138205
Local loss @ local epoch 4: 0.0024075049441307783
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.79 seconds!
[tester] 
AGNewsMetric: acc=0.7844736842105263, hinge=1.5148772653780485, ce=7.738935231660542
Local test acc @ epoch 92: 0.7845
Global evaluate on test data...
Evaluate data in 123.09 seconds!
[tester] 
AGNewsMetric: acc=0.8680263157894736, hinge=1.2398453371148361, ce=9.123496222245066
Global test acc @ epoch 92: 0.868
Global epoch 93...
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.056986432522535324
Local loss @ local epoch 1: 0.001359417918138206
Local loss @ local epoch 2: 0.0008551776991225779
Local loss @ local epoch 3: 0.0012925947085022926
Local loss @ local epoch 4: 0.0005996582913212478
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.38 seconds!
[tester] 
AGNewsMetric: acc=0.5405263157894736, hinge=3.6302086112373755, ce=9.904463579278243
Local test acc @ epoch 93: 0.5405
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.014106817543506622
Local loss @ local epoch 1: 4.619346327672247e-06
Local loss @ local epoch 2: 2.3543314455309883e-05
Local loss @ local epoch 3: 3.2780462788650766e-05
Local loss @ local epoch 4: 0.00043415254913270473
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.77 seconds!
[tester] 
AGNewsMetric: acc=0.6917105263157894, hinge=3.535415826596712, ce=9.846276919716283
Local test acc @ epoch 93: 0.6917
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.028535090386867523
Local loss @ local epoch 1: 2.814185427268967e-05
Local loss @ local epoch 2: 1.1639040167210624e-05
Local loss @ local epoch 3: 9.41966864047572e-05
Local loss @ local epoch 4: 0.00013010174734517932
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.36 seconds!
[tester] 
AGNewsMetric: acc=0.520921052631579, hinge=6.779998936653137, ce=11.590991985923365
Local test acc @ epoch 93: 0.5209
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.19117583334445953
Local loss @ local epoch 1: 0.03637152910232544
Local loss @ local epoch 2: 0.0924377366900444
Local loss @ local epoch 3: 0.0012336275540292263
Local loss @ local epoch 4: 0.07628676295280457
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.11 seconds!
[tester] 
AGNewsMetric: acc=0.76, hinge=2.395384918263084, ce=10.199995309930099
Local test acc @ epoch 93: 0.76
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0018914894899353385
Local loss @ local epoch 1: 5.1266528316773474e-05
Local loss @ local epoch 2: 0.0006684539257548749
Local loss @ local epoch 3: 2.3493683329434134e-05
Local loss @ local epoch 4: 7.379917951766402e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.5 seconds!
[tester] 
AGNewsMetric: acc=0.7676315789473684, hinge=2.2648174612145673, ce=8.317902354190224
Local test acc @ epoch 93: 0.7676
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.10937858372926712
Local loss @ local epoch 1: 0.001473060343414545
Local loss @ local epoch 2: 0.1782088577747345
Local loss @ local epoch 3: 0.0031742393039166927
Local loss @ local epoch 4: 0.0017166725592687726
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.82 seconds!
[tester] 
AGNewsMetric: acc=0.5725, hinge=4.114771312914397, ce=8.045735521818463
Local test acc @ epoch 93: 0.5725
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.010760092176496983
Local loss @ local epoch 1: 0.1874358206987381
Local loss @ local epoch 2: 0.07091470807790756
Local loss @ local epoch 3: 0.0324258878827095
Local loss @ local epoch 4: 0.028238492086529732
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.53 seconds!
[tester] 
AGNewsMetric: acc=0.7239473684210527, hinge=2.059537302820306, ce=5.905095199785735
Local test acc @ epoch 93: 0.7239
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 1.668929883180681e-07
Local loss @ local epoch 1: 9.775150147106615e-07
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.384185648907078e-08
Local loss @ local epoch 4: 5.483622089741402e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.07 seconds!
[tester] 
AGNewsMetric: acc=0.6844736842105263, hinge=4.078867619163112, ce=10.785617681804457
Local test acc @ epoch 93: 0.6845
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.011508879251778126
Local loss @ local epoch 1: 5.22531263413839e-06
Local loss @ local epoch 2: 1.813903327274602e-05
Local loss @ local epoch 3: 0.0005162569577805698
Local loss @ local epoch 4: 0.00029685557819902897
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.3 seconds!
[tester] 
AGNewsMetric: acc=0.43723684210526315, hinge=9.048578376770019, ce=13.513549063833135
Local test acc @ epoch 93: 0.4372
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.23981469869613647
Local loss @ local epoch 1: 0.004065683111548424
Local loss @ local epoch 2: 0.03294913470745087
Local loss @ local epoch 3: 0.001816317904740572
Local loss @ local epoch 4: 0.0006802818970754743
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.73 seconds!
[tester] 
AGNewsMetric: acc=0.3593421052631579, hinge=8.630862548225805, ce=12.440354915418123
Local test acc @ epoch 93: 0.3593
Global evaluate on test data...
Evaluate data in 123.79 seconds!
[tester] 
AGNewsMetric: acc=0.8539473684210527, hinge=1.4382440597132633, ce=9.058351936340332
Global test acc @ epoch 93: 0.8539
Global epoch 94...
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.35809043049812317
Local loss @ local epoch 1: 0.10248006135225296
Local loss @ local epoch 2: 0.003377809887751937
Local loss @ local epoch 3: 0.017264707013964653
Local loss @ local epoch 4: 0.0012931961100548506
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.19 seconds!
[tester] 
AGNewsMetric: acc=0.685921052631579, hinge=2.798127327216299, ce=8.690297678897256
Local test acc @ epoch 94: 0.6859
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.00017104687867686152
Local loss @ local epoch 1: 8.601380250183865e-05
Local loss @ local epoch 2: 1.6529622371308506e-05
Local loss @ local epoch 3: 2.473514359735418e-05
Local loss @ local epoch 4: 0.016722356900572777
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.03 seconds!
[tester] 
AGNewsMetric: acc=0.5042105263157894, hinge=8.046048786263716, ce=12.012152463009484
Local test acc @ epoch 94: 0.5042
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 7.283229933818802e-05
Local loss @ local epoch 1: 1.8298298527952284e-05
Local loss @ local epoch 2: 1.4096282029640861e-05
Local loss @ local epoch 3: 1.1384239769540727e-05
Local loss @ local epoch 4: 1.892399086500518e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.9 seconds!
[tester] 
AGNewsMetric: acc=0.6696052631578947, hinge=3.875955030290704, ce=8.078375489084344
Local test acc @ epoch 94: 0.6696
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.024484211578965187
Local loss @ local epoch 1: 0.03358575701713562
Local loss @ local epoch 2: 0.8058521151542664
Local loss @ local epoch 3: 0.014679056592285633
Local loss @ local epoch 4: 0.044073961675167084
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.22 seconds!
[tester] 
AGNewsMetric: acc=0.7573684210526316, hinge=2.08119909286499, ce=8.399660328312924
Local test acc @ epoch 94: 0.7574
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 9.96046801446937e-05
Local loss @ local epoch 1: 0.0002628423389978707
Local loss @ local epoch 2: 1.5486588381463662e-05
Local loss @ local epoch 3: 7.438367902068421e-05
Local loss @ local epoch 4: 4.068697671755217e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.73 seconds!
[tester] 
AGNewsMetric: acc=0.7356578947368421, hinge=2.4399611568450927, ce=9.601742734407123
Local test acc @ epoch 94: 0.7357
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.03048318810760975
Local loss @ local epoch 1: 0.0012914204271510243
Local loss @ local epoch 2: 0.00010116223711520433
Local loss @ local epoch 3: 0.0004493468441069126
Local loss @ local epoch 4: 0.0008897997322492301
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.0 seconds!
[tester] 
AGNewsMetric: acc=0.5960526315789474, hinge=3.063010563599436, ce=8.29677729154888
Local test acc @ epoch 94: 0.5961
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 1.1920927533992653e-07
Local loss @ local epoch 1: 4.768371297814156e-08
Local loss @ local epoch 2: 4.768370942542788e-08
Local loss @ local epoch 3: 1.1920927533992653e-07
Local loss @ local epoch 4: 1.621181218069978e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.12 seconds!
[tester] 
AGNewsMetric: acc=0.7551315789473684, hinge=2.82771729820653, ce=10.733869050678454
Local test acc @ epoch 94: 0.7551
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.32436469197273254
Local loss @ local epoch 1: 0.0001343795593129471
Local loss @ local epoch 2: 0.0002899857936426997
Local loss @ local epoch 3: 0.0005016750656068325
Local loss @ local epoch 4: 0.0003624105593189597
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.43 seconds!
[tester] 
AGNewsMetric: acc=0.3501315789473684, hinge=8.199653689735815, ce=11.243227430644788
Local test acc @ epoch 94: 0.3501
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0012050054501742125
Local loss @ local epoch 1: 1.2668324416154064e-05
Local loss @ local epoch 2: 0.00016464093641843647
Local loss @ local epoch 3: 8.723890459805261e-06
Local loss @ local epoch 4: 5.2560208132490516e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.17 seconds!
[tester] 
AGNewsMetric: acc=0.4263157894736842, hinge=10.018654249090897, ce=13.88944873207494
Local test acc @ epoch 94: 0.4263
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.04944795370101929
Local loss @ local epoch 1: 0.0015081905294209719
Local loss @ local epoch 2: 0.015504566952586174
Local loss @ local epoch 3: 0.0004151972243562341
Local loss @ local epoch 4: 0.001527033164165914
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 122.74 seconds!
[tester] 
AGNewsMetric: acc=0.5830263157894737, hinge=5.435370066793341, ce=10.552556714509663
Local test acc @ epoch 94: 0.583
Global evaluate on test data...
Evaluate data in 123.53 seconds!
[tester] 
AGNewsMetric: acc=0.8523684210526316, hinge=1.427348844879552, ce=8.92812624881142
Global test acc @ epoch 94: 0.8524
Global epoch 95...
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.19710363447666168
Local loss @ local epoch 1: 0.0048562875017523766
Local loss @ local epoch 2: 0.5398457050323486
Local loss @ local epoch 3: 0.1880750060081482
Local loss @ local epoch 4: 0.01388520561158657
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.2 seconds!
[tester] 
AGNewsMetric: acc=0.7739473684210526, hinge=2.0951954911884507, ce=8.076264495849609
Local test acc @ epoch 95: 0.7739
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.04763740673661232
Local loss @ local epoch 1: 2.75861984846415e-05
Local loss @ local epoch 2: 1.2665633221331518e-05
Local loss @ local epoch 3: 8.384294233110268e-06
Local loss @ local epoch 4: 1.4066411495150533e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.14 seconds!
[tester] 
AGNewsMetric: acc=0.4867105263157895, hinge=7.620658749028256, ce=10.758225979052092
Local test acc @ epoch 95: 0.4867
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.009374497458338737
Local loss @ local epoch 1: 0.21037055552005768
Local loss @ local epoch 2: 0.2215915024280548
Local loss @ local epoch 3: 0.007426480296999216
Local loss @ local epoch 4: 0.09632231295108795
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.39 seconds!
[tester] 
AGNewsMetric: acc=0.720657894736842, hinge=2.1172698999706068, ce=10.060655206379138
Local test acc @ epoch 95: 0.7207
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.003979604225605726
Local loss @ local epoch 1: 0.012470570392906666
Local loss @ local epoch 2: 0.010447447188198566
Local loss @ local epoch 3: 0.029879802837967873
Local loss @ local epoch 4: 0.0028706127777695656
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.29 seconds!
[tester] 
AGNewsMetric: acc=0.5497368421052632, hinge=3.122360334396362, ce=10.540506431178043
Local test acc @ epoch 95: 0.5497
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.05772324651479721
Local loss @ local epoch 1: 0.00044373460696078837
Local loss @ local epoch 2: 0.0014974023215472698
Local loss @ local epoch 3: 0.0007204051944427192
Local loss @ local epoch 4: 0.03734467551112175
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.33 seconds!
[tester] 
AGNewsMetric: acc=0.39302631578947367, hinge=8.622747410222104, ce=12.852310658505088
Local test acc @ epoch 95: 0.393
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.002292389515787363
Local loss @ local epoch 1: 0.0002449425228405744
Local loss @ local epoch 2: 1.9722820070455782e-05
Local loss @ local epoch 3: 1.368718221783638e-05
Local loss @ local epoch 4: 3.4350417990935966e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.98 seconds!
[tester] 
AGNewsMetric: acc=0.6627631578947368, hinge=3.8297582586188064, ce=10.328381213137979
Local test acc @ epoch 95: 0.6628
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 3.5731514799408615e-05
Local loss @ local epoch 1: 4.380921836855123e-06
Local loss @ local epoch 2: 9.655849680711981e-06
Local loss @ local epoch 3: 8.987056207843125e-05
Local loss @ local epoch 4: 0.003712615929543972
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.17 seconds!
[tester] 
AGNewsMetric: acc=0.6852631578947368, hinge=4.976546908679762, ce=10.084931867499101
Local test acc @ epoch 95: 0.6853
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.077393539249897
Local loss @ local epoch 1: 0.003290387336164713
Local loss @ local epoch 2: 0.0009791561169549823
Local loss @ local epoch 3: 0.003294367343187332
Local loss @ local epoch 4: 0.32167744636535645
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.62 seconds!
[tester] 
AGNewsMetric: acc=0.5064473684210526, hinge=6.852149403722662, ce=11.601858747381913
Local test acc @ epoch 95: 0.5064
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0024900545831769705
Local loss @ local epoch 1: 0.00041784043423831463
Local loss @ local epoch 2: 2.1595185899059288e-05
Local loss @ local epoch 3: 0.006289795506745577
Local loss @ local epoch 4: 7.63421630836092e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.94 seconds!
[tester] 
AGNewsMetric: acc=0.7344736842105263, hinge=2.9894915600826866, ce=8.48433797735917
Local test acc @ epoch 95: 0.7345
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 1.454349103369168e-06
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.1920926823449918e-07
Local loss @ local epoch 3: 9.536742595628311e-08
Local loss @ local epoch 4: 4.05311396889374e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.54 seconds!
[tester] 
AGNewsMetric: acc=0.8182894736842106, hinge=2.0130694971586527, ce=7.989748629519814
Local test acc @ epoch 95: 0.8183
Global evaluate on test data...
Evaluate data in 123.9 seconds!
[tester] 
AGNewsMetric: acc=0.8298684210526316, hinge=1.694392624403301, ce=8.803693801478335
Global test acc @ epoch 95: 0.8299
Global epoch 96...
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0014850336592644453
Local loss @ local epoch 1: 0.0008394187316298485
Local loss @ local epoch 2: 0.01710764318704605
Local loss @ local epoch 3: 0.00047067171544767916
Local loss @ local epoch 4: 0.0011170185171067715
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.66 seconds!
[tester] 
AGNewsMetric: acc=0.8621052631578947, hinge=1.3288274145126342, ce=8.972758518018221
Local test acc @ epoch 96: 0.8621
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 3.4102442441508174e-05
Local loss @ local epoch 1: 3.0196622901712544e-05
Local loss @ local epoch 2: 3.685885894810781e-05
Local loss @ local epoch 3: 1.371863345411839e-05
Local loss @ local epoch 4: 0.0003104109491687268
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.98 seconds!
[tester] 
AGNewsMetric: acc=0.7202631578947368, hinge=3.416844731130098, ce=10.69406974993254
Local test acc @ epoch 96: 0.7203
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.7232171297073364
Local loss @ local epoch 1: 0.1349654346704483
Local loss @ local epoch 2: 0.006113525480031967
Local loss @ local epoch 3: 0.0004868292307946831
Local loss @ local epoch 4: 0.00038183608558028936
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.88 seconds!
[tester] 
AGNewsMetric: acc=0.44157894736842107, hinge=6.027839001103452, ce=11.426419794183028
Local test acc @ epoch 96: 0.4416
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 4.148459538555471e-06
Local loss @ local epoch 1: 1.4305109630186053e-07
Local loss @ local epoch 2: 3.5762758443524945e-07
Local loss @ local epoch 3: 3.07557593259844e-06
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.8 seconds!
[tester] 
AGNewsMetric: acc=0.5010526315789474, hinge=7.51544872986643, ce=13.864917530260588
Local test acc @ epoch 96: 0.5011
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.05402069166302681
Local loss @ local epoch 1: 0.014986642636358738
Local loss @ local epoch 2: 0.09960587322711945
Local loss @ local epoch 3: 0.005072926636785269
Local loss @ local epoch 4: 0.03391581028699875
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.88 seconds!
[tester] 
AGNewsMetric: acc=0.7882894736842105, hinge=1.610705939594068, ce=9.674396123384174
Local test acc @ epoch 96: 0.7883
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.00026933790650218725
Local loss @ local epoch 1: 0.005150779616087675
Local loss @ local epoch 2: 9.442940063308924e-05
Local loss @ local epoch 3: 2.550998397055082e-05
Local loss @ local epoch 4: 4.982699465472251e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.22 seconds!
[tester] 
AGNewsMetric: acc=0.7539473684210526, hinge=2.219619622481497, ce=9.383153447602924
Local test acc @ epoch 96: 0.7539
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 4.1515679185977206e-05
Local loss @ local epoch 1: 3.4895658700406784e-06
Local loss @ local epoch 2: 3.853035013889894e-05
Local loss @ local epoch 3: 1.4521833691105712e-06
Local loss @ local epoch 4: 1.2246032383700367e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.66 seconds!
[tester] 
AGNewsMetric: acc=0.35092105263157897, hinge=15.911754688463713, ce=14.53427019420423
Local test acc @ epoch 96: 0.3509
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.08719424158334732
Local loss @ local epoch 1: 0.0003248769498895854
Local loss @ local epoch 2: 0.0016834106063470244
Local loss @ local epoch 3: 0.00039935868699103594
Local loss @ local epoch 4: 0.0003906258207280189
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.01 seconds!
[tester] 
AGNewsMetric: acc=0.46171052631578946, hinge=6.337557347950183, ce=10.832618751525878
Local test acc @ epoch 96: 0.4617
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0211790818721056
Local loss @ local epoch 1: 0.060711007565259933
Local loss @ local epoch 2: 0.00037318342947401106
Local loss @ local epoch 3: 0.003133716294541955
Local loss @ local epoch 4: 0.006552864331752062
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.6 seconds!
[tester] 
AGNewsMetric: acc=0.5298684210526315, hinge=3.7601662199120773, ce=11.421361724451968
Local test acc @ epoch 96: 0.5299
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0010977914789691567
Local loss @ local epoch 1: 2.3652120944461785e-05
Local loss @ local epoch 2: 0.0003615653549786657
Local loss @ local epoch 3: 0.00012574094580486417
Local loss @ local epoch 4: 9.169670374831185e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.57 seconds!
[tester] 
AGNewsMetric: acc=0.44355263157894737, hinge=13.256719020040412, ce=12.712924182289525
Local test acc @ epoch 96: 0.4436
Global evaluate on test data...
Evaluate data in 124.03 seconds!
[tester] 
AGNewsMetric: acc=0.8671052631578947, hinge=1.36907226888757, ce=9.282775270562423
Global test acc @ epoch 96: 0.8671
Global epoch 97...
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0016648323507979512
Local loss @ local epoch 1: 1.697611151030287e-05
Local loss @ local epoch 2: 1.571532447997015e-05
Local loss @ local epoch 3: 1.7165699318866245e-05
Local loss @ local epoch 4: 2.4457176550640725e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.64 seconds!
[tester] 
AGNewsMetric: acc=0.4086842105263158, hinge=11.43973387366847, ce=12.913372140181693
Local test acc @ epoch 97: 0.4087
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.49080362915992737
Local loss @ local epoch 1: 0.0019824092742055655
Local loss @ local epoch 2: 0.0020444486290216446
Local loss @ local epoch 3: 0.0014528458705171943
Local loss @ local epoch 4: 0.019708728417754173
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.72 seconds!
[tester] 
AGNewsMetric: acc=0.5921052631578947, hinge=4.126019023594103, ce=8.892789603785465
Local test acc @ epoch 97: 0.5921
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.6353969573974609
Local loss @ local epoch 1: 0.0034847878850996494
Local loss @ local epoch 2: 0.0016248575411736965
Local loss @ local epoch 3: 0.0010593500919640064
Local loss @ local epoch 4: 0.0017972966888919473
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.5 seconds!
[tester] 
AGNewsMetric: acc=0.5380263157894737, hinge=6.406482218692177, ce=12.075679148623818
Local test acc @ epoch 97: 0.538
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0006418937118723989
Local loss @ local epoch 1: 3.476615893305279e-05
Local loss @ local epoch 2: 1.81790364877088e-05
Local loss @ local epoch 3: 5.164964750292711e-05
Local loss @ local epoch 4: 0.0018112940015271306
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.82 seconds!
[tester] 
AGNewsMetric: acc=0.6668421052631579, hinge=4.150397356685839, ce=11.216915439806487
Local test acc @ epoch 97: 0.6668
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.1485971212387085
Local loss @ local epoch 1: 0.6829690337181091
Local loss @ local epoch 2: 0.00860282126814127
Local loss @ local epoch 3: 0.013432934880256653
Local loss @ local epoch 4: 0.05559767037630081
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.57 seconds!
[tester] 
AGNewsMetric: acc=0.8111842105263158, hinge=1.253220627935309, ce=4.91722311220671
Local test acc @ epoch 97: 0.8112
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.004718836862593889
Local loss @ local epoch 1: 2.5444944185437635e-05
Local loss @ local epoch 2: 6.4047303567349445e-06
Local loss @ local epoch 3: 3.100326284766197e-05
Local loss @ local epoch 4: 1.9224426068831235e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.02 seconds!
[tester] 
AGNewsMetric: acc=0.40157894736842104, hinge=10.176068969023856, ce=13.479320477937398
Local test acc @ epoch 97: 0.4016
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0008955132216215134
Local loss @ local epoch 1: 0.0006686615524813533
Local loss @ local epoch 2: 2.241089168819599e-05
Local loss @ local epoch 3: 8.61156004248187e-05
Local loss @ local epoch 4: 7.897522664279677e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.34 seconds!
[tester] 
AGNewsMetric: acc=0.6714473684210527, hinge=3.308651463358026, ce=9.418580685665733
Local test acc @ epoch 97: 0.6714
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.10632998496294022
Local loss @ local epoch 1: 0.0012271878076717257
Local loss @ local epoch 2: 0.02001664787530899
Local loss @ local epoch 3: 0.23591646552085876
Local loss @ local epoch 4: 0.006489929743111134
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.67 seconds!
[tester] 
AGNewsMetric: acc=0.7857894736842105, hinge=2.4604544639587402, ce=10.323363535027754
Local test acc @ epoch 97: 0.7858
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0007467925897799432
Local loss @ local epoch 1: 4.8277888708980754e-05
Local loss @ local epoch 2: 0.00019840092863887548
Local loss @ local epoch 3: 0.00010541375377215445
Local loss @ local epoch 4: 4.8833888286026195e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.58 seconds!
[tester] 
AGNewsMetric: acc=0.5460526315789473, hinge=6.056949671695107, ce=12.618835529528166
Local test acc @ epoch 97: 0.5461
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 4.2915317521874385e-07
Local loss @ local epoch 1: 1.907348377017115e-07
Local loss @ local epoch 2: 9.536724974168465e-07
Local loss @ local epoch 3: 9.536741885085576e-08
Local loss @ local epoch 4: 5.722043283640232e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.39 seconds!
[tester] 
AGNewsMetric: acc=0.7472368421052632, hinge=2.8466322888826068, ce=11.213305037649054
Local test acc @ epoch 97: 0.7472
Global evaluate on test data...
Evaluate data in 124.46 seconds!
[tester] 
AGNewsMetric: acc=0.8451315789473685, hinge=1.6758622578570717, ce=9.242045149552196
Global test acc @ epoch 97: 0.8451
Global epoch 98...
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 2.2647733203484677e-05
Local loss @ local epoch 1: 8.89086277311435e-06
Local loss @ local epoch 2: 8.960422746895347e-06
Local loss @ local epoch 3: 0.014480176381766796
Local loss @ local epoch 4: 4.132610047236085e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.36 seconds!
[tester] 
AGNewsMetric: acc=0.8278947368421052, hinge=2.040839777243765, ce=8.962701524433337
Local test acc @ epoch 98: 0.8279
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.6371145248413086
Local loss @ local epoch 1: 0.0006542623159475625
Local loss @ local epoch 2: 0.00010855037544388324
Local loss @ local epoch 3: 0.498962938785553
Local loss @ local epoch 4: 0.0010260659037157893
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.45 seconds!
[tester] 
AGNewsMetric: acc=0.5726315789473684, hinge=5.644973520981638, ce=10.914846436349968
Local test acc @ epoch 98: 0.5726
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 2.5331215510959737e-05
Local loss @ local epoch 1: 1.14736403702409e-05
Local loss @ local epoch 2: 6.570161349372938e-05
Local loss @ local epoch 3: 9.655839676270261e-06
Local loss @ local epoch 4: 1.32022114485153e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.73 seconds!
[tester] 
AGNewsMetric: acc=0.4714473684210526, hinge=12.338746008872986, ce=12.346041713513825
Local test acc @ epoch 98: 0.4714
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.09640010446310043
Local loss @ local epoch 1: 0.0005470190080814064
Local loss @ local epoch 2: 0.0011521816486492753
Local loss @ local epoch 3: 0.0013917722972109914
Local loss @ local epoch 4: 0.02405974455177784
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.26 seconds!
[tester] 
AGNewsMetric: acc=0.7475, hinge=1.9309960852171246, ce=5.544776631405479
Local test acc @ epoch 98: 0.7475
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 1.5258762005032622e-06
Local loss @ local epoch 1: 2.3126494852476753e-06
Local loss @ local epoch 2: 2.384185648907078e-08
Local loss @ local epoch 3: 1.1920927533992653e-07
Local loss @ local epoch 4: 1.6689297410721338e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.61 seconds!
[tester] 
AGNewsMetric: acc=0.43526315789473685, hinge=9.22455491316946, ce=14.611575646651419
Local test acc @ epoch 98: 0.4353
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 3.026687045348808e-05
Local loss @ local epoch 1: 2.080735612253193e-06
Local loss @ local epoch 2: 2.7201174361835e-06
Local loss @ local epoch 3: 9.319983860223147e-07
Local loss @ local epoch 4: 1.517206783319125e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.78 seconds!
[tester] 
AGNewsMetric: acc=0.3873684210526316, hinge=15.651774781879626, ce=14.969187796743293
Local test acc @ epoch 98: 0.3874
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.002723396522924304
Local loss @ local epoch 1: 0.0046430653892457485
Local loss @ local epoch 2: 0.005962257739156485
Local loss @ local epoch 3: 0.264149010181427
Local loss @ local epoch 4: 0.03483539819717407
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.56 seconds!
[tester] 
AGNewsMetric: acc=0.7094736842105264, hinge=2.816509458140323, ce=11.399340904637388
Local test acc @ epoch 98: 0.7095
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 6.749619205947965e-05
Local loss @ local epoch 1: 1.0043266229331493e-05
Local loss @ local epoch 2: 4.624909706762992e-05
Local loss @ local epoch 3: 1.391532063484192
Local loss @ local epoch 4: 0.0016802723985165358
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.96 seconds!
[tester] 
AGNewsMetric: acc=0.6194736842105263, hinge=4.4906780069752745, ce=9.135558292991236
Local test acc @ epoch 98: 0.6195
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0040182191878557205
Local loss @ local epoch 1: 0.00010762121382867917
Local loss @ local epoch 2: 0.05954796075820923
Local loss @ local epoch 3: 0.0010687949834391475
Local loss @ local epoch 4: 0.0002446790167596191
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.19 seconds!
[tester] 
AGNewsMetric: acc=0.8521052631578947, hinge=1.5863275949578537, ce=9.06630909166838
Local test acc @ epoch 98: 0.8521
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.1087338924407959
Local loss @ local epoch 1: 0.0003153107827529311
Local loss @ local epoch 2: 0.00024288325221277773
Local loss @ local epoch 3: 0.0001175154757220298
Local loss @ local epoch 4: 0.00016099809727165848
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.9 seconds!
[tester] 
AGNewsMetric: acc=0.42118421052631577, hinge=8.315192588003057, ce=12.697057677821109
Local test acc @ epoch 98: 0.4212
Global evaluate on test data...
Evaluate data in 123.93 seconds!
[tester] 
AGNewsMetric: acc=0.8492105263157895, hinge=1.6108844772138093, ce=8.995470215646844
Global test acc @ epoch 98: 0.8492
Global epoch 99...
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.023982666432857513
Local loss @ local epoch 1: 2.3645301553187892e-05
Local loss @ local epoch 2: 3.294493353678263e-06
Local loss @ local epoch 3: 1.7989732441492379e-06
Local loss @ local epoch 4: 5.5594236982869916e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.45 seconds!
[tester] 
AGNewsMetric: acc=0.3840789473684211, hinge=12.373364583065635, ce=13.513321826332493
Local test acc @ epoch 99: 0.3841
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.007837609387934208
Local loss @ local epoch 1: 3.881571683450602e-05
Local loss @ local epoch 2: 0.03422192856669426
Local loss @ local epoch 3: 4.146954233874567e-05
Local loss @ local epoch 4: 9.754391066962853e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.59 seconds!
[tester] 
AGNewsMetric: acc=0.8423684210526315, hinge=1.7259128322099384, ce=9.5925000963713
Local test acc @ epoch 99: 0.8424
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.00012105923815397546
Local loss @ local epoch 1: 2.0563556972774677e-06
Local loss @ local epoch 2: 7.649159670108929e-05
Local loss @ local epoch 3: 1.9847679141093977e-05
Local loss @ local epoch 4: 6.765096259186976e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.94 seconds!
[tester] 
AGNewsMetric: acc=0.6573684210526316, hinge=3.5767252161628322, ce=9.569408922697368
Local test acc @ epoch 99: 0.6574
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.918935239315033
Local loss @ local epoch 1: 0.0006372900097630918
Local loss @ local epoch 2: 0.07246538996696472
Local loss @ local epoch 3: 0.5224899649620056
Local loss @ local epoch 4: 0.025317151099443436
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.7 seconds!
[tester] 
AGNewsMetric: acc=0.6925, hinge=3.737699506659257, ce=10.050056140297338
Local test acc @ epoch 99: 0.6925
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.03410244733095169
Local loss @ local epoch 1: 4.132543836021796e-06
Local loss @ local epoch 2: 4.340177110861987e-05
Local loss @ local epoch 3: 0.000160953524755314
Local loss @ local epoch 4: 0.0022351851221174
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.4 seconds!
[tester] 
AGNewsMetric: acc=0.4139473684210526, hinge=10.90371164522673, ce=12.687520193802683
Local test acc @ epoch 99: 0.4139
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 9.536741885085576e-08
Local loss @ local epoch 1: 2.1457660182022664e-07
Local loss @ local epoch 2: 1.9073476664743794e-07
Local loss @ local epoch 3: 1.4305111051271524e-07
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.89 seconds!
[tester] 
AGNewsMetric: acc=0.7626315789473684, hinge=2.5493212908192686, ce=10.55830643704063
Local test acc @ epoch 99: 0.7626
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.016756847500801086
Local loss @ local epoch 1: 0.0064660534262657166
Local loss @ local epoch 2: 0.048634033650159836
Local loss @ local epoch 3: 0.02068839780986309
Local loss @ local epoch 4: 0.013220005668699741
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.47 seconds!
[tester] 
AGNewsMetric: acc=0.71, hinge=2.5039162103753343, ce=9.869260290045487
Local test acc @ epoch 99: 0.71
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.16498662531375885
Local loss @ local epoch 1: 0.008580192923545837
Local loss @ local epoch 2: 0.0004539955116342753
Local loss @ local epoch 3: 0.4216250479221344
Local loss @ local epoch 4: 0.001378496759571135
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.12 seconds!
[tester] 
AGNewsMetric: acc=0.6364473684210527, hinge=2.97317440685473, ce=9.063590768512926
Local test acc @ epoch 99: 0.6364
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.002902888460084796
Local loss @ local epoch 1: 0.0021588506642729044
Local loss @ local epoch 2: 0.0002804874675348401
Local loss @ local epoch 3: 0.5751157999038696
Local loss @ local epoch 4: 0.0005385459517128766
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.68 seconds!
[tester] 
AGNewsMetric: acc=0.5455263157894736, hinge=3.5175775307103208, ce=11.393221861186781
Local test acc @ epoch 99: 0.5455
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.3655622601509094
Local loss @ local epoch 1: 0.07864943146705627
Local loss @ local epoch 2: 0.006171192973852158
Local loss @ local epoch 3: 0.0009838892146945
Local loss @ local epoch 4: 0.000401647062972188
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.05 seconds!
[tester] 
AGNewsMetric: acc=0.4342105263157895, hinge=8.390675305818256, ce=12.32169376774838
Local test acc @ epoch 99: 0.4342
Global evaluate on test data...
Evaluate data in 123.98 seconds!
[tester] 
AGNewsMetric: acc=0.854078947368421, hinge=1.6466453145679674, ce=8.668385826913934
Global test acc @ epoch 99: 0.8541
Global epoch 100...
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 1.186951994895935
Local loss @ local epoch 1: 0.007955954410135746
Local loss @ local epoch 2: 0.004430075641721487
Local loss @ local epoch 3: 0.04256211221218109
Local loss @ local epoch 4: 0.00016238787793554366
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.97 seconds!
[tester] 
AGNewsMetric: acc=0.5765789473684211, hinge=4.066055631637573, ce=9.100484344080876
Local test acc @ epoch 100: 0.5766
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0008326417300850153
Local loss @ local epoch 1: 5.830374448123621e-06
Local loss @ local epoch 2: 1.5767807781230658e-05
Local loss @ local epoch 3: 2.4827169909258373e-05
Local loss @ local epoch 4: 0.00022709737822879106
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.14 seconds!
[tester] 
AGNewsMetric: acc=0.3485526315789474, hinge=12.62722793378328, ce=14.02683585919832
Local test acc @ epoch 100: 0.3486
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.02741735242307186
Local loss @ local epoch 1: 0.00087279750732705
Local loss @ local epoch 2: 0.0004515617329161614
Local loss @ local epoch 3: 0.009227409027516842
Local loss @ local epoch 4: 0.0011692242696881294
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.57 seconds!
[tester] 
AGNewsMetric: acc=0.5967105263157895, hinge=2.800853041598671, ce=10.760493776421798
Local test acc @ epoch 100: 0.5967
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 1.9300090571050532e-05
Local loss @ local epoch 1: 7.22190588930971e-06
Local loss @ local epoch 2: 2.8014080726279644e-06
Local loss @ local epoch 3: 1.8278720972375595e-06
Local loss @ local epoch 4: 1.9916649762308225e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.08 seconds!
[tester] 
AGNewsMetric: acc=0.46539473684210525, hinge=11.356462888717651, ce=11.736108510870682
Local test acc @ epoch 100: 0.4654
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 1.823841557779815e-05
Local loss @ local epoch 1: 0.00021729747822973877
Local loss @ local epoch 2: 7.152501893870067e-06
Local loss @ local epoch 3: 0.0001540317462058738
Local loss @ local epoch 4: 1.3321490769158117e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.23 seconds!
[tester] 
AGNewsMetric: acc=0.714078947368421, hinge=2.3794961854031214, ce=6.41922282068353
Local test acc @ epoch 100: 0.7141
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.5657305717468262
Local loss @ local epoch 1: 0.015153233893215656
Local loss @ local epoch 2: 0.00015815954247955233
Local loss @ local epoch 3: 0.00013536987535189837
Local loss @ local epoch 4: 0.00040911382529884577
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 125.4 seconds!
[tester] 
AGNewsMetric: acc=0.4996052631578947, hinge=5.474863259164911, ce=10.167229172556024
Local test acc @ epoch 100: 0.4996
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.30933862924575806
Local loss @ local epoch 1: 0.8367354273796082
Local loss @ local epoch 2: 1.0210260152816772
Local loss @ local epoch 3: 0.08914292603731155
Local loss @ local epoch 4: 0.13292236626148224
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.75 seconds!
[tester] 
AGNewsMetric: acc=0.6117105263157895, hinge=3.244031255621659, ce=11.63651090722335
Local test acc @ epoch 100: 0.6117
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 2.8610219260372105e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.384185648907078e-08
Local loss @ local epoch 3: 2.384185648907078e-08
Local loss @ local epoch 4: 2.384185648907078e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.58 seconds!
[tester] 
AGNewsMetric: acc=0.6236842105263158, hinge=5.225072091504147, ce=10.381301709225303
Local test acc @ epoch 100: 0.6237
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0001357165165245533
Local loss @ local epoch 1: 1.195024378830567e-05
Local loss @ local epoch 2: 7.014661241555586e-05
Local loss @ local epoch 3: 0.0006905861664563417
Local loss @ local epoch 4: 2.1060252493043663e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.86 seconds!
[tester] 
AGNewsMetric: acc=0.7835526315789474, hinge=2.5993204156975995, ce=8.1809299007215
Local test acc @ epoch 100: 0.7836
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.00033075103419832885
Local loss @ local epoch 1: 0.007135242689400911
Local loss @ local epoch 2: 0.0002611784148029983
Local loss @ local epoch 3: 0.007368347141891718
Local loss @ local epoch 4: 0.0006955149583518505
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.57 seconds!
[tester] 
AGNewsMetric: acc=0.8175, hinge=2.1241140937805176, ce=9.012985633047004
Local test acc @ epoch 100: 0.8175
Global evaluate on test data...
Evaluate data in 123.42 seconds!
[tester] 
AGNewsMetric: acc=0.8371052631578947, hinge=1.6790961998387386, ce=8.648569203426963
Global test acc @ epoch 100: 0.8371
Global epoch 101...
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0360458642244339
Local loss @ local epoch 1: 0.0017364569939672947
Local loss @ local epoch 2: 0.009005516767501831
Local loss @ local epoch 3: 0.20506615936756134
Local loss @ local epoch 4: 0.0038416744209825993
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.4 seconds!
[tester] 
AGNewsMetric: acc=0.7256578947368421, hinge=3.1608474892064145, ce=8.981298490825452
Local test acc @ epoch 101: 0.7257
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 4.9082478653872386e-05
Local loss @ local epoch 1: 0.00036272150464355946
Local loss @ local epoch 2: 1.0490334716450889e-05
Local loss @ local epoch 3: 1.3917331671109423e-05
Local loss @ local epoch 4: 1.6093230215119547e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.71 seconds!
[tester] 
AGNewsMetric: acc=0.7117105263157895, hinge=3.5001092599567616, ce=11.11843371341103
Local test acc @ epoch 101: 0.7117
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.017534418031573296
Local loss @ local epoch 1: 9.970223118216381e-07
Local loss @ local epoch 2: 1.2137651310695219e-06
Local loss @ local epoch 3: 2.210785396528081e-06
Local loss @ local epoch 4: 8.68052666191943e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.46 seconds!
[tester] 
AGNewsMetric: acc=0.4163157894736842, hinge=10.170927096417076, ce=13.929276795638234
Local test acc @ epoch 101: 0.4163
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.008290719240903854
Local loss @ local epoch 1: 0.005133811384439468
Local loss @ local epoch 2: 9.664638491813093e-05
Local loss @ local epoch 3: 0.00015753073967061937
Local loss @ local epoch 4: 0.0021452719811350107
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.35 seconds!
[tester] 
AGNewsMetric: acc=0.4831578947368421, hinge=7.4693928618180125, ce=11.112649518063193
Local test acc @ epoch 101: 0.4832
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.00859911646693945
Local loss @ local epoch 1: 1.2377717212075368e-05
Local loss @ local epoch 2: 1.0887602002185304e-05
Local loss @ local epoch 3: 0.000565702619496733
Local loss @ local epoch 4: 0.00028167609707452357
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.45 seconds!
[tester] 
AGNewsMetric: acc=0.43605263157894736, hinge=11.523364763259888, ce=12.27954388066342
Local test acc @ epoch 101: 0.4361
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.003499300917610526
Local loss @ local epoch 1: 0.00017058197408914566
Local loss @ local epoch 2: 0.001420046086423099
Local loss @ local epoch 3: 3.2159303373191506e-05
Local loss @ local epoch 4: 6.576790474355221e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.03 seconds!
[tester] 
AGNewsMetric: acc=0.5236842105263158, hinge=8.114430759831478, ce=12.218549103987844
Local test acc @ epoch 101: 0.5237
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.007116321939975023
Local loss @ local epoch 1: 0.0006331725162453949
Local loss @ local epoch 2: 0.008018025197088718
Local loss @ local epoch 3: 0.03468212112784386
Local loss @ local epoch 4: 0.0003995531005784869
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.85 seconds!
[tester] 
AGNewsMetric: acc=0.5782894736842106, hinge=4.118650795786004, ce=11.228152419642399
Local test acc @ epoch 101: 0.5783
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 7.152556946721234e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.384185648907078e-08
Local loss @ local epoch 3: 7.629379865647934e-07
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.64 seconds!
[tester] 
AGNewsMetric: acc=0.5818421052631579, hinge=4.979957904815674, ce=11.366275468123586
Local test acc @ epoch 101: 0.5818
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 4.078214624314569e-05
Local loss @ local epoch 1: 3.268306272730115e-06
Local loss @ local epoch 2: 6.841508002253249e-05
Local loss @ local epoch 3: 2.5250716134905815e-05
Local loss @ local epoch 4: 4.922352309222333e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.75 seconds!
[tester] 
AGNewsMetric: acc=0.8005263157894736, hinge=2.3591619268216584, ce=9.54354616265548
Local test acc @ epoch 101: 0.8005
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.11005467921495438
Local loss @ local epoch 1: 0.16495774686336517
Local loss @ local epoch 2: 0.006070335395634174
Local loss @ local epoch 3: 0.014767616987228394
Local loss @ local epoch 4: 0.04942828789353371
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.44 seconds!
[tester] 
AGNewsMetric: acc=0.8010526315789473, hinge=1.6375244110508969, ce=8.358177620737177
Local test acc @ epoch 101: 0.8011
Global evaluate on test data...
Evaluate data in 123.91 seconds!
[tester] 
AGNewsMetric: acc=0.8647368421052631, hinge=1.5078802291970503, ce=8.913049232081363
Global test acc @ epoch 101: 0.8647
Global epoch 102...
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.00022781272127758712
Local loss @ local epoch 1: 2.3660386432311498e-05
Local loss @ local epoch 2: 1.2943779438501224e-05
Local loss @ local epoch 3: 3.557050149538554e-05
Local loss @ local epoch 4: 5.4553584050154313e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.78 seconds!
[tester] 
AGNewsMetric: acc=0.5692105263157895, hinge=6.31023180459675, ce=11.863269908302708
Local test acc @ epoch 102: 0.5692
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.00017953325004782528
Local loss @ local epoch 1: 3.5003888569917763e-06
Local loss @ local epoch 2: 2.1824023860972375e-05
Local loss @ local epoch 3: 4.62744810647564e-06
Local loss @ local epoch 4: 2.1566004306805553e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.13 seconds!
[tester] 
AGNewsMetric: acc=0.4760526315789474, hinge=10.013399543009307, ce=12.891476004751105
Local test acc @ epoch 102: 0.4761
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.0391913652420044
Local loss @ local epoch 1: 0.024576228111982346
Local loss @ local epoch 2: 0.01712540164589882
Local loss @ local epoch 3: 0.06529751420021057
Local loss @ local epoch 4: 0.0011053356574848294
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.4 seconds!
[tester] 
AGNewsMetric: acc=0.585, hinge=3.860038281490928, ce=10.513608330174497
Local test acc @ epoch 102: 0.585
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.009819930419325829
Local loss @ local epoch 1: 0.00024011284403968602
Local loss @ local epoch 2: 0.0007442634669132531
Local loss @ local epoch 3: 1.6495739221572876
Local loss @ local epoch 4: 0.0026247045025229454
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 125.02 seconds!
[tester] 
AGNewsMetric: acc=0.8113157894736842, hinge=1.8438053595392327, ce=8.376013115330746
Local test acc @ epoch 102: 0.8113
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 6.442845915444195e-05
Local loss @ local epoch 1: 0.00011945270671276376
Local loss @ local epoch 2: 0.0001061741349985823
Local loss @ local epoch 3: 3.2931032180786133
Local loss @ local epoch 4: 4.3449908844195306e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.57 seconds!
[tester] 
AGNewsMetric: acc=0.6977631578947369, hinge=2.6560254769576224, ce=9.656221068532844
Local test acc @ epoch 102: 0.6978
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.4247225522994995
Local loss @ local epoch 1: 0.002198098925873637
Local loss @ local epoch 2: 7.087424455676228e-05
Local loss @ local epoch 3: 0.0011037994408980012
Local loss @ local epoch 4: 0.007388630416244268
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.81 seconds!
[tester] 
AGNewsMetric: acc=0.5786842105263158, hinge=4.52280748166536, ce=9.769407744156688
Local test acc @ epoch 102: 0.5787
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 1.2397747468639864e-06
Local loss @ local epoch 1: 3.5762758443524945e-07
Local loss @ local epoch 2: 5.24520601175027e-07
Local loss @ local epoch 3: 3.0994402777650976e-07
Local loss @ local epoch 4: 2.8610219260372105e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.25 seconds!
[tester] 
AGNewsMetric: acc=0.6063157894736843, hinge=5.247436975679899, ce=10.747267705013877
Local test acc @ epoch 102: 0.6063
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.00047080928925424814
Local loss @ local epoch 1: 1.8337394067202695e-05
Local loss @ local epoch 2: 2.1595005819108337e-05
Local loss @ local epoch 3: 1.9191784303984605e-05
Local loss @ local epoch 4: 3.137049134238623e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.45 seconds!
[tester] 
AGNewsMetric: acc=0.44263157894736843, hinge=10.270914547568873, ce=12.214216376856754
Local test acc @ epoch 102: 0.4426
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.04528653621673584
Local loss @ local epoch 1: 0.0016370011726394296
Local loss @ local epoch 2: 0.006966190878301859
Local loss @ local epoch 3: 0.7434051632881165
Local loss @ local epoch 4: 0.06236989051103592
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.51 seconds!
[tester] 
AGNewsMetric: acc=0.7661842105263158, hinge=2.3066095035954524, ce=7.471094265987999
Local test acc @ epoch 102: 0.7662
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.015056493692100048
Local loss @ local epoch 1: 0.002434208756312728
Local loss @ local epoch 2: 0.0005540857673622668
Local loss @ local epoch 3: 0.001182420877739787
Local loss @ local epoch 4: 0.004507312551140785
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.0 seconds!
[tester] 
AGNewsMetric: acc=0.43644736842105264, hinge=4.325965546055844, ce=12.490921689083702
Local test acc @ epoch 102: 0.4364
Global evaluate on test data...
Evaluate data in 124.41 seconds!
[tester] 
AGNewsMetric: acc=0.8326315789473684, hinge=1.6986269584454987, ce=8.880978285136976
Global test acc @ epoch 102: 0.8326
Global epoch 103...
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0006257523782551289
Local loss @ local epoch 1: 4.301447461330099e-06
Local loss @ local epoch 2: 1.3539908650272992e-05
Local loss @ local epoch 3: 2.516150379960891e-05
Local loss @ local epoch 4: 1.9221979528083466e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.44 seconds!
[tester] 
AGNewsMetric: acc=0.4357894736842105, hinge=11.633591032530132, ce=15.071388690346165
Local test acc @ epoch 103: 0.4358
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 8.106224527182349e-07
Local loss @ local epoch 1: 2.384185648907078e-08
Local loss @ local epoch 2: 4.768371297814156e-08
Local loss @ local epoch 3: 1.1920925402364446e-07
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.14 seconds!
[tester] 
AGNewsMetric: acc=0.3844736842105263, hinge=13.577368003443668, ce=15.971027876201429
Local test acc @ epoch 103: 0.3845
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.3199411928653717
Local loss @ local epoch 1: 6.269605364650488e-05
Local loss @ local epoch 2: 0.000156184469233267
Local loss @ local epoch 3: 2.693945680221077e-05
Local loss @ local epoch 4: 0.006930345669388771
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.83 seconds!
[tester] 
AGNewsMetric: acc=0.41657894736842105, hinge=9.422191562652587, ce=12.326722897981343
Local test acc @ epoch 103: 0.4166
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0013761264272034168
Local loss @ local epoch 1: 0.0007482345099560916
Local loss @ local epoch 2: 0.0004833494604099542
Local loss @ local epoch 3: 0.0022494697477668524
Local loss @ local epoch 4: 0.0006782086566090584
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.9 seconds!
[tester] 
AGNewsMetric: acc=0.595657894736842, hinge=3.079263896440205, ce=9.278252838536313
Local test acc @ epoch 103: 0.5957
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0002855665807146579
Local loss @ local epoch 1: 4.845426883548498e-05
Local loss @ local epoch 2: 4.4633463403442875e-05
Local loss @ local epoch 3: 0.000507995137013495
Local loss @ local epoch 4: 2.1922924133832566e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.49 seconds!
[tester] 
AGNewsMetric: acc=0.47039473684210525, hinge=11.761125616274382, ce=12.14665348253752
Local test acc @ epoch 103: 0.4704
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.2326478511095047
Local loss @ local epoch 1: 0.0019167732680216432
Local loss @ local epoch 2: 0.0008213057881221175
Local loss @ local epoch 3: 0.008738008327782154
Local loss @ local epoch 4: 0.009038715623319149
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.47 seconds!
[tester] 
AGNewsMetric: acc=0.5896052631578947, hinge=4.03370481892636, ce=10.016729236402009
Local test acc @ epoch 103: 0.5896
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 3.966432632296346e-05
Local loss @ local epoch 1: 7.631225162185729e-05
Local loss @ local epoch 2: 5.662438411491166e-07
Local loss @ local epoch 3: 4.0829036151990294e-06
Local loss @ local epoch 4: 2.562989948273753e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.29 seconds!
[tester] 
AGNewsMetric: acc=0.5742105263157895, hinge=4.621767329667744, ce=10.431644383480675
Local test acc @ epoch 103: 0.5742
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.006099289748817682
Local loss @ local epoch 1: 0.0015842760913074017
Local loss @ local epoch 2: 0.011257224716246128
Local loss @ local epoch 3: 0.00200904649682343
Local loss @ local epoch 4: 0.0039877500385046005
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.3 seconds!
[tester] 
AGNewsMetric: acc=0.8088157894736843, hinge=2.2067977541371397, ce=8.671553868745503
Local test acc @ epoch 103: 0.8088
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.02231886424124241
Local loss @ local epoch 1: 0.013615159317851067
Local loss @ local epoch 2: 0.0021559945307672024
Local loss @ local epoch 3: 0.013560527004301548
Local loss @ local epoch 4: 0.28362324833869934
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.45 seconds!
[tester] 
AGNewsMetric: acc=0.6903947368421053, hinge=2.393418849141974, ce=9.581964569091797
Local test acc @ epoch 103: 0.6904
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.00015052547678351402
Local loss @ local epoch 1: 1.9073455632678815e-06
Local loss @ local epoch 2: 2.895467150665354e-05
Local loss @ local epoch 3: 9.596115887688939e-06
Local loss @ local epoch 4: 0.16870541870594025
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.73 seconds!
[tester] 
AGNewsMetric: acc=0.574078947368421, hinge=6.898383721552397, ce=11.76088913967735
Local test acc @ epoch 103: 0.5741
Global evaluate on test data...
Evaluate data in 124.22 seconds!
[tester] 
AGNewsMetric: acc=0.858421052631579, hinge=1.5487295394194753, ce=8.685903430737946
Global test acc @ epoch 103: 0.8584
Global epoch 104...
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.06113487482070923
Local loss @ local epoch 1: 0.0010774919064715505
Local loss @ local epoch 2: 0.005875156726688147
Local loss @ local epoch 3: 0.02211766131222248
Local loss @ local epoch 4: 0.005118225701153278
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.56 seconds!
[tester] 
AGNewsMetric: acc=0.6536842105263158, hinge=4.477070659838224, ce=9.839504173680355
Local test acc @ epoch 104: 0.6537
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 2.384185648907078e-08
Local loss @ local epoch 1: 2.384185648907078e-08
Local loss @ local epoch 2: 4.053113116242457e-07
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 9.53674117454284e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.74 seconds!
[tester] 
AGNewsMetric: acc=0.6252631578947369, hinge=4.5334303341413795, ce=11.196819871601306
Local test acc @ epoch 104: 0.6253
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.00023131088528316468
Local loss @ local epoch 1: 4.2315979953855276e-05
Local loss @ local epoch 2: 3.7848826650588308e-06
Local loss @ local epoch 3: 2.9802226890751626e-06
Local loss @ local epoch 4: 1.484133827034384e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.78 seconds!
[tester] 
AGNewsMetric: acc=0.7498684210526316, hinge=2.4555245075727763, ce=8.027595744885897
Local test acc @ epoch 104: 0.7499
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.00022275630908552557
Local loss @ local epoch 1: 6.715388735756278e-06
Local loss @ local epoch 2: 3.87428599424311e-06
Local loss @ local epoch 3: 7.2021507548925e-06
Local loss @ local epoch 4: 0.0006587219540961087
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.93 seconds!
[tester] 
AGNewsMetric: acc=0.5073684210526316, hinge=8.346125682027717, ce=12.517906642713045
Local test acc @ epoch 104: 0.5074
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0027983493637293577
Local loss @ local epoch 1: 8.669756539347873e-07
Local loss @ local epoch 2: 1.59306648583879e-06
Local loss @ local epoch 3: 2.25412736654107e-06
Local loss @ local epoch 4: 4.193983841105364e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.76 seconds!
[tester] 
AGNewsMetric: acc=0.3732894736842105, hinge=14.024276442276804, ce=15.422213470057438
Local test acc @ epoch 104: 0.3733
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.24966464936733246
Local loss @ local epoch 1: 0.0007080620853230357
Local loss @ local epoch 2: 0.0002527839387767017
Local loss @ local epoch 3: 0.002668204251676798
Local loss @ local epoch 4: 0.0044721802696585655
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.72 seconds!
[tester] 
AGNewsMetric: acc=0.5851315789473684, hinge=6.260584883438914, ce=10.682936029936139
Local test acc @ epoch 104: 0.5851
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0037609036080539227
Local loss @ local epoch 1: 0.3432973325252533
Local loss @ local epoch 2: 0.02537343092262745
Local loss @ local epoch 3: 0.057398922741413116
Local loss @ local epoch 4: 0.013113942928612232
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.68 seconds!
[tester] 
AGNewsMetric: acc=0.8039473684210526, hinge=1.4734512682964926, ce=9.916905726382607
Local test acc @ epoch 104: 0.8039
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.26996156573295593
Local loss @ local epoch 1: 0.000760468712542206
Local loss @ local epoch 2: 0.003631554776802659
Local loss @ local epoch 3: 0.009311978705227375
Local loss @ local epoch 4: 0.058607589453458786
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.19 seconds!
[tester] 
AGNewsMetric: acc=0.5132894736842105, hinge=4.826825664419877, ce=9.60656399777061
Local test acc @ epoch 104: 0.5133
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0010613681515678763
Local loss @ local epoch 1: 5.582904123002663e-06
Local loss @ local epoch 2: 0.016452563926577568
Local loss @ local epoch 3: 0.00014636623382102698
Local loss @ local epoch 4: 0.0009483241010457277
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.86 seconds!
[tester] 
AGNewsMetric: acc=0.8431578947368421, hinge=1.457680529795195, ce=6.862460167533473
Local test acc @ epoch 104: 0.8432
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.03656727820634842
Local loss @ local epoch 1: 0.0014995975652709603
Local loss @ local epoch 2: 0.003186873160302639
Local loss @ local epoch 3: 0.001514409319497645
Local loss @ local epoch 4: 0.0012766477884724736
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.6 seconds!
[tester] 
AGNewsMetric: acc=0.5686842105263158, hinge=3.749900160337749, ce=11.32047826666581
Local test acc @ epoch 104: 0.5687
Global evaluate on test data...
Evaluate data in 123.62 seconds!
[tester] 
AGNewsMetric: acc=0.8561842105263158, hinge=1.7246578294352481, ce=8.75950897618344
Global test acc @ epoch 104: 0.8562
Global epoch 105...
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 7.03568002791144e-05
Local loss @ local epoch 1: 5.215373676037416e-06
Local loss @ local epoch 2: 2.3600672648171894e-05
Local loss @ local epoch 3: 1.7840089640230872e-05
Local loss @ local epoch 4: 5.6425265029247385e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.21 seconds!
[tester] 
AGNewsMetric: acc=0.7917105263157894, hinge=2.398796904463517, ce=9.339585705807334
Local test acc @ epoch 105: 0.7917
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.008604997768998146
Local loss @ local epoch 1: 0.002449063118547201
Local loss @ local epoch 2: 0.2689109742641449
Local loss @ local epoch 3: 0.005470909643918276
Local loss @ local epoch 4: 0.004716565366834402
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.09 seconds!
[tester] 
AGNewsMetric: acc=0.7047368421052631, hinge=2.9866170569470056, ce=4.663696917483681
Local test acc @ epoch 105: 0.7047
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 3.4568365663290024e-05
Local loss @ local epoch 1: 1.957983295142185e-05
Local loss @ local epoch 2: 2.9294134947122075e-05
Local loss @ local epoch 3: 0.0004379883757792413
Local loss @ local epoch 4: 0.000235642641200684
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.26 seconds!
[tester] 
AGNewsMetric: acc=0.7503947368421052, hinge=2.471847165760241, ce=8.61378704472592
Local test acc @ epoch 105: 0.7504
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 2.429554115224164e-05
Local loss @ local epoch 1: 2.4708597265998833e-06
Local loss @ local epoch 2: 2.611750232972554e-06
Local loss @ local epoch 3: 1.3113003660691902e-06
Local loss @ local epoch 4: 1.8965038179885596e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.96 seconds!
[tester] 
AGNewsMetric: acc=0.38026315789473686, hinge=15.606795161397834, ce=17.633958101774518
Local test acc @ epoch 105: 0.3803
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.14521537721157074
Local loss @ local epoch 1: 0.0008931548218242824
Local loss @ local epoch 2: 0.0006406654138118029
Local loss @ local epoch 3: 0.00045634451089426875
Local loss @ local epoch 4: 0.08439434319734573
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.78 seconds!
[tester] 
AGNewsMetric: acc=0.5051315789473684, hinge=8.046891468449642, ce=11.889621214615671
Local test acc @ epoch 105: 0.5051
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 3.317951495773741e-06
Local loss @ local epoch 1: 0.00012588985555339605
Local loss @ local epoch 2: 1.5894524949544575e-06
Local loss @ local epoch 3: 1.8676009858609177e-06
Local loss @ local epoch 4: 9.478937136009336e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.87 seconds!
[tester] 
AGNewsMetric: acc=0.43105263157894735, hinge=13.3796521563279, ce=14.341175751937064
Local test acc @ epoch 105: 0.4311
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.00037528370739892125
Local loss @ local epoch 1: 0.001625874894671142
Local loss @ local epoch 2: 0.0002046577719738707
Local loss @ local epoch 3: 0.00017056474462151527
Local loss @ local epoch 4: 0.0005751745775341988
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.32 seconds!
[tester] 
AGNewsMetric: acc=0.8148684210526316, hinge=1.8693185058392976, ce=9.981031303405763
Local test acc @ epoch 105: 0.8149
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.2968447506427765
Local loss @ local epoch 1: 0.0008086598245427012
Local loss @ local epoch 2: 0.0003300064417999238
Local loss @ local epoch 3: 0.0009131503757089376
Local loss @ local epoch 4: 0.0018990462413057685
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.51 seconds!
[tester] 
AGNewsMetric: acc=0.5826315789473684, hinge=4.222965897007993, ce=9.853806507712916
Local test acc @ epoch 105: 0.5826
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.003539114026352763
Local loss @ local epoch 1: 0.1533559411764145
Local loss @ local epoch 2: 0.004536220338195562
Local loss @ local epoch 3: 0.001458912156522274
Local loss @ local epoch 4: 0.0008234761189669371
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.55 seconds!
[tester] 
AGNewsMetric: acc=0.42894736842105263, hinge=3.8576300309833726, ce=12.000495011179071
Local test acc @ epoch 105: 0.4289
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 2.384185648907078e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.384185648907078e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.63 seconds!
[tester] 
AGNewsMetric: acc=0.7005263157894737, hinge=4.098204378830759, ce=12.615386491072805
Local test acc @ epoch 105: 0.7005
Global evaluate on test data...
Evaluate data in 123.66 seconds!
[tester] 
AGNewsMetric: acc=0.8488157894736842, hinge=1.5838087882493672, ce=9.225677359731574
Global test acc @ epoch 105: 0.8488
Global epoch 106...
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.17285872995853424
Local loss @ local epoch 1: 1.641960443521384e-05
Local loss @ local epoch 2: 0.004037559498101473
Local loss @ local epoch 3: 0.02068815752863884
Local loss @ local epoch 4: 0.024326657876372337
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.09 seconds!
[tester] 
AGNewsMetric: acc=0.47407894736842104, hinge=9.745938133691487, ce=13.150971629494116
Local test acc @ epoch 106: 0.4741
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.006222808267921209
Local loss @ local epoch 1: 0.030983541160821915
Local loss @ local epoch 2: 0.39144986867904663
Local loss @ local epoch 3: 0.28310146927833557
Local loss @ local epoch 4: 0.042580097913742065
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.89 seconds!
[tester] 
AGNewsMetric: acc=0.7664473684210527, hinge=1.8400220881010356, ce=6.599618434906006
Local test acc @ epoch 106: 0.7664
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.48068806529045105
Local loss @ local epoch 1: 0.0002692432899493724
Local loss @ local epoch 2: 0.0780763104557991
Local loss @ local epoch 3: 0.12190480530261993
Local loss @ local epoch 4: 0.0009671524167060852
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.94 seconds!
[tester] 
AGNewsMetric: acc=0.6921052631578948, hinge=3.7015193472410504, ce=9.588587156596937
Local test acc @ epoch 106: 0.6921
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.004451702814549208
Local loss @ local epoch 1: 2.8846872737631202e-05
Local loss @ local epoch 2: 4.655676821130328e-05
Local loss @ local epoch 3: 5.185269037610851e-05
Local loss @ local epoch 4: 1.7631564332987182e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.36 seconds!
[tester] 
AGNewsMetric: acc=0.4361842105263158, hinge=12.568897444072523, ce=14.993348631607859
Local test acc @ epoch 106: 0.4362
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.0009876855183392763
Local loss @ local epoch 1: 0.00015411789354402572
Local loss @ local epoch 2: 7.287578227987979e-06
Local loss @ local epoch 3: 0.7152320146560669
Local loss @ local epoch 4: 1.1563068255782127e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.24 seconds!
[tester] 
AGNewsMetric: acc=0.6348684210526315, hinge=4.685318025287829, ce=11.026296248185007
Local test acc @ epoch 106: 0.6349
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.011093296110630035
Local loss @ local epoch 1: 0.002146105282008648
Local loss @ local epoch 2: 0.008717325516045094
Local loss @ local epoch 3: 0.00042583176400512457
Local loss @ local epoch 4: 0.0004339545557741076
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.75 seconds!
[tester] 
AGNewsMetric: acc=0.5707894736842105, hinge=3.579022079267, ce=11.572258569817794
Local test acc @ epoch 106: 0.5708
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.012801221571862698
Local loss @ local epoch 1: 1.1424211834309972e-06
Local loss @ local epoch 2: 3.5907880373997614e-05
Local loss @ local epoch 3: 1.9271255951025523e-05
Local loss @ local epoch 4: 0.0004218943358864635
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.74 seconds!
[tester] 
AGNewsMetric: acc=0.3161842105263158, hinge=14.325688513705606, ce=15.683175669218365
Local test acc @ epoch 106: 0.3162
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0633421391248703
Local loss @ local epoch 1: 0.00031208558357320726
Local loss @ local epoch 2: 0.0017476914217695594
Local loss @ local epoch 3: 0.0014084939612075686
Local loss @ local epoch 4: 0.00035408715484663844
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.43 seconds!
[tester] 
AGNewsMetric: acc=0.5319736842105263, hinge=7.857146777102821, ce=14.920870469745838
Local test acc @ epoch 106: 0.532
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 1.9073476664743794e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.384185648907078e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.6689295989635866e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.64 seconds!
[tester] 
AGNewsMetric: acc=0.43197368421052634, hinge=10.061997222900391, ce=15.162014481393914
Local test acc @ epoch 106: 0.432
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 3.060584276681766e-05
Local loss @ local epoch 1: 0.00028519521583803
Local loss @ local epoch 2: 6.467051662184531e-06
Local loss @ local epoch 3: 5.1259485189802945e-06
Local loss @ local epoch 4: 8.046621928770037e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.04 seconds!
[tester] 
AGNewsMetric: acc=0.6448684210526315, hinge=4.612174349835044, ce=11.383120338038394
Local test acc @ epoch 106: 0.6449
Global evaluate on test data...
Evaluate data in 123.88 seconds!
[tester] 
AGNewsMetric: acc=0.8371052631578947, hinge=2.0691117866415727, ce=9.438796454981754
Global test acc @ epoch 106: 0.8371
Global epoch 107...
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.6971282362937927
Local loss @ local epoch 1: 0.13127896189689636
Local loss @ local epoch 2: 0.0001622237905394286
Local loss @ local epoch 3: 0.0040407199412584305
Local loss @ local epoch 4: 0.0002349131682422012
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.96 seconds!
[tester] 
AGNewsMetric: acc=0.5457894736842105, hinge=5.970592472678737, ce=11.659501479299445
Local test acc @ epoch 107: 0.5458
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.003342124866321683
Local loss @ local epoch 1: 0.001882644253782928
Local loss @ local epoch 2: 0.0005594594986177981
Local loss @ local epoch 3: 0.007388337980955839
Local loss @ local epoch 4: 0.00012234791938681155
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.73 seconds!
[tester] 
AGNewsMetric: acc=0.7832894736842105, hinge=2.680350136756897, ce=9.430616386815121
Local test acc @ epoch 107: 0.7833
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 1.1811899639724288e-05
Local loss @ local epoch 1: 2.2758135287404002e-07
Local loss @ local epoch 2: 2.384184938364342e-07
Local loss @ local epoch 3: 1.6255808077403344e-07
Local loss @ local epoch 4: 1.1920926823449918e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.27 seconds!
[tester] 
AGNewsMetric: acc=0.5948684210526316, hinge=7.079253851489017, ce=12.001170208579616
Local test acc @ epoch 107: 0.5949
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.00012067492207279429
Local loss @ local epoch 1: 9.537987352814525e-05
Local loss @ local epoch 2: 0.0006406512693502009
Local loss @ local epoch 3: 1.2934010555909481e-05
Local loss @ local epoch 4: 1.5139420611376408e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.94 seconds!
[tester] 
AGNewsMetric: acc=0.656578947368421, hinge=4.2193337533348485, ce=9.866173406902112
Local test acc @ epoch 107: 0.6566
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.015798788517713547
Local loss @ local epoch 1: 0.059664301574230194
Local loss @ local epoch 2: 0.07187957316637039
Local loss @ local epoch 3: 0.07592935115098953
Local loss @ local epoch 4: 0.08699602633714676
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.05 seconds!
[tester] 
AGNewsMetric: acc=0.7203947368421053, hinge=2.504014456397609, ce=8.78074388202868
Local test acc @ epoch 107: 0.7204
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.7141067385673523
Local loss @ local epoch 1: 0.00967473816126585
Local loss @ local epoch 2: 0.08695823699235916
Local loss @ local epoch 3: 0.0017193229869008064
Local loss @ local epoch 4: 0.00033143768087029457
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.06 seconds!
[tester] 
AGNewsMetric: acc=0.44671052631578945, hinge=6.612335832495439, ce=11.27834400578549
Local test acc @ epoch 107: 0.4467
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 9.129214959102683e-06
Local loss @ local epoch 1: 7.529969934694236e-06
Local loss @ local epoch 2: 7.400697995763039e-06
Local loss @ local epoch 3: 2.7716080239770235e-06
Local loss @ local epoch 4: 4.190237450529821e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.93 seconds!
[tester] 
AGNewsMetric: acc=0.7938157894736843, hinge=2.2680737889440437, ce=9.051783648039166
Local test acc @ epoch 107: 0.7938
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.00658440263941884
Local loss @ local epoch 1: 0.001277550240047276
Local loss @ local epoch 2: 0.0008697977173142135
Local loss @ local epoch 3: 0.0007884520455263555
Local loss @ local epoch 4: 0.0007881501223891973
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.55 seconds!
[tester] 
AGNewsMetric: acc=0.5988157894736842, hinge=3.260542953390824, ce=10.408462689048365
Local test acc @ epoch 107: 0.5988
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 1.0410803042759653e-05
Local loss @ local epoch 1: 3.0795717975706793e-07
Local loss @ local epoch 2: 3.6755925520992605e-06
Local loss @ local epoch 3: 7.74859188368282e-07
Local loss @ local epoch 4: 4.0729824490881583e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.77 seconds!
[tester] 
AGNewsMetric: acc=0.515921052631579, hinge=9.845873936602944, ce=12.955844393278424
Local test acc @ epoch 107: 0.5159
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 2.622603858526418e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 4.529951240783703e-07
Local loss @ local epoch 3: 2.384185648907078e-08
Local loss @ local epoch 4: 1.6689295989635866e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.93 seconds!
[tester] 
AGNewsMetric: acc=0.6568421052631579, hinge=3.8314867074866044, ce=10.807654013382761
Local test acc @ epoch 107: 0.6568
Global evaluate on test data...
Evaluate data in 123.73 seconds!
[tester] 
AGNewsMetric: acc=0.8218421052631579, hinge=1.9784411224566008, ce=9.296788892244038
Global test acc @ epoch 107: 0.8218
Global epoch 108...
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.1983349323272705
Local loss @ local epoch 1: 3.7749407511000754e-06
Local loss @ local epoch 2: 7.924875535536557e-05
Local loss @ local epoch 3: 0.0014582258882001042
Local loss @ local epoch 4: 0.012735358439385891
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.13 seconds!
[tester] 
AGNewsMetric: acc=0.49605263157894736, hinge=9.291432336506091, ce=14.482148804915578
Local test acc @ epoch 108: 0.4961
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0059221237897872925
Local loss @ local epoch 1: 0.0035348276142030954
Local loss @ local epoch 2: 0.0021286841947585344
Local loss @ local epoch 3: 0.0024357440415769815
Local loss @ local epoch 4: 0.0009156183223240077
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.3 seconds!
[tester] 
AGNewsMetric: acc=0.3425, hinge=5.478329366382799, ce=10.942418999922904
Local test acc @ epoch 108: 0.3425
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 2.3245770535140764e-06
Local loss @ local epoch 1: 1.6510117347934283e-05
Local loss @ local epoch 2: 1.460288513044361e-05
Local loss @ local epoch 3: 0.00014417245984077454
Local loss @ local epoch 4: 2.3811177015886642e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.83 seconds!
[tester] 
AGNewsMetric: acc=0.6223684210526316, hinge=5.6013923163163035, ce=10.247374669125206
Local test acc @ epoch 108: 0.6224
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 1.381628394126892
Local loss @ local epoch 1: 0.010238434188067913
Local loss @ local epoch 2: 6.973632935114438e-06
Local loss @ local epoch 3: 1.9172773590980796e-06
Local loss @ local epoch 4: 1.4165080756356474e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.34 seconds!
[tester] 
AGNewsMetric: acc=0.5780263157894737, hinge=6.4411035121114635, ce=12.029636035718417
Local test acc @ epoch 108: 0.578
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 2.3841843699301535e-07
Local loss @ local epoch 1: 7.152556946721234e-08
Local loss @ local epoch 2: 5.722039304600912e-07
Local loss @ local epoch 3: 3.8146953329487587e-07
Local loss @ local epoch 4: 7.867807880757027e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.3 seconds!
[tester] 
AGNewsMetric: acc=0.6355263157894737, hinge=5.087207412217793, ce=5.939594837991815
Local test acc @ epoch 108: 0.6355
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.021381178870797157
Local loss @ local epoch 1: 0.00015518379223067313
Local loss @ local epoch 2: 0.00014661411114502698
Local loss @ local epoch 3: 0.01902175322175026
Local loss @ local epoch 4: 9.351992048323154e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.29 seconds!
[tester] 
AGNewsMetric: acc=0.628421052631579, hinge=4.306368387623837, ce=10.926416782579924
Local test acc @ epoch 108: 0.6284
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.9220647215843201
Local loss @ local epoch 1: 1.3264510016597342e-05
Local loss @ local epoch 2: 9.319802302343305e-06
Local loss @ local epoch 3: 2.297481159985182e-06
Local loss @ local epoch 4: 1.6894122381927446e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.88 seconds!
[tester] 
AGNewsMetric: acc=0.47842105263157897, hinge=9.931972668296412, ce=13.617509325930946
Local test acc @ epoch 108: 0.4784
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.019872993230819702
Local loss @ local epoch 1: 0.00010263386502629146
Local loss @ local epoch 2: 7.251822535181418e-05
Local loss @ local epoch 3: 0.0007646363810636103
Local loss @ local epoch 4: 0.31385597586631775
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.94 seconds!
[tester] 
AGNewsMetric: acc=0.5794736842105264, hinge=5.8482866181825335, ce=12.509223426015753
Local test acc @ epoch 108: 0.5795
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.004094361327588558
Local loss @ local epoch 1: 0.009454898536205292
Local loss @ local epoch 2: 0.006348036229610443
Local loss @ local epoch 3: 0.0057054185308516026
Local loss @ local epoch 4: 0.015861334279179573
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.35 seconds!
[tester] 
AGNewsMetric: acc=0.8092105263157895, hinge=1.821486957951596, ce=9.429018373991314
Local test acc @ epoch 108: 0.8092
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 2.5494344234466553
Local loss @ local epoch 1: 0.0006647799746133387
Local loss @ local epoch 2: 0.0015130973188206553
Local loss @ local epoch 3: 0.010105862282216549
Local loss @ local epoch 4: 0.6019830107688904
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.08 seconds!
[tester] 
AGNewsMetric: acc=0.6310526315789474, hinge=4.729866713975605, ce=9.870714832105135
Local test acc @ epoch 108: 0.6311
Global evaluate on test data...
Evaluate data in 123.7 seconds!
[tester] 
AGNewsMetric: acc=0.8461842105263158, hinge=1.9565690294064975, ce=9.201083038731625
Global test acc @ epoch 108: 0.8462
Global epoch 109...
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 6.357753136398969e-06
Local loss @ local epoch 1: 8.642659281576925e-07
Local loss @ local epoch 2: 2.1159585230634548e-06
Local loss @ local epoch 3: 8.294764484162442e-06
Local loss @ local epoch 4: 5.46375531484955e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.54 seconds!
[tester] 
AGNewsMetric: acc=0.5060526315789474, hinge=10.311084056151541, ce=12.85035619233784
Local test acc @ epoch 109: 0.5061
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.005029359832406044
Local loss @ local epoch 1: 0.00811957847326994
Local loss @ local epoch 2: 0.0008264600764960051
Local loss @ local epoch 3: 0.01418719906359911
Local loss @ local epoch 4: 0.0009543715859763324
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.85 seconds!
[tester] 
AGNewsMetric: acc=0.7418421052631579, hinge=2.0179097614790265, ce=10.746345122487922
Local test acc @ epoch 109: 0.7418
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 3.447806375334039e-05
Local loss @ local epoch 1: 3.4597236663103104e-05
Local loss @ local epoch 2: 2.0157144717813935e-06
Local loss @ local epoch 3: 1.4955320466469857e-06
Local loss @ local epoch 4: 1.6580902411078569e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.7 seconds!
[tester] 
AGNewsMetric: acc=0.47210526315789475, hinge=7.79127718925476, ce=12.093558391771818
Local test acc @ epoch 109: 0.4721
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 1.65041983127594
Local loss @ local epoch 1: 0.0009420995484106243
Local loss @ local epoch 2: 0.00050164177082479
Local loss @ local epoch 3: 0.00857583712786436
Local loss @ local epoch 4: 0.008260742761194706
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.82 seconds!
[tester] 
AGNewsMetric: acc=0.6763157894736842, hinge=2.9956750771873875, ce=9.930407305265728
Local test acc @ epoch 109: 0.6763
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 1.907348234908568e-07
Local loss @ local epoch 1: 2.861021641820116e-07
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 8.96433812158648e-06
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.84 seconds!
[tester] 
AGNewsMetric: acc=0.554078947368421, hinge=6.326507435848838, ce=11.058857889677348
Local test acc @ epoch 109: 0.5541
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.004343237262219191
Local loss @ local epoch 1: 0.04740720987319946
Local loss @ local epoch 2: 0.0003237428900320083
Local loss @ local epoch 3: 0.0003609089180827141
Local loss @ local epoch 4: 0.10916392505168915
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.15 seconds!
[tester] 
AGNewsMetric: acc=0.8442105263157895, hinge=1.9640686765470003, ce=9.591713084170692
Local test acc @ epoch 109: 0.8442
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.039894383400678635
Local loss @ local epoch 1: 0.0005738590843975544
Local loss @ local epoch 2: 0.09106165915727615
Local loss @ local epoch 3: 0.0048829237930476665
Local loss @ local epoch 4: 0.0031054490245878696
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.94 seconds!
[tester] 
AGNewsMetric: acc=0.7067105263157895, hinge=3.5030018053556744, ce=10.884219539040012
Local test acc @ epoch 109: 0.7067
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 2.1814184947288595e-05
Local loss @ local epoch 1: 1.2218921483508893e-06
Local loss @ local epoch 2: 4.202077616355382e-05
Local loss @ local epoch 3: 1.7384644479534472e-06
Local loss @ local epoch 4: 3.2782420475996332e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.83 seconds!
[tester] 
AGNewsMetric: acc=0.8446052631578947, hinge=1.7727174450221814, ce=8.065544090270997
Local test acc @ epoch 109: 0.8446
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.816227912902832
Local loss @ local epoch 1: 0.019375566393136978
Local loss @ local epoch 2: 0.029777197167277336
Local loss @ local epoch 3: 0.0006071255193091929
Local loss @ local epoch 4: 0.038674212992191315
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.38 seconds!
[tester] 
AGNewsMetric: acc=0.5342105263157895, hinge=7.346056365966797, ce=11.830805509466874
Local test acc @ epoch 109: 0.5342
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.00015352477203123271
Local loss @ local epoch 1: 0.0001732136297505349
Local loss @ local epoch 2: 1.272544886887772e-05
Local loss @ local epoch 3: 8.19734123069793e-05
Local loss @ local epoch 4: 0.0001904329692479223
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.42 seconds!
[tester] 
AGNewsMetric: acc=0.7226315789473684, hinge=3.328407109913073, ce=7.701108286004318
Local test acc @ epoch 109: 0.7226
Global evaluate on test data...
Evaluate data in 123.87 seconds!
[tester] 
AGNewsMetric: acc=0.8431578947368421, hinge=1.738232085328353, ce=9.000575196115594
Global test acc @ epoch 109: 0.8432
Global epoch 110...
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.021661216393113136
Local loss @ local epoch 1: 0.002263431902974844
Local loss @ local epoch 2: 0.0006048465147614479
Local loss @ local epoch 3: 0.0002857173385564238
Local loss @ local epoch 4: 0.00024055232643149793
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.31 seconds!
[tester] 
AGNewsMetric: acc=0.5076315789473684, hinge=8.52649534376044, ce=12.653470756129215
Local test acc @ epoch 110: 0.5076
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0014483872801065445
Local loss @ local epoch 1: 3.5464481697999872e-06
Local loss @ local epoch 2: 2.7285066607873887e-05
Local loss @ local epoch 3: 3.942171315429732e-05
Local loss @ local epoch 4: 0.0004040201602037996
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.03 seconds!
[tester] 
AGNewsMetric: acc=0.42828947368421055, hinge=13.50650554857756, ce=15.348212918733296
Local test acc @ epoch 110: 0.4283
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 1.6267873048782349
Local loss @ local epoch 1: 0.0011034250492230058
Local loss @ local epoch 2: 0.002608077833428979
Local loss @ local epoch 3: 0.04233277216553688
Local loss @ local epoch 4: 0.09267104417085648
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 125.7 seconds!
[tester] 
AGNewsMetric: acc=0.6102631578947368, hinge=4.7573599599537095, ce=8.57314552708676
Local test acc @ epoch 110: 0.6103
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.00507113104686141
Local loss @ local epoch 1: 0.0014921351103112102
Local loss @ local epoch 2: 0.0029475234914571047
Local loss @ local epoch 3: 0.010683293454349041
Local loss @ local epoch 4: 0.0031212440226227045
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 126.52 seconds!
[tester] 
AGNewsMetric: acc=0.5607894736842105, hinge=3.774700493561594, ce=7.889057635257118
Local test acc @ epoch 110: 0.5608
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 3.069625336138415e-06
Local loss @ local epoch 1: 3.1916642910800874e-05
Local loss @ local epoch 2: 1.543719736218918e-05
Local loss @ local epoch 3: 1.785133281373419e-05
Local loss @ local epoch 4: 9.536736911286425e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 125.13 seconds!
[tester] 
AGNewsMetric: acc=0.7151315789473685, hinge=4.042652649126555, ce=9.25996470200388
Local test acc @ epoch 110: 0.7151
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 4.410695055412361e-06
Local loss @ local epoch 1: 7.152556236178498e-08
Local loss @ local epoch 2: 2.622603858526418e-07
Local loss @ local epoch 3: 1.6689295989635866e-07
Local loss @ local epoch 4: 4.768371297814156e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.64 seconds!
[tester] 
AGNewsMetric: acc=0.7805263157894737, hinge=3.2707539957448057, ce=9.457030938801013
Local test acc @ epoch 110: 0.7805
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.04033518210053444
Local loss @ local epoch 1: 2.51422375185939e-06
Local loss @ local epoch 2: 4.063911546836607e-06
Local loss @ local epoch 3: 1.1064411410188768e-05
Local loss @ local epoch 4: 2.4925402613007464e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.14 seconds!
[tester] 
AGNewsMetric: acc=0.4594736842105263, hinge=10.542437671862151, ce=13.838900154515317
Local test acc @ epoch 110: 0.4595
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.05514108017086983
Local loss @ local epoch 1: 0.0008443986298516393
Local loss @ local epoch 2: 0.23798781633377075
Local loss @ local epoch 3: 0.0002981492434628308
Local loss @ local epoch 4: 0.01036917045712471
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.25 seconds!
[tester] 
AGNewsMetric: acc=0.7776315789473685, hinge=1.8169078357596147, ce=9.277175728647332
Local test acc @ epoch 110: 0.7776
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.008738314732909203
Local loss @ local epoch 1: 6.904050223965896e-06
Local loss @ local epoch 2: 4.24183326686034e-06
Local loss @ local epoch 3: 1.823856837290805e-05
Local loss @ local epoch 4: 0.0001429304393241182
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.94 seconds!
[tester] 
AGNewsMetric: acc=0.5030263157894737, hinge=9.66949868252403, ce=11.492965921100817
Local test acc @ epoch 110: 0.503
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.004652430769056082
Local loss @ local epoch 1: 0.0376371331512928
Local loss @ local epoch 2: 0.5336641073226929
Local loss @ local epoch 3: 0.17008331418037415
Local loss @ local epoch 4: 0.2688124477863312
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.1 seconds!
[tester] 
AGNewsMetric: acc=0.6657894736842105, hinge=2.680380072844656, ce=8.844149734095524
Local test acc @ epoch 110: 0.6658
Global evaluate on test data...
Evaluate data in 123.77 seconds!
[tester] 
AGNewsMetric: acc=0.8219736842105263, hinge=2.42281881533171, ce=9.022769044574938
Global test acc @ epoch 110: 0.822
Global epoch 111...
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 1.0251867934130132e-05
Local loss @ local epoch 1: 0.00032087427098304033
Local loss @ local epoch 2: 2.8847452995250933e-05
Local loss @ local epoch 3: 3.5969973396277055e-05
Local loss @ local epoch 4: 2.6732104743132368e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.4 seconds!
[tester] 
AGNewsMetric: acc=0.7521052631578947, hinge=2.5402144750795865, ce=8.59627110330682
Local test acc @ epoch 111: 0.7521
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 1.816208004951477
Local loss @ local epoch 1: 0.0009221031796187162
Local loss @ local epoch 2: 0.0011489999014884233
Local loss @ local epoch 3: 0.0005184576730243862
Local loss @ local epoch 4: 0.00013866586959920824
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.97 seconds!
[tester] 
AGNewsMetric: acc=0.6560526315789473, hinge=3.560533241472746, ce=7.83958000383879
Local test acc @ epoch 111: 0.6561
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 3.0994402777650976e-07
Local loss @ local epoch 1: 9.536741885085576e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.152556946721234e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.14 seconds!
[tester] 
AGNewsMetric: acc=0.6564473684210527, hinge=4.850111590937564, ce=10.964943823563425
Local test acc @ epoch 111: 0.6564
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0022857736330479383
Local loss @ local epoch 1: 0.013419772498309612
Local loss @ local epoch 2: 0.02298867143690586
Local loss @ local epoch 3: 0.004245330113917589
Local loss @ local epoch 4: 0.0012521391035988927
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.73 seconds!
[tester] 
AGNewsMetric: acc=0.7710526315789473, hinge=1.81870225504825, ce=6.773236316881682
Local test acc @ epoch 111: 0.7711
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.002982087666168809
Local loss @ local epoch 1: 0.0032300890889018774
Local loss @ local epoch 2: 0.003263956168666482
Local loss @ local epoch 3: 0.002581236185505986
Local loss @ local epoch 4: 0.002047586953267455
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.56 seconds!
[tester] 
AGNewsMetric: acc=0.5330263157894737, hinge=4.045481067958631, ce=9.24192616914448
Local test acc @ epoch 111: 0.533
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 2.8212664346938254e-06
Local loss @ local epoch 1: 1.7881349094750476e-06
Local loss @ local epoch 2: 1.9868068648065673e-06
Local loss @ local epoch 3: 3.728447700268589e-05
Local loss @ local epoch 4: 2.7716075692296727e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.83 seconds!
[tester] 
AGNewsMetric: acc=0.8656578947368421, hinge=1.5183801548104536, ce=9.461560245313143
Local test acc @ epoch 111: 0.8657
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.1865500211715698
Local loss @ local epoch 1: 0.003939767833799124
Local loss @ local epoch 2: 0.014649813063442707
Local loss @ local epoch 3: 0.00024594576098024845
Local loss @ local epoch 4: 0.0003101779439020902
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.39 seconds!
[tester] 
AGNewsMetric: acc=0.56, hinge=4.548236540242245, ce=8.862855652257016
Local test acc @ epoch 111: 0.56
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 2.7526355097506894e-06
Local loss @ local epoch 1: 1.517208829682204e-07
Local loss @ local epoch 2: 7.369286549874232e-07
Local loss @ local epoch 3: 3.2511621839148575e-08
Local loss @ local epoch 4: 2.3841852225814364e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.74 seconds!
[tester] 
AGNewsMetric: acc=0.5169736842105264, hinge=9.090901483234607, ce=12.704614677429198
Local test acc @ epoch 111: 0.517
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 1.1126149956908193e-06
Local loss @ local epoch 1: 1.1126170420538983e-06
Local loss @ local epoch 2: 8.245298772635579e-07
Local loss @ local epoch 3: 6.457163976847369e-07
Local loss @ local epoch 4: 4.172321723672212e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.94 seconds!
[tester] 
AGNewsMetric: acc=0.575, hinge=6.723524124245895, ce=12.116957913448935
Local test acc @ epoch 111: 0.575
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0002538888656999916
Local loss @ local epoch 1: 0.00021830867626704276
Local loss @ local epoch 2: 0.0004697158292401582
Local loss @ local epoch 3: 0.00024295342154800892
Local loss @ local epoch 4: 0.0005885467398911715
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.46 seconds!
[tester] 
AGNewsMetric: acc=0.7926315789473685, hinge=2.7676250206796746, ce=9.630299524006091
Local test acc @ epoch 111: 0.7926
Global evaluate on test data...
Evaluate data in 124.0 seconds!
[tester] 
AGNewsMetric: acc=0.8171052631578948, hinge=1.9367359276821738, ce=8.869455927798622
Global test acc @ epoch 111: 0.8171
Global epoch 112...
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 7.778355211485177e-06
Local loss @ local epoch 1: 0.00010980208026012406
Local loss @ local epoch 2: 9.536729521641973e-07
Local loss @ local epoch 3: 4.738555162475677e-06
Local loss @ local epoch 4: 2.831211531884037e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.28 seconds!
[tester] 
AGNewsMetric: acc=0.6519736842105263, hinge=5.1880362375159015, ce=10.169942922090229
Local test acc @ epoch 112: 0.652
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 1.226949691772461
Local loss @ local epoch 1: 0.0413556806743145
Local loss @ local epoch 2: 1.460310272705101e-06
Local loss @ local epoch 3: 1.41064083436504e-06
Local loss @ local epoch 4: 3.953744453610852e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.61 seconds!
[tester] 
AGNewsMetric: acc=0.4843421052631579, hinge=9.73048849181125, ce=12.556253625970138
Local test acc @ epoch 112: 0.4843
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.01144313532859087
Local loss @ local epoch 1: 0.0011417075293138623
Local loss @ local epoch 2: 0.0007305725594051182
Local loss @ local epoch 3: 0.001384800300002098
Local loss @ local epoch 4: 0.004553615115582943
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.89 seconds!
[tester] 
AGNewsMetric: acc=0.31934210526315787, hinge=6.63694849114669, ce=13.643564955058851
Local test acc @ epoch 112: 0.3193
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.6631581783294678
Local loss @ local epoch 1: 0.0007048569386824965
Local loss @ local epoch 2: 0.0008147985790856183
Local loss @ local epoch 3: 0.0012876533437520266
Local loss @ local epoch 4: 0.0010327347554266453
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.89 seconds!
[tester] 
AGNewsMetric: acc=0.5148684210526315, hinge=7.340738439058002, ce=12.64382064819336
Local test acc @ epoch 112: 0.5149
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 1.668929883180681e-07
Local loss @ local epoch 1: 2.384185648907078e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.25 seconds!
[tester] 
AGNewsMetric: acc=0.5852631578947368, hinge=5.549279104533948, ce=9.141264371370015
Local test acc @ epoch 112: 0.5853
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 1.1539125442504883
Local loss @ local epoch 1: 3.028800529136788e-05
Local loss @ local epoch 2: 1.018696366372751e-06
Local loss @ local epoch 3: 4.735768015962094e-06
Local loss @ local epoch 4: 1.0728828101491672e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.03 seconds!
[tester] 
AGNewsMetric: acc=0.5981578947368421, hinge=5.480810117721558, ce=11.159654952601382
Local test acc @ epoch 112: 0.5982
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.5100919604301453
Local loss @ local epoch 1: 0.0007204127032309771
Local loss @ local epoch 2: 0.227495014667511
Local loss @ local epoch 3: 0.0029585426673293114
Local loss @ local epoch 4: 0.00034180449438281357
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.67 seconds!
[tester] 
AGNewsMetric: acc=0.5882894736842105, hinge=5.052792537086888, ce=10.337838074533563
Local test acc @ epoch 112: 0.5883
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.039983998984098434
Local loss @ local epoch 1: 0.003721279324963689
Local loss @ local epoch 2: 5.563043941947399e-06
Local loss @ local epoch 3: 6.1193436522444244e-06
Local loss @ local epoch 4: 0.000407869229093194
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.88 seconds!
[tester] 
AGNewsMetric: acc=0.5198684210526315, hinge=7.587831134043242, ce=12.450720154611687
Local test acc @ epoch 112: 0.5199
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.000683117366861552
Local loss @ local epoch 1: 0.0009525122004561126
Local loss @ local epoch 2: 0.0008093244396150112
Local loss @ local epoch 3: 0.0011634606635197997
Local loss @ local epoch 4: 0.0006531151593662798
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.03 seconds!
[tester] 
AGNewsMetric: acc=0.6278947368421053, hinge=4.539224708958676, ce=11.530926254674007
Local test acc @ epoch 112: 0.6279
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 1.9763039350509644
Local loss @ local epoch 1: 0.0181582048535347
Local loss @ local epoch 2: 0.003114406019449234
Local loss @ local epoch 3: 0.004667941480875015
Local loss @ local epoch 4: 0.03722420707345009
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.12 seconds!
[tester] 
AGNewsMetric: acc=0.595657894736842, hinge=5.912908253920706, ce=11.744323399192409
Local test acc @ epoch 112: 0.5957
Global evaluate on test data...
Evaluate data in 124.56 seconds!
[tester] 
AGNewsMetric: acc=0.8330263157894737, hinge=2.0444808877141853, ce=8.955234864887439
Global test acc @ epoch 112: 0.833
Global epoch 113...
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 1.267951574845938e-06
Local loss @ local epoch 1: 7.586043437868284e-08
Local loss @ local epoch 2: 3.359532456670422e-07
Local loss @ local epoch 3: 6.502323657286979e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.7 seconds!
[tester] 
AGNewsMetric: acc=0.4726315789473684, hinge=11.54422913350557, ce=14.029634136400725
Local test acc @ epoch 113: 0.4726
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.017390543594956398
Local loss @ local epoch 1: 0.002923552878201008
Local loss @ local epoch 2: 0.04929785430431366
Local loss @ local epoch 3: 0.002184489509090781
Local loss @ local epoch 4: 0.00015159866597969085
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.8 seconds!
[tester] 
AGNewsMetric: acc=0.5997368421052631, hinge=5.160815983320537, ce=9.843064364383094
Local test acc @ epoch 113: 0.5997
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.02452564612030983
Local loss @ local epoch 1: 0.0020700350869446993
Local loss @ local epoch 2: 0.6043890118598938
Local loss @ local epoch 3: 0.0033636759035289288
Local loss @ local epoch 4: 0.017177995294332504
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.65 seconds!
[tester] 
AGNewsMetric: acc=0.7043421052631579, hinge=2.3458735433377718, ce=10.611944841083728
Local test acc @ epoch 113: 0.7043
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 8.642543434689287e-06
Local loss @ local epoch 1: 0.0006377680110745132
Local loss @ local epoch 2: 4.666657332563773e-05
Local loss @ local epoch 3: 2.712006562433089e-06
Local loss @ local epoch 4: 6.794886758143548e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.0 seconds!
[tester] 
AGNewsMetric: acc=0.6414473684210527, hinge=5.287005499036688, ce=11.054066471300628
Local test acc @ epoch 113: 0.6414
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 3.1237126677297056e-05
Local loss @ local epoch 1: 1.0629463531586225e-06
Local loss @ local epoch 2: 6.437116553570377e-06
Local loss @ local epoch 3: 2.7616545139608206e-06
Local loss @ local epoch 4: 0.0002877666265703738
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.02 seconds!
[tester] 
AGNewsMetric: acc=0.4768421052631579, hinge=11.095136343554447, ce=13.00199434983103
Local test acc @ epoch 113: 0.4768
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.06429976969957352
Local loss @ local epoch 1: 0.0005675847642123699
Local loss @ local epoch 2: 0.029806962236762047
Local loss @ local epoch 3: 0.00045272547868080437
Local loss @ local epoch 4: 0.0019453596323728561
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.11 seconds!
[tester] 
AGNewsMetric: acc=0.5546052631578947, hinge=3.6163345838847913, ce=7.3949636489466615
Local test acc @ epoch 113: 0.5546
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.049968186765909195
Local loss @ local epoch 1: 0.0036989354994148016
Local loss @ local epoch 2: 0.0007161099347285926
Local loss @ local epoch 3: 0.002484663622453809
Local loss @ local epoch 4: 0.00021899161220062524
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.28 seconds!
[tester] 
AGNewsMetric: acc=0.5503947368421053, hinge=5.682493810151753, ce=10.737099396555047
Local test acc @ epoch 113: 0.5504
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 2.821269845298957e-06
Local loss @ local epoch 1: 1.7583291764822206e-06
Local loss @ local epoch 2: 7.251889542203571e-07
Local loss @ local epoch 3: 4.539776909950888e-06
Local loss @ local epoch 4: 1.2814958836315782e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.82 seconds!
[tester] 
AGNewsMetric: acc=0.780921052631579, hinge=2.729967618239553, ce=8.821279094093724
Local test acc @ epoch 113: 0.7809
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 9.536742595628311e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.3841846541472478e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.74 seconds!
[tester] 
AGNewsMetric: acc=0.8023684210526316, hinge=2.5678297155781795, ce=9.546081020957546
Local test acc @ epoch 113: 0.8024
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.002794144209474325
Local loss @ local epoch 1: 0.009169709868729115
Local loss @ local epoch 2: 0.023824991658329964
Local loss @ local epoch 3: 9.704349213279784e-05
Local loss @ local epoch 4: 6.250962906051427e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.28 seconds!
[tester] 
AGNewsMetric: acc=0.8465789473684211, hinge=1.8029838940971776, ce=8.943874698438142
Local test acc @ epoch 113: 0.8466
Global evaluate on test data...
Evaluate data in 124.62 seconds!
[tester] 
AGNewsMetric: acc=0.853421052631579, hinge=1.7562858561465615, ce=8.90546575847425
Global test acc @ epoch 113: 0.8534
Global epoch 114...
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.5041628479957581
Local loss @ local epoch 1: 0.00020929446327500045
Local loss @ local epoch 2: 0.03439858928322792
Local loss @ local epoch 3: 0.00114448182284832
Local loss @ local epoch 4: 0.002714649075642228
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.75 seconds!
[tester] 
AGNewsMetric: acc=0.6268421052631579, hinge=6.3503853592119714, ce=10.711060134486148
Local test acc @ epoch 114: 0.6268
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.00014771657879464328
Local loss @ local epoch 1: 4.172293756710133e-06
Local loss @ local epoch 2: 1.2278395843168255e-05
Local loss @ local epoch 3: 1.8923919924418442e-05
Local loss @ local epoch 4: 1.3947285879112314e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.51 seconds!
[tester] 
AGNewsMetric: acc=0.7044736842105264, hinge=3.504699659096567, ce=10.402859127646998
Local test acc @ epoch 114: 0.7045
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.014114612713456154
Local loss @ local epoch 1: 0.00013490601850207895
Local loss @ local epoch 2: 0.00021635115263052285
Local loss @ local epoch 3: 5.5402470025001094e-05
Local loss @ local epoch 4: 0.0004733823298010975
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.72 seconds!
[tester] 
AGNewsMetric: acc=0.5952631578947368, hinge=7.090785441147654, ce=11.845699201885022
Local test acc @ epoch 114: 0.5953
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.018816092982888222
Local loss @ local epoch 1: 1.2218926030982402e-06
Local loss @ local epoch 2: 3.9736414692015387e-07
Local loss @ local epoch 3: 2.8808901220145344e-07
Local loss @ local epoch 4: 8.970379894890357e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.29 seconds!
[tester] 
AGNewsMetric: acc=0.4030263157894737, hinge=14.32832520836278, ce=14.6538917320653
Local test acc @ epoch 114: 0.403
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0005265643703751266
Local loss @ local epoch 1: 0.0037479607854038477
Local loss @ local epoch 2: 0.0001654080842854455
Local loss @ local epoch 3: 0.02977282553911209
Local loss @ local epoch 4: 0.0010783056495711207
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.07 seconds!
[tester] 
AGNewsMetric: acc=0.5089473684210526, hinge=5.183018139287045, ce=11.562668169925088
Local test acc @ epoch 114: 0.5089
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0031041319016367197
Local loss @ local epoch 1: 1.5019165402918588e-05
Local loss @ local epoch 2: 1.696975050435867e-05
Local loss @ local epoch 3: 1.6991865777526982e-05
Local loss @ local epoch 4: 1.3979638424643781e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.8 seconds!
[tester] 
AGNewsMetric: acc=0.44105263157894736, hinge=11.418673217171117, ce=12.777397472983912
Local test acc @ epoch 114: 0.4411
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 1.4305112472356996e-07
Local loss @ local epoch 1: 2.384185648907078e-08
Local loss @ local epoch 2: 6.675709869341517e-07
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.73 seconds!
[tester] 
AGNewsMetric: acc=0.7443421052631579, hinge=3.3915973876651964, ce=9.464052152131734
Local test acc @ epoch 114: 0.7443
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 1.0389453172683716
Local loss @ local epoch 1: 0.00035676753032021224
Local loss @ local epoch 2: 0.0005076864617876709
Local loss @ local epoch 3: 0.5666290521621704
Local loss @ local epoch 4: 0.8214423656463623
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.65 seconds!
[tester] 
AGNewsMetric: acc=0.6227631578947368, hinge=5.332009191513062, ce=10.855884005897924
Local test acc @ epoch 114: 0.6228
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 4.9217978812521324e-05
Local loss @ local epoch 1: 1.2456544027372729e-05
Local loss @ local epoch 2: 3.89414935852983e-06
Local loss @ local epoch 3: 7.738512067589909e-06
Local loss @ local epoch 4: 0.0006171745480969548
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.84 seconds!
[tester] 
AGNewsMetric: acc=0.6686842105263158, hinge=5.36382673740387, ce=10.738270892093055
Local test acc @ epoch 114: 0.6687
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0028202603571116924
Local loss @ local epoch 1: 0.002686456311494112
Local loss @ local epoch 2: 0.0011587485205382109
Local loss @ local epoch 3: 0.0003677816712297499
Local loss @ local epoch 4: 0.001688531949184835
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.35 seconds!
[tester] 
AGNewsMetric: acc=0.7567105263157895, hinge=3.0536887337032117, ce=10.29177348287482
Local test acc @ epoch 114: 0.7567
Global evaluate on test data...
Evaluate data in 124.02 seconds!
[tester] 
AGNewsMetric: acc=0.7877631578947368, hinge=2.8898130093122782, ce=8.732328633760151
Global test acc @ epoch 114: 0.7878
Global epoch 115...
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 4.380910013424e-06
Local loss @ local epoch 1: 1.1622877309491741e-06
Local loss @ local epoch 2: 6.556490461662179e-07
Local loss @ local epoch 3: 8.562792572774924e-06
Local loss @ local epoch 4: 4.172323713191872e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.27 seconds!
[tester] 
AGNewsMetric: acc=0.805921052631579, hinge=2.5005540355883147, ce=9.001457579763311
Local test acc @ epoch 115: 0.8059
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 1.2319573163986206
Local loss @ local epoch 1: 0.03160965070128441
Local loss @ local epoch 2: 0.0026982666458934546
Local loss @ local epoch 3: 0.007301564794033766
Local loss @ local epoch 4: 0.010007922537624836
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.99 seconds!
[tester] 
AGNewsMetric: acc=0.7618421052631579, hinge=1.756727742395903, ce=6.61425881235223
Local test acc @ epoch 115: 0.7618
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.002145014237612486
Local loss @ local epoch 1: 0.0003419597342144698
Local loss @ local epoch 2: 0.00704999128356576
Local loss @ local epoch 3: 0.011460233479738235
Local loss @ local epoch 4: 0.0003493063850328326
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.32 seconds!
[tester] 
AGNewsMetric: acc=0.8072368421052631, hinge=1.801668818875363, ce=8.491423677143297
Local test acc @ epoch 115: 0.8072
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 9.753476888363366e-07
Local loss @ local epoch 1: 2.0590687199728563e-07
Local loss @ local epoch 2: 4.334883030310266e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.586042727325548e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.36 seconds!
[tester] 
AGNewsMetric: acc=0.5498684210526316, hinge=8.554130052265368, ce=12.090243235136333
Local test acc @ epoch 115: 0.5499
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.6817668080329895
Local loss @ local epoch 1: 0.00012331211473792791
Local loss @ local epoch 2: 4.1370625694980845e-05
Local loss @ local epoch 3: 0.001351353945210576
Local loss @ local epoch 4: 0.002685180865228176
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.29 seconds!
[tester] 
AGNewsMetric: acc=0.570921052631579, hinge=5.754535978216874, ce=10.826838975203664
Local test acc @ epoch 115: 0.5709
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.004667922388762236
Local loss @ local epoch 1: 0.0008112788200378418
Local loss @ local epoch 2: 0.0015631417045369744
Local loss @ local epoch 3: 0.00960633996874094
Local loss @ local epoch 4: 0.0031264887657016516
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.06 seconds!
[tester] 
AGNewsMetric: acc=0.595, hinge=3.7772813405488668, ce=11.542788611964175
Local test acc @ epoch 115: 0.595
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 1.0927491302936687e-06
Local loss @ local epoch 1: 6.159129384286643e-07
Local loss @ local epoch 2: 1.0331453950129799e-06
Local loss @ local epoch 3: 4.1723220078893064e-07
Local loss @ local epoch 4: 6.953874276405259e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.21 seconds!
[tester] 
AGNewsMetric: acc=0.5769736842105263, hinge=8.349724528664037, ce=11.288718580948679
Local test acc @ epoch 115: 0.577
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 2.3840742869651876e-05
Local loss @ local epoch 1: 1.2308069017308298e-05
Local loss @ local epoch 2: 3.24843313137535e-06
Local loss @ local epoch 3: 2.354374828428263e-06
Local loss @ local epoch 4: 1.6927249816944823e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.82 seconds!
[tester] 
AGNewsMetric: acc=0.6056578947368421, hinge=5.4058789722543015, ce=10.953993763170745
Local test acc @ epoch 115: 0.6057
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 4.768371297814156e-08
Local loss @ local epoch 1: 2.384185648907078e-08
Local loss @ local epoch 2: 2.384185648907078e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.31 seconds!
[tester] 
AGNewsMetric: acc=0.6751315789473684, hinge=5.243240691235191, ce=11.66444157249049
Local test acc @ epoch 115: 0.6751
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.49813559651374817
Local loss @ local epoch 1: 0.013613319955766201
Local loss @ local epoch 2: 0.0016882647760212421
Local loss @ local epoch 3: 1.6643853086861782e-05
Local loss @ local epoch 4: 5.215388227952644e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.05 seconds!
[tester] 
AGNewsMetric: acc=0.46092105263157895, hinge=8.025947835821855, ce=12.683160982633892
Local test acc @ epoch 115: 0.4609
Global evaluate on test data...
Evaluate data in 124.3 seconds!
[tester] 
AGNewsMetric: acc=0.8298684210526316, hinge=1.9784916897823936, ce=8.94951610364412
Global test acc @ epoch 115: 0.8299
Global epoch 116...
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.33185097575187683
Local loss @ local epoch 1: 4.46273188572377e-05
Local loss @ local epoch 2: 1.8677983462112024e-05
Local loss @ local epoch 3: 3.1571995350532234e-05
Local loss @ local epoch 4: 0.10469961911439896
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.42 seconds!
[tester] 
AGNewsMetric: acc=0.5375, hinge=7.530039260261937, ce=11.938926859403912
Local test acc @ epoch 116: 0.5375
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.3517618775367737
Local loss @ local epoch 1: 5.466174116008915e-05
Local loss @ local epoch 2: 4.243207513354719e-05
Local loss @ local epoch 3: 0.000218033223063685
Local loss @ local epoch 4: 0.00023441662779077888
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.03 seconds!
[tester] 
AGNewsMetric: acc=0.5823684210526315, hinge=6.33909336491635, ce=10.480918201647306
Local test acc @ epoch 116: 0.5824
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 1.1473000049591064
Local loss @ local epoch 1: 0.00025348321651108563
Local loss @ local epoch 2: 0.03586095944046974
Local loss @ local epoch 3: 0.007432847749441862
Local loss @ local epoch 4: 0.01453750766813755
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.69 seconds!
[tester] 
AGNewsMetric: acc=0.5968421052631578, hinge=6.87867708432047, ce=11.176847425761975
Local test acc @ epoch 116: 0.5968
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0005805755499750376
Local loss @ local epoch 1: 0.00019194086780771613
Local loss @ local epoch 2: 0.004099191632121801
Local loss @ local epoch 3: 0.0018160854233428836
Local loss @ local epoch 4: 0.000376390089513734
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 125.14 seconds!
[tester] 
AGNewsMetric: acc=0.5898684210526316, hinge=3.5850505111092015, ce=10.787930843955593
Local test acc @ epoch 116: 0.5899
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.01118497084826231
Local loss @ local epoch 1: 0.38594499230384827
Local loss @ local epoch 2: 0.009445474483072758
Local loss @ local epoch 3: 0.003255082992836833
Local loss @ local epoch 4: 0.013233920559287071
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.06 seconds!
[tester] 
AGNewsMetric: acc=0.7136842105263158, hinge=2.409570369469492, ce=7.799284101787366
Local test acc @ epoch 116: 0.7137
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 3.5762778338721546e-07
Local loss @ local epoch 1: 2.622603290092229e-07
Local loss @ local epoch 2: 7.152556236178498e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.4305111051271524e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.29 seconds!
[tester] 
AGNewsMetric: acc=0.7867105263157895, hinge=3.0641035893088895, ce=8.985574738351922
Local test acc @ epoch 116: 0.7867
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.03291025012731552
Local loss @ local epoch 1: 6.457079143729061e-05
Local loss @ local epoch 2: 1.890565727080684e-05
Local loss @ local epoch 3: 0.35194462537765503
Local loss @ local epoch 4: 0.00014035003550816327
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.89 seconds!
[tester] 
AGNewsMetric: acc=0.5861842105263158, hinge=6.691541211981522, ce=11.892766739694697
Local test acc @ epoch 116: 0.5862
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 1.084781797544565e-05
Local loss @ local epoch 1: 3.251259113312699e-05
Local loss @ local epoch 2: 1.1920915312657598e-06
Local loss @ local epoch 3: 2.6822026484296657e-06
Local loss @ local epoch 4: 1.4007059689902235e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.11 seconds!
[tester] 
AGNewsMetric: acc=0.6690789473684211, hinge=4.363014757758693, ce=10.377122079949629
Local test acc @ epoch 116: 0.6691
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.36517056822776794
Local loss @ local epoch 1: 6.725154889863916e-06
Local loss @ local epoch 2: 0.00024294230388477445
Local loss @ local epoch 3: 0.02457360364496708
Local loss @ local epoch 4: 0.01868622563779354
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.54 seconds!
[tester] 
AGNewsMetric: acc=0.5625, hinge=7.601448291477404, ce=11.548521814848247
Local test acc @ epoch 116: 0.5625
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.651566207408905
Local loss @ local epoch 1: 3.5563443816499785e-06
Local loss @ local epoch 2: 6.655841389147099e-07
Local loss @ local epoch 3: 3.278254041561013e-07
Local loss @ local epoch 4: 7.947266453811608e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.07 seconds!
[tester] 
AGNewsMetric: acc=0.4710526315789474, hinge=11.268712148164449, ce=13.06994793540553
Local test acc @ epoch 116: 0.4711
Global evaluate on test data...
Evaluate data in 122.96 seconds!
[tester] 
AGNewsMetric: acc=0.8457894736842105, hinge=2.1537109615928247, ce=8.779013975043046
Global test acc @ epoch 116: 0.8458
Global epoch 117...
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 3.831761205219664e-05
Local loss @ local epoch 1: 9.93410651517479e-08
Local loss @ local epoch 2: 1.0927517024583722e-07
Local loss @ local epoch 3: 3.285873754066415e-05
Local loss @ local epoch 4: 1.5795158105902374e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 122.87 seconds!
[tester] 
AGNewsMetric: acc=0.49592105263157893, hinge=11.085341374748632, ce=13.188901630200839
Local test acc @ epoch 117: 0.4959
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0020185986068099737
Local loss @ local epoch 1: 0.002784736454486847
Local loss @ local epoch 2: 0.002236643573269248
Local loss @ local epoch 3: 0.0001937533525051549
Local loss @ local epoch 4: 0.000274362915661186
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.11 seconds!
[tester] 
AGNewsMetric: acc=0.5723684210526315, hinge=4.1461694918180765, ce=9.7380413456967
Local test acc @ epoch 117: 0.5724
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.02073039673268795
Local loss @ local epoch 1: 0.0010479724733158946
Local loss @ local epoch 2: 0.00024263634986709803
Local loss @ local epoch 3: 0.001283370889723301
Local loss @ local epoch 4: 0.0002799674984999001
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.02 seconds!
[tester] 
AGNewsMetric: acc=0.45644736842105266, hinge=5.202261231071071, ce=11.900245672527113
Local test acc @ epoch 117: 0.4564
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 2.384185648907078e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.384185648907078e-08
Local loss @ local epoch 3: 2.384185648907078e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.89 seconds!
[tester] 
AGNewsMetric: acc=0.7897368421052632, hinge=2.4743210019563375, ce=9.88977172650789
Local test acc @ epoch 117: 0.7897
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0005503501161001623
Local loss @ local epoch 1: 0.000794443127233535
Local loss @ local epoch 2: 0.00031434959964826703
Local loss @ local epoch 3: 0.0013481704518198967
Local loss @ local epoch 4: 0.0005560783902183175
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.76 seconds!
[tester] 
AGNewsMetric: acc=0.6726315789473685, hinge=4.859867889504684, ce=9.605050456398411
Local test acc @ epoch 117: 0.6726
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 8.543320291209966e-07
Local loss @ local epoch 1: 4.3212280615989584e-06
Local loss @ local epoch 2: 2.1159542029636214e-06
Local loss @ local epoch 3: 9.963451702788007e-06
Local loss @ local epoch 4: 2.8808733532059705e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.14 seconds!
[tester] 
AGNewsMetric: acc=0.7702631578947369, hinge=3.113271464046679, ce=9.211577487744783
Local test acc @ epoch 117: 0.7703
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 1.3654837403009878e-06
Local loss @ local epoch 1: 1.9506970261318202e-07
Local loss @ local epoch 2: 2.167441515155133e-08
Local loss @ local epoch 3: 1.4088368516240735e-07
Local loss @ local epoch 4: 5.310226924848394e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.19 seconds!
[tester] 
AGNewsMetric: acc=0.4573684210526316, hinge=12.544418023260016, ce=13.087824385793585
Local test acc @ epoch 117: 0.4574
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 1.1116178939118981e-05
Local loss @ local epoch 1: 2.589721407275647e-05
Local loss @ local epoch 2: 7.899609772721305e-05
Local loss @ local epoch 3: 1.057968256645836e-05
Local loss @ local epoch 4: 1.9669500943564344e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.93 seconds!
[tester] 
AGNewsMetric: acc=0.7523684210526316, hinge=2.475169449103506, ce=9.534238409745067
Local test acc @ epoch 117: 0.7524
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.7868669033050537
Local loss @ local epoch 1: 0.05070994049310684
Local loss @ local epoch 2: 0.18373338878154755
Local loss @ local epoch 3: 0.0050118593499064445
Local loss @ local epoch 4: 0.0013759051216766238
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.76 seconds!
[tester] 
AGNewsMetric: acc=0.5234210526315789, hinge=4.878856126885665, ce=11.370812903956363
Local test acc @ epoch 117: 0.5234
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.28266677260398865
Local loss @ local epoch 1: 8.515871741110459e-05
Local loss @ local epoch 2: 0.009742976166307926
Local loss @ local epoch 3: 0.00010609989840304479
Local loss @ local epoch 4: 3.636880501289852e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.07 seconds!
[tester] 
AGNewsMetric: acc=0.5426315789473685, hinge=5.8306723935980544, ce=10.835935658906635
Local test acc @ epoch 117: 0.5426
Global evaluate on test data...
Evaluate data in 123.96 seconds!
[tester] 
AGNewsMetric: acc=0.8602631578947368, hinge=1.5449369749269988, ce=8.80506875690661
Global test acc @ epoch 117: 0.8603
Global epoch 118...
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 1.2814987258025212e-06
Local loss @ local epoch 1: 1.856621565821115e-05
Local loss @ local epoch 2: 7.748493771941867e-06
Local loss @ local epoch 3: 5.274973773339298e-06
Local loss @ local epoch 4: 1.1920907354578958e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.53 seconds!
[tester] 
AGNewsMetric: acc=0.75, hinge=2.7333858831305253, ce=7.750898570010537
Local test acc @ epoch 118: 0.75
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.001192515017464757
Local loss @ local epoch 1: 1.9181791230948875e-06
Local loss @ local epoch 2: 4.985113832844945e-07
Local loss @ local epoch 3: 3.8255057006608695e-06
Local loss @ local epoch 4: 4.280680514057167e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.75 seconds!
[tester] 
AGNewsMetric: acc=0.4648684210526316, hinge=10.40621952609012, ce=12.624990991291247
Local test acc @ epoch 118: 0.4649
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 4.4238524424145e-05
Local loss @ local epoch 1: 3.0398130093090003e-06
Local loss @ local epoch 2: 3.933836069336394e-06
Local loss @ local epoch 3: 1.7859856598079205e-05
Local loss @ local epoch 4: 2.9093536795699038e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.78 seconds!
[tester] 
AGNewsMetric: acc=0.5571052631578948, hinge=8.462882357647544, ce=12.40076941841527
Local test acc @ epoch 118: 0.5571
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.26357853412628174
Local loss @ local epoch 1: 7.659620314370841e-05
Local loss @ local epoch 2: 0.00022311315115075558
Local loss @ local epoch 3: 0.00019356378470547497
Local loss @ local epoch 4: 0.0003348941681906581
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.04 seconds!
[tester] 
AGNewsMetric: acc=0.5619736842105263, hinge=6.413031940962139, ce=11.799068250154194
Local test acc @ epoch 118: 0.562
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.6281996369361877
Local loss @ local epoch 1: 0.0011854177573695779
Local loss @ local epoch 2: 4.646532397600822e-05
Local loss @ local epoch 3: 0.007714301347732544
Local loss @ local epoch 4: 0.020839951932430267
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.54 seconds!
[tester] 
AGNewsMetric: acc=0.5235526315789474, hinge=8.262541670799255, ce=10.686015299746865
Local test acc @ epoch 118: 0.5236
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0885351374745369
Local loss @ local epoch 1: 2.602718495836598e-06
Local loss @ local epoch 2: 8.940682505453879e-07
Local loss @ local epoch 3: 7.0034534473961685e-06
Local loss @ local epoch 4: 2.0909681552438997e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.74 seconds!
[tester] 
AGNewsMetric: acc=0.48828947368421055, hinge=9.266879569605777, ce=11.944464530944824
Local test acc @ epoch 118: 0.4883
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0007256415556184947
Local loss @ local epoch 1: 0.008514503948390484
Local loss @ local epoch 2: 0.004079787526279688
Local loss @ local epoch 3: 0.0075666350312530994
Local loss @ local epoch 4: 0.0924730896949768
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.66 seconds!
[tester] 
AGNewsMetric: acc=0.6318421052631579, hinge=3.1925060879556755, ce=10.229282965409128
Local test acc @ epoch 118: 0.6318
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.001962309004738927
Local loss @ local epoch 1: 0.00033640829497016966
Local loss @ local epoch 2: 0.0006012842059135437
Local loss @ local epoch 3: 0.00022383517352864146
Local loss @ local epoch 4: 6.163150101201609e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.45 seconds!
[tester] 
AGNewsMetric: acc=0.6361842105263158, hinge=7.12857952519467, ce=11.342431672748766
Local test acc @ epoch 118: 0.6362
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0007366624777205288
Local loss @ local epoch 1: 9.92147033684887e-05
Local loss @ local epoch 2: 0.002580005442723632
Local loss @ local epoch 3: 0.00015582940250169486
Local loss @ local epoch 4: 5.078159665572457e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.69 seconds!
[tester] 
AGNewsMetric: acc=0.56, hinge=5.042665934311716, ce=10.558949400249281
Local test acc @ epoch 118: 0.56
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 4.768370942542788e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.95 seconds!
[tester] 
AGNewsMetric: acc=0.5977631578947369, hinge=7.074741515109413, ce=12.84096651779978
Local test acc @ epoch 118: 0.5978
Global evaluate on test data...
Evaluate data in 123.2 seconds!
[tester] 
AGNewsMetric: acc=0.8243421052631579, hinge=2.4539720987018785, ce=9.002061020700555
Global test acc @ epoch 118: 0.8243
Global epoch 119...
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.003217135090380907
Local loss @ local epoch 1: 0.008626671507954597
Local loss @ local epoch 2: 0.004280489403754473
Local loss @ local epoch 3: 0.0013589092995971441
Local loss @ local epoch 4: 0.21404854953289032
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.6 seconds!
[tester] 
AGNewsMetric: acc=0.6405263157894737, hinge=3.5618782901763915, ce=10.424608168351023
Local test acc @ epoch 119: 0.6405
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0008894114871509373
Local loss @ local epoch 1: 0.0006337095401249826
Local loss @ local epoch 2: 0.000204924275749363
Local loss @ local epoch 3: 0.039762742817401886
Local loss @ local epoch 4: 0.0005890072206966579
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.94 seconds!
[tester] 
AGNewsMetric: acc=0.6102631578947368, hinge=3.0694759494379946, ce=7.037324262920179
Local test acc @ epoch 119: 0.6103
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 2.6117422748939134e-06
Local loss @ local epoch 1: 8.019505912670866e-07
Local loss @ local epoch 2: 1.4088368516240735e-07
Local loss @ local epoch 3: 3.2511596259610087e-07
Local loss @ local epoch 4: 2.0590691462984978e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.6 seconds!
[tester] 
AGNewsMetric: acc=0.4305263157894737, hinge=13.765148496125875, ce=14.519813459295975
Local test acc @ epoch 119: 0.4305
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 9.53674117454284e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.53 seconds!
[tester] 
AGNewsMetric: acc=0.7857894736842105, hinge=2.7942463879836232, ce=10.095723997417249
Local test acc @ epoch 119: 0.7858
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.0894343852996826
Local loss @ local epoch 1: 0.4330644905567169
Local loss @ local epoch 2: 0.0016711298376321793
Local loss @ local epoch 3: 0.0002979289856739342
Local loss @ local epoch 4: 0.00015835305384825915
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.79 seconds!
[tester] 
AGNewsMetric: acc=0.5731578947368421, hinge=4.170438930360895, ce=9.708636952450401
Local test acc @ epoch 119: 0.5732
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.01236796285957098
Local loss @ local epoch 1: 6.264755938900635e-05
Local loss @ local epoch 2: 1.3225761651992798
Local loss @ local epoch 3: 0.002682298654690385
Local loss @ local epoch 4: 0.02554820105433464
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.52 seconds!
[tester] 
AGNewsMetric: acc=0.7786842105263158, hinge=3.0509238827855962, ce=9.514785403201454
Local test acc @ epoch 119: 0.7787
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 7.649251188013295e-07
Local loss @ local epoch 1: 1.887479044171414e-07
Local loss @ local epoch 2: 2.483526202468056e-07
Local loss @ local epoch 3: 1.768260062817717e-06
Local loss @ local epoch 4: 8.940694584680386e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.56 seconds!
[tester] 
AGNewsMetric: acc=0.5623684210526316, hinge=8.60944047400826, ce=12.324383878205952
Local test acc @ epoch 119: 0.5624
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 1.7583280396138434e-06
Local loss @ local epoch 1: 2.2053627617424354e-06
Local loss @ local epoch 2: 3.377594737230538e-07
Local loss @ local epoch 3: 3.6756162558049255e-07
Local loss @ local epoch 4: 3.7351464925450273e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.74 seconds!
[tester] 
AGNewsMetric: acc=0.7013157894736842, hinge=4.669596586227417, ce=9.379406750327663
Local test acc @ epoch 119: 0.7013
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 1.589787244796753
Local loss @ local epoch 1: 0.025004129856824875
Local loss @ local epoch 2: 0.04271687939763069
Local loss @ local epoch 3: 0.0033948493655771017
Local loss @ local epoch 4: 0.0001866171951405704
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.8 seconds!
[tester] 
AGNewsMetric: acc=0.626578947368421, hinge=4.482146029723318, ce=9.450953579952841
Local test acc @ epoch 119: 0.6266
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 2.354377556912368e-06
Local loss @ local epoch 1: 1.5795208128110971e-06
Local loss @ local epoch 2: 2.861013626898057e-06
Local loss @ local epoch 3: 2.2917020032764412e-05
Local loss @ local epoch 4: 5.2749742280866485e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.93 seconds!
[tester] 
AGNewsMetric: acc=0.6944736842105264, hinge=3.735848022762098, ce=9.90755587326853
Local test acc @ epoch 119: 0.6945
Global evaluate on test data...
Evaluate data in 124.85 seconds!
[tester] 
AGNewsMetric: acc=0.859078947368421, hinge=1.6847049567573948, ce=8.834398865950735
Global test acc @ epoch 119: 0.8591
Global epoch 120...
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.00036846764851361513
Local loss @ local epoch 1: 0.0003979600442107767
Local loss @ local epoch 2: 9.635215246817097e-05
Local loss @ local epoch 3: 0.0002890464093070477
Local loss @ local epoch 4: 0.0012155375443398952
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.8 seconds!
[tester] 
AGNewsMetric: acc=0.5313157894736842, hinge=6.697650968652023, ce=12.812339676304868
Local test acc @ epoch 120: 0.5313
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 2.000679523916915e-05
Local loss @ local epoch 1: 9.934088893714943e-07
Local loss @ local epoch 2: 1.7086545085476246e-06
Local loss @ local epoch 3: 0.437165766954422
Local loss @ local epoch 4: 5.413952749222517e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.96 seconds!
[tester] 
AGNewsMetric: acc=0.7359210526315789, hinge=4.137147249422576, ce=10.064306560315584
Local test acc @ epoch 120: 0.7359
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 8.642527063784655e-06
Local loss @ local epoch 1: 1.07288167328079e-06
Local loss @ local epoch 2: 6.25842312729219e-06
Local loss @ local epoch 3: 7.748534699203447e-06
Local loss @ local epoch 4: 2.2947738216316793e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.36 seconds!
[tester] 
AGNewsMetric: acc=0.6832894736842106, hinge=4.439430051853782, ce=10.507641573454205
Local test acc @ epoch 120: 0.6833
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.00183293002191931
Local loss @ local epoch 1: 7.586029937556305e-07
Local loss @ local epoch 2: 9.10321375613421e-07
Local loss @ local epoch 3: 7.586044858953755e-08
Local loss @ local epoch 4: 2.0198445781716146e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.22 seconds!
[tester] 
AGNewsMetric: acc=0.47157894736842104, hinge=11.82743278101871, ce=12.522461447464792
Local test acc @ epoch 120: 0.4716
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 7.152556946721234e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.9073476664743794e-07
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.46 seconds!
[tester] 
AGNewsMetric: acc=0.8025, hinge=2.4092037439346314, ce=10.012659554732473
Local test acc @ epoch 120: 0.8025
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.0007282179431058466
Local loss @ local epoch 1: 0.0014517134986817837
Local loss @ local epoch 2: 0.0037321916315704584
Local loss @ local epoch 3: 7.261829887283966e-05
Local loss @ local epoch 4: 0.0015109297819435596
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.02 seconds!
[tester] 
AGNewsMetric: acc=0.7131578947368421, hinge=2.9692072577225535, ce=10.120364094784385
Local test acc @ epoch 120: 0.7132
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.3736822009086609
Local loss @ local epoch 1: 2.2261399863054976e-05
Local loss @ local epoch 2: 8.166610496118665e-05
Local loss @ local epoch 3: 0.0006352548371069133
Local loss @ local epoch 4: 0.00023954370408318937
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.43 seconds!
[tester] 
AGNewsMetric: acc=0.5506578947368421, hinge=6.374504625922755, ce=12.225242393895199
Local test acc @ epoch 120: 0.5507
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.38466933369636536
Local loss @ local epoch 1: 0.006639805622398853
Local loss @ local epoch 2: 0.013818872161209583
Local loss @ local epoch 3: 0.25450026988983154
Local loss @ local epoch 4: 0.0007750173681415617
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.74 seconds!
[tester] 
AGNewsMetric: acc=0.7193421052631579, hinge=3.3355985360396536, ce=9.095827664827045
Local test acc @ epoch 120: 0.7193
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.2606147825717926
Local loss @ local epoch 1: 2.461487201799173e-05
Local loss @ local epoch 2: 2.920590304711368e-06
Local loss @ local epoch 3: 1.2914315448142588e-06
Local loss @ local epoch 4: 0.00014475367788691074
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.49 seconds!
[tester] 
AGNewsMetric: acc=0.5694736842105264, hinge=7.405969301273949, ce=12.257789666025262
Local test acc @ epoch 120: 0.5695
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.009048429317772388
Local loss @ local epoch 1: 0.07351293414831161
Local loss @ local epoch 2: 0.05633413419127464
Local loss @ local epoch 3: 0.032985713332891464
Local loss @ local epoch 4: 0.02393629588186741
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.88 seconds!
[tester] 
AGNewsMetric: acc=0.7698684210526315, hinge=1.8280832064779182, ce=8.39413731022885
Local test acc @ epoch 120: 0.7699
Global evaluate on test data...
Evaluate data in 123.89 seconds!
[tester] 
AGNewsMetric: acc=0.8536842105263158, hinge=1.8891003756774098, ce=8.66346422898142
Global test acc @ epoch 120: 0.8537
Global epoch 121...
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.005107576493173838
Local loss @ local epoch 1: 0.09672928601503372
Local loss @ local epoch 2: 0.0028285644948482513
Local loss @ local epoch 3: 0.0007461975328624249
Local loss @ local epoch 4: 0.001004067831672728
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.73 seconds!
[tester] 
AGNewsMetric: acc=0.6073684210526316, hinge=2.7252880743930215, ce=10.48585496400532
Local test acc @ epoch 121: 0.6074
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.2962460517883301
Local loss @ local epoch 1: 0.0012334957718849182
Local loss @ local epoch 2: 0.0005192492390051484
Local loss @ local epoch 3: 7.11682514520362e-05
Local loss @ local epoch 4: 0.00020414569007698447
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.63 seconds!
[tester] 
AGNewsMetric: acc=0.6261842105263158, hinge=3.84754370287845, ce=8.409458869130988
Local test acc @ epoch 121: 0.6262
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.834549605846405
Local loss @ local epoch 1: 0.00024290996952913702
Local loss @ local epoch 2: 1.81634932232555e-05
Local loss @ local epoch 3: 6.48176910544862e-06
Local loss @ local epoch 4: 1.4222375284589361e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.38 seconds!
[tester] 
AGNewsMetric: acc=0.48526315789473684, hinge=8.271832947981984, ce=13.285923500061035
Local test acc @ epoch 121: 0.4853
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 6.238475179998204e-06
Local loss @ local epoch 1: 1.4404373587240116e-06
Local loss @ local epoch 2: 1.0828160839082557e-06
Local loss @ local epoch 3: 8.05627951194765e-06
Local loss @ local epoch 4: 7.251892952808703e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.28 seconds!
[tester] 
AGNewsMetric: acc=0.6339473684210526, hinge=5.383643724039981, ce=9.805718203092876
Local test acc @ epoch 121: 0.6339
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 3.476936001334252e-07
Local loss @ local epoch 1: 5.662257990479702e-06
Local loss @ local epoch 2: 9.934106870446158e-09
Local loss @ local epoch 3: 1.4901158351676713e-07
Local loss @ local epoch 4: 6.953874276405259e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.51 seconds!
[tester] 
AGNewsMetric: acc=0.775, hinge=3.5094945694270887, ce=9.72221562234979
Local test acc @ epoch 121: 0.775
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 4.2915326048387215e-07
Local loss @ local epoch 1: 2.384185648907078e-08
Local loss @ local epoch 2: 2.384185648907078e-08
Local loss @ local epoch 3: 1.4305109630186053e-07
Local loss @ local epoch 4: 4.768371297814156e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.6 seconds!
[tester] 
AGNewsMetric: acc=0.5310526315789473, hinge=7.316490917205811, ce=10.687846352426629
Local test acc @ epoch 121: 0.5311
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.01513804029673338
Local loss @ local epoch 1: 0.001740400679409504
Local loss @ local epoch 2: 0.00265027629211545
Local loss @ local epoch 3: 0.014764869585633278
Local loss @ local epoch 4: 0.0013015670701861382
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.38 seconds!
[tester] 
AGNewsMetric: acc=0.48355263157894735, hinge=4.664546743694105, ce=12.188337165430973
Local test acc @ epoch 121: 0.4836
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.00043200558866374195
Local loss @ local epoch 1: 0.00011186752817593515
Local loss @ local epoch 2: 0.0013242170680314302
Local loss @ local epoch 3: 0.0002983814338222146
Local loss @ local epoch 4: 0.0008071442716754973
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.62 seconds!
[tester] 
AGNewsMetric: acc=0.7325, hinge=3.6702763248744765, ce=10.348890017459267
Local test acc @ epoch 121: 0.7325
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 1.8423157825964154e-06
Local loss @ local epoch 1: 3.251158773309726e-07
Local loss @ local epoch 2: 1.517208971790751e-07
Local loss @ local epoch 3: 2.9260448286549945e-07
Local loss @ local epoch 4: 2.0590688620814035e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.29 seconds!
[tester] 
AGNewsMetric: acc=0.4276315789473684, hinge=12.34549341051202, ce=14.46154860647101
Local test acc @ epoch 121: 0.4276
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 4.559730768960435e-06
Local loss @ local epoch 1: 8.791585969447624e-06
Local loss @ local epoch 2: 7.241905223054346e-06
Local loss @ local epoch 3: 4.7683681714261184e-07
Local loss @ local epoch 4: 5.811420123791322e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.02 seconds!
[tester] 
AGNewsMetric: acc=0.7151315789473685, hinge=3.2286402202907363, ce=9.52927077443976
Local test acc @ epoch 121: 0.7151
Global evaluate on test data...
Evaluate data in 124.22 seconds!
[tester] 
AGNewsMetric: acc=0.8380263157894737, hinge=1.909589366410908, ce=9.01737376765201
Global test acc @ epoch 121: 0.838
Global epoch 122...
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0034851953387260437
Local loss @ local epoch 1: 2.086161856595936e-07
Local loss @ local epoch 2: 6.457158292505483e-07
Local loss @ local epoch 3: 4.1723231447576836e-07
Local loss @ local epoch 4: 7.251888405335194e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.49 seconds!
[tester] 
AGNewsMetric: acc=0.4635526315789474, hinge=11.4849492953953, ce=12.095662058780068
Local test acc @ epoch 122: 0.4636
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.008648033253848553
Local loss @ local epoch 1: 0.027346814051270485
Local loss @ local epoch 2: 0.8645676970481873
Local loss @ local epoch 3: 0.2630248963832855
Local loss @ local epoch 4: 0.08415216952562332
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.54 seconds!
[tester] 
AGNewsMetric: acc=0.8205263157894737, hinge=1.3500446768810874, ce=9.525483037045127
Local test acc @ epoch 122: 0.8205
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.005109038203954697
Local loss @ local epoch 1: 8.127889827846957e-07
Local loss @ local epoch 2: 1.3979937421026989e-06
Local loss @ local epoch 3: 2.622588226586231e-06
Local loss @ local epoch 4: 3.164449481118936e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.55 seconds!
[tester] 
AGNewsMetric: acc=0.4231578947368421, hinge=11.081724783244885, ce=13.576505502399645
Local test acc @ epoch 122: 0.4232
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 2.294772230015951e-06
Local loss @ local epoch 1: 3.874300205097825e-07
Local loss @ local epoch 2: 1.75833270077419e-06
Local loss @ local epoch 3: 4.023283509013709e-06
Local loss @ local epoch 4: 7.450576049450319e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.21 seconds!
[tester] 
AGNewsMetric: acc=0.6688157894736843, hinge=4.7907770877135425, ce=10.484308766816792
Local test acc @ epoch 122: 0.6688
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 7.69207690609619e-05
Local loss @ local epoch 1: 2.483525349816773e-07
Local loss @ local epoch 2: 2.880890690448723e-07
Local loss @ local epoch 3: 0.008115646429359913
Local loss @ local epoch 4: 8.046617949730717e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.43 seconds!
[tester] 
AGNewsMetric: acc=0.7825, hinge=2.8108059115158883, ce=9.150058989273875
Local test acc @ epoch 122: 0.7825
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 7.152556236178498e-08
Local loss @ local epoch 1: 4.768370942542788e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 4.768371297814156e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.22 seconds!
[tester] 
AGNewsMetric: acc=0.656578947368421, hinge=5.200830943960892, ce=10.771173914859169
Local test acc @ epoch 122: 0.6566
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.02431229129433632
Local loss @ local epoch 1: 0.0018394103972241282
Local loss @ local epoch 2: 2.6536459699855186e-05
Local loss @ local epoch 3: 0.00015588942915201187
Local loss @ local epoch 4: 0.00022760152933187783
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.31 seconds!
[tester] 
AGNewsMetric: acc=0.5660526315789474, hinge=6.012746208090531, ce=12.153092402407998
Local test acc @ epoch 122: 0.5661
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.007783959154039621
Local loss @ local epoch 1: 0.0012958678416907787
Local loss @ local epoch 2: 0.0031087230890989304
Local loss @ local epoch 3: 0.0008587327320128679
Local loss @ local epoch 4: 0.0007467434625141323
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.95 seconds!
[tester] 
AGNewsMetric: acc=0.5230263157894737, hinge=3.7263396544205514, ce=9.983000857704564
Local test acc @ epoch 122: 0.523
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.04476170986890793
Local loss @ local epoch 1: 0.0002576290862634778
Local loss @ local epoch 2: 0.34312379360198975
Local loss @ local epoch 3: 0.0024497362319380045
Local loss @ local epoch 4: 0.00019427786173764616
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.88 seconds!
[tester] 
AGNewsMetric: acc=0.7842105263157895, hinge=2.9905291805769267, ce=9.035705010263543
Local test acc @ epoch 122: 0.7842
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.02437874861061573
Local loss @ local epoch 1: 3.856293551507406e-05
Local loss @ local epoch 2: 0.00030534787219949067
Local loss @ local epoch 3: 0.29339417815208435
Local loss @ local epoch 4: 0.0016364422626793385
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.89 seconds!
[tester] 
AGNewsMetric: acc=0.6292105263157894, hinge=5.000769532605221, ce=10.187856702302632
Local test acc @ epoch 122: 0.6292
Global evaluate on test data...
Evaluate data in 123.99 seconds!
[tester] 
AGNewsMetric: acc=0.8355263157894737, hinge=2.2295576057936017, ce=8.65448366667095
Global test acc @ epoch 122: 0.8355
Global epoch 123...
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 3.894121164194075e-06
Local loss @ local epoch 1: 1.3907747131725046e-07
Local loss @ local epoch 2: 1.490115550950577e-07
Local loss @ local epoch 3: 7.152549983402423e-07
Local loss @ local epoch 4: 2.682207878024201e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.58 seconds!
[tester] 
AGNewsMetric: acc=0.43526315789473685, hinge=14.09769784525821, ce=13.344072123075787
Local test acc @ epoch 123: 0.4353
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.1459721475839615
Local loss @ local epoch 1: 0.0009938139701262116
Local loss @ local epoch 2: 0.0006753740599378943
Local loss @ local epoch 3: 0.0017635097028687596
Local loss @ local epoch 4: 0.00019639256061054766
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.21 seconds!
[tester] 
AGNewsMetric: acc=0.7068421052631579, hinge=3.667520297953957, ce=10.631112937927247
Local test acc @ epoch 123: 0.7068
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.004672081209719181
Local loss @ local epoch 1: 0.00246699177660048
Local loss @ local epoch 2: 0.002059861086308956
Local loss @ local epoch 3: 0.0022771426010876894
Local loss @ local epoch 4: 0.0006348959868773818
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.24 seconds!
[tester] 
AGNewsMetric: acc=0.5027631578947368, hinge=4.940820166437249, ce=12.050167764362536
Local test acc @ epoch 123: 0.5028
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 1.2516949254859355e-06
Local loss @ local epoch 1: 2.4139826564351097e-06
Local loss @ local epoch 2: 7.569683930341853e-06
Local loss @ local epoch 3: 2.7716043859982165e-06
Local loss @ local epoch 4: 1.9669500943564344e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.02 seconds!
[tester] 
AGNewsMetric: acc=0.6548684210526315, hinge=4.5228954264992165, ce=9.528621685630396
Local test acc @ epoch 123: 0.6549
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 1.1920927533992653e-07
Local loss @ local epoch 1: 9.53674117454284e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.27 seconds!
[tester] 
AGNewsMetric: acc=0.579078947368421, hinge=5.4022900947771575, ce=11.023217795522589
Local test acc @ epoch 123: 0.5791
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.41782456636428833
Local loss @ local epoch 1: 0.00034345343010500073
Local loss @ local epoch 2: 0.0012541089672595263
Local loss @ local epoch 3: 0.00014432237367145717
Local loss @ local epoch 4: 6.775215297238901e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.79 seconds!
[tester] 
AGNewsMetric: acc=0.5164473684210527, hinge=6.222309054826435, ce=11.687127097280403
Local test acc @ epoch 123: 0.5164
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 2.3841852225814364e-07
Local loss @ local epoch 1: 4.334883030310266e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.167441337519449e-08
Local loss @ local epoch 4: 2.167441515155133e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.41 seconds!
[tester] 
AGNewsMetric: acc=0.5714473684210526, hinge=8.40977929466649, ce=11.10263506738763
Local test acc @ epoch 123: 0.5714
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0015572196571156383
Local loss @ local epoch 1: 0.009816466830670834
Local loss @ local epoch 2: 0.0022043653298169374
Local loss @ local epoch 3: 0.0009034070535562932
Local loss @ local epoch 4: 0.0048246849328279495
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.0 seconds!
[tester] 
AGNewsMetric: acc=0.5582894736842106, hinge=3.7617663388503226, ce=11.026321752447831
Local test acc @ epoch 123: 0.5583
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 5.861113550054142e-07
Local loss @ local epoch 1: 3.0795717975706793e-07
Local loss @ local epoch 2: 7.549897418357432e-07
Local loss @ local epoch 3: 3.6756182453245856e-07
Local loss @ local epoch 4: 3.576276412786683e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.58 seconds!
[tester] 
AGNewsMetric: acc=0.7777631578947368, hinge=3.3727740992997823, ce=8.724781753138492
Local test acc @ epoch 123: 0.7778
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.00048636633437126875
Local loss @ local epoch 1: 0.032306987792253494
Local loss @ local epoch 2: 0.00033702448126859963
Local loss @ local epoch 3: 0.004753740504384041
Local loss @ local epoch 4: 0.010443618521094322
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.63 seconds!
[tester] 
AGNewsMetric: acc=0.633421052631579, hinge=5.688592402809545, ce=10.089439725373921
Local test acc @ epoch 123: 0.6334
Global evaluate on test data...
Evaluate data in 124.33 seconds!
[tester] 
AGNewsMetric: acc=0.8532894736842105, hinge=1.7527141681470368, ce=8.910600971422697
Global test acc @ epoch 123: 0.8533
Global epoch 124...
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.34468650817871094
Local loss @ local epoch 1: 0.005371117498725653
Local loss @ local epoch 2: 0.00033858802635222673
Local loss @ local epoch 3: 0.0009712594328448176
Local loss @ local epoch 4: 0.0005681973416358232
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.49 seconds!
[tester] 
AGNewsMetric: acc=0.5444736842105263, hinge=8.937321259348016, ce=11.91277403982062
Local test acc @ epoch 124: 0.5445
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 1.0579632544249762e-05
Local loss @ local epoch 1: 5.0365456445433665e-06
Local loss @ local epoch 2: 2.2947704110265477e-06
Local loss @ local epoch 3: 3.2782359085103963e-06
Local loss @ local epoch 4: 1.7583337239557295e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.44 seconds!
[tester] 
AGNewsMetric: acc=0.628421052631579, hinge=5.094704177756059, ce=10.313838705765574
Local test acc @ epoch 124: 0.6284
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.007919961586594582
Local loss @ local epoch 1: 1.1920926823449918e-07
Local loss @ local epoch 2: 9.211591418534226e-07
Local loss @ local epoch 3: 9.861840908342856e-07
Local loss @ local epoch 4: 1.3004647314573958e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.79 seconds!
[tester] 
AGNewsMetric: acc=0.4176315789473684, hinge=13.746471364874589, ce=13.206234794415925
Local test acc @ epoch 124: 0.4176
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.002255728468298912
Local loss @ local epoch 1: 0.05470552295446396
Local loss @ local epoch 2: 0.002108921529725194
Local loss @ local epoch 3: 0.011088098399341106
Local loss @ local epoch 4: 0.009107817895710468
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.78 seconds!
[tester] 
AGNewsMetric: acc=0.7978947368421052, hinge=2.272709043653388, ce=9.366596631501851
Local test acc @ epoch 124: 0.7979
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.005529196932911873
Local loss @ local epoch 1: 1.0430782140247175e-06
Local loss @ local epoch 2: 1.7086513253161684e-06
Local loss @ local epoch 3: 0.6806963086128235
Local loss @ local epoch 4: 1.4145028217171784e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.62 seconds!
[tester] 
AGNewsMetric: acc=0.7725, hinge=3.4807784158305117, ce=9.32588413439299
Local test acc @ epoch 124: 0.7725
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.200099378824234
Local loss @ local epoch 1: 9.518791193841025e-05
Local loss @ local epoch 2: 0.00011527624155860394
Local loss @ local epoch 3: 2.3919554223539308e-05
Local loss @ local epoch 4: 4.594403799274005e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.39 seconds!
[tester] 
AGNewsMetric: acc=0.5715789473684211, hinge=6.6308455296566615, ce=11.39070571497867
Local test acc @ epoch 124: 0.5716
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.12525640428066254
Local loss @ local epoch 1: 1.670766323513817e-05
Local loss @ local epoch 2: 1.1424206149968086e-06
Local loss @ local epoch 3: 1.6093189287857967e-06
Local loss @ local epoch 4: 5.751797743869247e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.49 seconds!
[tester] 
AGNewsMetric: acc=0.4769736842105263, hinge=9.798767975255062, ce=10.90117032000893
Local test acc @ epoch 124: 0.477
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.000825617229565978
Local loss @ local epoch 1: 0.0001383100898237899
Local loss @ local epoch 2: 0.0017837329069152474
Local loss @ local epoch 3: 0.0026892477180808783
Local loss @ local epoch 4: 0.0018391265766695142
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.89 seconds!
[tester] 
AGNewsMetric: acc=0.6052631578947368, hinge=2.9381235218048096, ce=10.11243248788934
Local test acc @ epoch 124: 0.6053
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.6792662143707275
Local loss @ local epoch 1: 7.645369623787701e-05
Local loss @ local epoch 2: 0.009013845585286617
Local loss @ local epoch 3: 0.10680034011602402
Local loss @ local epoch 4: 0.04958244785666466
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.74 seconds!
[tester] 
AGNewsMetric: acc=0.6105263157894737, hinge=7.530613396544205, ce=10.625029071004768
Local test acc @ epoch 124: 0.6105
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 7.152556946721234e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 9.53674117454284e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.76 seconds!
[tester] 
AGNewsMetric: acc=0.5719736842105263, hinge=5.875086590616327, ce=11.311711158752441
Local test acc @ epoch 124: 0.572
Global evaluate on test data...
Evaluate data in 123.77 seconds!
[tester] 
AGNewsMetric: acc=0.7964473684210527, hinge=2.8667972005041022, ce=8.196185770536724
Global test acc @ epoch 124: 0.7964
Global epoch 125...
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.07252441346645355
Local loss @ local epoch 1: 0.000266670627752319
Local loss @ local epoch 2: 0.009707561694085598
Local loss @ local epoch 3: 0.002125827129930258
Local loss @ local epoch 4: 0.00015620532212778926
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.02 seconds!
[tester] 
AGNewsMetric: acc=0.5811842105263157, hinge=6.302406787370381, ce=11.231526222229004
Local test acc @ epoch 125: 0.5812
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.007800109218806028
Local loss @ local epoch 1: 0.001106198295019567
Local loss @ local epoch 2: 0.0025795723777264357
Local loss @ local epoch 3: 0.0019317707046866417
Local loss @ local epoch 4: 0.0005592870875261724
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.26 seconds!
[tester] 
AGNewsMetric: acc=0.6214473684210526, hinge=3.382521434583162, ce=10.703932740060907
Local test acc @ epoch 125: 0.6214
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0001658485853113234
Local loss @ local epoch 1: 0.00012329299352131784
Local loss @ local epoch 2: 1.8953316612169147e-05
Local loss @ local epoch 3: 4.253143924870528e-05
Local loss @ local epoch 4: 0.32147088646888733
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.69 seconds!
[tester] 
AGNewsMetric: acc=0.7519736842105263, hinge=3.7582958831285174, ce=9.185502787138287
Local test acc @ epoch 125: 0.752
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 9.73540068116563e-07
Local loss @ local epoch 1: 1.5894563887286495e-07
Local loss @ local epoch 2: 4.569685927435785e-07
Local loss @ local epoch 3: 6.755181516382436e-07
Local loss @ local epoch 4: 1.6291793372147367e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.75 seconds!
[tester] 
AGNewsMetric: acc=0.6652631578947369, hinge=6.034763070407666, ce=10.98123465287058
Local test acc @ epoch 125: 0.6653
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 1.4603103863919387e-06
Local loss @ local epoch 1: 4.2318974919908214e-06
Local loss @ local epoch 2: 9.834757292992435e-07
Local loss @ local epoch 3: 5.453772246255539e-06
Local loss @ local epoch 4: 3.874300489314919e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.17 seconds!
[tester] 
AGNewsMetric: acc=0.6222368421052632, hinge=5.828199513585944, ce=11.082894915530556
Local test acc @ epoch 125: 0.6222
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 2.308308921783464e-06
Local loss @ local epoch 1: 7.586044858953755e-08
Local loss @ local epoch 2: 1.3004644472403015e-07
Local loss @ local epoch 3: 2.492556347988284e-07
Local loss @ local epoch 4: 3.2511621839148575e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.51 seconds!
[tester] 
AGNewsMetric: acc=0.45460526315789473, hinge=12.833084066039637, ce=12.573550354807
Local test acc @ epoch 125: 0.4546
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 8.046609423217888e-07
Local loss @ local epoch 1: 4.669026338888216e-07
Local loss @ local epoch 2: 8.8413145249433e-07
Local loss @ local epoch 3: 3.774955530388979e-07
Local loss @ local epoch 4: 1.1920926112907182e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.15 seconds!
[tester] 
AGNewsMetric: acc=0.598421052631579, hinge=7.342205788712753, ce=10.743959455992046
Local test acc @ epoch 125: 0.5984
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0030752308666706085
Local loss @ local epoch 1: 0.036628179252147675
Local loss @ local epoch 2: 0.0009224609821103513
Local loss @ local epoch 3: 0.003277550218626857
Local loss @ local epoch 4: 0.004679061938077211
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.11 seconds!
[tester] 
AGNewsMetric: acc=0.5586842105263158, hinge=3.8050728973589445, ce=10.039996892025597
Local test acc @ epoch 125: 0.5587
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 4.76836760299193e-07
Local loss @ local epoch 1: 7.152556946721234e-08
Local loss @ local epoch 2: 2.1457667287450022e-07
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.152556946721234e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.01 seconds!
[tester] 
AGNewsMetric: acc=0.36144736842105263, hinge=12.02836993167275, ce=16.96807743875604
Local test acc @ epoch 125: 0.3614
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.006701991893351078
Local loss @ local epoch 1: 0.053333401679992676
Local loss @ local epoch 2: 0.00531708262860775
Local loss @ local epoch 3: 0.0001587371079949662
Local loss @ local epoch 4: 1.996751052502077e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.52 seconds!
[tester] 
AGNewsMetric: acc=0.5061842105263158, hinge=7.668538144262214, ce=11.612764575355932
Local test acc @ epoch 125: 0.5062
Global evaluate on test data...
Evaluate data in 122.9 seconds!
[tester] 
AGNewsMetric: acc=0.8497368421052631, hinge=1.9421680417813754, ce=9.138603503578588
Global test acc @ epoch 125: 0.8497
Global epoch 126...
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.07248374074697495
Local loss @ local epoch 1: 8.145939318637829e-07
Local loss @ local epoch 2: 1.6290574421873316e-05
Local loss @ local epoch 3: 0.3767370879650116
Local loss @ local epoch 4: 0.27857524156570435
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.69 seconds!
[tester] 
AGNewsMetric: acc=0.5461842105263158, hinge=8.91709692051536, ce=13.044271880701968
Local test acc @ epoch 126: 0.5462
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.045230645686388016
Local loss @ local epoch 1: 1.0511512300581671e-05
Local loss @ local epoch 2: 5.852079425494594e-07
Local loss @ local epoch 3: 3.251160762829386e-07
Local loss @ local epoch 4: 7.47765568576142e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.16 seconds!
[tester] 
AGNewsMetric: acc=0.5963157894736842, hinge=6.882672269469813, ce=10.487422264500669
Local test acc @ epoch 126: 0.5963
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.02349311113357544
Local loss @ local epoch 1: 0.00030293664894998074
Local loss @ local epoch 2: 0.005248999688774347
Local loss @ local epoch 3: 0.0016684355214238167
Local loss @ local epoch 4: 0.0018202081555500627
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.26 seconds!
[tester] 
AGNewsMetric: acc=0.4660526315789474, hinge=4.514754243148, ce=10.999430044073808
Local test acc @ epoch 126: 0.4661
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.43819913268089294
Local loss @ local epoch 1: 0.0008847906719893217
Local loss @ local epoch 2: 8.846958371577784e-05
Local loss @ local epoch 3: 0.00017151900101453066
Local loss @ local epoch 4: 0.00041569015593267977
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.53 seconds!
[tester] 
AGNewsMetric: acc=0.5186842105263157, hinge=7.514093830209029, ce=12.643210848758095
Local test acc @ epoch 126: 0.5187
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 3.4570505249575945e-06
Local loss @ local epoch 1: 0.0006436460535041988
Local loss @ local epoch 2: 1.960920781129971e-05
Local loss @ local epoch 3: 2.4134414196014404
Local loss @ local epoch 4: 2.840014894900378e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.05 seconds!
[tester] 
AGNewsMetric: acc=0.8164473684210526, hinge=2.306894635652241, ce=8.614686227095754
Local test acc @ epoch 126: 0.8164
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.006536423694342375
Local loss @ local epoch 1: 0.003826247062534094
Local loss @ local epoch 2: 0.0005120500572957098
Local loss @ local epoch 3: 0.0007712034857831895
Local loss @ local epoch 4: 0.010148479603230953
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.25 seconds!
[tester] 
AGNewsMetric: acc=0.7882894736842105, hinge=2.253340906845896, ce=7.445056037902832
Local test acc @ epoch 126: 0.7883
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.020075729116797447
Local loss @ local epoch 1: 1.4320310583570972e-05
Local loss @ local epoch 2: 0.02089562453329563
Local loss @ local epoch 3: 0.0002934146032202989
Local loss @ local epoch 4: 0.00021077018755022436
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.84 seconds!
[tester] 
AGNewsMetric: acc=0.6734210526315789, hinge=3.0614029588197407, ce=9.636540436995658
Local test acc @ epoch 126: 0.6734
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.152556236178498e-08
Local loss @ local epoch 2: 7.152556946721234e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.52 seconds!
[tester] 
AGNewsMetric: acc=0.8092105263157895, hinge=2.618029626545153, ce=10.121601648832621
Local test acc @ epoch 126: 0.8092
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.07323838025331497
Local loss @ local epoch 1: 1.3025710359215736e-05
Local loss @ local epoch 2: 0.4746558964252472
Local loss @ local epoch 3: 0.0004436330928001553
Local loss @ local epoch 4: 0.000764989061281085
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.84 seconds!
[tester] 
AGNewsMetric: acc=0.7889473684210526, hinge=3.200562757692839, ce=9.096846588536312
Local test acc @ epoch 126: 0.7889
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0023197014816105366
Local loss @ local epoch 1: 1.3907748552810517e-07
Local loss @ local epoch 2: 4.0729790384830267e-07
Local loss @ local epoch 3: 1.1920907354578958e-06
Local loss @ local epoch 4: 0.0009253253811039031
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.66 seconds!
[tester] 
AGNewsMetric: acc=0.46210526315789474, hinge=13.261157323435734, ce=13.628588795912894
Local test acc @ epoch 126: 0.4621
Global evaluate on test data...
Evaluate data in 124.15 seconds!
[tester] 
AGNewsMetric: acc=0.8288157894736842, hinge=2.365268131306297, ce=8.688428900869269
Global test acc @ epoch 126: 0.8288
Global epoch 127...
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.014762490056455135
Local loss @ local epoch 1: 0.00432010879740119
Local loss @ local epoch 2: 0.0004455901507753879
Local loss @ local epoch 3: 0.0012698726495727897
Local loss @ local epoch 4: 0.0009018136188387871
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.62 seconds!
[tester] 
AGNewsMetric: acc=0.4928947368421053, hinge=4.322213085074174, ce=8.729334520038806
Local test acc @ epoch 127: 0.4929
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.04681580513715744
Local loss @ local epoch 1: 0.011276526376605034
Local loss @ local epoch 2: 8.025487477425486e-05
Local loss @ local epoch 3: 2.2731077478965744e-05
Local loss @ local epoch 4: 0.00015813350910320878
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.75 seconds!
[tester] 
AGNewsMetric: acc=0.5601315789473684, hinge=7.883506908416748, ce=11.492824795371607
Local test acc @ epoch 127: 0.5601
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 3.3855171750474256e-06
Local loss @ local epoch 1: 4.768370942542788e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 4.768371297814156e-08
Local loss @ local epoch 4: 9.536742595628311e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.96 seconds!
[tester] 
AGNewsMetric: acc=0.7501315789473684, hinge=3.753122252665068, ce=11.028129170066432
Local test acc @ epoch 127: 0.7501
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.00022280894336290658
Local loss @ local epoch 1: 0.0014951316406950355
Local loss @ local epoch 2: 0.002510498510673642
Local loss @ local epoch 3: 0.0028202307876199484
Local loss @ local epoch 4: 0.006371658761054277
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.35 seconds!
[tester] 
AGNewsMetric: acc=0.4785526315789474, hinge=5.806435570967825, ce=8.745560766521253
Local test acc @ epoch 127: 0.4786
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 5.761776264989749e-07
Local loss @ local epoch 1: 7.351214321715815e-07
Local loss @ local epoch 2: 6.953873565862523e-08
Local loss @ local epoch 3: 3.377593884579255e-07
Local loss @ local epoch 4: 4.5696847905674076e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.37 seconds!
[tester] 
AGNewsMetric: acc=0.7481578947368421, hinge=4.3400528531325495, ce=8.526101634376927
Local test acc @ epoch 127: 0.7482
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 8.669728686072631e-07
Local loss @ local epoch 1: 2.167441515155133e-08
Local loss @ local epoch 2: 2.1674412664651754e-07
Local loss @ local epoch 3: 3.2511621839148575e-08
Local loss @ local epoch 4: 1.0837207575775665e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.09 seconds!
[tester] 
AGNewsMetric: acc=0.5184210526315789, hinge=8.6909460037633, ce=11.439708535043817
Local test acc @ epoch 127: 0.5184
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 6.85452675952547e-07
Local loss @ local epoch 1: 6.953873565862523e-08
Local loss @ local epoch 2: 2.0861619987044833e-07
Local loss @ local epoch 3: 5.861116392225085e-07
Local loss @ local epoch 4: 1.092751560349825e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.49 seconds!
[tester] 
AGNewsMetric: acc=0.4614473684210526, hinge=14.023510397358944, ce=15.316193235296952
Local test acc @ epoch 127: 0.4614
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.010835599154233932
Local loss @ local epoch 1: 1.745974805089645e-05
Local loss @ local epoch 2: 0.00010316521365894005
Local loss @ local epoch 3: 2.1638992620864883e-05
Local loss @ local epoch 4: 0.04703028127551079
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.52 seconds!
[tester] 
AGNewsMetric: acc=0.5846052631578947, hinge=6.528825087296335, ce=11.727464559454667
Local test acc @ epoch 127: 0.5846
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0012526705395430326
Local loss @ local epoch 1: 0.002390987006947398
Local loss @ local epoch 2: 1.1508606803545263e-05
Local loss @ local epoch 3: 0.00028362360899336636
Local loss @ local epoch 4: 0.0012603423092514277
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.13 seconds!
[tester] 
AGNewsMetric: acc=0.8519736842105263, hinge=1.8148359240983662, ce=9.084061136747662
Local test acc @ epoch 127: 0.852
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 7.152517355279997e-06
Local loss @ local epoch 1: 4.589521722664358e-06
Local loss @ local epoch 2: 2.831209940268309e-06
Local loss @ local epoch 3: 8.940686484493199e-07
Local loss @ local epoch 4: 3.8743007735320134e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.56 seconds!
[tester] 
AGNewsMetric: acc=0.6997368421052632, hinge=4.3466362185227245, ce=9.985038946051347
Local test acc @ epoch 127: 0.6997
Global evaluate on test data...
Evaluate data in 123.75 seconds!
[tester] 
AGNewsMetric: acc=0.8475, hinge=1.8973293040928088, ce=8.967918002479955
Global test acc @ epoch 127: 0.8475
Global epoch 128...
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.00014670031669083983
Local loss @ local epoch 1: 2.7815480052595376e-07
Local loss @ local epoch 2: 9.536720426694956e-07
Local loss @ local epoch 3: 5.316043097991496e-05
Local loss @ local epoch 4: 0.0026967471931129694
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.79 seconds!
[tester] 
AGNewsMetric: acc=0.6148684210526316, hinge=7.348137997075131, ce=11.946204579001979
Local test acc @ epoch 128: 0.6149
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0012900882866233587
Local loss @ local epoch 1: 0.3316362202167511
Local loss @ local epoch 2: 0.021068695932626724
Local loss @ local epoch 3: 0.026071567088365555
Local loss @ local epoch 4: 0.03356363996863365
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.11 seconds!
[tester] 
AGNewsMetric: acc=0.8538157894736842, hinge=1.3599443681616532, ce=9.587604847958213
Local test acc @ epoch 128: 0.8538
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.008885775692760944
Local loss @ local epoch 1: 0.002471452346071601
Local loss @ local epoch 2: 0.07217691838741302
Local loss @ local epoch 3: 0.0009559710160829127
Local loss @ local epoch 4: 0.002419118070974946
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.41 seconds!
[tester] 
AGNewsMetric: acc=0.4814473684210526, hinge=4.218236172324732, ce=11.388395652770996
Local test acc @ epoch 128: 0.4814
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.009395190514624119
Local loss @ local epoch 1: 2.6550906113698147e-06
Local loss @ local epoch 2: 0.00014091491175349802
Local loss @ local epoch 3: 5.1584593165898696e-06
Local loss @ local epoch 4: 0.17627546191215515
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.19 seconds!
[tester] 
AGNewsMetric: acc=0.6748684210526316, hinge=5.219647536026804, ce=9.727046079133686
Local test acc @ epoch 128: 0.6749
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.4852718710899353
Local loss @ local epoch 1: 1.163756132882554e-05
Local loss @ local epoch 2: 4.19275056628976e-05
Local loss @ local epoch 3: 5.974386294838041e-05
Local loss @ local epoch 4: 0.29989778995513916
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.71 seconds!
[tester] 
AGNewsMetric: acc=0.6167105263157895, hinge=5.002324597710057, ce=11.140699229993318
Local test acc @ epoch 128: 0.6167
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 4.115454794373363e-05
Local loss @ local epoch 1: 4.172323428974778e-07
Local loss @ local epoch 2: 3.129228616671753e-06
Local loss @ local epoch 3: 9.834760703597567e-07
Local loss @ local epoch 4: 2.9206166800577193e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.14 seconds!
[tester] 
AGNewsMetric: acc=0.6401315789473684, hinge=5.151921033357319, ce=9.48554639916671
Local test acc @ epoch 128: 0.6401
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.6923455595970154
Local loss @ local epoch 1: 0.00017076588119380176
Local loss @ local epoch 2: 0.0003972809063270688
Local loss @ local epoch 3: 0.06811490654945374
Local loss @ local epoch 4: 0.1638953536748886
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.2 seconds!
[tester] 
AGNewsMetric: acc=0.5873684210526315, hinge=7.106845099298577, ce=10.551956458844636
Local test acc @ epoch 128: 0.5874
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.22689266502857208
Local loss @ local epoch 1: 1.1622844340308802e-06
Local loss @ local epoch 2: 1.986820308275128e-07
Local loss @ local epoch 3: 1.6429490642622113e-05
Local loss @ local epoch 4: 1.0728806500992505e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.82 seconds!
[tester] 
AGNewsMetric: acc=0.4369736842105263, hinge=13.435009868019506, ce=13.327555519907097
Local test acc @ epoch 128: 0.437
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.15543866157531738
Local loss @ local epoch 1: 0.00011571914365049452
Local loss @ local epoch 2: 5.055477231508121e-05
Local loss @ local epoch 3: 4.288742638891563e-05
Local loss @ local epoch 4: 0.20722219347953796
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.53 seconds!
[tester] 
AGNewsMetric: acc=0.5725, hinge=4.932274646257099, ce=10.912309114556564
Local test acc @ epoch 128: 0.5725
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 2.3841853646899835e-07
Local loss @ local epoch 1: 2.384185648907078e-08
Local loss @ local epoch 2: 9.53674117454284e-08
Local loss @ local epoch 3: 2.861022494471399e-07
Local loss @ local epoch 4: 4.053076736454386e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.57 seconds!
[tester] 
AGNewsMetric: acc=0.7671052631578947, hinge=2.769017360586869, ce=8.916845919960423
Local test acc @ epoch 128: 0.7671
Global evaluate on test data...
Evaluate data in 122.79 seconds!
[tester] 
AGNewsMetric: acc=0.7981578947368421, hinge=2.715813423457899, ce=8.559984769319232
Global test acc @ epoch 128: 0.7982
Global epoch 129...
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.7496276497840881
Local loss @ local epoch 1: 0.00011402984819142148
Local loss @ local epoch 2: 0.00025994234601967037
Local loss @ local epoch 3: 0.00016222499834839255
Local loss @ local epoch 4: 9.692942694528028e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.72 seconds!
[tester] 
AGNewsMetric: acc=0.6044736842105263, hinge=4.938480672585337, ce=10.379562199241237
Local test acc @ epoch 129: 0.6045
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 7.152556946721234e-08
Local loss @ local epoch 1: 9.536741885085576e-08
Local loss @ local epoch 2: 1.1920927533992653e-07
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.74 seconds!
[tester] 
AGNewsMetric: acc=0.6838157894736843, hinge=4.330208086465534, ce=10.390213014703049
Local test acc @ epoch 129: 0.6838
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.007826336659491062
Local loss @ local epoch 1: 0.001513012801297009
Local loss @ local epoch 2: 0.006298468913882971
Local loss @ local epoch 3: 0.00025108628324232996
Local loss @ local epoch 4: 0.013464006595313549
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.64 seconds!
[tester] 
AGNewsMetric: acc=0.7053947368421053, hinge=2.457614114911933, ce=10.302975742942408
Local test acc @ epoch 129: 0.7054
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0006280489033088088
Local loss @ local epoch 1: 0.0012068573851138353
Local loss @ local epoch 2: 2.509889418433886e-05
Local loss @ local epoch 3: 1.5459323549293913e-05
Local loss @ local epoch 4: 3.658203468148713e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.86 seconds!
[tester] 
AGNewsMetric: acc=0.5443421052631578, hinge=6.6927672155279865, ce=11.37609046534488
Local test acc @ epoch 129: 0.5443
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.005428641103208065
Local loss @ local epoch 1: 0.0014689633389934897
Local loss @ local epoch 2: 0.24000291526317596
Local loss @ local epoch 3: 0.03129692003130913
Local loss @ local epoch 4: 0.026662861928343773
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.3 seconds!
[tester] 
AGNewsMetric: acc=0.7052631578947368, hinge=2.747190883285121, ce=10.891355647036903
Local test acc @ epoch 129: 0.7053
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 5.06638798469794e-07
Local loss @ local epoch 1: 3.7749546777376963e-07
Local loss @ local epoch 2: 5.721081106457859e-05
Local loss @ local epoch 3: 9.934105804632054e-08
Local loss @ local epoch 4: 1.053013534146885e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.29 seconds!
[tester] 
AGNewsMetric: acc=0.8146052631578947, hinge=2.23646515068255, ce=8.47037447879189
Local test acc @ epoch 129: 0.8146
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 5.4537795222131535e-06
Local loss @ local epoch 1: 2.264971499243984e-06
Local loss @ local epoch 2: 2.0861621408130304e-07
Local loss @ local epoch 3: 1.3709038739762036e-06
Local loss @ local epoch 4: 6.258483153942507e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.86 seconds!
[tester] 
AGNewsMetric: acc=0.6678947368421052, hinge=4.608766229278163, ce=10.477394581844932
Local test acc @ epoch 129: 0.6679
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 7.351229669438908e-07
Local loss @ local epoch 1: 1.6887979370494577e-07
Local loss @ local epoch 2: 2.48352449716549e-07
Local loss @ local epoch 3: 5.36440836640395e-07
Local loss @ local epoch 4: 7.053191097838862e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.92 seconds!
[tester] 
AGNewsMetric: acc=0.5197368421052632, hinge=11.084029489316439, ce=11.913075150941548
Local test acc @ epoch 129: 0.5197
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 7.152540888455405e-07
Local loss @ local epoch 1: 7.586044858953755e-08
Local loss @ local epoch 2: 3.2511621839148575e-08
Local loss @ local epoch 3: 1.1920926823449918e-07
Local loss @ local epoch 4: 6.502323657286979e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.54 seconds!
[tester] 
AGNewsMetric: acc=0.5917105263157895, hinge=7.823810308607001, ce=10.423101346869217
Local test acc @ epoch 129: 0.5917
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 6.371579365804791e-05
Local loss @ local epoch 1: 0.00010848794772755355
Local loss @ local epoch 2: 0.0002772293228190392
Local loss @ local epoch 3: 0.037219516932964325
Local loss @ local epoch 4: 4.519839785643853e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.27 seconds!
[tester] 
AGNewsMetric: acc=0.7202631578947368, hinge=4.100929899717632, ce=9.96277196582995
Local test acc @ epoch 129: 0.7203
Global evaluate on test data...
Evaluate data in 124.06 seconds!
[tester] 
AGNewsMetric: acc=0.8640789473684211, hinge=1.771587364297164, ce=8.684299009222734
Global test acc @ epoch 129: 0.8641
Global epoch 130...
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.40321114659309387
Local loss @ local epoch 1: 0.0008646080386824906
Local loss @ local epoch 2: 0.0010456264717504382
Local loss @ local epoch 3: 0.550663948059082
Local loss @ local epoch 4: 0.001771105919033289
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.15 seconds!
[tester] 
AGNewsMetric: acc=0.6855263157894737, hinge=5.676174582180224, ce=10.54957883332905
Local test acc @ epoch 130: 0.6855
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.007759257685393095
Local loss @ local epoch 1: 0.00509262690320611
Local loss @ local epoch 2: 0.7799781560897827
Local loss @ local epoch 3: 0.9494898915290833
Local loss @ local epoch 4: 0.1670387089252472
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.52 seconds!
[tester] 
AGNewsMetric: acc=0.7544736842105263, hinge=1.631570691560444, ce=6.6075130693536055
Local test acc @ epoch 130: 0.7545
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 4.768371297814156e-08
Local loss @ local epoch 1: 7.152556946721234e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.68 seconds!
[tester] 
AGNewsMetric: acc=0.7893421052631578, hinge=3.0606962789987264, ce=9.677308441965204
Local test acc @ epoch 130: 0.7893
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0010680160485208035
Local loss @ local epoch 1: 1.5338109733420424e-05
Local loss @ local epoch 2: 3.862252924591303e-05
Local loss @ local epoch 3: 9.039395808940753e-05
Local loss @ local epoch 4: 0.006985580548644066
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.78 seconds!
[tester] 
AGNewsMetric: acc=0.5672368421052632, hinge=5.301684305291427, ce=11.713494029798007
Local test acc @ epoch 130: 0.5672
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.1425163745880127
Local loss @ local epoch 1: 3.8144189602462575e-05
Local loss @ local epoch 2: 2.859285996237304e-05
Local loss @ local epoch 3: 0.0005306530511006713
Local loss @ local epoch 4: 0.0009693730971775949
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.57 seconds!
[tester] 
AGNewsMetric: acc=0.5964473684210526, hinge=5.151822241231015, ce=10.391910115292198
Local test acc @ epoch 130: 0.5964
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.13089270889759064
Local loss @ local epoch 1: 9.437376320420299e-07
Local loss @ local epoch 2: 2.880888700929063e-07
Local loss @ local epoch 3: 2.5828671823546756e-07
Local loss @ local epoch 4: 4.072981028002687e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.01 seconds!
[tester] 
AGNewsMetric: acc=0.5055263157894737, hinge=10.06171233428152, ce=12.605707582172595
Local test acc @ epoch 130: 0.5055
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 3.8271831726888195e-05
Local loss @ local epoch 1: 1.0927516314040986e-07
Local loss @ local epoch 2: 7.639010618731845e-06
Local loss @ local epoch 3: 0.007113975938409567
Local loss @ local epoch 4: 2.1855025522654614e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.75 seconds!
[tester] 
AGNewsMetric: acc=0.7540789473684211, hinge=3.859479546045002, ce=10.096513886702688
Local test acc @ epoch 130: 0.7541
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 1.34110246108321e-06
Local loss @ local epoch 1: 1.2814969068131177e-06
Local loss @ local epoch 2: 4.112705937586725e-06
Local loss @ local epoch 3: 2.4704972020117566e-05
Local loss @ local epoch 4: 1.0132779380001011e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.49 seconds!
[tester] 
AGNewsMetric: acc=0.714078947368421, hinge=3.7099008803618583, ce=9.504222948174728
Local test acc @ epoch 130: 0.7141
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.1089361235499382
Local loss @ local epoch 1: 0.00012420807615853846
Local loss @ local epoch 2: 3.836017640423961e-05
Local loss @ local epoch 3: 7.466584065696225e-05
Local loss @ local epoch 4: 1.800766767701134e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.12 seconds!
[tester] 
AGNewsMetric: acc=0.5959210526315789, hinge=7.171131028627094, ce=11.357525674920334
Local test acc @ epoch 130: 0.5959
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.001290583866648376
Local loss @ local epoch 1: 2.926045112872089e-07
Local loss @ local epoch 2: 5.41860060820909e-07
Local loss @ local epoch 3: 8.474357855448034e-06
Local loss @ local epoch 4: 4.443252521468821e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.19 seconds!
[tester] 
AGNewsMetric: acc=0.5728947368421052, hinge=8.54208870511306, ce=11.366612464503238
Local test acc @ epoch 130: 0.5729
Global evaluate on test data...
Evaluate data in 122.9 seconds!
[tester] 
AGNewsMetric: acc=0.8194736842105264, hinge=2.7024733510770296, ce=8.311988932960912
Global test acc @ epoch 130: 0.8195
Global epoch 131...
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 8.940694584680386e-08
Local loss @ local epoch 1: 9.934105804632054e-08
Local loss @ local epoch 2: 1.9868213740892315e-08
Local loss @ local epoch 3: 1.0927516314040986e-07
Local loss @ local epoch 4: 8.940694584680386e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.01 seconds!
[tester] 
AGNewsMetric: acc=0.7621052631578947, hinge=3.8155476186149997, ce=10.024195885909231
Local test acc @ epoch 131: 0.7621
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 2.7595799110713415e-05
Local loss @ local epoch 1: 1.2814971341867931e-06
Local loss @ local epoch 2: 7.65504883020185e-05
Local loss @ local epoch 3: 9.406957542523742e-05
Local loss @ local epoch 4: 0.0015368981985375285
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.33 seconds!
[tester] 
AGNewsMetric: acc=0.7338157894736842, hinge=3.281155138015747, ce=8.904323955335116
Local test acc @ epoch 131: 0.7338
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.001709461328573525
Local loss @ local epoch 1: 0.01060748752206564
Local loss @ local epoch 2: 0.006416161544620991
Local loss @ local epoch 3: 0.006544020492583513
Local loss @ local epoch 4: 0.0016083853552117944
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.52 seconds!
[tester] 
AGNewsMetric: acc=0.6602631578947369, hinge=3.5329350975940104, ce=11.178711840980931
Local test acc @ epoch 131: 0.6603
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.12587061524391174
Local loss @ local epoch 1: 0.015410689637064934
Local loss @ local epoch 2: 9.527887596050277e-05
Local loss @ local epoch 3: 6.67351414449513e-05
Local loss @ local epoch 4: 0.0001239428820554167
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.01 seconds!
[tester] 
AGNewsMetric: acc=0.615, hinge=5.261181405719958, ce=10.83546362224378
Local test acc @ epoch 131: 0.615
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 2.817671997945581e-07
Local loss @ local epoch 1: 1.0837207575775665e-08
Local loss @ local epoch 2: 6.502324367829715e-08
Local loss @ local epoch 3: 3.2511621839148575e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.09 seconds!
[tester] 
AGNewsMetric: acc=0.6263157894736842, hinge=6.516814784250761, ce=11.11736197120265
Local test acc @ epoch 131: 0.6263
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0023921222891658545
Local loss @ local epoch 1: 0.0005995715619064867
Local loss @ local epoch 2: 0.00026282432372681797
Local loss @ local epoch 3: 0.0017043278785422444
Local loss @ local epoch 4: 0.0006190395797602832
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.42 seconds!
[tester] 
AGNewsMetric: acc=0.6247368421052631, hinge=3.353568121759515, ce=10.12872638903166
Local test acc @ epoch 131: 0.6247
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 4.80152630188968e-05
Local loss @ local epoch 1: 0.0002866220602300018
Local loss @ local epoch 2: 0.0009463143069297075
Local loss @ local epoch 3: 0.00010467504762345925
Local loss @ local epoch 4: 8.476486254949123e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.49 seconds!
[tester] 
AGNewsMetric: acc=0.8376315789473684, hinge=2.2095995473861696, ce=8.865241060758892
Local test acc @ epoch 131: 0.8376
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 7.152556236178498e-08
Local loss @ local epoch 1: 7.152556236178498e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.384185648907078e-08
Local loss @ local epoch 4: 2.384185648907078e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.44 seconds!
[tester] 
AGNewsMetric: acc=0.728421052631579, hinge=3.6699754393728155, ce=11.146476813868473
Local test acc @ epoch 131: 0.7284
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 3.476935717117158e-07
Local loss @ local epoch 1: 1.8874794704970554e-07
Local loss @ local epoch 2: 3.079568671182642e-07
Local loss @ local epoch 3: 2.086160861836106e-07
Local loss @ local epoch 4: 3.3775930319279723e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.01 seconds!
[tester] 
AGNewsMetric: acc=0.8069736842105263, hinge=2.925979538214834, ce=8.790437706395199
Local test acc @ epoch 131: 0.807
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.06151802837848663
Local loss @ local epoch 1: 0.0004939727950841188
Local loss @ local epoch 2: 0.00021685335377696902
Local loss @ local epoch 3: 0.5634496212005615
Local loss @ local epoch 4: 0.001434294623322785
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.8 seconds!
[tester] 
AGNewsMetric: acc=0.6893421052631579, hinge=3.2023415823986654, ce=9.258756111546566
Local test acc @ epoch 131: 0.6893
Global evaluate on test data...
Evaluate data in 122.84 seconds!
[tester] 
AGNewsMetric: acc=0.8602631578947368, hinge=1.8825171821995785, ce=8.820935727169639
Global test acc @ epoch 131: 0.8603
Global epoch 132...
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.006633475888520479
Local loss @ local epoch 1: 3.244773324695416e-05
Local loss @ local epoch 2: 3.6879921481158817e-06
Local loss @ local epoch 3: 0.00011179709690622985
Local loss @ local epoch 4: 1.52652519318508e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.3 seconds!
[tester] 
AGNewsMetric: acc=0.5539473684210526, hinge=9.008244626898515, ce=12.558631547626696
Local test acc @ epoch 132: 0.5539
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.20273174345493317
Local loss @ local epoch 1: 0.00015868229093030095
Local loss @ local epoch 2: 0.00037799871643073857
Local loss @ local epoch 3: 0.6816599369049072
Local loss @ local epoch 4: 0.045064594596624374
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.61 seconds!
[tester] 
AGNewsMetric: acc=0.7028947368421052, hinge=4.982493322523017, ce=10.683073483517296
Local test acc @ epoch 132: 0.7029
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 8.940696005765858e-08
Local loss @ local epoch 1: 3.5762769812208717e-07
Local loss @ local epoch 2: 2.3841852225814364e-07
Local loss @ local epoch 3: 3.2720807212172076e-05
Local loss @ local epoch 4: 5.960459930065554e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.66 seconds!
[tester] 
AGNewsMetric: acc=0.7553947368421052, hinge=2.8367521549526016, ce=9.711846520273308
Local test acc @ epoch 132: 0.7554
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.003089267760515213
Local loss @ local epoch 1: 0.17267990112304688
Local loss @ local epoch 2: 0.004284047055989504
Local loss @ local epoch 3: 0.005145126488059759
Local loss @ local epoch 4: 0.01866656169295311
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.53 seconds!
[tester] 
AGNewsMetric: acc=0.8263157894736842, hinge=1.6150554325706081, ce=9.496047317103336
Local test acc @ epoch 132: 0.8263
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.006333277095109224
Local loss @ local epoch 1: 0.0006482896278612316
Local loss @ local epoch 2: 0.0025793774984776974
Local loss @ local epoch 3: 0.00017806618416216224
Local loss @ local epoch 4: 0.010026284493505955
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.47 seconds!
[tester] 
AGNewsMetric: acc=0.4901315789473684, hinge=4.775192504682039, ce=13.577644091154399
Local test acc @ epoch 132: 0.4901
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 6.205465615494177e-05
Local loss @ local epoch 1: 5.960446856079216e-07
Local loss @ local epoch 2: 2.0861614302702947e-07
Local loss @ local epoch 3: 0.817631721496582
Local loss @ local epoch 4: 6.45715545033454e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.6 seconds!
[tester] 
AGNewsMetric: acc=0.7892105263157895, hinge=3.453563752425344, ce=9.786446956835295
Local test acc @ epoch 132: 0.7892
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 4.768371297814156e-08
Local loss @ local epoch 1: 1.4305111051271524e-07
Local loss @ local epoch 2: 1.1920893712158431e-06
Local loss @ local epoch 3: 8.821469918984803e-07
Local loss @ local epoch 4: 4.7683693082944956e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.66 seconds!
[tester] 
AGNewsMetric: acc=0.6001315789473685, hinge=6.213423086467542, ce=12.36478258835642
Local test acc @ epoch 132: 0.6001
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.007909748703241348
Local loss @ local epoch 1: 5.149754542799201e-06
Local loss @ local epoch 2: 0.2262813150882721
Local loss @ local epoch 3: 6.198769369802903e-06
Local loss @ local epoch 4: 1.5004065971879754e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.43 seconds!
[tester] 
AGNewsMetric: acc=0.7032894736842106, hinge=4.593600195583544, ce=10.289031552766499
Local test acc @ epoch 132: 0.7033
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.006514803972095251
Local loss @ local epoch 1: 6.177201044010872e-07
Local loss @ local epoch 2: 1.0837207575775665e-08
Local loss @ local epoch 3: 6.285575864239945e-07
Local loss @ local epoch 4: 7.477665349142626e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.32 seconds!
[tester] 
AGNewsMetric: acc=0.5338157894736842, hinge=8.856166817765487, ce=11.995341523822985
Local test acc @ epoch 132: 0.5338
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0009886539774015546
Local loss @ local epoch 1: 5.960463411724959e-08
Local loss @ local epoch 2: 2.453691877235542e-06
Local loss @ local epoch 3: 2.110798959620297e-05
Local loss @ local epoch 4: 1.1557376384735107
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.4 seconds!
[tester] 
AGNewsMetric: acc=0.5438157894736843, hinge=8.804842131765266, ce=12.879564985977977
Local test acc @ epoch 132: 0.5438
Global evaluate on test data...
Evaluate data in 123.54 seconds!
[tester] 
AGNewsMetric: acc=0.8289473684210527, hinge=2.4497438739475452, ce=9.309373044465717
Global test acc @ epoch 132: 0.8289
Global epoch 133...
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 3.476934864465875e-07
Local loss @ local epoch 1: 1.9868213740892315e-08
Local loss @ local epoch 2: 1.788138632718983e-07
Local loss @ local epoch 3: 3.5762741390499286e-07
Local loss @ local epoch 4: 2.9802320611338473e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.6 seconds!
[tester] 
AGNewsMetric: acc=0.7803947368421053, hinge=3.737703349464818, ce=10.00540003726357
Local test acc @ epoch 133: 0.7804
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.005999661982059479
Local loss @ local epoch 1: 0.00016524753300473094
Local loss @ local epoch 2: 6.734880298608914e-05
Local loss @ local epoch 3: 1.847725798143074e-05
Local loss @ local epoch 4: 0.008927853778004646
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.41 seconds!
[tester] 
AGNewsMetric: acc=0.48460526315789476, hinge=6.108778937490363, ce=14.282313477365594
Local test acc @ epoch 133: 0.4846
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 6.854528464828036e-07
Local loss @ local epoch 1: 5.066392532171449e-07
Local loss @ local epoch 2: 7.152552825573366e-07
Local loss @ local epoch 3: 4.1425028030062094e-06
Local loss @ local epoch 4: 1.311299229200813e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.12 seconds!
[tester] 
AGNewsMetric: acc=0.6963157894736842, hinge=4.336301619881078, ce=9.62616076820775
Local test acc @ epoch 133: 0.6963
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.7936508059501648
Local loss @ local epoch 1: 0.0007916331524029374
Local loss @ local epoch 2: 0.000524211791343987
Local loss @ local epoch 3: 0.0008256721193902194
Local loss @ local epoch 4: 0.0018259567441418767
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.49 seconds!
[tester] 
AGNewsMetric: acc=0.533157894736842, hinge=4.627921091380872, ce=10.741134203860634
Local test acc @ epoch 133: 0.5332
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 2.3841853646899835e-07
Local loss @ local epoch 1: 6.914131631674536e-07
Local loss @ local epoch 2: 7.152556236178498e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.384185648907078e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.17 seconds!
[tester] 
AGNewsMetric: acc=0.6255263157894737, hinge=6.685571486824437, ce=12.327528630306846
Local test acc @ epoch 133: 0.6255
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 1.962763963092584e-05
Local loss @ local epoch 1: 1.5833493307582103e-05
Local loss @ local epoch 2: 5.563097147387452e-07
Local loss @ local epoch 3: 9.307768777944148e-06
Local loss @ local epoch 4: 2.0662748738686787e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 122.78 seconds!
[tester] 
AGNewsMetric: acc=0.5371052631578948, hinge=10.19507115088011, ce=13.621148912530197
Local test acc @ epoch 133: 0.5371
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.477578341960907
Local loss @ local epoch 1: 0.000310753210214898
Local loss @ local epoch 2: 3.8952723116381094e-05
Local loss @ local epoch 3: 0.0009892811067402363
Local loss @ local epoch 4: 2.2266851374297403e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.09 seconds!
[tester] 
AGNewsMetric: acc=0.5456578947368421, hinge=6.89037657813022, ce=11.573278702183774
Local test acc @ epoch 133: 0.5457
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 4.226507428484183e-07
Local loss @ local epoch 1: 3.2511618286434896e-08
Local loss @ local epoch 2: 3.2511621839148575e-08
Local loss @ local epoch 3: 5.4186031661629386e-08
Local loss @ local epoch 4: 3.2511618286434896e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.36 seconds!
[tester] 
AGNewsMetric: acc=0.5348684210526315, hinge=10.68209235216442, ce=13.189436645507813
Local test acc @ epoch 133: 0.5349
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.6254639625549316
Local loss @ local epoch 1: 2.012330514844507e-05
Local loss @ local epoch 2: 1.128743497247342e-05
Local loss @ local epoch 3: 7.807921974745113e-06
Local loss @ local epoch 4: 0.0002563674934208393
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.03 seconds!
[tester] 
AGNewsMetric: acc=0.5303947368421053, hinge=6.648778723666543, ce=12.30652269062243
Local test acc @ epoch 133: 0.5304
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 5.596765913651325e-05
Local loss @ local epoch 1: 5.3922529332339764e-05
Local loss @ local epoch 2: 0.002845163457095623
Local loss @ local epoch 3: 0.0001300693693337962
Local loss @ local epoch 4: 2.284296351717785e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.65 seconds!
[tester] 
AGNewsMetric: acc=0.8397368421052631, hinge=2.0320867337678608, ce=9.633702141611199
Local test acc @ epoch 133: 0.8397
Global evaluate on test data...
Evaluate data in 124.23 seconds!
[tester] 
AGNewsMetric: acc=0.8421052631578947, hinge=2.124887277954503, ce=9.349374421772204
Global test acc @ epoch 133: 0.8421
Global epoch 134...
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 1.162288185696525e-06
Local loss @ local epoch 1: 2.6822084464583895e-07
Local loss @ local epoch 2: 8.63236200530082e-05
Local loss @ local epoch 3: 3.874300205097825e-07
Local loss @ local epoch 4: 3.874300205097825e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.1 seconds!
[tester] 
AGNewsMetric: acc=0.7076315789473684, hinge=3.9651899681593243, ce=9.839546876204642
Local test acc @ epoch 134: 0.7076
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.00037723613786511123
Local loss @ local epoch 1: 0.0009359122486785054
Local loss @ local epoch 2: 0.006541448179632425
Local loss @ local epoch 3: 0.004726482089608908
Local loss @ local epoch 4: 0.0056629180908203125
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.36 seconds!
[tester] 
AGNewsMetric: acc=0.7671052631578947, hinge=2.4786405723973326, ce=10.289466016669023
Local test acc @ epoch 134: 0.7671
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.29871442914009094
Local loss @ local epoch 1: 2.5828668981375813e-07
Local loss @ local epoch 2: 3.6756179611074913e-07
Local loss @ local epoch 3: 3.824550276476657e-06
Local loss @ local epoch 4: 4.491104118642397e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.32 seconds!
[tester] 
AGNewsMetric: acc=0.4089473684210526, hinge=13.112433594151547, ce=13.208944174114027
Local test acc @ epoch 134: 0.4089
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.00027410726761445403
Local loss @ local epoch 1: 2.84112661574909e-06
Local loss @ local epoch 2: 6.457164545281557e-07
Local loss @ local epoch 3: 1.5497170124945114e-06
Local loss @ local epoch 4: 3.098919478361495e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.27 seconds!
[tester] 
AGNewsMetric: acc=0.5018421052631579, hinge=9.131240508430883, ce=14.028610600923237
Local test acc @ epoch 134: 0.5018
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.007671584840863943
Local loss @ local epoch 1: 0.0093796756118536
Local loss @ local epoch 2: 3.601722346502356e-05
Local loss @ local epoch 3: 0.001088075339794159
Local loss @ local epoch 4: 0.3679253160953522
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.81 seconds!
[tester] 
AGNewsMetric: acc=0.6081578947368421, hinge=4.26235605089288, ce=11.190044700221012
Local test acc @ epoch 134: 0.6082
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.018138941377401352
Local loss @ local epoch 1: 0.00012600784248206764
Local loss @ local epoch 2: 4.688865374191664e-06
Local loss @ local epoch 3: 5.412075097410707e-06
Local loss @ local epoch 4: 1.923983290907927e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.04 seconds!
[tester] 
AGNewsMetric: acc=0.5732894736842106, hinge=7.377377046785856, ce=11.92497301804392
Local test acc @ epoch 134: 0.5733
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0015161833725869656
Local loss @ local epoch 1: 0.000775888271164149
Local loss @ local epoch 2: 0.0032076474744826555
Local loss @ local epoch 3: 9.226251859217882e-05
Local loss @ local epoch 4: 8.749403059482574e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 122.89 seconds!
[tester] 
AGNewsMetric: acc=0.5221052631578947, hinge=5.628230765493292, ce=13.432412105359528
Local test acc @ epoch 134: 0.5221
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 4.768371297814156e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.21 seconds!
[tester] 
AGNewsMetric: acc=0.756578947368421, hinge=3.7915572221655593, ce=11.434903229161312
Local test acc @ epoch 134: 0.7566
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.17320263385772705
Local loss @ local epoch 1: 5.87364456805517e-06
Local loss @ local epoch 2: 2.655096977832727e-06
Local loss @ local epoch 3: 3.793020368902944e-07
Local loss @ local epoch 4: 9.536725542602653e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.44 seconds!
[tester] 
AGNewsMetric: acc=0.6007894736842105, hinge=7.303338183352822, ce=12.439000370627955
Local test acc @ epoch 134: 0.6008
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 1.3223729133605957
Local loss @ local epoch 1: 0.00022353521490003914
Local loss @ local epoch 2: 0.0007717551779933274
Local loss @ local epoch 3: 0.3821697533130646
Local loss @ local epoch 4: 0.15565010905265808
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.62 seconds!
[tester] 
AGNewsMetric: acc=0.5739473684210527, hinge=8.569231008730437, ce=11.641186186137952
Local test acc @ epoch 134: 0.5739
Global evaluate on test data...
Evaluate data in 124.2 seconds!
[tester] 
AGNewsMetric: acc=0.8448684210526316, hinge=2.3037379420431034, ce=9.327128966482062
Global test acc @ epoch 134: 0.8449
Global epoch 135...
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0013475503074005246
Local loss @ local epoch 1: 0.002959941513836384
Local loss @ local epoch 2: 0.0018420740962028503
Local loss @ local epoch 3: 0.00033548296778462827
Local loss @ local epoch 4: 0.0005840293015353382
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.7 seconds!
[tester] 
AGNewsMetric: acc=0.5648684210526316, hinge=4.150865925738686, ce=11.897520097431384
Local test acc @ epoch 135: 0.5649
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 1.7881382063933415e-07
Local loss @ local epoch 1: 1.1920926823449918e-07
Local loss @ local epoch 2: 1.4901159772762185e-07
Local loss @ local epoch 3: 1.7881383485018887e-07
Local loss @ local epoch 4: 4.967053257587395e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.12 seconds!
[tester] 
AGNewsMetric: acc=0.8192105263157895, hinge=2.7741977061723406, ce=9.19979462473016
Local test acc @ epoch 135: 0.8192
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.00014690250100102276
Local loss @ local epoch 1: 8.642662123747868e-07
Local loss @ local epoch 2: 1.1920927533992653e-07
Local loss @ local epoch 3: 2.086161714487389e-07
Local loss @ local epoch 4: 6.258484290810884e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.3 seconds!
[tester] 
AGNewsMetric: acc=0.7480263157894737, hinge=3.3002231434771887, ce=10.067268720927991
Local test acc @ epoch 135: 0.748
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 5.38128697371576e-05
Local loss @ local epoch 1: 3.633549567894079e-05
Local loss @ local epoch 2: 3.142506830045022e-05
Local loss @ local epoch 3: 0.00019720061391126364
Local loss @ local epoch 4: 3.7081797927385196e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.44 seconds!
[tester] 
AGNewsMetric: acc=0.7403947368421052, hinge=4.144301974647924, ce=9.555568516379909
Local test acc @ epoch 135: 0.7404
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.004603359382599592
Local loss @ local epoch 1: 0.0046506114304065704
Local loss @ local epoch 2: 0.0011135751847177744
Local loss @ local epoch 3: 0.0015796265797689557
Local loss @ local epoch 4: 0.0009924456244334579
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.53 seconds!
[tester] 
AGNewsMetric: acc=0.5401315789473684, hinge=5.312360493007459, ce=12.697856298747816
Local test acc @ epoch 135: 0.5401
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.014584925957024097
Local loss @ local epoch 1: 0.00030533302924595773
Local loss @ local epoch 2: 4.824945062864572e-05
Local loss @ local epoch 3: 3.068990190513432e-05
Local loss @ local epoch 4: 0.27569252252578735
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.71 seconds!
[tester] 
AGNewsMetric: acc=0.63, hinge=6.452758387515419, ce=11.244875518397281
Local test acc @ epoch 135: 0.63
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 1.8423249059651425e-07
Local loss @ local epoch 1: 6.502323657286979e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 4.334882675038898e-08
Local loss @ local epoch 4: 2.167441515155133e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.51 seconds!
[tester] 
AGNewsMetric: acc=0.6225, hinge=7.736362290382385, ce=11.568690709565816
Local test acc @ epoch 135: 0.6225
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 1.1920926823449918e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.384185648907078e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.41 seconds!
[tester] 
AGNewsMetric: acc=0.7282894736842105, hinge=4.3275088940168684, ce=10.673401123849969
Local test acc @ epoch 135: 0.7283
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 2.9802305334669654e-07
Local loss @ local epoch 1: 3.079571513353585e-07
Local loss @ local epoch 2: 1.2914335911773378e-07
Local loss @ local epoch 3: 3.3775904739741236e-07
Local loss @ local epoch 4: 5.9604641222676946e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 122.34 seconds!
[tester] 
AGNewsMetric: acc=0.6118421052631579, hinge=8.406938896681133, ce=12.399827276531019
Local test acc @ epoch 135: 0.6118
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.3121928870677948
Local loss @ local epoch 1: 7.182962872320786e-05
Local loss @ local epoch 2: 0.00019910356786567718
Local loss @ local epoch 3: 0.005824287887662649
Local loss @ local epoch 4: 0.0007262893486768007
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.06 seconds!
[tester] 
AGNewsMetric: acc=0.5643421052631579, hinge=8.43522620753238, ce=12.203046312834088
Local test acc @ epoch 135: 0.5643
Global evaluate on test data...
Evaluate data in 123.93 seconds!
[tester] 
AGNewsMetric: acc=0.8505263157894737, hinge=2.0517586281425073, ce=9.237599238345497
Global test acc @ epoch 135: 0.8505
Global epoch 136...
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 3.3974538382608443e-06
Local loss @ local epoch 1: 5.364415756048402e-07
Local loss @ local epoch 2: 8.940696005765858e-08
Local loss @ local epoch 3: 9.536731795378728e-07
Local loss @ local epoch 4: 8.940683642322256e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.14 seconds!
[tester] 
AGNewsMetric: acc=0.6838157894736843, hinge=5.275624735480861, ce=10.854077084189967
Local test acc @ epoch 136: 0.6838
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.5698994994163513
Local loss @ local epoch 1: 4.443180387170287e-06
Local loss @ local epoch 2: 0.00041797489393502474
Local loss @ local epoch 3: 0.6259675621986389
Local loss @ local epoch 4: 0.05731072276830673
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 122.84 seconds!
[tester] 
AGNewsMetric: acc=0.598421052631579, hinge=7.342738788002416, ce=11.059205203809237
Local test acc @ epoch 136: 0.5984
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.00033296982292085886
Local loss @ local epoch 1: 0.0005260278121568263
Local loss @ local epoch 2: 5.2489252993837e-05
Local loss @ local epoch 3: 0.0005452847108244896
Local loss @ local epoch 4: 8.06597454356961e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.35 seconds!
[tester] 
AGNewsMetric: acc=0.3828947368421053, hinge=6.234900441420706, ce=12.209784525821084
Local test acc @ epoch 136: 0.3829
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 5.463678917294601e-06
Local loss @ local epoch 1: 4.1723203025867406e-07
Local loss @ local epoch 2: 4.967053257587395e-08
Local loss @ local epoch 3: 7.559420919278637e-05
Local loss @ local epoch 4: 9.735406365507515e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.34 seconds!
[tester] 
AGNewsMetric: acc=0.7403947368421052, hinge=4.588019495763277, ce=9.998670417384098
Local test acc @ epoch 136: 0.7404
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0043569570407271385
Local loss @ local epoch 1: 0.001038378570228815
Local loss @ local epoch 2: 0.00020064960699528456
Local loss @ local epoch 3: 0.0004775244160555303
Local loss @ local epoch 4: 0.9520986676216125
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.85 seconds!
[tester] 
AGNewsMetric: acc=0.8010526315789473, hinge=2.4637422167627436, ce=9.628388328552246
Local test acc @ epoch 136: 0.8011
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 9.290701564168558e-05
Local loss @ local epoch 1: 4.716169314633589e-06
Local loss @ local epoch 2: 1.6695543308742344e-05
Local loss @ local epoch 3: 1.4752097285963828e-06
Local loss @ local epoch 4: 3.032363792954129e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.6 seconds!
[tester] 
AGNewsMetric: acc=0.5875, hinge=6.8941466366617306, ce=12.635155679803146
Local test acc @ epoch 136: 0.5875
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.11544692516326904
Local loss @ local epoch 1: 2.3841842278216063e-07
Local loss @ local epoch 2: 3.476936001334252e-07
Local loss @ local epoch 3: 5.463754746415361e-07
Local loss @ local epoch 4: 1.0033407988885301e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.53 seconds!
[tester] 
AGNewsMetric: acc=0.516578947368421, hinge=9.193382745291057, ce=12.357503165194863
Local test acc @ epoch 136: 0.5166
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.004985022358596325
Local loss @ local epoch 1: 6.502323657286979e-08
Local loss @ local epoch 2: 1.9506961734805373e-07
Local loss @ local epoch 3: 1.007857918011723e-06
Local loss @ local epoch 4: 3.6304309105616994e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.64 seconds!
[tester] 
AGNewsMetric: acc=0.5089473684210526, hinge=9.8567910232042, ce=13.139539493761564
Local test acc @ epoch 136: 0.5089
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 1.1920927533992653e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.49 seconds!
[tester] 
AGNewsMetric: acc=0.7701315789473684, hinge=3.5902148492712724, ce=11.201869844135485
Local test acc @ epoch 136: 0.7701
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 2.4174451027647592e-05
Local loss @ local epoch 1: 3.663648385554552e-06
Local loss @ local epoch 2: 6.516767712128058e-07
Local loss @ local epoch 3: 0.03873733431100845
Local loss @ local epoch 4: 8.670240276842378e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.74 seconds!
[tester] 
AGNewsMetric: acc=0.6505263157894737, hinge=5.382719580248782, ce=11.275027495936344
Local test acc @ epoch 136: 0.6505
Global evaluate on test data...
Evaluate data in 125.17 seconds!
[tester] 
AGNewsMetric: acc=0.8514473684210526, hinge=2.1992481424933987, ce=8.62901979948345
Global test acc @ epoch 136: 0.8514
Global epoch 137...
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 2.384185648907078e-08
Local loss @ local epoch 1: 4.768370942542788e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.71 seconds!
[tester] 
AGNewsMetric: acc=0.8328947368421052, hinge=2.4033280820595593, ce=9.224965868498149
Local test acc @ epoch 137: 0.8329
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 1.1920928244535389e-07
Local loss @ local epoch 1: 7.748597568024707e-07
Local loss @ local epoch 2: 7.450570933542622e-07
Local loss @ local epoch 3: 9.238702887159889e-07
Local loss @ local epoch 4: 2.0861622829215776e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.01 seconds!
[tester] 
AGNewsMetric: acc=0.7357894736842105, hinge=4.392963528884085, ce=10.95851721111097
Local test acc @ epoch 137: 0.7358
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 3.9013903574414144e-07
Local loss @ local epoch 1: 9.753485130659101e-08
Local loss @ local epoch 2: 4.334882675038898e-08
Local loss @ local epoch 3: 1.0837207575775665e-08
Local loss @ local epoch 4: 2.167441515155133e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.84 seconds!
[tester] 
AGNewsMetric: acc=0.5806578947368422, hinge=8.036199772483425, ce=11.499667591295744
Local test acc @ epoch 137: 0.5807
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 4.371004536096734e-07
Local loss @ local epoch 1: 8.940694584680386e-08
Local loss @ local epoch 2: 1.788138632718983e-07
Local loss @ local epoch 3: 9.934105804632054e-08
Local loss @ local epoch 4: 1.3907744289554103e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.56 seconds!
[tester] 
AGNewsMetric: acc=0.8255263157894737, hinge=2.589120952455621, ce=8.70268550270482
Local test acc @ epoch 137: 0.8255
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 1.1920926823449918e-07
Local loss @ local epoch 1: 2.6822075938071066e-07
Local loss @ local epoch 2: 1.9868213740892315e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.25 seconds!
[tester] 
AGNewsMetric: acc=0.7163157894736842, hinge=5.231327964381168, ce=9.959003313968056
Local test acc @ epoch 137: 0.7163
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0681738331913948
Local loss @ local epoch 1: 0.0007692525396123528
Local loss @ local epoch 2: 0.0005614180117845535
Local loss @ local epoch 3: 0.00030239351326599717
Local loss @ local epoch 4: 0.00036357907811179757
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.11 seconds!
[tester] 
AGNewsMetric: acc=0.5535526315789474, hinge=7.998810571369372, ce=11.521496029904014
Local test acc @ epoch 137: 0.5536
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0006865633768029511
Local loss @ local epoch 1: 0.00012113475531805307
Local loss @ local epoch 2: 0.0005678875604644418
Local loss @ local epoch 3: 0.27496299147605896
Local loss @ local epoch 4: 3.940865644835867e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.24 seconds!
[tester] 
AGNewsMetric: acc=0.8314473684210526, hinge=2.445355765694066, ce=9.500505210474918
Local test acc @ epoch 137: 0.8314
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.0024978877045214176
Local loss @ local epoch 1: 1.2269743820070289e-05
Local loss @ local epoch 2: 6.254408617678564e-06
Local loss @ local epoch 3: 4.3789364099211525e-06
Local loss @ local epoch 4: 8.018686457944568e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.39 seconds!
[tester] 
AGNewsMetric: acc=0.5682894736842106, hinge=6.020028764072218, ce=9.658094701265034
Local test acc @ epoch 137: 0.5683
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.005345395300537348
Local loss @ local epoch 1: 0.0005559176206588745
Local loss @ local epoch 2: 0.0004262381698936224
Local loss @ local epoch 3: 0.00028860176098532975
Local loss @ local epoch 4: 0.0020828533452004194
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.42 seconds!
[tester] 
AGNewsMetric: acc=0.5668421052631579, hinge=3.7500784116042287, ce=10.887952390971936
Local test acc @ epoch 137: 0.5668
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.023255709558725357
Local loss @ local epoch 1: 0.0003465113404672593
Local loss @ local epoch 2: 0.0018046440090984106
Local loss @ local epoch 3: 0.0017038221703842282
Local loss @ local epoch 4: 0.04180341586470604
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.03 seconds!
[tester] 
AGNewsMetric: acc=0.6021052631578947, hinge=4.572758445739746, ce=10.385903984872918
Local test acc @ epoch 137: 0.6021
Global evaluate on test data...
Evaluate data in 123.41 seconds!
[tester] 
AGNewsMetric: acc=0.8607894736842105, hinge=1.918012829830772, ce=8.791462619179173
Global test acc @ epoch 137: 0.8608
Global epoch 138...
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0008128162007778883
Local loss @ local epoch 1: 9.801411215448752e-05
Local loss @ local epoch 2: 0.00010837451554834843
Local loss @ local epoch 3: 0.0007106046541593969
Local loss @ local epoch 4: 0.02984917163848877
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.06 seconds!
[tester] 
AGNewsMetric: acc=0.7435526315789474, hinge=4.448116589094463, ce=10.012724249990363
Local test acc @ epoch 138: 0.7436
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 9.040022064255027e-07
Local loss @ local epoch 1: 1.2914334490687907e-07
Local loss @ local epoch 2: 3.973642748178463e-08
Local loss @ local epoch 3: 7.450553312082775e-07
Local loss @ local epoch 4: 4.967053257587395e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.24 seconds!
[tester] 
AGNewsMetric: acc=0.7671052631578947, hinge=3.9367308782276353, ce=9.408812667445133
Local test acc @ epoch 138: 0.7671
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.00032712784013710916
Local loss @ local epoch 1: 3.6000669751956593e-06
Local loss @ local epoch 2: 1.6982170564006083e-05
Local loss @ local epoch 3: 3.5126765851600794e-06
Local loss @ local epoch 4: 4.7001816710690036e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.19 seconds!
[tester] 
AGNewsMetric: acc=0.5746052631578947, hinge=9.212543523688066, ce=13.559567983526932
Local test acc @ epoch 138: 0.5746
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0010171051835641265
Local loss @ local epoch 1: 2.5828663297033927e-07
Local loss @ local epoch 2: 1.0828109680005582e-06
Local loss @ local epoch 3: 2.9305153930181405e-06
Local loss @ local epoch 4: 1.3609648021883913e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.06 seconds!
[tester] 
AGNewsMetric: acc=0.435, hinge=13.539796109952425, ce=13.077979830691689
Local test acc @ epoch 138: 0.435
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 2.1024127363489242e-06
Local loss @ local epoch 1: 3.2511621839148575e-08
Local loss @ local epoch 2: 2.178257773266523e-06
Local loss @ local epoch 3: 6.502323657286979e-08
Local loss @ local epoch 4: 2.3841845120387006e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.99 seconds!
[tester] 
AGNewsMetric: acc=0.44092105263157894, hinge=13.230074395631489, ce=13.280641384124756
Local test acc @ epoch 138: 0.4409
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.06227199733257294
Local loss @ local epoch 1: 2.4056635083979927e-05
Local loss @ local epoch 2: 2.4458229745505378e-05
Local loss @ local epoch 3: 0.0007278234697878361
Local loss @ local epoch 4: 0.2557716369628906
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.81 seconds!
[tester] 
AGNewsMetric: acc=0.611578947368421, hinge=3.7169273941140424, ce=9.03209392748381
Local test acc @ epoch 138: 0.6116
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 2.0861619987044833e-07
Local loss @ local epoch 1: 1.7881390590446244e-07
Local loss @ local epoch 2: 4.172323428974778e-07
Local loss @ local epoch 3: 2.384184938364342e-07
Local loss @ local epoch 4: 1.1920927533992653e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.54 seconds!
[tester] 
AGNewsMetric: acc=0.7164473684210526, hinge=3.7604490026674773, ce=9.29331486149838
Local test acc @ epoch 138: 0.7164
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0006677261553704739
Local loss @ local epoch 1: 0.013285161927342415
Local loss @ local epoch 2: 0.001174526521936059
Local loss @ local epoch 3: 0.016761159524321556
Local loss @ local epoch 4: 0.11828012019395828
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.73 seconds!
[tester] 
AGNewsMetric: acc=0.7806578947368421, hinge=2.3206572811227097, ce=10.35436892459267
Local test acc @ epoch 138: 0.7807
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.004867842420935631
Local loss @ local epoch 1: 8.395841723540798e-05
Local loss @ local epoch 2: 0.00040411646477878094
Local loss @ local epoch 3: 7.493994053220376e-05
Local loss @ local epoch 4: 9.599804616300389e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.46 seconds!
[tester] 
AGNewsMetric: acc=0.5505263157894736, hinge=5.2345430273758735, ce=12.235552932337711
Local test acc @ epoch 138: 0.5505
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 2.384185648907078e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.384185648907078e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.66 seconds!
[tester] 
AGNewsMetric: acc=0.8088157894736843, hinge=2.8591391806853443, ce=10.087385006954795
Local test acc @ epoch 138: 0.8088
Global evaluate on test data...
Evaluate data in 124.65 seconds!
[tester] 
AGNewsMetric: acc=0.8410526315789474, hinge=2.497191199503447, ce=8.956147661711041
Global test acc @ epoch 138: 0.8411
Global epoch 139...
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 2.9802320611338473e-08
Local loss @ local epoch 1: 2.1855009890714427e-07
Local loss @ local epoch 2: 2.9802320611338473e-08
Local loss @ local epoch 3: 3.973642037635727e-08
Local loss @ local epoch 4: 4.967053257587395e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.72 seconds!
[tester] 
AGNewsMetric: acc=0.6273684210526316, hinge=7.976869557029323, ce=11.568788281490928
Local test acc @ epoch 139: 0.6274
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.010917369276285172
Local loss @ local epoch 1: 3.290160293545341e-06
Local loss @ local epoch 2: 2.193440195696894e-06
Local loss @ local epoch 3: 1.6012334526749328e-05
Local loss @ local epoch 4: 9.655353096604813e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.27 seconds!
[tester] 
AGNewsMetric: acc=0.5971052631578947, hinge=7.012624203782333, ce=12.666356341713353
Local test acc @ epoch 139: 0.5971
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 1.9073476664743794e-07
Local loss @ local epoch 1: 9.536741885085576e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.384185648907078e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.52 seconds!
[tester] 
AGNewsMetric: acc=0.7778947368421053, hinge=3.580216049646076, ce=9.666827346400211
Local test acc @ epoch 139: 0.7779
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 4.4069856812711805e-05
Local loss @ local epoch 1: 3.33781645167619e-06
Local loss @ local epoch 2: 1.4109536095929798e-05
Local loss @ local epoch 3: 0.0004715461400337517
Local loss @ local epoch 4: 1.8173141143051907e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.19 seconds!
[tester] 
AGNewsMetric: acc=0.7526315789473684, hinge=4.109702004382485, ce=9.974881216350354
Local test acc @ epoch 139: 0.7526
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 3.2511621839148575e-08
Local loss @ local epoch 1: 1.3004647314573958e-07
Local loss @ local epoch 2: 3.0344133961079933e-07
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 3.2511621839148575e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.58 seconds!
[tester] 
AGNewsMetric: acc=0.7247368421052631, hinge=4.903092376558404, ce=10.340784086930125
Local test acc @ epoch 139: 0.7247
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0007346929050981998
Local loss @ local epoch 1: 0.0012643502559512854
Local loss @ local epoch 2: 0.001470081740990281
Local loss @ local epoch 3: 0.0011366922408342361
Local loss @ local epoch 4: 0.03273620456457138
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.74 seconds!
[tester] 
AGNewsMetric: acc=0.5586842105263158, hinge=5.633541497682271, ce=12.697358880293997
Local test acc @ epoch 139: 0.5587
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 3.039824605366448e-06
Local loss @ local epoch 1: 1.615238215890713e-05
Local loss @ local epoch 2: 2.5629938136262354e-06
Local loss @ local epoch 3: 5.2717245125677437e-05
Local loss @ local epoch 4: 7.778325198160019e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.43 seconds!
[tester] 
AGNewsMetric: acc=0.6557894736842105, hinge=5.714551059070386, ce=11.400080927798623
Local test acc @ epoch 139: 0.6558
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.008317391388118267
Local loss @ local epoch 1: 5.601435623248108e-05
Local loss @ local epoch 2: 0.012257962487637997
Local loss @ local epoch 3: 6.146652140159858e-06
Local loss @ local epoch 4: 2.5331844426546013e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.42 seconds!
[tester] 
AGNewsMetric: acc=0.6136842105263158, hinge=6.954495976096705, ce=12.450889936748304
Local test acc @ epoch 139: 0.6137
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0010796800488606095
Local loss @ local epoch 1: 0.001291068852879107
Local loss @ local epoch 2: 0.008360072039067745
Local loss @ local epoch 3: 0.01189731527119875
Local loss @ local epoch 4: 0.0014020460657775402
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 122.9 seconds!
[tester] 
AGNewsMetric: acc=0.736578947368421, hinge=2.201246707564906, ce=12.244106995432
Local test acc @ epoch 139: 0.7366
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 2.5828651928350155e-07
Local loss @ local epoch 1: 3.3775950214476325e-07
Local loss @ local epoch 2: 1.5894563887286495e-07
Local loss @ local epoch 3: 3.973642392907095e-08
Local loss @ local epoch 4: 1.2914331648516963e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.16 seconds!
[tester] 
AGNewsMetric: acc=0.8043421052631579, hinge=3.372891542786046, ce=9.28833488263582
Local test acc @ epoch 139: 0.8043
Global evaluate on test data...
Evaluate data in 123.65 seconds!
[tester] 
AGNewsMetric: acc=0.8310526315789474, hinge=2.4092315249694023, ce=9.741347734551681
Global test acc @ epoch 139: 0.8311
Global epoch 140...
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.003012786852195859
Local loss @ local epoch 1: 4.967053257587395e-08
Local loss @ local epoch 2: 5.960446856079216e-07
Local loss @ local epoch 3: 3.7848112697247416e-06
Local loss @ local epoch 4: 0.0030210791155695915
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.65 seconds!
[tester] 
AGNewsMetric: acc=0.5552631578947368, hinge=9.86664746510355, ce=13.122436836644223
Local test acc @ epoch 140: 0.5553
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 9.563827916281298e-05
Local loss @ local epoch 1: 0.00026480143424123526
Local loss @ local epoch 2: 0.0019870412070304155
Local loss @ local epoch 3: 0.00044191928463988006
Local loss @ local epoch 4: 8.701449405634776e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.93 seconds!
[tester] 
AGNewsMetric: acc=0.43407894736842106, hinge=5.6410363036707825, ce=12.501058285361841
Local test acc @ epoch 140: 0.4341
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 9.298302643401257e-07
Local loss @ local epoch 1: 2.384185648907078e-08
Local loss @ local epoch 2: 4.768370942542788e-08
Local loss @ local epoch 3: 4.768370942542788e-08
Local loss @ local epoch 4: 2.384185648907078e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.82 seconds!
[tester] 
AGNewsMetric: acc=0.5430263157894737, hinge=8.586840778150057, ce=14.103477459957725
Local test acc @ epoch 140: 0.543
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.0508029460906982
Local loss @ local epoch 1: 0.0011702177580446005
Local loss @ local epoch 2: 1.0505291356821544e-06
Local loss @ local epoch 3: 7.234316399262752e-06
Local loss @ local epoch 4: 3.2037307846621843e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.0 seconds!
[tester] 
AGNewsMetric: acc=0.5825, hinge=6.227385518927323, ce=12.694472963433517
Local test acc @ epoch 140: 0.5825
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 1.0778673887252808
Local loss @ local epoch 1: 0.0001672507933108136
Local loss @ local epoch 2: 0.00012113909906474873
Local loss @ local epoch 3: 0.00018155401630792767
Local loss @ local epoch 4: 0.001350145903415978
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 122.86 seconds!
[tester] 
AGNewsMetric: acc=0.5802631578947368, hinge=7.476221330291346, ce=11.155775945563065
Local test acc @ epoch 140: 0.5803
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.6593819856643677
Local loss @ local epoch 1: 1.5172086875736568e-07
Local loss @ local epoch 2: 1.8423241954224068e-07
Local loss @ local epoch 3: 1.3004645893488487e-07
Local loss @ local epoch 4: 6.502324367829715e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.59 seconds!
[tester] 
AGNewsMetric: acc=0.4586842105263158, hinge=12.897738394486277, ce=13.384004254592092
Local test acc @ epoch 140: 0.4587
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.006858337204903364
Local loss @ local epoch 1: 8.02123686298728e-05
Local loss @ local epoch 2: 0.0012205011444166303
Local loss @ local epoch 3: 0.0005268494714982808
Local loss @ local epoch 4: 4.373817500891164e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 122.98 seconds!
[tester] 
AGNewsMetric: acc=0.6532894736842105, hinge=3.398758936179312, ce=10.178069976003547
Local test acc @ epoch 140: 0.6533
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.20899160206317902
Local loss @ local epoch 1: 5.960463411724959e-08
Local loss @ local epoch 2: 1.490115550950577e-07
Local loss @ local epoch 3: 4.5696847905674076e-07
Local loss @ local epoch 4: 1.1383792298147455e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.0 seconds!
[tester] 
AGNewsMetric: acc=0.3688157894736842, hinge=14.718439728586297, ce=15.25828847383198
Local test acc @ epoch 140: 0.3688
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 1.5199152585410047e-06
Local loss @ local epoch 1: 1.1026847914763493e-06
Local loss @ local epoch 2: 8.046622497204226e-07
Local loss @ local epoch 3: 6.258482585508318e-07
Local loss @ local epoch 4: 5.9604641222676946e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.94 seconds!
[tester] 
AGNewsMetric: acc=0.7910526315789473, hinge=3.0408785917884424, ce=8.97773108231394
Local test acc @ epoch 140: 0.7911
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.000281005835859105
Local loss @ local epoch 1: 0.004769050050526857
Local loss @ local epoch 2: 0.00013853835116606206
Local loss @ local epoch 3: 0.20658382773399353
Local loss @ local epoch 4: 0.000193322790437378
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 125.1 seconds!
[tester] 
AGNewsMetric: acc=0.779342105263158, hinge=2.412191686881216, ce=10.37132844422993
Local test acc @ epoch 140: 0.7793
Global evaluate on test data...
Evaluate data in 123.76 seconds!
[tester] 
AGNewsMetric: acc=0.8277631578947369, hinge=2.704081278600191, ce=9.059985821372583
Global test acc @ epoch 140: 0.8278
Global epoch 141...
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 9.53674117454284e-08
Local loss @ local epoch 1: 2.384185648907078e-08
Local loss @ local epoch 2: 7.152556236178498e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 4.768370942542788e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.69 seconds!
[tester] 
AGNewsMetric: acc=0.7718421052631579, hinge=3.1796972974977997, ce=10.193440991451865
Local test acc @ epoch 141: 0.7718
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0009698669309727848
Local loss @ local epoch 1: 0.0033556504640728235
Local loss @ local epoch 2: 0.0008617307175882161
Local loss @ local epoch 3: 0.0013219790998846292
Local loss @ local epoch 4: 0.000627197208814323
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.61 seconds!
[tester] 
AGNewsMetric: acc=0.5239473684210526, hinge=5.137284270336753, ce=12.358790524131374
Local test acc @ epoch 141: 0.5239
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 9.934106870446158e-09
Local loss @ local epoch 1: 1.3907747131725046e-07
Local loss @ local epoch 2: 2.9802320611338473e-08
Local loss @ local epoch 3: 1.0927514182412779e-07
Local loss @ local epoch 4: 1.9868213740892315e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.6 seconds!
[tester] 
AGNewsMetric: acc=0.8343421052631579, hinge=2.7463270433325517, ce=9.150437672263697
Local test acc @ epoch 141: 0.8343
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 1.589456815054291e-07
Local loss @ local epoch 1: 3.973642392907095e-08
Local loss @ local epoch 2: 3.973642392907095e-08
Local loss @ local epoch 3: 2.9802320611338473e-08
Local loss @ local epoch 4: 6.953874276405259e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.93 seconds!
[tester] 
AGNewsMetric: acc=0.7596052631578948, hinge=4.300556927229229, ce=9.901658379404168
Local test acc @ epoch 141: 0.7596
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 3.2511618286434896e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.167441515155133e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.43 seconds!
[tester] 
AGNewsMetric: acc=0.6857894736842105, hinge=6.020348230412132, ce=11.132889982524672
Local test acc @ epoch 141: 0.6858
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 2.184431468776893e-05
Local loss @ local epoch 1: 8.225308192777447e-06
Local loss @ local epoch 2: 3.203547021257691e-05
Local loss @ local epoch 3: 7.450572638845188e-07
Local loss @ local epoch 4: 2.6822084464583895e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.53 seconds!
[tester] 
AGNewsMetric: acc=0.6510526315789473, hinge=5.308628662008989, ce=11.487606512370862
Local test acc @ epoch 141: 0.6511
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.6268385052680969
Local loss @ local epoch 1: 1.2516260539996438e-05
Local loss @ local epoch 2: 4.3073973756690975e-06
Local loss @ local epoch 3: 4.033063305541873e-05
Local loss @ local epoch 4: 2.064486216113437e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 122.62 seconds!
[tester] 
AGNewsMetric: acc=0.5935526315789473, hinge=6.057548981716758, ce=12.520869859394274
Local test acc @ epoch 141: 0.5936
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0011355112073943019
Local loss @ local epoch 1: 2.464125633239746
Local loss @ local epoch 2: 0.0010368243092671037
Local loss @ local epoch 3: 0.0016817925497889519
Local loss @ local epoch 4: 0.0011872396571561694
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.33 seconds!
[tester] 
AGNewsMetric: acc=0.4428947368421053, hinge=4.664719309555857, ce=11.682219161987305
Local test acc @ epoch 141: 0.4429
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.030327877029776573
Local loss @ local epoch 1: 0.00010984112304868177
Local loss @ local epoch 2: 1.3560029401560314e-06
Local loss @ local epoch 3: 2.235164174635429e-06
Local loss @ local epoch 4: 3.0696219255332835e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.56 seconds!
[tester] 
AGNewsMetric: acc=0.5410526315789473, hinge=7.73704058797736, ce=13.82927597648219
Local test acc @ epoch 141: 0.5411
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 2.96250782412244e-05
Local loss @ local epoch 1: 1.6980617147055455e-05
Local loss @ local epoch 2: 8.886244359018747e-06
Local loss @ local epoch 3: 5.732791123591596e-06
Local loss @ local epoch 4: 0.00011175437975907698
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.79 seconds!
[tester] 
AGNewsMetric: acc=0.7610526315789473, hinge=3.8543041708594874, ce=10.752870953208522
Local test acc @ epoch 141: 0.7611
Global evaluate on test data...
Evaluate data in 123.56 seconds!
[tester] 
AGNewsMetric: acc=0.8417105263157895, hinge=2.1085551500320436, ce=9.39029575950221
Global test acc @ epoch 141: 0.8417
Global epoch 142...
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.078095942735672
Local loss @ local epoch 1: 4.373436695459532e-06
Local loss @ local epoch 2: 2.4368249796680175e-05
Local loss @ local epoch 3: 3.942568946513347e-05
Local loss @ local epoch 4: 1.2859301932621747e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.67 seconds!
[tester] 
AGNewsMetric: acc=0.5252631578947369, hinge=9.725454570368717, ce=13.826472826505961
Local test acc @ epoch 142: 0.5253
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 1.1920925402364446e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.384185648907078e-08
Local loss @ local epoch 4: 2.384185648907078e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.36 seconds!
[tester] 
AGNewsMetric: acc=0.858421052631579, hinge=1.9739240074157716, ce=8.929764954416376
Local test acc @ epoch 142: 0.8584
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.14892269670963287
Local loss @ local epoch 1: 2.9802320611338473e-08
Local loss @ local epoch 2: 6.953874276405259e-08
Local loss @ local epoch 3: 1.8874793283885083e-07
Local loss @ local epoch 4: 4.3710028307941684e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.64 seconds!
[tester] 
AGNewsMetric: acc=0.38605263157894737, hinge=14.502393142298649, ce=14.295867167021099
Local test acc @ epoch 142: 0.3861
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 1.1920928244535389e-07
Local loss @ local epoch 1: 1.4901159772762185e-07
Local loss @ local epoch 2: 6.854526191091281e-07
Local loss @ local epoch 3: 2.6822075938071066e-07
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.33 seconds!
[tester] 
AGNewsMetric: acc=0.718421052631579, hinge=4.387442921086362, ce=9.415188259325529
Local test acc @ epoch 142: 0.7184
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0007480945787392557
Local loss @ local epoch 1: 1.9868211964535476e-08
Local loss @ local epoch 2: 5.265063123260916e-07
Local loss @ local epoch 3: 5.235155185800977e-06
Local loss @ local epoch 4: 3.804736479651183e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.46 seconds!
[tester] 
AGNewsMetric: acc=0.4373684210526316, hinge=13.50846533574556, ce=14.03462454344097
Local test acc @ epoch 142: 0.4374
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.00010056110477307811
Local loss @ local epoch 1: 0.00010353908146498725
Local loss @ local epoch 2: 1.6689153198967688e-05
Local loss @ local epoch 3: 0.00022105558309704065
Local loss @ local epoch 4: 0.002395940711721778
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.97 seconds!
[tester] 
AGNewsMetric: acc=0.7093421052631579, hinge=3.7270266347182424, ce=12.426419860438296
Local test acc @ epoch 142: 0.7093
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.0005664328928105533
Local loss @ local epoch 1: 3.5603625292424113e-06
Local loss @ local epoch 2: 2.7682808649842627e-05
Local loss @ local epoch 3: 0.008516942150890827
Local loss @ local epoch 4: 3.623905513450154e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.57 seconds!
[tester] 
AGNewsMetric: acc=0.7292105263157894, hinge=3.750739496381659, ce=9.99545880568655
Local test acc @ epoch 142: 0.7292
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0018124281195923686
Local loss @ local epoch 1: 1.3004647314573958e-07
Local loss @ local epoch 2: 2.2758122497634758e-07
Local loss @ local epoch 3: 1.0837207042868613e-07
Local loss @ local epoch 4: 3.467905003162741e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.72 seconds!
[tester] 
AGNewsMetric: acc=0.6394736842105263, hinge=6.940875215530395, ce=11.77093839946546
Local test acc @ epoch 142: 0.6395
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0006597813917323947
Local loss @ local epoch 1: 0.00023281524772755802
Local loss @ local epoch 2: 0.00026339080068282783
Local loss @ local epoch 3: 2.8949853003723547e-05
Local loss @ local epoch 4: 0.0041748941875994205
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 125.09 seconds!
[tester] 
AGNewsMetric: acc=0.5714473684210526, hinge=6.800097045898437, ce=13.645367596274928
Local test acc @ epoch 142: 0.5714
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.7434511184692383
Local loss @ local epoch 1: 5.7151926739607006e-05
Local loss @ local epoch 2: 2.827180469466839e-05
Local loss @ local epoch 3: 0.000371796078979969
Local loss @ local epoch 4: 0.14382590353488922
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.21 seconds!
[tester] 
AGNewsMetric: acc=0.6605263157894737, hinge=6.40227428536666, ce=10.87123714246248
Local test acc @ epoch 142: 0.6605
Global evaluate on test data...
Evaluate data in 123.33 seconds!
[tester] 
AGNewsMetric: acc=0.8289473684210527, hinge=2.7577320673591212, ce=9.125354218733937
Global test acc @ epoch 142: 0.8289
Global epoch 143...
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 2.384185648907078e-08
Local loss @ local epoch 1: 4.768371297814156e-08
Local loss @ local epoch 2: 4.768370942542788e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.23 seconds!
[tester] 
AGNewsMetric: acc=0.7690789473684211, hinge=3.568352608680725, ce=10.176852661935907
Local test acc @ epoch 143: 0.7691
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0007041869102977216
Local loss @ local epoch 1: 0.0006204309174790978
Local loss @ local epoch 2: 1.609318019291095e-06
Local loss @ local epoch 3: 1.5348167607953656e-06
Local loss @ local epoch 4: 2.980229396598588e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.5 seconds!
[tester] 
AGNewsMetric: acc=0.49855263157894736, hinge=10.796552659586856, ce=15.223409116644609
Local test acc @ epoch 143: 0.4986
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0010799424489960074
Local loss @ local epoch 1: 0.0003691869496833533
Local loss @ local epoch 2: 0.008567489683628082
Local loss @ local epoch 3: 0.00039713154546916485
Local loss @ local epoch 4: 0.0017454380868002772
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.39 seconds!
[tester] 
AGNewsMetric: acc=0.7405263157894737, hinge=2.399279078684355, ce=9.172083296524852
Local test acc @ epoch 143: 0.7405
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 1.1920928244535389e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.6822084464583895e-07
Local loss @ local epoch 3: 2.9802320611338473e-08
Local loss @ local epoch 4: 1.1920926112907182e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.58 seconds!
[tester] 
AGNewsMetric: acc=0.8414473684210526, hinge=2.5835692900105527, ce=9.371291248923853
Local test acc @ epoch 143: 0.8414
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 2.3841836593874177e-07
Local loss @ local epoch 1: 6.502323657286979e-08
Local loss @ local epoch 2: 1.1920923981278975e-07
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.36 seconds!
[tester] 
AGNewsMetric: acc=0.4531578947368421, hinge=13.672506527147796, ce=15.299723261782997
Local test acc @ epoch 143: 0.4532
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 8.940694584680386e-08
Local loss @ local epoch 1: 1.2914335911773378e-07
Local loss @ local epoch 2: 5.9604641222676946e-08
Local loss @ local epoch 3: 4.967053257587395e-08
Local loss @ local epoch 4: 8.940691742509443e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.02 seconds!
[tester] 
AGNewsMetric: acc=0.7918421052631579, hinge=3.5695688240151657, ce=9.560521655835604
Local test acc @ epoch 143: 0.7918
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.00019651582988444716
Local loss @ local epoch 1: 0.5921940207481384
Local loss @ local epoch 2: 0.012113222852349281
Local loss @ local epoch 3: 0.10910172015428543
Local loss @ local epoch 4: 0.06997508555650711
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.27 seconds!
[tester] 
AGNewsMetric: acc=0.8382894736842105, hinge=1.4371874081461053, ce=9.146712074279785
Local test acc @ epoch 143: 0.8383
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.10574696213006973
Local loss @ local epoch 1: 0.0001791927934391424
Local loss @ local epoch 2: 7.795979399816133e-06
Local loss @ local epoch 3: 4.603709385264665e-05
Local loss @ local epoch 4: 3.017007293237839e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.47 seconds!
[tester] 
AGNewsMetric: acc=0.6188157894736842, hinge=6.6103297552309535, ce=11.88709425072921
Local test acc @ epoch 143: 0.6188
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 1.5894561045115552e-07
Local loss @ local epoch 1: 6.953872144777051e-08
Local loss @ local epoch 2: 9.934105804632054e-08
Local loss @ local epoch 3: 5.9604641222676946e-08
Local loss @ local epoch 4: 7.947281943643247e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.91 seconds!
[tester] 
AGNewsMetric: acc=0.6996052631578947, hinge=6.213077355936954, ce=10.66087036333586
Local test acc @ epoch 143: 0.6996
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 1.1877133147208951e-05
Local loss @ local epoch 1: 0.0001823496859287843
Local loss @ local epoch 2: 1.929010750245652e-06
Local loss @ local epoch 3: 4.19394064010703e-06
Local loss @ local epoch 4: 2.3969631001818925e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.84 seconds!
[tester] 
AGNewsMetric: acc=0.8219736842105263, hinge=2.415981110271655, ce=9.137127290023
Local test acc @ epoch 143: 0.822
Global evaluate on test data...
Evaluate data in 123.55 seconds!
[tester] 
AGNewsMetric: acc=0.8564473684210526, hinge=2.130426844797636, ce=9.019691258480675
Global test acc @ epoch 143: 0.8564
Global epoch 144...
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 5.884471192985075e-06
Local loss @ local epoch 1: 1.8423239112053125e-07
Local loss @ local epoch 2: 7.586044858953755e-08
Local loss @ local epoch 3: 5.028360646974761e-06
Local loss @ local epoch 4: 2.8176734190310526e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.86 seconds!
[tester] 
AGNewsMetric: acc=0.4676315789473684, hinge=13.160886196588216, ce=13.301404506281802
Local test acc @ epoch 144: 0.4676
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 1.0132779380001011e-06
Local loss @ local epoch 1: 8.940696005765858e-08
Local loss @ local epoch 2: 2.086161714487389e-07
Local loss @ local epoch 3: 5.9604641222676946e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.78 seconds!
[tester] 
AGNewsMetric: acc=0.6021052631578947, hinge=6.704978730553075, ce=11.691463335940712
Local test acc @ epoch 144: 0.6021
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 6.36154945823364e-05
Local loss @ local epoch 1: 6.687235145363957e-05
Local loss @ local epoch 2: 0.00019312789663672447
Local loss @ local epoch 3: 2.3920931198517792e-05
Local loss @ local epoch 4: 0.00013564253458753228
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.12 seconds!
[tester] 
AGNewsMetric: acc=0.4861842105263158, hinge=6.3513628096329535, ce=13.913248662446675
Local test acc @ epoch 144: 0.4862
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.07647107541561127
Local loss @ local epoch 1: 6.528718222398311e-05
Local loss @ local epoch 2: 4.6807239414192736e-05
Local loss @ local epoch 3: 9.78328098426573e-05
Local loss @ local epoch 4: 0.14829418063163757
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.03 seconds!
[tester] 
AGNewsMetric: acc=0.6478947368421053, hinge=7.931064534438284, ce=11.2210916800248
Local test acc @ epoch 144: 0.6479
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 2.384185648907078e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 4.768370942542788e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.26 seconds!
[tester] 
AGNewsMetric: acc=0.48236842105263156, hinge=11.44652238946212, ce=16.46010941756399
Local test acc @ epoch 144: 0.4824
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 1.708653940113436e-06
Local loss @ local epoch 1: 7.947284075271455e-08
Local loss @ local epoch 2: 1.0927513471870043e-07
Local loss @ local epoch 3: 4.2716615666904545e-07
Local loss @ local epoch 4: 0.031739912927150726
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.32 seconds!
[tester] 
AGNewsMetric: acc=0.8019736842105263, hinge=3.4162496882990787, ce=10.191359124434621
Local test acc @ epoch 144: 0.802
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 3.188079426763579e-05
Local loss @ local epoch 1: 1.3600156307802536e-05
Local loss @ local epoch 2: 5.743635483668186e-06
Local loss @ local epoch 3: 0.0005953020881861448
Local loss @ local epoch 4: 0.00018440611893311143
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.06 seconds!
[tester] 
AGNewsMetric: acc=0.758421052631579, hinge=4.1196350273333096, ce=10.00704876347592
Local test acc @ epoch 144: 0.7584
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.017300816252827644
Local loss @ local epoch 1: 1.6768713066994678e-06
Local loss @ local epoch 2: 1.4248676961869933e-05
Local loss @ local epoch 3: 0.32858866453170776
Local loss @ local epoch 4: 6.39743848296348e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.11 seconds!
[tester] 
AGNewsMetric: acc=0.6521052631578947, hinge=6.117150716279682, ce=11.37905514566522
Local test acc @ epoch 144: 0.6521
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.20368605852127075
Local loss @ local epoch 1: 1.8477247749615344e-06
Local loss @ local epoch 2: 8.940694584680386e-08
Local loss @ local epoch 3: 2.5828660454862984e-07
Local loss @ local epoch 4: 5.265070512905368e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.85 seconds!
[tester] 
AGNewsMetric: acc=0.46421052631578946, hinge=12.110348388772262, ce=13.248436675824617
Local test acc @ epoch 144: 0.4642
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 8.563620212953538e-05
Local loss @ local epoch 1: 0.0010534567991271615
Local loss @ local epoch 2: 0.003969889599829912
Local loss @ local epoch 3: 0.001123855821788311
Local loss @ local epoch 4: 7.184325659181923e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.45 seconds!
[tester] 
AGNewsMetric: acc=0.8178947368421052, hinge=2.226541324414705, ce=10.704917658755654
Local test acc @ epoch 144: 0.8179
Global evaluate on test data...
Evaluate data in 123.98 seconds!
[tester] 
AGNewsMetric: acc=0.8432894736842105, hinge=2.6040069810967696, ce=9.123368112664474
Global test acc @ epoch 144: 0.8433
Global epoch 145...
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 3.0344145329763705e-07
Local loss @ local epoch 1: 8.669762507906853e-08
Local loss @ local epoch 2: 2.167441337519449e-08
Local loss @ local epoch 3: 4.334882675038898e-08
Local loss @ local epoch 4: 1.3004647314573958e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.78 seconds!
[tester] 
AGNewsMetric: acc=0.7130263157894737, hinge=5.117291451504356, ce=9.618828765467594
Local test acc @ epoch 145: 0.713
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.00014401391672436148
Local loss @ local epoch 1: 4.529948682829854e-07
Local loss @ local epoch 2: 2.9519474992412142e-05
Local loss @ local epoch 3: 1.6689297410721338e-07
Local loss @ local epoch 4: 8.662532877679041e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.3 seconds!
[tester] 
AGNewsMetric: acc=0.485, hinge=11.880101014187462, ce=16.20879594903243
Local test acc @ epoch 145: 0.485
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0002177549322368577
Local loss @ local epoch 1: 0.0009845008607953787
Local loss @ local epoch 2: 0.0009172730497084558
Local loss @ local epoch 3: 0.009276735596358776
Local loss @ local epoch 4: 0.0005773587035946548
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.41 seconds!
[tester] 
AGNewsMetric: acc=0.5698684210526316, hinge=4.002072065253007, ce=11.5048694911756
Local test acc @ epoch 145: 0.5699
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 1.5695741240051575e-06
Local loss @ local epoch 1: 4.967045583725849e-07
Local loss @ local epoch 2: 6.953874276405259e-08
Local loss @ local epoch 3: 6.755174695172173e-07
Local loss @ local epoch 4: 8.940694584680386e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.27 seconds!
[tester] 
AGNewsMetric: acc=0.7592105263157894, hinge=3.800980204030087, ce=9.614425163269043
Local test acc @ epoch 145: 0.7592
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 7.116936467355117e-05
Local loss @ local epoch 1: 1.06851739474223e-05
Local loss @ local epoch 2: 1.442380562366452e-05
Local loss @ local epoch 3: 5.8648092817747965e-05
Local loss @ local epoch 4: 8.376889127248432e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.92 seconds!
[tester] 
AGNewsMetric: acc=0.7675, hinge=3.766810565496746, ce=9.788744151466771
Local test acc @ epoch 145: 0.7675
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 7.94728478581419e-08
Local loss @ local epoch 1: 1.0927513471870043e-07
Local loss @ local epoch 2: 9.934106870446158e-09
Local loss @ local epoch 3: 3.973642748178463e-08
Local loss @ local epoch 4: 8.940691742509443e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.62 seconds!
[tester] 
AGNewsMetric: acc=0.6486842105263158, hinge=7.313477321925916, ce=11.630927898005435
Local test acc @ epoch 145: 0.6487
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0267891027033329
Local loss @ local epoch 1: 4.033107325085439e-05
Local loss @ local epoch 2: 0.4546588063240051
Local loss @ local epoch 3: 0.049858566373586655
Local loss @ local epoch 4: 1.3268835573398974e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.53 seconds!
[tester] 
AGNewsMetric: acc=0.7623684210526316, hinge=2.990164442564312, ce=9.681132372805946
Local test acc @ epoch 145: 0.7624
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 4.768368739860307e-07
Local loss @ local epoch 1: 1.907344994833693e-06
Local loss @ local epoch 2: 6.258481448639941e-07
Local loss @ local epoch 3: 0.0003610625280998647
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.99 seconds!
[tester] 
AGNewsMetric: acc=0.8152631578947368, hinge=2.9003861148733843, ce=9.001831895928634
Local test acc @ epoch 145: 0.8153
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.00012018945562886074
Local loss @ local epoch 1: 0.0002564774767961353
Local loss @ local epoch 2: 1.8516997442930005e-05
Local loss @ local epoch 3: 9.218763807439245e-06
Local loss @ local epoch 4: 2.0662480892497115e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 122.97 seconds!
[tester] 
AGNewsMetric: acc=0.5931578947368421, hinge=3.9484079787605686, ce=11.555916324414705
Local test acc @ epoch 145: 0.5932
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 2.384185648907078e-08
Local loss @ local epoch 1: 2.384185648907078e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.4 seconds!
[tester] 
AGNewsMetric: acc=0.8438157894736842, hinge=2.513069745364942, ce=9.85697076094778
Local test acc @ epoch 145: 0.8438
Global evaluate on test data...
Evaluate data in 123.21 seconds!
[tester] 
AGNewsMetric: acc=0.8581578947368421, hinge=2.090178659087733, ce=9.00470573425293
Global test acc @ epoch 145: 0.8582
Global epoch 146...
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 4.768371297814156e-08
Local loss @ local epoch 1: 2.384185648907078e-08
Local loss @ local epoch 2: 2.384185648907078e-08
Local loss @ local epoch 3: 2.384185648907078e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.38 seconds!
[tester] 
AGNewsMetric: acc=0.6246052631578948, hinge=7.299662814893221, ce=13.34930995539615
Local test acc @ epoch 146: 0.6246
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.00013771222438663244
Local loss @ local epoch 1: 0.00021192291751503944
Local loss @ local epoch 2: 0.0004448189865797758
Local loss @ local epoch 3: 2.348364796489477e-05
Local loss @ local epoch 4: 9.957355359802023e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.55 seconds!
[tester] 
AGNewsMetric: acc=0.44157894736842107, hinge=6.112615664632697, ce=9.55805454856471
Local test acc @ epoch 146: 0.4416
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.39164063334465027
Local loss @ local epoch 1: 6.697849585179938e-06
Local loss @ local epoch 2: 2.9626051400555298e-05
Local loss @ local epoch 3: 3.1515737646259367e-06
Local loss @ local epoch 4: 0.00012320888345129788
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.41 seconds!
[tester] 
AGNewsMetric: acc=0.5976315789473684, hinge=8.3667733669281, ce=12.125223527205618
Local test acc @ epoch 146: 0.5976
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.11585468798875809
Local loss @ local epoch 1: 2.2888089006301016e-06
Local loss @ local epoch 2: 6.223934178706259e-05
Local loss @ local epoch 3: 0.4034039378166199
Local loss @ local epoch 4: 4.347141384641873e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.14 seconds!
[tester] 
AGNewsMetric: acc=0.6186842105263158, hinge=7.477063913847271, ce=12.08932049399928
Local test acc @ epoch 146: 0.6187
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.00024157970619853586
Local loss @ local epoch 1: 6.953874986947994e-08
Local loss @ local epoch 2: 0.040114328265190125
Local loss @ local epoch 3: 6.953873565862523e-08
Local loss @ local epoch 4: 1.291433733285885e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.86 seconds!
[tester] 
AGNewsMetric: acc=0.7919736842105263, hinge=3.4472920053883604, ce=9.188317178425036
Local test acc @ epoch 146: 0.792
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 6.053843389963731e-05
Local loss @ local epoch 1: 1.0837207575775665e-08
Local loss @ local epoch 2: 7.586044858953755e-08
Local loss @ local epoch 3: 3.142785658383218e-07
Local loss @ local epoch 4: 4.5516250679611403e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.05 seconds!
[tester] 
AGNewsMetric: acc=0.47039473684210525, hinge=12.377358660196004, ce=12.60307237223575
Local test acc @ epoch 146: 0.4704
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.2788313627243042
Local loss @ local epoch 1: 1.506366288595018e-06
Local loss @ local epoch 2: 0.8844337463378906
Local loss @ local epoch 3: 0.0055153463035821915
Local loss @ local epoch 4: 1.0728579582064413e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.9 seconds!
[tester] 
AGNewsMetric: acc=0.7621052631578947, hinge=3.9420236248719065, ce=9.545936357598556
Local test acc @ epoch 146: 0.7621
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 2.0861622829215776e-07
Local loss @ local epoch 1: 2.6822084464583895e-07
Local loss @ local epoch 2: 2.9802320611338473e-08
Local loss @ local epoch 3: 1.4901156930591242e-07
Local loss @ local epoch 4: 8.940696005765858e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.49 seconds!
[tester] 
AGNewsMetric: acc=0.6818421052631579, hinge=5.669490065574646, ce=11.431865298622533
Local test acc @ epoch 146: 0.6818
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 6.953874986947994e-08
Local loss @ local epoch 1: 3.973642392907095e-08
Local loss @ local epoch 2: 1.9868213740892315e-08
Local loss @ local epoch 3: 2.9802320611338473e-08
Local loss @ local epoch 4: 1.9868211964535476e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.91 seconds!
[tester] 
AGNewsMetric: acc=0.7803947368421053, hinge=4.034725835950751, ce=9.648907575105365
Local test acc @ epoch 146: 0.7804
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.00012012471415800974
Local loss @ local epoch 1: 5.413066173787229e-05
Local loss @ local epoch 2: 0.00018218446348328143
Local loss @ local epoch 3: 5.181910455576144e-05
Local loss @ local epoch 4: 0.00015190044359769672
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.46 seconds!
[tester] 
AGNewsMetric: acc=0.7278947368421053, hinge=3.1301543351223593, ce=12.521384829470986
Local test acc @ epoch 146: 0.7279
Global evaluate on test data...
Evaluate data in 123.68 seconds!
[tester] 
AGNewsMetric: acc=0.8396052631578947, hinge=2.5032845607556795, ce=9.06534416399504
Global test acc @ epoch 146: 0.8396
Global epoch 147...
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 6.031677548890002e-05
Local loss @ local epoch 1: 0.00035352533450350165
Local loss @ local epoch 2: 0.02475443296134472
Local loss @ local epoch 3: 0.0006440514116548002
Local loss @ local epoch 4: 0.00019718783732969314
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.53 seconds!
[tester] 
AGNewsMetric: acc=0.7336842105263158, hinge=2.6317349469034297, ce=4.854386967106869
Local test acc @ epoch 147: 0.7337
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 3.973642748178463e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 3.973642037635727e-08
Local loss @ local epoch 3: 5.960463056453591e-08
Local loss @ local epoch 4: 1.1920920428565296e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.76 seconds!
[tester] 
AGNewsMetric: acc=0.8260526315789474, hinge=2.9595167723454927, ce=8.705542903699373
Local test acc @ epoch 147: 0.8261
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 5.559415512834676e-06
Local loss @ local epoch 1: 6.0361649047990795e-06
Local loss @ local epoch 2: 6.881504759803647e-06
Local loss @ local epoch 3: 6.415522875613533e-06
Local loss @ local epoch 4: 2.61174045590451e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.05 seconds!
[tester] 
AGNewsMetric: acc=0.7882894736842105, hinge=3.339963838677657, ce=9.649336838973197
Local test acc @ epoch 147: 0.7883
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 3.2511621839148575e-08
Local loss @ local epoch 1: 1.7339516489300877e-07
Local loss @ local epoch 2: 3.2511621839148575e-08
Local loss @ local epoch 3: 3.2511621839148575e-08
Local loss @ local epoch 4: 4.334883030310266e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.48 seconds!
[tester] 
AGNewsMetric: acc=0.4909210526315789, hinge=11.882158926913613, ce=13.317107696533203
Local test acc @ epoch 147: 0.4909
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 6.261729140533134e-05
Local loss @ local epoch 1: 0.10187875479459763
Local loss @ local epoch 2: 1.346176941297017e-05
Local loss @ local epoch 3: 3.838512839138275e-06
Local loss @ local epoch 4: 2.6464085749466904e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.55 seconds!
[tester] 
AGNewsMetric: acc=0.6338157894736842, hinge=6.872464884958769, ce=12.63023851093493
Local test acc @ epoch 147: 0.6338
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 3.794740769080818e-05
Local loss @ local epoch 1: 1.601358235348016e-05
Local loss @ local epoch 2: 0.0003109518438577652
Local loss @ local epoch 3: 0.0006330705364234746
Local loss @ local epoch 4: 0.00038686953485012054
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.39 seconds!
[tester] 
AGNewsMetric: acc=0.5717105263157894, hinge=5.944056369379947, ce=12.025029353091591
Local test acc @ epoch 147: 0.5717
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0001039042035699822
Local loss @ local epoch 1: 4.932193860440748e-06
Local loss @ local epoch 2: 9.543568012304604e-06
Local loss @ local epoch 3: 3.3750986858649412e-06
Local loss @ local epoch 4: 0.00011434473708504811
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.6 seconds!
[tester] 
AGNewsMetric: acc=0.6057894736842105, hinge=8.174765394612363, ce=12.893861371090537
Local test acc @ epoch 147: 0.6058
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 4.271657587651134e-07
Local loss @ local epoch 1: 1.9868213740892315e-08
Local loss @ local epoch 2: 3.377593600362161e-07
Local loss @ local epoch 3: 9.93410154137564e-08
Local loss @ local epoch 4: 1.4901156930591242e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.06 seconds!
[tester] 
AGNewsMetric: acc=0.5369736842105263, hinge=9.8244312976536, ce=12.480811122091193
Local test acc @ epoch 147: 0.537
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.1682475360430544e-06
Local loss @ local epoch 4: 1.6689293147464923e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.42 seconds!
[tester] 
AGNewsMetric: acc=0.7339473684210527, hinge=4.777731858303673, ce=12.039673351488615
Local test acc @ epoch 147: 0.7339
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 7.748596999590518e-07
Local loss @ local epoch 1: 8.940688189795765e-07
Local loss @ local epoch 2: 5.9604641222676946e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.4007063100507366e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.37 seconds!
[tester] 
AGNewsMetric: acc=0.7544736842105263, hinge=3.6840939848046554, ce=9.281536208704898
Local test acc @ epoch 147: 0.7545
Global evaluate on test data...
Evaluate data in 124.06 seconds!
[tester] 
AGNewsMetric: acc=0.8530263157894736, hinge=2.3427598279400876, ce=8.81540532162315
Global test acc @ epoch 147: 0.853
Global epoch 148...
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 5.161510853213258e-05
Local loss @ local epoch 1: 0.0011088086757808924
Local loss @ local epoch 2: 0.0025445891078561544
Local loss @ local epoch 3: 0.001066661672666669
Local loss @ local epoch 4: 2.9920933229732327e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.9 seconds!
[tester] 
AGNewsMetric: acc=0.7359210526315789, hinge=3.3616335760919673, ce=10.90728578065571
Local test acc @ epoch 148: 0.7359
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.4714096486568451
Local loss @ local epoch 1: 0.0007956189219839871
Local loss @ local epoch 2: 0.4581502079963684
Local loss @ local epoch 3: 0.01846538670361042
Local loss @ local epoch 4: 4.8185909690801054e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.33 seconds!
[tester] 
AGNewsMetric: acc=0.6221052631578947, hinge=4.7257268205441925, ce=11.558931346692537
Local test acc @ epoch 148: 0.6221
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 1.1920920428565296e-07
Local loss @ local epoch 1: 1.9868213740892315e-08
Local loss @ local epoch 2: 3.3775941687963495e-07
Local loss @ local epoch 3: 3.1789105037205445e-07
Local loss @ local epoch 4: 6.953874276405259e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.74 seconds!
[tester] 
AGNewsMetric: acc=0.5375, hinge=10.973673828526547, ce=13.41346305847168
Local test acc @ epoch 148: 0.5375
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 1.3221318795331172e-06
Local loss @ local epoch 1: 2.56840303336503e-06
Local loss @ local epoch 2: 1.7989725620282115e-06
Local loss @ local epoch 3: 6.490264786407351e-05
Local loss @ local epoch 4: 6.957281129871262e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.37 seconds!
[tester] 
AGNewsMetric: acc=0.7775, hinge=3.718589741556268, ce=9.699249787581595
Local test acc @ epoch 148: 0.7775
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 2.167441337519449e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.0837207575775665e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 5.4186031661629386e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.99 seconds!
[tester] 
AGNewsMetric: acc=0.8155263157894737, hinge=3.2150365380236976, ce=9.918508541709498
Local test acc @ epoch 148: 0.8155
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 5.9604641222676946e-08
Local loss @ local epoch 1: 1.1920927533992653e-07
Local loss @ local epoch 2: 1.4901156930591242e-07
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.31 seconds!
[tester] 
AGNewsMetric: acc=0.7117105263157895, hinge=5.622763188512701, ce=10.890676128989773
Local test acc @ epoch 148: 0.7117
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.5645397305488586
Local loss @ local epoch 1: 3.9482114516431466e-05
Local loss @ local epoch 2: 0.0012942011235281825
Local loss @ local epoch 3: 6.688800203846768e-05
Local loss @ local epoch 4: 0.7596963047981262
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.85 seconds!
[tester] 
AGNewsMetric: acc=0.6460526315789473, hinge=7.494760625738847, ce=10.931665290029425
Local test acc @ epoch 148: 0.6461
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 7.940181967569515e-05
Local loss @ local epoch 1: 7.185740832937881e-05
Local loss @ local epoch 2: 6.198128539836034e-05
Local loss @ local epoch 3: 0.00012426117609720677
Local loss @ local epoch 4: 4.666168933908921e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.43 seconds!
[tester] 
AGNewsMetric: acc=0.7017105263157895, hinge=5.1604036953574735, ce=10.876113574379369
Local test acc @ epoch 148: 0.7017
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.384185648907078e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.51 seconds!
[tester] 
AGNewsMetric: acc=0.7776315789473685, hinge=3.6341327266944083, ce=11.017203708447909
Local test acc @ epoch 148: 0.7776
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 5.960463056453591e-08
Local loss @ local epoch 1: 2.9802320611338473e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.781546299956972e-07
Local loss @ local epoch 4: 1.490115550950577e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.51 seconds!
[tester] 
AGNewsMetric: acc=0.843421052631579, hinge=2.7038201394834016, ce=9.110462060225638
Local test acc @ epoch 148: 0.8434
Global evaluate on test data...
Evaluate data in 123.58 seconds!
[tester] 
AGNewsMetric: acc=0.8351315789473684, hinge=2.6788684059444225, ce=9.352013075979132
Global test acc @ epoch 148: 0.8351
Global epoch 149...
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 2.920580118370708e-05
Local loss @ local epoch 1: 0.00017662641766946763
Local loss @ local epoch 2: 0.0001828818494686857
Local loss @ local epoch 3: 3.0039593184483238e-05
Local loss @ local epoch 4: 0.0002886937581934035
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.47 seconds!
[tester] 
AGNewsMetric: acc=0.5513157894736842, hinge=6.014152487704628, ce=11.697876518651059
Local test acc @ epoch 149: 0.5513
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 1.5172082612480153e-07
Local loss @ local epoch 1: 4.334882675038898e-08
Local loss @ local epoch 2: 1.0837207575775665e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 5.4186031661629386e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.86 seconds!
[tester] 
AGNewsMetric: acc=0.6313157894736842, hinge=7.957060131775705, ce=11.550323644939223
Local test acc @ epoch 149: 0.6313
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 1.4901156930591242e-07
Local loss @ local epoch 1: 5.9604641222676946e-08
Local loss @ local epoch 2: 1.4901156930591242e-07
Local loss @ local epoch 3: 5.9604641222676946e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.42 seconds!
[tester] 
AGNewsMetric: acc=0.7293421052631579, hinge=4.159039661507857, ce=10.004615530716746
Local test acc @ epoch 149: 0.7293
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.00016432952543254942
Local loss @ local epoch 1: 0.016230834648013115
Local loss @ local epoch 2: 2.5712646674946882e-05
Local loss @ local epoch 3: 3.8941681168580544e-07
Local loss @ local epoch 4: 1.3088049854559358e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.19 seconds!
[tester] 
AGNewsMetric: acc=0.609078947368421, hinge=7.06935665231002, ce=12.581602634630705
Local test acc @ epoch 149: 0.6091
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 2.8315338568063453e-05
Local loss @ local epoch 1: 9.86184318207961e-07
Local loss @ local epoch 2: 9.980571121559478e-06
Local loss @ local epoch 3: 0.12332852184772491
Local loss @ local epoch 4: 5.700312158296583e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.07 seconds!
[tester] 
AGNewsMetric: acc=0.8026315789473685, hinge=3.2451181848425614, ce=10.098733474329899
Local test acc @ epoch 149: 0.8026
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 4.053113684676646e-07
Local loss @ local epoch 1: 2.384185648907078e-08
Local loss @ local epoch 2: 4.768370942542788e-08
Local loss @ local epoch 3: 7.152556236178498e-08
Local loss @ local epoch 4: 2.384185648907078e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.79 seconds!
[tester] 
AGNewsMetric: acc=0.8307894736842105, hinge=2.7739448871110617, ce=9.575131841960706
Local test acc @ epoch 149: 0.8308
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.00022991516743786633
Local loss @ local epoch 1: 0.6469937562942505
Local loss @ local epoch 2: 0.00738048180937767
Local loss @ local epoch 3: 0.008038723841309547
Local loss @ local epoch 4: 0.011758910492062569
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.0 seconds!
[tester] 
AGNewsMetric: acc=0.8060526315789474, hinge=2.1030106361288774, ce=9.772366003739206
Local test acc @ epoch 149: 0.8061
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.1286928951740265
Local loss @ local epoch 1: 1.8402852219878696e-06
Local loss @ local epoch 2: 1.385804353049025e-06
Local loss @ local epoch 3: 4.153205009060912e-05
Local loss @ local epoch 4: 1.0579803984001046e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.27 seconds!
[tester] 
AGNewsMetric: acc=0.6327631578947368, hinge=7.529675769805908, ce=12.037737163744474
Local test acc @ epoch 149: 0.6328
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 4.3710039676625456e-07
Local loss @ local epoch 1: 4.967052191773291e-08
Local loss @ local epoch 2: 9.934106870446158e-09
Local loss @ local epoch 3: 8.940694584680386e-08
Local loss @ local epoch 4: 6.953874276405259e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.15 seconds!
[tester] 
AGNewsMetric: acc=0.5485526315789474, hinge=10.556150216052407, ce=12.239739606756913
Local test acc @ epoch 149: 0.5486
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 1.4901156930591242e-07
Local loss @ local epoch 1: 6.953874276405259e-08
Local loss @ local epoch 2: 1.9868211964535476e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.9868211964535476e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.6 seconds!
[tester] 
AGNewsMetric: acc=0.7625, hinge=4.275848922980459, ce=9.55844267995734
Local test acc @ epoch 149: 0.7625
Global evaluate on test data...
Evaluate data in 123.85 seconds!
[tester] 
AGNewsMetric: acc=0.8525, hinge=2.442815200906051, ce=8.888695987902189
Global test acc @ epoch 149: 0.8525
Global epoch 150...
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.03814661130309105
Local loss @ local epoch 1: 0.0002804584219120443
Local loss @ local epoch 2: 2.408006594123435e-06
Local loss @ local epoch 3: 0.08204485476016998
Local loss @ local epoch 4: 6.632468284806237e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.69 seconds!
[tester] 
AGNewsMetric: acc=0.6606578947368421, hinge=5.808435490758796, ce=10.078403349424663
Local test acc @ epoch 150: 0.6607
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.09710373729467392
Local loss @ local epoch 1: 0.00012597316526807845
Local loss @ local epoch 2: 4.872589488513768e-05
Local loss @ local epoch 3: 0.000474717264296487
Local loss @ local epoch 4: 0.0016753710806369781
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.39 seconds!
[tester] 
AGNewsMetric: acc=0.6686842105263158, hinge=7.975879618996068, ce=10.625817349082546
Local test acc @ epoch 150: 0.6687
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 7.94728478581419e-08
Local loss @ local epoch 1: 1.9868213740892315e-08
Local loss @ local epoch 2: 1.9868213740892315e-08
Local loss @ local epoch 3: 3.973642392907095e-08
Local loss @ local epoch 4: 1.9868211964535476e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.84 seconds!
[tester] 
AGNewsMetric: acc=0.7925, hinge=3.7492425705257215, ce=10.02612157922042
Local test acc @ epoch 150: 0.7925
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 3.659627691376954e-05
Local loss @ local epoch 1: 0.0001306748017668724
Local loss @ local epoch 2: 0.0020192600786685944
Local loss @ local epoch 3: 0.0002386412234045565
Local loss @ local epoch 4: 0.003088924800977111
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.54 seconds!
[tester] 
AGNewsMetric: acc=0.7547368421052632, hinge=2.2694116301285594, ce=9.321973557723195
Local test acc @ epoch 150: 0.7547
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 8.66976463953506e-08
Local loss @ local epoch 1: 2.492554642685718e-07
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.0837207575775665e-08
Local loss @ local epoch 4: 2.167441337519449e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.93 seconds!
[tester] 
AGNewsMetric: acc=0.7442105263157894, hinge=4.825642641970986, ce=9.902045184687564
Local test acc @ epoch 150: 0.7442
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 2.9802320611338473e-08
Local loss @ local epoch 1: 5.9604641222676946e-08
Local loss @ local epoch 2: 2.6822084464583895e-07
Local loss @ local epoch 3: 2.9802320611338473e-08
Local loss @ local epoch 4: 5.9604641222676946e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.35 seconds!
[tester] 
AGNewsMetric: acc=0.7527631578947368, hinge=4.364407956223739, ce=10.843949259707802
Local test acc @ epoch 150: 0.7528
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 4.193959739495767e-06
Local loss @ local epoch 1: 2.6895419068750925e-05
Local loss @ local epoch 2: 3.283633986939094e-06
Local loss @ local epoch 3: 1.5301025996450335e-05
Local loss @ local epoch 4: 2.1132409528945573e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.61 seconds!
[tester] 
AGNewsMetric: acc=0.791578947368421, hinge=3.261710863866304, ce=9.889796080338327
Local test acc @ epoch 150: 0.7916
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 1.8874793283885083e-07
Local loss @ local epoch 1: 9.934106870446158e-09
Local loss @ local epoch 2: 2.5828660454862984e-07
Local loss @ local epoch 3: 9.934106870446158e-09
Local loss @ local epoch 4: 7.947283364728719e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.76 seconds!
[tester] 
AGNewsMetric: acc=0.7946052631578947, hinge=3.8782571842795925, ce=9.775089442604466
Local test acc @ epoch 150: 0.7946
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 4.768371297814156e-08
Local loss @ local epoch 1: 2.384185648907078e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.2 seconds!
[tester] 
AGNewsMetric: acc=0.7243421052631579, hinge=5.075554949107923, ce=12.047190742492676
Local test acc @ epoch 150: 0.7243
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.07148682326078415
Local loss @ local epoch 1: 0.0077926358208060265
Local loss @ local epoch 2: 6.012850644765422e-05
Local loss @ local epoch 3: 0.003519962774589658
Local loss @ local epoch 4: 0.002910210518166423
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.81 seconds!
[tester] 
AGNewsMetric: acc=0.6252631578947369, hinge=3.8122649852853074, ce=11.093989809939735
Local test acc @ epoch 150: 0.6253
Global evaluate on test data...
Evaluate data in 123.9 seconds!
[tester] 
AGNewsMetric: acc=0.8519736842105263, hinge=2.4707077591042768, ce=9.171483838934648
Global test acc @ epoch 150: 0.852
Global epoch 151...
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.005679734516888857
Local loss @ local epoch 1: 2.2757938040740555e-06
Local loss @ local epoch 2: 0.00839934404939413
Local loss @ local epoch 3: 4.489939965424128e-05
Local loss @ local epoch 4: 2.0491972463787533e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.64 seconds!
[tester] 
AGNewsMetric: acc=0.7743421052631579, hinge=3.8492949656436317, ce=9.016778193022075
Local test acc @ epoch 151: 0.7743
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 2.384185648907078e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 4.768371297814156e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.35 seconds!
[tester] 
AGNewsMetric: acc=0.8518421052631578, hinge=2.476863292016481, ce=9.910368941457648
Local test acc @ epoch 151: 0.8518
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0005385283729992807
Local loss @ local epoch 1: 5.9604641222676946e-08
Local loss @ local epoch 2: 3.079570376485208e-07
Local loss @ local epoch 3: 2.483525349816773e-07
Local loss @ local epoch 4: 7.053205877127766e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.88 seconds!
[tester] 
AGNewsMetric: acc=0.4673684210526316, hinge=11.918824414704975, ce=13.836187509235582
Local test acc @ epoch 151: 0.4674
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 4.56964426120976e-06
Local loss @ local epoch 1: 1.7484022407643351e-07
Local loss @ local epoch 2: 3.01996408325067e-07
Local loss @ local epoch 3: 1.6689297410721338e-07
Local loss @ local epoch 4: 1.9245704606873915e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.2 seconds!
[tester] 
AGNewsMetric: acc=0.7121052631578947, hinge=4.146906677798221, ce=9.033070871453535
Local test acc @ epoch 151: 0.7121
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.006920069456100464
Local loss @ local epoch 1: 6.042178938514553e-06
Local loss @ local epoch 2: 1.2665951771850814e-06
Local loss @ local epoch 3: 2.570428932813229e-06
Local loss @ local epoch 4: 0.34920722246170044
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.69 seconds!
[tester] 
AGNewsMetric: acc=0.6497368421052632, hinge=8.360879286715859, ce=12.355728506790964
Local test acc @ epoch 151: 0.6497
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 6.953874276405259e-08
Local loss @ local epoch 1: 4.967052902316027e-08
Local loss @ local epoch 2: 3.973642392907095e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.3112925216773874e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.38 seconds!
[tester] 
AGNewsMetric: acc=0.7686842105263157, hinge=4.637505255247417, ce=10.398674587450529
Local test acc @ epoch 151: 0.7687
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 3.3595298987165734e-07
Local loss @ local epoch 1: 5.4186035214343065e-08
Local loss @ local epoch 2: 7.586044858953755e-08
Local loss @ local epoch 3: 1.7339523594728234e-07
Local loss @ local epoch 4: 4.334882675038898e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.72 seconds!
[tester] 
AGNewsMetric: acc=0.6222368421052632, hinge=6.786410841188933, ce=12.13911568691856
Local test acc @ epoch 151: 0.6222
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.00012551590043585747
Local loss @ local epoch 1: 2.6861423975788057e-05
Local loss @ local epoch 2: 0.0002516746462788433
Local loss @ local epoch 3: 0.0023892868775874376
Local loss @ local epoch 4: 0.00012344858259893954
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.96 seconds!
[tester] 
AGNewsMetric: acc=0.5275, hinge=6.654290768472772, ce=13.597883814761513
Local test acc @ epoch 151: 0.5275
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.00046376881073229015
Local loss @ local epoch 1: 0.0004250656929798424
Local loss @ local epoch 2: 0.7721077799797058
Local loss @ local epoch 3: 0.020657027140259743
Local loss @ local epoch 4: 0.24830622971057892
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.93 seconds!
[tester] 
AGNewsMetric: acc=0.7901315789473684, hinge=1.6680622572647898, ce=6.522942787973505
Local test acc @ epoch 151: 0.7901
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.9802320611338473e-08
Local loss @ local epoch 2: 2.9802320611338473e-08
Local loss @ local epoch 3: 8.940695295223122e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.46 seconds!
[tester] 
AGNewsMetric: acc=0.7423684210526316, hinge=4.452496080147593, ce=10.853687782287597
Local test acc @ epoch 151: 0.7424
Global evaluate on test data...
Evaluate data in 123.76 seconds!
[tester] 
AGNewsMetric: acc=0.8452631578947368, hinge=2.644097918836694, ce=9.158218648810136
Global test acc @ epoch 151: 0.8453
Global epoch 152...
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.00010104035027325153
Local loss @ local epoch 1: 9.059858712134883e-06
Local loss @ local epoch 2: 2.9761975383735262e-05
Local loss @ local epoch 3: 0.0002882383414544165
Local loss @ local epoch 4: 0.0054862345568835735
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.05 seconds!
[tester] 
AGNewsMetric: acc=0.7201315789473685, hinge=3.4670076766767, ce=12.488029698823627
Local test acc @ epoch 152: 0.7201
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 1.1920927533992653e-07
Local loss @ local epoch 1: 8.940696005765858e-08
Local loss @ local epoch 2: 5.9604641222676946e-08
Local loss @ local epoch 3: 5.9604641222676946e-08
Local loss @ local epoch 4: 1.1920928244535389e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.8 seconds!
[tester] 
AGNewsMetric: acc=0.7557894736842106, hinge=3.5778078568609137, ce=10.45392285999499
Local test acc @ epoch 152: 0.7558
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 2.0482248146436177e-06
Local loss @ local epoch 1: 0.00012849652557633817
Local loss @ local epoch 2: 2.4816943096084287e-06
Local loss @ local epoch 3: 0.00042745002429001033
Local loss @ local epoch 4: 7.953856402309611e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.15 seconds!
[tester] 
AGNewsMetric: acc=0.5707894736842105, hinge=8.564676742051777, ce=12.73758332704243
Local test acc @ epoch 152: 0.5708
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 2.926043407569523e-07
Local loss @ local epoch 1: 6.502323657286979e-08
Local loss @ local epoch 2: 6.935788405826315e-07
Local loss @ local epoch 3: 1.0837207575775665e-08
Local loss @ local epoch 4: 2.167441337519449e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.72 seconds!
[tester] 
AGNewsMetric: acc=0.529342105263158, hinge=10.833552195900365, ce=14.059389899404426
Local test acc @ epoch 152: 0.5293
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 2.9802320611338473e-08
Local loss @ local epoch 1: 1.9868211964535476e-08
Local loss @ local epoch 2: 2.9802317058624794e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.79 seconds!
[tester] 
AGNewsMetric: acc=0.8310526315789474, hinge=2.93880037044224, ce=8.70124895597759
Local test acc @ epoch 152: 0.8311
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.000901845924090594
Local loss @ local epoch 1: 2.559515633038245e-05
Local loss @ local epoch 2: 0.14094819128513336
Local loss @ local epoch 3: 9.54115457716398e-05
Local loss @ local epoch 4: 0.0002503316500224173
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 125.4 seconds!
[tester] 
AGNewsMetric: acc=0.6857894736842105, hinge=4.080887049875761, ce=9.411652617203561
Local test acc @ epoch 152: 0.6858
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.2715228497982025
Local loss @ local epoch 1: 6.333794317470165e-06
Local loss @ local epoch 2: 3.0323635655804537e-05
Local loss @ local epoch 3: 0.00036451866617426276
Local loss @ local epoch 4: 0.00023843380040489137
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.3 seconds!
[tester] 
AGNewsMetric: acc=0.6201315789473684, hinge=8.743097089968229, ce=12.501751421878213
Local test acc @ epoch 152: 0.6201
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.152556236178498e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.384185648907078e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.12 seconds!
[tester] 
AGNewsMetric: acc=0.6328947368421053, hinge=7.448108913020084, ce=13.624089793155068
Local test acc @ epoch 152: 0.6329
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.17178630828857422
Local loss @ local epoch 1: 0.002100504469126463
Local loss @ local epoch 2: 0.0003138406900689006
Local loss @ local epoch 3: 0.00033113581594079733
Local loss @ local epoch 4: 1.759734732331708e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.15 seconds!
[tester] 
AGNewsMetric: acc=0.6156578947368421, hinge=9.410085380955746, ce=11.824125659340305
Local test acc @ epoch 152: 0.6157
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 6.953874276405259e-08
Local loss @ local epoch 1: 3.973642392907095e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 9.934106870446158e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.33 seconds!
[tester] 
AGNewsMetric: acc=0.7138157894736842, hinge=6.323053686493322, ce=11.166076320848967
Local test acc @ epoch 152: 0.7138
Global evaluate on test data...
Evaluate data in 123.12 seconds!
[tester] 
AGNewsMetric: acc=0.8126315789473684, hinge=3.2051022070332578, ce=9.7889838248805
Global test acc @ epoch 152: 0.8126
Global epoch 153...
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 3.973642392907095e-08
Local loss @ local epoch 1: 1.9868213740892315e-08
Local loss @ local epoch 2: 1.9868213740892315e-08
Local loss @ local epoch 3: 1.092751560349825e-07
Local loss @ local epoch 4: 1.9868213740892315e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.73 seconds!
[tester] 
AGNewsMetric: acc=0.7957894736842105, hinge=3.5044645362151297, ce=9.73756960015548
Local test acc @ epoch 153: 0.7958
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 8.940695295223122e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.41 seconds!
[tester] 
AGNewsMetric: acc=0.7914473684210527, hinge=3.7422299508044596, ce=9.627072900470935
Local test acc @ epoch 153: 0.7914
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 2.102406369886012e-06
Local loss @ local epoch 1: 6.177195928103174e-07
Local loss @ local epoch 2: 6.968123670958448e-06
Local loss @ local epoch 3: 2.232452970929444e-06
Local loss @ local epoch 4: 1.4955304550312576e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.97 seconds!
[tester] 
AGNewsMetric: acc=0.7505263157894737, hinge=4.304440772909867, ce=10.126378519158614
Local test acc @ epoch 153: 0.7505
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 3.3378574926246074e-07
Local loss @ local epoch 1: 2.384185648907078e-08
Local loss @ local epoch 2: 4.768370942542788e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.479537897670525e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.57 seconds!
[tester] 
AGNewsMetric: acc=0.7592105263157894, hinge=4.000050789933455, ce=10.542996292114259
Local test acc @ epoch 153: 0.7592
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 2.384182948844682e-07
Local loss @ local epoch 1: 2.9802320611338473e-08
Local loss @ local epoch 2: 2.9802317058624794e-08
Local loss @ local epoch 3: 9.934106870446158e-09
Local loss @ local epoch 4: 4.967052902316027e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.12 seconds!
[tester] 
AGNewsMetric: acc=0.5377631578947368, hinge=12.686598051472714, ce=14.235480347683556
Local test acc @ epoch 153: 0.5378
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 7.497974729631096e-05
Local loss @ local epoch 1: 0.0002984501770697534
Local loss @ local epoch 2: 0.00013183294504415244
Local loss @ local epoch 3: 0.00012531765969470143
Local loss @ local epoch 4: 0.0001549152220832184
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.3 seconds!
[tester] 
AGNewsMetric: acc=0.4453947368421053, hinge=5.740735726607474, ce=12.724522287469162
Local test acc @ epoch 153: 0.4454
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 4.053074917464983e-06
Local loss @ local epoch 1: 1.0430809993522416e-07
Local loss @ local epoch 2: 7.525055139012693e-07
Local loss @ local epoch 3: 1.4826592860117671e-06
Local loss @ local epoch 4: 1.3253281395009253e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.16 seconds!
[tester] 
AGNewsMetric: acc=0.6069736842105263, hinge=8.561281238355134, ce=12.186955560383044
Local test acc @ epoch 153: 0.607
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 4.800122496817494e-06
Local loss @ local epoch 1: 1.9868197398409393e-07
Local loss @ local epoch 2: 4.370999420189037e-07
Local loss @ local epoch 3: 2.8610170943466073e-07
Local loss @ local epoch 4: 6.198870892148989e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.63 seconds!
[tester] 
AGNewsMetric: acc=0.4926315789473684, hinge=12.629425961343866, ce=16.708004423442638
Local test acc @ epoch 153: 0.4926
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0003623675729613751
Local loss @ local epoch 1: 0.0020543246064335108
Local loss @ local epoch 2: 1.1731998920440674
Local loss @ local epoch 3: 0.05028475448489189
Local loss @ local epoch 4: 0.018097562715411186
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.68 seconds!
[tester] 
AGNewsMetric: acc=0.7315789473684211, hinge=3.4282378144013252, ce=10.0365318137721
Local test acc @ epoch 153: 0.7316
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 2.059068293647215e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.0837207575775665e-08
Local loss @ local epoch 3: 1.408836425298432e-07
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.34 seconds!
[tester] 
AGNewsMetric: acc=0.5569736842105263, hinge=11.008294713873612, ce=13.025240358051501
Local test acc @ epoch 153: 0.557
Global evaluate on test data...
Evaluate data in 123.92 seconds!
[tester] 
AGNewsMetric: acc=0.8563157894736843, hinge=2.4823851507588435, ce=9.023279710066946
Global test acc @ epoch 153: 0.8563
Global epoch 154...
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 5.304760179569712e-06
Local loss @ local epoch 1: 8.940696005765858e-08
Local loss @ local epoch 2: 5.9604641222676946e-08
Local loss @ local epoch 3: 2.9802320611338473e-08
Local loss @ local epoch 4: 1.0847923476831056e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.38 seconds!
[tester] 
AGNewsMetric: acc=0.6319736842105264, hinge=6.7665687581112515, ce=12.322395672045255
Local test acc @ epoch 154: 0.632
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 1.9868213740892315e-08
Local loss @ local epoch 1: 1.9868213740892315e-08
Local loss @ local epoch 2: 7.947284075271455e-08
Local loss @ local epoch 3: 7.947281943643247e-08
Local loss @ local epoch 4: 9.934106870446158e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.8 seconds!
[tester] 
AGNewsMetric: acc=0.7989473684210526, hinge=3.8860513155083907, ce=9.73896883111251
Local test acc @ epoch 154: 0.7989
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 5.3317402489483356e-05
Local loss @ local epoch 1: 0.00017371248395647854
Local loss @ local epoch 2: 2.2461215849034488e-05
Local loss @ local epoch 3: 3.8194764783838764e-05
Local loss @ local epoch 4: 0.00022054419969208539
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.8 seconds!
[tester] 
AGNewsMetric: acc=0.6477631578947368, hinge=5.593268731016861, ce=12.424880104064941
Local test acc @ epoch 154: 0.6478
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 1.4195972653396893e-05
Local loss @ local epoch 1: 4.5516225100072916e-07
Local loss @ local epoch 2: 0.00013593790936283767
Local loss @ local epoch 3: 1.4618237401009537e-05
Local loss @ local epoch 4: 7.369288255176798e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.98 seconds!
[tester] 
AGNewsMetric: acc=0.8606578947368421, hinge=2.324674455994054, ce=8.760155139722322
Local test acc @ epoch 154: 0.8607
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.0837207575775665e-08
Local loss @ local epoch 2: 1.4088361410813377e-07
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.38 seconds!
[tester] 
AGNewsMetric: acc=0.8184210526315789, hinge=3.439645820918836, ce=9.03335228167082
Local test acc @ epoch 154: 0.8184
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 7.947283364728719e-08
Local loss @ local epoch 1: 9.934106870446158e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 3.1789087984179787e-07
Local loss @ local epoch 4: 2.1855015575056314e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.8 seconds!
[tester] 
AGNewsMetric: acc=0.7776315789473685, hinge=4.18160127765254, ce=9.94537266580682
Local test acc @ epoch 154: 0.7776
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 5.199149381951429e-05
Local loss @ local epoch 1: 1.2477144082367886e-06
Local loss @ local epoch 2: 4.2915289100164955e-07
Local loss @ local epoch 3: 0.5141076445579529
Local loss @ local epoch 4: 6.993601573412889e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.68 seconds!
[tester] 
AGNewsMetric: acc=0.6444736842105263, hinge=8.08580248481349, ce=12.630505985460783
Local test acc @ epoch 154: 0.6445
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.1270875930786133
Local loss @ local epoch 1: 1.117585156862333e-06
Local loss @ local epoch 2: 2.2288730178843252e-05
Local loss @ local epoch 3: 1.1331815585435834e-05
Local loss @ local epoch 4: 1.41184636959224e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.49 seconds!
[tester] 
AGNewsMetric: acc=0.5726315789473684, hinge=6.068656722620914, ce=11.906990438762463
Local test acc @ epoch 154: 0.5726
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.00016611022874712944
Local loss @ local epoch 1: 0.0006084507331252098
Local loss @ local epoch 2: 0.010357563383877277
Local loss @ local epoch 3: 0.0009520392050035298
Local loss @ local epoch 4: 0.37853679060935974
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.62 seconds!
[tester] 
AGNewsMetric: acc=0.6213157894736843, hinge=3.7978705571827134, ce=12.012541289078563
Local test acc @ epoch 154: 0.6213
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 7.152556946721234e-08
Local loss @ local epoch 1: 2.384185648907078e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.63 seconds!
[tester] 
AGNewsMetric: acc=0.814078947368421, hinge=3.264718240813205, ce=10.77514179832057
Local test acc @ epoch 154: 0.8141
Global evaluate on test data...
Evaluate data in 124.23 seconds!
[tester] 
AGNewsMetric: acc=0.8555263157894737, hinge=2.4032859980432613, ce=9.177886133695903
Global test acc @ epoch 154: 0.8555
Global epoch 155...
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 1.215863085235469e-05
Local loss @ local epoch 1: 5.523142317542806e-05
Local loss @ local epoch 2: 2.7417777346272487e-06
Local loss @ local epoch 3: 4.681569043896161e-05
Local loss @ local epoch 4: 2.2649646780337207e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.93 seconds!
[tester] 
AGNewsMetric: acc=0.8317105263157895, hinge=2.69581139740191, ce=9.675843676516884
Local test acc @ epoch 155: 0.8317
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 4.232392893754877e-05
Local loss @ local epoch 1: 1.3663182471645996e-05
Local loss @ local epoch 2: 9.760203738551354e-07
Local loss @ local epoch 3: 4.02331039595083e-07
Local loss @ local epoch 4: 0.0003339752438478172
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.14 seconds!
[tester] 
AGNewsMetric: acc=0.6610526315789473, hinge=6.704030348125257, ce=12.40510498448422
Local test acc @ epoch 155: 0.6611
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 7.6293815709505e-07
Local loss @ local epoch 1: 1.9073476664743794e-07
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.384185648907078e-08
Local loss @ local epoch 4: 1.6689293147464923e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.59 seconds!
[tester] 
AGNewsMetric: acc=0.5915789473684211, hinge=8.794198539131566, ce=14.407439249942177
Local test acc @ epoch 155: 0.5916
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 1.0837207575775665e-08
Local loss @ local epoch 1: 7.586042727325548e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 5.4186035214343065e-08
Local loss @ local epoch 4: 1.0837207575775665e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.83 seconds!
[tester] 
AGNewsMetric: acc=0.6692105263157895, hinge=7.232837856443305, ce=11.251282047472502
Local test acc @ epoch 155: 0.6692
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.025821503251791
Local loss @ local epoch 1: 1.4137734979158267e-05
Local loss @ local epoch 2: 1.0808295201059082e-06
Local loss @ local epoch 3: 9.132982086157426e-05
Local loss @ local epoch 4: 0.43707603216171265
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.64 seconds!
[tester] 
AGNewsMetric: acc=0.690921052631579, hinge=4.40445895546361, ce=10.556217185572574
Local test acc @ epoch 155: 0.6909
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 9.83475501925568e-07
Local loss @ local epoch 1: 1.1920928244535389e-07
Local loss @ local epoch 2: 1.6689270978531567e-06
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 8.940696005765858e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.84 seconds!
[tester] 
AGNewsMetric: acc=0.7580263157894737, hinge=3.8749831972624125, ce=10.847847269961708
Local test acc @ epoch 155: 0.758
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 9.934106870446158e-09
Local loss @ local epoch 1: 1.8874793283885083e-07
Local loss @ local epoch 2: 2.9802285439473053e-07
Local loss @ local epoch 3: 4.967052902316027e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.89 seconds!
[tester] 
AGNewsMetric: acc=0.8422368421052632, hinge=2.8251536743264447, ce=9.499177332426372
Local test acc @ epoch 155: 0.8422
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 3.091916369157843e-05
Local loss @ local epoch 1: 1.9868213740892315e-08
Local loss @ local epoch 2: 3.973642748178463e-08
Local loss @ local epoch 3: 1.5894566729457438e-07
Local loss @ local epoch 4: 2.9802305334669654e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.68 seconds!
[tester] 
AGNewsMetric: acc=0.44605263157894737, hinge=13.868509871834203, ce=14.111799812316894
Local test acc @ epoch 155: 0.4461
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 9.860220416157972e-06
Local loss @ local epoch 1: 1.4747551176697016e-05
Local loss @ local epoch 2: 0.006857972126454115
Local loss @ local epoch 3: 4.732187153422274e-05
Local loss @ local epoch 4: 3.150356133119203e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.66 seconds!
[tester] 
AGNewsMetric: acc=0.7042105263157895, hinge=4.813864763661435, ce=11.330953204506322
Local test acc @ epoch 155: 0.7042
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0002970614586956799
Local loss @ local epoch 1: 1.275529939448461e-05
Local loss @ local epoch 2: 0.00019039021572098136
Local loss @ local epoch 3: 0.013269620947539806
Local loss @ local epoch 4: 2.1855007616977673e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.23 seconds!
[tester] 
AGNewsMetric: acc=0.4589473684210526, hinge=9.477844790408486, ce=14.874029008965744
Local test acc @ epoch 155: 0.4589
Global evaluate on test data...
Evaluate data in 124.16 seconds!
[tester] 
AGNewsMetric: acc=0.8501315789473685, hinge=2.6281116345054225, ce=9.523979630721243
Global test acc @ epoch 155: 0.8501
Global epoch 156...
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0011457320069894195
Local loss @ local epoch 1: 0.0006276327767409384
Local loss @ local epoch 2: 0.7051235437393188
Local loss @ local epoch 3: 0.21123647689819336
Local loss @ local epoch 4: 0.036812782287597656
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.02 seconds!
[tester] 
AGNewsMetric: acc=0.6039473684210527, hinge=3.863073282743755, ce=10.475004601729543
Local test acc @ epoch 156: 0.6039
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 2.086159867076276e-07
Local loss @ local epoch 1: 1.2914334490687907e-07
Local loss @ local epoch 2: 3.973642392907095e-08
Local loss @ local epoch 3: 2.682205888504541e-07
Local loss @ local epoch 4: 8.940694584680386e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.19 seconds!
[tester] 
AGNewsMetric: acc=0.7792105263157895, hinge=3.799050051538568, ce=9.649688764873304
Local test acc @ epoch 156: 0.7792
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.384185648907078e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.384185648907078e-08
Local loss @ local epoch 4: 2.384185648907078e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.26 seconds!
[tester] 
AGNewsMetric: acc=0.8192105263157895, hinge=3.2616041697953877, ce=10.555680132414166
Local test acc @ epoch 156: 0.8192
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 2.351648390686023e-06
Local loss @ local epoch 1: 0.004759201314300299
Local loss @ local epoch 2: 2.709300588321639e-07
Local loss @ local epoch 3: 0.0037537456955760717
Local loss @ local epoch 4: 0.00014110479969531298
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.53 seconds!
[tester] 
AGNewsMetric: acc=0.6119736842105263, hinge=8.36025544417532, ce=12.46617120240864
Local test acc @ epoch 156: 0.612
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0013233592035248876
Local loss @ local epoch 1: 0.0005024836864322424
Local loss @ local epoch 2: 9.647002298152074e-05
Local loss @ local epoch 3: 0.0010414744028821588
Local loss @ local epoch 4: 0.0017018475336953998
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.68 seconds!
[tester] 
AGNewsMetric: acc=0.4482894736842105, hinge=5.801332842174329, ce=12.525135769091154
Local test acc @ epoch 156: 0.4483
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.02955370768904686
Local loss @ local epoch 1: 1.676926331128925e-05
Local loss @ local epoch 2: 2.324571141798515e-06
Local loss @ local epoch 3: 3.7625043205480324e-06
Local loss @ local epoch 4: 9.275709089706652e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.73 seconds!
[tester] 
AGNewsMetric: acc=0.6478947368421053, hinge=6.795691514768099, ce=12.012148762753135
Local test acc @ epoch 156: 0.6479
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 1.5528259609709494e-05
Local loss @ local epoch 1: 9.536741885085576e-08
Local loss @ local epoch 2: 7.947271569719305e-07
Local loss @ local epoch 3: 4.847840386901225e-07
Local loss @ local epoch 4: 5.634404715237906e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.73 seconds!
[tester] 
AGNewsMetric: acc=0.45802631578947367, hinge=14.212713552776135, ce=17.035889860454358
Local test acc @ epoch 156: 0.458
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 1.0927516314040986e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.9868213740892315e-08
Local loss @ local epoch 3: 1.291432880634602e-07
Local loss @ local epoch 4: 1.9868211964535476e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.29 seconds!
[tester] 
AGNewsMetric: acc=0.5896052631578947, hinge=10.08704267100284, ce=13.030141500171862
Local test acc @ epoch 156: 0.5896
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 1.0837207575775665e-08
Local loss @ local epoch 1: 1.0837207575775665e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 3.2511618286434896e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.54 seconds!
[tester] 
AGNewsMetric: acc=0.7989473684210526, hinge=3.920431200579593, ce=9.70223104376542
Local test acc @ epoch 156: 0.7989
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 1.1920926112907182e-07
Local loss @ local epoch 1: 3.3378378248016816e-06
Local loss @ local epoch 2: 2.9802320611338473e-08
Local loss @ local epoch 3: 3.933875632355921e-06
Local loss @ local epoch 4: 2.9802320611338473e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.51 seconds!
[tester] 
AGNewsMetric: acc=0.8019736842105263, hinge=2.966092880148637, ce=7.938920239900288
Local test acc @ epoch 156: 0.802
Global evaluate on test data...
Evaluate data in 123.69 seconds!
[tester] 
AGNewsMetric: acc=0.8598684210526316, hinge=2.409683437096445, ce=8.998229340001156
Global test acc @ epoch 156: 0.8599
Global epoch 157...
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.00047757651191204786
Local loss @ local epoch 1: 6.119402655713202e-07
Local loss @ local epoch 2: 4.95110907650087e-06
Local loss @ local epoch 3: 0.7398568987846375
Local loss @ local epoch 4: 3.497713623801246e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.97 seconds!
[tester] 
AGNewsMetric: acc=0.699078947368421, hinge=5.020861023601733, ce=10.882012007863898
Local test acc @ epoch 157: 0.6991
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 7.586044858953755e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.0837207575775665e-08
Local loss @ local epoch 4: 1.0837207575775665e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.23 seconds!
[tester] 
AGNewsMetric: acc=0.6788157894736843, hinge=7.021592664718628, ce=11.220428916529606
Local test acc @ epoch 157: 0.6788
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 3.814694480297476e-07
Local loss @ local epoch 1: 2.384185648907078e-08
Local loss @ local epoch 2: 4.768371297814156e-08
Local loss @ local epoch 3: 2.384185648907078e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.72 seconds!
[tester] 
AGNewsMetric: acc=0.7122368421052632, hinge=5.21376995488217, ce=12.30513950950221
Local test acc @ epoch 157: 0.7122
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.00012952064571436495
Local loss @ local epoch 1: 9.934106870446158e-09
Local loss @ local epoch 2: 2.9802320611338473e-08
Local loss @ local epoch 3: 3.973642392907095e-08
Local loss @ local epoch 4: 4.967053257587395e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.66 seconds!
[tester] 
AGNewsMetric: acc=0.5567105263157894, hinge=10.694815432397943, ce=13.690119006508276
Local test acc @ epoch 157: 0.5567
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.23374000191688538
Local loss @ local epoch 1: 1.1053922435166896e-06
Local loss @ local epoch 2: 8.030138815229293e-06
Local loss @ local epoch 3: 0.001353684812784195
Local loss @ local epoch 4: 0.03203776106238365
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.85 seconds!
[tester] 
AGNewsMetric: acc=0.5325, hinge=9.325263424923545, ce=13.001177516736483
Local test acc @ epoch 157: 0.5325
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 1.9967440039181383e-06
Local loss @ local epoch 1: 9.934106870446158e-09
Local loss @ local epoch 2: 1.4503674492516438e-06
Local loss @ local epoch 3: 1.6887970843981748e-07
Local loss @ local epoch 4: 7.94728478581419e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.68 seconds!
[tester] 
AGNewsMetric: acc=0.5142105263157895, hinge=10.588480616117778, ce=13.109132337068257
Local test acc @ epoch 157: 0.5142
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 4.395181167637929e-05
Local loss @ local epoch 1: 9.327543375547975e-05
Local loss @ local epoch 2: 0.00019390393572393805
Local loss @ local epoch 3: 5.687131124432199e-05
Local loss @ local epoch 4: 3.5422069686319446e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.77 seconds!
[tester] 
AGNewsMetric: acc=0.6771052631578948, hinge=5.03462644526833, ce=11.975277591504549
Local test acc @ epoch 157: 0.6771
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.003333143424242735
Local loss @ local epoch 1: 2.6300231183995493e-06
Local loss @ local epoch 2: 3.85238163289614e-05
Local loss @ local epoch 3: 0.06521698087453842
Local loss @ local epoch 4: 6.884237336635124e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.93 seconds!
[tester] 
AGNewsMetric: acc=0.5969736842105263, hinge=8.270591044174997, ce=12.712827172530325
Local test acc @ epoch 157: 0.597
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 8.940696005765858e-08
Local loss @ local epoch 1: 5.960463766996327e-08
Local loss @ local epoch 2: 2.9802320611338473e-08
Local loss @ local epoch 3: 8.940696005765858e-08
Local loss @ local epoch 4: 1.430507836630568e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.5 seconds!
[tester] 
AGNewsMetric: acc=0.6923684210526316, hinge=4.178459911848369, ce=8.540220981397127
Local test acc @ epoch 157: 0.6924
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.00018127534713130444
Local loss @ local epoch 1: 1.9549894204828888e-05
Local loss @ local epoch 2: 1.251689263881417e-05
Local loss @ local epoch 3: 8.821442861517426e-06
Local loss @ local epoch 4: 0.0011381189106032252
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.78 seconds!
[tester] 
AGNewsMetric: acc=0.5322368421052631, hinge=7.410565858138235, ce=12.809306477998433
Local test acc @ epoch 157: 0.5322
Global evaluate on test data...
Evaluate data in 123.56 seconds!
[tester] 
AGNewsMetric: acc=0.8511842105263158, hinge=2.6382134821540433, ce=9.264583995216771
Global test acc @ epoch 157: 0.8512
Global epoch 158...
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 2.9802320611338473e-08
Local loss @ local epoch 1: 1.0132773695659125e-06
Local loss @ local epoch 2: 1.7881390590446244e-07
Local loss @ local epoch 3: 8.940695295223122e-08
Local loss @ local epoch 4: 1.1920928244535389e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.29 seconds!
[tester] 
AGNewsMetric: acc=0.7638157894736842, hinge=3.782291196020026, ce=9.805593962418406
Local test acc @ epoch 158: 0.7638
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.003119222354143858
Local loss @ local epoch 1: 3.353723741383874e-06
Local loss @ local epoch 2: 7.208056103991112e-06
Local loss @ local epoch 3: 3.5105837014270946e-05
Local loss @ local epoch 4: 0.2757393717765808
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.83 seconds!
[tester] 
AGNewsMetric: acc=0.6431578947368422, hinge=8.773360229291415, ce=12.463208999633789
Local test acc @ epoch 158: 0.6432
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 6.502322946744243e-08
Local loss @ local epoch 1: 1.0837207575775665e-08
Local loss @ local epoch 2: 1.0837207575775665e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.1 seconds!
[tester] 
AGNewsMetric: acc=0.7598684210526315, hinge=5.140311002480356, ce=10.51747825020238
Local test acc @ epoch 158: 0.7599
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 1.9868211964535476e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.9802320611338473e-08
Local loss @ local epoch 3: 1.9868213740892315e-08
Local loss @ local epoch 4: 9.934106870446158e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.73 seconds!
[tester] 
AGNewsMetric: acc=0.8396052631578947, hinge=2.9301038703165556, ce=9.800901306553891
Local test acc @ epoch 158: 0.8396
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.3458232581615448
Local loss @ local epoch 1: 0.0675964280962944
Local loss @ local epoch 2: 6.158106407383457e-05
Local loss @ local epoch 3: 0.17416350543498993
Local loss @ local epoch 4: 6.788202153984457e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.6 seconds!
[tester] 
AGNewsMetric: acc=0.6614473684210527, hinge=5.906058820674294, ce=11.813974372462223
Local test acc @ epoch 158: 0.6614
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.015561003237962723
Local loss @ local epoch 1: 2.20133806578815e-05
Local loss @ local epoch 2: 1.788112240319606e-05
Local loss @ local epoch 3: 4.430458284332417e-05
Local loss @ local epoch 4: 0.0005326500977389514
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.33 seconds!
[tester] 
AGNewsMetric: acc=0.2980263157894737, hinge=9.632186881617496, ce=15.083011061015881
Local test acc @ epoch 158: 0.298
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 2.0048673832206987e-06
Local loss @ local epoch 1: 1.3546451782531221e-06
Local loss @ local epoch 2: 1.5171971199379186e-06
Local loss @ local epoch 3: 1.842324337530954e-07
Local loss @ local epoch 4: 3.113007187494077e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.38 seconds!
[tester] 
AGNewsMetric: acc=0.7511842105263158, hinge=4.709635671063474, ce=10.28281526866712
Local test acc @ epoch 158: 0.7512
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.1920926823449918e-07
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.384185648907078e-08
Local loss @ local epoch 4: 2.384185648907078e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.82 seconds!
[tester] 
AGNewsMetric: acc=0.791578947368421, hinge=4.0063634789617435, ce=10.15712589263916
Local test acc @ epoch 158: 0.7916
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 1.9868213740892315e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 9.934106870446158e-09
Local loss @ local epoch 3: 9.934106870446158e-09
Local loss @ local epoch 4: 2.1258717879391043e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.88 seconds!
[tester] 
AGNewsMetric: acc=0.8332894736842106, hinge=3.1099952973817526, ce=9.660405988191304
Local test acc @ epoch 158: 0.8333
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 7.237667432491435e-06
Local loss @ local epoch 1: 9.842136933002621e-05
Local loss @ local epoch 2: 7.485550304409117e-05
Local loss @ local epoch 3: 0.13789229094982147
Local loss @ local epoch 4: 0.00013924864470027387
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.92 seconds!
[tester] 
AGNewsMetric: acc=0.8601315789473685, hinge=1.9641422969416569, ce=9.208877123782509
Local test acc @ epoch 158: 0.8601
Global evaluate on test data...
Evaluate data in 123.7 seconds!
[tester] 
AGNewsMetric: acc=0.8526315789473684, hinge=2.6097118697668376, ce=9.256369040639777
Global test acc @ epoch 158: 0.8526
Global epoch 159...
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 1.4781896879867418e-06
Local loss @ local epoch 1: 2.384185648907078e-08
Local loss @ local epoch 2: 2.1934408778179204e-06
Local loss @ local epoch 3: 4.768370942542788e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.82 seconds!
[tester] 
AGNewsMetric: acc=0.3806578947368421, hinge=12.851673851013183, ce=16.149198544150906
Local test acc @ epoch 159: 0.3807
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 8.54380486998707e-05
Local loss @ local epoch 1: 0.00011961998097831383
Local loss @ local epoch 2: 3.65574862826179e-07
Local loss @ local epoch 3: 1.8278753088907251e-07
Local loss @ local epoch 4: 3.266276962676784e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.03 seconds!
[tester] 
AGNewsMetric: acc=0.6505263157894737, hinge=7.0418634469885575, ce=11.688263226559288
Local test acc @ epoch 159: 0.6505
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.00011963194265263155
Local loss @ local epoch 1: 7.369275749624649e-07
Local loss @ local epoch 2: 0.10003981739282608
Local loss @ local epoch 3: 6.783848675695481e-06
Local loss @ local epoch 4: 1.6580862620685366e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.2 seconds!
[tester] 
AGNewsMetric: acc=0.8509210526315789, hinge=2.301773600327341, ce=9.539481751291376
Local test acc @ epoch 159: 0.8509
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0006137044983915985
Local loss @ local epoch 1: 5.8643377997213975e-05
Local loss @ local epoch 2: 0.7126715779304504
Local loss @ local epoch 3: 0.00440271245315671
Local loss @ local epoch 4: 0.027526309713721275
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.34 seconds!
[tester] 
AGNewsMetric: acc=0.7680263157894737, hinge=2.206581956712823, ce=9.795597552249307
Local test acc @ epoch 159: 0.768
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 1.1920926112907182e-07
Local loss @ local epoch 1: 8.940695295223122e-08
Local loss @ local epoch 2: 1.4901158351676713e-07
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.0861621408130304e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.54 seconds!
[tester] 
AGNewsMetric: acc=0.7735526315789474, hinge=4.498981169399462, ce=10.143654660676654
Local test acc @ epoch 159: 0.7736
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 6.502323657286979e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.84 seconds!
[tester] 
AGNewsMetric: acc=0.8110526315789474, hinge=3.71463950935163, ce=10.017950479607833
Local test acc @ epoch 159: 0.8111
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 2.02924529730808e-05
Local loss @ local epoch 1: 1.4975616977608297e-06
Local loss @ local epoch 2: 4.4191932829562575e-05
Local loss @ local epoch 3: 0.0003352416679263115
Local loss @ local epoch 4: 4.984305178368231e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.95 seconds!
[tester] 
AGNewsMetric: acc=0.6792105263157895, hinge=7.030263198049445, ce=11.068923335828279
Local test acc @ epoch 159: 0.6792
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 9.934106870446158e-09
Local loss @ local epoch 1: 1.9868200240580336e-07
Local loss @ local epoch 2: 1.0927516314040986e-07
Local loss @ local epoch 3: 5.960463411724959e-08
Local loss @ local epoch 4: 5.960462701182223e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.56 seconds!
[tester] 
AGNewsMetric: acc=0.815, hinge=3.4638060926136216, ce=9.361647433230752
Local test acc @ epoch 159: 0.815
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 7.271730282809585e-06
Local loss @ local epoch 1: 3.619902054197155e-05
Local loss @ local epoch 2: 4.569678367261076e-06
Local loss @ local epoch 3: 8.562795119360089e-05
Local loss @ local epoch 4: 4.160286334808916e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.68 seconds!
[tester] 
AGNewsMetric: acc=0.6810526315789474, hinge=3.809150128866497, ce=10.626241143879138
Local test acc @ epoch 159: 0.6811
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 2.18550312069965e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 9.934106870446158e-09
Local loss @ local epoch 3: 2.9802320611338473e-08
Local loss @ local epoch 4: 0.0001992088509723544
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.48 seconds!
[tester] 
AGNewsMetric: acc=0.5585526315789474, hinge=10.577102972833734, ce=13.395569650750412
Local test acc @ epoch 159: 0.5586
Global evaluate on test data...
Evaluate data in 124.59 seconds!
[tester] 
AGNewsMetric: acc=0.8553947368421052, hinge=2.589680721383346, ce=8.824286001105058
Global test acc @ epoch 159: 0.8554
Global epoch 160...
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.1867314875125885
Local loss @ local epoch 1: 1.743422330946487e-06
Local loss @ local epoch 2: 3.911484327545622e-06
Local loss @ local epoch 3: 0.0025913026183843613
Local loss @ local epoch 4: 0.00011554244701983407
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.24 seconds!
[tester] 
AGNewsMetric: acc=0.6353947368421052, hinge=6.273610077908165, ce=11.096437247426886
Local test acc @ epoch 160: 0.6354
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 4.334882675038898e-08
Local loss @ local epoch 1: 1.083720420069767e-07
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.0837207575775665e-08
Local loss @ local epoch 4: 3.2511618286434896e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.55 seconds!
[tester] 
AGNewsMetric: acc=0.6663157894736842, hinge=7.142110770376105, ce=11.67833000383879
Local test acc @ epoch 160: 0.6663
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.006948777940124273
Local loss @ local epoch 1: 5.165732090972597e-07
Local loss @ local epoch 2: 1.8554495909484103e-05
Local loss @ local epoch 3: 1.609199716767762e-05
Local loss @ local epoch 4: 5.2637653425335884e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.06 seconds!
[tester] 
AGNewsMetric: acc=0.6275, hinge=8.405050912154348, ce=13.326910085176166
Local test acc @ epoch 160: 0.6275
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 4.768370942542788e-08
Local loss @ local epoch 4: 4.768370942542788e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.4 seconds!
[tester] 
AGNewsMetric: acc=0.849078947368421, hinge=2.6955723230462327, ce=9.705867393895199
Local test acc @ epoch 160: 0.8491
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 1.1920926112907182e-07
Local loss @ local epoch 1: 8.940695295223122e-08
Local loss @ local epoch 2: 5.9604641222676946e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.63 seconds!
[tester] 
AGNewsMetric: acc=0.8367105263157895, hinge=2.863101145217293, ce=9.252016256232011
Local test acc @ epoch 160: 0.8367
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.01737098954617977
Local loss @ local epoch 1: 0.0006845067837275565
Local loss @ local epoch 2: 0.00021511156228370965
Local loss @ local epoch 3: 0.0015022713923826814
Local loss @ local epoch 4: 0.0006787219899706542
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.34 seconds!
[tester] 
AGNewsMetric: acc=0.7635526315789474, hinge=2.8922333669662477, ce=9.990385083650288
Local test acc @ epoch 160: 0.7636
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 5.662433864017657e-07
Local loss @ local epoch 1: 3.973642037635727e-08
Local loss @ local epoch 2: 3.973642037635727e-08
Local loss @ local epoch 3: 7.94728478581419e-08
Local loss @ local epoch 4: 4.1723163235474203e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.19 seconds!
[tester] 
AGNewsMetric: acc=0.4243421052631579, hinge=15.823641572249564, ce=16.17071798224198
Local test acc @ epoch 160: 0.4243
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 7.94728478581419e-08
Local loss @ local epoch 1: 1.9868211964535476e-08
Local loss @ local epoch 2: 9.934106870446158e-09
Local loss @ local epoch 3: 9.934106870446158e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.8 seconds!
[tester] 
AGNewsMetric: acc=0.7723684210526316, hinge=4.387687146789149, ce=10.106336902819182
Local test acc @ epoch 160: 0.7724
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 1.0808219485625159e-05
Local loss @ local epoch 1: 6.556456810358213e-06
Local loss @ local epoch 2: 3.5762778338721546e-07
Local loss @ local epoch 3: 4.967026598023949e-06
Local loss @ local epoch 4: 6.357826123348786e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.34 seconds!
[tester] 
AGNewsMetric: acc=0.6160526315789474, hinge=5.294556277425666, ce=12.510716610958701
Local test acc @ epoch 160: 0.6161
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 3.534463030518964e-05
Local loss @ local epoch 1: 6.502323657286979e-08
Local loss @ local epoch 2: 3.857992396660848e-06
Local loss @ local epoch 3: 2.286637027282268e-06
Local loss @ local epoch 4: 7.04417516317335e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.64 seconds!
[tester] 
AGNewsMetric: acc=0.5543421052631579, hinge=9.256475890310186, ce=12.46966532657021
Local test acc @ epoch 160: 0.5543
Global evaluate on test data...
Evaluate data in 123.98 seconds!
[tester] 
AGNewsMetric: acc=0.7984210526315789, hinge=3.829680336400082, ce=9.72394765351948
Global test acc @ epoch 160: 0.7984
Global epoch 161...
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 1.9868213740892315e-08
Local loss @ local epoch 1: 4.967052902316027e-08
Local loss @ local epoch 2: 5.960463411724959e-08
Local loss @ local epoch 3: 9.934106870446158e-09
Local loss @ local epoch 4: 1.9868213740892315e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.02 seconds!
[tester] 
AGNewsMetric: acc=0.7760526315789473, hinge=4.37842656712783, ce=10.153331140217029
Local test acc @ epoch 161: 0.7761
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.00696469284594059
Local loss @ local epoch 1: 1.8221326172351837e-05
Local loss @ local epoch 2: 0.0025491160340607166
Local loss @ local epoch 3: 5.95707242609933e-05
Local loss @ local epoch 4: 7.301841833395883e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.24 seconds!
[tester] 
AGNewsMetric: acc=0.58, hinge=5.109337211157146, ce=6.636878946203934
Local test acc @ epoch 161: 0.58
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 9.53674117454284e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.19 seconds!
[tester] 
AGNewsMetric: acc=0.8252631578947368, hinge=3.091476898444326, ce=9.83087888416491
Local test acc @ epoch 161: 0.8253
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.0837207575775665e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.9 seconds!
[tester] 
AGNewsMetric: acc=0.8139473684210526, hinge=3.451135125662151, ce=9.867498935900237
Local test acc @ epoch 161: 0.8139
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 4.569676832488767e-07
Local loss @ local epoch 1: 4.967052191773291e-08
Local loss @ local epoch 2: 1.9868213740892315e-08
Local loss @ local epoch 3: 9.238676170753024e-07
Local loss @ local epoch 4: 2.3841846541472478e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.2 seconds!
[tester] 
AGNewsMetric: acc=0.42473684210526313, hinge=15.127964693370618, ce=15.401493281314247
Local test acc @ epoch 161: 0.4247
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0008846647688187659
Local loss @ local epoch 1: 3.774782453547232e-05
Local loss @ local epoch 2: 0.000707906496245414
Local loss @ local epoch 3: 0.0002840182860381901
Local loss @ local epoch 4: 0.020926734432578087
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.83 seconds!
[tester] 
AGNewsMetric: acc=0.6821052631578948, hinge=2.9367885807940834, ce=10.850445843746787
Local test acc @ epoch 161: 0.6821
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.000825850700493902
Local loss @ local epoch 1: 0.00030650992994196713
Local loss @ local epoch 2: 0.0015912409871816635
Local loss @ local epoch 3: 0.0021270092111080885
Local loss @ local epoch 4: 0.004096534568816423
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.77 seconds!
[tester] 
AGNewsMetric: acc=0.5592105263157895, hinge=4.9979970399956954, ce=11.561429871007016
Local test acc @ epoch 161: 0.5592
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 8.372052980121225e-05
Local loss @ local epoch 1: 5.982555194350425e-06
Local loss @ local epoch 2: 7.398155048576882e-06
Local loss @ local epoch 3: 2.4586879021626373e-07
Local loss @ local epoch 4: 2.0116550558668678e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.84 seconds!
[tester] 
AGNewsMetric: acc=0.5267105263157895, hinge=10.661495417544716, ce=13.954710681312962
Local test acc @ epoch 161: 0.5267
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 2.9802320611338473e-08
Local loss @ local epoch 1: 2.9802320611338473e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.8 seconds!
[tester] 
AGNewsMetric: acc=0.7540789473684211, hinge=4.7762623593681734, ce=10.442222045095344
Local test acc @ epoch 161: 0.7541
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 1.842324337530954e-07
Local loss @ local epoch 1: 2.059068293647215e-07
Local loss @ local epoch 2: 1.8423239112053125e-07
Local loss @ local epoch 3: 1.777290208337945e-06
Local loss @ local epoch 4: 9.428356406715466e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.93 seconds!
[tester] 
AGNewsMetric: acc=0.7430263157894736, hinge=4.9845544689580015, ce=10.363484177840384
Local test acc @ epoch 161: 0.743
Global evaluate on test data...
Evaluate data in 124.4 seconds!
[tester] 
AGNewsMetric: acc=0.8375, hinge=2.66560268452293, ce=9.002388777481881
Global test acc @ epoch 161: 0.8375
Global epoch 162...
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.3300550580024719
Local loss @ local epoch 1: 1.3907661013945471e-06
Local loss @ local epoch 2: 2.606688667583512e-06
Local loss @ local epoch 3: 3.258369133618544e-06
Local loss @ local epoch 4: 1.0194330215454102
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.81 seconds!
[tester] 
AGNewsMetric: acc=0.6261842105263158, hinge=8.13536119109706, ce=13.289140761526008
Local test acc @ epoch 162: 0.6262
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 1.2349045276641846
Local loss @ local epoch 1: 1.0186932968281326e-06
Local loss @ local epoch 2: 0.0016756333643570542
Local loss @ local epoch 3: 1.5461505651474
Local loss @ local epoch 4: 4.314052104949951
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.63 seconds!
[tester] 
AGNewsMetric: acc=0.4676315789473684, hinge=12.313502874876324, ce=14.987539925826223
Local test acc @ epoch 162: 0.4676
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.00185749726369977
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.947284075271455e-08
Local loss @ local epoch 3: 8.543311196262948e-07
Local loss @ local epoch 4: 2.6324998998461524e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.54 seconds!
[tester] 
AGNewsMetric: acc=0.5544736842105263, hinge=11.217660338251214, ce=13.572569268879137
Local test acc @ epoch 162: 0.5545
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 1.8272690795129165e-05
Local loss @ local epoch 1: 0.00016475604206789285
Local loss @ local epoch 2: 3.116459311058861e-06
Local loss @ local epoch 3: 0.05321649834513664
Local loss @ local epoch 4: 4.240414455125574e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.84 seconds!
[tester] 
AGNewsMetric: acc=0.7192105263157895, hinge=4.009276550443549, ce=12.083420928151984
Local test acc @ epoch 162: 0.7192
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.3826301395893097
Local loss @ local epoch 1: 8.66976463953506e-08
Local loss @ local epoch 2: 4.334882675038898e-08
Local loss @ local epoch 3: 1.1920926823449918e-07
Local loss @ local epoch 4: 3.738811074072146e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.85 seconds!
[tester] 
AGNewsMetric: acc=0.42605263157894735, hinge=13.653709678649902, ce=14.71381088658383
Local test acc @ epoch 162: 0.4261
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 2.9802320611338473e-08
Local loss @ local epoch 1: 1.4901156930591242e-07
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.41 seconds!
[tester] 
AGNewsMetric: acc=0.7138157894736842, hinge=5.813049288297955, ce=10.831915445829692
Local test acc @ epoch 162: 0.7138
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.4104311168193817
Local loss @ local epoch 1: 5.215406062575312e-08
Local loss @ local epoch 2: 5.252459231996909e-06
Local loss @ local epoch 3: 3.9758928323863074e-05
Local loss @ local epoch 4: 0.00041124032577499747
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.85 seconds!
[tester] 
AGNewsMetric: acc=0.5655263157894737, hinge=7.150484497170699, ce=9.362216419420744
Local test acc @ epoch 162: 0.5655
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.17 seconds!
[tester] 
AGNewsMetric: acc=0.8411842105263158, hinge=2.7343980993722616, ce=9.349869459051835
Local test acc @ epoch 162: 0.8412
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.16965079307556152
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 4.370998567537754e-07
Local loss @ local epoch 3: 3.675614834719454e-07
Local loss @ local epoch 4: 4.973591785528697e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.85 seconds!
[tester] 
AGNewsMetric: acc=0.37723684210526315, hinge=15.524701959710372, ce=15.527648259213096
Local test acc @ epoch 162: 0.3772
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 1.7881369558381266e-06
Local loss @ local epoch 1: 9.536736911286425e-07
Local loss @ local epoch 2: 4.728618932858808e-06
Local loss @ local epoch 3: 5.960462203802308e-07
Local loss @ local epoch 4: 3.2502975955139846e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.46 seconds!
[tester] 
AGNewsMetric: acc=0.7053947368421053, hinge=4.529412026154367, ce=12.421270519055819
Local test acc @ epoch 162: 0.7054
Global evaluate on test data...
Evaluate data in 123.19 seconds!
[tester] 
AGNewsMetric: acc=0.7751315789473684, hinge=4.420849015336287, ce=10.007686912135075
Global test acc @ epoch 162: 0.7751
Global epoch 163...
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00043920156895183027
Local loss @ local epoch 1: 1.2367918316158466e-06
Local loss @ local epoch 2: 9.909247182804393e-07
Local loss @ local epoch 3: 1.2188790606160183e-05
Local loss @ local epoch 4: 0.19206422567367554
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.78 seconds!
[tester] 
AGNewsMetric: acc=0.6606578947368421, hinge=7.380180433674862, ce=11.777208589252673
Local test acc @ epoch 163: 0.6607
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 3.973642748178463e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 3.973642392907095e-08
Local loss @ local epoch 3: 3.973642392907095e-08
Local loss @ local epoch 4: 6.953873565862523e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.52 seconds!
[tester] 
AGNewsMetric: acc=0.7732894736842105, hinge=4.053544417933414, ce=10.045215199119166
Local test acc @ epoch 163: 0.7733
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 2.167441337519449e-08
Local loss @ local epoch 1: 1.0837207575775665e-08
Local loss @ local epoch 2: 1.0837207575775665e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.24 seconds!
[tester] 
AGNewsMetric: acc=0.7561842105263158, hinge=4.611543549989399, ce=10.698173215765703
Local test acc @ epoch 163: 0.7562
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0009979445021599531
Local loss @ local epoch 1: 0.03181242570281029
Local loss @ local epoch 2: 0.0004565185809042305
Local loss @ local epoch 3: 0.014490350149571896
Local loss @ local epoch 4: 0.0014102280838415027
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.31 seconds!
[tester] 
AGNewsMetric: acc=0.6023684210526316, hinge=3.104621360176488, ce=7.943564868726228
Local test acc @ epoch 163: 0.6024
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 3.973642392907095e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.5 seconds!
[tester] 
AGNewsMetric: acc=0.8001315789473684, hinge=3.494878046638087, ce=9.844580708553917
Local test acc @ epoch 163: 0.8001
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.00021668532281182706
Local loss @ local epoch 1: 2.4238822788902326e-06
Local loss @ local epoch 2: 2.064416548819281e-05
Local loss @ local epoch 3: 4.204060587653657e-06
Local loss @ local epoch 4: 2.765627868939191e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.74 seconds!
[tester] 
AGNewsMetric: acc=0.6248684210526316, hinge=7.798949951874582, ce=12.994793249431408
Local test acc @ epoch 163: 0.6249
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 1.7014340301102493e-06
Local loss @ local epoch 1: 8.669737781019649e-07
Local loss @ local epoch 2: 6.7296937231731135e-06
Local loss @ local epoch 3: 1.5713850416432251e-06
Local loss @ local epoch 4: 3.0018891266081482e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.4 seconds!
[tester] 
AGNewsMetric: acc=0.6002631578947368, hinge=7.964014958080493, ce=12.815023679231343
Local test acc @ epoch 163: 0.6003
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.020558489486575127
Local loss @ local epoch 1: 8.855485248204786e-06
Local loss @ local epoch 2: 7.967623969307169e-05
Local loss @ local epoch 3: 0.00157634646166116
Local loss @ local epoch 4: 0.0009447104530408978
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.32 seconds!
[tester] 
AGNewsMetric: acc=0.5538157894736843, hinge=4.896141625454551, ce=11.835738744233783
Local test acc @ epoch 163: 0.5538
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 4.768371297814156e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.08 seconds!
[tester] 
AGNewsMetric: acc=0.8153947368421053, hinge=3.0118225774012113, ce=9.821253103958933
Local test acc @ epoch 163: 0.8154
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 1.4901158351676713e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.31 seconds!
[tester] 
AGNewsMetric: acc=0.7427631578947368, hinge=4.647488594808077, ce=9.864604312495182
Local test acc @ epoch 163: 0.7428
Global evaluate on test data...
Evaluate data in 123.66 seconds!
[tester] 
AGNewsMetric: acc=0.8253947368421053, hinge=2.9813139872801933, ce=9.680162148726614
Global test acc @ epoch 163: 0.8254
Global epoch 164...
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.9578403234481812
Local loss @ local epoch 1: 4.6938617970226915e-07
Local loss @ local epoch 2: 6.175871385494247e-05
Local loss @ local epoch 3: 0.0007062723743729293
Local loss @ local epoch 4: 0.010055065155029297
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.78 seconds!
[tester] 
AGNewsMetric: acc=0.5507894736842105, hinge=5.742968835328755, ce=11.312946016412033
Local test acc @ epoch 164: 0.5508
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 2.3202381271403283e-05
Local loss @ local epoch 1: 5.245195779934875e-07
Local loss @ local epoch 2: 4.450470783012861e-07
Local loss @ local epoch 3: 3.3854587400128366e-06
Local loss @ local epoch 4: 2.940493573078129e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.55 seconds!
[tester] 
AGNewsMetric: acc=0.6518421052631579, hinge=7.178845559672306, ce=12.114220571016011
Local test acc @ epoch 164: 0.6518
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0003185607783962041
Local loss @ local epoch 1: 0.00043038607691414654
Local loss @ local epoch 2: 0.03714563697576523
Local loss @ local epoch 3: 0.005798018537461758
Local loss @ local epoch 4: 0.05641328915953636
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.67 seconds!
[tester] 
AGNewsMetric: acc=0.7827631578947368, hinge=1.9791195284692864, ce=9.846215565330104
Local test acc @ epoch 164: 0.7828
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.001582036493346095
Local loss @ local epoch 1: 9.753485130659101e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 3.2511621839148575e-08
Local loss @ local epoch 4: 3.1427870794686896e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.49 seconds!
[tester] 
AGNewsMetric: acc=0.44513157894736843, hinge=13.628511224043997, ce=15.317485488088508
Local test acc @ epoch 164: 0.4451
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 4.768370942542788e-08
Local loss @ local epoch 3: 2.384185648907078e-08
Local loss @ local epoch 4: 2.384185648907078e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.49 seconds!
[tester] 
AGNewsMetric: acc=0.8385526315789473, hinge=2.557882799349333, ce=9.349207882128264
Local test acc @ epoch 164: 0.8386
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 1.7881375242723152e-06
Local loss @ local epoch 1: 3.695473651532666e-06
Local loss @ local epoch 2: 2.6463685571798123e-05
Local loss @ local epoch 3: 9.020102879730985e-06
Local loss @ local epoch 4: 0.0010640042601153255
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.46 seconds!
[tester] 
AGNewsMetric: acc=0.529342105263158, hinge=4.054028630005686, ce=12.71042477858694
Local test acc @ epoch 164: 0.5293
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.9802320611338473e-08
Local loss @ local epoch 2: 1.4901158351676713e-07
Local loss @ local epoch 3: 1.3113005934428656e-06
Local loss @ local epoch 4: 8.940696005765858e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.92 seconds!
[tester] 
AGNewsMetric: acc=0.7446052631578948, hinge=4.459353111668637, ce=9.905766567430998
Local test acc @ epoch 164: 0.7446
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.478414922952652
Local loss @ local epoch 1: 4.967053257587395e-08
Local loss @ local epoch 2: 1.9868197398409393e-07
Local loss @ local epoch 3: 2.8907782052556286e-06
Local loss @ local epoch 4: 6.18073099758476e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.59 seconds!
[tester] 
AGNewsMetric: acc=0.5878947368421052, hinge=9.019497520798131, ce=13.859423956620066
Local test acc @ epoch 164: 0.5879
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.22470800578594208
Local loss @ local epoch 1: 1.9868211964535476e-08
Local loss @ local epoch 2: 9.934106870446158e-09
Local loss @ local epoch 3: 7.053188255667919e-07
Local loss @ local epoch 4: 6.953874276405259e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.78 seconds!
[tester] 
AGNewsMetric: acc=0.4419736842105263, hinge=12.146324790151496, ce=15.026089150278192
Local test acc @ epoch 164: 0.442
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 1.1378711462020874
Local loss @ local epoch 1: 5.852083972968103e-07
Local loss @ local epoch 2: 1.332969986833632e-06
Local loss @ local epoch 3: 0.00012014060484943911
Local loss @ local epoch 4: 0.011353474110364914
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.46 seconds!
[tester] 
AGNewsMetric: acc=0.5346052631578947, hinge=11.148740243158842, ce=14.279434691981265
Local test acc @ epoch 164: 0.5346
Global evaluate on test data...
Evaluate data in 123.14 seconds!
[tester] 
AGNewsMetric: acc=0.8360526315789474, hinge=2.980394145814996, ce=9.120582405893426
Global test acc @ epoch 164: 0.8361
Global epoch 165...
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 4.5516242153098574e-07
Local loss @ local epoch 1: 1.4738533309355262e-06
Local loss @ local epoch 2: 7.47764715924859e-07
Local loss @ local epoch 3: 2.1782605017506285e-06
Local loss @ local epoch 4: 4.4973457988817245e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.33 seconds!
[tester] 
AGNewsMetric: acc=0.7161842105263158, hinge=6.009171277598331, ce=11.308647948817203
Local test acc @ epoch 165: 0.7162
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 5.914115536143072e-05
Local loss @ local epoch 1: 5.154691098141484e-05
Local loss @ local epoch 2: 0.0002937586687039584
Local loss @ local epoch 3: 0.00012560114555526525
Local loss @ local epoch 4: 8.266761869890615e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.38 seconds!
[tester] 
AGNewsMetric: acc=0.5132894736842105, hinge=7.382591032730906, ce=11.483890971133583
Local test acc @ epoch 165: 0.5133
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.21875876188278198
Local loss @ local epoch 1: 7.599381660838844e-06
Local loss @ local epoch 2: 7.972113280629856e-07
Local loss @ local epoch 3: 1.996750597754726e-06
Local loss @ local epoch 4: 7.35941284801811e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.15 seconds!
[tester] 
AGNewsMetric: acc=0.6157894736842106, hinge=6.418147935365376, ce=12.229129451952483
Local test acc @ epoch 165: 0.6158
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.1457663024193607e-07
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.384185648907078e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.47 seconds!
[tester] 
AGNewsMetric: acc=0.8486842105263158, hinge=2.5619707689787212, ce=9.585424055802195
Local test acc @ epoch 165: 0.8487
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.3091558814048767
Local loss @ local epoch 1: 1.2000359674857464e-06
Local loss @ local epoch 2: 0.0001438055041944608
Local loss @ local epoch 3: 5.844514453201555e-05
Local loss @ local epoch 4: 7.263715360750211e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.96 seconds!
[tester] 
AGNewsMetric: acc=0.6110526315789474, hinge=5.483919352230273, ce=11.872327862789756
Local test acc @ epoch 165: 0.6111
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 5.9604641222676946e-08
Local loss @ local epoch 1: 3.8743007735320134e-07
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 5.9604641222676946e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.66 seconds!
[tester] 
AGNewsMetric: acc=0.7622368421052632, hinge=4.208540011707105, ce=9.597950204548082
Local test acc @ epoch 165: 0.7622
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 1.2914334490687907e-07
Local loss @ local epoch 1: 1.9868213740892315e-08
Local loss @ local epoch 2: 5.9604641222676946e-08
Local loss @ local epoch 3: 6.953873565862523e-08
Local loss @ local epoch 4: 1.0927516314040986e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.07 seconds!
[tester] 
AGNewsMetric: acc=0.8182894736842106, hinge=3.0637798033262555, ce=8.8219041663722
Local test acc @ epoch 165: 0.8183
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.00011037085641874
Local loss @ local epoch 1: 7.219638064270839e-05
Local loss @ local epoch 2: 0.00016583374235779047
Local loss @ local epoch 3: 8.915940998122096e-05
Local loss @ local epoch 4: 0.022678663954138756
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.69 seconds!
[tester] 
AGNewsMetric: acc=0.7913157894736842, hinge=2.212559380029377, ce=9.75107641521253
Local test acc @ epoch 165: 0.7913
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 1.9868213740892315e-08
Local loss @ local epoch 1: 1.9868213740892315e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 3.973642392907095e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.27 seconds!
[tester] 
AGNewsMetric: acc=0.7468421052631579, hinge=5.529779665595607, ce=11.020142657631322
Local test acc @ epoch 165: 0.7468
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 3.2511621839148575e-08
Local loss @ local epoch 1: 1.0837207575775665e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.83 seconds!
[tester] 
AGNewsMetric: acc=0.8392105263157895, hinge=2.779727193681817, ce=9.01024110492907
Local test acc @ epoch 165: 0.8392
Global evaluate on test data...
Evaluate data in 123.61 seconds!
[tester] 
AGNewsMetric: acc=0.8532894736842105, hinge=2.402080400366532, ce=9.125591537074039
Global test acc @ epoch 165: 0.8533
Global epoch 166...
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 8.940696005765858e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 5.9604641222676946e-08
Local loss @ local epoch 3: 8.344636626134161e-07
Local loss @ local epoch 4: 1.0728817869676277e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.99 seconds!
[tester] 
AGNewsMetric: acc=0.8025, hinge=3.5228148146679525, ce=9.283665889940764
Local test acc @ epoch 166: 0.8025
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0011650874512270093
Local loss @ local epoch 1: 2.9802320611338473e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 9.934106870446158e-09
Local loss @ local epoch 4: 1.788138632718983e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.24 seconds!
[tester] 
AGNewsMetric: acc=0.44302631578947366, hinge=13.571665029023823, ce=15.056721189398514
Local test acc @ epoch 166: 0.443
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 4.521924438449787e-06
Local loss @ local epoch 1: 1.0331471145264004e-07
Local loss @ local epoch 2: 1.549543594592251e-05
Local loss @ local epoch 3: 1.5894566729457438e-07
Local loss @ local epoch 4: 2.598720811874955e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.83 seconds!
[tester] 
AGNewsMetric: acc=0.7463157894736843, hinge=4.529081213599757, ce=10.3464366129825
Local test acc @ epoch 166: 0.7463
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.00045620836317539215
Local loss @ local epoch 1: 8.66976463953506e-08
Local loss @ local epoch 2: 9.753485130659101e-08
Local loss @ local epoch 3: 6.393938178916869e-07
Local loss @ local epoch 4: 5.201851536185131e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.35 seconds!
[tester] 
AGNewsMetric: acc=0.6427631578947368, hinge=7.841340703964233, ce=12.881975535342567
Local test acc @ epoch 166: 0.6428
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 8.463453923468478e-06
Local loss @ local epoch 1: 1.9868213740892315e-08
Local loss @ local epoch 2: 4.470337273687619e-07
Local loss @ local epoch 3: 0.03096170164644718
Local loss @ local epoch 4: 2.1855019838312728e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.02 seconds!
[tester] 
AGNewsMetric: acc=0.7921052631578948, hinge=4.200645573766608, ce=10.031380673458703
Local test acc @ epoch 166: 0.7921
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 1.907345335894206e-06
Local loss @ local epoch 1: 3.695469104059157e-06
Local loss @ local epoch 2: 3.3378537409589626e-06
Local loss @ local epoch 3: 3.814687943304307e-06
Local loss @ local epoch 4: 1.3232102901383769e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.25 seconds!
[tester] 
AGNewsMetric: acc=0.5965789473684211, hinge=6.045988466363204, ce=13.10782024383545
Local test acc @ epoch 166: 0.5966
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.4019817113876343
Local loss @ local epoch 1: 1.1053894013457466e-06
Local loss @ local epoch 2: 0.0008437382057309151
Local loss @ local epoch 3: 4.641646592062898e-05
Local loss @ local epoch 4: 1.3809539079666138
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.69 seconds!
[tester] 
AGNewsMetric: acc=0.4881578947368421, hinge=12.083094127052709, ce=14.667307104813425
Local test acc @ epoch 166: 0.4882
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 3.3393669582437724e-05
Local loss @ local epoch 1: 0.0008429557201452553
Local loss @ local epoch 2: 9.111961117014289e-05
Local loss @ local epoch 3: 7.935891517263371e-06
Local loss @ local epoch 4: 7.016249583102763e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.37 seconds!
[tester] 
AGNewsMetric: acc=0.6476315789473684, hinge=5.494563432492708, ce=13.10410011291504
Local test acc @ epoch 166: 0.6476
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 5.2345916628837585e-05
Local loss @ local epoch 1: 1.788138632718983e-07
Local loss @ local epoch 2: 2.0265329112589825e-06
Local loss @ local epoch 3: 2.1979039956931956e-06
Local loss @ local epoch 4: 4.164801794104278e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.88 seconds!
[tester] 
AGNewsMetric: acc=0.4718421052631579, hinge=9.47702769028513, ce=14.4286266367059
Local test acc @ epoch 166: 0.4718
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.384185648907078e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.55 seconds!
[tester] 
AGNewsMetric: acc=0.8532894736842105, hinge=2.561200210797159, ce=9.297307341726203
Local test acc @ epoch 166: 0.8533
Global evaluate on test data...
Evaluate data in 123.8 seconds!
[tester] 
AGNewsMetric: acc=0.8414473684210526, hinge=2.921947482761584, ce=9.275829046149003
Global test acc @ epoch 166: 0.8414
Global epoch 167...
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 2.9802320611338473e-08
Local loss @ local epoch 1: 2.086161714487389e-07
Local loss @ local epoch 2: 8.046561561059207e-06
Local loss @ local epoch 3: 2.9802320611338473e-08
Local loss @ local epoch 4: 7.450576049450319e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.93 seconds!
[tester] 
AGNewsMetric: acc=0.8527631578947369, hinge=2.2053605536410683, ce=9.249482458014237
Local test acc @ epoch 167: 0.8528
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.7335813641548157
Local loss @ local epoch 1: 5.693885395885445e-05
Local loss @ local epoch 2: 1.8713550161919557e-05
Local loss @ local epoch 3: 0.00013318339188117534
Local loss @ local epoch 4: 1.1300769074296113e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.43 seconds!
[tester] 
AGNewsMetric: acc=0.6714473684210527, hinge=5.755727009020354, ce=12.049341356377852
Local test acc @ epoch 167: 0.6714
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 4.55867666460108e-05
Local loss @ local epoch 1: 1.026896461553406e-05
Local loss @ local epoch 2: 4.9874011892825365e-05
Local loss @ local epoch 3: 1.8817167074303143e-05
Local loss @ local epoch 4: 3.4570598472782876e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.06 seconds!
[tester] 
AGNewsMetric: acc=0.6406578947368421, hinge=8.618682052210758, ce=13.501982197008635
Local test acc @ epoch 167: 0.6407
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 1.9516430256771855e-05
Local loss @ local epoch 1: 5.201855515224452e-07
Local loss @ local epoch 2: 4.822455139219528e-06
Local loss @ local epoch 3: 1.511728623881936e-05
Local loss @ local epoch 4: 3.175252459186595e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.76 seconds!
[tester] 
AGNewsMetric: acc=0.785921052631579, hinge=3.863208206076371, ce=9.778197322644685
Local test acc @ epoch 167: 0.7859
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 1.9868213740892315e-08
Local loss @ local epoch 1: 1.9868211964535476e-08
Local loss @ local epoch 2: 1.9868213740892315e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.92 seconds!
[tester] 
AGNewsMetric: acc=0.8319736842105263, hinge=3.1557032019213627, ce=9.01975832688181
Local test acc @ epoch 167: 0.832
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.00010532706073718145
Local loss @ local epoch 1: 0.0004912639269605279
Local loss @ local epoch 2: 0.00012610842532012612
Local loss @ local epoch 3: 4.6688041038578376e-05
Local loss @ local epoch 4: 2.5867730073514394e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.17 seconds!
[tester] 
AGNewsMetric: acc=0.5885526315789473, hinge=6.633645820617676, ce=12.601482100235788
Local test acc @ epoch 167: 0.5886
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0013077661860734224
Local loss @ local epoch 1: 1.1473869108158397e-06
Local loss @ local epoch 2: 4.157776857027784e-05
Local loss @ local epoch 3: 4.1931903979275376e-05
Local loss @ local epoch 4: 0.00036326394183561206
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.52 seconds!
[tester] 
AGNewsMetric: acc=0.5765789473684211, hinge=9.31975471998516, ce=13.714034455951891
Local test acc @ epoch 167: 0.5766
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 8.669762507906853e-08
Local loss @ local epoch 2: 3.2511621839148575e-08
Local loss @ local epoch 3: 8.669765350077796e-08
Local loss @ local epoch 4: 3.2511621839148575e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.29 seconds!
[tester] 
AGNewsMetric: acc=0.724078947368421, hinge=6.044119150011163, ce=11.47313952195017
Local test acc @ epoch 167: 0.7241
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 7.152556946721234e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.42 seconds!
[tester] 
AGNewsMetric: acc=0.8188157894736842, hinge=3.4072161607993277, ce=10.120724684062758
Local test acc @ epoch 167: 0.8188
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 9.934106870446158e-09
Local loss @ local epoch 1: 1.9868211964535476e-08
Local loss @ local epoch 2: 9.934106870446158e-09
Local loss @ local epoch 3: 1.9868211964535476e-08
Local loss @ local epoch 4: 9.934106870446158e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.21 seconds!
[tester] 
AGNewsMetric: acc=0.8459210526315789, hinge=2.7144331487856412, ce=9.349580738669948
Local test acc @ epoch 167: 0.8459
Global evaluate on test data...
Evaluate data in 123.64 seconds!
[tester] 
AGNewsMetric: acc=0.8548684210526316, hinge=2.4762139890068458, ce=9.242461381209525
Global test acc @ epoch 167: 0.8549
Global epoch 168...
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.00015021898434497416
Local loss @ local epoch 1: 2.3047122965635936e-07
Local loss @ local epoch 2: 2.702075221350242e-07
Local loss @ local epoch 3: 3.651598308351822e-05
Local loss @ local epoch 4: 2.503376890672371e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.03 seconds!
[tester] 
AGNewsMetric: acc=0.5803947368421053, hinge=9.313237941139622, ce=14.189592999910053
Local test acc @ epoch 168: 0.5804
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.42996370792388916
Local loss @ local epoch 1: 1.7014364175338414e-06
Local loss @ local epoch 2: 2.600927757612226e-07
Local loss @ local epoch 3: 0.08957403898239136
Local loss @ local epoch 4: 6.296355877566384e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.42 seconds!
[tester] 
AGNewsMetric: acc=0.6047368421052631, hinge=8.886977128982544, ce=13.557087444506193
Local test acc @ epoch 168: 0.6047
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 8.003877883311361e-05
Local loss @ local epoch 1: 5.06638798469794e-07
Local loss @ local epoch 2: 1.5646216411369096e-07
Local loss @ local epoch 3: 2.2351733264258655e-07
Local loss @ local epoch 4: 4.738451934827026e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.38 seconds!
[tester] 
AGNewsMetric: acc=0.5603947368421053, hinge=9.556957087767751, ce=14.479905793039423
Local test acc @ epoch 168: 0.5604
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 8.344646289515367e-07
Local loss @ local epoch 1: 4.005229857284576e-05
Local loss @ local epoch 2: 5.471504482557066e-05
Local loss @ local epoch 3: 0.00012062053428962827
Local loss @ local epoch 4: 6.794889031880302e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.54 seconds!
[tester] 
AGNewsMetric: acc=0.4925, hinge=8.110321309942949, ce=14.125725964997944
Local test acc @ epoch 168: 0.4925
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.1920927533992653e-07
Local loss @ local epoch 2: 7.152551688704989e-07
Local loss @ local epoch 3: 3.862366156681674e-06
Local loss @ local epoch 4: 1.1968301805609372e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.27 seconds!
[tester] 
AGNewsMetric: acc=0.8292105263157895, hinge=1.6886371651448702, ce=9.771502528943513
Local test acc @ epoch 168: 0.8292
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.00017192383529618382
Local loss @ local epoch 1: 2.9802320611338473e-08
Local loss @ local epoch 2: 2.9802320611338473e-08
Local loss @ local epoch 3: 1.1920926823449918e-07
Local loss @ local epoch 4: 5.612588665826479e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.95 seconds!
[tester] 
AGNewsMetric: acc=0.4036842105263158, hinge=15.93055380168714, ce=17.170835207888956
Local test acc @ epoch 168: 0.4037
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 7.450572638845188e-07
Local loss @ local epoch 1: 2.9802320611338473e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 8.940696005765858e-08
Local loss @ local epoch 4: 2.9802308176840597e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 125.07 seconds!
[tester] 
AGNewsMetric: acc=0.703421052631579, hinge=5.810469657998336, ce=10.937235498930278
Local test acc @ epoch 168: 0.7034
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 3.9568127249367535e-05
Local loss @ local epoch 1: 2.9802320611338473e-08
Local loss @ local epoch 2: 2.9802317058624794e-08
Local loss @ local epoch 3: 2.0114208382437937e-05
Local loss @ local epoch 4: 0.00015782302943989635
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.55 seconds!
[tester] 
AGNewsMetric: acc=0.5311842105263158, hinge=10.924423831136604, ce=14.387960490176551
Local test acc @ epoch 168: 0.5312
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 2.6602674552123062e-05
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.167441515155133e-08
Local loss @ local epoch 3: 1.0837185300260899e-06
Local loss @ local epoch 4: 9.319975902144506e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.83 seconds!
[tester] 
AGNewsMetric: acc=0.4544736842105263, hinge=12.881058065514816, ce=15.509081890708522
Local test acc @ epoch 168: 0.4545
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 8.634046025690623e-06
Local loss @ local epoch 1: 0.005211623851209879
Local loss @ local epoch 2: 2.7077444428869057e-06
Local loss @ local epoch 3: 7.833593372197356e-06
Local loss @ local epoch 4: 8.934937795856968e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.92 seconds!
[tester] 
AGNewsMetric: acc=0.7364473684210526, hinge=4.741304328567104, ce=11.816456290797184
Local test acc @ epoch 168: 0.7364
Global evaluate on test data...
Evaluate data in 123.26 seconds!
[tester] 
AGNewsMetric: acc=0.8025, hinge=3.943839104175568, ce=9.81721140811318
Global test acc @ epoch 168: 0.8025
Global epoch 169...
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0017364523373544216
Local loss @ local epoch 1: 0.0021529013756662607
Local loss @ local epoch 2: 8.344599336851388e-06
Local loss @ local epoch 3: 0.0009019006392918527
Local loss @ local epoch 4: 4.645051740226336e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.34 seconds!
[tester] 
AGNewsMetric: acc=0.6603947368421053, hinge=3.482509287533007, ce=10.555328634161699
Local test acc @ epoch 169: 0.6604
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 1.4305111051271524e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.92 seconds!
[tester] 
AGNewsMetric: acc=0.5989473684210527, hinge=8.653450649663021, ce=13.687764996980366
Local test acc @ epoch 169: 0.5989
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 6.502323657286979e-08
Local loss @ local epoch 1: 3.2511621839148575e-08
Local loss @ local epoch 2: 3.2511621839148575e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.7772857745512738e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.4 seconds!
[tester] 
AGNewsMetric: acc=0.7730263157894737, hinge=4.317012622607382, ce=10.06475351434005
Local test acc @ epoch 169: 0.773
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 1.7583312228452996e-06
Local loss @ local epoch 1: 8.940696005765858e-08
Local loss @ local epoch 2: 8.642662123747868e-07
Local loss @ local epoch 3: 5.960461635368119e-07
Local loss @ local epoch 4: 2.7716055228665937e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.03 seconds!
[tester] 
AGNewsMetric: acc=0.7839473684210526, hinge=3.414605894841646, ce=8.871661617881374
Local test acc @ epoch 169: 0.7839
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 1.7785472869873047
Local loss @ local epoch 1: 1.9073478085829265e-07
Local loss @ local epoch 2: 1.0093006039824104e-06
Local loss @ local epoch 3: 3.337858913710079e-07
Local loss @ local epoch 4: 4.9183850933331996e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.75 seconds!
[tester] 
AGNewsMetric: acc=0.5921052631578947, hinge=8.063671132639834, ce=12.997419373361687
Local test acc @ epoch 169: 0.5921
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.7179314494132996
Local loss @ local epoch 1: 2.600213065306889e-06
Local loss @ local epoch 2: 1.490115550950577e-07
Local loss @ local epoch 3: 8.19563723553074e-08
Local loss @ local epoch 4: 1.4901156930591242e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.61 seconds!
[tester] 
AGNewsMetric: acc=0.5513157894736842, hinge=8.900996909392507, ce=14.30928117852462
Local test acc @ epoch 169: 0.5513
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 7.26090718217165e-07
Local loss @ local epoch 1: 2.8176725663797697e-07
Local loss @ local epoch 2: 2.600928610263509e-07
Local loss @ local epoch 3: 2.3841843699301535e-07
Local loss @ local epoch 4: 1.3004647314573958e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.65 seconds!
[tester] 
AGNewsMetric: acc=0.7769736842105263, hinge=3.759454516360634, ce=10.270003401103773
Local test acc @ epoch 169: 0.777
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 7.947284075271455e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 4.5696799588768044e-07
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 9.934106870446158e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.61 seconds!
[tester] 
AGNewsMetric: acc=0.7998684210526316, hinge=3.6962205031043607, ce=9.989127612866854
Local test acc @ epoch 169: 0.7999
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 8.940694584680386e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 5.960463056453591e-08
Local loss @ local epoch 4: 2.9802317058624794e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.57 seconds!
[tester] 
AGNewsMetric: acc=0.7971052631578948, hinge=3.812682382182071, ce=9.805934078818874
Local test acc @ epoch 169: 0.7971
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 4.7118901420617476e-05
Local loss @ local epoch 1: 5.4866006394149736e-05
Local loss @ local epoch 2: 4.538291977951303e-05
Local loss @ local epoch 3: 0.00016858101298566908
Local loss @ local epoch 4: 0.0005742671783082187
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.68 seconds!
[tester] 
AGNewsMetric: acc=0.6061842105263158, hinge=5.111190679951718, ce=11.611967713205438
Local test acc @ epoch 169: 0.6062
Global evaluate on test data...
Evaluate data in 123.84 seconds!
[tester] 
AGNewsMetric: acc=0.8196052631578947, hinge=3.200158106653314, ce=9.683143744217722
Global test acc @ epoch 169: 0.8196
Global epoch 170...
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 1.5682244300842285
Local loss @ local epoch 1: 4.822468781640055e-06
Local loss @ local epoch 2: 6.3720667640154716e-06
Local loss @ local epoch 3: 1.0684107542037964
Local loss @ local epoch 4: 0.896004319190979
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.47 seconds!
[tester] 
AGNewsMetric: acc=0.6064473684210526, hinge=8.062869863510132, ce=11.835869885494834
Local test acc @ epoch 170: 0.6064
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 1.5322338342666626
Local loss @ local epoch 1: 4.967053257587395e-08
Local loss @ local epoch 2: 7.947281943643247e-08
Local loss @ local epoch 3: 6.854518801446829e-07
Local loss @ local epoch 4: 2.781548289476632e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.06 seconds!
[tester] 
AGNewsMetric: acc=0.4557894736842105, hinge=12.98680620394255, ce=15.816099162854647
Local test acc @ epoch 170: 0.4558
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 1.1920926112907182e-07
Local loss @ local epoch 1: 7.947285496356926e-09
Local loss @ local epoch 2: 3.1789138432714026e-08
Local loss @ local epoch 3: 3.973642392907095e-08
Local loss @ local epoch 4: 7.947285496356926e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.97 seconds!
[tester] 
AGNewsMetric: acc=0.6043421052631579, hinge=9.196971117320814, ce=14.494844265987998
Local test acc @ epoch 170: 0.6043
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.010844535194337368
Local loss @ local epoch 1: 4.2716592929537e-07
Local loss @ local epoch 2: 4.967052902316027e-08
Local loss @ local epoch 3: 1.953812716237735e-05
Local loss @ local epoch 4: 0.0003452888922765851
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.91 seconds!
[tester] 
AGNewsMetric: acc=0.5272368421052631, hinge=11.315121025286222, ce=14.633300275300678
Local test acc @ epoch 170: 0.5272
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 2.384185648907078e-08
Local loss @ local epoch 1: 7.152556236178498e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.49 seconds!
[tester] 
AGNewsMetric: acc=0.7123684210526315, hinge=6.049094130867406, ce=11.483284048783151
Local test acc @ epoch 170: 0.7124
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 2.9802305334669654e-07
Local loss @ local epoch 1: 8.940695295223122e-08
Local loss @ local epoch 2: 1.1920926112907182e-07
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.9802320611338473e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.47 seconds!
[tester] 
AGNewsMetric: acc=0.729078947368421, hinge=5.22532980366757, ce=10.57605937355443
Local test acc @ epoch 170: 0.7291
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 2.0637899069697596e-06
Local loss @ local epoch 1: 1.4901154088420299e-07
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 4.470339263207279e-07
Local loss @ local epoch 4: 6.705521116145974e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.75 seconds!
[tester] 
AGNewsMetric: acc=0.49144736842105263, hinge=12.517305861021343, ce=17.130193654110556
Local test acc @ epoch 170: 0.4914
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 3.3934284147107974e-05
Local loss @ local epoch 1: 0.0016467832028865814
Local loss @ local epoch 2: 0.00018505110347177833
Local loss @ local epoch 3: 9.515980491414666e-05
Local loss @ local epoch 4: 0.0002010361640714109
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.33 seconds!
[tester] 
AGNewsMetric: acc=0.4556578947368421, hinge=4.719359777350174, ce=11.940902828417327
Local test acc @ epoch 170: 0.4557
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.18325553834438324
Local loss @ local epoch 1: 5.4186035214343065e-08
Local loss @ local epoch 2: 2.167441337519449e-08
Local loss @ local epoch 3: 1.0837207575775665e-08
Local loss @ local epoch 4: 1.0837207575775665e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.59 seconds!
[tester] 
AGNewsMetric: acc=0.5973684210526315, hinge=8.427921258022911, ce=13.11918860586066
Local test acc @ epoch 170: 0.5974
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 2.7502055672812276e-05
Local loss @ local epoch 1: 7.714420462434646e-06
Local loss @ local epoch 2: 0.007173591293394566
Local loss @ local epoch 3: 0.0046266550198197365
Local loss @ local epoch 4: 6.140530604170635e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.81 seconds!
[tester] 
AGNewsMetric: acc=0.73, hinge=3.7669992311377274, ce=11.068274765014648
Local test acc @ epoch 170: 0.73
Global evaluate on test data...
Evaluate data in 123.98 seconds!
[tester] 
AGNewsMetric: acc=0.8398684210526316, hinge=2.8373750473323622, ce=9.11631374359131
Global test acc @ epoch 170: 0.8399
Global epoch 171...
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 7.044161520752823e-07
Local loss @ local epoch 1: 0.01631024479866028
Local loss @ local epoch 2: 8.452996098640142e-07
Local loss @ local epoch 3: 6.393935336745926e-07
Local loss @ local epoch 4: 2.015710606428911e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.53 seconds!
[tester] 
AGNewsMetric: acc=0.6430263157894737, hinge=8.609810160586708, ce=13.303023749903629
Local test acc @ epoch 171: 0.643
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 9.934106870446158e-09
Local loss @ local epoch 2: 1.0927513471870043e-07
Local loss @ local epoch 3: 5.761763759437599e-07
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.77 seconds!
[tester] 
AGNewsMetric: acc=0.7251315789473685, hinge=5.636571138281571, ce=11.44720762955515
Local test acc @ epoch 171: 0.7251
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.167441337519449e-08
Local loss @ local epoch 4: 3.2511621839148575e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.47 seconds!
[tester] 
AGNewsMetric: acc=0.8127631578947369, hinge=3.4581186742531624, ce=9.751068372224507
Local test acc @ epoch 171: 0.8128
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 8.940695295223122e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.21 seconds!
[tester] 
AGNewsMetric: acc=0.7702631578947369, hinge=4.519239094006388, ce=10.770686033148515
Local test acc @ epoch 171: 0.7703
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00014614938118029386
Local loss @ local epoch 1: 2.9333654310903512e-05
Local loss @ local epoch 2: 3.799789283220889e-07
Local loss @ local epoch 3: 1.0934622287750244
Local loss @ local epoch 4: 8.940679663282936e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.54 seconds!
[tester] 
AGNewsMetric: acc=0.6552631578947369, hinge=5.243026538648103, ce=10.940686962730005
Local test acc @ epoch 171: 0.6553
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.5118499994277954
Local loss @ local epoch 1: 2.996100420205039e-06
Local loss @ local epoch 2: 2.551054876676062e-06
Local loss @ local epoch 3: 1.152351842392818e-06
Local loss @ local epoch 4: 7.867804470151896e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 125.23 seconds!
[tester] 
AGNewsMetric: acc=0.7028947368421052, hinge=5.0889107272499485, ce=11.165821597450657
Local test acc @ epoch 171: 0.7029
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0006008849595673382
Local loss @ local epoch 1: 1.4611413462262135e-05
Local loss @ local epoch 2: 1.2955704927444458
Local loss @ local epoch 3: 0.00020093230705242604
Local loss @ local epoch 4: 0.0004470419662538916
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.83 seconds!
[tester] 
AGNewsMetric: acc=0.7523684210526316, hinge=3.3554750106209204, ce=9.804044932315223
Local test acc @ epoch 171: 0.7524
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 1.1920926823449918e-07
Local loss @ local epoch 1: 9.53674117454284e-08
Local loss @ local epoch 2: 2.384185648907078e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.66 seconds!
[tester] 
AGNewsMetric: acc=0.7686842105263157, hinge=4.274916036254481, ce=10.073985910917584
Local test acc @ epoch 171: 0.7687
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 1.9868213740892315e-08
Local loss @ local epoch 1: 2.9802320611338473e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 5.960462701182223e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.67 seconds!
[tester] 
AGNewsMetric: acc=0.8035526315789474, hinge=3.7629195754151596, ce=9.8465818043759
Local test acc @ epoch 171: 0.8036
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 7.032691064523533e-05
Local loss @ local epoch 1: 5.245183729130076e-06
Local loss @ local epoch 2: 8.83643442648463e-05
Local loss @ local epoch 3: 9.020063771458808e-06
Local loss @ local epoch 4: 9.536735774418048e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.05 seconds!
[tester] 
AGNewsMetric: acc=0.47539473684210526, hinge=9.267863328833329, ce=15.10611253437243
Local test acc @ epoch 171: 0.4754
Global evaluate on test data...
Evaluate data in 123.71 seconds!
[tester] 
AGNewsMetric: acc=0.8555263157894737, hinge=2.500107396276374, ce=9.021068378247712
Global test acc @ epoch 171: 0.8555
Global epoch 172...
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 7.003352948231623e-06
Local loss @ local epoch 1: 3.2782497783045983e-07
Local loss @ local epoch 2: 7.450577754752885e-08
Local loss @ local epoch 3: 0.7555479407310486
Local loss @ local epoch 4: 8.344628099621332e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.89 seconds!
[tester] 
AGNewsMetric: acc=0.6169736842105263, hinge=9.178186550642314, ce=13.225523041173032
Local test acc @ epoch 172: 0.617
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 3.377587063368992e-06
Local loss @ local epoch 1: 1.0450541594764218e-05
Local loss @ local epoch 2: 1.2794924259651452e-05
Local loss @ local epoch 3: 1.3152613973943517e-05
Local loss @ local epoch 4: 6.814164953539148e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.27 seconds!
[tester] 
AGNewsMetric: acc=0.6298684210526316, hinge=5.341247875815943, ce=11.872335024381938
Local test acc @ epoch 172: 0.6299
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 6.904043402755633e-06
Local loss @ local epoch 1: 3.973642392907095e-08
Local loss @ local epoch 2: 3.973642037635727e-08
Local loss @ local epoch 3: 6.953874276405259e-08
Local loss @ local epoch 4: 5.165732659406785e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.89 seconds!
[tester] 
AGNewsMetric: acc=0.36894736842105263, hinge=16.151198080966346, ce=18.749769877383585
Local test acc @ epoch 172: 0.3689
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0010217276867479086
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 4.768371297814156e-08
Local loss @ local epoch 4: 6.818694146204507e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.09 seconds!
[tester] 
AGNewsMetric: acc=0.33171052631578946, hinge=14.296732731869346, ce=18.98094732987253
Local test acc @ epoch 172: 0.3317
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 2.9802320611338473e-08
Local loss @ local epoch 1: 2.9802320611338473e-08
Local loss @ local epoch 2: 2.9802320611338473e-08
Local loss @ local epoch 3: 2.9802320611338473e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.53 seconds!
[tester] 
AGNewsMetric: acc=0.8296052631578947, hinge=3.069732915978683, ce=9.646520548368755
Local test acc @ epoch 172: 0.8296
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.21613003313541412
Local loss @ local epoch 1: 4.98510360102955e-07
Local loss @ local epoch 2: 0.0003422259178478271
Local loss @ local epoch 3: 0.2900625467300415
Local loss @ local epoch 4: 1.3296466931933537e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.75 seconds!
[tester] 
AGNewsMetric: acc=0.6946052631578947, hinge=6.372376724293358, ce=11.597134375321238
Local test acc @ epoch 172: 0.6946
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 2.2034309949958697e-05
Local loss @ local epoch 1: 3.8146924907778157e-07
Local loss @ local epoch 2: 6.739085802109912e-05
Local loss @ local epoch 3: 1.6689295989635866e-07
Local loss @ local epoch 4: 7.470434297829343e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.69 seconds!
[tester] 
AGNewsMetric: acc=0.7956578947368421, hinge=3.362448696337248, ce=10.081237847177606
Local test acc @ epoch 172: 0.7957
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.00035216708783991635
Local loss @ local epoch 1: 1.6255798129805044e-07
Local loss @ local epoch 2: 4.659988803723536e-07
Local loss @ local epoch 3: 7.260923098328931e-07
Local loss @ local epoch 4: 2.8910617402289063e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.11 seconds!
[tester] 
AGNewsMetric: acc=0.4586842105263158, hinge=11.678226986935265, ce=14.767362678929379
Local test acc @ epoch 172: 0.4587
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 3.6390974855748937e-05
Local loss @ local epoch 1: 6.286170537350699e-05
Local loss @ local epoch 2: 2.80991889667348e-06
Local loss @ local epoch 3: 0.0001517076016170904
Local loss @ local epoch 4: 2.843975835276069e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.86 seconds!
[tester] 
AGNewsMetric: acc=0.755, hinge=4.111222877753408, ce=11.029740454021253
Local test acc @ epoch 172: 0.755
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 6.755172421435418e-07
Local loss @ local epoch 1: 1.9868211964535476e-08
Local loss @ local epoch 2: 1.0927514182412779e-07
Local loss @ local epoch 3: 3.973642392907095e-08
Local loss @ local epoch 4: 0.0029125551227480173
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.84 seconds!
[tester] 
AGNewsMetric: acc=0.7242105263157895, hinge=5.57624503386648, ce=11.609366324575324
Local test acc @ epoch 172: 0.7242
Global evaluate on test data...
Evaluate data in 123.66 seconds!
[tester] 
AGNewsMetric: acc=0.8198684210526316, hinge=3.420881142867239, ce=9.760468513087222
Global test acc @ epoch 172: 0.8199
Global epoch 173...
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.9953099489212036
Local loss @ local epoch 1: 2.2001784600433894e-05
Local loss @ local epoch 2: 1.2482718375395052e-05
Local loss @ local epoch 3: 0.0008633779361844063
Local loss @ local epoch 4: 0.0034270677715539932
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.71 seconds!
[tester] 
AGNewsMetric: acc=0.6219736842105263, hinge=4.595305063348068, ce=11.081587323640521
Local test acc @ epoch 173: 0.622
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 2.384185648907078e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.02 seconds!
[tester] 
AGNewsMetric: acc=0.8202631578947368, hinge=3.137272220787249, ce=10.271875024092825
Local test acc @ epoch 173: 0.8203
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.00847635231912136
Local loss @ local epoch 1: 4.5299432827050623e-07
Local loss @ local epoch 2: 6.039915660949191e-07
Local loss @ local epoch 3: 5.086250780550472e-07
Local loss @ local epoch 4: 9.377746437166934e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.59 seconds!
[tester] 
AGNewsMetric: acc=0.6194736842105263, hinge=8.241905855379606, ce=13.785106936003032
Local test acc @ epoch 173: 0.6195
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 2.167441337519449e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.0837207575775665e-08
Local loss @ local epoch 3: 1.0837207575775665e-08
Local loss @ local epoch 4: 2.167441515155133e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.18 seconds!
[tester] 
AGNewsMetric: acc=0.7796052631578947, hinge=4.380806641829642, ce=10.050977765133506
Local test acc @ epoch 173: 0.7796
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 2.9802320611338473e-08
Local loss @ local epoch 1: 1.4901156930591242e-07
Local loss @ local epoch 2: 3.576276412786683e-07
Local loss @ local epoch 3: 2.384184938364342e-07
Local loss @ local epoch 4: 2.3841852225814364e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.67 seconds!
[tester] 
AGNewsMetric: acc=0.7014473684210526, hinge=6.289359467406022, ce=11.522532687940096
Local test acc @ epoch 173: 0.7014
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 8.452985298390558e-07
Local loss @ local epoch 1: 1.2571122169902083e-06
Local loss @ local epoch 2: 1.1920926823449918e-07
Local loss @ local epoch 3: 5.093476147521869e-07
Local loss @ local epoch 4: 8.66976463953506e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.34 seconds!
[tester] 
AGNewsMetric: acc=0.8194736842105264, hinge=3.2564008544620715, ce=9.226977579217207
Local test acc @ epoch 173: 0.8195
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 2.9802320611338473e-08
Local loss @ local epoch 1: 5.960463056453591e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.61 seconds!
[tester] 
AGNewsMetric: acc=0.7728947368421053, hinge=4.821811728602961, ce=10.764933425501773
Local test acc @ epoch 173: 0.7729
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 4.967052902316027e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 3.973642748178463e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.6 seconds!
[tester] 
AGNewsMetric: acc=0.7952631578947369, hinge=3.826944389719712, ce=9.9243514593024
Local test acc @ epoch 173: 0.7953
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.004973310977220535
Local loss @ local epoch 1: 1.3411040811206476e-07
Local loss @ local epoch 2: 5.960463411724959e-08
Local loss @ local epoch 3: 0.5046522617340088
Local loss @ local epoch 4: 1.2144414540671278e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.13 seconds!
[tester] 
AGNewsMetric: acc=0.7132894736842105, hinge=5.062801261701082, ce=10.717629778008712
Local test acc @ epoch 173: 0.7133
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 4.108600478502922e-05
Local loss @ local epoch 1: 8.169472130248323e-05
Local loss @ local epoch 2: 3.186745379935019e-05
Local loss @ local epoch 3: 0.004718472715467215
Local loss @ local epoch 4: 0.0004549118457362056
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.7 seconds!
[tester] 
AGNewsMetric: acc=0.5515789473684211, hinge=4.703017475730494, ce=11.230210171749718
Local test acc @ epoch 173: 0.5516
Global evaluate on test data...
Evaluate data in 123.02 seconds!
[tester] 
AGNewsMetric: acc=0.8452631578947368, hinge=2.808556728614004, ce=9.108162127043071
Global test acc @ epoch 173: 0.8453
Global epoch 174...
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 3.6160015497443965e-06
Local loss @ local epoch 1: 2.1576239305431955e-05
Local loss @ local epoch 2: 1.3788368960376829e-05
Local loss @ local epoch 3: 3.0159142625052482e-05
Local loss @ local epoch 4: 7.152528269216418e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.95 seconds!
[tester] 
AGNewsMetric: acc=0.5619736842105263, hinge=6.8087817613702075, ce=13.256429971393786
Local test acc @ epoch 174: 0.562
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.024222292006015778
Local loss @ local epoch 1: 2.5033778001670726e-06
Local loss @ local epoch 2: 2.3191403215605533e-06
Local loss @ local epoch 3: 0.028603704646229744
Local loss @ local epoch 4: 0.015082848258316517
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.36 seconds!
[tester] 
AGNewsMetric: acc=0.6517105263157895, hinge=7.372900951285112, ce=12.142825726960835
Local test acc @ epoch 174: 0.6517
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.03260524943470955
Local loss @ local epoch 1: 3.6865567381028086e-05
Local loss @ local epoch 2: 0.0005796948680654168
Local loss @ local epoch 3: 0.00030514944228343666
Local loss @ local epoch 4: 0.30365538597106934
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.73 seconds!
[tester] 
AGNewsMetric: acc=0.5511842105263158, hinge=5.379606959192376, ce=11.75813897584614
Local test acc @ epoch 174: 0.5512
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.11177392303943634
Local loss @ local epoch 1: 2.66229562839726e-06
Local loss @ local epoch 2: 4.609420614087867e-07
Local loss @ local epoch 3: 2.63050310422841e-06
Local loss @ local epoch 4: 1.0060714483261108
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.86 seconds!
[tester] 
AGNewsMetric: acc=0.5594736842105263, hinge=9.36641735679225, ce=14.893907956575093
Local test acc @ epoch 174: 0.5595
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 8.344619573108503e-07
Local loss @ local epoch 1: 3.725289943190546e-08
Local loss @ local epoch 2: 2.2351740014414645e-08
Local loss @ local epoch 3: 4.470347647611561e-08
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.99 seconds!
[tester] 
AGNewsMetric: acc=0.733421052631579, hinge=5.377390177375392, ce=11.356808170519377
Local test acc @ epoch 174: 0.7334
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 1.172221686829289e-06
Local loss @ local epoch 1: 3.973642037635727e-08
Local loss @ local epoch 2: 3.4769337275974976e-07
Local loss @ local epoch 3: 2.3841845120387006e-07
Local loss @ local epoch 4: 1.2777988910675049
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.95 seconds!
[tester] 
AGNewsMetric: acc=0.62, hinge=8.493163390159607, ce=13.454682279887953
Local test acc @ epoch 174: 0.62
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.384185648907078e-08
Local loss @ local epoch 2: 2.384185648907078e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.75 seconds!
[tester] 
AGNewsMetric: acc=0.7482894736842105, hinge=4.875943157547399, ce=11.659388917621813
Local test acc @ epoch 174: 0.7483
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0011350946733728051
Local loss @ local epoch 1: 1.9868211964535476e-08
Local loss @ local epoch 2: 3.973642392907095e-08
Local loss @ local epoch 3: 2.3841842278216063e-07
Local loss @ local epoch 4: 4.609336883731885e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.66 seconds!
[tester] 
AGNewsMetric: acc=0.5059210526315789, hinge=11.88401551823867, ce=14.866384743138363
Local test acc @ epoch 174: 0.5059
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.9802320611338473e-08
Local loss @ local epoch 2: 2.086161714487389e-07
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.9802320611338473e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.49 seconds!
[tester] 
AGNewsMetric: acc=0.8232894736842106, hinge=3.1894136566864817, ce=8.619623580731844
Local test acc @ epoch 174: 0.8233
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.001335124485194683
Local loss @ local epoch 1: 2.167441337519449e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.03 seconds!
[tester] 
AGNewsMetric: acc=0.4525, hinge=12.632088907141435, ce=16.406543494776674
Local test acc @ epoch 174: 0.4525
Global evaluate on test data...
Evaluate data in 123.42 seconds!
[tester] 
AGNewsMetric: acc=0.8509210526315789, hinge=2.781214641018918, ce=9.12091121673584
Global test acc @ epoch 174: 0.8509
Global epoch 175...
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 2.817672850596864e-07
Local loss @ local epoch 1: 1.0945527719741222e-06
Local loss @ local epoch 2: 3.305314521639957e-06
Local loss @ local epoch 3: 2.3841840857130592e-07
Local loss @ local epoch 4: 3.09939923681668e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.14 seconds!
[tester] 
AGNewsMetric: acc=0.8231578947368421, hinge=3.1664846932260615, ce=9.634610621803684
Local test acc @ epoch 175: 0.8232
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.9802320611338473e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 5.9604641222676946e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.38 seconds!
[tester] 
AGNewsMetric: acc=0.8539473684210527, hinge=2.6574729128887777, ce=9.478362695794356
Local test acc @ epoch 175: 0.8539
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0002618232392705977
Local loss @ local epoch 1: 0.0008849580772221088
Local loss @ local epoch 2: 0.004795412067323923
Local loss @ local epoch 3: 0.0028527171816676855
Local loss @ local epoch 4: 3.8126825529616326e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.84 seconds!
[tester] 
AGNewsMetric: acc=0.6461842105263158, hinge=6.0040626350202055, ce=11.745303611755372
Local test acc @ epoch 175: 0.6462
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 4.657403769670054e-05
Local loss @ local epoch 1: 1.0331470434721268e-07
Local loss @ local epoch 2: 9.536741885085576e-08
Local loss @ local epoch 3: 3.0994382882454374e-07
Local loss @ local epoch 4: 1.3192408232498565e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.79 seconds!
[tester] 
AGNewsMetric: acc=0.5496052631578947, hinge=11.028749752044678, ce=14.638468680130808
Local test acc @ epoch 175: 0.5496
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 6.953874276405259e-08
Local loss @ local epoch 1: 2.9802317058624794e-08
Local loss @ local epoch 2: 9.934106870446158e-09
Local loss @ local epoch 3: 9.934106870446158e-09
Local loss @ local epoch 4: 2.9802320611338473e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.38 seconds!
[tester] 
AGNewsMetric: acc=0.8475, hinge=2.823124658810465, ce=8.82773684250681
Local test acc @ epoch 175: 0.8475
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 2.9802320611338473e-08
Local loss @ local epoch 1: 9.934106870446158e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 9.934106870446158e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 125.08 seconds!
[tester] 
AGNewsMetric: acc=0.8073684210526316, hinge=3.951052576366224, ce=9.908718817861457
Local test acc @ epoch 175: 0.8074
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.46 seconds!
[tester] 
AGNewsMetric: acc=0.8267105263157895, hinge=3.2725918415973063, ce=9.657369946931539
Local test acc @ epoch 175: 0.8267
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 5.066020821686834e-05
Local loss @ local epoch 1: 1.311290998273762e-05
Local loss @ local epoch 2: 3.3655567676760256e-05
Local loss @ local epoch 3: 9.456472616875544e-05
Local loss @ local epoch 4: 0.0006642210646532476
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.34 seconds!
[tester] 
AGNewsMetric: acc=0.723421052631579, hinge=2.7048026980851825, ce=10.411089405260588
Local test acc @ epoch 175: 0.7234
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 1.0837207575775665e-08
Local loss @ local epoch 1: 2.167441515155133e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.71 seconds!
[tester] 
AGNewsMetric: acc=0.8163157894736842, hinge=3.664324400926891, ce=9.85954133485493
Local test acc @ epoch 175: 0.8163
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00014995233505032957
Local loss @ local epoch 1: 3.7252880247251596e-07
Local loss @ local epoch 2: 3.7997932622602093e-07
Local loss @ local epoch 3: 1.1465312242507935
Local loss @ local epoch 4: 1.7732328387864982e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.02 seconds!
[tester] 
AGNewsMetric: acc=0.8084210526315789, hinge=2.8565625346334356, ce=10.041572556746633
Local test acc @ epoch 175: 0.8084
Global evaluate on test data...
Evaluate data in 124.33 seconds!
[tester] 
AGNewsMetric: acc=0.8552631578947368, hinge=2.609271831512451, ce=8.905102404544229
Global test acc @ epoch 175: 0.8553
Global epoch 176...
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 2.9802320611338473e-08
Local loss @ local epoch 1: 1.490115550950577e-07
Local loss @ local epoch 2: 1.5894556781859137e-07
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.384182948844682e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.45 seconds!
[tester] 
AGNewsMetric: acc=0.8376315789473684, hinge=2.9691057774895118, ce=8.684064266807155
Local test acc @ epoch 176: 0.8376
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 2.364301280977088e-06
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 9.934106870446158e-09
Local loss @ local epoch 3: 4.7683636239526095e-07
Local loss @ local epoch 4: 2.0861615723788418e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.76 seconds!
[tester] 
AGNewsMetric: acc=0.40328947368421053, hinge=16.036644523018285, ce=17.528662344280043
Local test acc @ epoch 176: 0.4033
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0002057482925010845
Local loss @ local epoch 1: 6.70552182668871e-08
Local loss @ local epoch 2: 1.3335166840988677e-05
Local loss @ local epoch 3: 1.8626448650138627e-07
Local loss @ local epoch 4: 8.1211214819632e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.99 seconds!
[tester] 
AGNewsMetric: acc=0.6189473684210526, hinge=8.661737380780671, ce=13.150141983032226
Local test acc @ epoch 176: 0.6189
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 6.755190042895265e-07
Local loss @ local epoch 1: 2.781549426345009e-07
Local loss @ local epoch 2: 1.9868208767093165e-07
Local loss @ local epoch 3: 2.1855009890714427e-06
Local loss @ local epoch 4: 0.00018539877783041447
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 122.98 seconds!
[tester] 
AGNewsMetric: acc=0.7582894736842105, hinge=4.47850094029778, ce=11.229993057250976
Local test acc @ epoch 176: 0.7583
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 1.8920336515293457e-05
Local loss @ local epoch 1: 1.6255806656317873e-07
Local loss @ local epoch 2: 2.0157021936029196e-06
Local loss @ local epoch 3: 4.698889097198844e-05
Local loss @ local epoch 4: 1.1605964573391248e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.71 seconds!
[tester] 
AGNewsMetric: acc=0.6717105263157894, hinge=7.50470928493299, ce=12.464004331889905
Local test acc @ epoch 176: 0.6717
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 5.960463766996327e-08
Local loss @ local epoch 4: 1.1920927533992653e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.88 seconds!
[tester] 
AGNewsMetric: acc=0.845657894736842, hinge=2.7998946182351365, ce=8.918105002955386
Local test acc @ epoch 176: 0.8457
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.3025453984737396
Local loss @ local epoch 1: 3.2511621839148575e-08
Local loss @ local epoch 2: 5.418602455620203e-08
Local loss @ local epoch 3: 4.33488231976753e-08
Local loss @ local epoch 4: 3.034415101410559e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.13 seconds!
[tester] 
AGNewsMetric: acc=0.5471052631578948, hinge=9.605055477995622, ce=13.38207721710205
Local test acc @ epoch 176: 0.5471
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.384185648907078e-08
Local loss @ local epoch 2: 9.536741885085576e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.66 seconds!
[tester] 
AGNewsMetric: acc=0.660921052631579, hinge=6.590079997213263, ce=12.386198477494089
Local test acc @ epoch 176: 0.6609
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 3.790809387282934e-06
Local loss @ local epoch 1: 2.3047113018037635e-07
Local loss @ local epoch 2: 7.94728478581419e-08
Local loss @ local epoch 3: 1.033146688200759e-07
Local loss @ local epoch 4: 0.6275879740715027
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.73 seconds!
[tester] 
AGNewsMetric: acc=0.6257894736842106, hinge=8.92953840858058, ce=13.822086806046336
Local test acc @ epoch 176: 0.6258
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 3.882799319399055e-06
Local loss @ local epoch 1: 2.6566465294308728e-06
Local loss @ local epoch 2: 5.790160457763704e-07
Local loss @ local epoch 3: 2.895058287322172e-06
Local loss @ local epoch 4: 2.9291174996615155e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.09 seconds!
[tester] 
AGNewsMetric: acc=0.679078947368421, hinge=5.523717329627589, ce=12.432929000854493
Local test acc @ epoch 176: 0.6791
Global evaluate on test data...
Evaluate data in 125.14 seconds!
[tester] 
AGNewsMetric: acc=0.8167105263157894, hinge=3.5638504931801243, ce=9.514238640634638
Global test acc @ epoch 176: 0.8167
Global epoch 177...
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 9.933542605722323e-05
Local loss @ local epoch 1: 0.007166535593569279
Local loss @ local epoch 2: 0.043083734810352325
Local loss @ local epoch 3: 8.270105240626435e-07
Local loss @ local epoch 4: 8.270120588349528e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.64 seconds!
[tester] 
AGNewsMetric: acc=0.8117105263157894, hinge=3.0315792987221166, ce=9.288911628723145
Local test acc @ epoch 177: 0.8117
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 2.4437554202449974e-06
Local loss @ local epoch 1: 1.9868213740892315e-08
Local loss @ local epoch 2: 8.940691742509443e-08
Local loss @ local epoch 3: 1.4463214029092342e-05
Local loss @ local epoch 4: 9.934106870446158e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.18 seconds!
[tester] 
AGNewsMetric: acc=0.7372368421052632, hinge=5.642073091707732, ce=11.15839534960295
Local test acc @ epoch 177: 0.7372
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.66 seconds!
[tester] 
AGNewsMetric: acc=0.7719736842105264, hinge=4.643768357226723, ce=10.916421111257453
Local test acc @ epoch 177: 0.772
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.003587363986298442
Local loss @ local epoch 1: 6.838813715148717e-05
Local loss @ local epoch 2: 0.0005546290194615722
Local loss @ local epoch 3: 1.0500675439834595
Local loss @ local epoch 4: 0.022282524034380913
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.48 seconds!
[tester] 
AGNewsMetric: acc=0.6653947368421053, hinge=4.061986670243113, ce=11.427853532088431
Local test acc @ epoch 177: 0.6654
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 2.9802320611338473e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.9802320611338473e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.76 seconds!
[tester] 
AGNewsMetric: acc=0.8285526315789473, hinge=3.2295045234027664, ce=9.662882911280581
Local test acc @ epoch 177: 0.8286
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 6.068818265703158e-07
Local loss @ local epoch 1: 7.694389410062286e-07
Local loss @ local epoch 2: 6.502323657286979e-08
Local loss @ local epoch 3: 7.802764230291359e-07
Local loss @ local epoch 4: 4.0097640408021107e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.31 seconds!
[tester] 
AGNewsMetric: acc=0.6857894736842105, hinge=7.067261475261889, ce=11.780156274092825
Local test acc @ epoch 177: 0.6858
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 5.129586497787386e-05
Local loss @ local epoch 1: 5.284922281134641e-06
Local loss @ local epoch 2: 4.35486035712529e-05
Local loss @ local epoch 3: 7.795396231813356e-05
Local loss @ local epoch 4: 9.814808436203748e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 125.28 seconds!
[tester] 
AGNewsMetric: acc=0.4513157894736842, hinge=8.853493702537135, ce=14.232375050594932
Local test acc @ epoch 177: 0.4513
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 7.947284075271455e-08
Local loss @ local epoch 1: 9.934106870446158e-09
Local loss @ local epoch 2: 8.940693163594915e-08
Local loss @ local epoch 3: 1.8874789020628668e-07
Local loss @ local epoch 4: 1.9868213740892315e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.26 seconds!
[tester] 
AGNewsMetric: acc=0.7834210526315789, hinge=4.137538383132533, ce=9.55614492315995
Local test acc @ epoch 177: 0.7834
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.0010798029834404588
Local loss @ local epoch 1: 1.033146688200759e-07
Local loss @ local epoch 2: 2.066293376401518e-07
Local loss @ local epoch 3: 2.384184938364342e-07
Local loss @ local epoch 4: 2.225238660003015e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.81 seconds!
[tester] 
AGNewsMetric: acc=0.5965789473684211, hinge=9.324467202236779, ce=13.253977773565994
Local test acc @ epoch 177: 0.5966
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.167441515155133e-08
Local loss @ local epoch 2: 1.0837207575775665e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.43 seconds!
[tester] 
AGNewsMetric: acc=0.8038157894736843, hinge=3.9422970197075293, ce=10.120542628639623
Local test acc @ epoch 177: 0.8038
Global evaluate on test data...
Evaluate data in 123.7 seconds!
[tester] 
AGNewsMetric: acc=0.8463157894736842, hinge=2.890571843950372, ce=8.98382438258121
Global test acc @ epoch 177: 0.8463
Global epoch 178...
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.005573814269155264
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.5894561045115552e-07
Local loss @ local epoch 3: 1.169163533631945e-05
Local loss @ local epoch 4: 2.37984561920166
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.04 seconds!
[tester] 
AGNewsMetric: acc=0.4710526315789474, hinge=13.770159114034552, ce=16.71596101459704
Local test acc @ epoch 178: 0.4711
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 4.7172538870654535e-06
Local loss @ local epoch 1: 2.418239546386758e-06
Local loss @ local epoch 2: 9.29818725126097e-06
Local loss @ local epoch 3: 1.277223327633692e-05
Local loss @ local epoch 4: 1.4507800340652466
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.27 seconds!
[tester] 
AGNewsMetric: acc=0.7822368421052631, hinge=3.0649391917178503, ce=10.202048568725585
Local test acc @ epoch 178: 0.7822
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.1810011863708496
Local loss @ local epoch 1: 4.6938487230363535e-07
Local loss @ local epoch 2: 1.9371505288745539e-07
Local loss @ local epoch 3: 3.0547369078703923e-07
Local loss @ local epoch 4: 1.2478826647566166e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.53 seconds!
[tester] 
AGNewsMetric: acc=0.6127631578947368, hinge=9.80923836457102, ce=13.866470433285361
Local test acc @ epoch 178: 0.6128
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.30346766114234924
Local loss @ local epoch 1: 2.6226027216580405e-07
Local loss @ local epoch 2: 1.2318191693339031e-06
Local loss @ local epoch 3: 4.450466235539352e-07
Local loss @ local epoch 4: 9.37749064178206e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.84 seconds!
[tester] 
AGNewsMetric: acc=0.593421052631579, hinge=7.796672933478105, ce=12.980620325991982
Local test acc @ epoch 178: 0.5934
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 1.6255799550890515e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 4.334883030310266e-08
Local loss @ local epoch 4: 1.4088358568642434e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.55 seconds!
[tester] 
AGNewsMetric: acc=0.5684210526315789, hinge=10.431452165904798, ce=14.905758930005526
Local test acc @ epoch 178: 0.5684
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 3.5762778338721546e-07
Local loss @ local epoch 1: 2.5431227186345495e-06
Local loss @ local epoch 2: 5.563098852690018e-07
Local loss @ local epoch 3: 4.7683693082944956e-07
Local loss @ local epoch 4: 3.973642748178463e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.59 seconds!
[tester] 
AGNewsMetric: acc=0.6586842105263158, hinge=5.822348825555099, ce=12.741078708046361
Local test acc @ epoch 178: 0.6587
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 1.0620441344144638e-06
Local loss @ local epoch 1: 4.334882675038898e-08
Local loss @ local epoch 2: 8.84273413248593e-06
Local loss @ local epoch 3: 9.536701668366732e-07
Local loss @ local epoch 4: 3.793019516251661e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.4 seconds!
[tester] 
AGNewsMetric: acc=0.8021052631578948, hinge=3.9135457183185376, ce=10.075778595773798
Local test acc @ epoch 178: 0.8021
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 3.973642748178463e-08
Local loss @ local epoch 1: 6.953873565862523e-08
Local loss @ local epoch 2: 3.0795681027484534e-07
Local loss @ local epoch 3: 4.967052191773291e-08
Local loss @ local epoch 4: 9.934106870446158e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.88 seconds!
[tester] 
AGNewsMetric: acc=0.8356578947368422, hinge=3.2971181919700223, ce=8.937795992399517
Local test acc @ epoch 178: 0.8357
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 2.9802320611338473e-08
Local loss @ local epoch 1: 1.1920928244535389e-07
Local loss @ local epoch 2: 2.9802320611338473e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 5.662435000886035e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.35 seconds!
[tester] 
AGNewsMetric: acc=0.7628947368421053, hinge=4.175809829611527, ce=9.565770554793508
Local test acc @ epoch 178: 0.7629
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 2.384185648907078e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.384185648907078e-08
Local loss @ local epoch 3: 2.384185648907078e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.77 seconds!
[tester] 
AGNewsMetric: acc=0.8315789473684211, hinge=3.0557452987369738, ce=10.052159550315455
Local test acc @ epoch 178: 0.8316
Global evaluate on test data...
Evaluate data in 123.45 seconds!
[tester] 
AGNewsMetric: acc=0.8442105263157895, hinge=3.0130087183651173, ce=9.092590324000309
Global test acc @ epoch 178: 0.8442
Global epoch 179...
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 8.670233000884764e-06
Local loss @ local epoch 1: 1.0331469013635797e-07
Local loss @ local epoch 2: 5.722024525312008e-07
Local loss @ local epoch 3: 0.0007357870345003903
Local loss @ local epoch 4: 5.086251917418849e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.56 seconds!
[tester] 
AGNewsMetric: acc=0.7598684210526315, hinge=4.851150588989258, ce=10.62821630578292
Local test acc @ epoch 179: 0.7599
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 2.9802320611338473e-08
Local loss @ local epoch 1: 2.9802320611338473e-08
Local loss @ local epoch 2: 2.9802320611338473e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.44 seconds!
[tester] 
AGNewsMetric: acc=0.8172368421052632, hinge=3.7996678967224926, ce=9.373113226639598
Local test acc @ epoch 179: 0.8172
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 1.5894558202944609e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.9868213740892315e-08
Local loss @ local epoch 4: 1.9868211964535476e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.37 seconds!
[tester] 
AGNewsMetric: acc=0.8025, hinge=4.157782876867997, ce=9.469323144210012
Local test acc @ epoch 179: 0.8025
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0002506512973923236
Local loss @ local epoch 1: 0.00034679812961257994
Local loss @ local epoch 2: 0.0007433246937580407
Local loss @ local epoch 3: 0.0715322494506836
Local loss @ local epoch 4: 0.006479757372289896
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.55 seconds!
[tester] 
AGNewsMetric: acc=0.7057894736842105, hinge=3.532522164896915, ce=11.054228469447086
Local test acc @ epoch 179: 0.7058
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 1.0837207575775665e-08
Local loss @ local epoch 1: 1.0837207575775665e-08
Local loss @ local epoch 2: 5.4186031661629386e-08
Local loss @ local epoch 3: 1.0837207575775665e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.48 seconds!
[tester] 
AGNewsMetric: acc=0.8007894736842105, hinge=4.314222136296724, ce=9.760308056881554
Local test acc @ epoch 179: 0.8008
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 6.953874276405259e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 8.940693874137651e-08
Local loss @ local epoch 3: 1.9868211964535476e-08
Local loss @ local epoch 4: 9.934106870446158e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.08 seconds!
[tester] 
AGNewsMetric: acc=0.8011842105263158, hinge=4.020445771970247, ce=10.06538212625604
Local test acc @ epoch 179: 0.8012
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.4305111051271524e-07
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.18 seconds!
[tester] 
AGNewsMetric: acc=0.8375, hinge=3.037233175353, ce=9.163384036013955
Local test acc @ epoch 179: 0.8375
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 2.438360525047756e-06
Local loss @ local epoch 1: 1.1920926823449918e-07
Local loss @ local epoch 2: 8.56138115068461e-07
Local loss @ local epoch 3: 1.5880210399627686
Local loss @ local epoch 4: 3.5003868106286973e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.44 seconds!
[tester] 
AGNewsMetric: acc=0.7696052631578948, hinge=4.702827464153892, ce=9.751755941290604
Local test acc @ epoch 179: 0.7696
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 9.139372991739947e-07
Local loss @ local epoch 1: 0.00013786221097689122
Local loss @ local epoch 2: 3.655733962659724e-06
Local loss @ local epoch 3: 2.423852311039809e-05
Local loss @ local epoch 4: 1.0092971024278086e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.48 seconds!
[tester] 
AGNewsMetric: acc=0.5614473684210526, hinge=6.386957258927195, ce=12.303761134900546
Local test acc @ epoch 179: 0.5614
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 5.438913035504811e-07
Local loss @ local epoch 1: 3.5762693073593255e-07
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.6 seconds!
[tester] 
AGNewsMetric: acc=0.6880263157894737, hinge=6.428948034487273, ce=11.895064506530762
Local test acc @ epoch 179: 0.688
Global evaluate on test data...
Evaluate data in 124.01 seconds!
[tester] 
AGNewsMetric: acc=0.8467105263157895, hinge=2.8192203819124324, ce=8.71926102286891
Global test acc @ epoch 179: 0.8467
Global epoch 180...
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 1.0837207575775665e-08
Local loss @ local epoch 1: 7.586043437868284e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.0837207575775665e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.14 seconds!
[tester] 
AGNewsMetric: acc=0.7072368421052632, hinge=6.7949197287308545, ce=11.590871754696495
Local test acc @ epoch 180: 0.7072
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 5.563073955272557e-06
Local loss @ local epoch 1: 0.000791833212133497
Local loss @ local epoch 2: 3.973642748178463e-08
Local loss @ local epoch 3: 1.9868211609264108e-07
Local loss @ local epoch 4: 4.291521236154949e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.21 seconds!
[tester] 
AGNewsMetric: acc=0.5238157894736842, hinge=8.268274686712967, ce=14.757948863380834
Local test acc @ epoch 180: 0.5238
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.19450892508029938
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 6.705521116145974e-08
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.2282325178384781
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.12 seconds!
[tester] 
AGNewsMetric: acc=0.6048684210526316, hinge=8.631982524269505, ce=13.917422129982397
Local test acc @ epoch 180: 0.6049
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.9853431582450867
Local loss @ local epoch 1: 0.07718336582183838
Local loss @ local epoch 2: 1.7484022407643351e-07
Local loss @ local epoch 3: 9.536740464000104e-08
Local loss @ local epoch 4: 6.1988703237148e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.84 seconds!
[tester] 
AGNewsMetric: acc=0.6194736842105263, hinge=9.706262686880011, ce=14.209089542188142
Local test acc @ epoch 180: 0.6195
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 9.53674117454284e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.1920925402364446e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.15 seconds!
[tester] 
AGNewsMetric: acc=0.714078947368421, hinge=6.299259252046284, ce=11.664713869596783
Local test acc @ epoch 180: 0.7141
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 7.586043437868284e-08
Local loss @ local epoch 1: 1.0837202779612198e-07
Local loss @ local epoch 2: 6.502323657286979e-08
Local loss @ local epoch 3: 2.936855253210524e-06
Local loss @ local epoch 4: 7.58604414841102e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.97 seconds!
[tester] 
AGNewsMetric: acc=0.7986842105263158, hinge=3.901243620295274, ce=9.696442602057205
Local test acc @ epoch 180: 0.7987
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 2.775863549686619e-06
Local loss @ local epoch 1: 2.591737029433716e-05
Local loss @ local epoch 2: 1.3794185633742018e-06
Local loss @ local epoch 3: 2.1798184661747655e-06
Local loss @ local epoch 4: 5.466538368636975e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.17 seconds!
[tester] 
AGNewsMetric: acc=0.729078947368421, hinge=4.257646009043643, ce=10.88794547633121
Local test acc @ epoch 180: 0.7291
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 2.9802320611338473e-08
Local loss @ local epoch 1: 1.7881387748275301e-07
Local loss @ local epoch 2: 1.1920926112907182e-07
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.82 seconds!
[tester] 
AGNewsMetric: acc=0.8406578947368422, hinge=3.0002095533672133, ce=9.194528704191509
Local test acc @ epoch 180: 0.8407
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 3.973642037635727e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.5298388689188869e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.71 seconds!
[tester] 
AGNewsMetric: acc=0.8328947368421052, hinge=3.1770546438819482, ce=9.113237635963841
Local test acc @ epoch 180: 0.8329
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 2.3841835172788706e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.9868213740892315e-08
Local loss @ local epoch 4: 9.934106870446158e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.08 seconds!
[tester] 
AGNewsMetric: acc=0.6160526315789474, hinge=9.041386646722492, ce=12.865588216279683
Local test acc @ epoch 180: 0.6161
Global evaluate on test data...
Evaluate data in 124.17 seconds!
[tester] 
AGNewsMetric: acc=0.8472368421052632, hinge=2.9243134364328887, ce=8.970179630078768
Global test acc @ epoch 180: 0.8472
Global epoch 181...
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 3.973642037635727e-08
Local loss @ local epoch 1: 2.9802320611338473e-08
Local loss @ local epoch 2: 9.934106870446158e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.9868211964535476e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.53 seconds!
[tester] 
AGNewsMetric: acc=0.7055263157894737, hinge=6.244051463980424, ce=11.385877279984324
Local test acc @ epoch 181: 0.7055
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 4.33488231976753e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.0837207575775665e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.28 seconds!
[tester] 
AGNewsMetric: acc=0.8275, hinge=3.361612600652795, ce=9.28056144915129
Local test acc @ epoch 181: 0.8275
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 1.8698481653700583e-05
Local loss @ local epoch 1: 7.799549166520592e-06
Local loss @ local epoch 2: 5.091905222798232e-06
Local loss @ local epoch 3: 0.0006018991698510945
Local loss @ local epoch 4: 1.1750445082725491e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.52 seconds!
[tester] 
AGNewsMetric: acc=0.6655263157894736, hinge=5.333571881745991, ce=11.173554573059082
Local test acc @ epoch 181: 0.6655
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 2.6009283260464144e-07
Local loss @ local epoch 1: 4.334882675038898e-08
Local loss @ local epoch 2: 5.418590944827884e-07
Local loss @ local epoch 3: 3.2511618286434896e-08
Local loss @ local epoch 4: 2.709263071665191e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 125.04 seconds!
[tester] 
AGNewsMetric: acc=0.7931578947368421, hinge=3.9915374823620446, ce=9.748137349580464
Local test acc @ epoch 181: 0.7932
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.0794938802719116
Local loss @ local epoch 1: 9.931020031217486e-06
Local loss @ local epoch 2: 4.917371825285954e-07
Local loss @ local epoch 3: 0.5373652577400208
Local loss @ local epoch 4: 0.00022090334095992148
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.58 seconds!
[tester] 
AGNewsMetric: acc=0.7988157894736843, hinge=2.63410610575425, ce=9.457481271844161
Local test acc @ epoch 181: 0.7988
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 2.384185648907078e-08
Local loss @ local epoch 1: 2.384185648907078e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.73 seconds!
[tester] 
AGNewsMetric: acc=0.8310526315789474, hinge=3.167487848306957, ce=9.901982580486097
Local test acc @ epoch 181: 0.8311
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 3.0100218282314017e-06
Local loss @ local epoch 2: 5.960463766996327e-08
Local loss @ local epoch 3: 3.5762769812208717e-07
Local loss @ local epoch 4: 3.874300205097825e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.72 seconds!
[tester] 
AGNewsMetric: acc=0.6544736842105263, hinge=6.64796128624364, ce=11.974497439735813
Local test acc @ epoch 181: 0.6545
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.00017523298447486013
Local loss @ local epoch 1: 1.0688992006180342e-05
Local loss @ local epoch 2: 0.00010950082651106641
Local loss @ local epoch 3: 0.0004996566567569971
Local loss @ local epoch 4: 0.016950028017163277
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.06 seconds!
[tester] 
AGNewsMetric: acc=0.7872368421052631, hinge=2.72557408960242, ce=11.165825181258352
Local test acc @ epoch 181: 0.7872
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.00018190400442108512
Local loss @ local epoch 1: 6.039929303369718e-07
Local loss @ local epoch 2: 0.8597276210784912
Local loss @ local epoch 3: 1.986820450383675e-07
Local loss @ local epoch 4: 3.0355007766047493e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.36 seconds!
[tester] 
AGNewsMetric: acc=0.8293421052631579, hinge=2.7173601848200746, ce=8.866685281050833
Local test acc @ epoch 181: 0.8293
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 9.934106870446158e-09
Local loss @ local epoch 1: 3.973642392907095e-08
Local loss @ local epoch 2: 1.1920925402364446e-07
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.58 seconds!
[tester] 
AGNewsMetric: acc=0.7956578947368421, hinge=4.401735977122658, ce=10.00584245581376
Local test acc @ epoch 181: 0.7957
Global evaluate on test data...
Evaluate data in 124.19 seconds!
[tester] 
AGNewsMetric: acc=0.8523684210526316, hinge=2.7163910137979608, ce=8.789759491368343
Global test acc @ epoch 181: 0.8524
Global epoch 182...
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 9.934106870446158e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.9868211964535476e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.29 seconds!
[tester] 
AGNewsMetric: acc=0.8509210526315789, hinge=2.901766863998614, ce=9.151068085118345
Local test acc @ epoch 182: 0.8509
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 1.39077394578635e-06
Local loss @ local epoch 1: 5.364391199691454e-06
Local loss @ local epoch 2: 1.513929328211816e-05
Local loss @ local epoch 3: 0.0007461109780706465
Local loss @ local epoch 4: 0.00018167241069022566
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.78 seconds!
[tester] 
AGNewsMetric: acc=0.8331578947368421, hinge=1.8639469242095947, ce=9.546716740256862
Local test acc @ epoch 182: 0.8332
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 1.887479044171414e-07
Local loss @ local epoch 1: 9.934106870446158e-09
Local loss @ local epoch 2: 8.940694584680386e-08
Local loss @ local epoch 3: 3.774955530388979e-07
Local loss @ local epoch 4: 1.5894556781859137e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.99 seconds!
[tester] 
AGNewsMetric: acc=0.5817105263157895, hinge=10.76239088861566, ce=14.28927295885588
Local test acc @ epoch 182: 0.5817
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 5.4186031661629386e-08
Local loss @ local epoch 1: 2.167441337519449e-08
Local loss @ local epoch 2: 3.034415669844748e-07
Local loss @ local epoch 3: 2.167441515155133e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.8 seconds!
[tester] 
AGNewsMetric: acc=0.6546052631578947, hinge=7.735603965458117, ce=12.216479399831671
Local test acc @ epoch 182: 0.6546
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.3634530660056043e-06
Local loss @ local epoch 1: 5.215404996761208e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.68 seconds!
[tester] 
AGNewsMetric: acc=0.5064473684210526, hinge=12.03201173180028, ce=16.46985768167596
Local test acc @ epoch 182: 0.5064
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 6.659706741629634e-06
Local loss @ local epoch 1: 7.152554815093026e-08
Local loss @ local epoch 2: 3.9020110307319555e-06
Local loss @ local epoch 3: 1.9868205924922222e-07
Local loss @ local epoch 4: 3.1416620913660154e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.06 seconds!
[tester] 
AGNewsMetric: acc=0.7178947368421053, hinge=6.16357220097592, ce=10.894698233353465
Local test acc @ epoch 182: 0.7179
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 1.1920927533992653e-07
Local loss @ local epoch 1: 2.9802320611338473e-08
Local loss @ local epoch 2: 1.7881387748275301e-07
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 5.066389690000506e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.83 seconds!
[tester] 
AGNewsMetric: acc=0.8394736842105263, hinge=2.7914369170289293, ce=8.945390717355828
Local test acc @ epoch 182: 0.8395
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 7.442006335622864e-06
Local loss @ local epoch 1: 0.00023769632389303297
Local loss @ local epoch 2: 0.3517614006996155
Local loss @ local epoch 3: 0.0009688365389592946
Local loss @ local epoch 4: 0.013989084400236607
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.36 seconds!
[tester] 
AGNewsMetric: acc=0.7480263157894737, hinge=2.2454023526844225, ce=10.579984321594239
Local test acc @ epoch 182: 0.748
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 7.152556236178498e-08
Local loss @ local epoch 1: 2.384185648907078e-08
Local loss @ local epoch 2: 1.1920926823449918e-07
Local loss @ local epoch 3: 7.152556236178498e-08
Local loss @ local epoch 4: 1.4305112472356996e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.11 seconds!
[tester] 
AGNewsMetric: acc=0.7475, hinge=4.185535884405438, ce=10.424605028252852
Local test acc @ epoch 182: 0.7475
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 1.0837206332325877e-07
Local loss @ local epoch 1: 1.5172082612480153e-07
Local loss @ local epoch 2: 8.669762507906853e-08
Local loss @ local epoch 3: 2.4925557795540954e-07
Local loss @ local epoch 4: 2.167441515155133e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.64 seconds!
[tester] 
AGNewsMetric: acc=0.7407894736842106, hinge=5.536766225915206, ce=10.925627431367573
Local test acc @ epoch 182: 0.7408
Global evaluate on test data...
Evaluate data in 124.55 seconds!
[tester] 
AGNewsMetric: acc=0.8476315789473684, hinge=2.8699138140678406, ce=8.79313284422222
Global test acc @ epoch 182: 0.8476
Global epoch 183...
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 1.2715646562355687e-06
Local loss @ local epoch 1: 1.589456957162838e-07
Local loss @ local epoch 2: 5.04650961374864e-06
Local loss @ local epoch 3: 1.1483713024063036e-05
Local loss @ local epoch 4: 0.00021212227875366807
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.37 seconds!
[tester] 
AGNewsMetric: acc=0.7467105263157895, hinge=3.8342623748277362, ce=9.333773398148386
Local test acc @ epoch 183: 0.7467
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 1.3300113096192945e-05
Local loss @ local epoch 1: 4.352675750851631e-05
Local loss @ local epoch 2: 0.0013251813361421227
Local loss @ local epoch 3: 0.00010309389472240582
Local loss @ local epoch 4: 5.483017230289988e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.54 seconds!
[tester] 
AGNewsMetric: acc=0.5377631578947368, hinge=6.2115991497039795, ce=12.879913532859401
Local test acc @ epoch 183: 0.5378
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 9.934106870446158e-09
Local loss @ local epoch 1: 1.0927514182412779e-07
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 9.934106870446158e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.76 seconds!
[tester] 
AGNewsMetric: acc=0.843421052631579, hinge=2.935785972319151, ce=8.839657851771305
Local test acc @ epoch 183: 0.8434
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 9.934106870446158e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 9.934106870446158e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.76 seconds!
[tester] 
AGNewsMetric: acc=0.8361842105263158, hinge=3.25464360287315, ce=9.49903756593403
Local test acc @ epoch 183: 0.8362
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 2.948422206827672e-06
Local loss @ local epoch 1: 8.185657520698442e-07
Local loss @ local epoch 2: 7.947285496356926e-09
Local loss @ local epoch 3: 1.7484013881130522e-07
Local loss @ local epoch 4: 7.947285496356926e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.53 seconds!
[tester] 
AGNewsMetric: acc=0.5502631578947368, hinge=12.039449939727783, ce=16.019870830335115
Local test acc @ epoch 183: 0.5503
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 2.384185648907078e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.37 seconds!
[tester] 
AGNewsMetric: acc=0.8372368421052632, hinge=3.059588144201981, ce=9.248660780254163
Local test acc @ epoch 183: 0.8372
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.9802320611338473e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.41 seconds!
[tester] 
AGNewsMetric: acc=0.8389473684210527, hinge=3.099447641498164, ce=9.321631212736431
Local test acc @ epoch 183: 0.8389
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 2.8176702926430153e-07
Local loss @ local epoch 1: 4.334883030310266e-08
Local loss @ local epoch 2: 3.034415669844748e-07
Local loss @ local epoch 3: 1.0435851436341181e-05
Local loss @ local epoch 4: 3.901390925875603e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.62 seconds!
[tester] 
AGNewsMetric: acc=0.8573684210526316, hinge=2.5110915123788935, ce=8.706136374222606
Local test acc @ epoch 183: 0.8574
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.586042727325548e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.57 seconds!
[tester] 
AGNewsMetric: acc=0.8501315789473685, hinge=2.8173273992538452, ce=8.969361981843647
Local test acc @ epoch 183: 0.8501
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4132680917100515e-05
Local loss @ local epoch 1: 1.7881379221762472e-07
Local loss @ local epoch 2: 4.917371256851766e-07
Local loss @ local epoch 3: 1.9371501025489124e-07
Local loss @ local epoch 4: 6.161356395750772e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.68 seconds!
[tester] 
AGNewsMetric: acc=0.6793421052631579, hinge=6.2729160128141705, ce=11.596068420410155
Local test acc @ epoch 183: 0.6793
Global evaluate on test data...
Evaluate data in 123.94 seconds!
[tester] 
AGNewsMetric: acc=0.8465789473684211, hinge=2.922697878134878, ce=9.066441654406097
Global test acc @ epoch 183: 0.8466
Global epoch 184...
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 6.001903602737002e-05
Local loss @ local epoch 1: 2.167441515155133e-08
Local loss @ local epoch 2: 3.955495230911765e-06
Local loss @ local epoch 3: 3.2511621839148575e-08
Local loss @ local epoch 4: 1.517208971790751e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.13 seconds!
[tester] 
AGNewsMetric: acc=0.3427631578947368, hinge=17.043581444589716, ce=18.604168657001697
Local test acc @ epoch 184: 0.3428
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.10579057782888412
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 4.7282908781198785e-05
Local loss @ local epoch 3: 0.38635310530662537
Local loss @ local epoch 4: 0.12470230460166931
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.36 seconds!
[tester] 
AGNewsMetric: acc=0.6046052631578948, hinge=9.073565790276778, ce=13.485938550045615
Local test acc @ epoch 184: 0.6046
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 2.31089234148385e-05
Local loss @ local epoch 1: 7.066932448651642e-05
Local loss @ local epoch 2: 0.39539390802383423
Local loss @ local epoch 3: 0.07532081753015518
Local loss @ local epoch 4: 0.28545913100242615
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.68 seconds!
[tester] 
AGNewsMetric: acc=0.7867105263157895, hinge=1.8293389887558786, ce=5.278520892293829
Local test acc @ epoch 184: 0.7867
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.415609887089886e-07
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 2.2351740014414645e-08
Local loss @ local epoch 3: 5.9604616353681195e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.57 seconds!
[tester] 
AGNewsMetric: acc=0.7214473684210526, hinge=6.287643438640393, ce=11.730378865693744
Local test acc @ epoch 184: 0.7214
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.34563758969306946
Local loss @ local epoch 1: 2.167441337519449e-08
Local loss @ local epoch 2: 0.0009013250819407403
Local loss @ local epoch 3: 0.947364091873169
Local loss @ local epoch 4: 2.7936264814343303e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.92 seconds!
[tester] 
AGNewsMetric: acc=0.585, hinge=11.300329378027666, ce=14.496014723526804
Local test acc @ epoch 184: 0.585
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 6.755157755833352e-06
Local loss @ local epoch 1: 2.1457642560562817e-06
Local loss @ local epoch 2: 3.4570582556625595e-06
Local loss @ local epoch 3: 2.185471930715721e-05
Local loss @ local epoch 4: 0.0014820108190178871
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.73 seconds!
[tester] 
AGNewsMetric: acc=0.6263157894736842, hinge=5.686748800779644, ce=11.648381841559159
Local test acc @ epoch 184: 0.6263
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.6924676895141602
Local loss @ local epoch 1: 2.9802320611338473e-08
Local loss @ local epoch 2: 3.973642392907095e-08
Local loss @ local epoch 3: 3.3775924634937837e-07
Local loss @ local epoch 4: 1.8576669162939652e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.85 seconds!
[tester] 
AGNewsMetric: acc=0.35789473684210527, hinge=16.421567358719674, ce=18.469948401200146
Local test acc @ epoch 184: 0.3579
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 2.503352334315423e-06
Local loss @ local epoch 1: 5.563098071093009e-08
Local loss @ local epoch 2: 4.768370942542788e-08
Local loss @ local epoch 3: 0.0144910654053092
Local loss @ local epoch 4: 5.801501856694813e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.93 seconds!
[tester] 
AGNewsMetric: acc=0.7611842105263158, hinge=4.912580638935691, ce=10.628744350232576
Local test acc @ epoch 184: 0.7612
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.9802320611338473e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.0 seconds!
[tester] 
AGNewsMetric: acc=0.8403947368421053, hinge=2.8021106130198428, ce=9.350174486260665
Local test acc @ epoch 184: 0.8404
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 2.384185648907078e-08
Local loss @ local epoch 1: 7.152556236178498e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.77 seconds!
[tester] 
AGNewsMetric: acc=0.8397368421052631, hinge=3.353016684808229, ce=9.309505663420024
Local test acc @ epoch 184: 0.8397
Global evaluate on test data...
Evaluate data in 124.19 seconds!
[tester] 
AGNewsMetric: acc=0.7993421052631579, hinge=4.319561328762456, ce=9.7580363323814
Global test acc @ epoch 184: 0.7993
Global epoch 185...
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 9.753482288488158e-08
Local loss @ local epoch 1: 2.167441515155133e-08
Local loss @ local epoch 2: 9.753482288488158e-08
Local loss @ local epoch 3: 2.8176722821626754e-07
Local loss @ local epoch 4: 6.285568474595493e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.63 seconds!
[tester] 
AGNewsMetric: acc=0.8263157894736842, hinge=3.255139642891131, ce=9.60123791945608
Local test acc @ epoch 185: 0.8263
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 1.23159921169281
Local loss @ local epoch 1: 5.245194643066498e-07
Local loss @ local epoch 2: 2.3841845120387006e-07
Local loss @ local epoch 3: 7.470427476619079e-07
Local loss @ local epoch 4: 0.0017732938285917044
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.94 seconds!
[tester] 
AGNewsMetric: acc=0.7096052631578947, hinge=3.935406052689803, ce=10.310552593030428
Local test acc @ epoch 185: 0.7096
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 7.013989670667797e-05
Local loss @ local epoch 1: 8.800513751339167e-05
Local loss @ local epoch 2: 0.00011837534111691639
Local loss @ local epoch 3: 0.00035213693627156317
Local loss @ local epoch 4: 0.004099561367183924
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.27 seconds!
[tester] 
AGNewsMetric: acc=0.5980263157894737, hinge=4.577214212919537, ce=9.42205080333509
Local test acc @ epoch 185: 0.598
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 7.748592452117009e-07
Local loss @ local epoch 1: 5.9604641222676946e-08
Local loss @ local epoch 2: 8.940695295223122e-08
Local loss @ local epoch 3: 5.364414619180025e-07
Local loss @ local epoch 4: 5.9604641222676946e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.66 seconds!
[tester] 
AGNewsMetric: acc=0.7814473684210527, hinge=4.106452804615623, ce=9.859757481625206
Local test acc @ epoch 185: 0.7814
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 7.152556946721234e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.7166064480989007e-06
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.06 seconds!
[tester] 
AGNewsMetric: acc=0.8361842105263158, hinge=2.8472282572796472, ce=8.97293933065314
Local test acc @ epoch 185: 0.8362
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 9.934106870446158e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 4.967052191773291e-08
Local loss @ local epoch 4: 9.934106870446158e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.47 seconds!
[tester] 
AGNewsMetric: acc=0.8369736842105263, hinge=3.0446942148710554, ce=9.144396968640779
Local test acc @ epoch 185: 0.837
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.004945136606693268
Local loss @ local epoch 1: 3.203747667157586e-07
Local loss @ local epoch 2: 3.772021955228411e-05
Local loss @ local epoch 3: 5.654873348248657e-06
Local loss @ local epoch 4: 9.685716122476151e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.39 seconds!
[tester] 
AGNewsMetric: acc=0.6814473684210526, hinge=4.900139327551189, ce=10.785906454387463
Local test acc @ epoch 185: 0.6814
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0001727015624055639
Local loss @ local epoch 1: 5.404130206443369e-06
Local loss @ local epoch 2: 6.794904038542882e-06
Local loss @ local epoch 3: 0.0001516872871434316
Local loss @ local epoch 4: 4.899359555565752e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.86 seconds!
[tester] 
AGNewsMetric: acc=0.6185526315789474, hinge=4.667075949719077, ce=11.337284965515137
Local test acc @ epoch 185: 0.6186
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 9.934106870446158e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.9868211964535476e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.52 seconds!
[tester] 
AGNewsMetric: acc=0.8122368421052631, hinge=3.8220114817117388, ce=9.914908055757222
Local test acc @ epoch 185: 0.8122
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 3.6846438433713047e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.167441337519449e-08
Local loss @ local epoch 3: 2.167441337519449e-08
Local loss @ local epoch 4: 3.2511621839148575e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.5 seconds!
[tester] 
AGNewsMetric: acc=0.7898684210526316, hinge=3.5013687221627485, ce=9.328977835805793
Local test acc @ epoch 185: 0.7899
Global evaluate on test data...
Evaluate data in 123.52 seconds!
[tester] 
AGNewsMetric: acc=0.8378947368421052, hinge=2.9544259681199727, ce=9.154749486822832
Global test acc @ epoch 185: 0.8379
Global epoch 186...
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.1622878446360119e-06
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 6.645829671469983e-06
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.4 seconds!
[tester] 
AGNewsMetric: acc=0.8205263157894737, hinge=2.9233154269268637, ce=8.744625392713045
Local test acc @ epoch 186: 0.8205
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.9830155372619629
Local loss @ local epoch 1: 1.4901152667334827e-07
Local loss @ local epoch 2: 1.8874796126056026e-07
Local loss @ local epoch 3: 1.9868207346007694e-07
Local loss @ local epoch 4: 2.4295348339364864e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.59 seconds!
[tester] 
AGNewsMetric: acc=0.59, hinge=9.212552934194866, ce=13.791323597556666
Local test acc @ epoch 186: 0.59
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 6.03988928560284e-06
Local loss @ local epoch 1: 6.750872853444889e-05
Local loss @ local epoch 2: 5.165733796275163e-07
Local loss @ local epoch 3: 1.4702460475746193e-06
Local loss @ local epoch 4: 7.947281233100512e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.65 seconds!
[tester] 
AGNewsMetric: acc=0.3601315789473684, hinge=13.893766507600484, ce=18.50945362291838
Local test acc @ epoch 186: 0.3601
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 2.2504973458126187e-05
Local loss @ local epoch 1: 2.384185648907078e-08
Local loss @ local epoch 2: 1.5099834627108066e-07
Local loss @ local epoch 3: 3.411040233913809e-05
Local loss @ local epoch 4: 4.990709840058116e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.7 seconds!
[tester] 
AGNewsMetric: acc=0.6230263157894737, hinge=8.015084371566772, ce=13.497691881280197
Local test acc @ epoch 186: 0.623
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 1.221021193487104e-05
Local loss @ local epoch 1: 2.261396912217606e-05
Local loss @ local epoch 2: 2.7247749585512793e-06
Local loss @ local epoch 3: 1.1665294550766703e-05
Local loss @ local epoch 4: 1.0047413525171578e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.62 seconds!
[tester] 
AGNewsMetric: acc=0.5576315789473684, hinge=8.546928421823601, ce=15.077751976816277
Local test acc @ epoch 186: 0.5576
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.003097779117524624
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450577754752885e-08
Local loss @ local epoch 3: 3.725289943190546e-08
Local loss @ local epoch 4: 0.03479182720184326
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.41 seconds!
[tester] 
AGNewsMetric: acc=0.5876315789473684, hinge=9.369863310362163, ce=13.847415705229107
Local test acc @ epoch 186: 0.5876
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 1.2947251796722412
Local loss @ local epoch 1: 2.167441515155133e-08
Local loss @ local epoch 2: 1.246271835952939e-06
Local loss @ local epoch 3: 6.4577761804685e-05
Local loss @ local epoch 4: 4.5552496885648e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.88 seconds!
[tester] 
AGNewsMetric: acc=0.5605263157894737, hinge=10.469712152983012, ce=14.063082142880088
Local test acc @ epoch 186: 0.5605
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.6760571002960205
Local loss @ local epoch 1: 2.167441337519449e-08
Local loss @ local epoch 2: 2.167441515155133e-08
Local loss @ local epoch 3: 6.827421543675882e-07
Local loss @ local epoch 4: 8.669763218449589e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.52 seconds!
[tester] 
AGNewsMetric: acc=0.5003947368421052, hinge=12.464894977368807, ce=15.484224905716745
Local test acc @ epoch 186: 0.5004
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.5451568961143494
Local loss @ local epoch 1: 5.960463056453591e-08
Local loss @ local epoch 2: 1.9868211964535476e-08
Local loss @ local epoch 3: 3.894081146427197e-06
Local loss @ local epoch 4: 4.371003399228357e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.27 seconds!
[tester] 
AGNewsMetric: acc=0.38842105263157894, hinge=14.318039277729236, ce=17.94899199636359
Local test acc @ epoch 186: 0.3884
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 4.768370942542788e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.61 seconds!
[tester] 
AGNewsMetric: acc=0.8288157894736842, hinge=3.101523878699855, ce=8.82989374461927
Local test acc @ epoch 186: 0.8288
Global evaluate on test data...
Evaluate data in 123.84 seconds!
[tester] 
AGNewsMetric: acc=0.8257894736842105, hinge=3.303321055864033, ce=9.198176789534719
Global test acc @ epoch 186: 0.8258
Global epoch 187...
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 8.940696005765858e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 8.940695295223122e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.93 seconds!
[tester] 
AGNewsMetric: acc=0.7692105263157895, hinge=4.313443777435705, ce=10.778555789746736
Local test acc @ epoch 187: 0.7692
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 3.973642037635727e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 5.960463056453591e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.44 seconds!
[tester] 
AGNewsMetric: acc=0.8427631578947369, hinge=2.8309273439959477, ce=9.157503710295025
Local test acc @ epoch 187: 0.8428
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0008266427903436124
Local loss @ local epoch 1: 1.1175867342672063e-07
Local loss @ local epoch 2: 4.470347647611561e-08
Local loss @ local epoch 3: 6.70552182668871e-08
Local loss @ local epoch 4: 4.470348002882929e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.16 seconds!
[tester] 
AGNewsMetric: acc=0.560921052631579, hinge=10.540478923195288, ce=15.296997307225277
Local test acc @ epoch 187: 0.5609
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 5.8014934438688215e-06
Local loss @ local epoch 1: 2.503390760466573e-06
Local loss @ local epoch 2: 1.0649287105479743e-05
Local loss @ local epoch 3: 0.0047942777164280415
Local loss @ local epoch 4: 0.004001513589173555
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.64 seconds!
[tester] 
AGNewsMetric: acc=0.7547368421052632, hinge=2.124655619922437, ce=8.286966032730906
Local test acc @ epoch 187: 0.7547
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 8.310503289976623e-06
Local loss @ local epoch 1: 2.7077483082393883e-06
Local loss @ local epoch 2: 0.0001591145555721596
Local loss @ local epoch 3: 5.283876816974953e-05
Local loss @ local epoch 4: 3.2491192541783676e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.18 seconds!
[tester] 
AGNewsMetric: acc=0.6467105263157895, hinge=6.095967871013441, ce=12.237198181152344
Local test acc @ epoch 187: 0.6467
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 1.9868213740892315e-08
Local loss @ local epoch 1: 9.934106870446158e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.91 seconds!
[tester] 
AGNewsMetric: acc=0.7944736842105263, hinge=4.320866415500641, ce=10.332066740738718
Local test acc @ epoch 187: 0.7945
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 5.4186035214343065e-08
Local loss @ local epoch 1: 1.0837207575775665e-08
Local loss @ local epoch 2: 1.5172084033565625e-07
Local loss @ local epoch 3: 4.334882675038898e-08
Local loss @ local epoch 4: 7.586044858953755e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.43 seconds!
[tester] 
AGNewsMetric: acc=0.824078947368421, hinge=3.477326354854985, ce=9.54925641511616
Local test acc @ epoch 187: 0.8241
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.384185648907078e-08
Local loss @ local epoch 2: 2.384185648907078e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.48 seconds!
[tester] 
AGNewsMetric: acc=0.7268421052631578, hinge=5.281503295898437, ce=11.609257284465588
Local test acc @ epoch 187: 0.7268
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.00848288182169199
Local loss @ local epoch 1: 1.2636122619369416e-06
Local loss @ local epoch 2: 1.025196979753673e-06
Local loss @ local epoch 3: 4.2915297626677784e-07
Local loss @ local epoch 4: 0.5465949773788452
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.27 seconds!
[tester] 
AGNewsMetric: acc=0.6819736842105263, hinge=7.667032788427252, ce=12.763129216244346
Local test acc @ epoch 187: 0.682
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 2.167441337519449e-08
Local loss @ local epoch 1: 1.0837207575775665e-08
Local loss @ local epoch 2: 2.167441337519449e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 3.9013877994875656e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.64 seconds!
[tester] 
AGNewsMetric: acc=0.8186842105263158, hinge=3.643214562943107, ce=9.853249156349584
Local test acc @ epoch 187: 0.8187
Global evaluate on test data...
Evaluate data in 123.96 seconds!
[tester] 
AGNewsMetric: acc=0.8389473684210527, hinge=3.0111407475722465, ce=9.389602966308594
Global test acc @ epoch 187: 0.8389
Global epoch 188...
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.004536856431514025
Local loss @ local epoch 1: 3.2511621839148575e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.0837207575775665e-08
Local loss @ local epoch 4: 4.334882675038898e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.52 seconds!
[tester] 
AGNewsMetric: acc=0.5211842105263158, hinge=11.20595582560489, ce=15.58924353950902
Local test acc @ epoch 188: 0.5212
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 1.351038463326404e-07
Local loss @ local epoch 1: 5.5630994921784804e-08
Local loss @ local epoch 2: 3.973642748178463e-08
Local loss @ local epoch 3: 1.033146688200759e-07
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.01 seconds!
[tester] 
AGNewsMetric: acc=0.7117105263157895, hinge=6.568961625350149, ce=12.677810413962916
Local test acc @ epoch 188: 0.7117
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 1.8874784757372254e-07
Local loss @ local epoch 1: 1.4901151246249356e-07
Local loss @ local epoch 2: 1.9868211964535476e-08
Local loss @ local epoch 3: 4.726300903712399e-05
Local loss @ local epoch 4: 3.049715587621904e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.5 seconds!
[tester] 
AGNewsMetric: acc=0.7878947368421053, hinge=4.537668210330763, ce=9.90866983514083
Local test acc @ epoch 188: 0.7879
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.152556236178498e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.74 seconds!
[tester] 
AGNewsMetric: acc=0.8360526315789474, hinge=2.9025947907096463, ce=9.499486355028655
Local test acc @ epoch 188: 0.8361
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 3.707230280269869e-05
Local loss @ local epoch 1: 0.00015545805217698216
Local loss @ local epoch 2: 0.00012959723244421184
Local loss @ local epoch 3: 0.00010739257413661107
Local loss @ local epoch 4: 2.69408574240515e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.27 seconds!
[tester] 
AGNewsMetric: acc=0.42223684210526313, hinge=9.017233997144197, ce=14.760974145186575
Local test acc @ epoch 188: 0.4222
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 5.9604641222676946e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.9802320611338473e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.11 seconds!
[tester] 
AGNewsMetric: acc=0.8403947368421053, hinge=2.8055346556713707, ce=9.218082082648026
Local test acc @ epoch 188: 0.8404
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.04361216351389885
Local loss @ local epoch 1: 9.934106870446158e-09
Local loss @ local epoch 2: 1.9868211964535476e-08
Local loss @ local epoch 3: 7.241663752211025e-06
Local loss @ local epoch 4: 7.611023465869948e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.37 seconds!
[tester] 
AGNewsMetric: acc=0.6230263157894737, hinge=7.398777994858591, ce=12.997515204580207
Local test acc @ epoch 188: 0.623
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 4.989720764569938e-06
Local loss @ local epoch 1: 6.8289455157355405e-06
Local loss @ local epoch 2: 1.256399393081665
Local loss @ local epoch 3: 0.004507511388510466
Local loss @ local epoch 4: 0.0038522209506481886
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.28 seconds!
[tester] 
AGNewsMetric: acc=0.7432894736842105, hinge=2.7174399438657257, ce=9.248847355089689
Local test acc @ epoch 188: 0.7433
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.7657763957977295
Local loss @ local epoch 1: 1.560549549139978e-06
Local loss @ local epoch 2: 4.9741506700229365e-06
Local loss @ local epoch 3: 0.00018662492220755666
Local loss @ local epoch 4: 0.009133630432188511
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.73 seconds!
[tester] 
AGNewsMetric: acc=0.5517105263157894, hinge=9.747549429441753, ce=14.45870342053865
Local test acc @ epoch 188: 0.5517
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.8146165609359741
Local loss @ local epoch 1: 3.725289943190546e-08
Local loss @ local epoch 2: 1.177186732093105e-06
Local loss @ local epoch 3: 2.831219205745583e-07
Local loss @ local epoch 4: 0.9429740905761719
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.55 seconds!
[tester] 
AGNewsMetric: acc=0.7051315789473684, hinge=4.726793556213379, ce=11.874334174708316
Local test acc @ epoch 188: 0.7051
Global evaluate on test data...
Evaluate data in 124.22 seconds!
[tester] 
AGNewsMetric: acc=0.8422368421052632, hinge=2.9409966391011286, ce=9.324156182941637
Global test acc @ epoch 188: 0.8422
Global epoch 189...
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.6822075938071066e-07
Local loss @ local epoch 2: 2.1861793994903564
Local loss @ local epoch 3: 1.072882469088654e-06
Local loss @ local epoch 4: 5.167462950339541e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.62 seconds!
[tester] 
AGNewsMetric: acc=0.7397368421052631, hinge=2.583534763235795, ce=6.747114691483347
Local test acc @ epoch 189: 0.7397
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 2.781549426345009e-07
Local loss @ local epoch 1: 3.9736414692015387e-07
Local loss @ local epoch 2: 3.973640616550256e-07
Local loss @ local epoch 3: 6.357824418046221e-07
Local loss @ local epoch 4: 1.1126185199827887e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.1 seconds!
[tester] 
AGNewsMetric: acc=0.4856578947368421, hinge=11.174268854040848, ce=17.031513049477024
Local test acc @ epoch 189: 0.4857
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.04876508563756943
Local loss @ local epoch 1: 1.2591381164384075e-06
Local loss @ local epoch 2: 5.885950713491184e-07
Local loss @ local epoch 3: 1.6018657333916053e-06
Local loss @ local epoch 4: 2.659839992702473e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.61 seconds!
[tester] 
AGNewsMetric: acc=0.5961842105263158, hinge=9.248941689541466, ce=13.077013726485403
Local test acc @ epoch 189: 0.5962
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 2.167441515155133e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 6.502323657286979e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.49 seconds!
[tester] 
AGNewsMetric: acc=0.7977631578947368, hinge=4.0738601634376925, ce=9.801197899266294
Local test acc @ epoch 189: 0.7978
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 2.7309654342388967e-06
Local loss @ local epoch 1: 7.586043437868284e-08
Local loss @ local epoch 2: 9.850750757323112e-06
Local loss @ local epoch 3: 1.6255806656317873e-07
Local loss @ local epoch 4: 3.4679035820772697e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.69 seconds!
[tester] 
AGNewsMetric: acc=0.7728947368421053, hinge=5.0303611346295005, ce=10.526881338420667
Local test acc @ epoch 189: 0.7729
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.384185648907078e-08
Local loss @ local epoch 2: 2.384185648907078e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 4.2915326048387215e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.6 seconds!
[tester] 
AGNewsMetric: acc=0.37315789473684213, hinge=13.844312515258789, ce=17.73724131533974
Local test acc @ epoch 189: 0.3732
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 2.2563941456610337e-05
Local loss @ local epoch 1: 4.115905539947562e-05
Local loss @ local epoch 2: 0.08506159484386444
Local loss @ local epoch 3: 3.4262367989867926e-05
Local loss @ local epoch 4: 0.00010642665438354015
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.88 seconds!
[tester] 
AGNewsMetric: acc=0.7181578947368421, hinge=3.2429149948923213, ce=10.33030567369963
Local test acc @ epoch 189: 0.7182
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 9.934106870446158e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 3.973642392907095e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.26 seconds!
[tester] 
AGNewsMetric: acc=0.8444736842105263, hinge=2.9562472110045586, ce=9.578011018853438
Local test acc @ epoch 189: 0.8445
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 6.953873565862523e-08
Local loss @ local epoch 1: 9.934106870446158e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.2615361811185721e-05
Local loss @ local epoch 4: 2.9802317058624794e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.01 seconds!
[tester] 
AGNewsMetric: acc=0.8056578947368421, hinge=3.778964336294877, ce=9.75083613144724
Local test acc @ epoch 189: 0.8057
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.5578481554985046
Local loss @ local epoch 1: 1.6689294568550395e-07
Local loss @ local epoch 2: 5.086253054287226e-07
Local loss @ local epoch 3: 3.766927648030105e-06
Local loss @ local epoch 4: 0.06083998829126358
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.95 seconds!
[tester] 
AGNewsMetric: acc=0.5669736842105263, hinge=8.925084380601582, ce=14.644140492489463
Local test acc @ epoch 189: 0.567
Global evaluate on test data...
Evaluate data in 124.04 seconds!
[tester] 
AGNewsMetric: acc=0.8515789473684211, hinge=2.755190148228093, ce=9.217468757629394
Global test acc @ epoch 189: 0.8516
Global epoch 190...
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 1.9073476664743794e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 4.768370942542788e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.35 seconds!
[tester] 
AGNewsMetric: acc=0.8306578947368422, hinge=2.837379951226084, ce=9.596921402780634
Local test acc @ epoch 190: 0.8307
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 2.6009274733951315e-07
Local loss @ local epoch 1: 5.418602455620203e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.0837207575775665e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.83 seconds!
[tester] 
AGNewsMetric: acc=0.48828947368421055, hinge=12.69385632063213, ce=15.776354048879522
Local test acc @ epoch 190: 0.4883
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 1.4901151246249356e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 4.967052902316027e-08
Local loss @ local epoch 3: 4.967053257587395e-08
Local loss @ local epoch 4: 6.953873565862523e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.28 seconds!
[tester] 
AGNewsMetric: acc=0.5685526315789474, hinge=10.566338817696822, ce=14.938004720587479
Local test acc @ epoch 190: 0.5686
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 1.0243307769997045e-05
Local loss @ local epoch 1: 7.947285496356926e-09
Local loss @ local epoch 2: 4.768370942542788e-08
Local loss @ local epoch 3: 3.1789141985427705e-08
Local loss @ local epoch 4: 1.5894569216357013e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.0 seconds!
[tester] 
AGNewsMetric: acc=0.6376315789473684, hinge=7.834429726851614, ce=13.382690301192435
Local test acc @ epoch 190: 0.6376
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 1.1920920996999484e-06
Local loss @ local epoch 1: 1.8914297470473684e-05
Local loss @ local epoch 2: 3.5365317216928815e-06
Local loss @ local epoch 3: 5.960445832897676e-06
Local loss @ local epoch 4: 1.5576470104861073e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.68 seconds!
[tester] 
AGNewsMetric: acc=0.6376315789473684, hinge=7.898273900684558, ce=12.415775566101074
Local test acc @ epoch 190: 0.6376
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 5.5849552154541016e-05
Local loss @ local epoch 1: 9.196137398248538e-07
Local loss @ local epoch 2: 4.4788093873648904e-06
Local loss @ local epoch 3: 1.602470911166165e-05
Local loss @ local epoch 4: 4.240413090883521e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.69 seconds!
[tester] 
AGNewsMetric: acc=0.6009210526315789, hinge=7.119448594545063, ce=13.698683377316124
Local test acc @ epoch 190: 0.6009
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 9.934103673003847e-08
Local loss @ local epoch 1: 1.9868211964535476e-08
Local loss @ local epoch 2: 2.9802320611338473e-08
Local loss @ local epoch 3: 8.940693163594915e-08
Local loss @ local epoch 4: 9.934106870446158e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.39 seconds!
[tester] 
AGNewsMetric: acc=0.8378947368421052, hinge=2.945522265936199, ce=9.571070022583008
Local test acc @ epoch 190: 0.8379
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 9.611217137717176e-07
Local loss @ local epoch 1: 4.3213327671765e-07
Local loss @ local epoch 2: 8.940690321423972e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.9802315282267955e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.92 seconds!
[tester] 
AGNewsMetric: acc=0.6077631578947369, hinge=8.596044398859927, ce=13.777980324594598
Local test acc @ epoch 190: 0.6078
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 2.9802320611338473e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 5.960463766996327e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.16 seconds!
[tester] 
AGNewsMetric: acc=0.8432894736842105, hinge=2.6711951940938046, ce=8.934079551696778
Local test acc @ epoch 190: 0.8433
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 5.526969744096277e-07
Local loss @ local epoch 1: 3.684645832890965e-07
Local loss @ local epoch 2: 4.334882675038898e-08
Local loss @ local epoch 3: 6.686387223453494e-06
Local loss @ local epoch 4: 3.1427859426003124e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.91 seconds!
[tester] 
AGNewsMetric: acc=0.8186842105263158, hinge=3.2903904171993856, ce=9.26576784234298
Local test acc @ epoch 190: 0.8187
Global evaluate on test data...
Evaluate data in 124.82 seconds!
[tester] 
AGNewsMetric: acc=0.8530263157894736, hinge=2.714003360020487, ce=8.736371959887054
Global test acc @ epoch 190: 0.853
Global epoch 191...
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.0166971106082201
Local loss @ local epoch 1: 9.457214105168532e-07
Local loss @ local epoch 2: 4.2915300468848727e-07
Local loss @ local epoch 3: 1.1080050468444824
Local loss @ local epoch 4: 1.961984162335284e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.98 seconds!
[tester] 
AGNewsMetric: acc=0.7572368421052632, hinge=4.499796352637442, ce=10.334117744847347
Local test acc @ epoch 191: 0.7572
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 3.973642392907095e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.4 seconds!
[tester] 
AGNewsMetric: acc=0.8338157894736842, hinge=3.2826853514345067, ce=9.274115389773721
Local test acc @ epoch 191: 0.8338
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.5 seconds!
[tester] 
AGNewsMetric: acc=0.8363157894736842, hinge=3.1716723292752316, ce=9.590940903111507
Local test acc @ epoch 191: 0.8363
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 5.358642738428898e-05
Local loss @ local epoch 1: 1.0217931958322879e-06
Local loss @ local epoch 2: 8.685241823513934e-07
Local loss @ local epoch 3: 1.6859573861438548e-06
Local loss @ local epoch 4: 6.894682155689225e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.87 seconds!
[tester] 
AGNewsMetric: acc=0.6522368421052631, hinge=5.950787902129324, ce=11.271801922446803
Local test acc @ epoch 191: 0.6522
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 4.432313289726153e-06
Local loss @ local epoch 1: 4.334882675038898e-08
Local loss @ local epoch 2: 4.811605776922079e-06
Local loss @ local epoch 3: 0.36182233691215515
Local loss @ local epoch 4: 2.9260448286549945e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.0 seconds!
[tester] 
AGNewsMetric: acc=0.7676315789473684, hinge=5.305634698114897, ce=10.923137578462299
Local test acc @ epoch 191: 0.7676
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 4.334882675038898e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.57 seconds!
[tester] 
AGNewsMetric: acc=0.8196052631578947, hinge=3.88104548755445, ce=9.306346094231856
Local test acc @ epoch 191: 0.8196
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 4.0711827750783414e-05
Local loss @ local epoch 1: 3.9487952108174795e-07
Local loss @ local epoch 2: 2.0116557664096035e-07
Local loss @ local epoch 3: 5.10344125359552e-06
Local loss @ local epoch 4: 1.981838295250782e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.66 seconds!
[tester] 
AGNewsMetric: acc=0.6164473684210526, hinge=9.20697575719733, ce=13.985591137534694
Local test acc @ epoch 191: 0.6164
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 4.967052902316027e-08
Local loss @ local epoch 1: 1.9868211964535476e-08
Local loss @ local epoch 2: 9.934106870446158e-09
Local loss @ local epoch 3: 9.934106870446158e-09
Local loss @ local epoch 4: 9.934106870446158e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.21 seconds!
[tester] 
AGNewsMetric: acc=0.8101315789473684, hinge=3.996158728599548, ce=9.622261163811935
Local test acc @ epoch 191: 0.8101
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.9802320611338473e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.75 seconds!
[tester] 
AGNewsMetric: acc=0.8339473684210527, hinge=3.25655814082999, ce=9.017698157461066
Local test acc @ epoch 191: 0.8339
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 4.331255240686005e-06
Local loss @ local epoch 1: 3.973642748178463e-08
Local loss @ local epoch 2: 3.5762778338721546e-07
Local loss @ local epoch 3: 3.973642748178463e-08
Local loss @ local epoch 4: 4.1325733945996035e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.5 seconds!
[tester] 
AGNewsMetric: acc=0.435, hinge=9.742248533148514, ce=15.193447335895739
Local test acc @ epoch 191: 0.435
Global evaluate on test data...
Evaluate data in 123.21 seconds!
[tester] 
AGNewsMetric: acc=0.8528947368421053, hinge=2.810536305527938, ce=8.881048252708034
Global test acc @ epoch 191: 0.8529
Global epoch 192...
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.6822075938071066e-07
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.26 seconds!
[tester] 
AGNewsMetric: acc=0.8221052631578948, hinge=3.393233457113567, ce=9.848144691868832
Local test acc @ epoch 192: 0.8221
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 1.9868213740892315e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 9.934106870446158e-09
Local loss @ local epoch 4: 2.9802320611338473e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.28 seconds!
[tester] 
AGNewsMetric: acc=0.8472368421052632, hinge=3.0011510876605385, ce=8.870785480298494
Local test acc @ epoch 192: 0.8472
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 1.5497181493628887e-06
Local loss @ local epoch 1: 1.5099823258424294e-06
Local loss @ local epoch 2: 1.1920928244535389e-07
Local loss @ local epoch 3: 4.21204413214582e-06
Local loss @ local epoch 4: 3.7469628296094015e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.34 seconds!
[tester] 
AGNewsMetric: acc=0.6217105263157895, hinge=8.418032478533293, ce=13.878983696385434
Local test acc @ epoch 192: 0.6217
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 3.2511621839148575e-08
Local loss @ local epoch 1: 2.167441337519449e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.4088358568642434e-07
Local loss @ local epoch 4: 5.418602455620203e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.61 seconds!
[tester] 
AGNewsMetric: acc=0.7898684210526316, hinge=4.582789483195857, ce=10.041118039582905
Local test acc @ epoch 192: 0.7899
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 1.2516891274572117e-06
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.788137637959153e-07
Local loss @ local epoch 3: 1.6887970843981748e-07
Local loss @ local epoch 4: 1.9073348767051357e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.16 seconds!
[tester] 
AGNewsMetric: acc=0.4817105263157895, hinge=13.151674965306333, ce=16.89051379153603
Local test acc @ epoch 192: 0.4817
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 4.734285084850853e-06
Local loss @ local epoch 1: 6.079596914787544e-06
Local loss @ local epoch 2: 0.0003964848874602467
Local loss @ local epoch 3: 1.413477434653032e-06
Local loss @ local epoch 4: 1.6211703041335568e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.4 seconds!
[tester] 
AGNewsMetric: acc=0.7288157894736842, hinge=4.596299359171014, ce=11.234224042390522
Local test acc @ epoch 192: 0.7288
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 5.0940661822096445e-06
Local loss @ local epoch 1: 9.536741885085576e-08
Local loss @ local epoch 2: 0.0003423549351282418
Local loss @ local epoch 3: 4.132576805204735e-07
Local loss @ local epoch 4: 7.629366791661596e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.47 seconds!
[tester] 
AGNewsMetric: acc=0.8027631578947368, hinge=3.561946744667856, ce=9.447661379763954
Local test acc @ epoch 192: 0.8028
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 2.384185648907078e-08
Local loss @ local epoch 1: 7.152556236178498e-08
Local loss @ local epoch 2: 2.384185648907078e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.384185648907078e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.45 seconds!
[tester] 
AGNewsMetric: acc=0.8211842105263157, hinge=3.6457106486119724, ce=9.71753156360827
Local test acc @ epoch 192: 0.8212
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.1175844747413066e-06
Local loss @ local epoch 1: 6.70552182668871e-08
Local loss @ local epoch 2: 1.2665977067172207e-07
Local loss @ local epoch 3: 3.7252892326478104e-08
Local loss @ local epoch 4: 4.023304995826038e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.96 seconds!
[tester] 
AGNewsMetric: acc=0.5744736842105264, hinge=9.722544399060702, ce=15.069563407897949
Local test acc @ epoch 192: 0.5745
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.3899632692337036
Local loss @ local epoch 1: 3.2511621839148575e-08
Local loss @ local epoch 2: 0.02788054756820202
Local loss @ local epoch 3: 0.5868932604789734
Local loss @ local epoch 4: 4.768271992361406e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.21 seconds!
[tester] 
AGNewsMetric: acc=0.6697368421052632, hinge=7.662905575601678, ce=12.892927587408769
Local test acc @ epoch 192: 0.6697
Global evaluate on test data...
Evaluate data in 124.46 seconds!
[tester] 
AGNewsMetric: acc=0.8525, hinge=2.8624511472802414, ce=9.001632021853798
Global test acc @ epoch 192: 0.8525
Global epoch 193...
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.9802317058624794e-08
Local loss @ local epoch 2: 9.934106870446158e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 9.934106870446158e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.11 seconds!
[tester] 
AGNewsMetric: acc=0.8251315789473684, hinge=3.6834878724499753, ce=9.692271128202739
Local test acc @ epoch 193: 0.8251
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.10731111466884613
Local loss @ local epoch 1: 3.8941624325161683e-07
Local loss @ local epoch 2: 3.1789141985427705e-08
Local loss @ local epoch 3: 8.742013335449883e-08
Local loss @ local epoch 4: 3.973642748178463e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.64 seconds!
[tester] 
AGNewsMetric: acc=0.5672368421052632, hinge=10.072607546354595, ce=15.101381518715307
Local test acc @ epoch 193: 0.5672
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 2.781549426345009e-07
Local loss @ local epoch 1: 4.6491391003655735e-06
Local loss @ local epoch 2: 2.3841853646899835e-07
Local loss @ local epoch 3: 2.781549426345009e-07
Local loss @ local epoch 4: 2.3841850804728892e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.0 seconds!
[tester] 
AGNewsMetric: acc=0.6555263157894737, hinge=6.937327226839567, ce=13.247102219431024
Local test acc @ epoch 193: 0.6555
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.9802320611338473e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.4901156930591242e-07
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.81 seconds!
[tester] 
AGNewsMetric: acc=0.8181578947368421, hinge=3.36600502516094, ce=9.53652259023566
Local test acc @ epoch 193: 0.8182
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 3.0994402777650976e-07
Local loss @ local epoch 1: 2.384185648907078e-08
Local loss @ local epoch 2: 2.384185648907078e-08
Local loss @ local epoch 3: 2.384185648907078e-08
Local loss @ local epoch 4: 7.152556946721234e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.54 seconds!
[tester] 
AGNewsMetric: acc=0.4689473684210526, hinge=11.693329642446418, ce=16.89339356271844
Local test acc @ epoch 193: 0.4689
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 5.4186031661629386e-08
Local loss @ local epoch 2: 1.0837207575775665e-08
Local loss @ local epoch 3: 3.2511621839148575e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.75 seconds!
[tester] 
AGNewsMetric: acc=0.7093421052631579, hinge=6.722112134632312, ce=12.207330161646793
Local test acc @ epoch 193: 0.7093
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 1.8051669030683115e-06
Local loss @ local epoch 1: 3.7465741797859664e-07
Local loss @ local epoch 2: 0.005045875906944275
Local loss @ local epoch 3: 3.0142614377837162e-06
Local loss @ local epoch 4: 1.3794198139294167e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.56 seconds!
[tester] 
AGNewsMetric: acc=0.7596052631578948, hinge=4.510687804724041, ce=11.332694300601357
Local test acc @ epoch 193: 0.7596
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 3.2511621839148575e-08
Local loss @ local epoch 1: 5.4186035214343065e-08
Local loss @ local epoch 2: 2.9260419864840514e-07
Local loss @ local epoch 3: 1.0837207575775665e-08
Local loss @ local epoch 4: 8.669763218449589e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.2 seconds!
[tester] 
AGNewsMetric: acc=0.6865789473684211, hinge=7.461070680116352, ce=12.304123103493138
Local test acc @ epoch 193: 0.6866
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 9.934106870446158e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.9868211964535476e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 9.934106870446158e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.13 seconds!
[tester] 
AGNewsMetric: acc=0.8219736842105263, hinge=3.6987148793120133, ce=9.950827590540836
Local test acc @ epoch 193: 0.822
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 5.93040704188752e-06
Local loss @ local epoch 1: 1.4901152667334827e-07
Local loss @ local epoch 2: 2.9802296808156825e-07
Local loss @ local epoch 3: 1.1063235433539376e-05
Local loss @ local epoch 4: 7.003533823990438e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.43 seconds!
[tester] 
AGNewsMetric: acc=0.7242105263157895, hinge=5.498226046311228, ce=11.270832830730237
Local test acc @ epoch 193: 0.7242
Global evaluate on test data...
Evaluate data in 124.13 seconds!
[tester] 
AGNewsMetric: acc=0.8559210526315789, hinge=2.8443078588184556, ce=9.05249653665643
Global test acc @ epoch 193: 0.8559
Global epoch 194...
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 2.9802320611338473e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 5.9604641222676946e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.54 seconds!
[tester] 
AGNewsMetric: acc=0.8375, hinge=3.170512733208506, ce=9.171866645812988
Local test acc @ epoch 194: 0.8375
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.384185648907078e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.7 seconds!
[tester] 
AGNewsMetric: acc=0.8242105263157895, hinge=3.647244647678576, ce=10.084171706751773
Local test acc @ epoch 194: 0.8242
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 7.94728478581419e-08
Local loss @ local epoch 1: 1.1920928244535389e-07
Local loss @ local epoch 2: 7.94728478581419e-08
Local loss @ local epoch 3: 1.5894570992713852e-07
Local loss @ local epoch 4: 3.973642748178463e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.59 seconds!
[tester] 
AGNewsMetric: acc=0.7611842105263158, hinge=4.424098340335645, ce=11.155247995476973
Local test acc @ epoch 194: 0.7612
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 1.3510315284293029e-06
Local loss @ local epoch 1: 2.1457660182022664e-07
Local loss @ local epoch 2: 7.947285496356926e-09
Local loss @ local epoch 3: 3.1789141985427705e-08
Local loss @ local epoch 4: 1.5099831784937123e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.15 seconds!
[tester] 
AGNewsMetric: acc=0.6815789473684211, hinge=6.898454898784035, ce=11.853952751159667
Local test acc @ epoch 194: 0.6816
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0002133101224899292
Local loss @ local epoch 1: 9.934106870446158e-09
Local loss @ local epoch 2: 9.934103673003847e-08
Local loss @ local epoch 3: 1.4901154088420299e-07
Local loss @ local epoch 4: 4.669025486236933e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.18 seconds!
[tester] 
AGNewsMetric: acc=0.4172368421052632, hinge=15.18936416425203, ce=18.842418510035465
Local test acc @ epoch 194: 0.4172
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 5.279265451463289e-07
Local loss @ local epoch 1: 6.590451903321082e-06
Local loss @ local epoch 2: 8.310350494866725e-06
Local loss @ local epoch 3: 3.082379180341377e-06
Local loss @ local epoch 4: 3.848712822218658e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.77 seconds!
[tester] 
AGNewsMetric: acc=0.6661842105263158, hinge=6.157266225814819, ce=13.454193542882015
Local test acc @ epoch 194: 0.6662
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 6.953873565862523e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 3.973642037635727e-08
Local loss @ local epoch 4: 1.1920925402364446e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.59 seconds!
[tester] 
AGNewsMetric: acc=0.8047368421052632, hinge=4.279306425044411, ce=10.370689225447805
Local test acc @ epoch 194: 0.8047
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 9.730077181302477e-06
Local loss @ local epoch 1: 6.705521116145974e-08
Local loss @ local epoch 2: 2.086161714487389e-07
Local loss @ local epoch 3: 2.5401339371455833e-05
Local loss @ local epoch 4: 3.948800326725177e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.47 seconds!
[tester] 
AGNewsMetric: acc=0.7331578947368421, hinge=5.095105975050675, ce=11.249442128633198
Local test acc @ epoch 194: 0.7332
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 7.911139050520433e-07
Local loss @ local epoch 1: 5.96044515077665e-07
Local loss @ local epoch 2: 2.384184938364342e-07
Local loss @ local epoch 3: 4.443250247732067e-07
Local loss @ local epoch 4: 2.0590685778643092e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.39 seconds!
[tester] 
AGNewsMetric: acc=0.5993421052631579, hinge=10.52352704198737, ce=14.596029054742111
Local test acc @ epoch 194: 0.5993
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 2.167441337519449e-08
Local loss @ local epoch 1: 1.0837207575775665e-08
Local loss @ local epoch 2: 1.0837207575775665e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.0837207575775665e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 125.06 seconds!
[tester] 
AGNewsMetric: acc=0.8253947368421053, hinge=3.769773657447413, ce=9.63117556521767
Local test acc @ epoch 194: 0.8254
Global evaluate on test data...
Evaluate data in 123.32 seconds!
[tester] 
AGNewsMetric: acc=0.8502631578947368, hinge=3.0214813099409406, ce=9.172704399510433
Global test acc @ epoch 194: 0.8503
Global epoch 195...
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 8.344644015778613e-07
Local loss @ local epoch 1: 1.9868208767093165e-07
Local loss @ local epoch 2: 1.986821303034958e-07
Local loss @ local epoch 3: 2.264973090859712e-06
Local loss @ local epoch 4: 8.742009072193468e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.03 seconds!
[tester] 
AGNewsMetric: acc=0.5011842105263158, hinge=9.075153468282599, ce=14.138098267003109
Local test acc @ epoch 195: 0.5012
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.384185648907078e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.05 seconds!
[tester] 
AGNewsMetric: acc=0.8361842105263158, hinge=3.3184742657761825, ce=10.212031185752467
Local test acc @ epoch 195: 0.8362
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 2.384183943604512e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.9802320611338473e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.88 seconds!
[tester] 
AGNewsMetric: acc=0.8361842105263158, hinge=3.113552142569893, ce=9.067165222167969
Local test acc @ epoch 195: 0.8362
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 2.9802320611338473e-08
Local loss @ local epoch 1: 5.960463766996327e-08
Local loss @ local epoch 2: 1.7881390590446244e-07
Local loss @ local epoch 3: 8.940695295223122e-08
Local loss @ local epoch 4: 8.940696005765858e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.79 seconds!
[tester] 
AGNewsMetric: acc=0.8515789473684211, hinge=2.6782014580776816, ce=9.267551383972169
Local test acc @ epoch 195: 0.8516
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 2.5555073079885915e-06
Local loss @ local epoch 1: 7.450579175838357e-08
Local loss @ local epoch 2: 2.2351740014414645e-08
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.72 seconds!
[tester] 
AGNewsMetric: acc=0.6682894736842105, hinge=7.8946624384428326, ce=12.326355038693077
Local test acc @ epoch 195: 0.6683
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 3.0889288609614596e-05
Local loss @ local epoch 1: 4.257472596691514e-07
Local loss @ local epoch 2: 2.5204167286574375e-06
Local loss @ local epoch 3: 1.396449988533277e-06
Local loss @ local epoch 4: 1.2431533832568675e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.42 seconds!
[tester] 
AGNewsMetric: acc=0.5119736842105264, hinge=9.57086436723408, ce=14.915087926764237
Local test acc @ epoch 195: 0.512
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 3.2511621839148575e-08
Local loss @ local epoch 2: 1.0837207575775665e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.91 seconds!
[tester] 
AGNewsMetric: acc=0.8147368421052632, hinge=3.998361186479267, ce=10.10452106074283
Local test acc @ epoch 195: 0.8147
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 7.772146091156173e-06
Local loss @ local epoch 1: 1.2715651109829196e-07
Local loss @ local epoch 2: 3.4173280027971487e-07
Local loss @ local epoch 3: 4.649011771107325e-06
Local loss @ local epoch 4: 9.377762353324215e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.2 seconds!
[tester] 
AGNewsMetric: acc=0.6351315789473684, hinge=8.019926764839575, ce=13.01215237667686
Local test acc @ epoch 195: 0.6351
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 1.192092469182171e-07
Local loss @ local epoch 1: 9.753485130659101e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.600927757612226e-07
Local loss @ local epoch 4: 4.334882675038898e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.48 seconds!
[tester] 
AGNewsMetric: acc=0.7923684210526316, hinge=4.543528352536653, ce=9.936275104723478
Local test acc @ epoch 195: 0.7924
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 9.934106870446158e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 3.973642037635727e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.89 seconds!
[tester] 
AGNewsMetric: acc=0.8142105263157895, hinge=3.9840410975406044, ce=10.254046913950067
Local test acc @ epoch 195: 0.8142
Global evaluate on test data...
Evaluate data in 123.51 seconds!
[tester] 
AGNewsMetric: acc=0.8535526315789473, hinge=2.9188533754097787, ce=8.874169697008634
Global test acc @ epoch 195: 0.8536
Global epoch 196...
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.4057835340499878
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.688782504061237e-06
Local loss @ local epoch 3: 0.7059294581413269
Local loss @ local epoch 4: 0.00926316436380148
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.46 seconds!
[tester] 
AGNewsMetric: acc=0.5798684210526316, hinge=10.093381887737074, ce=14.011881960818641
Local test acc @ epoch 196: 0.5799
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 3.0653805538349843e-07
Local loss @ local epoch 1: 2.895080797316041e-07
Local loss @ local epoch 2: 4.768367034557741e-07
Local loss @ local epoch 3: 1.7029897492193413e-08
Local loss @ local epoch 4: 1.1920927533992653e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.62 seconds!
[tester] 
AGNewsMetric: acc=0.6885526315789474, hinge=6.019489159835012, ce=13.03203391426488
Local test acc @ epoch 196: 0.6886
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 7.947285496356926e-08
Local loss @ local epoch 1: 7.152554530875932e-07
Local loss @ local epoch 2: 4.3710056729651114e-07
Local loss @ local epoch 3: 9.139369581134815e-07
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.77 seconds!
[tester] 
AGNewsMetric: acc=0.5672368421052632, hinge=8.41594262273688, ce=15.118935105173211
Local test acc @ epoch 196: 0.5672
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.152556236178498e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 9.53674117454284e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.04 seconds!
[tester] 
AGNewsMetric: acc=0.7564473684210526, hinge=4.876404571031269, ce=10.451923559088456
Local test acc @ epoch 196: 0.7564
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 1.0641520930221304e-05
Local loss @ local epoch 1: 5.418602455620203e-08
Local loss @ local epoch 2: 1.0837207575775665e-08
Local loss @ local epoch 3: 2.3408147171721794e-06
Local loss @ local epoch 4: 5.310225787980016e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.82 seconds!
[tester] 
AGNewsMetric: acc=0.7046052631578947, hinge=7.217893959221087, ce=12.017512978001644
Local test acc @ epoch 196: 0.7046
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0001264882303075865
Local loss @ local epoch 1: 4.470348002882929e-08
Local loss @ local epoch 2: 3.3527584264447796e-07
Local loss @ local epoch 3: 1.7881384906104358e-07
Local loss @ local epoch 4: 4.5448499008671206e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.69 seconds!
[tester] 
AGNewsMetric: acc=0.6051315789473685, hinge=7.272881387409411, ce=13.86449082023219
Local test acc @ epoch 196: 0.6051
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.08120351284742355
Local loss @ local epoch 1: 9.934106870446158e-09
Local loss @ local epoch 2: 5.960463411724959e-08
Local loss @ local epoch 3: 6.457148629124276e-07
Local loss @ local epoch 4: 4.142422767472453e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.34 seconds!
[tester] 
AGNewsMetric: acc=0.34671052631578947, hinge=17.585786152889852, ce=19.32128113194516
Local test acc @ epoch 196: 0.3467
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 2.9802320611338473e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.9802320611338473e-08
Local loss @ local epoch 3: 2.9802320611338473e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.35 seconds!
[tester] 
AGNewsMetric: acc=0.8473684210526315, hinge=3.0433065537402504, ce=9.037869154277601
Local test acc @ epoch 196: 0.8474
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 2.6086101570399478e-05
Local loss @ local epoch 1: 7.073066399243544e-07
Local loss @ local epoch 2: 1.6689297410721338e-07
Local loss @ local epoch 3: 5.483616405399516e-07
Local loss @ local epoch 4: 1.867600076366216e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.44 seconds!
[tester] 
AGNewsMetric: acc=0.5896052631578947, hinge=8.92452541301125, ce=14.147392212717156
Local test acc @ epoch 196: 0.5896
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 1.2846064567565918
Local loss @ local epoch 1: 1.0837207575775665e-08
Local loss @ local epoch 2: 1.4521755247187684e-06
Local loss @ local epoch 3: 9.839875019679312e-06
Local loss @ local epoch 4: 1.402026891708374
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.18 seconds!
[tester] 
AGNewsMetric: acc=0.6, hinge=9.572827338168496, ce=14.340586822911312
Local test acc @ epoch 196: 0.6
Global evaluate on test data...
Evaluate data in 124.08 seconds!
[tester] 
AGNewsMetric: acc=0.834078947368421, hinge=3.4215129398044786, ce=9.437401731390702
Global test acc @ epoch 196: 0.8341
Global epoch 197...
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 2.9802320611338473e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.17 seconds!
[tester] 
AGNewsMetric: acc=0.8225, hinge=3.509494759660018, ce=9.37108087037739
Local test acc @ epoch 197: 0.8225
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.384185648907078e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.384185648907078e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.25 seconds!
[tester] 
AGNewsMetric: acc=0.8367105263157895, hinge=3.4339236122683476, ce=9.820872589914423
Local test acc @ epoch 197: 0.8367
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 2.0116559085181507e-07
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.37 seconds!
[tester] 
AGNewsMetric: acc=0.7703947368421052, hinge=5.023431817857842, ce=10.840686446742007
Local test acc @ epoch 197: 0.7704
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.0837202069069463e-07
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.81 seconds!
[tester] 
AGNewsMetric: acc=0.8314473684210526, hinge=3.434498059122186, ce=9.561397046540913
Local test acc @ epoch 197: 0.8314
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 1.9868213740892315e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 9.934106870446158e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.91 seconds!
[tester] 
AGNewsMetric: acc=0.8377631578947369, hinge=3.1459135897536026, ce=9.432782578719289
Local test acc @ epoch 197: 0.8378
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0006029731594026089
Local loss @ local epoch 1: 7.152553394007555e-07
Local loss @ local epoch 2: 1.708664171928831e-06
Local loss @ local epoch 3: 3.337853513585287e-06
Local loss @ local epoch 4: 6.477004717453383e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.46 seconds!
[tester] 
AGNewsMetric: acc=0.46710526315789475, hinge=9.767408810665733, ce=14.189326025310315
Local test acc @ epoch 197: 0.4671
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 8.020905625016894e-06
Local loss @ local epoch 1: 2.390946974628605e-05
Local loss @ local epoch 2: 1.011478304862976
Local loss @ local epoch 3: 3.453409226494841e-05
Local loss @ local epoch 4: 3.383615330676548e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.45 seconds!
[tester] 
AGNewsMetric: acc=0.7836842105263158, hinge=3.058893639664901, ce=9.64545928553531
Local test acc @ epoch 197: 0.7837
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 9.934106870446158e-09
Local loss @ local epoch 1: 9.934106870446158e-09
Local loss @ local epoch 2: 2.9802320611338473e-08
Local loss @ local epoch 3: 6.953873565862523e-08
Local loss @ local epoch 4: 6.953873565862523e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.7 seconds!
[tester] 
AGNewsMetric: acc=0.8263157894736842, hinge=3.5047983561064067, ce=9.488069755152653
Local test acc @ epoch 197: 0.8263
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 8.026747195799544e-07
Local loss @ local epoch 1: 1.4305102524758695e-07
Local loss @ local epoch 2: 1.4305109630186053e-07
Local loss @ local epoch 3: 8.74201049327894e-08
Local loss @ local epoch 4: 1.5894570992713852e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.43 seconds!
[tester] 
AGNewsMetric: acc=0.733421052631579, hinge=5.845956673873098, ce=11.693864888642963
Local test acc @ epoch 197: 0.7334
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 2.167441515155133e-08
Local loss @ local epoch 1: 2.167441515155133e-08
Local loss @ local epoch 2: 2.8176697242088267e-07
Local loss @ local epoch 3: 6.285563358687796e-07
Local loss @ local epoch 4: 2.167441337519449e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.43 seconds!
[tester] 
AGNewsMetric: acc=0.718421052631579, hinge=6.480494672875655, ce=11.573622388337787
Local test acc @ epoch 197: 0.7184
Global evaluate on test data...
Evaluate data in 123.78 seconds!
[tester] 
AGNewsMetric: acc=0.8509210526315789, hinge=3.0029194462926765, ce=8.843770695736534
Global test acc @ epoch 197: 0.8509
Global epoch 198...
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 5.960463411724959e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.291432880634602e-07
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.81 seconds!
[tester] 
AGNewsMetric: acc=0.8346052631578947, hinge=3.268070322463387, ce=9.005546935232061
Local test acc @ epoch 198: 0.8346
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 1.505373165855417e-05
Local loss @ local epoch 1: 3.6473596992436796e-05
Local loss @ local epoch 2: 5.51758876099484e-06
Local loss @ local epoch 3: 0.0004244933952577412
Local loss @ local epoch 4: 7.827593799447641e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.62 seconds!
[tester] 
AGNewsMetric: acc=0.7825, hinge=3.9515052855642216, ce=10.07415166152151
Local test acc @ epoch 198: 0.7825
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 2.781541297736112e-06
Local loss @ local epoch 1: 3.973642748178463e-08
Local loss @ local epoch 2: 1.1920911902052467e-06
Local loss @ local epoch 3: 5.563095442084887e-07
Local loss @ local epoch 4: 7.152552825573366e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.34 seconds!
[tester] 
AGNewsMetric: acc=0.786578947368421, hinge=3.765000964214927, ce=10.115593942341052
Local test acc @ epoch 198: 0.7866
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.1920926823449918e-07
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.0837207575775665e-08
Local loss @ local epoch 4: 1.0837202779612198e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.58 seconds!
[tester] 
AGNewsMetric: acc=0.6939473684210526, hinge=7.571914668334158, ce=12.12547993509393
Local test acc @ epoch 198: 0.6939
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 7.29244202375412e-05
Local loss @ local epoch 1: 5.5630994921784804e-08
Local loss @ local epoch 2: 5.563098781635745e-08
Local loss @ local epoch 3: 0.0009455402614548802
Local loss @ local epoch 4: 2.384185648907078e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.7 seconds!
[tester] 
AGNewsMetric: acc=0.7769736842105263, hinge=3.553305166897021, ce=10.041829759698166
Local test acc @ epoch 198: 0.777
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.6689293147464923e-07
Local loss @ local epoch 2: 2.384185648907078e-08
Local loss @ local epoch 3: 2.384185648907078e-08
Local loss @ local epoch 4: 7.152556946721234e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.71 seconds!
[tester] 
AGNewsMetric: acc=0.8509210526315789, hinge=2.8272238858122574, ce=9.340904227808903
Local test acc @ epoch 198: 0.8509
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 4.097812507097842e-07
Local loss @ local epoch 1: 1.2665975646086736e-07
Local loss @ local epoch 2: 3.725289587919178e-08
Local loss @ local epoch 3: 1.2665981330428622e-07
Local loss @ local epoch 4: 5.960463056453591e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 122.88 seconds!
[tester] 
AGNewsMetric: acc=0.6426315789473684, hinge=8.964528229362086, ce=13.861714919240852
Local test acc @ epoch 198: 0.6426
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 2.9802320611338473e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.19 seconds!
[tester] 
AGNewsMetric: acc=0.8548684210526316, hinge=2.923823806863082, ce=9.160485335902164
Local test acc @ epoch 198: 0.8549
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 9.934106870446158e-09
Local loss @ local epoch 3: 2.1855015575056314e-07
Local loss @ local epoch 4: 1.9868211964535476e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.18 seconds!
[tester] 
AGNewsMetric: acc=0.8173684210526316, hinge=3.8669091465598657, ce=9.90506556460732
Local test acc @ epoch 198: 0.8174
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 7.369293371084495e-07
Local loss @ local epoch 1: 1.1920920428565296e-07
Local loss @ local epoch 2: 0.0006503145559690893
Local loss @ local epoch 3: 1.9940339370805304e-06
Local loss @ local epoch 4: 3.1427879321199725e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.95 seconds!
[tester] 
AGNewsMetric: acc=0.7773684210526316, hinge=4.612544397680383, ce=10.137938513504832
Local test acc @ epoch 198: 0.7774
Global evaluate on test data...
Evaluate data in 123.34 seconds!
[tester] 
AGNewsMetric: acc=0.8597368421052631, hinge=2.8809223714627716, ce=8.8186348824752
Global test acc @ epoch 198: 0.8597
Global epoch 199...
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 9.934106870446158e-09
Local loss @ local epoch 2: 6.953874276405259e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.41 seconds!
[tester] 
AGNewsMetric: acc=0.8577631578947369, hinge=2.8905618276094134, ce=8.986335439180072
Local test acc @ epoch 199: 0.8578
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 2.384185648907078e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.384185648907078e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.68 seconds!
[tester] 
AGNewsMetric: acc=0.8553947368421052, hinge=2.9632986144015665, ce=9.05802567532188
Local test acc @ epoch 199: 0.8554
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.167441515155133e-08
Local loss @ local epoch 2: 2.167441337519449e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.31 seconds!
[tester] 
AGNewsMetric: acc=0.795, hinge=4.53399572209308, ce=10.297314651890805
Local test acc @ epoch 199: 0.795
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.0430811414607888e-07
Local loss @ local epoch 1: 2.2351740014414645e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 1.4901159417490817e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.24 seconds!
[tester] 
AGNewsMetric: acc=0.785921052631579, hinge=4.786964564574392, ce=10.242184078818873
Local test acc @ epoch 199: 0.7859
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 3.973642392907095e-08
Local loss @ local epoch 1: 7.947283364728719e-08
Local loss @ local epoch 2: 9.934106870446158e-09
Local loss @ local epoch 3: 9.934106870446158e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.55 seconds!
[tester] 
AGNewsMetric: acc=0.7682894736842105, hinge=5.545232712344119, ce=10.981928686844675
Local test acc @ epoch 199: 0.7683
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 5.960463766996327e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.61 seconds!
[tester] 
AGNewsMetric: acc=0.835, hinge=3.174744136458949, ce=9.0883419137252
Local test acc @ epoch 199: 0.835
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 3.855322938761674e-05
Local loss @ local epoch 1: 5.790161594632082e-07
Local loss @ local epoch 2: 0.0007856817683205009
Local loss @ local epoch 3: 1.0643489076755941e-05
Local loss @ local epoch 4: 0.00010718908015405759
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.49 seconds!
[tester] 
AGNewsMetric: acc=0.7780263157894737, hinge=3.6720004520918192, ce=9.464649447390908
Local test acc @ epoch 199: 0.778
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 2.622603290092229e-07
Local loss @ local epoch 1: 1.5894569216357013e-08
Local loss @ local epoch 2: 1.5894570992713852e-08
Local loss @ local epoch 3: 7.947285496356926e-09
Local loss @ local epoch 4: 1.0331465460922118e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.64 seconds!
[tester] 
AGNewsMetric: acc=0.58, hinge=11.084294960624293, ce=16.00705545525802
Local test acc @ epoch 199: 0.58
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 1.5497195136049413e-06
Local loss @ local epoch 1: 1.6847843653522432e-05
Local loss @ local epoch 2: 1.5695537513238378e-05
Local loss @ local epoch 3: 0.00019211374456062913
Local loss @ local epoch 4: 1.0847878002095968e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.32 seconds!
[tester] 
AGNewsMetric: acc=0.6368421052631579, hinge=5.8031433451803105, ce=11.306896402459396
Local test acc @ epoch 199: 0.6368
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 2.600926904960943e-07
Local loss @ local epoch 1: 2.167439987488251e-07
Local loss @ local epoch 2: 9.753482999030894e-08
Local loss @ local epoch 3: 5.093478989692812e-07
Local loss @ local epoch 4: 4.33488231976753e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.75 seconds!
[tester] 
AGNewsMetric: acc=0.7596052631578948, hinge=5.1030138397216795, ce=10.646035634091026
Local test acc @ epoch 199: 0.7596
Global evaluate on test data...
Evaluate data in 123.22 seconds!
[tester] 
AGNewsMetric: acc=0.8596052631578948, hinge=2.906786126463037, ce=8.795304918791118
Global test acc @ epoch 199: 0.8596
Global epoch 200...
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 2.3330892418016447e-06
Local loss @ local epoch 1: 1.1750607882277109e-06
Local loss @ local epoch 2: 1.3742502233071718e-05
Local loss @ local epoch 3: 3.576277265437966e-07
Local loss @ local epoch 4: 6.641656682404573e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.96 seconds!
[tester] 
AGNewsMetric: acc=0.7648684210526315, hinge=4.236387609933552, ce=10.761645650361714
Local test acc @ epoch 200: 0.7649
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.000573761819396168
Local loss @ local epoch 1: 7.152535772547708e-07
Local loss @ local epoch 2: 2.1674268282367848e-06
Local loss @ local epoch 3: 0.460702508687973
Local loss @ local epoch 4: 1.2245992593307164e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.06 seconds!
[tester] 
AGNewsMetric: acc=0.8060526315789474, hinge=3.992878732304824, ce=10.306429901123046
Local test acc @ epoch 200: 0.8061
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.9802320611338473e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.1920926112907182e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.03 seconds!
[tester] 
AGNewsMetric: acc=0.8488157894736842, hinge=3.036989693767146, ce=9.338799073068719
Local test acc @ epoch 200: 0.8488
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 9.53674117454284e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.384185648907078e-08
Local loss @ local epoch 3: 7.152556236178498e-08
Local loss @ local epoch 4: 4.768370942542788e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.22 seconds!
[tester] 
AGNewsMetric: acc=0.8084210526315789, hinge=4.182472351601249, ce=9.822106969732987
Local test acc @ epoch 200: 0.8084
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 1.1920923981278975e-07
Local loss @ local epoch 1: 9.934106870446158e-09
Local loss @ local epoch 2: 3.973642748178463e-08
Local loss @ local epoch 3: 2.9802320611338473e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.85 seconds!
[tester] 
AGNewsMetric: acc=0.6103947368421052, hinge=9.919206535941676, ce=14.211068101180228
Local test acc @ epoch 200: 0.6104
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 9.934106870446158e-09
Local loss @ local epoch 3: 1.0927514182412779e-07
Local loss @ local epoch 4: 9.934106870446158e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.63 seconds!
[tester] 
AGNewsMetric: acc=0.858421052631579, hinge=2.8358781301347835, ce=9.03707295869526
Local test acc @ epoch 200: 0.8584
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 8.742003956285771e-07
Local loss @ local epoch 1: 5.960460498499742e-07
Local loss @ local epoch 2: 1.0967173693643417e-05
Local loss @ local epoch 3: 5.4438664847111795e-06
Local loss @ local epoch 4: 3.973631464759819e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.34 seconds!
[tester] 
AGNewsMetric: acc=0.5605263157894737, hinge=10.557654105738589, ce=15.037270825034694
Local test acc @ epoch 200: 0.5605
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 3.129240155885782e-07
Local loss @ local epoch 1: 1.0430807861894209e-07
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.9802315282267955e-08
Local loss @ local epoch 4: 5.960463411724959e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.81 seconds!
[tester] 
AGNewsMetric: acc=0.6285526315789474, hinge=9.153995326192755, ce=14.662012782849764
Local test acc @ epoch 200: 0.6286
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 1.2715652530914667e-07
Local loss @ local epoch 1: 7.152554815093026e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.947285496356926e-09
Local loss @ local epoch 4: 1.5894570992713852e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.87 seconds!
[tester] 
AGNewsMetric: acc=0.7438157894736842, hinge=6.105789684998362, ce=11.335894136930767
Local test acc @ epoch 200: 0.7438
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 3.1032504921313375e-05
Local loss @ local epoch 1: 2.167441337519449e-08
Local loss @ local epoch 2: 2.167441337519449e-08
Local loss @ local epoch 3: 2.94767733066692e-06
Local loss @ local epoch 4: 5.526969175662089e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.19 seconds!
[tester] 
AGNewsMetric: acc=0.6088157894736842, hinge=9.207920657710025, ce=13.901219745435213
Local test acc @ epoch 200: 0.6088
Global evaluate on test data...
Evaluate data in 123.55 seconds!
[tester] 
AGNewsMetric: acc=0.8453947368421053, hinge=3.224563425716601, ce=9.223192506087454
Global test acc @ epoch 200: 0.8454
Global epoch 201...
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 1.3113009345033788e-06
Local loss @ local epoch 1: 1.589456957162838e-07
Local loss @ local epoch 2: 6.118868623161688e-05
Local loss @ local epoch 3: 3.7749412058474263e-06
Local loss @ local epoch 4: 2.781549426345009e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.74 seconds!
[tester] 
AGNewsMetric: acc=0.41828947368421054, hinge=12.66912430411891, ce=16.444206928453948
Local test acc @ epoch 201: 0.4183
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 1.4088362831898849e-07
Local loss @ local epoch 1: 6.502323657286979e-08
Local loss @ local epoch 2: 2.60092804182932e-07
Local loss @ local epoch 3: 1.2386084563331679e-05
Local loss @ local epoch 4: 4.334883030310266e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.0 seconds!
[tester] 
AGNewsMetric: acc=0.8264473684210526, hinge=3.6765914898169667, ce=9.591835335179379
Local test acc @ epoch 201: 0.8264
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 2.9802320611338473e-08
Local loss @ local epoch 1: 9.934106870446158e-09
Local loss @ local epoch 2: 1.9868213740892315e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.14 seconds!
[tester] 
AGNewsMetric: acc=0.8306578947368422, hinge=3.525152965219397, ce=9.588516671030145
Local test acc @ epoch 201: 0.8307
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 5.9604641222676946e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.77 seconds!
[tester] 
AGNewsMetric: acc=0.8444736842105263, hinge=3.2117070374990764, ce=9.327473437660618
Local test acc @ epoch 201: 0.8445
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0003127434756606817
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.0837207575775665e-08
Local loss @ local epoch 3: 3.2511618286434896e-08
Local loss @ local epoch 4: 1.517208971790751e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.39 seconds!
[tester] 
AGNewsMetric: acc=0.38184210526315787, hinge=14.7315522495069, ce=18.640260166368986
Local test acc @ epoch 201: 0.3818
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 9.025836220644123e-07
Local loss @ local epoch 1: 9.468401913181879e-06
Local loss @ local epoch 2: 6.857106200186536e-05
Local loss @ local epoch 3: 5.208525908528827e-05
Local loss @ local epoch 4: 7.663449537176348e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.74 seconds!
[tester] 
AGNewsMetric: acc=0.6667105263157894, hinge=5.567572502086037, ce=11.686580316643965
Local test acc @ epoch 201: 0.6667
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 2.8610190838662675e-07
Local loss @ local epoch 1: 5.5630994921784804e-08
Local loss @ local epoch 2: 2.384185648907078e-08
Local loss @ local epoch 3: 2.60665933637938e-06
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 122.89 seconds!
[tester] 
AGNewsMetric: acc=0.7068421052631579, hinge=6.239357512122706, ce=12.103149743331105
Local test acc @ epoch 201: 0.7068
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 2.384185648907078e-08
Local loss @ local epoch 1: 9.53674117454284e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.05 seconds!
[tester] 
AGNewsMetric: acc=0.8368421052631579, hinge=3.3445347102064837, ce=9.365132514552066
Local test acc @ epoch 201: 0.8368
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 6.498366565210745e-05
Local loss @ local epoch 1: 4.967052902316027e-08
Local loss @ local epoch 2: 4.967052902316027e-08
Local loss @ local epoch 3: 6.258476901166432e-07
Local loss @ local epoch 4: 0.6863781809806824
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.64 seconds!
[tester] 
AGNewsMetric: acc=0.5536842105263158, hinge=12.016806989469027, ce=16.23897557509573
Local test acc @ epoch 201: 0.5537
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 9.313198461313732e-07
Local loss @ local epoch 1: 3.725289587919178e-08
Local loss @ local epoch 2: 1.7136314056642732e-07
Local loss @ local epoch 3: 0.9265643358230591
Local loss @ local epoch 4: 8.195636524988004e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.64 seconds!
[tester] 
AGNewsMetric: acc=0.8335526315789473, hinge=3.287870670619764, ce=9.715946251718622
Local test acc @ epoch 201: 0.8336
Global evaluate on test data...
Evaluate data in 123.64 seconds!
[tester] 
AGNewsMetric: acc=0.8385526315789473, hinge=3.381867708908884, ce=9.358427356920744
Global test acc @ epoch 201: 0.8386
Global epoch 202...
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 3.973642748178463e-08
Local loss @ local epoch 3: 1.9868211964535476e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.07 seconds!
[tester] 
AGNewsMetric: acc=0.838421052631579, hinge=3.390819769784024, ce=9.508336155540064
Local test acc @ epoch 202: 0.8384
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 3.2511621839148575e-08
Local loss @ local epoch 1: 1.0837207575775665e-08
Local loss @ local epoch 2: 1.0837207575775665e-08
Local loss @ local epoch 3: 3.2511621839148575e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 125.02 seconds!
[tester] 
AGNewsMetric: acc=0.8314473684210526, hinge=3.5657463570644983, ce=9.387156404194078
Local test acc @ epoch 202: 0.8314
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 1.9073446537731797e-06
Local loss @ local epoch 1: 2.6225955025438452e-06
Local loss @ local epoch 2: 5.841234724357491e-06
Local loss @ local epoch 3: 9.25846688915044e-06
Local loss @ local epoch 4: 5.8809546317206696e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.29 seconds!
[tester] 
AGNewsMetric: acc=0.7961842105263158, hinge=3.599562833936591, ce=10.012673147101152
Local test acc @ epoch 202: 0.7962
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 1.4305113893442467e-07
Local loss @ local epoch 1: 1.5894570992713852e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.947285496356926e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.08 seconds!
[tester] 
AGNewsMetric: acc=0.6652631578947369, hinge=8.12378081924037, ce=13.536720486691124
Local test acc @ epoch 202: 0.6653
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 9.934106870446158e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 9.934106870446158e-09
Local loss @ local epoch 4: 1.9868213740892315e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 122.97 seconds!
[tester] 
AGNewsMetric: acc=0.839078947368421, hinge=3.345734541416168, ce=9.375865321912263
Local test acc @ epoch 202: 0.8391
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.019836746156215668
Local loss @ local epoch 1: 1.5348009583249222e-06
Local loss @ local epoch 2: 4.470347647611561e-08
Local loss @ local epoch 3: 5.960463766996327e-08
Local loss @ local epoch 4: 1.0430809993522416e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.62 seconds!
[tester] 
AGNewsMetric: acc=0.5546052631578947, hinge=10.215897975720857, ce=15.236437749360737
Local test acc @ epoch 202: 0.5546
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 1.1920926112907182e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.9802320611338473e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.9 seconds!
[tester] 
AGNewsMetric: acc=0.8369736842105263, hinge=3.217274362413507, ce=9.375217851337634
Local test acc @ epoch 202: 0.837
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 5.313272140483605e-06
Local loss @ local epoch 1: 3.1334857339970767e-06
Local loss @ local epoch 2: 3.252700253142393e-06
Local loss @ local epoch 3: 1.1273600648564752e-05
Local loss @ local epoch 4: 3.5592361200542655e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 125.13 seconds!
[tester] 
AGNewsMetric: acc=0.6236842105263158, hinge=7.021177121212608, ce=13.07802051744963
Local test acc @ epoch 202: 0.6237
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.167441337519449e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 5.4186031661629386e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.64 seconds!
[tester] 
AGNewsMetric: acc=0.809078947368421, hinge=4.088025009757594, ce=9.878127688357704
Local test acc @ epoch 202: 0.8091
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.38 seconds!
[tester] 
AGNewsMetric: acc=0.8225, hinge=3.807599757847033, ce=10.112389546444541
Local test acc @ epoch 202: 0.8225
Global evaluate on test data...
Evaluate data in 123.44 seconds!
[tester] 
AGNewsMetric: acc=0.8457894736842105, hinge=3.204825889185855, ce=9.22519426044665
Global test acc @ epoch 202: 0.8458
Global epoch 203...
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 1.589456957162838e-07
Local loss @ local epoch 1: 1.9868211609264108e-07
Local loss @ local epoch 2: 1.1920928244535389e-07
Local loss @ local epoch 3: 1.6689278936610208e-06
Local loss @ local epoch 4: 4.7683693082944956e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.56 seconds!
[tester] 
AGNewsMetric: acc=0.5544736842105263, hinge=10.841577896318938, ce=15.387432455765573
Local test acc @ epoch 203: 0.5545
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 5.52696064914926e-07
Local loss @ local epoch 1: 3.2511621839148575e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 3.9013866626191884e-07
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.76 seconds!
[tester] 
AGNewsMetric: acc=0.521578947368421, hinge=12.465095710754394, ce=15.738943828783537
Local test acc @ epoch 203: 0.5216
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 1.192091971802256e-07
Local loss @ local epoch 1: 3.1789138432714026e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 8.74201049327894e-08
Local loss @ local epoch 4: 7.947285496356926e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.82 seconds!
[tester] 
AGNewsMetric: acc=0.7407894736842106, hinge=5.720306736544559, ce=11.259189151964689
Local test acc @ epoch 203: 0.7408
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 2.9802320611338473e-08
Local loss @ local epoch 1: 2.9802320611338473e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.74 seconds!
[tester] 
AGNewsMetric: acc=0.8271052631578948, hinge=3.7170515893635, ce=9.362407357065301
Local test acc @ epoch 203: 0.8271
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 4.768371297814156e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.384185648907078e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.96 seconds!
[tester] 
AGNewsMetric: acc=0.8367105263157895, hinge=3.339014670472396, ce=9.568835119950144
Local test acc @ epoch 203: 0.8367
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 8.514948746096707e-08
Local loss @ local epoch 1: 9.536733500681294e-07
Local loss @ local epoch 2: 5.347330898075597e-06
Local loss @ local epoch 3: 1.3044484148849733e-05
Local loss @ local epoch 4: 1.702989465002247e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 122.92 seconds!
[tester] 
AGNewsMetric: acc=0.7260526315789474, hinge=5.2140007295106585, ce=11.682810532419305
Local test acc @ epoch 203: 0.7261
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 1.4154919881548267e-05
Local loss @ local epoch 1: 2.9802317058624794e-08
Local loss @ local epoch 2: 2.9802320611338473e-08
Local loss @ local epoch 3: 0.9033467173576355
Local loss @ local epoch 4: 1.1920923981278975e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.36 seconds!
[tester] 
AGNewsMetric: acc=0.7826315789473685, hinge=4.680815191268921, ce=10.495013331363076
Local test acc @ epoch 203: 0.7826
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.19149595499038696
Local loss @ local epoch 1: 4.334882675038898e-08
Local loss @ local epoch 2: 9.753485130659101e-08
Local loss @ local epoch 3: 3.175281790390727e-06
Local loss @ local epoch 4: 0.889322817325592
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.25 seconds!
[tester] 
AGNewsMetric: acc=0.7080263157894737, hinge=4.403870814348522, ce=8.586262437920821
Local test acc @ epoch 203: 0.708
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 9.934106870446158e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 4.967052191773291e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.56 seconds!
[tester] 
AGNewsMetric: acc=0.7525, hinge=5.912858992375826, ce=11.669781339544999
Local test acc @ epoch 203: 0.7525
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901144140821998e-07
Local loss @ local epoch 1: 4.470347647611561e-08
Local loss @ local epoch 2: 2.2351740014414645e-08
Local loss @ local epoch 3: 1.4901159417490817e-08
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.54 seconds!
[tester] 
AGNewsMetric: acc=0.6397368421052632, hinge=8.887524524989882, ce=14.44520166296708
Local test acc @ epoch 203: 0.6397
Global evaluate on test data...
Evaluate data in 123.82 seconds!
[tester] 
AGNewsMetric: acc=0.8426315789473684, hinge=3.330531476171393, ce=9.293242821944387
Global test acc @ epoch 203: 0.8426
Global epoch 204...
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 1.5326879747590283e-06
Local loss @ local epoch 1: 9.366434028379444e-07
Local loss @ local epoch 2: 3.0653799854007957e-07
Local loss @ local epoch 3: 2.367137540204567e-06
Local loss @ local epoch 4: 4.938665938425402e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.7 seconds!
[tester] 
AGNewsMetric: acc=0.7147368421052631, hinge=5.302662228032163, ce=12.081421101218776
Local test acc @ epoch 204: 0.7147
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.9868213740892315e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.53 seconds!
[tester] 
AGNewsMetric: acc=0.8427631578947369, hinge=3.3458340047535144, ce=9.60139533595035
Local test acc @ epoch 204: 0.8428
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.23 seconds!
[tester] 
AGNewsMetric: acc=0.8397368421052631, hinge=3.3153063811753927, ce=9.486613205357601
Local test acc @ epoch 204: 0.8397
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.000188978185178712
Local loss @ local epoch 1: 7.947285496356926e-09
Local loss @ local epoch 2: 2.225238660003015e-07
Local loss @ local epoch 3: 4.6094203298707725e-07
Local loss @ local epoch 4: 1.748402098655788e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.37 seconds!
[tester] 
AGNewsMetric: acc=0.5736842105263158, hinge=9.072919344651071, ce=14.000938624331825
Local test acc @ epoch 204: 0.5737
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 4.5745964598609135e-06
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 3.725289943190546e-08
Local loss @ local epoch 3: 0.009045829996466637
Local loss @ local epoch 4: 5.662416810991999e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.42 seconds!
[tester] 
AGNewsMetric: acc=0.8144736842105263, hinge=3.9772729273846275, ce=10.108256978486713
Local test acc @ epoch 204: 0.8145
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 1.0837207575775665e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.167441337519449e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.06 seconds!
[tester] 
AGNewsMetric: acc=0.8061842105263158, hinge=4.327368220530058, ce=10.095406913757325
Local test acc @ epoch 204: 0.8062
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.0837207575775665e-08
Local loss @ local epoch 2: 1.0837207575775665e-08
Local loss @ local epoch 3: 2.167441515155133e-08
Local loss @ local epoch 4: 3.2511618286434896e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.82 seconds!
[tester] 
AGNewsMetric: acc=0.8398684210526316, hinge=3.3657087774025767, ce=9.601776177255731
Local test acc @ epoch 204: 0.8399
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 2.5470102627878077e-05
Local loss @ local epoch 1: 3.973642748178463e-08
Local loss @ local epoch 2: 3.5762778338721546e-07
Local loss @ local epoch 3: 4.331243417254882e-06
Local loss @ local epoch 4: 4.3710062413993e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.34 seconds!
[tester] 
AGNewsMetric: acc=0.48644736842105263, hinge=9.955584186754729, ce=15.222339379160028
Local test acc @ epoch 204: 0.4864
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 5.9604641222676946e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.72 seconds!
[tester] 
AGNewsMetric: acc=0.8371052631578947, hinge=3.550020791354932, ce=9.505498482553582
Local test acc @ epoch 204: 0.8371
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 9.934106870446158e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 3.973642392907095e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.38 seconds!
[tester] 
AGNewsMetric: acc=0.8371052631578947, hinge=3.4301678843247263, ce=9.579119015743858
Local test acc @ epoch 204: 0.8371
Global evaluate on test data...
Evaluate data in 123.67 seconds!
[tester] 
AGNewsMetric: acc=0.8531578947368421, hinge=2.9426473803269237, ce=9.123449767263311
Global test acc @ epoch 204: 0.8532
Global epoch 205...
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 9.53674117454284e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.1 seconds!
[tester] 
AGNewsMetric: acc=0.8081578947368421, hinge=3.952207226000334, ce=10.100421353390342
Local test acc @ epoch 205: 0.8082
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 8.145935339598509e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.351211479544872e-07
Local loss @ local epoch 3: 1.7583225826456328e-06
Local loss @ local epoch 4: 1.8058271962217987e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.61 seconds!
[tester] 
AGNewsMetric: acc=0.5467105263157894, hinge=11.801819217079563, ce=14.996533937956157
Local test acc @ epoch 205: 0.5467
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 3.65574862826179e-07
Local loss @ local epoch 1: 3.9736416823643594e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.15409618616104126
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.72 seconds!
[tester] 
AGNewsMetric: acc=0.7292105263157894, hinge=6.532173945778295, ce=12.577322710940713
Local test acc @ epoch 205: 0.7292
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 6.641656682404573e-07
Local loss @ local epoch 1: 4.138252279517474e-06
Local loss @ local epoch 2: 2.8490068871178664e-05
Local loss @ local epoch 3: 0.9358922839164734
Local loss @ local epoch 4: 0.0015322808176279068
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.01 seconds!
[tester] 
AGNewsMetric: acc=0.71, hinge=3.595177005466662, ce=10.01844973313181
Local test acc @ epoch 205: 0.71
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 2.9802320611338473e-08
Local loss @ local epoch 1: 7.15254714123148e-07
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 5.960463766996327e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.53 seconds!
[tester] 
AGNewsMetric: acc=0.8427631578947369, hinge=2.9989089481454148, ce=8.699579299123664
Local test acc @ epoch 205: 0.8428
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 6.491280146292411e-06
Local loss @ local epoch 1: 4.334882675038898e-08
Local loss @ local epoch 2: 1.2245972129676375e-06
Local loss @ local epoch 3: 1.6059093475341797
Local loss @ local epoch 4: 6.39299105387181e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.09 seconds!
[tester] 
AGNewsMetric: acc=0.8253947368421053, hinge=3.4445233723991797, ce=8.806304712797466
Local test acc @ epoch 205: 0.8254
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4156096028727916e-07
Local loss @ local epoch 1: 1.4901159417490817e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 3.725289587919178e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.02 seconds!
[tester] 
AGNewsMetric: acc=0.6844736842105263, hinge=8.130567414635106, ce=13.139492779781945
Local test acc @ epoch 205: 0.6845
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 3.973642748178463e-08
Local loss @ local epoch 1: 1.1920928244535389e-07
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.1920928244535389e-07
Local loss @ local epoch 4: 2.3841853646899835e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.96 seconds!
[tester] 
AGNewsMetric: acc=0.6017105263157895, hinge=9.161325805061741, ce=13.40608349448756
Local test acc @ epoch 205: 0.6017
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 5.960463411724959e-08
Local loss @ local epoch 1: 4.967053257587395e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 9.934106870446158e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.43 seconds!
[tester] 
AGNewsMetric: acc=0.8064473684210526, hinge=4.106232322893645, ce=9.877363443876568
Local test acc @ epoch 205: 0.8064
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 4.334882675038898e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 6.502322946744243e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.17 seconds!
[tester] 
AGNewsMetric: acc=0.7643421052631579, hinge=5.2161334173302905, ce=10.604816780090331
Local test acc @ epoch 205: 0.7643
Global evaluate on test data...
Evaluate data in 123.86 seconds!
[tester] 
AGNewsMetric: acc=0.8468421052631578, hinge=3.161759731016661, ce=9.00713157051488
Global test acc @ epoch 205: 0.8468
Global epoch 206...
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.9802320611338473e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.34 seconds!
[tester] 
AGNewsMetric: acc=0.8539473684210527, hinge=2.9060464217788295, ce=9.246384855571547
Local test acc @ epoch 206: 0.8539
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 3.7749529724351305e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 4.967052902316027e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.32 seconds!
[tester] 
AGNewsMetric: acc=0.8081578947368421, hinge=4.1616515724282515, ce=9.920725894727205
Local test acc @ epoch 206: 0.8082
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 1.2431802360879374e-06
Local loss @ local epoch 1: 5.79015818402695e-07
Local loss @ local epoch 2: 5.449557534120686e-07
Local loss @ local epoch 3: 1.4134753882899531e-06
Local loss @ local epoch 4: 1.5326907032431336e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.77 seconds!
[tester] 
AGNewsMetric: acc=0.6639473684210526, hinge=7.93341510371158, ce=12.60985033135665
Local test acc @ epoch 206: 0.6639
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 1.9868211964535476e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.9802317058624794e-08
Local loss @ local epoch 3: 2.9802317058624794e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.81 seconds!
[tester] 
AGNewsMetric: acc=0.8506578947368421, hinge=3.006671246478432, ce=9.149333739029734
Local test acc @ epoch 206: 0.8507
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450579175838357e-08
Local loss @ local epoch 1: 1.7136315477728203e-07
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.24 seconds!
[tester] 
AGNewsMetric: acc=0.7243421052631579, hinge=6.362309152703536, ce=11.514725761413574
Local test acc @ epoch 206: 0.7243
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.167441515155133e-08
Local loss @ local epoch 2: 3.1427862268174067e-07
Local loss @ local epoch 3: 5.418602455620203e-08
Local loss @ local epoch 4: 3.6087205899093533e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.84 seconds!
[tester] 
AGNewsMetric: acc=0.7838157894736842, hinge=4.404868549673181, ce=10.139682316027189
Local test acc @ epoch 206: 0.7838
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.2 seconds!
[tester] 
AGNewsMetric: acc=0.8486842105263158, hinge=3.115450599946474, ce=9.101352255971808
Local test acc @ epoch 206: 0.8487
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 1.6711066564312205e-05
Local loss @ local epoch 1: 3.973642392907095e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.5894569216357013e-08
Local loss @ local epoch 4: 3.1789141985427705e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.35 seconds!
[tester] 
AGNewsMetric: acc=0.525921052631579, hinge=12.06257253446077, ce=16.60352307972155
Local test acc @ epoch 206: 0.5259
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 2.3841850804728892e-07
Local loss @ local epoch 1: 7.94728478581419e-08
Local loss @ local epoch 2: 3.973642748178463e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 3.973642748178463e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.95 seconds!
[tester] 
AGNewsMetric: acc=0.7061842105263157, hinge=5.524104929472271, ce=11.939401319403398
Local test acc @ epoch 206: 0.7062
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.384185648907078e-08
Local loss @ local epoch 3: 2.384185648907078e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.49 seconds!
[tester] 
AGNewsMetric: acc=0.8578947368421053, hinge=2.6467858339610855, ce=9.461241846586528
Local test acc @ epoch 206: 0.8579
Global evaluate on test data...
Evaluate data in 123.49 seconds!
[tester] 
AGNewsMetric: acc=0.8552631578947368, hinge=2.9749983546608374, ce=9.031173645822625
Global test acc @ epoch 206: 0.8553
Global epoch 207...
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 5.852076583323651e-07
Local loss @ local epoch 1: 6.502323657286979e-08
Local loss @ local epoch 2: 4.334882675038898e-08
Local loss @ local epoch 3: 1.0620407238093321e-06
Local loss @ local epoch 4: 8.669765350077796e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 122.83 seconds!
[tester] 
AGNewsMetric: acc=0.7031578947368421, hinge=6.862934698556598, ce=11.763751927425988
Local test acc @ epoch 207: 0.7032
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.8016030788421631
Local loss @ local epoch 1: 3.973642748178463e-08
Local loss @ local epoch 2: 4.3710056729651114e-07
Local loss @ local epoch 3: 2.344445420021657e-06
Local loss @ local epoch 4: 2.4913819288485684e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.56 seconds!
[tester] 
AGNewsMetric: acc=0.42605263157894735, hinge=10.94153562244616, ce=15.330018726148104
Local test acc @ epoch 207: 0.4261
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.384185648907078e-08
Local loss @ local epoch 2: 4.768370942542788e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.85 seconds!
[tester] 
AGNewsMetric: acc=0.8352631578947368, hinge=3.4717515252765856, ce=9.66625709734465
Local test acc @ epoch 207: 0.8353
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 2.3513717678724788e-05
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.0837167110366863e-06
Local loss @ local epoch 4: 4.4432479739953123e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.43 seconds!
[tester] 
AGNewsMetric: acc=0.4122368421052632, hinge=15.377363286269338, ce=18.763122586702046
Local test acc @ epoch 207: 0.4122
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 4.967053257587395e-08
Local loss @ local epoch 1: 1.1920920428565296e-07
Local loss @ local epoch 2: 7.947281943643247e-08
Local loss @ local epoch 3: 9.934106870446158e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.41 seconds!
[tester] 
AGNewsMetric: acc=0.7868421052631579, hinge=4.995031332969665, ce=10.552717744927657
Local test acc @ epoch 207: 0.7868
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 9.70702558333869e-07
Local loss @ local epoch 1: 4.410680503497133e-06
Local loss @ local epoch 2: 5.960460498499742e-07
Local loss @ local epoch 3: 6.130758265499026e-07
Local loss @ local epoch 4: 3.4723925590515137
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.7 seconds!
[tester] 
AGNewsMetric: acc=0.8247368421052632, hinge=3.2041723115820635, ce=9.426918915196469
Local test acc @ epoch 207: 0.8247
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 3.576276128569589e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.62 seconds!
[tester] 
AGNewsMetric: acc=0.7825, hinge=5.026895313513906, ce=10.37243166672556
Local test acc @ epoch 207: 0.7825
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 1.078972578048706
Local loss @ local epoch 1: 1.5894569216357013e-08
Local loss @ local epoch 2: 1.5894569216357013e-08
Local loss @ local epoch 3: 0.0024700367357581854
Local loss @ local epoch 4: 3.1789138432714026e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.07 seconds!
[tester] 
AGNewsMetric: acc=0.6488157894736842, hinge=7.9802621018259146, ce=13.353564673975894
Local test acc @ epoch 207: 0.6488
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 1.986820308275128e-07
Local loss @ local epoch 1: 9.934106870446158e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.947284075271455e-08
Local loss @ local epoch 4: 4.0729787542659324e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.32 seconds!
[tester] 
AGNewsMetric: acc=0.6114473684210526, hinge=10.156060530386473, ce=14.529184865449604
Local test acc @ epoch 207: 0.6114
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 5.960463056453591e-08
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 1.4901159417490817e-08
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.99 seconds!
[tester] 
AGNewsMetric: acc=0.7409210526315789, hinge=6.329991832030447, ce=11.980753485027112
Local test acc @ epoch 207: 0.7409
Global evaluate on test data...
Evaluate data in 123.02 seconds!
[tester] 
AGNewsMetric: acc=0.8444736842105263, hinge=3.3324150774353427, ce=9.176409090945596
Global test acc @ epoch 207: 0.8445
Global epoch 208...
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 9.934106870446158e-09
Local loss @ local epoch 1: 9.934106870446158e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.9868211964535476e-08
Local loss @ local epoch 4: 1.9868213740892315e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.55 seconds!
[tester] 
AGNewsMetric: acc=0.8444736842105263, hinge=3.2208868679247407, ce=9.367076389915065
Local test acc @ epoch 208: 0.8445
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 1.4305090871857828e-06
Local loss @ local epoch 1: 3.746576453522721e-07
Local loss @ local epoch 2: 1.0047626801679144e-06
Local loss @ local epoch 3: 7.492984877899289e-06
Local loss @ local epoch 4: 2.009521949730697e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.9 seconds!
[tester] 
AGNewsMetric: acc=0.5721052631578948, hinge=9.889601411317525, ce=14.4035099651939
Local test acc @ epoch 208: 0.5721
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 9.934106870446158e-09
Local loss @ local epoch 1: 9.934106870446158e-09
Local loss @ local epoch 2: 9.934106870446158e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.71 seconds!
[tester] 
AGNewsMetric: acc=0.8427631578947369, hinge=3.194454318849664, ce=9.21016083566766
Local test acc @ epoch 208: 0.8428
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 4.334882675038898e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.014670505188405514
Local loss @ local epoch 3: 4.33488231976753e-08
Local loss @ local epoch 4: 6.502322946744243e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.52 seconds!
[tester] 
AGNewsMetric: acc=0.7189473684210527, hinge=6.887380486538536, ce=11.98614668795937
Local test acc @ epoch 208: 0.7189
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.00017834962636698037
Local loss @ local epoch 1: 0.00019182832329533994
Local loss @ local epoch 2: 0.27837860584259033
Local loss @ local epoch 3: 4.1325844790662813e-07
Local loss @ local epoch 4: 0.00032946121064014733
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.89 seconds!
[tester] 
AGNewsMetric: acc=0.8575, hinge=2.458402216810929, ce=9.058575851038883
Local test acc @ epoch 208: 0.8575
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.682207878024201e-07
Local loss @ local epoch 2: 2.682208162241295e-07
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.9802320611338473e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.89 seconds!
[tester] 
AGNewsMetric: acc=0.7713157894736842, hinge=4.660735379771182, ce=10.325836737783332
Local test acc @ epoch 208: 0.7713
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 3.2511621839148575e-08
Local loss @ local epoch 4: 4.150556378590409e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.07 seconds!
[tester] 
AGNewsMetric: acc=0.781578947368421, hinge=5.054027600037424, ce=10.915556293286775
Local test acc @ epoch 208: 0.7816
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 1.9073476664743794e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.65 seconds!
[tester] 
AGNewsMetric: acc=0.7280263157894736, hinge=5.688277107037996, ce=10.770850462662546
Local test acc @ epoch 208: 0.728
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 5.960459361631365e-07
Local loss @ local epoch 1: 5.284904545987956e-06
Local loss @ local epoch 2: 8.543292096874211e-06
Local loss @ local epoch 3: 0.00010504914098419249
Local loss @ local epoch 4: 6.477006991190137e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.89 seconds!
[tester] 
AGNewsMetric: acc=0.8338157894736842, hinge=2.8417409413739256, ce=10.041722179212067
Local test acc @ epoch 208: 0.8338
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.415609887089886e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 8.940690321423972e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.54 seconds!
[tester] 
AGNewsMetric: acc=0.6490789473684211, hinge=8.504318711130242, ce=14.184923475165116
Local test acc @ epoch 208: 0.6491
Global evaluate on test data...
Evaluate data in 123.84 seconds!
[tester] 
AGNewsMetric: acc=0.8601315789473685, hinge=2.9495747224908127, ce=9.051021654229416
Global test acc @ epoch 208: 0.8601
Global epoch 209...
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.9802320611338473e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.79 seconds!
[tester] 
AGNewsMetric: acc=0.8565789473684211, hinge=2.9739197193948845, ce=9.116709492332056
Local test acc @ epoch 209: 0.8566
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0001268161431653425
Local loss @ local epoch 1: 2.167441515155133e-08
Local loss @ local epoch 2: 2.926043407569523e-07
Local loss @ local epoch 3: 2.4792236217763275e-05
Local loss @ local epoch 4: 9.731311365612783e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.54 seconds!
[tester] 
AGNewsMetric: acc=0.45631578947368423, hinge=14.219369962591873, ce=17.727847707648028
Local test acc @ epoch 209: 0.4563
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 3.3378583452758903e-07
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.88 seconds!
[tester] 
AGNewsMetric: acc=0.815921052631579, hinge=3.8471883714826483, ce=9.28764496050383
Local test acc @ epoch 209: 0.8159
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 7.057016773615032e-05
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 1.415610029198433e-07
Local loss @ local epoch 3: 4.1723220078893064e-07
Local loss @ local epoch 4: 1.981838977371808e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.79 seconds!
[tester] 
AGNewsMetric: acc=0.6498684210526315, hinge=8.41685571770919, ce=13.675608837730007
Local test acc @ epoch 209: 0.6499
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 1.343807980447309e-06
Local loss @ local epoch 1: 1.3004645893488487e-07
Local loss @ local epoch 2: 1.1378998578948085e-06
Local loss @ local epoch 3: 2.7851413051394047e-06
Local loss @ local epoch 4: 1.0837202069069463e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.37 seconds!
[tester] 
AGNewsMetric: acc=0.7069736842105263, hinge=6.984750486675062, ce=12.071274709199605
Local test acc @ epoch 209: 0.707
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 4.6094126560092263e-07
Local loss @ local epoch 1: 7.947285496356926e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.152555525635762e-08
Local loss @ local epoch 4: 0.22482576966285706
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.21 seconds!
[tester] 
AGNewsMetric: acc=0.6873684210526316, hinge=7.625712230581986, ce=13.37567402488307
Local test acc @ epoch 209: 0.6874
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 2.3841853646899835e-07
Local loss @ local epoch 1: 1.986821303034958e-07
Local loss @ local epoch 2: 8.657553553348407e-05
Local loss @ local epoch 3: 3.727087823790498e-05
Local loss @ local epoch 4: 1.8278720972375595e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.96 seconds!
[tester] 
AGNewsMetric: acc=0.4494736842105263, hinge=10.73782049279464, ce=15.115532812821238
Local test acc @ epoch 209: 0.4495
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 2.503362111383467e-06
Local loss @ local epoch 1: 5.960463411724959e-08
Local loss @ local epoch 2: 5.265064260129293e-07
Local loss @ local epoch 3: 4.34112780567375e-06
Local loss @ local epoch 4: 1.2914334490687907e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.76 seconds!
[tester] 
AGNewsMetric: acc=0.5285526315789474, hinge=11.182817879225079, ce=15.172969785991468
Local test acc @ epoch 209: 0.5286
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 5.3845393267693e-05
Local loss @ local epoch 1: 9.934103673003847e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 4.956973498337902e-06
Local loss @ local epoch 4: 0.03317476809024811
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.36 seconds!
[tester] 
AGNewsMetric: acc=0.5902631578947368, hinge=9.917967521265933, ce=14.054509490163703
Local test acc @ epoch 209: 0.5903
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 1.362391657266926e-07
Local loss @ local epoch 1: 1.2772408126693335e-06
Local loss @ local epoch 2: 5.771973519586027e-05
Local loss @ local epoch 3: 8.514948746096707e-08
Local loss @ local epoch 4: 1.8221950313090929e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.72 seconds!
[tester] 
AGNewsMetric: acc=0.8147368421052632, hinge=3.2983873846656397, ce=10.50439136906674
Local test acc @ epoch 209: 0.8147
Global evaluate on test data...
Evaluate data in 123.59 seconds!
[tester] 
AGNewsMetric: acc=0.8203947368421053, hinge=3.8748880789154456, ce=9.771936147589432
Global test acc @ epoch 209: 0.8204
Global epoch 210...
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 1.8732808939603274e-06
Local loss @ local epoch 1: 0.352920800447464
Local loss @ local epoch 2: 0.00017448978906031698
Local loss @ local epoch 3: 0.0037706010043621063
Local loss @ local epoch 4: 0.04976961761713028
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.11 seconds!
[tester] 
AGNewsMetric: acc=0.5007894736842106, hinge=5.314112991533781, ce=10.26298108351858
Local test acc @ epoch 210: 0.5008
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.0008101915591396391
Local loss @ local epoch 1: 7.867767521929636e-07
Local loss @ local epoch 2: 3.1789141985427705e-08
Local loss @ local epoch 3: 4.212052431284974e-07
Local loss @ local epoch 4: 1.1920926112907182e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.93 seconds!
[tester] 
AGNewsMetric: acc=0.7460526315789474, hinge=5.625482625961304, ce=10.992084908736379
Local test acc @ epoch 210: 0.7461
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 6.194616435095668e-05
Local loss @ local epoch 1: 2.2212350813788362e-05
Local loss @ local epoch 2: 6.755190611329454e-07
Local loss @ local epoch 3: 4.835780055145733e-05
Local loss @ local epoch 4: 0.0003158779873047024
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.98 seconds!
[tester] 
AGNewsMetric: acc=0.6713157894736842, hinge=3.766129630490353, ce=11.10459131140458
Local test acc @ epoch 210: 0.6713
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 4.768370942542788e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.66 seconds!
[tester] 
AGNewsMetric: acc=0.829078947368421, hinge=3.481272788800691, ce=9.028474805731522
Local test acc @ epoch 210: 0.8291
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.004510954022407532
Local loss @ local epoch 1: 1.4901152667334827e-07
Local loss @ local epoch 2: 2.2351740014414645e-08
Local loss @ local epoch 3: 1.4156088923300558e-07
Local loss @ local epoch 4: 1.5646213569198153e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.89 seconds!
[tester] 
AGNewsMetric: acc=0.6540789473684211, hinge=8.28105662120016, ce=12.957759547986482
Local test acc @ epoch 210: 0.6541
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 2.9802317058624794e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 9.934106870446158e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.947283364728719e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 125.12 seconds!
[tester] 
AGNewsMetric: acc=0.8297368421052631, hinge=3.467899371699283, ce=9.097071067408512
Local test acc @ epoch 210: 0.8297
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 3.2511621839148575e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.97 seconds!
[tester] 
AGNewsMetric: acc=0.824078947368421, hinge=3.7986195921897887, ce=9.573173091286106
Local test acc @ epoch 210: 0.8241
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 1.0837207575775665e-08
Local loss @ local epoch 1: 3.2511621839148575e-08
Local loss @ local epoch 2: 8.66976463953506e-08
Local loss @ local epoch 3: 1.0837207575775665e-08
Local loss @ local epoch 4: 3.2511621839148575e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.86 seconds!
[tester] 
AGNewsMetric: acc=0.8061842105263158, hinge=4.243171687753577, ce=10.00526045749062
Local test acc @ epoch 210: 0.8062
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 6.556502967214328e-07
Local loss @ local epoch 1: 8.940695295223122e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.9802320611338473e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.1 seconds!
[tester] 
AGNewsMetric: acc=0.7598684210526315, hinge=5.2475798230422175, ce=11.070232104251259
Local test acc @ epoch 210: 0.7599
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 2.9802320611338473e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 9.934106870446158e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.53 seconds!
[tester] 
AGNewsMetric: acc=0.8381578947368421, hinge=3.0905511787063196, ce=9.13659234297903
Local test acc @ epoch 210: 0.8382
Global evaluate on test data...
Evaluate data in 123.51 seconds!
[tester] 
AGNewsMetric: acc=0.8314473684210526, hinge=3.514412445018166, ce=9.516990705791272
Global test acc @ epoch 210: 0.8314
Global epoch 211...
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 3.9571824073791504
Local loss @ local epoch 1: 7.586042727325548e-08
Local loss @ local epoch 2: 1.7339520752557291e-07
Local loss @ local epoch 3: 1.2050181794620585e-05
Local loss @ local epoch 4: 0.0647391825914383
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.39 seconds!
[tester] 
AGNewsMetric: acc=0.5747368421052632, hinge=12.15117541664525, ce=15.35453738162392
Local test acc @ epoch 211: 0.5747
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 2.384185648907078e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 4.768371297814156e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.64 seconds!
[tester] 
AGNewsMetric: acc=0.7848684210526315, hinge=4.866612144269442, ce=10.874708796049418
Local test acc @ epoch 211: 0.7849
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.9469337463378906
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 9.934106870446158e-09
Local loss @ local epoch 3: 4.86770204588538e-07
Local loss @ local epoch 4: 3.625871840995387e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.83 seconds!
[tester] 
AGNewsMetric: acc=0.640921052631579, hinge=8.50581180974057, ce=13.792573276319002
Local test acc @ epoch 211: 0.6409
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 8.940696005765858e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.75 seconds!
[tester] 
AGNewsMetric: acc=0.8564473684210526, hinge=2.8681373439337077, ce=9.043124578375565
Local test acc @ epoch 211: 0.8564
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 5.165733796275163e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.3841850804728892e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.74 seconds!
[tester] 
AGNewsMetric: acc=0.6378947368421053, hinge=7.230212570993523, ce=13.50632416373805
Local test acc @ epoch 211: 0.6379
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.384185648907078e-08
Local loss @ local epoch 4: 4.768371297814156e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.68 seconds!
[tester] 
AGNewsMetric: acc=0.7734210526315789, hinge=4.44352459192276, ce=11.16779592614425
Local test acc @ epoch 211: 0.7734
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 2.6281867027282715
Local loss @ local epoch 1: 0.00010270514758303761
Local loss @ local epoch 2: 9.934106870446158e-09
Local loss @ local epoch 3: 1.0927514182412779e-07
Local loss @ local epoch 4: 2.9802320611338473e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.27 seconds!
[tester] 
AGNewsMetric: acc=0.6447368421052632, hinge=8.212056388102079, ce=12.27699686953896
Local test acc @ epoch 211: 0.6447
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 5.960461635368119e-07
Local loss @ local epoch 1: 1.8732885109784547e-07
Local loss @ local epoch 2: 1.1920925402364446e-07
Local loss @ local epoch 3: 9.366430617774313e-07
Local loss @ local epoch 4: 9.604540537111461e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.85 seconds!
[tester] 
AGNewsMetric: acc=0.7336842105263158, hinge=5.430842387550755, ce=11.199211030257375
Local test acc @ epoch 211: 0.7337
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.8323650360107422
Local loss @ local epoch 1: 2.2758116813292872e-07
Local loss @ local epoch 2: 9.753482999030894e-08
Local loss @ local epoch 3: 1.0837207575775665e-08
Local loss @ local epoch 4: 2.167441515155133e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.16 seconds!
[tester] 
AGNewsMetric: acc=0.6681578947368421, hinge=7.6814052707270575, ce=12.224728367454126
Local test acc @ epoch 211: 0.6682
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 2.9802315282267955e-08
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 8.195634393359796e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.47 seconds!
[tester] 
AGNewsMetric: acc=0.8155263157894737, hinge=4.0143780715842, ce=9.92264817890368
Local test acc @ epoch 211: 0.8155
Global evaluate on test data...
Evaluate data in 123.46 seconds!
[tester] 
AGNewsMetric: acc=0.8496052631578948, hinge=3.034398591769369, ce=9.101302185058593
Global test acc @ epoch 211: 0.8496
Global epoch 212...
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.00011807723058154806
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 2.0116542032155849e-07
Local loss @ local epoch 3: 6.705521116145974e-08
Local loss @ local epoch 4: 3.5017683330806904e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.57 seconds!
[tester] 
AGNewsMetric: acc=0.6175, hinge=8.644623698184365, ce=14.309003149333753
Local test acc @ epoch 212: 0.6175
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.9868213740892315e-08
Local loss @ local epoch 2: 2.9802320611338473e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.82 seconds!
[tester] 
AGNewsMetric: acc=0.8373684210526315, hinge=3.3446836013542978, ce=9.433290525737561
Local test acc @ epoch 212: 0.8374
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 6.755190042895265e-07
Local loss @ local epoch 1: 5.960461635368119e-07
Local loss @ local epoch 2: 3.973642748178463e-08
Local loss @ local epoch 3: 7.94728478581419e-08
Local loss @ local epoch 4: 1.0768416359496769e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.92 seconds!
[tester] 
AGNewsMetric: acc=0.8309210526315789, hinge=3.141328125, ce=9.310394483867444
Local test acc @ epoch 212: 0.8309
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.167441337519449e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.167441515155133e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.15 seconds!
[tester] 
AGNewsMetric: acc=0.8301315789473684, hinge=3.4861861143614115, ce=9.601517888119346
Local test acc @ epoch 212: 0.8301
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 2.384185648907078e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.5 seconds!
[tester] 
AGNewsMetric: acc=0.8317105263157895, hinge=3.3085754954187494, ce=10.208260582371762
Local test acc @ epoch 212: 0.8317
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.641770601272583
Local loss @ local epoch 1: 1.3024377039982937e-05
Local loss @ local epoch 2: 1.6689294568550395e-07
Local loss @ local epoch 3: 0.0013613804476335645
Local loss @ local epoch 4: 8.467143925372511e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.5 seconds!
[tester] 
AGNewsMetric: acc=0.6327631578947368, hinge=7.400714641119304, ce=13.374581314890008
Local test acc @ epoch 212: 0.6328
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 2.9802305334669654e-07
Local loss @ local epoch 1: 5.960463766996327e-08
Local loss @ local epoch 2: 1.4901156930591242e-07
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.88 seconds!
[tester] 
AGNewsMetric: acc=0.8482894736842105, hinge=3.0089596877600018, ce=8.996803372031764
Local test acc @ epoch 212: 0.8483
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0001964144903467968
Local loss @ local epoch 1: 1.0217938495316048e-07
Local loss @ local epoch 2: 1.1682371223287191e-05
Local loss @ local epoch 3: 8.685129614605103e-06
Local loss @ local epoch 4: 1.5121842807275243e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.22 seconds!
[tester] 
AGNewsMetric: acc=0.6427631578947368, hinge=7.408978619826468, ce=11.89371951053017
Local test acc @ epoch 212: 0.6428
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 1.0837202069069463e-07
Local loss @ local epoch 1: 5.526969744096277e-07
Local loss @ local epoch 2: 5.4186031661629386e-08
Local loss @ local epoch 3: 1.9723509012692375e-06
Local loss @ local epoch 4: 2.7092980303677905e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.75 seconds!
[tester] 
AGNewsMetric: acc=0.8113157894736842, hinge=3.9048989720093576, ce=9.718318182292737
Local test acc @ epoch 212: 0.8113
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 9.934106870446158e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 9.934106870446158e-09
Local loss @ local epoch 3: 9.934106870446158e-09
Local loss @ local epoch 4: 6.953873565862523e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.52 seconds!
[tester] 
AGNewsMetric: acc=0.8452631578947368, hinge=3.1267713765094154, ce=9.17617431640625
Local test acc @ epoch 212: 0.8453
Global evaluate on test data...
Evaluate data in 123.91 seconds!
[tester] 
AGNewsMetric: acc=0.8503947368421053, hinge=3.0312710627756623, ce=9.170492609927528
Global test acc @ epoch 212: 0.8504
Global epoch 213...
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.384185648907078e-08
Local loss @ local epoch 2: 4.768371297814156e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.89 seconds!
[tester] 
AGNewsMetric: acc=0.8507894736842105, hinge=2.9487996932079916, ce=9.233783932736046
Local test acc @ epoch 213: 0.8508
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 9.753485130659101e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.0837207575775665e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.49 seconds!
[tester] 
AGNewsMetric: acc=0.7982894736842105, hinge=4.302257789310656, ce=9.900930079409951
Local test acc @ epoch 213: 0.7983
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.62 seconds!
[tester] 
AGNewsMetric: acc=0.8432894736842105, hinge=3.2916389986088403, ce=9.216671853316457
Local test acc @ epoch 213: 0.8433
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 6.079621016397141e-06
Local loss @ local epoch 1: 2.781549426345009e-07
Local loss @ local epoch 2: 6.755190611329454e-07
Local loss @ local epoch 3: 9.139367307398061e-07
Local loss @ local epoch 4: 0.000101074343547225
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.67 seconds!
[tester] 
AGNewsMetric: acc=0.5092105263157894, hinge=10.13609107770418, ce=14.453635567112974
Local test acc @ epoch 213: 0.5092
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 3.973642748178463e-08
Local loss @ local epoch 1: 7.947285496356926e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.947285496356926e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.7 seconds!
[tester] 
AGNewsMetric: acc=0.8269736842105263, hinge=3.7733747156042803, ce=9.891100371511358
Local test acc @ epoch 213: 0.827
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 7.37386380933458e-06
Local loss @ local epoch 1: 0.11336708068847656
Local loss @ local epoch 2: 7.612272838741774e-06
Local loss @ local epoch 3: 0.0005488666938617826
Local loss @ local epoch 4: 0.2906396985054016
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.73 seconds!
[tester] 
AGNewsMetric: acc=0.8439473684210527, hinge=2.7794351782296833, ce=8.666052400689376
Local test acc @ epoch 213: 0.8439
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 7.152527814469067e-07
Local loss @ local epoch 1: 4.370996009583905e-07
Local loss @ local epoch 2: 9.934106870446158e-09
Local loss @ local epoch 3: 1.9868213740892315e-08
Local loss @ local epoch 4: 1.4901154088420299e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.26 seconds!
[tester] 
AGNewsMetric: acc=0.7201315789473685, hinge=6.011958090631586, ce=11.92574153699373
Local test acc @ epoch 213: 0.7201
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 1.3654808981300448e-06
Local loss @ local epoch 1: 2.167441337519449e-08
Local loss @ local epoch 2: 7.260900360961386e-07
Local loss @ local epoch 3: 6.502323657286979e-08
Local loss @ local epoch 4: 0.00407841382548213
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.92 seconds!
[tester] 
AGNewsMetric: acc=0.7609210526315789, hinge=4.9164845669896975, ce=10.642297543977437
Local test acc @ epoch 213: 0.7609
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 4.695525058195926e-05
Local loss @ local epoch 1: 9.934106870446158e-09
Local loss @ local epoch 2: 9.934106870446158e-09
Local loss @ local epoch 3: 2.1855009890714427e-07
Local loss @ local epoch 4: 9.934105804632054e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.38 seconds!
[tester] 
AGNewsMetric: acc=0.4673684210526316, hinge=13.351039175736277, ce=17.057514716700503
Local test acc @ epoch 213: 0.4674
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 3.725289943190546e-08
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.42 seconds!
[tester] 
AGNewsMetric: acc=0.8272368421052632, hinge=3.700840518851029, ce=9.978264469347502
Local test acc @ epoch 213: 0.8272
Global evaluate on test data...
Evaluate data in 124.14 seconds!
[tester] 
AGNewsMetric: acc=0.8331578947368421, hinge=3.415084328024011, ce=9.40332231220446
Global test acc @ epoch 213: 0.8332
Global epoch 214...
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 2.167441337519449e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.0837207575775665e-08
Local loss @ local epoch 3: 1.0837207575775665e-08
Local loss @ local epoch 4: 8.669762507906853e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.89 seconds!
[tester] 
AGNewsMetric: acc=0.8375, hinge=3.192063920121444, ce=9.372192131845575
Local test acc @ epoch 214: 0.8375
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 5.3303074309951626e-06
Local loss @ local epoch 1: 4.921573690808145e-06
Local loss @ local epoch 2: 9.451425285078585e-06
Local loss @ local epoch 3: 1.1869612535519991e-05
Local loss @ local epoch 4: 9.503030014457181e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.81 seconds!
[tester] 
AGNewsMetric: acc=0.7786842105263158, hinge=3.8053537777850504, ce=10.776907969023052
Local test acc @ epoch 214: 0.7787
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 9.934106870446158e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.4901149825163884e-07
Local loss @ local epoch 4: 4.967052191773291e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.92 seconds!
[tester] 
AGNewsMetric: acc=0.8548684210526316, hinge=2.8457259323722437, ce=8.97021624113384
Local test acc @ epoch 214: 0.8549
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 7.649228450645751e-07
Local loss @ local epoch 1: 9.934106870446158e-09
Local loss @ local epoch 2: 6.953873565862523e-08
Local loss @ local epoch 3: 1.1920923981278975e-07
Local loss @ local epoch 4: 8.94029471965041e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.15 seconds!
[tester] 
AGNewsMetric: acc=0.49355263157894735, hinge=11.958261436663175, ce=16.183355482001055
Local test acc @ epoch 214: 0.4936
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 5.526958943846694e-07
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.0837207575775665e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.48 seconds!
[tester] 
AGNewsMetric: acc=0.8435526315789473, hinge=3.240750853889867, ce=9.215580544722707
Local test acc @ epoch 214: 0.8436
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.63 seconds!
[tester] 
AGNewsMetric: acc=0.8393421052631579, hinge=3.337847302085475, ce=9.653902312830875
Local test acc @ epoch 214: 0.8393
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.00034630767186172307
Local loss @ local epoch 1: 2.384185648907078e-08
Local loss @ local epoch 2: 7.947285496356926e-09
Local loss @ local epoch 3: 1.271565395200014e-07
Local loss @ local epoch 4: 1.072822942660423e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.85 seconds!
[tester] 
AGNewsMetric: acc=0.5796052631578947, hinge=10.174393528386167, ce=14.908075541446083
Local test acc @ epoch 214: 0.5796
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.15022359788417816
Local loss @ local epoch 1: 3.6507785239336954e-07
Local loss @ local epoch 2: 3.1292415769712534e-07
Local loss @ local epoch 3: 6.332989528345934e-07
Local loss @ local epoch 4: 1.2114089258830063e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.9 seconds!
[tester] 
AGNewsMetric: acc=0.564078947368421, hinge=9.25149324115954, ce=13.813538507160388
Local test acc @ epoch 214: 0.5641
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 1.9868173239956377e-06
Local loss @ local epoch 1: 9.934093441188452e-07
Local loss @ local epoch 2: 1.1245255336689297e-05
Local loss @ local epoch 3: 5.455566497403197e-05
Local loss @ local epoch 4: 2.090099769702647e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.58 seconds!
[tester] 
AGNewsMetric: acc=0.495, hinge=7.571153036418714, ce=13.917073546961735
Local test acc @ epoch 214: 0.495
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.9802320611338473e-08
Local loss @ local epoch 4: 2.9802320611338473e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.37 seconds!
[tester] 
AGNewsMetric: acc=0.7988157894736843, hinge=4.042955764971281, ce=10.323882123043663
Local test acc @ epoch 214: 0.7988
Global evaluate on test data...
Evaluate data in 123.41 seconds!
[tester] 
AGNewsMetric: acc=0.848421052631579, hinge=3.110403451166655, ce=9.141977175662392
Global test acc @ epoch 214: 0.8484
Global epoch 215...
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.9 seconds!
[tester] 
AGNewsMetric: acc=0.45052631578947366, hinge=12.599315980610095, ce=17.778249867087915
Local test acc @ epoch 215: 0.4505
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 6.665529781457735e-06
Local loss @ local epoch 1: 3.973642037635727e-08
Local loss @ local epoch 2: 2.781546584174066e-07
Local loss @ local epoch 3: 0.042107563465833664
Local loss @ local epoch 4: 3.17891021950345e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.96 seconds!
[tester] 
AGNewsMetric: acc=0.7796052631578947, hinge=4.699016316815427, ce=10.614777994657818
Local test acc @ epoch 215: 0.7796
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 3.4967990814038785e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.5099834627108066e-07
Local loss @ local epoch 3: 1.5894570992713852e-08
Local loss @ local epoch 4: 7.947285496356926e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.61 seconds!
[tester] 
AGNewsMetric: acc=0.7726315789473684, hinge=4.652322570148267, ce=10.435862679732473
Local test acc @ epoch 215: 0.7726
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 1.1920927533992653e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.9802320611338473e-08
Local loss @ local epoch 3: 5.960463766996327e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.54 seconds!
[tester] 
AGNewsMetric: acc=0.8378947368421052, hinge=3.3893253418018943, ce=9.083151206970214
Local test acc @ epoch 215: 0.8379
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 3.973642748178463e-08
Local loss @ local epoch 1: 3.019956011485192e-06
Local loss @ local epoch 2: 4.092833933100337e-06
Local loss @ local epoch 3: 2.1854978058399865e-06
Local loss @ local epoch 4: 2.741806156336679e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.63 seconds!
[tester] 
AGNewsMetric: acc=0.5718421052631579, hinge=7.548829134890908, ce=12.597460198653371
Local test acc @ epoch 215: 0.5718
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 2.2351740014414645e-08
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 1.4901159417490817e-08
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.57 seconds!
[tester] 
AGNewsMetric: acc=0.7927631578947368, hinge=4.683089941677294, ce=10.40105476981715
Local test acc @ epoch 215: 0.7928
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 1.9868213740892315e-08
Local loss @ local epoch 1: 9.934106870446158e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.53 seconds!
[tester] 
AGNewsMetric: acc=0.8114473684210526, hinge=4.101819722526952, ce=10.221244832089074
Local test acc @ epoch 215: 0.8114
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 1.0837207575775665e-08
Local loss @ local epoch 1: 4.334882675038898e-08
Local loss @ local epoch 2: 3.2511621839148575e-08
Local loss @ local epoch 3: 2.167441515155133e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.48 seconds!
[tester] 
AGNewsMetric: acc=0.7307894736842105, hinge=6.57080100159896, ce=11.881492177059776
Local test acc @ epoch 215: 0.7308
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 4.938668212162156e-07
Local loss @ local epoch 1: 3.576277265437966e-07
Local loss @ local epoch 2: 0.26520341634750366
Local loss @ local epoch 3: 2.3277991203940473e-05
Local loss @ local epoch 4: 1.1920927533992653e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.69 seconds!
[tester] 
AGNewsMetric: acc=0.7256578947368421, hinge=5.6770325645647555, ce=11.55896578337017
Local test acc @ epoch 215: 0.7257
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 1.7231024003194761e-06
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.586042727325548e-08
Local loss @ local epoch 3: 1.4088358568642434e-07
Local loss @ local epoch 4: 1.0837207575775665e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.49 seconds!
[tester] 
AGNewsMetric: acc=0.4748684210526316, hinge=13.359587985590885, ce=16.9363452971609
Local test acc @ epoch 215: 0.4749
Global evaluate on test data...
Evaluate data in 123.87 seconds!
[tester] 
AGNewsMetric: acc=0.8465789473684211, hinge=3.1532456243665594, ce=9.037055079811498
Global test acc @ epoch 215: 0.8466
Global epoch 216...
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 4.33488231976753e-08
Local loss @ local epoch 1: 1.0837207575775665e-08
Local loss @ local epoch 2: 1.0837207575775665e-08
Local loss @ local epoch 3: 3.2511621839148575e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.75 seconds!
[tester] 
AGNewsMetric: acc=0.8428947368421053, hinge=3.21429922906976, ce=9.423556721335963
Local test acc @ epoch 216: 0.8429
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 5.06639196373726e-07
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.61 seconds!
[tester] 
AGNewsMetric: acc=0.8526315789473684, hinge=2.9742413124285245, ce=9.4074763287996
Local test acc @ epoch 216: 0.8526
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 4.3709982833206595e-07
Local loss @ local epoch 1: 2.3841833751703234e-07
Local loss @ local epoch 2: 7.947285496356926e-09
Local loss @ local epoch 3: 1.5894569216357013e-08
Local loss @ local epoch 4: 3.973642748178463e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.77 seconds!
[tester] 
AGNewsMetric: acc=0.7577631578947368, hinge=5.4468432890741445, ce=11.375241904007762
Local test acc @ epoch 216: 0.7578
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.384185648907078e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.384185648907078e-08
Local loss @ local epoch 4: 9.536741885085576e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.54 seconds!
[tester] 
AGNewsMetric: acc=0.8438157894736842, hinge=3.2194642701901888, ce=9.35399147234465
Local test acc @ epoch 216: 0.8438
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.002607494592666626
Local loss @ local epoch 1: 5.563098852690018e-07
Local loss @ local epoch 2: 6.357826691782975e-07
Local loss @ local epoch 3: 2.0265545117581496e-06
Local loss @ local epoch 4: 3.377585017005913e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.57 seconds!
[tester] 
AGNewsMetric: acc=0.5436842105263158, hinge=8.069841189133493, ce=12.75185202749152
Local test acc @ epoch 216: 0.5437
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 3.8316816244332585e-06
Local loss @ local epoch 1: 1.7727070371620357e-05
Local loss @ local epoch 2: 2.724783314533852e-07
Local loss @ local epoch 3: 3.4059783615703054e-07
Local loss @ local epoch 4: 1.2091206826880807e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.8 seconds!
[tester] 
AGNewsMetric: acc=0.7618421052631579, hinge=4.9881725946225615, ce=11.551382721348812
Local test acc @ epoch 216: 0.7618
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 5.4186035214343065e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 3.2511618286434896e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.08 seconds!
[tester] 
AGNewsMetric: acc=0.7390789473684211, hinge=6.082149005689119, ce=10.913461456298828
Local test acc @ epoch 216: 0.7391
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 9.934106870446158e-09
Local loss @ local epoch 3: 9.934106870446158e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.78 seconds!
[tester] 
AGNewsMetric: acc=0.8355263157894737, hinge=3.4639392747377094, ce=9.576166749251517
Local test acc @ epoch 216: 0.8355
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 3.725289587919178e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.93 seconds!
[tester] 
AGNewsMetric: acc=0.8461842105263158, hinge=3.2609547999030664, ce=9.57744153273733
Local test acc @ epoch 216: 0.8462
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 9.934106870446158e-09
Local loss @ local epoch 1: 1.9868211964535476e-08
Local loss @ local epoch 2: 7.947281943643247e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.18 seconds!
[tester] 
AGNewsMetric: acc=0.8123684210526316, hinge=4.1218011276345505, ce=10.06050738886783
Local test acc @ epoch 216: 0.8124
Global evaluate on test data...
Evaluate data in 123.75 seconds!
[tester] 
AGNewsMetric: acc=0.8467105263157895, hinge=3.173462202674464, ce=9.025141171907125
Global test acc @ epoch 216: 0.8467
Global epoch 217...
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 9.934106870446158e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 9.934106870446158e-09
Local loss @ local epoch 3: 9.934106870446158e-09
Local loss @ local epoch 4: 9.934106870446158e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.1 seconds!
[tester] 
AGNewsMetric: acc=0.843421052631579, hinge=3.3190919303894044, ce=9.268409078497635
Local test acc @ epoch 217: 0.8434
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 1.1920927533992653e-07
Local loss @ local epoch 1: 2.2138860344966815e-07
Local loss @ local epoch 2: 3.4059794984386826e-08
Local loss @ local epoch 3: 1.5326904190260393e-07
Local loss @ local epoch 4: 9.53672667947103e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.91 seconds!
[tester] 
AGNewsMetric: acc=0.7503947368421052, hinge=5.620912080062063, ce=11.640373488978335
Local test acc @ epoch 217: 0.7504
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0009871802758425474
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 1.4901159417490817e-08
Local loss @ local epoch 3: 1.1920923270736239e-07
Local loss @ local epoch 4: 3.9488026004619314e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.44 seconds!
[tester] 
AGNewsMetric: acc=0.5855263157894737, hinge=9.130294678336696, ce=15.212017559252287
Local test acc @ epoch 217: 0.5855
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 2.9802320611338473e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.66 seconds!
[tester] 
AGNewsMetric: acc=0.7118421052631579, hinge=7.720462748376947, ce=13.062453406484504
Local test acc @ epoch 217: 0.7118
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.9868213740892315e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 9.934106870446158e-09
Local loss @ local epoch 4: 6.953873565862523e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.63 seconds!
[tester] 
AGNewsMetric: acc=0.7972368421052631, hinge=4.382680825183266, ce=10.280924433657997
Local test acc @ epoch 217: 0.7972
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 3.604565063142218e-05
Local loss @ local epoch 3: 1.6689293147464923e-07
Local loss @ local epoch 4: 1.6689297410721338e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.49 seconds!
[tester] 
AGNewsMetric: acc=0.7039473684210527, hinge=6.061665295048764, ce=12.854690764577764
Local test acc @ epoch 217: 0.7039
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 5.960447424513404e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.8 seconds!
[tester] 
AGNewsMetric: acc=0.7023684210526315, hinge=6.5528739153711415, ce=10.992336787173622
Local test acc @ epoch 217: 0.7024
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.8701992034912109
Local loss @ local epoch 1: 7.947285496356926e-09
Local loss @ local epoch 2: 1.3510380370007624e-07
Local loss @ local epoch 3: 1.3510380370007624e-07
Local loss @ local epoch 4: 2.0503721316345036e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.81 seconds!
[tester] 
AGNewsMetric: acc=0.6656578947368421, hinge=6.979859287362349, ce=12.752176624097322
Local test acc @ epoch 217: 0.6657
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 3.1319009394792374e-06
Local loss @ local epoch 1: 2.167441337519449e-08
Local loss @ local epoch 2: 6.340822437778115e-05
Local loss @ local epoch 3: 1.6255806656317873e-07
Local loss @ local epoch 4: 2.167441515155133e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.49 seconds!
[tester] 
AGNewsMetric: acc=0.8530263157894736, hinge=3.067865443104192, ce=8.808130222119782
Local test acc @ epoch 217: 0.853
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 8.742006798456714e-07
Local loss @ local epoch 1: 1.1920926823449918e-07
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 3.5762778338721546e-07
Local loss @ local epoch 4: 0.00020168087212368846
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.42 seconds!
[tester] 
AGNewsMetric: acc=0.6430263157894737, hinge=8.381550872200414, ce=12.172677112378572
Local test acc @ epoch 217: 0.643
Global evaluate on test data...
Evaluate data in 123.56 seconds!
[tester] 
AGNewsMetric: acc=0.8364473684210526, hinge=3.4273313365484537, ce=9.50394127695184
Global test acc @ epoch 217: 0.8364
Global epoch 218...
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 1.621184856048785e-05
Local loss @ local epoch 1: 2.946157337646582e-06
Local loss @ local epoch 2: 4.7002031351439655e-06
Local loss @ local epoch 3: 0.7592353224754333
Local loss @ local epoch 4: 0.00011620639270404354
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.78 seconds!
[tester] 
AGNewsMetric: acc=0.775, hinge=3.828758780328851, ce=10.141080233925267
Local test acc @ epoch 218: 0.775
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 2.8053500500391237e-06
Local loss @ local epoch 1: 4.768370232000052e-08
Local loss @ local epoch 2: 7.947285496356926e-09
Local loss @ local epoch 3: 4.768371297814156e-08
Local loss @ local epoch 4: 8.742013335449883e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.6 seconds!
[tester] 
AGNewsMetric: acc=0.7742105263157895, hinge=4.694213183051661, ce=10.175644499126234
Local test acc @ epoch 218: 0.7742
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 125.1 seconds!
[tester] 
AGNewsMetric: acc=0.8280263157894737, hinge=3.6525589255282753, ce=9.719631684955798
Local test acc @ epoch 218: 0.828
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.9802320611338473e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.11 seconds!
[tester] 
AGNewsMetric: acc=0.8376315789473684, hinge=3.386599513856988, ce=9.324890480041503
Local test acc @ epoch 218: 0.8376
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 4.967040467818151e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 9.934106870446158e-09
Local loss @ local epoch 4: 4.569678537791333e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.29 seconds!
[tester] 
AGNewsMetric: acc=0.6203947368421052, hinge=8.44854541979338, ce=13.808478907534951
Local test acc @ epoch 218: 0.6204
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 4.470347292340193e-08
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.03 seconds!
[tester] 
AGNewsMetric: acc=0.8421052631578947, hinge=3.38860474774712, ce=9.355639154534591
Local test acc @ epoch 218: 0.8421
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 6.610673040086112e-07
Local loss @ local epoch 1: 6.068816560400592e-07
Local loss @ local epoch 2: 1.62558052352324e-07
Local loss @ local epoch 3: 1.860578777268529e-05
Local loss @ local epoch 4: 2.0590681515386677e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.11 seconds!
[tester] 
AGNewsMetric: acc=0.7936842105263158, hinge=4.527614472037867, ce=9.982401733398438
Local test acc @ epoch 218: 0.7937
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 3.2511618286434896e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.0837207575775665e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.93 seconds!
[tester] 
AGNewsMetric: acc=0.7823684210526316, hinge=5.135410238065218, ce=10.963953064366391
Local test acc @ epoch 218: 0.7824
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 5.563097715821641e-07
Local loss @ local epoch 1: 1.0331459634471685e-06
Local loss @ local epoch 2: 2.5033900783455465e-06
Local loss @ local epoch 3: 0.00043286095024086535
Local loss @ local epoch 4: 1.7126096281572245e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.12 seconds!
[tester] 
AGNewsMetric: acc=0.7288157894736842, hinge=4.569910836972689, ce=10.364684926083214
Local test acc @ epoch 218: 0.7288
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 6.953872144777051e-08
Local loss @ local epoch 2: 1.2715597677015467e-06
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 9.934106870446158e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.13 seconds!
[tester] 
AGNewsMetric: acc=0.6455263157894737, hinge=8.490732210058916, ce=13.44878386045757
Local test acc @ epoch 218: 0.6455
Global evaluate on test data...
Evaluate data in 124.3 seconds!
[tester] 
AGNewsMetric: acc=0.8461842105263158, hinge=3.2851927581586335, ce=9.159731563768888
Global test acc @ epoch 218: 0.8462
Global epoch 219...
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 2.9802320611338473e-08
Local loss @ local epoch 1: 2.9802320611338473e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.9802320611338473e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.86 seconds!
[tester] 
AGNewsMetric: acc=0.8375, hinge=3.3077944021475942, ce=9.179168504413806
Local test acc @ epoch 219: 0.8375
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.7334787249565125
Local loss @ local epoch 1: 6.357802249112865e-07
Local loss @ local epoch 2: 3.973642748178463e-08
Local loss @ local epoch 3: 3.3378566399733245e-07
Local loss @ local epoch 4: 5.563098781635745e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.07 seconds!
[tester] 
AGNewsMetric: acc=0.6477631578947368, hinge=7.282138385772705, ce=14.175979491785952
Local test acc @ epoch 219: 0.6478
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 3.2511621839148575e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 4.334882675038898e-08
Local loss @ local epoch 3: 6.502322946744243e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.52 seconds!
[tester] 
AGNewsMetric: acc=0.755, hinge=5.896891988704079, ce=11.24006830717388
Local test acc @ epoch 219: 0.755
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 1.1245222594880033e-05
Local loss @ local epoch 1: 6.357824418046221e-07
Local loss @ local epoch 2: 2.3841852225814364e-07
Local loss @ local epoch 3: 3.9736411849844444e-07
Local loss @ local epoch 4: 1.1920928244535389e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.05 seconds!
[tester] 
AGNewsMetric: acc=0.6286842105263157, hinge=8.293530389886154, ce=13.065330406992059
Local test acc @ epoch 219: 0.6287
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 3.973642037635727e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 9.934106870446158e-09
Local loss @ local epoch 3: 1.9868211964535476e-08
Local loss @ local epoch 4: 9.934106870446158e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.69 seconds!
[tester] 
AGNewsMetric: acc=0.8457894736842105, hinge=3.1404724633066277, ce=9.334878897415964
Local test acc @ epoch 219: 0.8458
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 1.1562852705537807e-05
Local loss @ local epoch 1: 1.3453593510348583e-06
Local loss @ local epoch 2: 1.4986268297434435e-06
Local loss @ local epoch 3: 3.405979143167315e-08
Local loss @ local epoch 4: 0.0002973916125483811
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.6 seconds!
[tester] 
AGNewsMetric: acc=0.713421052631579, hinge=5.567384732146012, ce=11.29027690084357
Local test acc @ epoch 219: 0.7134
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.1674391348369682e-07
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.586042727325548e-08
Local loss @ local epoch 4: 1.5172086875736568e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.42 seconds!
[tester] 
AGNewsMetric: acc=0.8311842105263157, hinge=3.468563928102192, ce=9.236953992341695
Local test acc @ epoch 219: 0.8312
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 4.7353583795484155e-05
Local loss @ local epoch 1: 2.2351738238057806e-08
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 2.0861610039446532e-07
Local loss @ local epoch 4: 4.842863745579962e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.91 seconds!
[tester] 
AGNewsMetric: acc=0.6228947368421053, hinge=8.013887326089959, ce=13.429384956359863
Local test acc @ epoch 219: 0.6229
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 9.934106870446158e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.23 seconds!
[tester] 
AGNewsMetric: acc=0.8243421052631579, hinge=3.837316476922286, ce=9.81940751125938
Local test acc @ epoch 219: 0.8243
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.384185648907078e-08
Local loss @ local epoch 4: 2.384185648907078e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.82 seconds!
[tester] 
AGNewsMetric: acc=0.8444736842105263, hinge=3.099710012109656, ce=9.298625598706698
Local test acc @ epoch 219: 0.8445
Global evaluate on test data...
Evaluate data in 124.83 seconds!
[tester] 
AGNewsMetric: acc=0.8522368421052632, hinge=3.1677720791415163, ce=9.129060399908768
Global test acc @ epoch 219: 0.8522
Global epoch 220...
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 2.9802320611338473e-08
Local loss @ local epoch 1: 1.9868213740892315e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 9.934106870446158e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.94 seconds!
[tester] 
AGNewsMetric: acc=0.8401315789473685, hinge=3.456401747527875, ce=9.176817791587428
Local test acc @ epoch 220: 0.8401
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.00023986835731193423
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.99 seconds!
[tester] 
AGNewsMetric: acc=0.7153947368421053, hinge=6.443318188315944, ce=12.04540415512888
Local test acc @ epoch 220: 0.7154
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 1.3907728089179727e-06
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.9868208767093165e-07
Local loss @ local epoch 3: 4.7683684556432127e-07
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.83 seconds!
[tester] 
AGNewsMetric: acc=0.7701315789473684, hinge=4.8837265506543615, ce=10.690125740452817
Local test acc @ epoch 220: 0.7701
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 9.536700531498354e-07
Local loss @ local epoch 1: 2.2351740014414645e-08
Local loss @ local epoch 2: 2.9802285439473053e-07
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.39 seconds!
[tester] 
AGNewsMetric: acc=0.616578947368421, hinge=10.074564610531455, ce=15.852446347286827
Local test acc @ epoch 220: 0.6166
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 2.492554642685718e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 4.909129074803786e-06
Local loss @ local epoch 3: 8.669765350077796e-08
Local loss @ local epoch 4: 3.4679041505114583e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.21 seconds!
[tester] 
AGNewsMetric: acc=0.8, hinge=4.382947542792873, ce=10.092117462158203
Local test acc @ epoch 220: 0.8
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0001888120750663802
Local loss @ local epoch 1: 6.81195828633463e-08
Local loss @ local epoch 2: 3.576277265437966e-07
Local loss @ local epoch 3: 6.999215202085907e-06
Local loss @ local epoch 4: 2.4182404558814596e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.79 seconds!
[tester] 
AGNewsMetric: acc=0.5909210526315789, hinge=8.013352163214433, ce=13.42085391195197
Local test acc @ epoch 220: 0.5909
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 3.4967982287525956e-07
Local loss @ local epoch 1: 7.947285496356926e-09
Local loss @ local epoch 2: 7.947285496356926e-09
Local loss @ local epoch 3: 7.947285496356926e-09
Local loss @ local epoch 4: 7.947285496356926e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.57 seconds!
[tester] 
AGNewsMetric: acc=0.654342105263158, hinge=8.471811079226041, ce=13.158696640416196
Local test acc @ epoch 220: 0.6543
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 5.9604641222676946e-08
Local loss @ local epoch 2: 5.781585059594363e-06
Local loss @ local epoch 3: 2.9802320611338473e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.83 seconds!
[tester] 
AGNewsMetric: acc=0.7032894736842106, hinge=6.780718493963542, ce=12.231824736344187
Local test acc @ epoch 220: 0.7033
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 9.53674117454284e-08
Local loss @ local epoch 3: 2.1457667287450022e-07
Local loss @ local epoch 4: 3.337858913710079e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.48 seconds!
[tester] 
AGNewsMetric: acc=0.6111842105263158, hinge=7.528859729766846, ce=13.683961404499255
Local test acc @ epoch 220: 0.6112
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.6822047516361636e-07
Local loss @ local epoch 3: 9.934106870446158e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.9 seconds!
[tester] 
AGNewsMetric: acc=0.6968421052631579, hinge=7.317373432862131, ce=12.639884970815558
Local test acc @ epoch 220: 0.6968
Global evaluate on test data...
Evaluate data in 124.08 seconds!
[tester] 
AGNewsMetric: acc=0.8448684210526316, hinge=3.379320857022938, ce=9.460892619082802
Global test acc @ epoch 220: 0.8449
Global epoch 221...
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 3.844470484182239e-06
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.9802320611338473e-08
Local loss @ local epoch 3: 2.9802320611338473e-08
Local loss @ local epoch 4: 1.221893057845591e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.15 seconds!
[tester] 
AGNewsMetric: acc=0.7988157894736843, hinge=4.201034471863195, ce=9.424286729913009
Local test acc @ epoch 221: 0.7988
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 7.947285496356926e-09
Local loss @ local epoch 1: 8.742013335449883e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.947285496356926e-09
Local loss @ local epoch 4: 3.973642748178463e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.38 seconds!
[tester] 
AGNewsMetric: acc=0.7672368421052631, hinge=5.9113262713582895, ce=11.697090395877236
Local test acc @ epoch 221: 0.7672
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 1.788138632718983e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.9868211964535476e-08
Local loss @ local epoch 3: 3.4769354329000635e-07
Local loss @ local epoch 4: 2.582864055966638e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.83 seconds!
[tester] 
AGNewsMetric: acc=0.5675, hinge=11.605026982959949, ce=15.936128897415964
Local test acc @ epoch 221: 0.5675
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450579175838357e-08
Local loss @ local epoch 1: 2.2351740014414645e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.4901159417490817e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.42 seconds!
[tester] 
AGNewsMetric: acc=0.8192105263157895, hinge=4.058541626428303, ce=9.69196819706967
Local test acc @ epoch 221: 0.8192
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 7.94728478581419e-08
Local loss @ local epoch 1: 3.973642748178463e-08
Local loss @ local epoch 2: 1.2318284916545963e-06
Local loss @ local epoch 3: 4.7683701609457785e-07
Local loss @ local epoch 4: 4.371005104530923e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.56 seconds!
[tester] 
AGNewsMetric: acc=0.4863157894736842, hinge=9.099293303238719, ce=13.841595330489309
Local test acc @ epoch 221: 0.4863
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 2.2138858923881344e-07
Local loss @ local epoch 1: 5.108969247658024e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 5.108968892386656e-08
Local loss @ local epoch 4: 3.320791392980027e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.22 seconds!
[tester] 
AGNewsMetric: acc=0.7852631578947369, hinge=4.51646710069556, ce=10.928940501965975
Local test acc @ epoch 221: 0.7853
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 1.9868211964535476e-08
Local loss @ local epoch 1: 1.9868213740892315e-08
Local loss @ local epoch 2: 9.934106870446158e-09
Local loss @ local epoch 3: 9.934106870446158e-09
Local loss @ local epoch 4: 1.9868211964535476e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.18 seconds!
[tester] 
AGNewsMetric: acc=0.848421052631579, hinge=3.1625745982872813, ce=9.319944166886179
Local test acc @ epoch 221: 0.8484
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 5.4186035214343065e-08
Local loss @ local epoch 1: 3.2511621839148575e-08
Local loss @ local epoch 2: 1.0837207575775665e-08
Local loss @ local epoch 3: 1.0837207575775665e-08
Local loss @ local epoch 4: 4.334882675038898e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.93 seconds!
[tester] 
AGNewsMetric: acc=0.8421052631578947, hinge=3.3346415743074918, ce=9.728407104893735
Local test acc @ epoch 221: 0.8421
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 7.152556236178498e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.51 seconds!
[tester] 
AGNewsMetric: acc=0.8343421052631579, hinge=3.526378753938173, ce=9.3467282887509
Local test acc @ epoch 221: 0.8343
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 2.167441337519449e-08
Local loss @ local epoch 1: 3.2511621839148575e-08
Local loss @ local epoch 2: 9.753482288488158e-08
Local loss @ local epoch 3: 1.0837207575775665e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.65 seconds!
[tester] 
AGNewsMetric: acc=0.7696052631578948, hinge=5.027829950232255, ce=10.449571904634174
Local test acc @ epoch 221: 0.7696
Global evaluate on test data...
Evaluate data in 124.51 seconds!
[tester] 
AGNewsMetric: acc=0.8531578947368421, hinge=3.107949931998002, ce=8.934327362462094
Global test acc @ epoch 221: 0.8532
Global epoch 222...
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0005808646092191339
Local loss @ local epoch 3: 9.934106870446158e-09
Local loss @ local epoch 4: 5.960463411724959e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.63 seconds!
[tester] 
AGNewsMetric: acc=0.6497368421052632, hinge=8.557055098884984, ce=13.807890697278474
Local test acc @ epoch 222: 0.6497
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 1.0837207575775665e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.167441337519449e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.3 seconds!
[tester] 
AGNewsMetric: acc=0.838421052631579, hinge=3.4556973582819888, ce=9.298821706269917
Local test acc @ epoch 222: 0.8384
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 8.514948746096707e-08
Local loss @ local epoch 1: 6.811958996877365e-08
Local loss @ local epoch 2: 5.108960863253742e-07
Local loss @ local epoch 3: 3.4059794984386826e-08
Local loss @ local epoch 4: 3.405979143167315e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.83 seconds!
[tester] 
AGNewsMetric: acc=0.7246052631578948, hinge=5.378210012034366, ce=11.833842713205438
Local test acc @ epoch 222: 0.7246
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 2.384185648907078e-08
Local loss @ local epoch 1: 2.384185648907078e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.32 seconds!
[tester] 
AGNewsMetric: acc=0.8502631578947368, hinge=3.274613013769451, ce=9.305674494693154
Local test acc @ epoch 222: 0.8503
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 8.940695295223122e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.7881387748275301e-07
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.63 seconds!
[tester] 
AGNewsMetric: acc=0.8527631578947369, hinge=3.057135866817675, ce=9.07610386497096
Local test acc @ epoch 222: 0.8528
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0010671394411474466
Local loss @ local epoch 1: 9.61117507358722e-07
Local loss @ local epoch 2: 5.215405707303944e-08
Local loss @ local epoch 3: 2.5331945607831585e-07
Local loss @ local epoch 4: 1.4437583558901679e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.68 seconds!
[tester] 
AGNewsMetric: acc=0.6036842105263158, hinge=9.135249878732782, ce=13.999922991300885
Local test acc @ epoch 222: 0.6037
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 8.669765350077796e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.0837207575775665e-08
Local loss @ local epoch 4: 6.502323657286979e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.93 seconds!
[tester] 
AGNewsMetric: acc=0.8393421052631579, hinge=3.3344801794855217, ce=9.415327232762387
Local test acc @ epoch 222: 0.8393
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 3.6756117083314166e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.36 seconds!
[tester] 
AGNewsMetric: acc=0.8552631578947368, hinge=2.990839690534692, ce=9.150985055220755
Local test acc @ epoch 222: 0.8553
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 3.973642748178463e-08
Local loss @ local epoch 1: 3.178913630108582e-07
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.54 seconds!
[tester] 
AGNewsMetric: acc=0.6742105263157895, hinge=7.187982116498445, ce=12.50019805506656
Local test acc @ epoch 222: 0.6742
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 1.1126196852728754e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 4.2915272047139297e-07
Local loss @ local epoch 3: 7.947285496356926e-09
Local loss @ local epoch 4: 1.5099834627108066e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.54 seconds!
[tester] 
AGNewsMetric: acc=0.7526315789473684, hinge=5.630971231460571, ce=11.5233319212261
Local test acc @ epoch 222: 0.7526
Global evaluate on test data...
Evaluate data in 123.82 seconds!
[tester] 
AGNewsMetric: acc=0.8518421052631578, hinge=3.190143232094614, ce=9.237668788307591
Global test acc @ epoch 222: 0.8518
Global epoch 223...
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 5.653815605910495e-06
Local loss @ local epoch 1: 6.81195828633463e-08
Local loss @ local epoch 2: 2.2290480046649463e-05
Local loss @ local epoch 3: 5.108969247658024e-08
Local loss @ local epoch 4: 3.2867521895241225e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.62 seconds!
[tester] 
AGNewsMetric: acc=0.6955263157894737, hinge=6.174040126549571, ce=11.745117723565352
Local test acc @ epoch 223: 0.6955
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 3.725289587919178e-08
Local loss @ local epoch 1: 3.7252892326478104e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.78813678530787e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.59 seconds!
[tester] 
AGNewsMetric: acc=0.8303947368421053, hinge=3.7469396406725832, ce=9.697895841096576
Local test acc @ epoch 223: 0.8304
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 8.095048542600125e-06
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.3129181861877441
Local loss @ local epoch 3: 1.8423247638565954e-07
Local loss @ local epoch 4: 2.059068293647215e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.26 seconds!
[tester] 
AGNewsMetric: acc=0.841842105263158, hinge=3.34394347881016, ce=9.416053326255398
Local test acc @ epoch 223: 0.8418
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 7.152555525635762e-08
Local loss @ local epoch 1: 3.9736416823643594e-08
Local loss @ local epoch 2: 7.947285496356926e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.5894569216357013e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.04 seconds!
[tester] 
AGNewsMetric: acc=0.7625, hinge=5.774852129283704, ce=11.793298211348684
Local test acc @ epoch 223: 0.7625
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 4.967053257587395e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.05 seconds!
[tester] 
AGNewsMetric: acc=0.8518421052631578, hinge=3.230061961851622, ce=9.419635192469547
Local test acc @ epoch 223: 0.8518
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 6.502323657286979e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.27 seconds!
[tester] 
AGNewsMetric: acc=0.6786842105263158, hinge=7.847570407265111, ce=12.918244520488539
Local test acc @ epoch 223: 0.6787
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 1.2059133041475434e-05
Local loss @ local epoch 1: 9.934106870446158e-09
Local loss @ local epoch 2: 2.9802320611338473e-08
Local loss @ local epoch 3: 2.3543509541923413e-06
Local loss @ local epoch 4: 4.172316039330326e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.97 seconds!
[tester] 
AGNewsMetric: acc=0.5093421052631579, hinge=12.35295650783338, ce=16.095542082535594
Local test acc @ epoch 223: 0.5093
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 4.768370942542788e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.5 seconds!
[tester] 
AGNewsMetric: acc=0.854078947368421, hinge=3.137246290131619, ce=9.145467511227256
Local test acc @ epoch 223: 0.8541
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 4.7683684556432127e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.8 seconds!
[tester] 
AGNewsMetric: acc=0.8089473684210526, hinge=3.8315356904581974, ce=10.111430298654657
Local test acc @ epoch 223: 0.8089
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.9802320611338473e-08
Local loss @ local epoch 2: 8.940695295223122e-08
Local loss @ local epoch 3: 2.9802320611338473e-08
Local loss @ local epoch 4: 2.9802320611338473e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.8 seconds!
[tester] 
AGNewsMetric: acc=0.8222368421052632, hinge=3.939545220450351, ce=10.031413807116056
Local test acc @ epoch 223: 0.8222
Global evaluate on test data...
Evaluate data in 124.92 seconds!
[tester] 
AGNewsMetric: acc=0.8494736842105263, hinge=3.30743630020242, ce=9.292030338488127
Global test acc @ epoch 223: 0.8495
Global epoch 224...
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.30046402091466e-07
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.167441337519449e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.26 seconds!
[tester] 
AGNewsMetric: acc=0.7375, hinge=6.289774665330586, ce=11.929496182893452
Local test acc @ epoch 224: 0.7375
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 3.973642748178463e-08
Local loss @ local epoch 1: 1.6291900237774826e-06
Local loss @ local epoch 2: 3.973642748178463e-08
Local loss @ local epoch 3: 3.973642748178463e-08
Local loss @ local epoch 4: 7.94728478581419e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.13 seconds!
[tester] 
AGNewsMetric: acc=0.6110526315789474, hinge=8.684753373798571, ce=12.868420357955129
Local test acc @ epoch 224: 0.6111
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.9802320611338473e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.9802320611338473e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.41 seconds!
[tester] 
AGNewsMetric: acc=0.8234210526315789, hinge=4.002921960228368, ce=9.795889984933954
Local test acc @ epoch 224: 0.8234
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 1.0837207575775665e-08
Local loss @ local epoch 1: 1.0837207575775665e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.34 seconds!
[tester] 
AGNewsMetric: acc=0.8147368421052632, hinge=4.126706029992355, ce=10.15639113376015
Local test acc @ epoch 224: 0.8147
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 2.2351740014414645e-08
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.24 seconds!
[tester] 
AGNewsMetric: acc=0.8402631578947368, hinge=3.5868950171219676, ce=9.782272979334781
Local test acc @ epoch 224: 0.8403
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 8.174330332622048e-07
Local loss @ local epoch 1: 8.514947325011235e-08
Local loss @ local epoch 2: 1.3623915151583788e-07
Local loss @ local epoch 3: 1.7029897492193413e-08
Local loss @ local epoch 4: 3.405979143167315e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.02 seconds!
[tester] 
AGNewsMetric: acc=0.6772368421052631, hinge=7.286830036765651, ce=12.855847800405401
Local test acc @ epoch 224: 0.6772
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 1.9868213740892315e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.73 seconds!
[tester] 
AGNewsMetric: acc=0.8380263157894737, hinge=3.5352827861434535, ce=9.313094815705952
Local test acc @ epoch 224: 0.838
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 3.178913488000035e-08
Local loss @ local epoch 1: 7.947285496356926e-09
Local loss @ local epoch 2: 1.5894570992713852e-08
Local loss @ local epoch 3: 2.384185648907078e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.09 seconds!
[tester] 
AGNewsMetric: acc=0.8205263157894737, hinge=4.250327298264755, ce=10.127571658084268
Local test acc @ epoch 224: 0.8205
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 4.768370942542788e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.4305111051271524e-07
Local loss @ local epoch 3: 2.384185648907078e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.83 seconds!
[tester] 
AGNewsMetric: acc=0.7107894736842105, hinge=6.518569920188503, ce=12.89634391383121
Local test acc @ epoch 224: 0.7108
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.9868213740892315e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.9868211964535476e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.1 seconds!
[tester] 
AGNewsMetric: acc=0.843421052631579, hinge=3.463131592273712, ce=9.460321241679944
Local test acc @ epoch 224: 0.8434
Global evaluate on test data...
Evaluate data in 124.02 seconds!
[tester] 
AGNewsMetric: acc=0.8521052631578947, hinge=3.2272599734758076, ce=9.18582088470459
Global test acc @ epoch 224: 0.8521
Global epoch 225...
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.033904194831848145
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.000250640936428681
Local loss @ local epoch 3: 3.054734634133638e-07
Local loss @ local epoch 4: 1.1622129678726196
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.1 seconds!
[tester] 
AGNewsMetric: acc=0.6102631578947368, hinge=6.871594729172556, ce=12.696966050800524
Local test acc @ epoch 225: 0.6103
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 6.502323657286979e-08
Local loss @ local epoch 1: 0.45449018478393555
Local loss @ local epoch 2: 3.2511618286434896e-08
Local loss @ local epoch 3: 8.236253279392258e-07
Local loss @ local epoch 4: 0.0032279668375849724
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.88 seconds!
[tester] 
AGNewsMetric: acc=0.5207894736842106, hinge=12.746309759742335, ce=16.546039675662392
Local test acc @ epoch 225: 0.5208
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 6.81195828633463e-08
Local loss @ local epoch 1: 8.514947325011235e-08
Local loss @ local epoch 2: 1.7029897492193413e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.7029897492193413e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.22 seconds!
[tester] 
AGNewsMetric: acc=0.6580263157894737, hinge=7.63397273113853, ce=13.35583779987536
Local test acc @ epoch 225: 0.658
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 5.960463411724959e-08
Local loss @ local epoch 2: 2.9802317058624794e-08
Local loss @ local epoch 3: 9.934106870446158e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.4 seconds!
[tester] 
AGNewsMetric: acc=0.7725, hinge=5.385806230243884, ce=11.100752934907613
Local test acc @ epoch 225: 0.7725
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 1.9868213740892315e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 3.973633511122898e-07
Local loss @ local epoch 3: 3.973642037635727e-08
Local loss @ local epoch 4: 1.9868213740892315e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.7 seconds!
[tester] 
AGNewsMetric: acc=0.7436842105263158, hinge=5.776993175305818, ce=11.150396881103516
Local test acc @ epoch 225: 0.7437
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 1.0837207575775665e-08
Local loss @ local epoch 1: 3.57627158109608e-07
Local loss @ local epoch 2: 1.0837207575775665e-08
Local loss @ local epoch 3: 1.842323484879671e-07
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.35 seconds!
[tester] 
AGNewsMetric: acc=0.6382894736842105, hinge=9.850462983783922, ce=14.460975705196983
Local test acc @ epoch 225: 0.6383
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 2.3841852225814364e-07
Local loss @ local epoch 1: 1.589456815054291e-07
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 3.973642748178463e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.01 seconds!
[tester] 
AGNewsMetric: acc=0.7085526315789473, hinge=6.029066721765618, ce=12.449420870730751
Local test acc @ epoch 225: 0.7086
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 1.3589758509624517e-06
Local loss @ local epoch 1: 3.1789138432714026e-08
Local loss @ local epoch 2: 2.384185648907078e-08
Local loss @ local epoch 3: 0.701220691204071
Local loss @ local epoch 4: 4.927306349600258e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.63 seconds!
[tester] 
AGNewsMetric: acc=0.7447368421052631, hinge=4.697247779243871, ce=11.061421159443102
Local test acc @ epoch 225: 0.7447
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.622603290092229e-07
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.36 seconds!
[tester] 
AGNewsMetric: acc=0.7185526315789473, hinge=6.040510016993473, ce=12.390525101109555
Local test acc @ epoch 225: 0.7186
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.9802320611338473e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.9802320611338473e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.63 seconds!
[tester] 
AGNewsMetric: acc=0.7063157894736842, hinge=7.720135116075214, ce=13.153240834286338
Local test acc @ epoch 225: 0.7063
Global evaluate on test data...
Evaluate data in 124.57 seconds!
[tester] 
AGNewsMetric: acc=0.8338157894736842, hinge=3.5999855081658616, ce=9.749144022088302
Global test acc @ epoch 225: 0.8338
Global epoch 226...
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 2.167441515155133e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.0837207575775665e-08
Local loss @ local epoch 3: 3.2511618286434896e-08
Local loss @ local epoch 4: 4.33488231976753e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.4 seconds!
[tester] 
AGNewsMetric: acc=0.8310526315789474, hinge=3.6112451189442685, ce=9.504950041519969
Local test acc @ epoch 226: 0.8311
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 2.384185648907078e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.1920925402364446e-07
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.93 seconds!
[tester] 
AGNewsMetric: acc=0.8163157894736842, hinge=3.9303268402501157, ce=10.24693431051154
Local test acc @ epoch 226: 0.8163
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 1.1920926112907182e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.9802320611338473e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.73 seconds!
[tester] 
AGNewsMetric: acc=0.841842105263158, hinge=3.2092776554509213, ce=9.56949834120901
Local test acc @ epoch 226: 0.8418
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 1.0837207575775665e-08
Local loss @ local epoch 1: 2.167441515155133e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.00040693534538149834
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.26 seconds!
[tester] 
AGNewsMetric: acc=0.7988157894736843, hinge=4.593917629091363, ce=10.422095684252287
Local test acc @ epoch 226: 0.7988
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 8.940695295223122e-08
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 5.2154042862184724e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.34 seconds!
[tester] 
AGNewsMetric: acc=0.8278947368421052, hinge=3.783933869663038, ce=9.752871127881502
Local test acc @ epoch 226: 0.8279
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.002820374444127083
Local loss @ local epoch 1: 0.0008636396378278732
Local loss @ local epoch 2: 0.30111533403396606
Local loss @ local epoch 3: 0.000204276671865955
Local loss @ local epoch 4: 0.0019688440952450037
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.91 seconds!
[tester] 
AGNewsMetric: acc=0.7442105263157894, hinge=3.532115582666899, ce=9.452994296425267
Local test acc @ epoch 226: 0.7442
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 1.9868211609264108e-07
Local loss @ local epoch 1: 3.973642748178463e-08
Local loss @ local epoch 2: 2.3841853646899835e-07
Local loss @ local epoch 3: 2.781549426345009e-07
Local loss @ local epoch 4: 3.576277265437966e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.05 seconds!
[tester] 
AGNewsMetric: acc=0.8068421052631579, hinge=3.3949173277302793, ce=9.88789608804803
Local test acc @ epoch 226: 0.8068
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.88 seconds!
[tester] 
AGNewsMetric: acc=0.833421052631579, hinge=3.5465259311073707, ce=9.894380822432668
Local test acc @ epoch 226: 0.8334
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 9.934106870446158e-09
Local loss @ local epoch 1: 1.1920925402364446e-07
Local loss @ local epoch 2: 9.934106870446158e-09
Local loss @ local epoch 3: 9.934106870446158e-09
Local loss @ local epoch 4: 9.934106870446158e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.45 seconds!
[tester] 
AGNewsMetric: acc=0.8347368421052631, hinge=3.3563545740278142, ce=9.321756802609093
Local test acc @ epoch 226: 0.8347
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 1.1920853921765229e-06
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.384185648907078e-08
Local loss @ local epoch 3: 2.384185648907078e-08
Local loss @ local epoch 4: 6.357827686542805e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.63 seconds!
[tester] 
AGNewsMetric: acc=0.6818421052631579, hinge=7.784997224807739, ce=13.43765393508108
Local test acc @ epoch 226: 0.6818
Global evaluate on test data...
Evaluate data in 124.32 seconds!
[tester] 
AGNewsMetric: acc=0.8542105263157894, hinge=3.250387541118421, ce=9.125179001657587
Global test acc @ epoch 226: 0.8542
Global epoch 227...
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 4.967052902316027e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.26 seconds!
[tester] 
AGNewsMetric: acc=0.7380263157894736, hinge=5.937865191007916, ce=11.607660223308363
Local test acc @ epoch 227: 0.738
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.66 seconds!
[tester] 
AGNewsMetric: acc=0.8498684210526316, hinge=3.309219662264774, ce=9.529695020976819
Local test acc @ epoch 227: 0.8499
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.1920926112907182e-07
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.52 seconds!
[tester] 
AGNewsMetric: acc=0.8517105263157895, hinge=3.229046578281804, ce=9.697744116532176
Local test acc @ epoch 227: 0.8517
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 3.725289943190546e-08
Local loss @ local epoch 1: 2.2351738238057806e-08
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.48 seconds!
[tester] 
AGNewsMetric: acc=0.7702631578947369, hinge=5.708123293424907, ce=11.381361425299394
Local test acc @ epoch 227: 0.7703
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 8.742009782736204e-08
Local loss @ local epoch 1: 4.768370942542788e-08
Local loss @ local epoch 2: 3.1789138432714026e-08
Local loss @ local epoch 3: 7.947285496356926e-09
Local loss @ local epoch 4: 1.2397661066643195e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.19 seconds!
[tester] 
AGNewsMetric: acc=0.7330263157894736, hinge=6.959813080837852, ce=12.60438451265034
Local test acc @ epoch 227: 0.733
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 9.753485130659101e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.9506961734805373e-07
Local loss @ local epoch 3: 2.469464743626304e-05
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.31 seconds!
[tester] 
AGNewsMetric: acc=0.8177631578947369, hinge=4.071099785754555, ce=9.573353414033589
Local test acc @ epoch 227: 0.8178
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 9.934102962461111e-08
Local loss @ local epoch 1: 2.9802317058624794e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 3.973642392907095e-08
Local loss @ local epoch 4: 5.960463056453591e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.27 seconds!
[tester] 
AGNewsMetric: acc=0.5317105263157895, hinge=12.26933265284488, ce=15.805512386121247
Local test acc @ epoch 227: 0.5317
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 3.973642748178463e-08
Local loss @ local epoch 1: 3.973642748178463e-08
Local loss @ local epoch 2: 3.973642748178463e-08
Local loss @ local epoch 3: 3.973642748178463e-08
Local loss @ local epoch 4: 3.973640616550256e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.39 seconds!
[tester] 
AGNewsMetric: acc=0.6885526315789474, hinge=6.610326710751182, ce=12.426125263414885
Local test acc @ epoch 227: 0.6886
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 5.108969247658024e-08
Local loss @ local epoch 1: 1.7029897492193413e-08
Local loss @ local epoch 2: 8.514947325011235e-08
Local loss @ local epoch 3: 9.025819167618465e-07
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.42 seconds!
[tester] 
AGNewsMetric: acc=0.8123684210526316, hinge=4.159855501024347, ce=10.080324771278782
Local test acc @ epoch 227: 0.8124
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.3979890809423523e-06
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.45 seconds!
[tester] 
AGNewsMetric: acc=0.6726315789473685, hinge=7.774865254853901, ce=12.648480680365312
Local test acc @ epoch 227: 0.6726
Global evaluate on test data...
Evaluate data in 124.62 seconds!
[tester] 
AGNewsMetric: acc=0.8414473684210526, hinge=3.518754419904006, ce=9.434510698820416
Global test acc @ epoch 227: 0.8414
Global epoch 228...
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.64 seconds!
[tester] 
AGNewsMetric: acc=0.8431578947368421, hinge=3.6088161172364885, ce=9.158130081578305
Local test acc @ epoch 228: 0.8432
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.1920926823449918e-07
Local loss @ local epoch 3: 2.384185648907078e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.68 seconds!
[tester] 
AGNewsMetric: acc=0.8478947368421053, hinge=3.2972448717920404, ce=9.679766689099763
Local test acc @ epoch 228: 0.8479
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 8.514947325011235e-08
Local loss @ local epoch 1: 2.0435868464119267e-07
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 3.405979143167315e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.76 seconds!
[tester] 
AGNewsMetric: acc=0.5898684210526316, hinge=10.847970617193925, ce=15.734978669819078
Local test acc @ epoch 228: 0.5899
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 2.3285174393095076e-06
Local loss @ local epoch 1: 9.536740464000104e-08
Local loss @ local epoch 2: 0.06808646023273468
Local loss @ local epoch 3: 7.947285496356926e-09
Local loss @ local epoch 4: 2.384185648907078e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.62 seconds!
[tester] 
AGNewsMetric: acc=0.8122368421052631, hinge=4.178680277874595, ce=10.105081457840768
Local test acc @ epoch 228: 0.8122
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 1.0837207575775665e-08
Local loss @ local epoch 1: 1.0837207575775665e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.0837207575775665e-08
Local loss @ local epoch 4: 1.7339516489300877e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.45 seconds!
[tester] 
AGNewsMetric: acc=0.820921052631579, hinge=3.978799369711625, ce=9.772381581758198
Local test acc @ epoch 228: 0.8209
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 9.934106870446158e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.01 seconds!
[tester] 
AGNewsMetric: acc=0.8394736842105263, hinge=3.5049627941533137, ce=9.480271176789936
Local test acc @ epoch 228: 0.8395
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 9.934106870446158e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.67 seconds!
[tester] 
AGNewsMetric: acc=0.8435526315789473, hinge=3.45422933064009, ce=9.572287035490337
Local test acc @ epoch 228: 0.8436
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 1.3411039390121005e-07
Local loss @ local epoch 2: 1.0430805019723266e-07
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.41 seconds!
[tester] 
AGNewsMetric: acc=0.7836842105263158, hinge=4.998330220423247, ce=10.896908739993446
Local test acc @ epoch 228: 0.7837
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 1.589456815054291e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 3.973642748178463e-08
Local loss @ local epoch 3: 3.973642748178463e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.13 seconds!
[tester] 
AGNewsMetric: acc=0.7525, hinge=5.285873327255249, ce=10.833974243967157
Local test acc @ epoch 228: 0.7525
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.0837207575775665e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.31 seconds!
[tester] 
AGNewsMetric: acc=0.8336842105263158, hinge=3.8099404343805814, ce=9.844434513292814
Local test acc @ epoch 228: 0.8337
Global evaluate on test data...
Evaluate data in 123.8 seconds!
[tester] 
AGNewsMetric: acc=0.8502631578947368, hinge=3.3284493654652647, ce=9.297053379259612
Global test acc @ epoch 228: 0.8503
Global epoch 229...
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 3.973642748178463e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 5.165733796275163e-07
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.6 seconds!
[tester] 
AGNewsMetric: acc=0.7353947368421052, hinge=6.382688292453164, ce=12.188435670953048
Local test acc @ epoch 229: 0.7354
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 1.3623915151583788e-07
Local loss @ local epoch 1: 3.4059794984386826e-08
Local loss @ local epoch 2: 1.7029897492193413e-08
Local loss @ local epoch 3: 1.7029897492193413e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.03 seconds!
[tester] 
AGNewsMetric: acc=0.8234210526315789, hinge=4.14136299359171, ce=9.989079330845883
Local test acc @ epoch 229: 0.8234
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 1.1920923270736239e-07
Local loss @ local epoch 1: 7.251866804836027e-07
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 6.953873565862523e-08
Local loss @ local epoch 4: 1.0927513471870043e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.38 seconds!
[tester] 
AGNewsMetric: acc=0.755, hinge=5.683061717183967, ce=11.516867840415554
Local test acc @ epoch 229: 0.755
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 2.7092991672361677e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.167441515155133e-08
Local loss @ local epoch 3: 6.502323657286979e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.44 seconds!
[tester] 
AGNewsMetric: acc=0.5826315789473684, hinge=10.474582393043919, ce=14.73542696701853
Local test acc @ epoch 229: 0.5826
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 5.960463766996327e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.85 seconds!
[tester] 
AGNewsMetric: acc=0.848421052631579, hinge=3.3729422867925543, ce=9.557494713632684
Local test acc @ epoch 229: 0.8484
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0010238023241981864
Local loss @ local epoch 1: 4.33488231976753e-08
Local loss @ local epoch 2: 9.753486551744572e-08
Local loss @ local epoch 3: 0.8275342583656311
Local loss @ local epoch 4: 7.369284844571666e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.41 seconds!
[tester] 
AGNewsMetric: acc=0.7478947368421053, hinge=5.629108648300171, ce=11.001864166259766
Local test acc @ epoch 229: 0.7479
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 5.2154042862184724e-08
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.57 seconds!
[tester] 
AGNewsMetric: acc=0.7517105263157895, hinge=5.7398266985541895, ce=11.322491760253905
Local test acc @ epoch 229: 0.7517
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 4.768371297814156e-08
Local loss @ local epoch 1: 7.947285496356926e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.947285496356926e-09
Local loss @ local epoch 4: 7.947285496356926e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.07 seconds!
[tester] 
AGNewsMetric: acc=0.7702631578947369, hinge=5.880176642568488, ce=11.495367833187705
Local test acc @ epoch 229: 0.7703
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 9.934106870446158e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.9868211964535476e-08
Local loss @ local epoch 3: 9.934106870446158e-09
Local loss @ local epoch 4: 9.934106870446158e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.47 seconds!
[tester] 
AGNewsMetric: acc=0.8411842105263158, hinge=3.5774366561990036, ce=9.519175585696571
Local test acc @ epoch 229: 0.8412
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.6689293147464923e-07
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.41 seconds!
[tester] 
AGNewsMetric: acc=0.5406578947368421, hinge=11.74592512231124, ce=16.446788880197627
Local test acc @ epoch 229: 0.5407
Global evaluate on test data...
Evaluate data in 123.42 seconds!
[tester] 
AGNewsMetric: acc=0.8386842105263158, hinge=3.670375487804413, ce=9.617901336268375
Global test acc @ epoch 229: 0.8387
Global epoch 230...
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 3.973642037635727e-08
Local loss @ local epoch 2: 9.934106870446158e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.52 seconds!
[tester] 
AGNewsMetric: acc=0.8360526315789474, hinge=3.6599239062008104, ce=9.765370858844959
Local test acc @ epoch 230: 0.8361
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.21934373676776886
Local loss @ local epoch 1: 1.5894570992713852e-08
Local loss @ local epoch 2: 5.563098781635745e-08
Local loss @ local epoch 3: 2.7815448788715e-07
Local loss @ local epoch 4: 5.960446287645027e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.85 seconds!
[tester] 
AGNewsMetric: acc=0.68, hinge=6.935538714810422, ce=12.09366126612613
Local test acc @ epoch 230: 0.68
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 4.470347292340193e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.2351738238057806e-08
Local loss @ local epoch 3: 3.725289587919178e-08
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.9 seconds!
[tester] 
AGNewsMetric: acc=0.8053947368421053, hinge=4.546269159317017, ce=10.359347004137542
Local test acc @ epoch 230: 0.8054
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 5.4186035214343065e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 3.2511618286434896e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.9 seconds!
[tester] 
AGNewsMetric: acc=0.7785526315789474, hinge=4.859085142737941, ce=10.758674711930125
Local test acc @ epoch 230: 0.7786
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 2.3841850804728892e-07
Local loss @ local epoch 1: 0.00012379583495203406
Local loss @ local epoch 2: 5.0464950618334115e-06
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0003000360738951713
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.94 seconds!
[tester] 
AGNewsMetric: acc=0.36907894736842106, hinge=12.799414321497867, ce=17.319934339021383
Local test acc @ epoch 230: 0.3691
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.9802320611338473e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.87 seconds!
[tester] 
AGNewsMetric: acc=0.843421052631579, hinge=3.5297202589637355, ce=9.47318917123895
Local test acc @ epoch 230: 0.8434
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 4.33488231976753e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 4.2894385842373595e-05
Local loss @ local epoch 3: 1.0837207575775665e-08
Local loss @ local epoch 4: 1.3004645893488487e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.98 seconds!
[tester] 
AGNewsMetric: acc=0.5792105263157895, hinge=10.474875613764713, ce=15.261381938332006
Local test acc @ epoch 230: 0.5792
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 9.934106870446158e-09
Local loss @ local epoch 1: 9.934106870446158e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 9.934106870446158e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.78 seconds!
[tester] 
AGNewsMetric: acc=0.8281578947368421, hinge=3.862327063209132, ce=9.806297093441612
Local test acc @ epoch 230: 0.8282
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 2.384185648907078e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.04 seconds!
[tester] 
AGNewsMetric: acc=0.841842105263158, hinge=3.569184708344309, ce=9.53077756781327
Local test acc @ epoch 230: 0.8418
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 1.7029897492193413e-08
Local loss @ local epoch 1: 5.279259198687214e-07
Local loss @ local epoch 2: 4.938661959386081e-07
Local loss @ local epoch 3: 1.7029897492193413e-08
Local loss @ local epoch 4: 1.0217937784773312e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.17 seconds!
[tester] 
AGNewsMetric: acc=0.7214473684210526, hinge=6.084001977318212, ce=11.95780306163587
Local test acc @ epoch 230: 0.7214
Global evaluate on test data...
Evaluate data in 123.89 seconds!
[tester] 
AGNewsMetric: acc=0.8413157894736842, hinge=3.52827871837114, ce=9.424857093409488
Global test acc @ epoch 230: 0.8413
Global epoch 231...
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 6.953872144777051e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 9.934106870446158e-09
Local loss @ local epoch 4: 3.973642037635727e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 122.97 seconds!
[tester] 
AGNewsMetric: acc=0.8425, hinge=3.385544640766947, ce=9.267540686757942
Local test acc @ epoch 231: 0.8425
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 2.384185648907078e-08
Local loss @ local epoch 1: 2.384185648907078e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.62 seconds!
[tester] 
AGNewsMetric: acc=0.748421052631579, hinge=5.749486344989977, ce=11.276726427580181
Local test acc @ epoch 231: 0.7484
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 1.8732885109784547e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 8.685221359883144e-07
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 122.92 seconds!
[tester] 
AGNewsMetric: acc=0.7028947368421052, hinge=6.54269509541361, ce=11.401480991965846
Local test acc @ epoch 231: 0.7029
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 2.3841850804728892e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.1523544571900857e-06
Local loss @ local epoch 3: 3.973642748178463e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.14 seconds!
[tester] 
AGNewsMetric: acc=0.6664473684210527, hinge=7.1511804018522565, ce=12.851600070752596
Local test acc @ epoch 231: 0.6664
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 3.2511621839148575e-08
Local loss @ local epoch 2: 2.167441337519449e-08
Local loss @ local epoch 3: 3.2511618286434896e-08
Local loss @ local epoch 4: 1.0837207575775665e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.55 seconds!
[tester] 
AGNewsMetric: acc=0.7875, hinge=4.843434093123988, ce=10.478946298298084
Local test acc @ epoch 231: 0.7875
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 2.167441337519449e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 3.2511621839148575e-08
Local loss @ local epoch 3: 1.0837207575775665e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.35 seconds!
[tester] 
AGNewsMetric: acc=0.7678947368421053, hinge=5.621840147219206, ce=10.906999535811575
Local test acc @ epoch 231: 0.7679
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 8.758923650020733e-05
Local loss @ local epoch 1: 7.947285496356926e-09
Local loss @ local epoch 2: 7.947285496356926e-09
Local loss @ local epoch 3: 2.384185648907078e-08
Local loss @ local epoch 4: 0.24790935218334198
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.72 seconds!
[tester] 
AGNewsMetric: acc=0.6726315789473685, hinge=8.368792934919659, ce=13.830029975489566
Local test acc @ epoch 231: 0.6726
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 4.967052191773291e-08
Local loss @ local epoch 1: 9.934106870446158e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 125.11 seconds!
[tester] 
AGNewsMetric: acc=0.7935526315789474, hinge=4.778980415745785, ce=10.064818420410155
Local test acc @ epoch 231: 0.7936
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.9802320611338473e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.66 seconds!
[tester] 
AGNewsMetric: acc=0.8525, hinge=3.3192938468330784, ce=9.068811215852437
Local test acc @ epoch 231: 0.8525
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.3539002239704132
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.9802315282267955e-08
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 5.960463056453591e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.83 seconds!
[tester] 
AGNewsMetric: acc=0.5552631578947368, hinge=10.90156029450266, ce=16.167650044089868
Local test acc @ epoch 231: 0.5553
Global evaluate on test data...
Evaluate data in 123.98 seconds!
[tester] 
AGNewsMetric: acc=0.845657894736842, hinge=3.441548197896857, ce=9.299075570357473
Global test acc @ epoch 231: 0.8457
Global epoch 232...
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 3.973642748178463e-08
Local loss @ local epoch 2: 3.973642748178463e-08
Local loss @ local epoch 3: 3.973642748178463e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.22 seconds!
[tester] 
AGNewsMetric: acc=0.5938157894736842, hinge=9.557752368324682, ce=14.563578258313632
Local test acc @ epoch 232: 0.5938
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 3.4059794984386826e-08
Local loss @ local epoch 1: 3.4059794984386826e-08
Local loss @ local epoch 2: 6.81195828633463e-08
Local loss @ local epoch 3: 8.855520832184993e-07
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.78 seconds!
[tester] 
AGNewsMetric: acc=0.7867105263157895, hinge=4.544693069708975, ce=11.194779689186499
Local test acc @ epoch 232: 0.7867
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.4901160305669237e-08
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.25 seconds!
[tester] 
AGNewsMetric: acc=0.8377631578947369, hinge=3.7200450038909914, ce=9.51406276702881
Local test acc @ epoch 232: 0.8378
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 1.0378347724326886e-05
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.947285496356926e-09
Local loss @ local epoch 4: 1.5894570992713852e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.67 seconds!
[tester] 
AGNewsMetric: acc=0.5857894736842105, hinge=10.551191718452856, ce=15.380267462479441
Local test acc @ epoch 232: 0.5858
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 5.418602455620203e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.0837207575775665e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.81 seconds!
[tester] 
AGNewsMetric: acc=0.7753947368421052, hinge=5.359795625084325, ce=10.939573468660054
Local test acc @ epoch 232: 0.7754
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 4.967052902316027e-08
Local loss @ local epoch 1: 9.934106870446158e-09
Local loss @ local epoch 2: 1.9868213740892315e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 9.934106870446158e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.42 seconds!
[tester] 
AGNewsMetric: acc=0.6910526315789474, hinge=7.390686602341502, ce=12.838511836403294
Local test acc @ epoch 232: 0.6911
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.384185648907078e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.12 seconds!
[tester] 
AGNewsMetric: acc=0.833421052631579, hinge=3.486563619814421, ce=9.931725419697008
Local test acc @ epoch 232: 0.8334
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.82 seconds!
[tester] 
AGNewsMetric: acc=0.8464473684210526, hinge=3.4658891130748546, ce=9.430726519132916
Local test acc @ epoch 232: 0.8464
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.58604414841102e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 6.502323657286979e-08
Local loss @ local epoch 4: 1.0837207575775665e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.87 seconds!
[tester] 
AGNewsMetric: acc=0.7376315789473684, hinge=6.232779380396793, ce=11.649090592233758
Local test acc @ epoch 232: 0.7376
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 9.934106870446158e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.65 seconds!
[tester] 
AGNewsMetric: acc=0.8127631578947369, hinge=4.4058831112008345, ce=10.214635397258558
Local test acc @ epoch 232: 0.8128
Global evaluate on test data...
Evaluate data in 123.81 seconds!
[tester] 
AGNewsMetric: acc=0.8485526315789473, hinge=3.3832045630404823, ce=9.298069967972605
Global test acc @ epoch 232: 0.8486
Global epoch 233...
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 5.960463056453591e-08
Local loss @ local epoch 1: 4.4703469370688254e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.6 seconds!
[tester] 
AGNewsMetric: acc=0.8135526315789474, hinge=4.537492779681557, ce=9.817361721239592
Local test acc @ epoch 233: 0.8136
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 1.5894562466201023e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 4.768370942542788e-08
Local loss @ local epoch 4: 7.947285496356926e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.33 seconds!
[tester] 
AGNewsMetric: acc=0.7403947368421052, hinge=6.235289462240119, ce=12.090891271892346
Local test acc @ epoch 233: 0.7404
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.384185648907078e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.54 seconds!
[tester] 
AGNewsMetric: acc=0.8485526315789473, hinge=3.3448859149531316, ce=9.672031260038677
Local test acc @ epoch 233: 0.8486
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 5.108969247658024e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.7029897492193413e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.96 seconds!
[tester] 
AGNewsMetric: acc=0.8060526315789474, hinge=4.519139583487259, ce=10.71195785522461
Local test acc @ epoch 233: 0.8061
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.059067440995932e-07
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.0837207575775665e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.65 seconds!
[tester] 
AGNewsMetric: acc=0.8257894736842105, hinge=4.017359397285863, ce=9.86975319511012
Local test acc @ epoch 233: 0.8258
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 3.2511618286434896e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.14 seconds!
[tester] 
AGNewsMetric: acc=0.8477631578947369, hinge=3.437245576005233, ce=9.41549159200568
Local test acc @ epoch 233: 0.8478
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 9.934106870446158e-09
Local loss @ local epoch 4: 9.934106870446158e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.23 seconds!
[tester] 
AGNewsMetric: acc=0.8405263157894737, hinge=3.5271705943659732, ce=9.493504612571314
Local test acc @ epoch 233: 0.8405
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.9868211609264108e-07
Local loss @ local epoch 2: 1.3113007071297034e-06
Local loss @ local epoch 3: 3.178913630108582e-07
Local loss @ local epoch 4: 5.563096578953264e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.52 seconds!
[tester] 
AGNewsMetric: acc=0.7740789473684211, hinge=4.682642329868518, ce=10.407276665536981
Local test acc @ epoch 233: 0.7741
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.9802320611338473e-08
Local loss @ local epoch 3: 4.4703443791149766e-07
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.62 seconds!
[tester] 
AGNewsMetric: acc=0.7671052631578947, hinge=5.433782296933626, ce=11.686956865411055
Local test acc @ epoch 233: 0.7671
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 9.934106870446158e-09
Local loss @ local epoch 1: 9.934106870446158e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.64 seconds!
[tester] 
AGNewsMetric: acc=0.8493421052631579, hinge=3.3003332203312925, ce=9.196198029769095
Local test acc @ epoch 233: 0.8493
Global evaluate on test data...
Evaluate data in 123.74 seconds!
[tester] 
AGNewsMetric: acc=0.8497368421052631, hinge=3.398927104724081, ce=9.445470205608167
Global test acc @ epoch 233: 0.8497
Global epoch 234...
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 6.953872144777051e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 9.934106870446158e-09
Local loss @ local epoch 3: 9.934106870446158e-09
Local loss @ local epoch 4: 9.934106870446158e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.3 seconds!
[tester] 
AGNewsMetric: acc=0.6578947368421053, hinge=9.206491053731819, ce=13.52862899981047
Local test acc @ epoch 234: 0.6579
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 2.384185648907078e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.23 seconds!
[tester] 
AGNewsMetric: acc=0.845657894736842, hinge=3.4708781356560556, ce=9.446943644473427
Local test acc @ epoch 234: 0.8457
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.6877748966217041
Local loss @ local epoch 1: 1.0837207575775665e-08
Local loss @ local epoch 2: 2.3408092602039687e-06
Local loss @ local epoch 3: 1.8815757036209106
Local loss @ local epoch 4: 0.3237312436103821
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.77 seconds!
[tester] 
AGNewsMetric: acc=0.49486842105263157, hinge=12.189302765695672, ce=16.978701103611996
Local test acc @ epoch 234: 0.4949
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.947285496356926e-09
Local loss @ local epoch 2: 3.1789138432714026e-08
Local loss @ local epoch 3: 7.947285496356926e-09
Local loss @ local epoch 4: 1.5894570992713852e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.73 seconds!
[tester] 
AGNewsMetric: acc=0.8353947368421053, hinge=3.863835677849619, ce=9.950390460365696
Local test acc @ epoch 234: 0.8354
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 3.4059794984386826e-08
Local loss @ local epoch 1: 1.362391657266926e-07
Local loss @ local epoch 2: 2.554483273797814e-07
Local loss @ local epoch 3: 6.81195828633463e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.61 seconds!
[tester] 
AGNewsMetric: acc=0.5994736842105263, hinge=8.890220535679868, ce=14.257050333525005
Local test acc @ epoch 234: 0.5995
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 1.701282599242404e-05
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.586043437868284e-08
Local loss @ local epoch 4: 6.393943863258755e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.92 seconds!
[tester] 
AGNewsMetric: acc=0.42276315789473684, hinge=14.612794791773746, ce=18.611393031070108
Local test acc @ epoch 234: 0.4228
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 1.534678267489653e-05
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.291432880634602e-07
Local loss @ local epoch 3: 0.0013341191224753857
Local loss @ local epoch 4: 9.934106870446158e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.66 seconds!
[tester] 
AGNewsMetric: acc=0.8339473684210527, hinge=3.438064726653852, ce=9.833181708486457
Local test acc @ epoch 234: 0.8339
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.117586450050112e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.2351738238057806e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 4.8819489165907726e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.85 seconds!
[tester] 
AGNewsMetric: acc=0.7532894736842105, hinge=6.308097150953192, ce=12.048000024494373
Local test acc @ epoch 234: 0.7533
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.41 seconds!
[tester] 
AGNewsMetric: acc=0.8451315789473685, hinge=3.5098074329526803, ce=9.324896533363743
Local test acc @ epoch 234: 0.8451
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 3.973642748178463e-08
Local loss @ local epoch 1: 3.973642748178463e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.94 seconds!
[tester] 
AGNewsMetric: acc=0.7847368421052632, hinge=4.760505902641698, ce=10.999781833447908
Local test acc @ epoch 234: 0.7847
Global evaluate on test data...
Evaluate data in 123.61 seconds!
[tester] 
AGNewsMetric: acc=0.8294736842105264, hinge=3.8370483242838005, ce=9.722479679709986
Global test acc @ epoch 234: 0.8295
Global epoch 235...
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 3.973642748178463e-08
Local loss @ local epoch 2: 5.960459361631365e-07
Local loss @ local epoch 3: 2.781549426345009e-07
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.62 seconds!
[tester] 
AGNewsMetric: acc=0.7490789473684211, hinge=5.126113189898039, ce=10.197287993180124
Local test acc @ epoch 235: 0.7491
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 2.9802320611338473e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 5.960463766996327e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.53 seconds!
[tester] 
AGNewsMetric: acc=0.8305263157894737, hinge=3.8867729731609946, ce=9.575371382863898
Local test acc @ epoch 235: 0.8305
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 9.934106870446158e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.74 seconds!
[tester] 
AGNewsMetric: acc=0.8394736842105263, hinge=3.5195522655938802, ce=9.56791970303184
Local test acc @ epoch 235: 0.8395
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 7.947282654185983e-08
Local loss @ local epoch 1: 1.5338084722316125e-06
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.5894570992713852e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.88 seconds!
[tester] 
AGNewsMetric: acc=0.59, hinge=10.98687657205682, ce=15.607459297180176
Local test acc @ epoch 235: 0.59
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 9.934106870446158e-09
Local loss @ local epoch 3: 9.934106870446158e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.62 seconds!
[tester] 
AGNewsMetric: acc=0.8398684210526316, hinge=3.538642072050195, ce=9.581822824980083
Local test acc @ epoch 235: 0.8399
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 1.0837207575775665e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.167441337519449e-08
Local loss @ local epoch 3: 1.0837207575775665e-08
Local loss @ local epoch 4: 2.167441337519449e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.71 seconds!
[tester] 
AGNewsMetric: acc=0.7817105263157895, hinge=4.9381090791601885, ce=10.866727076078716
Local test acc @ epoch 235: 0.7817
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 1.0837207575775665e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 3.2511621839148575e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.92 seconds!
[tester] 
AGNewsMetric: acc=0.8435526315789473, hinge=3.426809495122809, ce=9.227911459270276
Local test acc @ epoch 235: 0.8436
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 1.4305109630186053e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.7 seconds!
[tester] 
AGNewsMetric: acc=0.8452631578947368, hinge=3.468925354606227, ce=8.789042780022871
Local test acc @ epoch 235: 0.8453
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.08671211451292038
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.7136314056642732e-07
Local loss @ local epoch 3: 0.007605701219290495
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.73 seconds!
[tester] 
AGNewsMetric: acc=0.6351315789473684, hinge=8.737851314544677, ce=13.96144356978567
Local test acc @ epoch 235: 0.6351
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 1.7029897492193413e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 5.279265451463289e-07
Local loss @ local epoch 3: 1.1920927533992653e-07
Local loss @ local epoch 4: 7.527026355091948e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.71 seconds!
[tester] 
AGNewsMetric: acc=0.465, hinge=11.615850117332057, ce=16.08283462524414
Local test acc @ epoch 235: 0.465
Global evaluate on test data...
Evaluate data in 124.21 seconds!
[tester] 
AGNewsMetric: acc=0.8431578947368421, hinge=3.5560350716741462, ce=9.390453764262952
Global test acc @ epoch 235: 0.8432
Global epoch 236...
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 1.1920928244535389e-07
Local loss @ local epoch 1: 7.947285496356926e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.54 seconds!
[tester] 
AGNewsMetric: acc=0.7180263157894737, hinge=6.61181784529435, ce=12.549596148039166
Local test acc @ epoch 236: 0.718
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.021822325885295868
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.2527527107740752e-05
Local loss @ local epoch 3: 0.001319187693297863
Local loss @ local epoch 4: 0.41350099444389343
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.82 seconds!
[tester] 
AGNewsMetric: acc=0.7419736842105263, hinge=5.724956184688367, ce=10.574355229829488
Local test acc @ epoch 236: 0.742
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.7955641169464798e-06
Local loss @ local epoch 1: 4.470333294648299e-07
Local loss @ local epoch 2: 5.2154042862184724e-08
Local loss @ local epoch 3: 4.365890617918922e-06
Local loss @ local epoch 4: 5.662424200636451e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.46 seconds!
[tester] 
AGNewsMetric: acc=0.7476315789473684, hinge=5.390389544336419, ce=11.328975386368601
Local test acc @ epoch 236: 0.7476
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 6.198873734319932e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.1920926823449918e-07
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.15 seconds!
[tester] 
AGNewsMetric: acc=0.8180263157894737, hinge=3.7528257274627688, ce=9.34886136105186
Local test acc @ epoch 236: 0.818
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.16451798379421234
Local loss @ local epoch 1: 1.0837207575775665e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.842323484879671e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.79 seconds!
[tester] 
AGNewsMetric: acc=0.5160526315789473, hinge=11.48017522209569, ce=16.663144974959526
Local test acc @ epoch 236: 0.5161
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 8.514948746096707e-08
Local loss @ local epoch 1: 3.4059794984386826e-08
Local loss @ local epoch 2: 8.514947325011235e-08
Local loss @ local epoch 3: 3.4059794984386826e-08
Local loss @ local epoch 4: 1.7029893228936999e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.89 seconds!
[tester] 
AGNewsMetric: acc=0.7331578947368421, hinge=5.925743085961593, ce=11.748502901980752
Local test acc @ epoch 236: 0.7332
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.11 seconds!
[tester] 
AGNewsMetric: acc=0.8351315789473684, hinge=3.7095946595543308, ce=9.647795034709729
Local test acc @ epoch 236: 0.8351
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 7.947285496356926e-09
Local loss @ local epoch 1: 3.6557460703079414e-07
Local loss @ local epoch 2: 7.947285496356926e-09
Local loss @ local epoch 3: 2.225237807351732e-07
Local loss @ local epoch 4: 3.973642392907095e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.38 seconds!
[tester] 
AGNewsMetric: acc=0.6531578947368422, hinge=8.878634307259007, ce=14.628831311276084
Local test acc @ epoch 236: 0.6532
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0002549367491155863
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.9868211964535476e-08
Local loss @ local epoch 3: 9.397156645718496e-06
Local loss @ local epoch 4: 8.046595212363172e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.93 seconds!
[tester] 
AGNewsMetric: acc=0.4589473684210526, hinge=12.692483807613975, ce=17.20537925720215
Local test acc @ epoch 236: 0.4589
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 3.619577910285443e-06
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 6.502324367829715e-08
Local loss @ local epoch 3: 0.0008470140164718032
Local loss @ local epoch 4: 1.062043224919762e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.37 seconds!
[tester] 
AGNewsMetric: acc=0.7863157894736842, hinge=4.705463757514954, ce=10.655176508050216
Local test acc @ epoch 236: 0.7863
Global evaluate on test data...
Evaluate data in 123.97 seconds!
[tester] 
AGNewsMetric: acc=0.8344736842105264, hinge=3.6206732647042523, ce=9.45205735859118
Global test acc @ epoch 236: 0.8345
Global epoch 237...
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.09 seconds!
[tester] 
AGNewsMetric: acc=0.8321052631578948, hinge=3.6076483548314946, ce=9.816629542300575
Local test acc @ epoch 237: 0.8321
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 1.1126193300015075e-07
Local loss @ local epoch 1: 3.1789141985427705e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.947285496356926e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.89 seconds!
[tester] 
AGNewsMetric: acc=0.7740789473684211, hinge=5.257238007846632, ce=10.57341333489669
Local test acc @ epoch 237: 0.7741
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 6.828858658991521e-06
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.5544835580149083e-07
Local loss @ local epoch 3: 4.006575545645319e-05
Local loss @ local epoch 4: 3.4059794984386826e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.85 seconds!
[tester] 
AGNewsMetric: acc=0.7119736842105263, hinge=6.94080688928303, ce=11.186673379195364
Local test acc @ epoch 237: 0.712
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 1.9868211964535476e-08
Local loss @ local epoch 1: 9.934106870446158e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.55 seconds!
[tester] 
AGNewsMetric: acc=0.8094736842105263, hinge=4.442405778232374, ce=10.167179430911416
Local test acc @ epoch 237: 0.8095
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.1920928244535389e-07
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 3.973642748178463e-08
Local loss @ local epoch 4: 3.973642748178463e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.53 seconds!
[tester] 
AGNewsMetric: acc=0.66, hinge=7.778019950264379, ce=13.067210358067562
Local test acc @ epoch 237: 0.66
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.0837207575775665e-08
Local loss @ local epoch 3: 8.669762507906853e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.3 seconds!
[tester] 
AGNewsMetric: acc=0.8311842105263157, hinge=3.6377572410985044, ce=9.601990199841952
Local test acc @ epoch 237: 0.8312
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 5.960463056453591e-08
Local loss @ local epoch 2: 2.2351740014414645e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.42 seconds!
[tester] 
AGNewsMetric: acc=0.7932894736842105, hinge=4.892587530738429, ce=10.644198688707853
Local test acc @ epoch 237: 0.7933
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 4.33488231976753e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.0837207575775665e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.85 seconds!
[tester] 
AGNewsMetric: acc=0.7989473684210526, hinge=4.5202397110587675, ce=10.289399630897924
Local test acc @ epoch 237: 0.7989
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 6.953873565862523e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 9.934106870446158e-09
Local loss @ local epoch 4: 9.934106870446158e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.88 seconds!
[tester] 
AGNewsMetric: acc=0.8202631578947368, hinge=3.9099576031534293, ce=9.596055191441586
Local test acc @ epoch 237: 0.8203
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.7881387748275301e-07
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.7 seconds!
[tester] 
AGNewsMetric: acc=0.8414473684210526, hinge=3.422276592003672, ce=9.737302207946778
Local test acc @ epoch 237: 0.8414
Global evaluate on test data...
Evaluate data in 123.66 seconds!
[tester] 
AGNewsMetric: acc=0.8506578947368421, hinge=3.3172238600881476, ce=9.202467803955079
Global test acc @ epoch 237: 0.8507
Global epoch 238...
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 9.934106870446158e-09
Local loss @ local epoch 2: 9.934106870446158e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 9.934106870446158e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.55 seconds!
[tester] 
AGNewsMetric: acc=0.8288157894736842, hinge=3.814756797991301, ce=9.880606846056487
Local test acc @ epoch 238: 0.8288
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 9.934106870446158e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.9802320611338473e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.66 seconds!
[tester] 
AGNewsMetric: acc=0.8511842105263158, hinge=3.3078240107235155, ce=9.235949096679688
Local test acc @ epoch 238: 0.8512
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 3.725289587919178e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.44 seconds!
[tester] 
AGNewsMetric: acc=0.7869736842105263, hinge=4.972090755010906, ce=11.271812786303068
Local test acc @ epoch 238: 0.787
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 3.973642748178463e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 3.973642748178463e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.85 seconds!
[tester] 
AGNewsMetric: acc=0.6189473684210526, hinge=8.842051638553016, ce=14.715754408585397
Local test acc @ epoch 238: 0.6189
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 8.514947325011235e-08
Local loss @ local epoch 1: 5.108969247658024e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.7029897492193413e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.53 seconds!
[tester] 
AGNewsMetric: acc=0.7664473684210527, hinge=5.120087920741031, ce=11.572462589866237
Local test acc @ epoch 238: 0.7664
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.384185648907078e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.76 seconds!
[tester] 
AGNewsMetric: acc=0.8464473684210526, hinge=3.460477260539406, ce=9.563256026820133
Local test acc @ epoch 238: 0.8464
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 3.684643274937116e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 3.2511621839148575e-08
Local loss @ local epoch 3: 1.9176405668258667
Local loss @ local epoch 4: 2.398958921432495
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.39 seconds!
[tester] 
AGNewsMetric: acc=0.6105263157894737, hinge=8.684396713156449, ce=14.10528584128932
Local test acc @ epoch 238: 0.6105
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 6.675687700408162e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.8516932414058829e-06
Local loss @ local epoch 3: 1.0331468303093061e-07
Local loss @ local epoch 4: 7.947285496356926e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.68 seconds!
[tester] 
AGNewsMetric: acc=0.6371052631578947, hinge=9.160284289811786, ce=14.973831674676193
Local test acc @ epoch 238: 0.6371
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.38 seconds!
[tester] 
AGNewsMetric: acc=0.8546052631578948, hinge=3.1652702449497423, ce=9.28590870104338
Local test acc @ epoch 238: 0.8546
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 1.0837202779612198e-07
Local loss @ local epoch 1: 2.167441337519449e-08
Local loss @ local epoch 2: 1.0837207575775665e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.4088358568642434e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.15 seconds!
[tester] 
AGNewsMetric: acc=0.6151315789473685, hinge=9.049023995524959, ce=14.177351001940275
Local test acc @ epoch 238: 0.6151
Global evaluate on test data...
Evaluate data in 124.23 seconds!
[tester] 
AGNewsMetric: acc=0.8498684210526316, hinge=3.305378019056822, ce=9.504993486906352
Global test acc @ epoch 238: 0.8499
Global epoch 239...
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.9802320611338473e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 122.81 seconds!
[tester] 
AGNewsMetric: acc=0.84, hinge=3.4984158062934876, ce=9.81991933320698
Local test acc @ epoch 239: 0.84
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 9.753482288488158e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.0837207575775665e-08
Local loss @ local epoch 3: 1.849735781433992e-05
Local loss @ local epoch 4: 1.0837207575775665e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.29 seconds!
[tester] 
AGNewsMetric: acc=0.8065789473684211, hinge=4.185496643969887, ce=10.155009026778371
Local test acc @ epoch 239: 0.8066
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 125.35 seconds!
[tester] 
AGNewsMetric: acc=0.8489473684210527, hinge=3.2760936162346286, ce=9.917544780530427
Local test acc @ epoch 239: 0.8489
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 8.742011203821676e-08
Local loss @ local epoch 1: 7.947285496356926e-09
Local loss @ local epoch 2: 7.947285496356926e-09
Local loss @ local epoch 3: 7.947285496356926e-09
Local loss @ local epoch 4: 2.384185648907078e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 125.11 seconds!
[tester] 
AGNewsMetric: acc=0.7456578947368421, hinge=6.7103960760016195, ce=12.508038926375539
Local test acc @ epoch 239: 0.7457
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 1.021793636368784e-07
Local loss @ local epoch 1: 1.7029897492193413e-08
Local loss @ local epoch 2: 3.405979143167315e-08
Local loss @ local epoch 3: 1.7029897492193413e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.39 seconds!
[tester] 
AGNewsMetric: acc=0.7526315789473684, hinge=5.532796855223807, ce=11.810209481088739
Local test acc @ epoch 239: 0.7526
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 2.2351740014414645e-08
Local loss @ local epoch 1: 1.4901159417490817e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.02 seconds!
[tester] 
AGNewsMetric: acc=0.8303947368421053, hinge=3.942806074242843, ce=9.914803826181512
Local test acc @ epoch 239: 0.8304
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.9802320611338473e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.66 seconds!
[tester] 
AGNewsMetric: acc=0.8496052631578948, hinge=3.306506935169822, ce=9.750089910406816
Local test acc @ epoch 239: 0.8496
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 7.947285496356926e-08
Local loss @ local epoch 1: 1.3907721267969464e-06
Local loss @ local epoch 2: 4.7683693082944956e-07
Local loss @ local epoch 3: 2.8610149911401095e-06
Local loss @ local epoch 4: 3.0994285680208122e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.42 seconds!
[tester] 
AGNewsMetric: acc=0.6505263157894737, hinge=7.096966986405222, ce=14.041902485897667
Local test acc @ epoch 239: 0.6505
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 1.0837207575775665e-08
Local loss @ local epoch 1: 1.0837207575775665e-08
Local loss @ local epoch 2: 2.167441337519449e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.72 seconds!
[tester] 
AGNewsMetric: acc=0.8403947368421053, hinge=3.5265828797691747, ce=9.564650419134843
Local test acc @ epoch 239: 0.8404
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 9.934106870446158e-09
Local loss @ local epoch 1: 9.934106870446158e-09
Local loss @ local epoch 2: 6.953872144777051e-08
Local loss @ local epoch 3: 1.9868211964535476e-08
Local loss @ local epoch 4: 2.9802320611338473e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.56 seconds!
[tester] 
AGNewsMetric: acc=0.8313157894736842, hinge=3.3618327148337115, ce=9.665828461898
Local test acc @ epoch 239: 0.8313
Global evaluate on test data...
Evaluate data in 124.6 seconds!
[tester] 
AGNewsMetric: acc=0.8521052631578947, hinge=3.248356645232753, ce=9.542895624261153
Global test acc @ epoch 239: 0.8521
Global epoch 240...
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.9868211964535476e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.9868213740892315e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.94 seconds!
[tester] 
AGNewsMetric: acc=0.8121052631578948, hinge=4.232591565031754, ce=10.27115976835552
Local test acc @ epoch 240: 0.8121
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 1.9868208767093165e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.1920926823449918e-07
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 3.973642748178463e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.55 seconds!
[tester] 
AGNewsMetric: acc=0.674078947368421, hinge=7.445019552331222, ce=13.237803404958624
Local test acc @ epoch 240: 0.6741
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 9.934106870446158e-09
Local loss @ local epoch 1: 9.934106870446158e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 6.953874276405259e-08
Local loss @ local epoch 4: 4.967052902316027e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.01 seconds!
[tester] 
AGNewsMetric: acc=0.825921052631579, hinge=3.960970119677092, ce=9.85317998183401
Local test acc @ epoch 240: 0.8259
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.0837207575775665e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.76 seconds!
[tester] 
AGNewsMetric: acc=0.8331578947368421, hinge=3.6992894905491878, ce=10.035979489778217
Local test acc @ epoch 240: 0.8332
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.0430809993522416e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.84 seconds!
[tester] 
AGNewsMetric: acc=0.7794736842105263, hinge=5.186674738181265, ce=10.944741104527523
Local test acc @ epoch 240: 0.7795
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.19 seconds!
[tester] 
AGNewsMetric: acc=0.8496052631578948, hinge=3.3280729779444242, ce=9.836938588995682
Local test acc @ epoch 240: 0.8496
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 3.405979143167315e-08
Local loss @ local epoch 1: 3.4059794984386826e-08
Local loss @ local epoch 2: 1.7029897492193413e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.57 seconds!
[tester] 
AGNewsMetric: acc=0.7777631578947368, hinge=5.27594027770193, ce=11.708860104209498
Local test acc @ epoch 240: 0.7778
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 1.5894570992713852e-08
Local loss @ local epoch 1: 7.947285496356926e-09
Local loss @ local epoch 2: 3.973642748178463e-08
Local loss @ local epoch 3: 1.5894569216357013e-08
Local loss @ local epoch 4: 1.5894569216357013e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.2 seconds!
[tester] 
AGNewsMetric: acc=0.8098684210526316, hinge=4.608411139688994, ce=10.617652624029862
Local test acc @ epoch 240: 0.8099
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 1.3004647314573958e-07
Local loss @ local epoch 1: 1.0837207575775665e-08
Local loss @ local epoch 2: 4.063045707880519e-05
Local loss @ local epoch 3: 3.2511621839148575e-08
Local loss @ local epoch 4: 2.167441515155133e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.93 seconds!
[tester] 
AGNewsMetric: acc=0.848421052631579, hinge=3.3283606835415487, ce=9.519333977950247
Local test acc @ epoch 240: 0.8484
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.6 seconds!
[tester] 
AGNewsMetric: acc=0.84, hinge=3.622292408315759, ce=10.371105790389212
Local test acc @ epoch 240: 0.84
Global evaluate on test data...
Evaluate data in 124.66 seconds!
[tester] 
AGNewsMetric: acc=0.8514473684210526, hinge=3.3262679589422124, ce=9.463853679456209
Global test acc @ epoch 240: 0.8514
Global epoch 241...
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.9802320611338473e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.81 seconds!
[tester] 
AGNewsMetric: acc=0.8480263157894737, hinge=3.309154117860292, ce=9.701695628919099
Local test acc @ epoch 241: 0.848
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 5.108969247658024e-08
Local loss @ local epoch 1: 3.405979143167315e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.67 seconds!
[tester] 
AGNewsMetric: acc=0.8060526315789474, hinge=4.420142236006887, ce=10.930737595809134
Local test acc @ epoch 241: 0.8061
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.9868211964535476e-08
Local loss @ local epoch 3: 3.973642392907095e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.71 seconds!
[tester] 
AGNewsMetric: acc=0.8064473684210526, hinge=4.39716045028285, ce=10.598608442607679
Local test acc @ epoch 241: 0.8064
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 3.973642748178463e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.99 seconds!
[tester] 
AGNewsMetric: acc=0.8001315789473684, hinge=4.358385061966746, ce=10.933754714162726
Local test acc @ epoch 241: 0.8001
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 3.2511621839148575e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.30046402091466e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.1 seconds!
[tester] 
AGNewsMetric: acc=0.7403947368421052, hinge=6.426656043905961, ce=12.342286880894711
Local test acc @ epoch 241: 0.7404
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 3.973642748178463e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.95 seconds!
[tester] 
AGNewsMetric: acc=0.84, hinge=3.6321418310466567, ce=9.68867316396613
Local test acc @ epoch 241: 0.84
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 2.384183090953229e-07
Local loss @ local epoch 1: 3.178913488000035e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.5894570992713852e-08
Local loss @ local epoch 4: 7.947285496356926e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.83 seconds!
[tester] 
AGNewsMetric: acc=0.7225, hinge=6.949346173437018, ce=12.948938154923288
Local test acc @ epoch 241: 0.7225
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.7780671119689941
Local loss @ local epoch 1: 3.129236461063556e-07
Local loss @ local epoch 2: 7.450579175838357e-08
Local loss @ local epoch 3: 5.811432970403985e-07
Local loss @ local epoch 4: 4.072735464433208e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.78 seconds!
[tester] 
AGNewsMetric: acc=0.6252631578947369, hinge=7.606651045146742, ce=13.771279903211092
Local test acc @ epoch 241: 0.6253
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 1.929002564793336e-06
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 8.66976463953506e-08
Local loss @ local epoch 3: 0.9400436282157898
Local loss @ local epoch 4: 1.1313456525385845e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.32 seconds!
[tester] 
AGNewsMetric: acc=0.7902631578947369, hinge=4.1342503919099505, ce=10.837902444538317
Local test acc @ epoch 241: 0.7903
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.62 seconds!
[tester] 
AGNewsMetric: acc=0.8528947368421053, hinge=3.2752028210539565, ce=9.604996179279528
Local test acc @ epoch 241: 0.8529
Global evaluate on test data...
Evaluate data in 123.99 seconds!
[tester] 
AGNewsMetric: acc=0.8428947368421053, hinge=3.5450516190026935, ce=9.94727503726357
Global test acc @ epoch 241: 0.8429
Global epoch 242...
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 3.725289587919178e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.74 seconds!
[tester] 
AGNewsMetric: acc=0.8309210526315789, hinge=3.8431632531316655, ce=10.305169822291324
Local test acc @ epoch 242: 0.8309
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 9.93410154137564e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 9.934106870446158e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.83 seconds!
[tester] 
AGNewsMetric: acc=0.5305263157894737, hinge=11.96504782827277, ce=16.822043501201428
Local test acc @ epoch 242: 0.5305
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 3.546451125657768e-06
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.69 seconds!
[tester] 
AGNewsMetric: acc=0.7288157894736842, hinge=6.274928786127191, ce=13.19689619967812
Local test acc @ epoch 242: 0.7288
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 6.953874276405259e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.986819455623845e-07
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.18 seconds!
[tester] 
AGNewsMetric: acc=0.8153947368421053, hinge=3.9782513934687564, ce=9.919020787289268
Local test acc @ epoch 242: 0.8154
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 7.152556236178498e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.84 seconds!
[tester] 
AGNewsMetric: acc=0.8375, hinge=3.596002382228249, ce=9.741760703638981
Local test acc @ epoch 242: 0.8375
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.004395490977913141
Local loss @ local epoch 1: 1.7029897492193413e-08
Local loss @ local epoch 2: 3.405979143167315e-08
Local loss @ local epoch 3: 1.3623912309412844e-07
Local loss @ local epoch 4: 3.42297539646097e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 122.95 seconds!
[tester] 
AGNewsMetric: acc=0.6282894736842105, hinge=7.803083144740055, ce=12.805033103541325
Local test acc @ epoch 242: 0.6283
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 3.973642748178463e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.85 seconds!
[tester] 
AGNewsMetric: acc=0.6813157894736842, hinge=7.311154829326429, ce=13.42859584206029
Local test acc @ epoch 242: 0.6813
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 5.563098071093009e-08
Local loss @ local epoch 1: 7.947285496356926e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.152555525635762e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.52 seconds!
[tester] 
AGNewsMetric: acc=0.7964473684210527, hinge=4.844169741931714, ce=10.97217952527498
Local test acc @ epoch 242: 0.7964
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 1.8768130757962354e-05
Local loss @ local epoch 1: 2.167441515155133e-08
Local loss @ local epoch 2: 3.655830732895993e-05
Local loss @ local epoch 3: 2.2216015622689156e-06
Local loss @ local epoch 4: 3.2511621839148575e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.01 seconds!
[tester] 
AGNewsMetric: acc=0.700921052631579, hinge=6.636061239744487, ce=12.668398112246864
Local test acc @ epoch 242: 0.7009
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 1.0837207575775665e-08
Local loss @ local epoch 1: 1.0837207575775665e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.88 seconds!
[tester] 
AGNewsMetric: acc=0.8311842105263157, hinge=3.7582415476598237, ce=9.948959386725175
Local test acc @ epoch 242: 0.8312
Global evaluate on test data...
Evaluate data in 123.92 seconds!
[tester] 
AGNewsMetric: acc=0.8543421052631579, hinge=3.268632503685198, ce=9.50451182315224
Global test acc @ epoch 242: 0.8543
Global epoch 243...
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0069177947007119656
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 1.4901152667334827e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.58 seconds!
[tester] 
AGNewsMetric: acc=0.6205263157894737, hinge=9.90511429636102, ce=15.523401802464535
Local test acc @ epoch 243: 0.6205
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 1.3828140481564333e-06
Local loss @ local epoch 1: 3.178913488000035e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.8610199365175504e-07
Local loss @ local epoch 4: 0.290188193321228
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.59 seconds!
[tester] 
AGNewsMetric: acc=0.7305263157894737, hinge=6.672349537297299, ce=12.6318431794016
Local test acc @ epoch 243: 0.7305
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 8.514948746096707e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 5.108968892386656e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.33 seconds!
[tester] 
AGNewsMetric: acc=0.7675, hinge=5.348879117965698, ce=12.130709640101383
Local test acc @ epoch 243: 0.7675
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 2.4925549269028124e-07
Local loss @ local epoch 1: 2.167441515155133e-08
Local loss @ local epoch 2: 1.625580381414693e-07
Local loss @ local epoch 3: 5.873577720194589e-06
Local loss @ local epoch 4: 6.502323657286979e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.68 seconds!
[tester] 
AGNewsMetric: acc=0.6036842105263158, hinge=9.273439939398514, ce=14.94816545988384
Local test acc @ epoch 243: 0.6037
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 1.9868213740892315e-08
Local loss @ local epoch 1: 9.934106870446158e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 9.934106870446158e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.03 seconds!
[tester] 
AGNewsMetric: acc=0.838421052631579, hinge=3.6413140461319373, ce=9.661180273357191
Local test acc @ epoch 243: 0.8384
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 3.973642748178463e-08
Local loss @ local epoch 3: 4.7683681714261184e-07
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.73 seconds!
[tester] 
AGNewsMetric: acc=0.4478947368421053, hinge=14.205461638601204, ce=18.775017623901366
Local test acc @ epoch 243: 0.4479
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 5.960463766996327e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450569228240056e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.75 seconds!
[tester] 
AGNewsMetric: acc=0.8378947368421052, hinge=3.5041540577537136, ce=9.721913454156173
Local test acc @ epoch 243: 0.8379
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 1.9868213740892315e-08
Local loss @ local epoch 1: 9.934106870446158e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.9802317058624794e-08
Local loss @ local epoch 4: 3.973642037635727e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.56 seconds!
[tester] 
AGNewsMetric: acc=0.844078947368421, hinge=3.3911287805908605, ce=9.541118131938733
Local test acc @ epoch 243: 0.8441
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 1.6255802393061458e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.167441337519449e-08
Local loss @ local epoch 4: 4.334882675038898e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.1 seconds!
[tester] 
AGNewsMetric: acc=0.6548684210526315, hinge=9.661663246154784, ce=14.296209473860891
Local test acc @ epoch 243: 0.6549
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 2.384185648907078e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.56 seconds!
[tester] 
AGNewsMetric: acc=0.8488157894736842, hinge=3.2988738159129496, ce=10.170545060007196
Local test acc @ epoch 243: 0.8488
Global evaluate on test data...
Evaluate data in 124.69 seconds!
[tester] 
AGNewsMetric: acc=0.8272368421052632, hinge=3.828367301288404, ce=10.104509721053274
Global test acc @ epoch 243: 0.8272
Global epoch 244...
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 3.5762778338721546e-07
Local loss @ local epoch 2: 1.9112680092803203e-05
Local loss @ local epoch 3: 8.066418558883015e-06
Local loss @ local epoch 4: 4.982717291568406e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.51 seconds!
[tester] 
AGNewsMetric: acc=0.4142105263157895, hinge=12.607100326136539, ce=16.26074662459524
Local test acc @ epoch 244: 0.4142
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 1.0837207575775665e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.32 seconds!
[tester] 
AGNewsMetric: acc=0.8221052631578948, hinge=3.900336312243813, ce=10.477199978075529
Local test acc @ epoch 244: 0.8221
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 2.0435868464119267e-07
Local loss @ local epoch 1: 6.301057169366686e-07
Local loss @ local epoch 2: 2.588531742730993e-06
Local loss @ local epoch 3: 4.2487128666834906e-05
Local loss @ local epoch 4: 0.00022164110851008445
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.34 seconds!
[tester] 
AGNewsMetric: acc=0.5614473684210526, hinge=5.331287258047807, ce=9.670714095266241
Local test acc @ epoch 244: 0.5614
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 1.9868211964535476e-08
Local loss @ local epoch 1: 3.973642392907095e-08
Local loss @ local epoch 2: 3.973642037635727e-08
Local loss @ local epoch 3: 3.973642037635727e-08
Local loss @ local epoch 4: 1.5894558202944609e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.94 seconds!
[tester] 
AGNewsMetric: acc=0.7503947368421052, hinge=5.605611786089446, ce=11.698502705222682
Local test acc @ epoch 244: 0.7504
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.34 seconds!
[tester] 
AGNewsMetric: acc=0.8231578947368421, hinge=4.077904756947568, ce=10.240203166760896
Local test acc @ epoch 244: 0.8232
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 1.033146332929391e-07
Local loss @ local epoch 1: 2.384185648907078e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.152554815093026e-08
Local loss @ local epoch 4: 3.25837930859052e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.76 seconds!
[tester] 
AGNewsMetric: acc=0.7538157894736842, hinge=6.1330067524157075, ce=12.4027241556268
Local test acc @ epoch 244: 0.7538
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 8.940680800151313e-07
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.62 seconds!
[tester] 
AGNewsMetric: acc=0.6939473684210526, hinge=7.111005491708454, ce=12.12275357497366
Local test acc @ epoch 244: 0.6939
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 4.768370942542788e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.96 seconds!
[tester] 
AGNewsMetric: acc=0.8343421052631579, hinge=3.70788649885278, ce=10.088534130297209
Local test acc @ epoch 244: 0.8343
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 9.934106870446158e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 4.967038762515585e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.91 seconds!
[tester] 
AGNewsMetric: acc=0.8051315789473684, hinge=4.447243209638094, ce=10.819177151730186
Local test acc @ epoch 244: 0.8051
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 1.0837207575775665e-08
Local loss @ local epoch 1: 1.0837207575775665e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.59 seconds!
[tester] 
AGNewsMetric: acc=0.8275, hinge=3.725096865453218, ce=9.958769149780274
Local test acc @ epoch 244: 0.8275
Global evaluate on test data...
Evaluate data in 125.05 seconds!
[tester] 
AGNewsMetric: acc=0.8518421052631578, hinge=3.3110175198002865, ce=9.503296049017655
Global test acc @ epoch 244: 0.8518
Global epoch 245...
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 3.973641753418633e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.23 seconds!
[tester] 
AGNewsMetric: acc=0.7797368421052632, hinge=4.998392563368145, ce=11.579497662594443
Local test acc @ epoch 245: 0.7797
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.9802320611338473e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.92 seconds!
[tester] 
AGNewsMetric: acc=0.8564473684210526, hinge=3.225995249497263, ce=9.773532373528731
Local test acc @ epoch 245: 0.8564
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 1.4088365674069792e-07
Local loss @ local epoch 1: 3.2511618286434896e-08
Local loss @ local epoch 2: 1.0837207575775665e-08
Local loss @ local epoch 3: 2.167441515155133e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.45 seconds!
[tester] 
AGNewsMetric: acc=0.48986842105263156, hinge=13.826416233464291, ce=17.91230117597078
Local test acc @ epoch 245: 0.4899
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.7029897492193413e-08
Local loss @ local epoch 3: 1.7029897492193413e-08
Local loss @ local epoch 4: 5.108968892386656e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.49 seconds!
[tester] 
AGNewsMetric: acc=0.8071052631578948, hinge=4.201740542085547, ce=11.035312164708188
Local test acc @ epoch 245: 0.8071
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0003120295878034085
Local loss @ local epoch 1: 2.167441337519449e-08
Local loss @ local epoch 2: 9.753482288488158e-08
Local loss @ local epoch 3: 1.1518447399139404
Local loss @ local epoch 4: 1.0837207575775665e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.22 seconds!
[tester] 
AGNewsMetric: acc=0.7767105263157895, hinge=5.148891312448602, ce=11.087476967259457
Local test acc @ epoch 245: 0.7767
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 2.7815460157398775e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.947285496356926e-09
Local loss @ local epoch 4: 6.357802249112865e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.21 seconds!
[tester] 
AGNewsMetric: acc=0.5911842105263158, hinge=10.438408715097527, ce=15.998118424666556
Local test acc @ epoch 245: 0.5912
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 7.096889748936519e-05
Local loss @ local epoch 1: 9.934106870446158e-09
Local loss @ local epoch 2: 9.934102962461111e-08
Local loss @ local epoch 3: 2.2569401264190674
Local loss @ local epoch 4: 1.490115550950577e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.6 seconds!
[tester] 
AGNewsMetric: acc=0.6303947368421052, hinge=8.799572603326094, ce=15.108111789101049
Local test acc @ epoch 245: 0.6304
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 2.384185648907078e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.79 seconds!
[tester] 
AGNewsMetric: acc=0.8447368421052631, hinge=3.565611943571191, ce=9.911537246704102
Local test acc @ epoch 245: 0.8447
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 4.1054172470467165e-05
Local loss @ local epoch 1: 2.9802320611338473e-08
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 1.4901159417490817e-08
Local loss @ local epoch 4: 4.470347647611561e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.6 seconds!
[tester] 
AGNewsMetric: acc=0.5482894736842105, hinge=11.452071020226729, ce=16.89254822580438
Local test acc @ epoch 245: 0.5483
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 9.934106870446158e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 3.973642037635727e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.12 seconds!
[tester] 
AGNewsMetric: acc=0.8430263157894737, hinge=3.4972538835123967, ce=9.807492408752442
Local test acc @ epoch 245: 0.843
Global evaluate on test data...
Evaluate data in 123.72 seconds!
[tester] 
AGNewsMetric: acc=0.8344736842105264, hinge=3.7059333452425505, ce=10.199175166079872
Global test acc @ epoch 245: 0.8345
Global epoch 246...
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.0837207575775665e-08
Local loss @ local epoch 3: 2.167441515155133e-08
Local loss @ local epoch 4: 1.0837207575775665e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.43 seconds!
[tester] 
AGNewsMetric: acc=0.8371052631578947, hinge=3.5583830837199564, ce=10.174955974378085
Local test acc @ epoch 246: 0.8371
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 9.934106870446158e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.88 seconds!
[tester] 
AGNewsMetric: acc=0.8311842105263157, hinge=3.760285337849667, ce=10.373447151184083
Local test acc @ epoch 246: 0.8312
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 7.947285496356926e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.947285496356926e-09
Local loss @ local epoch 3: 2.384185471271394e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.41 seconds!
[tester] 
AGNewsMetric: acc=0.8307894736842105, hinge=3.9202707365939493, ce=10.311179813585783
Local test acc @ epoch 246: 0.8308
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 3.2356780366171733e-07
Local loss @ local epoch 2: 1.8732882267613604e-07
Local loss @ local epoch 3: 1.8732882267613604e-07
Local loss @ local epoch 4: 8.685240686645557e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.36 seconds!
[tester] 
AGNewsMetric: acc=0.631578947368421, hinge=9.469515920940198, ce=13.431774271914833
Local test acc @ epoch 246: 0.6316
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.04 seconds!
[tester] 
AGNewsMetric: acc=0.8286842105263158, hinge=3.7368307959406, ce=10.489414174933183
Local test acc @ epoch 246: 0.8287
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901159417490817e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 1.4901159417490817e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.55 seconds!
[tester] 
AGNewsMetric: acc=0.8273684210526315, hinge=3.8861761979052893, ce=10.47976034465589
Local test acc @ epoch 246: 0.8274
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.71 seconds!
[tester] 
AGNewsMetric: acc=0.8417105263157895, hinge=3.523701007868114, ce=10.377774198431718
Local test acc @ epoch 246: 0.8417
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0026644645258784294
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.947285496356926e-08
Local loss @ local epoch 3: 7.94728478581419e-08
Local loss @ local epoch 4: 1.1920928244535389e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.14 seconds!
[tester] 
AGNewsMetric: acc=0.5506578947368421, hinge=9.099445887113871, ce=13.163643381219162
Local test acc @ epoch 246: 0.5507
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 3.4678998872550437e-07
Local loss @ local epoch 2: 1.0837207575775665e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.56 seconds!
[tester] 
AGNewsMetric: acc=0.8215789473684211, hinge=3.704497020370082, ce=9.233677293877852
Local test acc @ epoch 246: 0.8216
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 9.934106870446158e-09
Local loss @ local epoch 1: 1.9868211964535476e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.9868213740892315e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.16 seconds!
[tester] 
AGNewsMetric: acc=0.8407894736842105, hinge=3.3223774237381782, ce=10.103377115350021
Local test acc @ epoch 246: 0.8408
Global evaluate on test data...
Evaluate data in 126.68 seconds!
[tester] 
AGNewsMetric: acc=0.8469736842105263, hinge=3.421431754890241, ce=9.741446633589895
Global test acc @ epoch 246: 0.847
Global epoch 247...
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 6.705520405603238e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.5646199358343438e-07
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 5.2154042862184724e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.94 seconds!
[tester] 
AGNewsMetric: acc=0.7298684210526316, hinge=6.60535438838758, ce=12.562156223497892
Local test acc @ epoch 247: 0.7299
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 2.2252365283748077e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.947285496356926e-09
Local loss @ local epoch 3: 4.768370942542788e-08
Local loss @ local epoch 4: 7.947285496356926e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.84 seconds!
[tester] 
AGNewsMetric: acc=0.7873684210526316, hinge=5.1100093028419895, ce=11.499640918530917
Local test acc @ epoch 247: 0.7874
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.9802320611338473e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.07 seconds!
[tester] 
AGNewsMetric: acc=0.7222368421052632, hinge=6.435778037623355, ce=12.493177879735043
Local test acc @ epoch 247: 0.7222
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 4.768370942542788e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 4.768370942542788e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.75 seconds!
[tester] 
AGNewsMetric: acc=0.8242105263157895, hinge=3.888876634397005, ce=10.017118369654606
Local test acc @ epoch 247: 0.8242
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 9.934106870446158e-09
Local loss @ local epoch 1: 1.7881374958506058e-07
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.9802296808156825e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.13 seconds!
[tester] 
AGNewsMetric: acc=0.8211842105263157, hinge=4.172305321442454, ce=9.881751530295924
Local test acc @ epoch 247: 0.8212
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.94728478581419e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.94728478581419e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.14 seconds!
[tester] 
AGNewsMetric: acc=0.7657894736842106, hinge=5.533875095467819, ce=11.749227369208086
Local test acc @ epoch 247: 0.7658
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 8.994838935905136e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 3.467903866294364e-07
Local loss @ local epoch 3: 1.1969408988952637
Local loss @ local epoch 4: 2.492556347988284e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.02 seconds!
[tester] 
AGNewsMetric: acc=0.7393421052631579, hinge=4.330296923737777, ce=11.732562225743344
Local test acc @ epoch 247: 0.7393
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 1.9868213740892315e-08
Local loss @ local epoch 1: 1.4901149825163884e-07
Local loss @ local epoch 2: 9.934106870446158e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.72 seconds!
[tester] 
AGNewsMetric: acc=0.5925, hinge=10.677826761948435, ce=15.835166856866135
Local test acc @ epoch 247: 0.5925
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 8.514947325011235e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.6075258255004883
Local loss @ local epoch 3: 2.7247818934483803e-07
Local loss @ local epoch 4: 0.005834396928548813
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.61 seconds!
[tester] 
AGNewsMetric: acc=0.8168421052631579, hinge=3.2292639215368975, ce=9.475903623480546
Local test acc @ epoch 247: 0.8168
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 1.6255800971975987e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.26 seconds!
[tester] 
AGNewsMetric: acc=0.7077631578947369, hinge=6.946398668791119, ce=12.72792584870991
Local test acc @ epoch 247: 0.7078
Global evaluate on test data...
Evaluate data in 123.67 seconds!
[tester] 
AGNewsMetric: acc=0.843421052631579, hinge=3.5401039454811496, ce=9.921678384479723
Global test acc @ epoch 247: 0.8434
Global epoch 248...
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.384185648907078e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.35 seconds!
[tester] 
AGNewsMetric: acc=0.8363157894736842, hinge=3.6140833582376177, ce=10.093818116439015
Local test acc @ epoch 248: 0.8363
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 1.9868213740892315e-08
Local loss @ local epoch 1: 9.934106870446158e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.96 seconds!
[tester] 
AGNewsMetric: acc=0.7578947368421053, hinge=5.870636968110737, ce=12.066624129445929
Local test acc @ epoch 248: 0.7579
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.167441337519449e-08
Local loss @ local epoch 4: 1.0837207575775665e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.37 seconds!
[tester] 
AGNewsMetric: acc=0.8363157894736842, hinge=3.6573476590608296, ce=10.03567163969341
Local test acc @ epoch 248: 0.8363
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 1.9868211964535476e-08
Local loss @ local epoch 1: 2.9802317058624794e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.67 seconds!
[tester] 
AGNewsMetric: acc=0.8239473684210527, hinge=3.8994641831046657, ce=10.224469658701043
Local test acc @ epoch 248: 0.8239
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.079427570104599
Local loss @ local epoch 1: 1.0837207575775665e-08
Local loss @ local epoch 2: 0.23449967801570892
Local loss @ local epoch 3: 1.1920923981278975e-07
Local loss @ local epoch 4: 4.334883030310266e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.34 seconds!
[tester] 
AGNewsMetric: acc=0.7878947368421053, hinge=4.556418008051421, ce=11.256386572185315
Local test acc @ epoch 248: 0.7879
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 3.7252892326478104e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.43 seconds!
[tester] 
AGNewsMetric: acc=0.841842105263158, hinge=3.5365818718860025, ce=9.962247003254138
Local test acc @ epoch 248: 0.8418
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 3.4059794984386826e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 5.108969247658024e-08
Local loss @ local epoch 3: 5.108968892386656e-08
Local loss @ local epoch 4: 1.7029897492193413e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.99 seconds!
[tester] 
AGNewsMetric: acc=0.6548684210526315, hinge=8.177026132282458, ce=13.701611593146072
Local test acc @ epoch 248: 0.6549
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 2.9802320611338473e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.86 seconds!
[tester] 
AGNewsMetric: acc=0.8380263157894737, hinge=3.778221393258948, ce=10.220169709858142
Local test acc @ epoch 248: 0.838
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 3.973642748178463e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.85 seconds!
[tester] 
AGNewsMetric: acc=0.7227631578947369, hinge=6.566982887167679, ce=12.84836502677516
Local test acc @ epoch 248: 0.7228
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 2.384185471271394e-08
Local loss @ local epoch 1: 1.5894569216357013e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.98 seconds!
[tester] 
AGNewsMetric: acc=0.783157894736842, hinge=5.615825780818337, ce=11.670995527568616
Local test acc @ epoch 248: 0.7832
Global evaluate on test data...
Evaluate data in 123.87 seconds!
[tester] 
AGNewsMetric: acc=0.8478947368421053, hinge=3.44744285508206, ce=9.805243225097657
Global test acc @ epoch 248: 0.8479
Global epoch 249...
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.167441337519449e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.66 seconds!
[tester] 
AGNewsMetric: acc=0.8475, hinge=3.441049947362197, ce=9.839269997446161
Local test acc @ epoch 249: 0.8475
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 1.9868213740892315e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0007720576249994338
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.09 seconds!
[tester] 
AGNewsMetric: acc=0.8018421052631579, hinge=4.460705678588465, ce=10.670023179305227
Local test acc @ epoch 249: 0.8018
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 7.94728478581419e-08
Local loss @ local epoch 1: 7.94728478581419e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.73 seconds!
[tester] 
AGNewsMetric: acc=0.7219736842105263, hinge=6.801986243599339, ce=12.36449265530235
Local test acc @ epoch 249: 0.722
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 9.934106870446158e-09
Local loss @ local epoch 3: 1.9868213740892315e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.11 seconds!
[tester] 
AGNewsMetric: acc=0.8427631578947369, hinge=3.495189135953, ce=10.063220963729055
Local test acc @ epoch 249: 0.8428
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.7029897492193413e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.7029897492193413e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.63 seconds!
[tester] 
AGNewsMetric: acc=0.8236842105263158, hinge=3.984191167480067, ce=10.712929721631502
Local test acc @ epoch 249: 0.8237
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.9802320611338473e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 5.960463766996327e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.92 seconds!
[tester] 
AGNewsMetric: acc=0.8452631578947368, hinge=3.513638010150508, ce=10.028574776900442
Local test acc @ epoch 249: 0.8453
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 1.4702361568197375e-06
Local loss @ local epoch 1: 7.947285496356926e-09
Local loss @ local epoch 2: 7.947285496356926e-09
Local loss @ local epoch 3: 1.5894570992713852e-08
Local loss @ local epoch 4: 1.5894570992713852e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.24 seconds!
[tester] 
AGNewsMetric: acc=0.5782894736842106, hinge=10.970910481904683, ce=16.377060113204152
Local test acc @ epoch 249: 0.5783
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 2.384185648907078e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.49 seconds!
[tester] 
AGNewsMetric: acc=0.849078947368421, hinge=3.454964518045124, ce=9.651348895022744
Local test acc @ epoch 249: 0.8491
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4006935771249118e-06
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 3.7252892326478104e-08
Local loss @ local epoch 3: 7.748590746814443e-07
Local loss @ local epoch 4: 1.4901159417490817e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.65 seconds!
[tester] 
AGNewsMetric: acc=0.6272368421052632, hinge=9.50996210800974, ce=14.965449710645174
Local test acc @ epoch 249: 0.6272
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 5.418602455620203e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 3.2511618286434896e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.29 seconds!
[tester] 
AGNewsMetric: acc=0.5267105263157895, hinge=11.895267461475573, ce=16.6874839622096
Local test acc @ epoch 249: 0.5267
Global evaluate on test data...
Evaluate data in 123.19 seconds!
[tester] 
AGNewsMetric: acc=0.8436842105263158, hinge=3.5830025173488416, ce=10.00152228505988
Global test acc @ epoch 249: 0.8437
Global epoch 250...
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 1.0837207575775665e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 6.502322946744243e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.76 seconds!
[tester] 
AGNewsMetric: acc=0.8444736842105263, hinge=3.543650719743026, ce=9.964412803649902
Local test acc @ epoch 250: 0.8445
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901159417490817e-08
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.33 seconds!
[tester] 
AGNewsMetric: acc=0.8285526315789473, hinge=4.129240196629574, ce=10.554882788407175
Local test acc @ epoch 250: 0.8286
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.086161714487389e-07
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 8.940696005765858e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.55 seconds!
[tester] 
AGNewsMetric: acc=0.7172368421052632, hinge=6.53583177190078, ce=11.738248578121787
Local test acc @ epoch 250: 0.7172
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 1.9868213740892315e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.9802317058624794e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 9.934106870446158e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.39 seconds!
[tester] 
AGNewsMetric: acc=0.8307894736842105, hinge=3.801753369883487, ce=10.057935088308234
Local test acc @ epoch 250: 0.8308
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.17754678428173065
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 3.49678953170951e-06
Local loss @ local epoch 4: 0.0002056681114481762
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.89 seconds!
[tester] 
AGNewsMetric: acc=0.4380263157894737, hinge=14.860300443548905, ce=17.344381236026162
Local test acc @ epoch 250: 0.438
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 3.2511618286434896e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.92 seconds!
[tester] 
AGNewsMetric: acc=0.7832894736842105, hinge=5.1949194175318665, ce=11.087277697512977
Local test acc @ epoch 250: 0.7833
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.7029897492193413e-08
Local loss @ local epoch 2: 2.8950805130989465e-07
Local loss @ local epoch 3: 3.405979143167315e-08
Local loss @ local epoch 4: 1.5326905611345865e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.83 seconds!
[tester] 
AGNewsMetric: acc=0.6356578947368421, hinge=8.330979269931191, ce=13.862246852673982
Local test acc @ epoch 250: 0.6357
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.947285496356926e-09
Local loss @ local epoch 2: 7.947285496356926e-09
Local loss @ local epoch 3: 7.947285496356926e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.05 seconds!
[tester] 
AGNewsMetric: acc=0.84, hinge=3.7180588920492874, ce=10.07672614850496
Local test acc @ epoch 250: 0.84
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.4305112472356996e-07
Local loss @ local epoch 3: 1.907348377017115e-07
Local loss @ local epoch 4: 1.4305112472356996e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.04 seconds!
[tester] 
AGNewsMetric: acc=0.45921052631578946, hinge=12.249919535988255, ce=18.4162124914872
Local test acc @ epoch 250: 0.4592
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.947281943643247e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.28 seconds!
[tester] 
AGNewsMetric: acc=0.7730263157894737, hinge=5.454124451185527, ce=11.78122045818128
Local test acc @ epoch 250: 0.773
Global evaluate on test data...
Evaluate data in 123.99 seconds!
[tester] 
AGNewsMetric: acc=0.8496052631578948, hinge=3.424245317986137, ce=9.682188206722861
Global test acc @ epoch 250: 0.8496
Global epoch 251...
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 1.0837207575775665e-08
Local loss @ local epoch 1: 1.0837207575775665e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.0837207575775665e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.53 seconds!
[tester] 
AGNewsMetric: acc=0.8360526315789474, hinge=3.7559677577018737, ce=9.972539287366365
Local test acc @ epoch 251: 0.8361
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 1.3510371843494795e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 3.178913488000035e-08
Local loss @ local epoch 3: 4.529937598363176e-07
Local loss @ local epoch 4: 2.384185648907078e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.28 seconds!
[tester] 
AGNewsMetric: acc=0.6059210526315789, hinge=9.372561190755743, ce=14.764158981724789
Local test acc @ epoch 251: 0.6059
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 4.768370942542788e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.68 seconds!
[tester] 
AGNewsMetric: acc=0.8464473684210526, hinge=3.4839335858194453, ce=9.842201644495914
Local test acc @ epoch 251: 0.8464
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.09 seconds!
[tester] 
AGNewsMetric: acc=0.8461842105263158, hinge=3.4553040794322367, ce=9.958171728033768
Local test acc @ epoch 251: 0.8462
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 9.753482288488158e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.62 seconds!
[tester] 
AGNewsMetric: acc=0.7202631578947368, hinge=6.790100452021549, ce=12.735207780536852
Local test acc @ epoch 251: 0.7203
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 9.934106870446158e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 9.934106870446158e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.41 seconds!
[tester] 
AGNewsMetric: acc=0.8425, hinge=3.6015241492422003, ce=9.967089932090358
Local test acc @ epoch 251: 0.8425
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 1.4901159417490817e-08
Local loss @ local epoch 2: 1.4901159417490817e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.08 seconds!
[tester] 
AGNewsMetric: acc=0.8106578947368421, hinge=4.484070640865125, ce=10.799615416275827
Local test acc @ epoch 251: 0.8107
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 8.940695295223122e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.8 seconds!
[tester] 
AGNewsMetric: acc=0.8417105263157895, hinge=3.561255626176533, ce=10.375718339618883
Local test acc @ epoch 251: 0.8417
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 3.973642748178463e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.589456815054291e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.93 seconds!
[tester] 
AGNewsMetric: acc=0.8210526315789474, hinge=4.357467112290232, ce=10.053512125517193
Local test acc @ epoch 251: 0.8211
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 6.81195828633463e-08
Local loss @ local epoch 1: 0.0003046946949325502
Local loss @ local epoch 2: 2.0690178871154785
Local loss @ local epoch 3: 0.32636207342147827
Local loss @ local epoch 4: 0.2606552541255951
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.1 seconds!
[tester] 
AGNewsMetric: acc=0.6325, hinge=3.578563941905373, ce=9.872693007619757
Local test acc @ epoch 251: 0.6325
Global evaluate on test data...
Evaluate data in 123.98 seconds!
[tester] 
AGNewsMetric: acc=0.8486842105263158, hinge=3.409693617569773, ce=9.686604413484272
Global test acc @ epoch 251: 0.8487
Global epoch 252...
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.94728478581419e-08
Local loss @ local epoch 2: 3.973642748178463e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.09 seconds!
[tester] 
AGNewsMetric: acc=0.7151315789473685, hinge=7.129922769948056, ce=12.232151449103105
Local test acc @ epoch 252: 0.7151
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 1.7029897492193413e-08
Local loss @ local epoch 1: 3.4059794984386826e-08
Local loss @ local epoch 2: 3.4059794984386826e-08
Local loss @ local epoch 3: 1.7029897492193413e-08
Local loss @ local epoch 4: 6.811957575791894e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.08 seconds!
[tester] 
AGNewsMetric: acc=0.8003947368421053, hinge=4.625153004997655, ce=11.001564274838096
Local test acc @ epoch 252: 0.8004
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.36 seconds!
[tester] 
AGNewsMetric: acc=0.7942105263157895, hinge=4.9894840505248625, ce=11.345377388000488
Local test acc @ epoch 252: 0.7942
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 6.880106957396492e-05
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 3.2511618286434896e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.07 seconds!
[tester] 
AGNewsMetric: acc=0.530921052631579, hinge=10.592629406577663, ce=14.405751760382401
Local test acc @ epoch 252: 0.5309
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.9802320611338473e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.24 seconds!
[tester] 
AGNewsMetric: acc=0.8347368421052631, hinge=3.7334021354976454, ce=10.098220234921104
Local test acc @ epoch 252: 0.8347
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 3.725289943190546e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.309676574441255e-07
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.4901159417490817e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.17 seconds!
[tester] 
AGNewsMetric: acc=0.7902631578947369, hinge=4.960504014868485, ce=10.926657170747456
Local test acc @ epoch 252: 0.7903
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 2.384185648907078e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.384185648907078e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.74 seconds!
[tester] 
AGNewsMetric: acc=0.8488157894736842, hinge=3.4177057074245654, ce=10.06026414369282
Local test acc @ epoch 252: 0.8488
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 5.483611289491819e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.8450697300286265e-06
Local loss @ local epoch 4: 0.8248433470726013
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.06 seconds!
[tester] 
AGNewsMetric: acc=0.7173684210526315, hinge=7.162624650252493, ce=13.889280889410722
Local test acc @ epoch 252: 0.7174
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 1.0837202069069463e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.8176702926430153e-07
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.4 seconds!
[tester] 
AGNewsMetric: acc=0.7418421052631579, hinge=5.957464640767951, ce=11.856345756932308
Local test acc @ epoch 252: 0.7418
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.947284075271455e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.24 seconds!
[tester] 
AGNewsMetric: acc=0.7889473684210526, hinge=5.085305477945428, ce=11.037838341562372
Local test acc @ epoch 252: 0.7889
Global evaluate on test data...
Evaluate data in 124.41 seconds!
[tester] 
AGNewsMetric: acc=0.8480263157894737, hinge=3.4445086800424676, ce=9.784889024433337
Global test acc @ epoch 252: 0.848
Global epoch 253...
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 3.973642037635727e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 9.934106870446158e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.37 seconds!
[tester] 
AGNewsMetric: acc=0.8184210526315789, hinge=4.067466539081774, ce=9.953496519389905
Local test acc @ epoch 253: 0.8184
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 3.5762766970037774e-07
Local loss @ local epoch 1: 3.973642748178463e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 3.973642748178463e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.72 seconds!
[tester] 
AGNewsMetric: acc=0.656578947368421, hinge=7.431692203722502, ce=12.996021838941072
Local test acc @ epoch 253: 0.6566
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 9.753485130659101e-08
Local loss @ local epoch 2: 3.2511621839148575e-08
Local loss @ local epoch 3: 2.167441337519449e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.23 seconds!
[tester] 
AGNewsMetric: acc=0.8393421052631579, hinge=3.278908745113172, ce=9.506814438669306
Local test acc @ epoch 253: 0.8393
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 2.2351738238057806e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.26 seconds!
[tester] 
AGNewsMetric: acc=0.7684210526315789, hinge=5.950600486805564, ce=12.073358065956517
Local test acc @ epoch 253: 0.7684
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.06 seconds!
[tester] 
AGNewsMetric: acc=0.7597368421052632, hinge=5.678194741700825, ce=11.586053858305279
Local test acc @ epoch 253: 0.7597
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 3.405979143167315e-08
Local loss @ local epoch 1: 0.0020551406778395176
Local loss @ local epoch 2: 2.6055536181956995e-06
Local loss @ local epoch 3: 3.4400291042402387e-06
Local loss @ local epoch 4: 0.00010820564784808084
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.97 seconds!
[tester] 
AGNewsMetric: acc=0.8139473684210526, hinge=2.7077451801300048, ce=7.824143793206466
Local test acc @ epoch 253: 0.8139
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 1.5894569216357013e-08
Local loss @ local epoch 1: 1.5894570992713852e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.43 seconds!
[tester] 
AGNewsMetric: acc=0.8346052631578947, hinge=3.7189207850004498, ce=10.150054734882556
Local test acc @ epoch 253: 0.8346
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0010869951220229268
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.1457660182022664e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.16 seconds!
[tester] 
AGNewsMetric: acc=0.36947368421052634, hinge=14.489393310546875, ce=20.691557629233913
Local test acc @ epoch 253: 0.3695
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 2.9802317058624794e-08
Local loss @ local epoch 1: 2.4835230760800187e-07
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.11 seconds!
[tester] 
AGNewsMetric: acc=0.8002631578947368, hinge=4.15465185843016, ce=10.820412603679456
Local test acc @ epoch 253: 0.8003
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 5.418602455620203e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.0837207575775665e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.65 seconds!
[tester] 
AGNewsMetric: acc=0.7571052631578947, hinge=5.485359145716617, ce=11.288017048082853
Local test acc @ epoch 253: 0.7571
Global evaluate on test data...
Evaluate data in 123.81 seconds!
[tester] 
AGNewsMetric: acc=0.8535526315789473, hinge=3.3171757230005765, ce=9.584651979145251
Global test acc @ epoch 253: 0.8536
Global epoch 254...
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.93 seconds!
[tester] 
AGNewsMetric: acc=0.8536842105263158, hinge=3.2998826057032535, ce=9.813557251378109
Local test acc @ epoch 254: 0.8537
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 3.9736416823643594e-08
Local loss @ local epoch 1: 7.152553394007555e-08
Local loss @ local epoch 2: 7.788297011757095e-07
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0001366961223538965
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.71 seconds!
[tester] 
AGNewsMetric: acc=0.7342105263157894, hinge=7.513351495893378, ce=13.306316526312576
Local test acc @ epoch 254: 0.7342
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.0837207575775665e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.71 seconds!
[tester] 
AGNewsMetric: acc=0.8444736842105263, hinge=3.4947170917611374, ce=9.813180066158896
Local test acc @ epoch 254: 0.8445
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.94728478581419e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.94728478581419e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.67 seconds!
[tester] 
AGNewsMetric: acc=0.7389473684210527, hinge=6.645934882916902, ce=12.051739939639443
Local test acc @ epoch 254: 0.7389
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 2.9802317058624794e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 4.470336136819242e-07
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.95 seconds!
[tester] 
AGNewsMetric: acc=0.7351315789473685, hinge=5.989085467489142, ce=12.188492602298135
Local test acc @ epoch 254: 0.7351
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.947281943643247e-08
Local loss @ local epoch 4: 2.9802317058624794e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.66 seconds!
[tester] 
AGNewsMetric: acc=0.8486842105263158, hinge=3.5024223651384054, ce=9.602282935694644
Local test acc @ epoch 254: 0.8487
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 1.0837207575775665e-08
Local loss @ local epoch 1: 1.0837207575775665e-08
Local loss @ local epoch 2: 7.47764318020927e-07
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0013268871698528528
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.52 seconds!
[tester] 
AGNewsMetric: acc=0.7684210526315789, hinge=5.423535671736064, ce=11.451961473163806
Local test acc @ epoch 254: 0.7684
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 4.470347647611561e-08
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.69 seconds!
[tester] 
AGNewsMetric: acc=0.804078947368421, hinge=4.876899726516322, ce=11.294936085751182
Local test acc @ epoch 254: 0.8041
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.26705485582351685
Local loss @ local epoch 2: 6.811958996877365e-08
Local loss @ local epoch 3: 1.2754829185723793e-05
Local loss @ local epoch 4: 2.454380512237549
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.52 seconds!
[tester] 
AGNewsMetric: acc=0.5675, hinge=7.834881500444914, ce=13.017040102105392
Local test acc @ epoch 254: 0.5675
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.4901156930591242e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.19 seconds!
[tester] 
AGNewsMetric: acc=0.8486842105263158, hinge=3.4140002499128643, ce=9.922176752592389
Local test acc @ epoch 254: 0.8487
Global evaluate on test data...
Evaluate data in 124.19 seconds!
[tester] 
AGNewsMetric: acc=0.848421052631579, hinge=3.4369789527591905, ce=9.675161305477745
Global test acc @ epoch 254: 0.8484
Global epoch 255...
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.03628548979759216
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 8.195632972274325e-08
Local loss @ local epoch 3: 1.7881369274164172e-07
Local loss @ local epoch 4: 6.042243057891028e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.32 seconds!
[tester] 
AGNewsMetric: acc=0.5969736842105263, hinge=9.757301190024927, ce=15.39734457517925
Local test acc @ epoch 255: 0.597
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 4.967052191773291e-08
Local loss @ local epoch 3: 9.934106870446158e-09
Local loss @ local epoch 4: 4.927173449686961e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.92 seconds!
[tester] 
AGNewsMetric: acc=0.8134210526315789, hinge=4.128644231746072, ce=10.322781245582982
Local test acc @ epoch 255: 0.8134
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 4.334882675038898e-08
Local loss @ local epoch 4: 1.0837207575775665e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.84 seconds!
[tester] 
AGNewsMetric: acc=0.8296052631578947, hinge=3.891912181126444, ce=10.199846279746607
Local test acc @ epoch 255: 0.8296
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.9868211964535476e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.45 seconds!
[tester] 
AGNewsMetric: acc=0.83, hinge=3.837101454985769, ce=10.20473413567794
Local test acc @ epoch 255: 0.83
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 3.065379416966607e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 5.108969247658024e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.7029897492193413e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.95 seconds!
[tester] 
AGNewsMetric: acc=0.8, hinge=4.196194942373978, ce=10.699129150792173
Local test acc @ epoch 255: 0.8
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 3.2511618286434896e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 3.2511618286434896e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.25 seconds!
[tester] 
AGNewsMetric: acc=0.8344736842105264, hinge=3.721449950368781, ce=9.963027084752133
Local test acc @ epoch 255: 0.8345
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.9802320611338473e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.23 seconds!
[tester] 
AGNewsMetric: acc=0.8522368421052632, hinge=3.340638386575799, ce=9.892874743812962
Local test acc @ epoch 255: 0.8522
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.384185648907078e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.91 seconds!
[tester] 
AGNewsMetric: acc=0.8452631578947368, hinge=3.5356880768976713, ce=9.751846474095395
Local test acc @ epoch 255: 0.8453
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.18 seconds!
[tester] 
AGNewsMetric: acc=0.8053947368421053, hinge=4.376824172170538, ce=10.842857525474146
Local test acc @ epoch 255: 0.8054
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 1.5099830363851652e-07
Local loss @ local epoch 1: 2.384185648907078e-08
Local loss @ local epoch 2: 7.152553394007555e-08
Local loss @ local epoch 3: 4.768370942542788e-08
Local loss @ local epoch 4: 8.74201049327894e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.26 seconds!
[tester] 
AGNewsMetric: acc=0.665, hinge=8.75806598010816, ce=14.111042129115054
Local test acc @ epoch 255: 0.665
Global evaluate on test data...
Evaluate data in 124.25 seconds!
[tester] 
AGNewsMetric: acc=0.8444736842105263, hinge=3.4987172013834904, ce=9.861167321456106
Global test acc @ epoch 255: 0.8445
Global epoch 256...
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 2.384185648907078e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.12 seconds!
[tester] 
AGNewsMetric: acc=0.8493421052631579, hinge=3.3976090283142892, ce=10.087637174505936
Local test acc @ epoch 256: 0.8493
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.52 seconds!
[tester] 
AGNewsMetric: acc=0.8052631578947368, hinge=4.746571623651605, ce=11.212528981660542
Local test acc @ epoch 256: 0.8053
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.11 seconds!
[tester] 
AGNewsMetric: acc=0.8253947368421053, hinge=4.1412459201561775, ce=10.616147623564068
Local test acc @ epoch 256: 0.8254
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 1.5596402818118804e-06
Local loss @ local epoch 1: 9.934106870446158e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.8785642385482788
Local loss @ local epoch 4: 2.06307053565979
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.61 seconds!
[tester] 
AGNewsMetric: acc=0.46960526315789475, hinge=13.719137913051405, ce=17.512739571019225
Local test acc @ epoch 256: 0.4696
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 4.334882675038898e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 4.33488231976753e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.75 seconds!
[tester] 
AGNewsMetric: acc=0.796578947368421, hinge=4.625508438662479, ce=10.323495985332288
Local test acc @ epoch 256: 0.7966
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.947285496356926e-09
Local loss @ local epoch 2: 7.947285496356926e-09
Local loss @ local epoch 3: 3.1789138432714026e-08
Local loss @ local epoch 4: 7.947285496356926e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.83 seconds!
[tester] 
AGNewsMetric: acc=0.8382894736842105, hinge=3.7436726159798472, ce=10.09467601776123
Local test acc @ epoch 256: 0.8383
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.33 seconds!
[tester] 
AGNewsMetric: acc=0.8380263157894737, hinge=3.7671183355231035, ce=10.025211213764392
Local test acc @ epoch 256: 0.838
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.0837207575775665e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 125.68 seconds!
[tester] 
AGNewsMetric: acc=0.8364473684210526, hinge=3.7176754042976783, ce=10.000081829271819
Local test acc @ epoch 256: 0.8364
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 3.405979143167315e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 3.405979143167315e-08
Local loss @ local epoch 3: 3.4059794984386826e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.55 seconds!
[tester] 
AGNewsMetric: acc=0.7832894736842105, hinge=4.883461120254115, ce=11.523325283652857
Local test acc @ epoch 256: 0.7833
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 6.953873565862523e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.85 seconds!
[tester] 
AGNewsMetric: acc=0.8267105263157895, hinge=3.878593871467992, ce=9.910265041150545
Local test acc @ epoch 256: 0.8267
Global evaluate on test data...
Evaluate data in 122.99 seconds!
[tester] 
AGNewsMetric: acc=0.8467105263157895, hinge=3.408196442252711, ce=9.821755953337016
Global test acc @ epoch 256: 0.8467
Global epoch 257...
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.0837207575775665e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.45 seconds!
[tester] 
AGNewsMetric: acc=0.8369736842105263, hinge=3.6107817727641054, ce=10.04062457636783
Local test acc @ epoch 257: 0.837
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 1.0837207575775665e-08
Local loss @ local epoch 1: 1.0837207575775665e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.0837207575775665e-08
Local loss @ local epoch 4: 1.0837207575775665e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.39 seconds!
[tester] 
AGNewsMetric: acc=0.8277631578947369, hinge=3.798675391046624, ce=10.133050113477205
Local test acc @ epoch 257: 0.8278
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.89 seconds!
[tester] 
AGNewsMetric: acc=0.7260526315789474, hinge=5.239152918363873, ce=11.500840068616364
Local test acc @ epoch 257: 0.7261
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.2351738238057806e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 5.960462345910855e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.29 seconds!
[tester] 
AGNewsMetric: acc=0.8342105263157895, hinge=3.818282059368334, ce=10.354807349757145
Local test acc @ epoch 257: 0.8342
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.384185648907078e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.87 seconds!
[tester] 
AGNewsMetric: acc=0.8464473684210526, hinge=3.3742237167609366, ce=9.8607784030312
Local test acc @ epoch 257: 0.8464
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 1.9868211964535476e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 9.934106870446158e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.02 seconds!
[tester] 
AGNewsMetric: acc=0.8377631578947369, hinge=3.4404019094768326, ce=9.586540989122893
Local test acc @ epoch 257: 0.8378
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 3.973642037635727e-08
Local loss @ local epoch 2: 9.934106870446158e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.9868213740892315e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.49 seconds!
[tester] 
AGNewsMetric: acc=0.8351315789473684, hinge=3.8258818261246934, ce=10.041210098266601
Local test acc @ epoch 257: 0.8351
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 3.405979143167315e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.02 seconds!
[tester] 
AGNewsMetric: acc=0.8117105263157894, hinge=4.258069723405336, ce=10.873922661229184
Local test acc @ epoch 257: 0.8117
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 1.1920921849650767e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.947285496356926e-09
Local loss @ local epoch 3: 1.5894569216357013e-08
Local loss @ local epoch 4: 1.5894569216357013e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.13 seconds!
[tester] 
AGNewsMetric: acc=0.7613157894736842, hinge=5.883477724978798, ce=12.16281032963803
Local test acc @ epoch 257: 0.7613
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 4.947137313138228e-06
Local loss @ local epoch 4: 5.960463766996327e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.38 seconds!
[tester] 
AGNewsMetric: acc=0.8472368421052632, hinge=3.394299680559259, ce=9.987203435395893
Local test acc @ epoch 257: 0.8472
Global evaluate on test data...
Evaluate data in 123.85 seconds!
[tester] 
AGNewsMetric: acc=0.8510526315789474, hinge=3.373336381786748, ce=9.711873831497995
Global test acc @ epoch 257: 0.8511
Global epoch 258...
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 7.947285496356926e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.033146332929391e-07
Local loss @ local epoch 3: 1.5894569216357013e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.99 seconds!
[tester] 
AGNewsMetric: acc=0.741578947368421, hinge=6.4769826053318225, ce=12.768322298150313
Local test acc @ epoch 258: 0.7416
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 9.934106870446158e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 9.934106870446158e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.04 seconds!
[tester] 
AGNewsMetric: acc=0.839078947368421, hinge=3.630280586543836, ce=10.028439379240337
Local test acc @ epoch 258: 0.8391
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.52 seconds!
[tester] 
AGNewsMetric: acc=0.8498684210526316, hinge=3.4489012311634264, ce=9.792708139921489
Local test acc @ epoch 258: 0.8499
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.3096757217899722e-07
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 8.195635814445268e-08
Local loss @ local epoch 4: 1.4901159417490817e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.53 seconds!
[tester] 
AGNewsMetric: acc=0.6922368421052632, hinge=8.058499020526284, ce=14.099000738043534
Local test acc @ epoch 258: 0.6922
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 3.405979143167315e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.2309000087261666e-06
Local loss @ local epoch 3: 1.7029897492193413e-08
Local loss @ local epoch 4: 1.7029897492193413e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.99 seconds!
[tester] 
AGNewsMetric: acc=0.8006578947368421, hinge=4.069154498953568, ce=10.68371133904708
Local test acc @ epoch 258: 0.8007
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 5.418602455620203e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.0837207575775665e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.1 seconds!
[tester] 
AGNewsMetric: acc=0.7142105263157895, hinge=7.265580558776856, ce=13.230718699003521
Local test acc @ epoch 258: 0.7142
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 3.973642748178463e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.32 seconds!
[tester] 
AGNewsMetric: acc=0.8244736842105264, hinge=4.026945751591732, ce=10.195794294256913
Local test acc @ epoch 258: 0.8245
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 1.0837207575775665e-08
Local loss @ local epoch 1: 1.6255798129805044e-07
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.8 seconds!
[tester] 
AGNewsMetric: acc=0.8318421052631579, hinge=3.601481526023463, ce=9.064440618816175
Local test acc @ epoch 258: 0.8318
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 3.079567534314265e-07
Local loss @ local epoch 1: 1.9868211964535476e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 3.973642392907095e-08
Local loss @ local epoch 4: 1.09275106296991e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.71 seconds!
[tester] 
AGNewsMetric: acc=0.8323684210526315, hinge=3.3684721499995183, ce=10.38791276831376
Local test acc @ epoch 258: 0.8324
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.384185648907078e-08
Local loss @ local epoch 4: 2.1457667287450022e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.12 seconds!
[tester] 
AGNewsMetric: acc=0.5306578947368421, hinge=10.425877677515933, ce=16.01668035206042
Local test acc @ epoch 258: 0.5307
Global evaluate on test data...
Evaluate data in 124.19 seconds!
[tester] 
AGNewsMetric: acc=0.8372368421052632, hinge=3.747250714051096, ce=10.125417117068642
Global test acc @ epoch 258: 0.8372
Global epoch 259...
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.0837207575775665e-08
Local loss @ local epoch 2: 7.586042727325548e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.58 seconds!
[tester] 
AGNewsMetric: acc=0.8106578947368421, hinge=4.436198815546538, ce=10.516970503957648
Local test acc @ epoch 259: 0.8107
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 9.934106870446158e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.93 seconds!
[tester] 
AGNewsMetric: acc=0.8360526315789474, hinge=3.7194202990280956, ce=10.33786471718236
Local test acc @ epoch 259: 0.8361
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 3.973642037635727e-08
Local loss @ local epoch 2: 9.934106870446158e-09
Local loss @ local epoch 3: 9.934106870446158e-09
Local loss @ local epoch 4: 2.2450785763794556e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.13 seconds!
[tester] 
AGNewsMetric: acc=0.8377631578947369, hinge=3.638502870107952, ce=9.717032398424651
Local test acc @ epoch 259: 0.8378
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 1.0837207575775665e-08
Local loss @ local epoch 1: 1.625580381414693e-07
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.3004641630232072e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.95 seconds!
[tester] 
AGNewsMetric: acc=0.6832894736842106, hinge=8.075507714120965, ce=13.63273637470446
Local test acc @ epoch 259: 0.6833
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.53 seconds!
[tester] 
AGNewsMetric: acc=0.8365789473684211, hinge=3.8113591153998123, ce=10.198042536283793
Local test acc @ epoch 259: 0.8366
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.68 seconds!
[tester] 
AGNewsMetric: acc=0.8411842105263158, hinge=3.4816653638137014, ce=10.154386815522846
Local test acc @ epoch 259: 0.8412
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.23 seconds!
[tester] 
AGNewsMetric: acc=0.8411842105263158, hinge=3.581081003264377, ce=9.753879001015111
Local test acc @ epoch 259: 0.8412
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 1.589456957162838e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 3.973642748178463e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.91 seconds!
[tester] 
AGNewsMetric: acc=0.6996052631578947, hinge=6.676926655016447, ce=12.962350532130191
Local test acc @ epoch 259: 0.6996
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 5.5630994921784804e-08
Local loss @ local epoch 1: 2.0662911026647635e-07
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 6.35782697600007e-08
Local loss @ local epoch 4: 4.768370942542788e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.91 seconds!
[tester] 
AGNewsMetric: acc=0.72, hinge=7.312965157910397, ce=12.435445899963378
Local test acc @ epoch 259: 0.72
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 1.1920925402364446e-07
Local loss @ local epoch 1: 1.9584254005167168e-06
Local loss @ local epoch 2: 4.700180397776421e-06
Local loss @ local epoch 3: 4.0871728401725704e-07
Local loss @ local epoch 4: 1.5326904190260393e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.63 seconds!
[tester] 
AGNewsMetric: acc=0.5042105263157894, hinge=11.498529028641551, ce=16.1892428749486
Local test acc @ epoch 259: 0.5042
Global evaluate on test data...
Evaluate data in 123.61 seconds!
[tester] 
AGNewsMetric: acc=0.8467105263157895, hinge=3.4550217691220735, ce=9.767030768143503
Global test acc @ epoch 259: 0.8467
Global epoch 260...
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 7.788310654177621e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.578144838276785e-05
Local loss @ local epoch 4: 1.5894569216357013e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.81 seconds!
[tester] 
AGNewsMetric: acc=0.6960526315789474, hinge=8.005834339041458, ce=13.995590583399723
Local test acc @ epoch 260: 0.6961
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 9.934106870446158e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.9802317058624794e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.31 seconds!
[tester] 
AGNewsMetric: acc=0.8464473684210526, hinge=3.4678277688277395, ce=9.91528094442267
Local test acc @ epoch 260: 0.8464
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.7029897492193413e-08
Local loss @ local epoch 2: 1.5326899927003979e-07
Local loss @ local epoch 3: 1.7029897492193413e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.62 seconds!
[tester] 
AGNewsMetric: acc=0.8136842105263158, hinge=4.141524922722264, ce=11.386132394891035
Local test acc @ epoch 260: 0.8137
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 2.319133045602939e-06
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.0837207575775665e-08
Local loss @ local epoch 3: 1.4336506865220144e-05
Local loss @ local epoch 4: 0.00010740942525444552
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.09 seconds!
[tester] 
AGNewsMetric: acc=0.7769736842105263, hinge=5.101443879729823, ce=11.417635092484323
Local test acc @ epoch 260: 0.777
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.384185648907078e-08
Local loss @ local epoch 2: 2.384185648907078e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.27 seconds!
[tester] 
AGNewsMetric: acc=0.800921052631579, hinge=4.359851433603387, ce=11.27004105417352
Local test acc @ epoch 260: 0.8009
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 1.350929233012721e-05
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.4901151246249356e-07
Local loss @ local epoch 4: 1.678781336522661e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.29 seconds!
[tester] 
AGNewsMetric: acc=0.5767105263157895, hinge=10.03296035164281, ce=15.435720481872558
Local test acc @ epoch 260: 0.5767
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 1.259317398071289
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 3.2511618286434896e-08
Local loss @ local epoch 3: 3.2511618286434896e-08
Local loss @ local epoch 4: 3.1427850899490295e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.02 seconds!
[tester] 
AGNewsMetric: acc=0.4419736842105263, hinge=13.378418737712659, ce=17.739937575490853
Local test acc @ epoch 260: 0.442
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.947285496356926e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.17 seconds!
[tester] 
AGNewsMetric: acc=0.8061842105263158, hinge=4.3692273993241155, ce=11.298574042069285
Local test acc @ epoch 260: 0.8062
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.9802320611338473e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.3 seconds!
[tester] 
AGNewsMetric: acc=0.841842105263158, hinge=3.632553287932747, ce=10.012708310578999
Local test acc @ epoch 260: 0.8418
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.9802315282267955e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.9802318834981634e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.66 seconds!
[tester] 
AGNewsMetric: acc=0.8331578947368421, hinge=3.9527792721045643, ce=10.189770021940532
Local test acc @ epoch 260: 0.8332
Global evaluate on test data...
Evaluate data in 124.77 seconds!
[tester] 
AGNewsMetric: acc=0.8288157894736842, hinge=3.867449061870575, ce=10.441370478178326
Global test acc @ epoch 260: 0.8288
Global epoch 261...
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.9802320611338473e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.58 seconds!
[tester] 
AGNewsMetric: acc=0.8014473684210527, hinge=4.461595238886382, ce=11.297805932697496
Local test acc @ epoch 261: 0.8014
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 9.934106870446158e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.05 seconds!
[tester] 
AGNewsMetric: acc=0.8417105263157895, hinge=3.5168072542391324, ce=10.43921692898399
Local test acc @ epoch 261: 0.8417
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 7.073063557072601e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 4.6094098138382833e-07
Local loss @ local epoch 4: 3.178913488000035e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.65 seconds!
[tester] 
AGNewsMetric: acc=0.6313157894736842, hinge=10.103776843422338, ce=14.881496349133943
Local test acc @ epoch 261: 0.6313
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 1.5326905611345865e-07
Local loss @ local epoch 1: 1.7029897492193413e-08
Local loss @ local epoch 2: 5.108969247658024e-08
Local loss @ local epoch 3: 6.743786798324436e-06
Local loss @ local epoch 4: 0.30315402150154114
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.19 seconds!
[tester] 
AGNewsMetric: acc=0.5584210526315789, hinge=5.441591182006033, ce=11.833787466350355
Local test acc @ epoch 261: 0.5584
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.152556236178498e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.13 seconds!
[tester] 
AGNewsMetric: acc=0.8338157894736842, hinge=3.6493591358787136, ce=10.609249044719496
Local test acc @ epoch 261: 0.8338
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.167441337519449e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.95 seconds!
[tester] 
AGNewsMetric: acc=0.8111842105263158, hinge=4.271571782764636, ce=10.767728642915424
Local test acc @ epoch 261: 0.8112
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.0837207575775665e-08
Local loss @ local epoch 4: 2.167441337519449e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.58 seconds!
[tester] 
AGNewsMetric: acc=0.8322368421052632, hinge=3.7310751726752835, ce=10.391326834026136
Local test acc @ epoch 261: 0.8322
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 1.9868211964535476e-08
Local loss @ local epoch 1: 9.934106870446158e-09
Local loss @ local epoch 2: 3.973642037635727e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.9802317058624794e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.12 seconds!
[tester] 
AGNewsMetric: acc=0.8168421052631579, hinge=4.013404312384756, ce=10.39292548129433
Local test acc @ epoch 261: 0.8168
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 8.19563723553074e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.1920917586394353e-07
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.87 seconds!
[tester] 
AGNewsMetric: acc=0.6631578947368421, hinge=8.190885279806036, ce=14.648035298397666
Local test acc @ epoch 261: 0.6632
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.94728478581419e-08
Local loss @ local epoch 2: 3.576277265437966e-07
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 3.5762778338721546e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.11 seconds!
[tester] 
AGNewsMetric: acc=0.6238157894736842, hinge=7.38971637324283, ce=13.099044056942589
Local test acc @ epoch 261: 0.6238
Global evaluate on test data...
Evaluate data in 124.35 seconds!
[tester] 
AGNewsMetric: acc=0.8426315789473684, hinge=3.623145137711575, ce=10.163042156821803
Global test acc @ epoch 261: 0.8426
Global epoch 262...
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.04640183225274086
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.0837202779612198e-07
Local loss @ local epoch 3: 2.167441337519449e-08
Local loss @ local epoch 4: 8.778110327511968e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.76 seconds!
[tester] 
AGNewsMetric: acc=0.5634210526315789, hinge=10.2642210468493, ce=15.380853546544126
Local test acc @ epoch 262: 0.5634
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.96 seconds!
[tester] 
AGNewsMetric: acc=0.838421052631579, hinge=3.816172364009054, ce=10.22495809454667
Local test acc @ epoch 262: 0.8384
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 6.488093640655279e-05
Local loss @ local epoch 1: 9.934106870446158e-09
Local loss @ local epoch 2: 1.9868211964535476e-08
Local loss @ local epoch 3: 9.934106870446158e-09
Local loss @ local epoch 4: 0.7673470377922058
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.01 seconds!
[tester] 
AGNewsMetric: acc=0.48907894736842106, hinge=13.873368048918875, ce=18.43630133980199
Local test acc @ epoch 262: 0.4891
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 3.973642392907095e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.947285496356926e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.56 seconds!
[tester] 
AGNewsMetric: acc=0.8134210526315789, hinge=4.478115625632436, ce=11.24819719013415
Local test acc @ epoch 262: 0.8134
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.20778729021549225
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.87 seconds!
[tester] 
AGNewsMetric: acc=0.6126315789473684, hinge=10.212818936799701, ce=15.775548202113102
Local test acc @ epoch 262: 0.6126
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.43 seconds!
[tester] 
AGNewsMetric: acc=0.8438157894736842, hinge=3.5435183190044603, ce=10.062128378215588
Local test acc @ epoch 262: 0.8438
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 7.947285496356926e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.78 seconds!
[tester] 
AGNewsMetric: acc=0.7805263157894737, hinge=4.944968222065976, ce=10.631626105057565
Local test acc @ epoch 262: 0.7805
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 1.9868213740892315e-08
Local loss @ local epoch 1: 9.934106870446158e-09
Local loss @ local epoch 2: 9.934106870446158e-09
Local loss @ local epoch 3: 1.9868211964535476e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.59 seconds!
[tester] 
AGNewsMetric: acc=0.7643421052631579, hinge=5.842939538453755, ce=12.128169376975611
Local test acc @ epoch 262: 0.7643
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0015889331698417664
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 6.502323657286979e-08
Local loss @ local epoch 3: 1.0837207575775665e-08
Local loss @ local epoch 4: 2.167441515155133e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.43 seconds!
[tester] 
AGNewsMetric: acc=0.49486842105263157, hinge=12.706794738267597, ce=18.3590270273309
Local test acc @ epoch 262: 0.4949
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 1.7029897492193413e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.833732524886727e-07
Local loss @ local epoch 3: 5.108968892386656e-08
Local loss @ local epoch 4: 8.514948746096707e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.62 seconds!
[tester] 
AGNewsMetric: acc=0.7540789473684211, hinge=4.890775648418225, ce=11.02042472638582
Local test acc @ epoch 262: 0.7541
Global evaluate on test data...
Evaluate data in 123.87 seconds!
[tester] 
AGNewsMetric: acc=0.8231578947368421, hinge=3.9586875017065752, ce=10.427285176327354
Global test acc @ epoch 262: 0.8232
Global epoch 263...
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.72 seconds!
[tester] 
AGNewsMetric: acc=0.825921052631579, hinge=3.9202247722525345, ce=10.610288961310136
Local test acc @ epoch 263: 0.8259
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.192092469182171e-07
Local loss @ local epoch 1: 6.705518984517767e-08
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.28 seconds!
[tester] 
AGNewsMetric: acc=0.8173684210526316, hinge=4.017144134923031, ce=10.525591533058568
Local test acc @ epoch 263: 0.8174
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.0837207575775665e-08
Local loss @ local epoch 4: 1.0837207575775665e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.88 seconds!
[tester] 
AGNewsMetric: acc=0.8269736842105263, hinge=3.8640104753092714, ce=10.380140232286955
Local test acc @ epoch 263: 0.827
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 3.973642748178463e-08
Local loss @ local epoch 1: 7.418184395646676e-05
Local loss @ local epoch 2: 0.00010635754006216303
Local loss @ local epoch 3: 4.3710065256163944e-07
Local loss @ local epoch 4: 2.2252329472394194e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.96 seconds!
[tester] 
AGNewsMetric: acc=0.719078947368421, hinge=5.714969109485024, ce=11.649333359567743
Local test acc @ epoch 263: 0.7191
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 8.514946614468499e-08
Local loss @ local epoch 1: 1.7029897492193413e-08
Local loss @ local epoch 2: 3.4059794984386826e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 3.5762741390499286e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.7 seconds!
[tester] 
AGNewsMetric: acc=0.7518421052631579, hinge=6.077182527341341, ce=12.336942740992496
Local test acc @ epoch 263: 0.7518
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.42 seconds!
[tester] 
AGNewsMetric: acc=0.8318421052631579, hinge=3.663550620957425, ce=10.512765000995836
Local test acc @ epoch 263: 0.8318
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.17 seconds!
[tester] 
AGNewsMetric: acc=0.8302631578947368, hinge=3.726381103992462, ce=10.380703667088559
Local test acc @ epoch 263: 0.8303
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 1.192092469182171e-07
Local loss @ local epoch 1: 3.178913488000035e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.947285496356926e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.84 seconds!
[tester] 
AGNewsMetric: acc=0.6773684210526316, hinge=8.623558353624846, ce=14.37991572530646
Local test acc @ epoch 263: 0.6774
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 9.934106870446158e-09
Local loss @ local epoch 4: 3.973642037635727e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.85 seconds!
[tester] 
AGNewsMetric: acc=0.82, hinge=4.043478630718432, ce=10.602268120615106
Local test acc @ epoch 263: 0.82
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 1.6987150956992991e-06
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 9.834712955125724e-07
Local loss @ local epoch 4: 3.973634363774181e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.13 seconds!
[tester] 
AGNewsMetric: acc=0.743421052631579, hinge=6.037754262623034, ce=11.895238502903988
Local test acc @ epoch 263: 0.7434
Global evaluate on test data...
Evaluate data in 124.13 seconds!
[tester] 
AGNewsMetric: acc=0.8522368421052632, hinge=3.3935178159412587, ce=9.884827772441664
Global test acc @ epoch 263: 0.8522
Global epoch 264...
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 2.384185648907078e-08
Local loss @ local epoch 1: 7.152553394007555e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.384185471271394e-08
Local loss @ local epoch 4: 5.563098071093009e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.57 seconds!
[tester] 
AGNewsMetric: acc=0.7061842105263157, hinge=7.560058613827354, ce=13.700115242004394
Local test acc @ epoch 264: 0.7062
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 3.2511618286434896e-08
Local loss @ local epoch 1: 2.167441337519449e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.167441337519449e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.17 seconds!
[tester] 
AGNewsMetric: acc=0.8247368421052632, hinge=4.0878184663622, ce=10.028356748882093
Local test acc @ epoch 264: 0.8247
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.9802320611338473e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.59 seconds!
[tester] 
AGNewsMetric: acc=0.8496052631578948, hinge=3.475792938031648, ce=9.990469539040014
Local test acc @ epoch 264: 0.8496
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.4901159417490817e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.2351738238057806e-08
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.18 seconds!
[tester] 
AGNewsMetric: acc=0.84, hinge=3.681440600219526, ce=10.361467066313091
Local test acc @ epoch 264: 0.84
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 9.934106870446158e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.67 seconds!
[tester] 
AGNewsMetric: acc=0.8413157894736842, hinge=3.4958151588941875, ce=10.253553430657638
Local test acc @ epoch 264: 0.8413
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 4.768370942542788e-08
Local loss @ local epoch 2: 2.384185648907078e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.48 seconds!
[tester] 
AGNewsMetric: acc=0.8417105263157895, hinge=3.6173120072013454, ce=9.705233569898104
Local test acc @ epoch 264: 0.8417
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 4.967052902316027e-08
Local loss @ local epoch 1: 9.934106870446158e-09
Local loss @ local epoch 2: 9.934106870446158e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 9.934106870446158e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.4 seconds!
[tester] 
AGNewsMetric: acc=0.6822368421052631, hinge=8.04806921256216, ce=13.676542438707854
Local test acc @ epoch 264: 0.6822
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.0837207575775665e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.9506954629378015e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.36 seconds!
[tester] 
AGNewsMetric: acc=0.8468421052631578, hinge=3.473917579650879, ce=10.037464282387182
Local test acc @ epoch 264: 0.8468
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 5.108969247658024e-08
Local loss @ local epoch 2: 1.7029897492193413e-08
Local loss @ local epoch 3: 5.108968892386656e-08
Local loss @ local epoch 4: 2.52040263148956e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.06 seconds!
[tester] 
AGNewsMetric: acc=0.74, hinge=6.488490963986045, ce=12.613688487002724
Local test acc @ epoch 264: 0.74
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.31 seconds!
[tester] 
AGNewsMetric: acc=0.8067105263157894, hinge=4.174280076277883, ce=10.635397585818643
Local test acc @ epoch 264: 0.8067
Global evaluate on test data...
Evaluate data in 123.65 seconds!
[tester] 
AGNewsMetric: acc=0.8510526315789474, hinge=3.4260937915350262, ce=9.821363041526393
Global test acc @ epoch 264: 0.8511
Global epoch 265...
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 6.357825554914598e-08
Local loss @ local epoch 1: 4.76837058727142e-08
Local loss @ local epoch 2: 7.947285496356926e-09
Local loss @ local epoch 3: 1.5894569216357013e-08
Local loss @ local epoch 4: 7.947285496356926e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.56 seconds!
[tester] 
AGNewsMetric: acc=0.6080263157894736, hinge=11.145157579120836, ce=16.602226552461325
Local test acc @ epoch 265: 0.608
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 5.960463766996327e-08
Local loss @ local epoch 4: 5.9604641222676946e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.75 seconds!
[tester] 
AGNewsMetric: acc=0.8335526315789473, hinge=3.4076320397226434, ce=10.139232513026187
Local test acc @ epoch 265: 0.8336
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 2.079857949865982e-05
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0013819936430081725
Local loss @ local epoch 3: 2.592748614915763e-06
Local loss @ local epoch 4: 0.22368551790714264
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.61 seconds!
[tester] 
AGNewsMetric: acc=0.7002631578947368, hinge=7.548516232339959, ce=13.458295011018452
Local test acc @ epoch 265: 0.7003
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 5.960459930065554e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 5.960460498499742e-07
Local loss @ local epoch 3: 3.973642748178463e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.22 seconds!
[tester] 
AGNewsMetric: acc=0.4469736842105263, hinge=11.853102965103952, ce=16.367010843377365
Local test acc @ epoch 265: 0.447
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 3.973642392907095e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 9.934106870446158e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.68 seconds!
[tester] 
AGNewsMetric: acc=0.8471052631578947, hinge=3.4926461478283533, ce=9.956221590544049
Local test acc @ epoch 265: 0.8471
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.384185648907078e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 4.768370942542788e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.6 seconds!
[tester] 
AGNewsMetric: acc=0.7348684210526316, hinge=5.98474822496113, ce=13.155512484500283
Local test acc @ epoch 265: 0.7349
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.586042727325548e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.0837207575775665e-08
Local loss @ local epoch 4: 4.443146735866321e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.99 seconds!
[tester] 
AGNewsMetric: acc=0.7885526315789474, hinge=4.891837411428753, ce=10.971106603522049
Local test acc @ epoch 265: 0.7886
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.98 seconds!
[tester] 
AGNewsMetric: acc=0.8507894736842105, hinge=3.4091343249772725, ce=9.999867256566098
Local test acc @ epoch 265: 0.8508
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.00508636562153697
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.167441337519449e-08
Local loss @ local epoch 4: 3.2511621839148575e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.0 seconds!
[tester] 
AGNewsMetric: acc=0.3701315789473684, hinge=16.578785263864617, ce=20.3239653938695
Local test acc @ epoch 265: 0.3701
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 3.746572758700495e-07
Local loss @ local epoch 1: 1.7029897492193413e-08
Local loss @ local epoch 2: 6.81195828633463e-08
Local loss @ local epoch 3: 1.7029897492193413e-08
Local loss @ local epoch 4: 1.7029897492193413e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.97 seconds!
[tester] 
AGNewsMetric: acc=0.8173684210526316, hinge=3.956137442588806, ce=10.769758511593468
Local test acc @ epoch 265: 0.8174
Global evaluate on test data...
Evaluate data in 123.88 seconds!
[tester] 
AGNewsMetric: acc=0.8439473684210527, hinge=3.573127469012612, ce=9.964737378170616
Global test acc @ epoch 265: 0.8439
Global epoch 266...
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 4.27165531391438e-07
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 9.934106870446158e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.6 seconds!
[tester] 
AGNewsMetric: acc=0.685921052631579, hinge=7.378657221543161, ce=13.629644681027061
Local test acc @ epoch 266: 0.6859
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 1.9868191714067507e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 4.967052902316027e-08
Local loss @ local epoch 3: 1.0132731631529168e-06
Local loss @ local epoch 4: 9.934106870446158e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.17 seconds!
[tester] 
AGNewsMetric: acc=0.7797368421052632, hinge=4.812467442437222, ce=11.334938077424702
Local test acc @ epoch 266: 0.7797
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 1.0837207575775665e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 5.418602455620203e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.7 seconds!
[tester] 
AGNewsMetric: acc=0.8319736842105263, hinge=3.850041393229836, ce=10.302388978255422
Local test acc @ epoch 266: 0.832
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 2.167441515155133e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 3.2511618286434896e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.99 seconds!
[tester] 
AGNewsMetric: acc=0.838421052631579, hinge=3.6558822954328436, ce=9.81770884664435
Local test acc @ epoch 266: 0.8384
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 2.384185648907078e-08
Local loss @ local epoch 1: 2.384185648907078e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.82 seconds!
[tester] 
AGNewsMetric: acc=0.8426315789473684, hinge=3.541681211371171, ce=9.654428849471243
Local test acc @ epoch 266: 0.8426
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.51 seconds!
[tester] 
AGNewsMetric: acc=0.8371052631578947, hinge=3.752034484210767, ce=10.453519068266216
Local test acc @ epoch 266: 0.8371
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.947285496356926e-09
Local loss @ local epoch 2: 1.5894569216357013e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.6 seconds!
[tester] 
AGNewsMetric: acc=0.8367105263157895, hinge=3.7719264800925005, ce=10.410955748307078
Local test acc @ epoch 266: 0.8367
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 1.7029897492193413e-08
Local loss @ local epoch 1: 6.81195828633463e-08
Local loss @ local epoch 2: 3.405979143167315e-08
Local loss @ local epoch 3: 3.4059794984386826e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.15 seconds!
[tester] 
AGNewsMetric: acc=0.7789473684210526, hinge=4.930925646079214, ce=11.237416259364078
Local test acc @ epoch 266: 0.7789
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0001109598160837777
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.9802315282267955e-08
Local loss @ local epoch 3: 1.8700677628658013e-06
Local loss @ local epoch 4: 1.1503983736038208
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.64 seconds!
[tester] 
AGNewsMetric: acc=0.44394736842105265, hinge=10.657511314592863, ce=15.885499371980366
Local test acc @ epoch 266: 0.4439
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.06 seconds!
[tester] 
AGNewsMetric: acc=0.8294736842105264, hinge=3.9772751524573877, ce=10.65085763228567
Local test acc @ epoch 266: 0.8295
Global evaluate on test data...
Evaluate data in 124.07 seconds!
[tester] 
AGNewsMetric: acc=0.8376315789473684, hinge=3.6953054162075647, ce=10.172055479350844
Global test acc @ epoch 266: 0.8376
Global epoch 267...
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 1.0837207575775665e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.0837207575775665e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.57 seconds!
[tester] 
AGNewsMetric: acc=0.829078947368421, hinge=3.989584487613879, ce=10.385298706857782
Local test acc @ epoch 267: 0.8291
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.947285496356926e-09
Local loss @ local epoch 2: 7.152554815093026e-08
Local loss @ local epoch 3: 7.947285496356926e-09
Local loss @ local epoch 4: 7.947285496356926e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.26 seconds!
[tester] 
AGNewsMetric: acc=0.8305263157894737, hinge=3.971168391579076, ce=10.658077466864334
Local test acc @ epoch 267: 0.8305
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.00027411262271925807
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 4.768370942542788e-08
Local loss @ local epoch 3: 9.536742595628311e-08
Local loss @ local epoch 4: 4.05311396889374e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.68 seconds!
[tester] 
AGNewsMetric: acc=0.3625, hinge=14.68719143114592, ce=20.913488058792918
Local test acc @ epoch 267: 0.3625
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 9.934106870446158e-09
Local loss @ local epoch 1: 9.934106870446158e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.947281943643247e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.91 seconds!
[tester] 
AGNewsMetric: acc=0.7984210526315789, hinge=4.724118513810007, ce=11.079539582101923
Local test acc @ epoch 267: 0.7984
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.91 seconds!
[tester] 
AGNewsMetric: acc=0.8332894736842106, hinge=3.843598326883818, ce=10.377002447027909
Local test acc @ epoch 267: 0.8333
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 5.108968892386656e-08
Local loss @ local epoch 2: 5.108969247658024e-08
Local loss @ local epoch 3: 3.7465750324372493e-07
Local loss @ local epoch 4: 7.152548846534046e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.57 seconds!
[tester] 
AGNewsMetric: acc=0.560921052631579, hinge=11.027802373986495, ce=16.122633683054072
Local test acc @ epoch 267: 0.5609
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.9802320611338473e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.3300713362696115e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.24 seconds!
[tester] 
AGNewsMetric: acc=0.8117105263157894, hinge=4.136961391850521, ce=10.73217512632671
Local test acc @ epoch 267: 0.8117
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 3.178913630108582e-07
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.67 seconds!
[tester] 
AGNewsMetric: acc=0.8327631578947369, hinge=3.871354932534067, ce=10.353497868588097
Local test acc @ epoch 267: 0.8328
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 5.960463766996327e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.2 seconds!
[tester] 
AGNewsMetric: acc=0.7177631578947369, hinge=6.360395466653924, ce=12.405134562442177
Local test acc @ epoch 267: 0.7178
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.88 seconds!
[tester] 
AGNewsMetric: acc=0.8360526315789474, hinge=3.6702938763718858, ce=10.230185655292711
Local test acc @ epoch 267: 0.8361
Global evaluate on test data...
Evaluate data in 123.6 seconds!
[tester] 
AGNewsMetric: acc=0.8401315789473685, hinge=3.7227909475878667, ce=10.188595251786081
Global test acc @ epoch 267: 0.8401
Global epoch 268...
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.4 seconds!
[tester] 
AGNewsMetric: acc=0.8332894736842106, hinge=3.977655831010718, ce=10.387214216935007
Local test acc @ epoch 268: 0.8333
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 2.2351740014414645e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.75 seconds!
[tester] 
AGNewsMetric: acc=0.8251315789473684, hinge=3.990390755251834, ce=10.669855768304123
Local test acc @ epoch 268: 0.8251
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 2.384185648907078e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.16 seconds!
[tester] 
AGNewsMetric: acc=0.8343421052631579, hinge=3.8201747342159873, ce=10.518520080164858
Local test acc @ epoch 268: 0.8343
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.1920928244535389e-07
Local loss @ local epoch 2: 7.94728478581419e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.53 seconds!
[tester] 
AGNewsMetric: acc=0.4155263157894737, hinge=14.480772098742033, ce=18.552371059216952
Local test acc @ epoch 268: 0.4155
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 9.934106870446158e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.36 seconds!
[tester] 
AGNewsMetric: acc=0.8389473684210527, hinge=3.7501350682660153, ce=10.32537704668547
Local test acc @ epoch 268: 0.8389
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 5.108969247658024e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.38 seconds!
[tester] 
AGNewsMetric: acc=0.7951315789473684, hinge=4.968546320764642, ce=11.241966398138748
Local test acc @ epoch 268: 0.7951
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 9.319958280684659e-07
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.0837207575775665e-08
Local loss @ local epoch 4: 1.6472478137075086e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.76 seconds!
[tester] 
AGNewsMetric: acc=0.6927631578947369, hinge=7.11263115029586, ce=13.496136892218338
Local test acc @ epoch 268: 0.6928
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.947285496356926e-09
Local loss @ local epoch 2: 1.5894569216357013e-08
Local loss @ local epoch 3: 4.76837058727142e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.0 seconds!
[tester] 
AGNewsMetric: acc=0.8256578947368421, hinge=4.2061461590465745, ce=10.732659904078433
Local test acc @ epoch 268: 0.8257
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0007715339306741953
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.0837207575775665e-08
Local loss @ local epoch 4: 2.167441337519449e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.73 seconds!
[tester] 
AGNewsMetric: acc=0.4311842105263158, hinge=15.266927348689029, ce=19.18299670169228
Local test acc @ epoch 268: 0.4312
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 9.039990231940465e-07
Local loss @ local epoch 1: 3.973642037635727e-08
Local loss @ local epoch 2: 1.4442940482695121e-05
Local loss @ local epoch 3: 5.662422495333885e-07
Local loss @ local epoch 4: 1.082810626940045e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.5 seconds!
[tester] 
AGNewsMetric: acc=0.7351315789473685, hinge=6.133784902974179, ce=11.66544910029361
Local test acc @ epoch 268: 0.7351
Global evaluate on test data...
Evaluate data in 124.0 seconds!
[tester] 
AGNewsMetric: acc=0.8393421052631579, hinge=3.729777947225069, ce=10.052437846535131
Global test acc @ epoch 268: 0.8393
Global epoch 269...
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.86 seconds!
[tester] 
AGNewsMetric: acc=0.5353947368421053, hinge=11.744600898341128, ce=15.826883243761564
Local test acc @ epoch 269: 0.5354
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.4489912688732147
Local loss @ local epoch 1: 1.5894570992713852e-08
Local loss @ local epoch 2: 7.947285496356926e-09
Local loss @ local epoch 3: 2.042425194304087e-06
Local loss @ local epoch 4: 0.8900144100189209
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.85 seconds!
[tester] 
AGNewsMetric: acc=0.5726315789473684, hinge=9.505835591366417, ce=16.266462918331747
Local test acc @ epoch 269: 0.5726
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 9.934106870446158e-09
Local loss @ local epoch 3: 1.9868211964535476e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.49 seconds!
[tester] 
AGNewsMetric: acc=0.845657894736842, hinge=3.593209845517811, ce=10.169260097302889
Local test acc @ epoch 269: 0.8457
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 5.418602455620203e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.08 seconds!
[tester] 
AGNewsMetric: acc=0.8006578947368421, hinge=4.824750462833204, ce=11.041236373499821
Local test acc @ epoch 269: 0.8007
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 2.9802320611338473e-08
Local loss @ local epoch 1: 5.960463766996327e-08
Local loss @ local epoch 2: 2.9802320611338473e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.9802320611338473e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.02 seconds!
[tester] 
AGNewsMetric: acc=0.8409210526315789, hinge=3.565297050978008, ce=9.818039241589998
Local test acc @ epoch 269: 0.8409
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.046255111694336
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 1.4901159417490817e-08
Local loss @ local epoch 3: 1.4901160305669237e-08
Local loss @ local epoch 4: 5.960463056453591e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.79 seconds!
[tester] 
AGNewsMetric: acc=0.5605263157894737, hinge=9.567987740165309, ce=15.279718477349533
Local test acc @ epoch 269: 0.5605
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.7029897492193413e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.42 seconds!
[tester] 
AGNewsMetric: acc=0.7964473684210527, hinge=5.013808866551048, ce=11.871598261782998
Local test acc @ epoch 269: 0.7964
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 4.334882675038898e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.0837207575775665e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.98 seconds!
[tester] 
AGNewsMetric: acc=0.7421052631578947, hinge=6.055959797909385, ce=12.461232600964998
Local test acc @ epoch 269: 0.7421
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.77 seconds!
[tester] 
AGNewsMetric: acc=0.7910526315789473, hinge=5.0182436512645925, ce=11.74144070073178
Local test acc @ epoch 269: 0.7911
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 9.934106870446158e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.91 seconds!
[tester] 
AGNewsMetric: acc=0.8406578947368422, hinge=3.75242514735774, ce=10.186641622844496
Local test acc @ epoch 269: 0.8407
Global evaluate on test data...
Evaluate data in 123.83 seconds!
[tester] 
AGNewsMetric: acc=0.8288157894736842, hinge=3.9739875799731204, ce=10.613134775663678
Global test acc @ epoch 269: 0.8288
Global epoch 270...
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 1.7029897492193413e-08
Local loss @ local epoch 1: 6.69260271024541e-06
Local loss @ local epoch 2: 0.8645347356796265
Local loss @ local epoch 3: 0.18011359870433807
Local loss @ local epoch 4: 0.007885947823524475
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.95 seconds!
[tester] 
AGNewsMetric: acc=0.6025, hinge=4.1387616087261, ce=7.80230120207134
Local test acc @ epoch 270: 0.6025
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.00012292999599594623
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.15 seconds!
[tester] 
AGNewsMetric: acc=0.8052631578947368, hinge=4.477466225373117, ce=11.208131611472682
Local test acc @ epoch 270: 0.8053
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.75 seconds!
[tester] 
AGNewsMetric: acc=0.8178947368421052, hinge=4.25933469922919, ce=11.058690898292943
Local test acc @ epoch 270: 0.8179
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 4.33488231976753e-08
Local loss @ local epoch 1: 4.33488231976753e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.62 seconds!
[tester] 
AGNewsMetric: acc=0.8210526315789474, hinge=3.7217926319021926, ce=11.108449879696495
Local test acc @ epoch 270: 0.8211
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 9.934106870446158e-09
Local loss @ local epoch 1: 9.934106870446158e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.9868211964535476e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.18 seconds!
[tester] 
AGNewsMetric: acc=0.7988157894736843, hinge=4.520308924097764, ce=11.170704970108835
Local test acc @ epoch 270: 0.7988
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.9868211964535476e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.9868211964535476e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.56 seconds!
[tester] 
AGNewsMetric: acc=0.8296052631578947, hinge=3.9273888631870872, ce=10.508863280446906
Local test acc @ epoch 270: 0.8296
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901159417490817e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.4901159417490817e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.93 seconds!
[tester] 
AGNewsMetric: acc=0.809078947368421, hinge=4.707670022311963, ce=11.038440495541222
Local test acc @ epoch 270: 0.8091
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.1920918296937089e-07
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.463656869622355e-07
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.31 seconds!
[tester] 
AGNewsMetric: acc=0.7676315789473684, hinge=5.879176209600348, ce=12.39222858027408
Local test acc @ epoch 270: 0.7676
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 5.165731522538408e-07
Local loss @ local epoch 2: 1.1920926823449918e-07
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.56 seconds!
[tester] 
AGNewsMetric: acc=0.5681578947368421, hinge=10.1517887597335, ce=15.669165444625051
Local test acc @ epoch 270: 0.5682
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 2.384185648907078e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.384185648907078e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.54 seconds!
[tester] 
AGNewsMetric: acc=0.8294736842105264, hinge=3.7288696651709707, ce=10.062323760986327
Local test acc @ epoch 270: 0.8295
Global evaluate on test data...
Evaluate data in 123.29 seconds!
[tester] 
AGNewsMetric: acc=0.8435526315789473, hinge=3.602658851648632, ce=10.040652734856856
Global test acc @ epoch 270: 0.8436
Global epoch 271...
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 3.973642037635727e-08
Local loss @ local epoch 1: 1.9868211964535476e-08
Local loss @ local epoch 2: 9.934106870446158e-09
Local loss @ local epoch 3: 9.934106870446158e-09
Local loss @ local epoch 4: 1.9868211964535476e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.21 seconds!
[tester] 
AGNewsMetric: acc=0.7901315789473684, hinge=5.241345443725586, ce=11.637326363011411
Local test acc @ epoch 271: 0.7901
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 1.7339517910386348e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.0837207575775665e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.42 seconds!
[tester] 
AGNewsMetric: acc=0.5810526315789474, hinge=11.454651511342902, ce=16.685882122642116
Local test acc @ epoch 271: 0.5811
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.008767659775912762
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.2665977067172207e-07
Local loss @ local epoch 3: 0.8963079452514648
Local loss @ local epoch 4: 2.933481846412178e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.56 seconds!
[tester] 
AGNewsMetric: acc=0.7692105263157895, hinge=4.938950680682534, ce=12.053160681473582
Local test acc @ epoch 271: 0.7692
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 8.940696005765858e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.52 seconds!
[tester] 
AGNewsMetric: acc=0.6910526315789474, hinge=7.884217843507465, ce=13.858427997388338
Local test acc @ epoch 271: 0.6911
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.81 seconds!
[tester] 
AGNewsMetric: acc=0.8410526315789474, hinge=3.6834925019113642, ce=10.398296681454307
Local test acc @ epoch 271: 0.8411
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 1.9868211964535476e-08
Local loss @ local epoch 1: 3.973642037635727e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.99 seconds!
[tester] 
AGNewsMetric: acc=0.796578947368421, hinge=4.949209823608398, ce=10.831255651775159
Local test acc @ epoch 271: 0.7966
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 2.5589833967387676e-06
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.947285496356926e-09
Local loss @ local epoch 3: 6.357827686542805e-08
Local loss @ local epoch 4: 0.003101993352174759
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.32 seconds!
[tester] 
AGNewsMetric: acc=0.6946052631578947, hinge=7.861909355866282, ce=14.359792954294305
Local test acc @ epoch 271: 0.6946
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 4.7683681714261184e-07
Local loss @ local epoch 3: 3.973642748178463e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.26 seconds!
[tester] 
AGNewsMetric: acc=0.765921052631579, hinge=5.014657819647538, ce=11.507872699938323
Local test acc @ epoch 271: 0.7659
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 1.517207977030921e-07
Local loss @ local epoch 1: 3.2511618286434896e-08
Local loss @ local epoch 2: 1.0837202069069463e-07
Local loss @ local epoch 3: 2.92604255491824e-07
Local loss @ local epoch 4: 1.7339520752557291e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.89 seconds!
[tester] 
AGNewsMetric: acc=0.718421052631579, hinge=6.358346516458612, ce=13.145751431113796
Local test acc @ epoch 271: 0.7184
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 1.7029897492193413e-08
Local loss @ local epoch 1: 1.7029897492193413e-08
Local loss @ local epoch 2: 3.4059794984386826e-08
Local loss @ local epoch 3: 2.724781609231286e-07
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.22 seconds!
[tester] 
AGNewsMetric: acc=0.7844736842105263, hinge=4.6867952798542225, ce=11.202340774536133
Local test acc @ epoch 271: 0.7845
Global evaluate on test data...
Evaluate data in 123.79 seconds!
[tester] 
AGNewsMetric: acc=0.8373684210526315, hinge=3.740469606173666, ce=10.53915811237536
Global test acc @ epoch 271: 0.8374
Global epoch 272...
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.167441337519449e-08
Local loss @ local epoch 2: 1.0837207575775665e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 125.27 seconds!
[tester] 
AGNewsMetric: acc=0.8309210526315789, hinge=4.094183304184361, ce=10.587501130355031
Local test acc @ epoch 272: 0.8309
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 2.9802318834981634e-08
Local loss @ local epoch 3: 5.215404996761208e-08
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.84 seconds!
[tester] 
AGNewsMetric: acc=0.8361842105263158, hinge=3.667496368257623, ce=10.662532019364207
Local test acc @ epoch 272: 0.8362
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 3.2635819911956787
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 4.7683538468845654e-06
Local loss @ local epoch 3: 1.3907728089179727e-06
Local loss @ local epoch 4: 7.589595043100417e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.69 seconds!
[tester] 
AGNewsMetric: acc=0.611578947368421, hinge=12.48374533101132, ce=15.359444507799651
Local test acc @ epoch 272: 0.6116
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.78 seconds!
[tester] 
AGNewsMetric: acc=0.8419736842105263, hinge=3.3278852336030256, ce=10.26817011582224
Local test acc @ epoch 272: 0.842
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 9.934106870446158e-09
Local loss @ local epoch 1: 9.934106870446158e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.63 seconds!
[tester] 
AGNewsMetric: acc=0.7964473684210527, hinge=4.845312208376432, ce=11.351676914817409
Local test acc @ epoch 272: 0.7964
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 5.449560944725818e-07
Local loss @ local epoch 1: 1.7029897492193413e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.7029897492193413e-08
Local loss @ local epoch 4: 3.405979143167315e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.59 seconds!
[tester] 
AGNewsMetric: acc=0.6936842105263158, hinge=7.784294840160169, ce=12.977357743915759
Local test acc @ epoch 272: 0.6937
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 2.384185648907078e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.947285496356926e-09
Local loss @ local epoch 3: 7.947285496356926e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.53 seconds!
[tester] 
AGNewsMetric: acc=0.8246052631578947, hinge=4.1092887198297605, ce=10.766618690490724
Local test acc @ epoch 272: 0.8246
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 9.934106870446158e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.9868211964535476e-08
Local loss @ local epoch 3: 9.934106870446158e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.32 seconds!
[tester] 
AGNewsMetric: acc=0.8303947368421053, hinge=3.786671001534713, ce=10.557752629330285
Local test acc @ epoch 272: 0.8304
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 2.167441337519449e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.0837207575775665e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.81 seconds!
[tester] 
AGNewsMetric: acc=0.8231578947368421, hinge=4.027075490951538, ce=10.556106414794922
Local test acc @ epoch 272: 0.8232
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.384185648907078e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.39 seconds!
[tester] 
AGNewsMetric: acc=0.839078947368421, hinge=3.646181869255869, ce=10.60291155363384
Local test acc @ epoch 272: 0.8391
Global evaluate on test data...
Evaluate data in 124.06 seconds!
[tester] 
AGNewsMetric: acc=0.854078947368421, hinge=3.280532574528142, ce=10.006124731365004
Global test acc @ epoch 272: 0.8541
Global epoch 273...
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 4.7683590764791006e-07
Local loss @ local epoch 1: 6.827415290899808e-07
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.0837202069069463e-07
Local loss @ local epoch 4: 3.2511621839148575e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.36 seconds!
[tester] 
AGNewsMetric: acc=0.6611842105263158, hinge=7.900108213424683, ce=14.575820627714458
Local test acc @ epoch 273: 0.6612
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 2.7715725536836544e-06
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.781546299956972e-07
Local loss @ local epoch 4: 0.2182706743478775
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.02 seconds!
[tester] 
AGNewsMetric: acc=0.5111842105263158, hinge=13.633242360667179, ce=17.631017781307822
Local test acc @ epoch 273: 0.5112
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 1.3501179637387395e-05
Local loss @ local epoch 1: 1.1126196142186018e-07
Local loss @ local epoch 2: 3.973642748178463e-08
Local loss @ local epoch 3: 0.6485502123832703
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.72 seconds!
[tester] 
AGNewsMetric: acc=0.7442105263157894, hinge=6.107361079768131, ce=12.355273570010537
Local test acc @ epoch 273: 0.7442
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 3.405979143167315e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 3.405979143167315e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.07 seconds!
[tester] 
AGNewsMetric: acc=0.8364473684210526, hinge=3.730204490987878, ce=10.55676405856484
Local test acc @ epoch 273: 0.8364
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.52 seconds!
[tester] 
AGNewsMetric: acc=0.8518421052631578, hinge=3.3334194331420095, ce=10.104252678720574
Local test acc @ epoch 273: 0.8518
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.384185648907078e-08
Local loss @ local epoch 3: 4.768370942542788e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.97 seconds!
[tester] 
AGNewsMetric: acc=0.8171052631578948, hinge=4.560472215978723, ce=10.978030381453665
Local test acc @ epoch 273: 0.8171
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 9.934106870446158e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.11 seconds!
[tester] 
AGNewsMetric: acc=0.8546052631578948, hinge=3.279354785241579, ce=10.060539639121608
Local test acc @ epoch 273: 0.8546
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 2.9802320611338473e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.9802320611338473e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.75 seconds!
[tester] 
AGNewsMetric: acc=0.8519736842105263, hinge=3.3086289763450623, ce=9.697885533383019
Local test acc @ epoch 273: 0.852
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 8.243916090577841e-05
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 3.725289587919178e-08
Local loss @ local epoch 3: 7.853197894291952e-05
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.15 seconds!
[tester] 
AGNewsMetric: acc=0.5269736842105263, hinge=11.466735344936973, ce=17.32925669820685
Local test acc @ epoch 273: 0.527
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 3.973642748178463e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.23 seconds!
[tester] 
AGNewsMetric: acc=0.8173684210526316, hinge=3.7588068023480865, ce=11.001306421380294
Local test acc @ epoch 273: 0.8174
Global evaluate on test data...
Evaluate data in 123.7 seconds!
[tester] 
AGNewsMetric: acc=0.8393421052631579, hinge=3.626026119056501, ce=10.42330693094354
Global test acc @ epoch 273: 0.8393
Global epoch 274...
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 1.0837207575775665e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.59 seconds!
[tester] 
AGNewsMetric: acc=0.8380263157894737, hinge=3.7067654735163638, ce=10.300871033919485
Local test acc @ epoch 274: 0.838
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.86 seconds!
[tester] 
AGNewsMetric: acc=0.6003947368421053, hinge=10.179491534985994, ce=15.647961935746043
Local test acc @ epoch 274: 0.6004
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.55 seconds!
[tester] 
AGNewsMetric: acc=0.8426315789473684, hinge=3.541849876203035, ce=10.462384747956929
Local test acc @ epoch 274: 0.8426
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 4.768370942542788e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.384185648907078e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.98 seconds!
[tester] 
AGNewsMetric: acc=0.8443421052631579, hinge=3.6357417754123085, ce=10.23890296534488
Local test acc @ epoch 274: 0.8443
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.9802315282267955e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.78 seconds!
[tester] 
AGNewsMetric: acc=0.8447368421052631, hinge=3.52465388310583, ce=10.35583304756566
Local test acc @ epoch 274: 0.8447
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 2.167441337519449e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.0837207575775665e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.18 seconds!
[tester] 
AGNewsMetric: acc=0.7431578947368421, hinge=6.564367424814325, ce=12.525084989447343
Local test acc @ epoch 274: 0.7432
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.9802320611338473e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.09 seconds!
[tester] 
AGNewsMetric: acc=0.8338157894736842, hinge=3.785222661620692, ce=10.658554719623767
Local test acc @ epoch 274: 0.8338
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 1.3510371843494795e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.97 seconds!
[tester] 
AGNewsMetric: acc=0.7205263157894737, hinge=7.456666102158396, ce=12.953353691101075
Local test acc @ epoch 274: 0.7205
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 4.4703443791149766e-07
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.5795180843269918e-06
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.72 seconds!
[tester] 
AGNewsMetric: acc=0.8222368421052632, hinge=3.9713001027860138, ce=10.217650299072266
Local test acc @ epoch 274: 0.8222
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.7029897492193413e-08
Local loss @ local epoch 2: 6.811957575791894e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 5.108969247658024e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.23 seconds!
[tester] 
AGNewsMetric: acc=0.8082894736842106, hinge=4.521196675551565, ce=11.307792974773205
Local test acc @ epoch 274: 0.8083
Global evaluate on test data...
Evaluate data in 123.73 seconds!
[tester] 
AGNewsMetric: acc=0.8502631578947368, hinge=3.432910662826739, ce=10.158070110521818
Global test acc @ epoch 274: 0.8503
Global epoch 275...
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.64 seconds!
[tester] 
AGNewsMetric: acc=0.8188157894736842, hinge=4.266153140319021, ce=10.78932393124229
Local test acc @ epoch 275: 0.8188
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 1.1379001989553217e-06
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.167441515155133e-08
Local loss @ local epoch 3: 5.093473305350926e-07
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.81 seconds!
[tester] 
AGNewsMetric: acc=0.30894736842105264, hinge=18.532570983485172, ce=22.503876880846526
Local test acc @ epoch 275: 0.3089
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.8950813657502295e-07
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 3.4059794984386826e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.36 seconds!
[tester] 
AGNewsMetric: acc=0.7464473684210526, hinge=6.8742430724595724, ce=12.511134181775544
Local test acc @ epoch 275: 0.7464
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 3.2511621839148575e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.62 seconds!
[tester] 
AGNewsMetric: acc=0.7660526315789473, hinge=5.754562245670118, ce=12.315749903227154
Local test acc @ epoch 275: 0.7661
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901159417490817e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.2351738238057806e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.98 seconds!
[tester] 
AGNewsMetric: acc=0.835, hinge=3.8091573702661616, ce=10.77092088598954
Local test acc @ epoch 275: 0.835
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 1.668929030529398e-07
Local loss @ local epoch 1: 7.947285496356926e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 9.53673620074369e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.01 seconds!
[tester] 
AGNewsMetric: acc=0.728421052631579, hinge=7.37700881456074, ce=13.309831785904734
Local test acc @ epoch 275: 0.7284
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 4.172321723672212e-07
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.68 seconds!
[tester] 
AGNewsMetric: acc=0.8413157894736842, hinge=3.448154956165113, ce=10.678374057569002
Local test acc @ epoch 275: 0.8413
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 9.934105804632054e-08
Local loss @ local epoch 1: 9.934106870446158e-09
Local loss @ local epoch 2: 5.960463411724959e-08
Local loss @ local epoch 3: 1.9868211964535476e-08
Local loss @ local epoch 4: 7.053202466522634e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.62 seconds!
[tester] 
AGNewsMetric: acc=0.6636842105263158, hinge=8.56873171505175, ce=13.537559914839894
Local test acc @ epoch 275: 0.6637
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 2.384185648907078e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.68 seconds!
[tester] 
AGNewsMetric: acc=0.8492105263157895, hinge=3.4464008228402387, ce=10.081883502759432
Local test acc @ epoch 275: 0.8492
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 2.9802317058624794e-08
Local loss @ local epoch 1: 9.934106870446158e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.98 seconds!
[tester] 
AGNewsMetric: acc=0.8521052631578947, hinge=3.4256032205882825, ce=10.221877475537752
Local test acc @ epoch 275: 0.8521
Global evaluate on test data...
Evaluate data in 124.3 seconds!
[tester] 
AGNewsMetric: acc=0.844078947368421, hinge=3.5758384035762987, ce=10.162555965624357
Global test acc @ epoch 275: 0.8441
Global epoch 276...
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.0837207575775665e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.78 seconds!
[tester] 
AGNewsMetric: acc=0.8475, hinge=3.5558008810093527, ce=10.206665330184133
Local test acc @ epoch 276: 0.8475
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 3.2511618286434896e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.65 seconds!
[tester] 
AGNewsMetric: acc=0.8402631578947368, hinge=3.651367560687818, ce=10.315934381986919
Local test acc @ epoch 276: 0.8403
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.384185648907078e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.98 seconds!
[tester] 
AGNewsMetric: acc=0.4934210526315789, hinge=12.466535658585398, ce=18.253512312236584
Local test acc @ epoch 276: 0.4934
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 2.9802317058624794e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 3.973642392907095e-08
Local loss @ local epoch 4: 1.9868213740892315e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.16 seconds!
[tester] 
AGNewsMetric: acc=0.5914473684210526, hinge=10.65324102100573, ce=16.132065590306333
Local test acc @ epoch 276: 0.5914
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 3.5285061130707618e-06
Local loss @ local epoch 1: 7.947285496356926e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.3047094543926505e-07
Local loss @ local epoch 4: 4.76837058727142e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.88 seconds!
[tester] 
AGNewsMetric: acc=0.5803947368421053, hinge=10.361387746710527, ce=16.231492727179276
Local test acc @ epoch 276: 0.5804
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 1.9868208767093165e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.89 seconds!
[tester] 
AGNewsMetric: acc=0.7827631578947368, hinge=5.09340091153195, ce=11.220017388996325
Local test acc @ epoch 276: 0.7828
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 6.811957575791894e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.7029897492193413e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.62 seconds!
[tester] 
AGNewsMetric: acc=0.7364473684210526, hinge=6.111706308063708, ce=12.53959995872096
Local test acc @ epoch 276: 0.7364
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 9.934106870446158e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 9.934106870446158e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.13 seconds!
[tester] 
AGNewsMetric: acc=0.8448684210526316, hinge=3.569172373947344, ce=10.185498454445288
Local test acc @ epoch 276: 0.8449
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.27 seconds!
[tester] 
AGNewsMetric: acc=0.8510526315789474, hinge=3.5229701772489044, ce=10.240758247375489
Local test acc @ epoch 276: 0.8511
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.2665974225001264e-07
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.97 seconds!
[tester] 
AGNewsMetric: acc=0.8086842105263158, hinge=4.647485692626551, ce=11.215953929298802
Local test acc @ epoch 276: 0.8087
Global evaluate on test data...
Evaluate data in 123.96 seconds!
[tester] 
AGNewsMetric: acc=0.8473684210526315, hinge=3.598743796975989, ce=10.296383056640625
Global test acc @ epoch 276: 0.8474
Global epoch 277...
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.0837207575775665e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.0837207575775665e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.62 seconds!
[tester] 
AGNewsMetric: acc=0.828421052631579, hinge=4.023855837646283, ce=10.592656629461992
Local test acc @ epoch 277: 0.8284
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 1.9868213740892315e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 9.934106870446158e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.35 seconds!
[tester] 
AGNewsMetric: acc=0.8313157894736842, hinge=3.9589792564040738, ce=10.410643585606625
Local test acc @ epoch 277: 0.8313
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 8.127542969305068e-06
Local loss @ local epoch 2: 1.0837207575775665e-08
Local loss @ local epoch 3: 1.6038925423345063e-06
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.35 seconds!
[tester] 
AGNewsMetric: acc=0.5680263157894737, hinge=12.06436733045076, ce=17.112636066235993
Local test acc @ epoch 277: 0.568
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 5.563098071093009e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.947285496356926e-09
Local loss @ local epoch 4: 7.947285496356926e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.84 seconds!
[tester] 
AGNewsMetric: acc=0.7630263157894737, hinge=6.256184781727038, ce=12.563033915067974
Local test acc @ epoch 277: 0.763
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 4.7683684556432127e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.94728478581419e-08
Local loss @ local epoch 4: 3.973642748178463e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.05 seconds!
[tester] 
AGNewsMetric: acc=0.5655263157894737, hinge=10.268231795461555, ce=15.36480301505641
Local test acc @ epoch 277: 0.5655
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 5.215404996761208e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.98 seconds!
[tester] 
AGNewsMetric: acc=0.7713157894736842, hinge=5.92175297536348, ce=12.30100241811652
Local test acc @ epoch 277: 0.7713
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 6.85450629589468e-07
Local loss @ local epoch 1: 1.9868213740892315e-08
Local loss @ local epoch 2: 6.139052402431844e-06
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 9.934106870446158e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.73 seconds!
[tester] 
AGNewsMetric: acc=0.74, hinge=6.028162410133763, ce=12.066769029717696
Local test acc @ epoch 277: 0.74
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 1.1920923981278975e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 5.790161594632082e-07
Local loss @ local epoch 3: 4.4277678057369485e-07
Local loss @ local epoch 4: 1.7029897492193413e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.32 seconds!
[tester] 
AGNewsMetric: acc=0.7906578947368421, hinge=4.750281849158438, ce=10.899421117682206
Local test acc @ epoch 277: 0.7907
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.68 seconds!
[tester] 
AGNewsMetric: acc=0.838421052631579, hinge=3.7460841360845065, ce=10.750175765188116
Local test acc @ epoch 277: 0.8384
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.93 seconds!
[tester] 
AGNewsMetric: acc=0.8465789473684211, hinge=3.675538622454593, ce=10.581723921926399
Local test acc @ epoch 277: 0.8466
Global evaluate on test data...
Evaluate data in 124.96 seconds!
[tester] 
AGNewsMetric: acc=0.8368421052631579, hinge=3.7147700917093376, ce=10.298190610785234
Global test acc @ epoch 277: 0.8368
Global epoch 278...
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.55 seconds!
[tester] 
AGNewsMetric: acc=0.8417105263157895, hinge=3.5811898429770217, ce=10.321415341025904
Local test acc @ epoch 278: 0.8417
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 3.973642748178463e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 3.973642748178463e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.72 seconds!
[tester] 
AGNewsMetric: acc=0.7860526315789473, hinge=4.96105802184657, ce=10.705305591382478
Local test acc @ epoch 278: 0.7861
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 2.9802320611338473e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.33 seconds!
[tester] 
AGNewsMetric: acc=0.8426315789473684, hinge=3.6796781600149053, ce=10.322722497237356
Local test acc @ epoch 278: 0.8426
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 3.091423195655807e-06
Local loss @ local epoch 1: 2.384185471271394e-08
Local loss @ local epoch 2: 4.927301802126749e-07
Local loss @ local epoch 3: 1.5894570992713852e-08
Local loss @ local epoch 4: 1.5894570992713852e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.46 seconds!
[tester] 
AGNewsMetric: acc=0.6969736842105263, hinge=8.200833588901318, ce=13.522158409921747
Local test acc @ epoch 278: 0.697
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 8.514947325011235e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.7029897492193413e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.49 seconds!
[tester] 
AGNewsMetric: acc=0.7153947368421053, hinge=7.12202279040688, ce=12.972133648521021
Local test acc @ epoch 278: 0.7154
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.51 seconds!
[tester] 
AGNewsMetric: acc=0.8415789473684211, hinge=3.7640354019717166, ce=10.46845780021266
Local test acc @ epoch 278: 0.8416
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.9802320611338473e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.55 seconds!
[tester] 
AGNewsMetric: acc=0.8394736842105263, hinge=3.6558357602671574, ce=10.30548743398566
Local test acc @ epoch 278: 0.8395
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.06668850779533386
Local loss @ local epoch 2: 6.705519695060502e-08
Local loss @ local epoch 3: 2.9802320611338473e-08
Local loss @ local epoch 4: 2.9802320611338473e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.34 seconds!
[tester] 
AGNewsMetric: acc=0.6819736842105263, hinge=7.554639120101928, ce=14.110781260038676
Local test acc @ epoch 278: 0.682
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.9868211964535476e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.9868211964535476e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.41 seconds!
[tester] 
AGNewsMetric: acc=0.8226315789473684, hinge=4.259135805431165, ce=10.656607214275159
Local test acc @ epoch 278: 0.8226
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 1.0837207575775665e-08
Local loss @ local epoch 1: 1.0837207575775665e-08
Local loss @ local epoch 2: 2.167441337519449e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.56 seconds!
[tester] 
AGNewsMetric: acc=0.7936842105263158, hinge=4.763136137912148, ce=10.955244210895739
Local test acc @ epoch 278: 0.7937
Global evaluate on test data...
Evaluate data in 123.82 seconds!
[tester] 
AGNewsMetric: acc=0.8523684210526316, hinge=3.4803717751252026, ce=9.905876938669305
Global test acc @ epoch 278: 0.8524
Global epoch 279...
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 3.405979143167315e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.7029897492193413e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.86 seconds!
[tester] 
AGNewsMetric: acc=0.8265789473684211, hinge=4.252734608650208, ce=10.723024593152498
Local test acc @ epoch 279: 0.8266
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 1.0837207575775665e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.1 seconds!
[tester] 
AGNewsMetric: acc=0.8506578947368421, hinge=3.4688275667240744, ce=9.819583860698499
Local test acc @ epoch 279: 0.8507
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.03 seconds!
[tester] 
AGNewsMetric: acc=0.8436842105263158, hinge=3.6587089925063285, ce=10.235689108999152
Local test acc @ epoch 279: 0.8437
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 2.9802320611338473e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.58 seconds!
[tester] 
AGNewsMetric: acc=0.8443421052631579, hinge=3.7395996791438053, ce=10.003476411919845
Local test acc @ epoch 279: 0.8443
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.08 seconds!
[tester] 
AGNewsMetric: acc=0.8526315789473684, hinge=3.5209879447284496, ce=10.426496469598067
Local test acc @ epoch 279: 0.8526
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 4.917367846246634e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 9.685746960030883e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.51 seconds!
[tester] 
AGNewsMetric: acc=0.5957894736842105, hinge=10.588824783124421, ce=16.032677417554353
Local test acc @ epoch 279: 0.5958
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.9802317058624794e-08
Local loss @ local epoch 3: 3.973642037635727e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.54 seconds!
[tester] 
AGNewsMetric: acc=0.8243421052631579, hinge=4.142155762848101, ce=10.615550179732473
Local test acc @ epoch 279: 0.8243
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 1.5894569216357013e-08
Local loss @ local epoch 1: 1.0172454949497478e-06
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 3.178913488000035e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.27 seconds!
[tester] 
AGNewsMetric: acc=0.6711842105263158, hinge=8.816627709740086, ce=14.274273404573139
Local test acc @ epoch 279: 0.6712
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.1920926823449918e-07
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.46 seconds!
[tester] 
AGNewsMetric: acc=0.7355263157894737, hinge=6.839654625340512, ce=12.39321012195788
Local test acc @ epoch 279: 0.7355
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 1.4305112472356996e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 3.0994391408967203e-07
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 125.06 seconds!
[tester] 
AGNewsMetric: acc=0.6506578947368421, hinge=8.527709860550729, ce=13.985894430060135
Local test acc @ epoch 279: 0.6507
Global evaluate on test data...
Evaluate data in 124.97 seconds!
[tester] 
AGNewsMetric: acc=0.8439473684210527, hinge=3.708047752380371, ce=10.060715962460167
Global test acc @ epoch 279: 0.8439
Global epoch 280...
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 1.7182135707116686e-05
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 5.108969247658024e-08
Local loss @ local epoch 3: 1.0186212062835693
Local loss @ local epoch 4: 1.192088575407979e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.0 seconds!
[tester] 
AGNewsMetric: acc=0.8164473684210526, hinge=3.584545808716824, ce=11.310735927381014
Local test acc @ epoch 280: 0.8164
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.947285496356926e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 3.9736416823643594e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.11 seconds!
[tester] 
AGNewsMetric: acc=0.8377631578947369, hinge=3.9429363412606087, ce=10.280710180182206
Local test acc @ epoch 280: 0.8378
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 1.1920921139108032e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 9.934106870446158e-09
Local loss @ local epoch 3: 6.953872144777051e-08
Local loss @ local epoch 4: 1.092751560349825e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.52 seconds!
[tester] 
AGNewsMetric: acc=0.6673684210526316, hinge=8.200470004332693, ce=14.00465463537919
Local test acc @ epoch 280: 0.6674
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.384185648907078e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.384185648907078e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.97 seconds!
[tester] 
AGNewsMetric: acc=0.8368421052631579, hinge=3.8331708734913876, ce=10.084981669375772
Local test acc @ epoch 280: 0.8368
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.89 seconds!
[tester] 
AGNewsMetric: acc=0.7051315789473684, hinge=7.051479415893555, ce=12.382586886757299
Local test acc @ epoch 280: 0.7051
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.37 seconds!
[tester] 
AGNewsMetric: acc=0.8392105263157895, hinge=3.758814489465011, ce=10.131927773325067
Local test acc @ epoch 280: 0.8392
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.4901159417490817e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.92 seconds!
[tester] 
AGNewsMetric: acc=0.8417105263157895, hinge=3.744371378547267, ce=10.181461954618754
Local test acc @ epoch 280: 0.8417
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 1.1270626600889955e-06
Local loss @ local epoch 1: 1.0837207575775665e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.006564691662788391
Local loss @ local epoch 4: 4.334882675038898e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.11 seconds!
[tester] 
AGNewsMetric: acc=0.8338157894736842, hinge=3.9041200050554776, ce=10.044594901235481
Local test acc @ epoch 280: 0.8338
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.9008855223655701
Local loss @ local epoch 1: 1.0837207575775665e-08
Local loss @ local epoch 2: 7.586044858953755e-08
Local loss @ local epoch 3: 2.167441337519449e-08
Local loss @ local epoch 4: 4.909126346319681e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.68 seconds!
[tester] 
AGNewsMetric: acc=0.616578947368421, hinge=8.546997163672197, ce=12.966973435251337
Local test acc @ epoch 280: 0.6166
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 1.1567435264587402
Local loss @ local epoch 1: 9.934106870446158e-09
Local loss @ local epoch 2: 3.079567534314265e-07
Local loss @ local epoch 3: 4.3709965780180937e-07
Local loss @ local epoch 4: 0.001227383385412395
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.92 seconds!
[tester] 
AGNewsMetric: acc=0.35289473684210526, hinge=17.37702016529284, ce=21.191995444046825
Local test acc @ epoch 280: 0.3529
Global evaluate on test data...
Evaluate data in 124.26 seconds!
[tester] 
AGNewsMetric: acc=0.839078947368421, hinge=3.716243400448247, ce=10.099016245791786
Global test acc @ epoch 280: 0.8391
Global epoch 281...
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 1.1175863079415649e-07
Local loss @ local epoch 4: 4.4703469370688254e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.09 seconds!
[tester] 
AGNewsMetric: acc=0.8352631578947368, hinge=3.7387646407830086, ce=10.319768749036287
Local test acc @ epoch 281: 0.8353
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.0837207575775665e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.9 seconds!
[tester] 
AGNewsMetric: acc=0.8356578947368422, hinge=3.8352961129891243, ce=10.281466578433388
Local test acc @ epoch 281: 0.8357
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.24 seconds!
[tester] 
AGNewsMetric: acc=0.7447368421052631, hinge=5.765525150299072, ce=11.85060713717812
Local test acc @ epoch 281: 0.7447
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 1.9868213740892315e-08
Local loss @ local epoch 1: 9.934106870446158e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 9.934106870446158e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.71 seconds!
[tester] 
AGNewsMetric: acc=0.8365789473684211, hinge=3.857558388459055, ce=10.013970387107447
Local test acc @ epoch 281: 0.8366
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 9.934106870446158e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 9.934106870446158e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.8 seconds!
[tester] 
AGNewsMetric: acc=0.8409210526315789, hinge=3.6904561924934387, ce=10.098853454589843
Local test acc @ epoch 281: 0.8409
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.6255798129805044e-07
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 4.659988803723536e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.42 seconds!
[tester] 
AGNewsMetric: acc=0.8034210526315789, hinge=4.57358006151099, ce=10.724526742634021
Local test acc @ epoch 281: 0.8034
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 3.4059794984386826e-08
Local loss @ local epoch 1: 3.4059794984386826e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.7029897492193413e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 122.99 seconds!
[tester] 
AGNewsMetric: acc=0.7934210526315789, hinge=4.528050185504712, ce=11.14724753931949
Local test acc @ epoch 281: 0.7934
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.9802320611338473e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.57 seconds!
[tester] 
AGNewsMetric: acc=0.7507894736842106, hinge=6.296100154675935, ce=12.80483926471911
Local test acc @ epoch 281: 0.7508
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 1.5894570992713852e-08
Local loss @ local epoch 1: 2.384185471271394e-08
Local loss @ local epoch 2: 7.947285496356926e-09
Local loss @ local epoch 3: 1.8278731772625179e-07
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 126.45 seconds!
[tester] 
AGNewsMetric: acc=0.8442105263157895, hinge=3.664376274661014, ce=10.380291760093288
Local test acc @ epoch 281: 0.8442
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.94 seconds!
[tester] 
AGNewsMetric: acc=0.838421052631579, hinge=3.8218721158880937, ce=10.274187132182874
Local test acc @ epoch 281: 0.8384
Global evaluate on test data...
Evaluate data in 123.89 seconds!
[tester] 
AGNewsMetric: acc=0.8481578947368421, hinge=3.604199554292779, ce=9.946934804414449
Global test acc @ epoch 281: 0.8482
Global epoch 282...
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.28 seconds!
[tester] 
AGNewsMetric: acc=0.8467105263157895, hinge=3.643015627861023, ce=10.101973676179584
Local test acc @ epoch 282: 0.8467
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.62 seconds!
[tester] 
AGNewsMetric: acc=0.8465789473684211, hinge=3.6645579291644848, ce=10.179617676985892
Local test acc @ epoch 282: 0.8466
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 7.947285496356926e-09
Local loss @ local epoch 1: 7.947285496356926e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 3.178913488000035e-08
Local loss @ local epoch 4: 3.9736416823643594e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.82 seconds!
[tester] 
AGNewsMetric: acc=0.8288157894736842, hinge=4.204446638006913, ce=10.409750685440867
Local test acc @ epoch 282: 0.8288
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 4.334883030310266e-08
Local loss @ local epoch 2: 0.0001520596706541255
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.2938707186549436e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.71 seconds!
[tester] 
AGNewsMetric: acc=0.623421052631579, hinge=9.042350395604183, ce=15.05176065143786
Local test acc @ epoch 282: 0.6234
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 9.934106870446158e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 9.934106870446158e-09
Local loss @ local epoch 4: 2.9802317058624794e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.35 seconds!
[tester] 
AGNewsMetric: acc=0.848421052631579, hinge=3.484442349860543, ce=9.935094833374023
Local test acc @ epoch 282: 0.8484
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 4.33488231976753e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.0837207575775665e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.11 seconds!
[tester] 
AGNewsMetric: acc=0.7531578947368421, hinge=5.810097056439048, ce=12.285141436928196
Local test acc @ epoch 282: 0.7532
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 3.973642748178463e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.94728478581419e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.08 seconds!
[tester] 
AGNewsMetric: acc=0.5153947368421052, hinge=10.933975163509972, ce=16.3206682988217
Local test acc @ epoch 282: 0.5154
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 7.450576333667414e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.42 seconds!
[tester] 
AGNewsMetric: acc=0.8185526315789474, hinge=4.398939845436498, ce=10.763709987841155
Local test acc @ epoch 282: 0.8186
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 6.953873565862523e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 9.934106870446158e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 9.934106870446158e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.1 seconds!
[tester] 
AGNewsMetric: acc=0.6647368421052632, hinge=9.370393120615105, ce=14.720342706379137
Local test acc @ epoch 282: 0.6647
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 3.661383061626111e-06
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 6.81195828633463e-08
Local loss @ local epoch 3: 8.514948746096707e-08
Local loss @ local epoch 4: 3.4059783615703054e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.04 seconds!
[tester] 
AGNewsMetric: acc=0.6718421052631579, hinge=7.7257559475145845, ce=12.496443557739259
Local test acc @ epoch 282: 0.6718
Global evaluate on test data...
Evaluate data in 124.3 seconds!
[tester] 
AGNewsMetric: acc=0.8457894736842105, hinge=3.6131767275458886, ce=9.971758513199656
Global test acc @ epoch 282: 0.8458
Global epoch 283...
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 8.514947325011235e-08
Local loss @ local epoch 1: 1.7029897492193413e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.81 seconds!
[tester] 
AGNewsMetric: acc=0.8026315789473685, hinge=4.696309839800785, ce=11.315578793977437
Local test acc @ epoch 283: 0.8026
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 5.201852673053509e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.0837207575775665e-08
Local loss @ local epoch 3: 0.3529682457447052
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.95 seconds!
[tester] 
AGNewsMetric: acc=0.7693421052631579, hinge=5.576857799730803, ce=11.704318984182258
Local test acc @ epoch 283: 0.7693
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.1920926823449918e-07
Local loss @ local epoch 3: 2.384185648907078e-08
Local loss @ local epoch 4: 1.1920926823449918e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.08 seconds!
[tester] 
AGNewsMetric: acc=0.3985526315789474, hinge=15.098573825233862, ce=20.397102030703895
Local test acc @ epoch 283: 0.3986
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 3.973642748178463e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.9 seconds!
[tester] 
AGNewsMetric: acc=0.8161842105263157, hinge=4.239467498503234, ce=11.357702249225817
Local test acc @ epoch 283: 0.8162
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 9.93410154137564e-08
Local loss @ local epoch 3: 9.934106870446158e-09
Local loss @ local epoch 4: 9.934106870446158e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.1 seconds!
[tester] 
AGNewsMetric: acc=0.8396052631578947, hinge=3.6065556713154443, ce=10.324879166452508
Local test acc @ epoch 283: 0.8396
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.12 seconds!
[tester] 
AGNewsMetric: acc=0.7894736842105263, hinge=5.37154067591617, ce=11.901414704573781
Local test acc @ epoch 283: 0.7895
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 8.250542305177078e-05
Local loss @ local epoch 1: 1.4901159417490817e-08
Local loss @ local epoch 2: 1.4901159417490817e-08
Local loss @ local epoch 3: 1.8626430176027498e-07
Local loss @ local epoch 4: 1.4677477793156868e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.89 seconds!
[tester] 
AGNewsMetric: acc=0.4817105263157895, hinge=12.755715858057926, ce=18.186537061992446
Local test acc @ epoch 283: 0.4817
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 1.0837207575775665e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.7 seconds!
[tester] 
AGNewsMetric: acc=0.7688157894736842, hinge=5.323911066557232, ce=11.830066901759098
Local test acc @ epoch 283: 0.7688
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 2.829186314556864e-06
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.5894569216357013e-08
Local loss @ local epoch 3: 1.025195388137945e-06
Local loss @ local epoch 4: 7.947285496356926e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.43 seconds!
[tester] 
AGNewsMetric: acc=0.6171052631578947, hinge=9.341528751975611, ce=15.239139781751131
Local test acc @ epoch 283: 0.6171
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.9802320611338473e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 9.934106870446158e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.64 seconds!
[tester] 
AGNewsMetric: acc=0.8398684210526316, hinge=3.658217402131934, ce=10.430089645385742
Local test acc @ epoch 283: 0.8399
Global evaluate on test data...
Evaluate data in 124.14 seconds!
[tester] 
AGNewsMetric: acc=0.8248684210526316, hinge=4.194767369973032, ce=10.69496128684596
Global test acc @ epoch 283: 0.8249
Global epoch 284...
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 4.33488231976753e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.39 seconds!
[tester] 
AGNewsMetric: acc=0.7517105263157895, hinge=6.341577477706106, ce=12.568574957596628
Local test acc @ epoch 284: 0.7517
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.9802320611338473e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.2 seconds!
[tester] 
AGNewsMetric: acc=0.8277631578947369, hinge=3.8471111130714415, ce=10.67767383374666
Local test acc @ epoch 284: 0.8278
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 4.967052191773291e-08
Local loss @ local epoch 1: 9.93410154137564e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.2891962230205536
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.77 seconds!
[tester] 
AGNewsMetric: acc=0.7647368421052632, hinge=5.380984065909135, ce=11.780263493186549
Local test acc @ epoch 284: 0.7647
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.9868213740892315e-08
Local loss @ local epoch 2: 1.9868213740892315e-08
Local loss @ local epoch 3: 1.9868211964535476e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.16 seconds!
[tester] 
AGNewsMetric: acc=0.8026315789473685, hinge=4.821446166791414, ce=11.130253309952586
Local test acc @ epoch 284: 0.8026
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 8.514948746096707e-08
Local loss @ local epoch 1: 8.004044502740726e-07
Local loss @ local epoch 2: 0.00014105836453381926
Local loss @ local epoch 3: 0.00015894390526227653
Local loss @ local epoch 4: 0.0023984152358025312
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.16 seconds!
[tester] 
AGNewsMetric: acc=0.6285526315789474, hinge=4.3199117823650965, ce=10.970527393943385
Local test acc @ epoch 284: 0.6286
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.384185648907078e-08
Local loss @ local epoch 2: 1.5894569216357013e-08
Local loss @ local epoch 3: 7.947285496356926e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.67 seconds!
[tester] 
AGNewsMetric: acc=0.8018421052631579, hinge=5.171607777695907, ce=11.541515304163882
Local test acc @ epoch 284: 0.8018
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.2351740014414645e-08
Local loss @ local epoch 3: 1.1175860947787442e-07
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.05 seconds!
[tester] 
AGNewsMetric: acc=0.8157894736842105, hinge=4.432284870147705, ce=10.934066919025621
Local test acc @ epoch 284: 0.8158
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.8610207891688333e-07
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.18 seconds!
[tester] 
AGNewsMetric: acc=0.825, hinge=4.075670438314739, ce=10.9513772763704
Local test acc @ epoch 284: 0.825
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 1.1920928244535389e-07
Local loss @ local epoch 1: 5.960461066933931e-07
Local loss @ local epoch 2: 0.0010525049874559045
Local loss @ local epoch 3: 6.397510787792271e-06
Local loss @ local epoch 4: 7.0333048824977595e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.04 seconds!
[tester] 
AGNewsMetric: acc=0.5802631578947368, hinge=11.049438365133184, ce=14.748926106503136
Local test acc @ epoch 284: 0.5803
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 4.334882675038898e-08
Local loss @ local epoch 2: 1.0837207575775665e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.2 seconds!
[tester] 
AGNewsMetric: acc=0.7947368421052632, hinge=4.751091034035934, ce=11.108438821089894
Local test acc @ epoch 284: 0.7947
Global evaluate on test data...
Evaluate data in 122.71 seconds!
[tester] 
AGNewsMetric: acc=0.8502631578947368, hinge=3.4391520432422036, ce=9.902844304536519
Global test acc @ epoch 284: 0.8503
Global epoch 285...
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.8312146582720743e-07
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.51 seconds!
[tester] 
AGNewsMetric: acc=0.8285526315789473, hinge=3.9035404215360945, ce=10.725701719585217
Local test acc @ epoch 285: 0.8286
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 4.768370942542788e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.54 seconds!
[tester] 
AGNewsMetric: acc=0.8497368421052631, hinge=3.467602175034975, ce=10.074982448377106
Local test acc @ epoch 285: 0.8497
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 9.934106870446158e-09
Local loss @ local epoch 1: 1.9868211964535476e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.9868211964535476e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.4 seconds!
[tester] 
AGNewsMetric: acc=0.8517105263157895, hinge=3.3566823118611384, ce=9.877493533084268
Local test acc @ epoch 285: 0.8517
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.7029897492193413e-08
Local loss @ local epoch 4: 8.514946614468499e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.08 seconds!
[tester] 
AGNewsMetric: acc=0.8451315789473685, hinge=3.510763427081861, ce=10.50162077853554
Local test acc @ epoch 285: 0.8451
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 9.298268537349941e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.5894569216357013e-08
Local loss @ local epoch 3: 0.5302070379257202
Local loss @ local epoch 4: 6.357827686542805e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.05 seconds!
[tester] 
AGNewsMetric: acc=0.7443421052631579, hinge=6.242536699897364, ce=12.778267900567306
Local test acc @ epoch 285: 0.7443
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 6.166447565192357e-05
Local loss @ local epoch 1: 1.0837207575775665e-08
Local loss @ local epoch 2: 1.0837202069069463e-07
Local loss @ local epoch 3: 8.669762507906853e-08
Local loss @ local epoch 4: 1.1920868701054133e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.8 seconds!
[tester] 
AGNewsMetric: acc=0.6067105263157895, hinge=9.951554993077329, ce=16.42557761342902
Local test acc @ epoch 285: 0.6067
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 3.973642748178463e-08
Local loss @ local epoch 1: 3.973642748178463e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 122.21 seconds!
[tester] 
AGNewsMetric: acc=0.8313157894736842, hinge=4.039825084083959, ce=10.513941889311138
Local test acc @ epoch 285: 0.8313
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 2.9802320611338473e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.3841846541472478e-07
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.9802320611338473e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 122.33 seconds!
[tester] 
AGNewsMetric: acc=0.849078947368421, hinge=3.3975045181575574, ce=9.390552677355315
Local test acc @ epoch 285: 0.8491
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 3.7749521197838476e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.2914334490687907e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 122.74 seconds!
[tester] 
AGNewsMetric: acc=0.5039473684210526, hinge=12.91383830120689, ce=18.160032308478105
Local test acc @ epoch 285: 0.5039
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 2.167441337519449e-08
Local loss @ local epoch 1: 4.334882675038898e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.32 seconds!
[tester] 
AGNewsMetric: acc=0.7306578947368421, hinge=6.63648664574874, ce=12.968737074199476
Local test acc @ epoch 285: 0.7307
Global evaluate on test data...
Evaluate data in 123.08 seconds!
[tester] 
AGNewsMetric: acc=0.8402631578947368, hinge=3.73988576161234, ce=10.215899762605366
Global test acc @ epoch 285: 0.8403
Global epoch 286...
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 2.3841828067361348e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.2351738238057806e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.3857926433047396e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.08 seconds!
[tester] 
AGNewsMetric: acc=0.6298684210526316, hinge=10.315073138789126, ce=15.289872452585321
Local test acc @ epoch 286: 0.6299
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 9.934106870446158e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.91 seconds!
[tester] 
AGNewsMetric: acc=0.8461842105263158, hinge=3.589420046429885, ce=10.081264206735712
Local test acc @ epoch 286: 0.8462
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.8 seconds!
[tester] 
AGNewsMetric: acc=0.8473684210526315, hinge=3.5752079422850356, ce=10.319724032753392
Local test acc @ epoch 286: 0.8474
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 6.811957575791894e-08
Local loss @ local epoch 1: 1.5326899927003979e-07
Local loss @ local epoch 2: 1.7029897492193413e-08
Local loss @ local epoch 3: 5.108969247658024e-08
Local loss @ local epoch 4: 1.7029897492193413e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.97 seconds!
[tester] 
AGNewsMetric: acc=0.6588157894736842, hinge=8.997827258862948, ce=14.535221649973016
Local test acc @ epoch 286: 0.6588
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.33 seconds!
[tester] 
AGNewsMetric: acc=0.8442105263157895, hinge=3.5538629240738717, ce=10.263693502325761
Local test acc @ epoch 286: 0.8442
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0006209704442881048
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 3.273331458331086e-05
Local loss @ local epoch 4: 3.1427850899490295e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.63 seconds!
[tester] 
AGNewsMetric: acc=0.7663157894736842, hinge=4.938707422959177, ce=10.86191338990864
Local test acc @ epoch 286: 0.7663
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 6.357827686542805e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.947285496356926e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.92 seconds!
[tester] 
AGNewsMetric: acc=0.8256578947368421, hinge=4.489533952160885, ce=10.856500555339613
Local test acc @ epoch 286: 0.8257
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 1.5814724974916317e-05
Local loss @ local epoch 1: 6.238561127247522e-06
Local loss @ local epoch 2: 1.589456815054291e-07
Local loss @ local epoch 3: 1.1920926823449918e-07
Local loss @ local epoch 4: 5.960462203802308e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.16 seconds!
[tester] 
AGNewsMetric: acc=0.5622368421052631, hinge=10.610745817485608, ce=14.535579689427426
Local test acc @ epoch 286: 0.5622
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.9802320611338473e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.43 seconds!
[tester] 
AGNewsMetric: acc=0.8455263157894737, hinge=3.557184431050953, ce=10.201388854980468
Local test acc @ epoch 286: 0.8455
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 9.934106870446158e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.54 seconds!
[tester] 
AGNewsMetric: acc=0.8413157894736842, hinge=3.6857752245350888, ce=10.288503546463815
Local test acc @ epoch 286: 0.8413
Global evaluate on test data...
Evaluate data in 124.13 seconds!
[tester] 
AGNewsMetric: acc=0.8476315789473684, hinge=3.58122315394251, ce=9.926308844716925
Global test acc @ epoch 286: 0.8476
Global epoch 287...
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.1 seconds!
[tester] 
AGNewsMetric: acc=0.7031578947368421, hinge=6.935843761343705, ce=12.893845762955515
Local test acc @ epoch 287: 0.7032
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.39 seconds!
[tester] 
AGNewsMetric: acc=0.8492105263157895, hinge=3.5086298173352293, ce=10.188261363380834
Local test acc @ epoch 287: 0.8492
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 3.973642037635727e-08
Local loss @ local epoch 1: 2.7815460157398775e-07
Local loss @ local epoch 2: 4.967052191773291e-08
Local loss @ local epoch 3: 9.934106870446158e-09
Local loss @ local epoch 4: 4.967052902316027e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.76 seconds!
[tester] 
AGNewsMetric: acc=0.8268421052631579, hinge=4.091283975902357, ce=9.596594230250309
Local test acc @ epoch 287: 0.8268
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 9.934106870446158e-09
Local loss @ local epoch 2: 0.0011422568932175636
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.6 seconds!
[tester] 
AGNewsMetric: acc=0.4963157894736842, hinge=13.20204433039615, ce=18.48389204727976
Local test acc @ epoch 287: 0.4963
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 4.172293301962782e-06
Local loss @ local epoch 4: 2.0265540570107987e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.83 seconds!
[tester] 
AGNewsMetric: acc=0.7576315789473684, hinge=4.576213745066994, ce=10.101837162218596
Local test acc @ epoch 287: 0.7576
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.713631121447179e-07
Local loss @ local epoch 2: 1.1175863079415649e-07
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.69 seconds!
[tester] 
AGNewsMetric: acc=0.7471052631578947, hinge=6.229688218769274, ce=12.25740323919999
Local test acc @ epoch 287: 0.7471
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 3.2511618286434896e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.0837207575775665e-08
Local loss @ local epoch 4: 1.0837207575775665e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.03 seconds!
[tester] 
AGNewsMetric: acc=0.804078947368421, hinge=4.749498051593179, ce=11.021963290164345
Local test acc @ epoch 287: 0.8041
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.167441515155133e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.58 seconds!
[tester] 
AGNewsMetric: acc=0.8411842105263158, hinge=3.721167357218893, ce=9.932395563627544
Local test acc @ epoch 287: 0.8412
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 1.7029897492193413e-08
Local loss @ local epoch 1: 4.087169713784533e-07
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.7029897492193413e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.3 seconds!
[tester] 
AGNewsMetric: acc=0.6438157894736842, hinge=9.369165489799098, ce=14.239978531285336
Local test acc @ epoch 287: 0.6438
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 1.295356273651123
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 6.357826265457334e-08
Local loss @ local epoch 3: 6.188121187733486e-05
Local loss @ local epoch 4: 3.3775190786400344e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.66 seconds!
[tester] 
AGNewsMetric: acc=0.6675, hinge=8.050683791010004, ce=15.181113991988333
Local test acc @ epoch 287: 0.6675
Global evaluate on test data...
Evaluate data in 123.94 seconds!
[tester] 
AGNewsMetric: acc=0.8473684210526315, hinge=3.5858209338941074, ce=10.066690842477898
Global test acc @ epoch 287: 0.8474
Global epoch 288...
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.24 seconds!
[tester] 
AGNewsMetric: acc=0.8492105263157895, hinge=3.555542188443636, ce=10.362995400679738
Local test acc @ epoch 288: 0.8492
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901159417490817e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.4156088923300558e-07
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.9 seconds!
[tester] 
AGNewsMetric: acc=0.814078947368421, hinge=4.53937048573243, ce=10.874724974381296
Local test acc @ epoch 288: 0.8141
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.6689136828063056e-06
Local loss @ local epoch 2: 2.9802317058624794e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.0828116501215845e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 125.04 seconds!
[tester] 
AGNewsMetric: acc=0.595657894736842, hinge=10.227444414841502, ce=16.083452019942435
Local test acc @ epoch 288: 0.5957
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 3.2511618286434896e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.87 seconds!
[tester] 
AGNewsMetric: acc=0.8473684210526315, hinge=3.6348343712405153, ce=10.233295773957906
Local test acc @ epoch 288: 0.8474
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.27 seconds!
[tester] 
AGNewsMetric: acc=0.7877631578947368, hinge=5.217913008740074, ce=11.133642989710758
Local test acc @ epoch 288: 0.7878
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 2.9910211196693126e-06
Local loss @ local epoch 1: 2.167441337519449e-08
Local loss @ local epoch 2: 1.3871539294996182e-06
Local loss @ local epoch 3: 3.3232976420549676e-05
Local loss @ local epoch 4: 4.334882675038898e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.71 seconds!
[tester] 
AGNewsMetric: acc=0.7977631578947368, hinge=4.908333438823098, ce=11.504725968210321
Local test acc @ epoch 288: 0.7978
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 2.384185648907078e-08
Local loss @ local epoch 1: 7.947285496356926e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.5894569216357013e-08
Local loss @ local epoch 4: 7.947285496356926e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.76 seconds!
[tester] 
AGNewsMetric: acc=0.8322368421052632, hinge=4.124099824052108, ce=10.571765618575247
Local test acc @ epoch 288: 0.8322
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 9.934106870446158e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 9.934106870446158e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.83 seconds!
[tester] 
AGNewsMetric: acc=0.8415789473684211, hinge=3.6835681393271997, ce=10.26200417167262
Local test acc @ epoch 288: 0.8416
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 3.4059794984386826e-08
Local loss @ local epoch 1: 1.7029897492193413e-08
Local loss @ local epoch 2: 8.514947325011235e-08
Local loss @ local epoch 3: 1.7029897492193413e-08
Local loss @ local epoch 4: 8.446088759228587e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.54 seconds!
[tester] 
AGNewsMetric: acc=0.7235526315789473, hinge=6.976686418432938, ce=12.455266832050524
Local test acc @ epoch 288: 0.7236
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.1 seconds!
[tester] 
AGNewsMetric: acc=0.8494736842105263, hinge=3.564406185024663, ce=10.319373377749795
Local test acc @ epoch 288: 0.8495
Global evaluate on test data...
Evaluate data in 124.22 seconds!
[tester] 
AGNewsMetric: acc=0.8506578947368421, hinge=3.557348705718392, ce=10.0834782750983
Global test acc @ epoch 288: 0.8507
Global epoch 289...
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.0837207575775665e-08
Local loss @ local epoch 2: 2.167441337519449e-08
Local loss @ local epoch 3: 2.7092980303677905e-07
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.88 seconds!
[tester] 
AGNewsMetric: acc=0.7363157894736843, hinge=6.566977733812834, ce=13.020933833875155
Local test acc @ epoch 289: 0.7363
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.4901156930591242e-07
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.37 seconds!
[tester] 
AGNewsMetric: acc=0.8444736842105263, hinge=3.673234967181557, ce=10.368372742502313
Local test acc @ epoch 289: 0.8445
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.152556236178498e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.5 seconds!
[tester] 
AGNewsMetric: acc=0.8485526315789473, hinge=3.5872290867253356, ce=10.470578304089997
Local test acc @ epoch 289: 0.8486
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 7.94728478581419e-08
Local loss @ local epoch 1: 1.5894569216357013e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.31 seconds!
[tester] 
AGNewsMetric: acc=0.7532894736842105, hinge=6.898645679574264, ce=12.7303741334614
Local test acc @ epoch 289: 0.7533
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 4.334883030310266e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.43 seconds!
[tester] 
AGNewsMetric: acc=0.8298684210526316, hinge=3.9530319750936407, ce=10.497628456918816
Local test acc @ epoch 289: 0.8299
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.1920926823449918e-07
Local loss @ local epoch 2: 3.973642748178463e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.34 seconds!
[tester] 
AGNewsMetric: acc=0.7842105263157895, hinge=5.220712875566984, ce=11.374579766926013
Local test acc @ epoch 289: 0.7842
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.6 seconds!
[tester] 
AGNewsMetric: acc=0.8473684210526315, hinge=3.623985220884022, ce=10.338262586091695
Local test acc @ epoch 289: 0.8474
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 1.9868211964535476e-08
Local loss @ local epoch 1: 1.9868211964535476e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 9.934106870446158e-09
Local loss @ local epoch 4: 9.934106870446158e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.36 seconds!
[tester] 
AGNewsMetric: acc=0.8067105263157894, hinge=4.478005418777466, ce=10.608133462604723
Local test acc @ epoch 289: 0.8067
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.7029897492193413e-08
Local loss @ local epoch 3: 3.405979143167315e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.44 seconds!
[tester] 
AGNewsMetric: acc=0.8301315789473684, hinge=3.844357327912983, ce=10.820110698499178
Local test acc @ epoch 289: 0.8301
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 2.4586890390310145e-07
Local loss @ local epoch 1: 5.960462345910855e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 4.470347647611561e-08
Local loss @ local epoch 4: 5.9604616353681195e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.25 seconds!
[tester] 
AGNewsMetric: acc=0.7536842105263157, hinge=5.901019313460902, ce=13.099678872760974
Local test acc @ epoch 289: 0.7537
Global evaluate on test data...
Evaluate data in 124.35 seconds!
[tester] 
AGNewsMetric: acc=0.8477631578947369, hinge=3.659601794293052, ce=10.258041383843674
Global test acc @ epoch 289: 0.8478
Global epoch 290...
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 3.725289587919178e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.27 seconds!
[tester] 
AGNewsMetric: acc=0.8486842105263158, hinge=3.7198538563126013, ce=10.151864158228824
Local test acc @ epoch 290: 0.8487
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.9802320611338473e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.6 seconds!
[tester] 
AGNewsMetric: acc=0.8501315789473685, hinge=3.4605373427742405, ce=10.201908828333805
Local test acc @ epoch 290: 0.8501
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 125.15 seconds!
[tester] 
AGNewsMetric: acc=0.8026315789473685, hinge=4.581051396821675, ce=11.675967359040913
Local test acc @ epoch 290: 0.8026
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.0837207575775665e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.68 seconds!
[tester] 
AGNewsMetric: acc=0.8376315789473684, hinge=3.8192267716558357, ce=10.526125705116673
Local test acc @ epoch 290: 0.8376
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 1.9868211964535476e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.98 seconds!
[tester] 
AGNewsMetric: acc=0.8425, hinge=3.7502770571959645, ce=10.13192455291748
Local test acc @ epoch 290: 0.8425
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 1.7029897492193413e-08
Local loss @ local epoch 1: 5.108968892386656e-08
Local loss @ local epoch 2: 6.81195828633463e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 3.405979143167315e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.09 seconds!
[tester] 
AGNewsMetric: acc=0.8365789473684211, hinge=3.779503580394544, ce=10.70416230452688
Local test acc @ epoch 290: 0.8366
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 3.973642748178463e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 3.973642748178463e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.32 seconds!
[tester] 
AGNewsMetric: acc=0.6460526315789473, hinge=9.467007577795732, ce=14.985306243896485
Local test acc @ epoch 290: 0.6461
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 2.384185648907078e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.64 seconds!
[tester] 
AGNewsMetric: acc=0.8139473684210526, hinge=4.694465197011044, ce=11.440986828051116
Local test acc @ epoch 290: 0.8139
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 1.9868211964535476e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 9.934106870446158e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.9802320611338473e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.88 seconds!
[tester] 
AGNewsMetric: acc=0.8501315789473685, hinge=3.5155013242520785, ce=10.278745054947702
Local test acc @ epoch 290: 0.8501
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.0837207575775665e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.75 seconds!
[tester] 
AGNewsMetric: acc=0.8476315789473684, hinge=3.5807065025128817, ce=10.310441448813991
Local test acc @ epoch 290: 0.8476
Global evaluate on test data...
Evaluate data in 123.91 seconds!
[tester] 
AGNewsMetric: acc=0.8493421052631579, hinge=3.549011894903685, ce=10.235461397672955
Global test acc @ epoch 290: 0.8493
Global epoch 291...
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.9802320611338473e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.04 seconds!
[tester] 
AGNewsMetric: acc=0.8514473684210526, hinge=3.320399001272101, ce=10.263548495644017
Local test acc @ epoch 291: 0.8514
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 3.973642748178463e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.2 seconds!
[tester] 
AGNewsMetric: acc=0.6298684210526316, hinge=8.765416394283896, ce=13.77827865600586
Local test acc @ epoch 291: 0.6299
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 4.967052191773291e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.02 seconds!
[tester] 
AGNewsMetric: acc=0.8452631578947368, hinge=3.5118928515283687, ce=10.231704776161596
Local test acc @ epoch 291: 0.8453
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 9.934106870446158e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 5.960462701182223e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.06 seconds!
[tester] 
AGNewsMetric: acc=0.8496052631578948, hinge=3.361620977928764, ce=10.276583737825092
Local test acc @ epoch 291: 0.8496
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.7029897492193413e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.32 seconds!
[tester] 
AGNewsMetric: acc=0.82, hinge=4.283377254385697, ce=10.909447085731907
Local test acc @ epoch 291: 0.82
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.028172505357361e-06
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.4901159417490817e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.8 seconds!
[tester] 
AGNewsMetric: acc=0.5827631578947369, hinge=10.862355209149813, ce=16.555300722624125
Local test acc @ epoch 291: 0.5828
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 1.0837207575775665e-08
Local loss @ local epoch 1: 1.0837207575775665e-08
Local loss @ local epoch 2: 3.2511618286434896e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.72 seconds!
[tester] 
AGNewsMetric: acc=0.8303947368421053, hinge=4.02273801013043, ce=10.803455398961118
Local test acc @ epoch 291: 0.8304
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 1.0837207575775665e-08
Local loss @ local epoch 1: 1.0837207575775665e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.95 seconds!
[tester] 
AGNewsMetric: acc=0.8442105263157895, hinge=3.7025074013910797, ce=10.141426698785079
Local test acc @ epoch 291: 0.8442
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.384185648907078e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.0 seconds!
[tester] 
AGNewsMetric: acc=0.8498684210526316, hinge=3.4918260378586616, ce=10.562825341475637
Local test acc @ epoch 291: 0.8499
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 1.748402098655788e-07
Local loss @ local epoch 1: 7.947285496356926e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.947285496356926e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.76 seconds!
[tester] 
AGNewsMetric: acc=0.6159210526315789, hinge=10.525494287390458, ce=16.000769460577715
Local test acc @ epoch 291: 0.6159
Global evaluate on test data...
Evaluate data in 123.58 seconds!
[tester] 
AGNewsMetric: acc=0.8392105263157895, hinge=3.8317087371725784, ce=10.466580802515933
Global test acc @ epoch 291: 0.8392
Global epoch 292...
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 9.934106870446158e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.15 seconds!
[tester] 
AGNewsMetric: acc=0.763421052631579, hinge=5.780834189967106, ce=12.308002600418893
Local test acc @ epoch 292: 0.7634
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.1920918296937089e-07
Local loss @ local epoch 2: 4.768370232000052e-08
Local loss @ local epoch 3: 7.947285496356926e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 125.36 seconds!
[tester] 
AGNewsMetric: acc=0.8321052631578948, hinge=3.9850857031972784, ce=10.511886600695158
Local test acc @ epoch 292: 0.8321
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 4.334882675038898e-08
Local loss @ local epoch 1: 2.600927189178037e-07
Local loss @ local epoch 2: 1.0837207575775665e-08
Local loss @ local epoch 3: 7.586042727325548e-08
Local loss @ local epoch 4: 1.6999709606170654
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.97 seconds!
[tester] 
AGNewsMetric: acc=0.6975, hinge=7.558931506307501, ce=13.689206053081312
Local test acc @ epoch 292: 0.6975
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 3.973642748178463e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.38 seconds!
[tester] 
AGNewsMetric: acc=0.5302631578947369, hinge=11.198379131116365, ce=16.296473187898336
Local test acc @ epoch 292: 0.5303
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 6.811957575791894e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.9 seconds!
[tester] 
AGNewsMetric: acc=0.7885526315789474, hinge=5.234780660428499, ce=11.259044576946058
Local test acc @ epoch 292: 0.7886
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 1.5646199358343438e-07
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.11 seconds!
[tester] 
AGNewsMetric: acc=0.8180263157894737, hinge=4.2344167282706815, ce=11.063877880698756
Local test acc @ epoch 292: 0.818
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 3.973642392907095e-08
Local loss @ local epoch 4: 4.967052191773291e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.39 seconds!
[tester] 
AGNewsMetric: acc=0.8343421052631579, hinge=4.112634024243606, ce=10.77102763125771
Local test acc @ epoch 292: 0.8343
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.57 seconds!
[tester] 
AGNewsMetric: acc=0.8461842105263158, hinge=3.6372308620653655, ce=10.679795979951557
Local test acc @ epoch 292: 0.8462
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 3.2511621839148575e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.0837207575775665e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.3 seconds!
[tester] 
AGNewsMetric: acc=0.8203947368421053, hinge=4.534071166389867, ce=10.977157847755834
Local test acc @ epoch 292: 0.8204
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.0639203537721187e-05
Local loss @ local epoch 2: 8.940696005765858e-08
Local loss @ local epoch 3: 9.834748198045418e-07
Local loss @ local epoch 4: 1.7612763258512132e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.44 seconds!
[tester] 
AGNewsMetric: acc=0.5726315789473684, hinge=8.629978051436575, ce=15.126953986318489
Local test acc @ epoch 292: 0.5726
Global evaluate on test data...
Evaluate data in 123.92 seconds!
[tester] 
AGNewsMetric: acc=0.8498684210526316, hinge=3.586167341784427, ce=10.202722147891397
Global test acc @ epoch 292: 0.8499
Global epoch 293...
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.7815488579108205e-07
Local loss @ local epoch 2: 5.165731522538408e-07
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.79 seconds!
[tester] 
AGNewsMetric: acc=0.7703947368421052, hinge=5.200630553396125, ce=11.62732885260331
Local test acc @ epoch 293: 0.7704
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.8978629112243652
Local loss @ local epoch 1: 1.4901160305669237e-08
Local loss @ local epoch 2: 3.278247504567844e-07
Local loss @ local epoch 3: 1.8328202031625551e-06
Local loss @ local epoch 4: 0.07853427529335022
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.07 seconds!
[tester] 
AGNewsMetric: acc=0.6653947368421053, hinge=6.687154294566104, ce=14.100569325497275
Local test acc @ epoch 293: 0.6654
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 1.7029897492193413e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.5326904190260393e-07
Local loss @ local epoch 3: 8.004029723451822e-07
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.45 seconds!
[tester] 
AGNewsMetric: acc=0.7328947368421053, hinge=5.953846971863195, ce=12.57824704019647
Local test acc @ epoch 293: 0.7329
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 4.768370942542788e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.384185648907078e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.5 seconds!
[tester] 
AGNewsMetric: acc=0.8417105263157895, hinge=3.8290306709942064, ce=10.047792539094624
Local test acc @ epoch 293: 0.8417
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.167441515155133e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.586042727325548e-08
Local loss @ local epoch 4: 1.0837207575775665e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.48 seconds!
[tester] 
AGNewsMetric: acc=0.8194736842105264, hinge=4.282177854839124, ce=10.787684300071314
Local test acc @ epoch 293: 0.8195
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.0837207575775665e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.0837207575775665e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.07 seconds!
[tester] 
AGNewsMetric: acc=0.8301315789473684, hinge=4.073246875311199, ce=10.832550255624872
Local test acc @ epoch 293: 0.8301
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 9.934106870446158e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.71 seconds!
[tester] 
AGNewsMetric: acc=0.8426315789473684, hinge=3.738033799246738, ce=10.558113680387798
Local test acc @ epoch 293: 0.8426
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.9802320611338473e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.9802320611338473e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.24 seconds!
[tester] 
AGNewsMetric: acc=0.8486842105263158, hinge=3.5123312163352964, ce=10.165850296020508
Local test acc @ epoch 293: 0.8487
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 7.947285496356926e-09
Local loss @ local epoch 1: 7.947285496356926e-09
Local loss @ local epoch 2: 2.384185648907078e-08
Local loss @ local epoch 3: 7.947285496356926e-09
Local loss @ local epoch 4: 3.178913488000035e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.42 seconds!
[tester] 
AGNewsMetric: acc=0.7982894736842105, hinge=5.159772891998291, ce=11.652355226215564
Local test acc @ epoch 293: 0.7983
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 1.9868211964535476e-08
Local loss @ local epoch 1: 2.9802317058624794e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.9802317058624794e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.08 seconds!
[tester] 
AGNewsMetric: acc=0.8385526315789473, hinge=3.7703504601277804, ce=9.78449164139597
Local test acc @ epoch 293: 0.8386
Global evaluate on test data...
Evaluate data in 124.22 seconds!
[tester] 
AGNewsMetric: acc=0.8498684210526316, hinge=3.4838438537246303, ce=10.102397318388286
Global test acc @ epoch 293: 0.8499
Global epoch 294...
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 3.4059794984386826e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.7029897492193413e-08
Local loss @ local epoch 4: 6.81195828633463e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.42 seconds!
[tester] 
AGNewsMetric: acc=0.7821052631578947, hinge=5.327485376910159, ce=11.795449652420848
Local test acc @ epoch 294: 0.7821
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.9802320611338473e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 9.934106870446158e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.92 seconds!
[tester] 
AGNewsMetric: acc=0.8465789473684211, hinge=3.5369758343696596, ce=10.062184532567075
Local test acc @ epoch 294: 0.8466
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.167441515155133e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.87 seconds!
[tester] 
AGNewsMetric: acc=0.824078947368421, hinge=4.208503605942977, ce=10.950171617206774
Local test acc @ epoch 294: 0.8241
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 3.973642748178463e-08
Local loss @ local epoch 1: 3.973642748178463e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.19 seconds!
[tester] 
AGNewsMetric: acc=0.6501315789473684, hinge=8.192224327890496, ce=13.932357515033923
Local test acc @ epoch 294: 0.6501
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.1920927533992653e-07
Local loss @ local epoch 2: 2.384185648907078e-08
Local loss @ local epoch 3: 1.1920927533992653e-07
Local loss @ local epoch 4: 1.4781899153604172e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.61 seconds!
[tester] 
AGNewsMetric: acc=0.6663157894736842, hinge=7.350762596130371, ce=14.577090636805485
Local test acc @ epoch 294: 0.6663
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 2.2351740014414645e-08
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.88 seconds!
[tester] 
AGNewsMetric: acc=0.8053947368421053, hinge=5.098664536225169, ce=11.431007481625205
Local test acc @ epoch 294: 0.8054
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 3.973642392907095e-08
Local loss @ local epoch 1: 9.934106870446158e-09
Local loss @ local epoch 2: 2.9802317058624794e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 9.934106870446158e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 125.06 seconds!
[tester] 
AGNewsMetric: acc=0.5896052631578947, hinge=10.670791939183285, ce=16.356622964959396
Local test acc @ epoch 294: 0.5896
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 3.178913488000035e-08
Local loss @ local epoch 1: 4.479968993109651e-05
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.56 seconds!
[tester] 
AGNewsMetric: acc=0.5564473684210526, hinge=12.757557489495529, ce=16.409542459186756
Local test acc @ epoch 294: 0.5564
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 3.034413964542182e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.46 seconds!
[tester] 
AGNewsMetric: acc=0.8405263157894737, hinge=3.708499669652236, ce=10.407510950188888
Local test acc @ epoch 294: 0.8405
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.9802320611338473e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.82 seconds!
[tester] 
AGNewsMetric: acc=0.8486842105263158, hinge=3.516238802106757, ce=10.24733667072497
Local test acc @ epoch 294: 0.8487
Global evaluate on test data...
Evaluate data in 124.85 seconds!
[tester] 
AGNewsMetric: acc=0.8523684210526316, hinge=3.4919253600271123, ce=10.147308498181795
Global test acc @ epoch 294: 0.8524
Global epoch 295...
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 3.973642748178463e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 3.059564551222138e-05
Local loss @ local epoch 4: 9.973706255550496e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.49 seconds!
[tester] 
AGNewsMetric: acc=0.6010526315789474, hinge=9.905257753071032, ce=14.830869216918945
Local test acc @ epoch 295: 0.6011
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.9802320611338473e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.04 seconds!
[tester] 
AGNewsMetric: acc=0.7867105263157895, hinge=5.095530287843001, ce=11.578610042772794
Local test acc @ epoch 295: 0.7867
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 4.0531122635911743e-07
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.33 seconds!
[tester] 
AGNewsMetric: acc=0.8410526315789474, hinge=3.657629291760294, ce=9.954042699713456
Local test acc @ epoch 295: 0.8411
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.07812727987766266
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 6.502322946744243e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.93 seconds!
[tester] 
AGNewsMetric: acc=0.6586842105263158, hinge=8.885728341152793, ce=14.986182373448422
Local test acc @ epoch 295: 0.6587
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.7029897492193413e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.7029897492193413e-08
Local loss @ local epoch 4: 1.7029897492193413e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.3 seconds!
[tester] 
AGNewsMetric: acc=0.8422368421052632, hinge=3.6059007274477106, ce=10.715246622185958
Local test acc @ epoch 295: 0.8422
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 4.3213228195781994e-07
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 3.427258548072132e-07
Local loss @ local epoch 3: 3.4718750612228177e-06
Local loss @ local epoch 4: 1.5646203621599852e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.08 seconds!
[tester] 
AGNewsMetric: acc=0.6826315789473684, hinge=8.587131311517012, ce=14.107666814703691
Local test acc @ epoch 295: 0.6826
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 7.947285496356926e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.384185648907078e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 6.198860091899405e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.98 seconds!
[tester] 
AGNewsMetric: acc=0.8184210526315789, hinge=4.600491680847971, ce=11.05752329575388
Local test acc @ epoch 295: 0.8184
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 5.960463411724959e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 3.973642392907095e-08
Local loss @ local epoch 3: 2.9802317058624794e-08
Local loss @ local epoch 4: 3.973642037635727e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.66 seconds!
[tester] 
AGNewsMetric: acc=0.8027631578947368, hinge=4.616170266552976, ce=10.724682651319002
Local test acc @ epoch 295: 0.8028
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 2.167441515155133e-08
Local loss @ local epoch 1: 1.0837207575775665e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.31 seconds!
[tester] 
AGNewsMetric: acc=0.7317105263157895, hinge=6.77634483688756, ce=13.14420933372096
Local test acc @ epoch 295: 0.7317
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 9.934106870446158e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.9868211964535476e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.64 seconds!
[tester] 
AGNewsMetric: acc=0.8463157894736842, hinge=3.618113343339217, ce=10.334493661177786
Local test acc @ epoch 295: 0.8463
Global evaluate on test data...
Evaluate data in 123.48 seconds!
[tester] 
AGNewsMetric: acc=0.8363157894736842, hinge=3.8776857810271412, ce=10.537753629182514
Global test acc @ epoch 295: 0.8363
Global epoch 296...
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.9868211964535476e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.79 seconds!
[tester] 
AGNewsMetric: acc=0.8402631578947368, hinge=3.746867271975467, ce=10.462522159375643
Local test acc @ epoch 296: 0.8403
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 9.934106870446158e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.97 seconds!
[tester] 
AGNewsMetric: acc=0.8373684210526315, hinge=3.762948900272972, ce=10.465500303569593
Local test acc @ epoch 296: 0.8374
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 4.768370942542788e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.28 seconds!
[tester] 
AGNewsMetric: acc=0.8509210526315789, hinge=3.4277593853599146, ce=10.181183630290784
Local test acc @ epoch 296: 0.8509
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 1.2715652530914667e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.311463150472264e-07
Local loss @ local epoch 4: 7.947285496356926e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.99 seconds!
[tester] 
AGNewsMetric: acc=0.779342105263158, hinge=5.644421541690827, ce=11.523282852172851
Local test acc @ epoch 296: 0.7793
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.1475311517715454
Local loss @ local epoch 2: 5.108969247658024e-08
Local loss @ local epoch 3: 0.0011717902962118387
Local loss @ local epoch 4: 0.0004948324640281498
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.64 seconds!
[tester] 
AGNewsMetric: acc=0.8168421052631579, hinge=2.350347438360515, ce=10.12002802196302
Local test acc @ epoch 296: 0.8168
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 3.973642748178463e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.48 seconds!
[tester] 
AGNewsMetric: acc=0.48236842105263156, hinge=12.12961804841694, ce=16.627881264937553
Local test acc @ epoch 296: 0.4824
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 2.2351738238057806e-08
Local loss @ local epoch 1: 1.4901159417490817e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.6 seconds!
[tester] 
AGNewsMetric: acc=0.8243421052631579, hinge=4.1590569541328835, ce=10.820692514118395
Local test acc @ epoch 296: 0.8243
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 2.167441337519449e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.0837207575775665e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.03 seconds!
[tester] 
AGNewsMetric: acc=0.8293421052631579, hinge=3.8322489548984326, ce=10.319927637200607
Local test acc @ epoch 296: 0.8293
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 2.9802320611338473e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.37 seconds!
[tester] 
AGNewsMetric: acc=0.8351315789473684, hinge=3.8396685851247687, ce=10.145486329731188
Local test acc @ epoch 296: 0.8351
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.167441337519449e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.0837207575775665e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.32 seconds!
[tester] 
AGNewsMetric: acc=0.8322368421052632, hinge=3.956640925532893, ce=10.48201886829577
Local test acc @ epoch 296: 0.8322
Global evaluate on test data...
Evaluate data in 123.99 seconds!
[tester] 
AGNewsMetric: acc=0.8521052631578947, hinge=3.460911387644316, ce=10.013322159616571
Global test acc @ epoch 296: 0.8521
Global epoch 297...
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.78 seconds!
[tester] 
AGNewsMetric: acc=0.8546052631578948, hinge=3.429570576391722, ce=10.256522108379164
Local test acc @ epoch 297: 0.8546
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.384185648907078e-08
Local loss @ local epoch 2: 4.768371297814156e-08
Local loss @ local epoch 3: 2.312654487468535e-06
Local loss @ local epoch 4: 7.152507805585628e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.74 seconds!
[tester] 
AGNewsMetric: acc=0.5919736842105263, hinge=8.346689249339857, ce=15.112870266563014
Local test acc @ epoch 297: 0.592
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 7.947285496356926e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.5894570992713852e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.92 seconds!
[tester] 
AGNewsMetric: acc=0.8403947368421053, hinge=3.8798540801750985, ce=10.50607987454063
Local test acc @ epoch 297: 0.8404
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 9.934106870446158e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 5.066379458185111e-07
Local loss @ local epoch 3: 9.934106870446158e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.88 seconds!
[tester] 
AGNewsMetric: acc=0.5864473684210526, hinge=11.42767109921104, ce=16.39656840073435
Local test acc @ epoch 297: 0.5864
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.94728478581419e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.15 seconds!
[tester] 
AGNewsMetric: acc=0.8089473684210526, hinge=4.482719705732245, ce=11.089773517407869
Local test acc @ epoch 297: 0.8089
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 1.1920923981278975e-07
Local loss @ local epoch 1: 1.7029897492193413e-08
Local loss @ local epoch 2: 1.7029897492193413e-08
Local loss @ local epoch 3: 6.811957575791894e-08
Local loss @ local epoch 4: 3.405979143167315e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.31 seconds!
[tester] 
AGNewsMetric: acc=0.7589473684210526, hinge=5.359378492957667, ce=11.594794562490362
Local test acc @ epoch 297: 0.7589
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 6.278119599301135e-06
Local loss @ local epoch 1: 9.934106870446158e-09
Local loss @ local epoch 2: 5.960463411724959e-08
Local loss @ local epoch 3: 2.384183943604512e-07
Local loss @ local epoch 4: 8.930632247938775e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.82 seconds!
[tester] 
AGNewsMetric: acc=0.6059210526315789, hinge=10.02805265727796, ce=15.20447150782535
Local test acc @ epoch 297: 0.6059
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 2.167441337519449e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.9506956050463486e-07
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.39 seconds!
[tester] 
AGNewsMetric: acc=0.7997368421052632, hinge=4.905630992588244, ce=11.195488214994732
Local test acc @ epoch 297: 0.7997
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.05321389064192772
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.39856401085853577
Local loss @ local epoch 4: 6.109460741754447e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.66 seconds!
[tester] 
AGNewsMetric: acc=0.6168421052631579, hinge=10.959407956976639, ce=15.854628576981394
Local test acc @ epoch 297: 0.6168
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.167441515155133e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.85 seconds!
[tester] 
AGNewsMetric: acc=0.8435526315789473, hinge=3.6730017894192746, ce=10.287583274841309
Local test acc @ epoch 297: 0.8436
Global evaluate on test data...
Evaluate data in 123.61 seconds!
[tester] 
AGNewsMetric: acc=0.8342105263157895, hinge=3.883804182880803, ce=10.477987668890702
Global test acc @ epoch 297: 0.8342
Global epoch 298...
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.4901148404078413e-07
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.55 seconds!
[tester] 
AGNewsMetric: acc=0.8426315789473684, hinge=3.4473222125203984, ce=10.233794631958007
Local test acc @ epoch 298: 0.8426
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0010723884915933013
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.82 seconds!
[tester] 
AGNewsMetric: acc=0.7972368421052631, hinge=4.788041646606044, ce=10.710362442418148
Local test acc @ epoch 298: 0.7972
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 4.529937598363176e-07
Local loss @ local epoch 1: 3.1789138432714026e-08
Local loss @ local epoch 2: 2.384185648907078e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 3.978839231422171e-05
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.87 seconds!
[tester] 
AGNewsMetric: acc=0.6753947368421053, hinge=8.767292336915668, ce=15.229881790562679
Local test acc @ epoch 298: 0.6754
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 3.973642037635727e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.26 seconds!
[tester] 
AGNewsMetric: acc=0.8409210526315789, hinge=3.6790784357723436, ce=10.292995503074245
Local test acc @ epoch 298: 0.8409
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.14 seconds!
[tester] 
AGNewsMetric: acc=0.8346052631578947, hinge=3.863464267253876, ce=10.47571919290643
Local test acc @ epoch 298: 0.8346
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 2.2351740014414645e-08
Local loss @ local epoch 1: 1.4901159417490817e-08
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.52 seconds!
[tester] 
AGNewsMetric: acc=0.8148684210526316, hinge=4.650578415268346, ce=11.19999546653346
Local test acc @ epoch 298: 0.8149
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.152556236178498e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.8 seconds!
[tester] 
AGNewsMetric: acc=0.8460526315789474, hinge=3.605345522479007, ce=10.20709350786711
Local test acc @ epoch 298: 0.8461
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 5.108968892386656e-08
Local loss @ local epoch 1: 1.7029897492193413e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 6.811957575791894e-08
Local loss @ local epoch 4: 3.4059794984386826e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.47 seconds!
[tester] 
AGNewsMetric: acc=0.7847368421052632, hinge=5.270667088157253, ce=11.294639984933953
Local test acc @ epoch 298: 0.7847
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.25 seconds!
[tester] 
AGNewsMetric: acc=0.8410526315789474, hinge=3.6775212078345447, ce=10.043792021901984
Local test acc @ epoch 298: 0.8411
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.0837207575775665e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.01 seconds!
[tester] 
AGNewsMetric: acc=0.8332894736842106, hinge=3.84982699645193, ce=10.56052532999139
Local test acc @ epoch 298: 0.8333
Global evaluate on test data...
Evaluate data in 123.88 seconds!
[tester] 
AGNewsMetric: acc=0.843421052631579, hinge=3.7481944886006806, ce=10.281705804122122
Global test acc @ epoch 298: 0.8434
Global epoch 299...
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 6.317952738754684e-06
Local loss @ local epoch 2: 1.0217937784773312e-07
Local loss @ local epoch 3: 1.6620291717117652e-05
Local loss @ local epoch 4: 1.5326902769174922e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.84 seconds!
[tester] 
AGNewsMetric: acc=0.8275, hinge=3.845729561103018, ce=10.192251337954872
Local test acc @ epoch 299: 0.8275
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.1 seconds!
[tester] 
AGNewsMetric: acc=0.8425, hinge=3.7360431539384944, ce=10.477443859702662
Local test acc @ epoch 299: 0.8425
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.947281943643247e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 3.973642392907095e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.7 seconds!
[tester] 
AGNewsMetric: acc=0.8411842105263158, hinge=3.5738687698464644, ce=10.264173632170024
Local test acc @ epoch 299: 0.8412
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.45 seconds!
[tester] 
AGNewsMetric: acc=0.8378947368421052, hinge=3.783159834962142, ce=10.528879510979904
Local test acc @ epoch 299: 0.8379
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.2758108286780043e-07
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.0837207575775665e-08
Local loss @ local epoch 4: 1.1920920428565296e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.24 seconds!
[tester] 
AGNewsMetric: acc=0.6590789473684211, hinge=8.231359868300588, ce=14.241456860994038
Local test acc @ epoch 299: 0.6591
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 2.384185648907078e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.94 seconds!
[tester] 
AGNewsMetric: acc=0.8457894736842105, hinge=3.5162958778833087, ce=10.244381366528962
Local test acc @ epoch 299: 0.8458
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 3.973642748178463e-08
Local loss @ local epoch 1: 5.165731522538408e-07
Local loss @ local epoch 2: 7.94728478581419e-08
Local loss @ local epoch 3: 4.3710056729651114e-07
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.59 seconds!
[tester] 
AGNewsMetric: acc=0.6780263157894737, hinge=8.517979894939222, ce=13.513613168816818
Local test acc @ epoch 299: 0.678
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.167441337519449e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.92 seconds!
[tester] 
AGNewsMetric: acc=0.8281578947368421, hinge=4.069263506939537, ce=10.631084329705489
Local test acc @ epoch 299: 0.8282
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 7.947281233100512e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 6.35782697600007e-08
Local loss @ local epoch 3: 7.947285496356926e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.73 seconds!
[tester] 
AGNewsMetric: acc=0.7880263157894737, hinge=5.196357186217057, ce=12.147785951714766
Local test acc @ epoch 299: 0.788
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.07 seconds!
[tester] 
AGNewsMetric: acc=0.8435526315789473, hinge=3.7554085538261814, ce=10.38037413747687
Local test acc @ epoch 299: 0.8436
Global evaluate on test data...
Evaluate data in 124.39 seconds!
[tester] 
AGNewsMetric: acc=0.8530263157894736, hinge=3.451483937062715, ce=10.125686125504343
Global test acc @ epoch 299: 0.853
Global epoch 300...
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 4.768370942542788e-08
Local loss @ local epoch 3: 0.00014278687012847513
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.96 seconds!
[tester] 
AGNewsMetric: acc=0.7889473684210526, hinge=5.253564898716776, ce=11.621469658299496
Local test acc @ epoch 300: 0.7889
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.94728478581419e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.97 seconds!
[tester] 
AGNewsMetric: acc=0.7222368421052632, hinge=6.747179921802721, ce=13.69351310529207
Local test acc @ epoch 300: 0.7222
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 5.9604616353681195e-08
Local loss @ local epoch 3: 2.2351740014414645e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.94 seconds!
[tester] 
AGNewsMetric: acc=0.8375, hinge=3.9715556265178478, ce=10.591937486748947
Local test acc @ epoch 300: 0.8375
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 1.0837207575775665e-08
Local loss @ local epoch 1: 1.0837207575775665e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 6.502322946744243e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.04 seconds!
[tester] 
AGNewsMetric: acc=0.8347368421052631, hinge=3.8489366004341528, ce=10.552656521044279
Local test acc @ epoch 300: 0.8347
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 4.3348728695491445e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 6.502322946744243e-08
Local loss @ local epoch 3: 1.1920923981278975e-07
Local loss @ local epoch 4: 7.737463420198765e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.7 seconds!
[tester] 
AGNewsMetric: acc=0.7430263157894736, hinge=7.173006308706183, ce=12.477144558555201
Local test acc @ epoch 300: 0.743
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.0 seconds!
[tester] 
AGNewsMetric: acc=0.8535526315789473, hinge=3.4859838646336607, ce=10.21070459265458
Local test acc @ epoch 300: 0.8536
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 9.934106870446158e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.84 seconds!
[tester] 
AGNewsMetric: acc=0.8514473684210526, hinge=3.4615181680729514, ce=10.300865147239284
Local test acc @ epoch 300: 0.8514
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 9.934106870446158e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.37 seconds!
[tester] 
AGNewsMetric: acc=0.8496052631578948, hinge=3.484635964694776, ce=10.184781957927504
Local test acc @ epoch 300: 0.8496
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.9 seconds!
[tester] 
AGNewsMetric: acc=0.8544736842105263, hinge=3.386784575738405, ce=9.933576704326429
Local test acc @ epoch 300: 0.8545
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 1.7029897492193413e-08
Local loss @ local epoch 1: 6.301048642853857e-07
Local loss @ local epoch 2: 3.4059794984386826e-08
Local loss @ local epoch 3: 3.4059794984386826e-08
Local loss @ local epoch 4: 2.24793302550097e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.95 seconds!
[tester] 
AGNewsMetric: acc=0.7680263157894737, hinge=5.114089050543936, ce=11.50847041280646
Local test acc @ epoch 300: 0.768
Global evaluate on test data...
Evaluate data in 124.43 seconds!
[tester] 
AGNewsMetric: acc=0.8530263157894736, hinge=3.480340273505763, ce=10.122245720311215
Global test acc @ epoch 300: 0.853
Global epoch 301...
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.959473138413159e-06
Local loss @ local epoch 1: 3.725289943190546e-08
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 4.470347647611561e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.62 seconds!
[tester] 
AGNewsMetric: acc=0.6792105263157895, hinge=9.10137053991619, ce=14.632406250803093
Local test acc @ epoch 301: 0.6792
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 3.973642392907095e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.22 seconds!
[tester] 
AGNewsMetric: acc=0.8228947368421052, hinge=4.281995200608906, ce=10.986508357399389
Local test acc @ epoch 301: 0.8229
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 5.563098781635745e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.5894569216357013e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.71 seconds!
[tester] 
AGNewsMetric: acc=0.8152631578947368, hinge=5.06525673615305, ce=11.418992604707416
Local test acc @ epoch 301: 0.8153
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 6.811957575791894e-08
Local loss @ local epoch 2: 2.0435865621948324e-07
Local loss @ local epoch 3: 3.4059794984386826e-08
Local loss @ local epoch 4: 1.7029897492193413e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.04 seconds!
[tester] 
AGNewsMetric: acc=0.8392105263157895, hinge=3.6778061934521324, ce=10.858106452540348
Local test acc @ epoch 301: 0.8392
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 9.934106870446158e-09
Local loss @ local epoch 1: 4.967052191773291e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.79 seconds!
[tester] 
AGNewsMetric: acc=0.8206578947368421, hinge=4.429234310953241, ce=10.846653396204898
Local test acc @ epoch 301: 0.8207
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.947285496356926e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.05 seconds!
[tester] 
AGNewsMetric: acc=0.8472368421052632, hinge=3.555313522564737, ce=10.404974855121813
Local test acc @ epoch 301: 0.8472
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 1.4305112472356996e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.5 seconds!
[tester] 
AGNewsMetric: acc=0.7311842105263158, hinge=6.628030450720536, ce=12.835038526434648
Local test acc @ epoch 301: 0.7312
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 2.167441337519449e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.167441337519449e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.59 seconds!
[tester] 
AGNewsMetric: acc=0.8348684210526316, hinge=3.9051402480978714, ce=10.3236130885074
Local test acc @ epoch 301: 0.8349
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.0837207575775665e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.09 seconds!
[tester] 
AGNewsMetric: acc=0.853421052631579, hinge=3.457337519244144, ce=10.279187200445877
Local test acc @ epoch 301: 0.8534
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.73 seconds!
[tester] 
AGNewsMetric: acc=0.8382894736842105, hinge=3.6284005852749472, ce=10.127013722469933
Local test acc @ epoch 301: 0.8383
Global evaluate on test data...
Evaluate data in 125.25 seconds!
[tester] 
AGNewsMetric: acc=0.8498684210526316, hinge=3.6639624372281525, ce=10.282792258011668
Global test acc @ epoch 301: 0.8499
Global epoch 302...
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 3.4059794984386826e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 125.06 seconds!
[tester] 
AGNewsMetric: acc=0.8413157894736842, hinge=3.6096466956640545, ce=10.875596640737433
Local test acc @ epoch 302: 0.8413
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.9802320611338473e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.13 seconds!
[tester] 
AGNewsMetric: acc=0.85, hinge=3.695418207017999, ce=10.464710753591437
Local test acc @ epoch 302: 0.85
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.9868211964535476e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.02 seconds!
[tester] 
AGNewsMetric: acc=0.8459210526315789, hinge=3.7575575386850457, ce=10.512827923423366
Local test acc @ epoch 302: 0.8459
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 7.152556236178498e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.4 seconds!
[tester] 
AGNewsMetric: acc=0.8305263157894737, hinge=4.0826335101378595, ce=10.67040448238975
Local test acc @ epoch 302: 0.8305
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 9.934106870446158e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 9.934106870446158e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.03 seconds!
[tester] 
AGNewsMetric: acc=0.8471052631578947, hinge=3.637516305823075, ce=10.091928395723041
Local test acc @ epoch 302: 0.8471
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.0837207575775665e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.7 seconds!
[tester] 
AGNewsMetric: acc=0.8476315789473684, hinge=3.5794904617259378, ce=10.440962227269223
Local test acc @ epoch 302: 0.8476
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.0837207575775665e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.23 seconds!
[tester] 
AGNewsMetric: acc=0.8496052631578948, hinge=3.6675644825634204, ce=10.34570315511603
Local test acc @ epoch 302: 0.8496
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 7.947285496356926e-09
Local loss @ local epoch 1: 2.2252382336773735e-07
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.21 seconds!
[tester] 
AGNewsMetric: acc=0.7718421052631579, hinge=5.491542253494263, ce=12.235429436533074
Local test acc @ epoch 302: 0.7718
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 2.2351738238057806e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.11 seconds!
[tester] 
AGNewsMetric: acc=0.8301315789473684, hinge=4.0625452459485905, ce=10.634055938720703
Local test acc @ epoch 302: 0.8301
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 2.7815488579108205e-07
Local loss @ local epoch 2: 1.1920926823449918e-07
Local loss @ local epoch 3: 7.947276685627003e-07
Local loss @ local epoch 4: 7.94728478581419e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.2 seconds!
[tester] 
AGNewsMetric: acc=0.7052631578947368, hinge=6.611472896274767, ce=11.70235894454153
Local test acc @ epoch 302: 0.7053
Global evaluate on test data...
Evaluate data in 124.22 seconds!
[tester] 
AGNewsMetric: acc=0.8502631578947368, hinge=3.6395462549360174, ce=10.253937307658948
Global test acc @ epoch 302: 0.8503
Global epoch 303...
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 1.0837207575775665e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 3.2511621839148575e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.97 seconds!
[tester] 
AGNewsMetric: acc=0.8031578947368421, hinge=4.810071014103136, ce=11.27471201444927
Local test acc @ epoch 303: 0.8032
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 9.934106870446158e-09
Local loss @ local epoch 2: 9.934106870446158e-09
Local loss @ local epoch 3: 2.9802317058624794e-08
Local loss @ local epoch 4: 9.934106870446158e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.99 seconds!
[tester] 
AGNewsMetric: acc=0.8311842105263157, hinge=4.130353011583027, ce=10.763260821292274
Local test acc @ epoch 303: 0.8312
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 3.973642748178463e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.7815488579108205e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.29 seconds!
[tester] 
AGNewsMetric: acc=0.7088157894736842, hinge=7.937070505242598, ce=13.138376047234786
Local test acc @ epoch 303: 0.7088
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 2.861016810129513e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.384185471271394e-08
Local loss @ local epoch 3: 3.973642748178463e-08
Local loss @ local epoch 4: 1.0649279147401103e-06
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.98 seconds!
[tester] 
AGNewsMetric: acc=0.7330263157894736, hinge=7.635682272660105, ce=12.953857484114797
Local test acc @ epoch 303: 0.733
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 2.167441337519449e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 3.2511621839148575e-08
Local loss @ local epoch 4: 1.0837207575775665e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.99 seconds!
[tester] 
AGNewsMetric: acc=0.8393421052631579, hinge=3.8743105410274707, ce=10.240802391453792
Local test acc @ epoch 303: 0.8393
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.4901160305669237e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.58 seconds!
[tester] 
AGNewsMetric: acc=0.8488157894736842, hinge=3.6200809584165876, ce=10.397816296627648
Local test acc @ epoch 303: 0.8488
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.02 seconds!
[tester] 
AGNewsMetric: acc=0.8519736842105263, hinge=3.6003996520293384, ce=10.504633971766422
Local test acc @ epoch 303: 0.852
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.8732875162186247e-07
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.873287800435719e-07
Local loss @ local epoch 4: 1.021793636368784e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.36 seconds!
[tester] 
AGNewsMetric: acc=0.8459210526315789, hinge=3.60717972968754, ce=10.604392923053942
Local test acc @ epoch 303: 0.8459
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 9.934106870446158e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 9.934106870446158e-09
Local loss @ local epoch 4: 2.9802320611338473e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.46 seconds!
[tester] 
AGNewsMetric: acc=0.8476315789473684, hinge=3.6156407150469327, ce=10.243553155597887
Local test acc @ epoch 303: 0.8476
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.52 seconds!
[tester] 
AGNewsMetric: acc=0.8511842105263158, hinge=3.6455345926786724, ce=10.54878078661467
Local test acc @ epoch 303: 0.8512
Global evaluate on test data...
Evaluate data in 124.73 seconds!
[tester] 
AGNewsMetric: acc=0.8465789473684211, hinge=3.7923200954888996, ce=10.360698573463841
Global test acc @ epoch 303: 0.8466
Global epoch 304...
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.71 seconds!
[tester] 
AGNewsMetric: acc=0.8182894736842106, hinge=4.482120691098665, ce=11.092883868970368
Local test acc @ epoch 304: 0.8183
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.35 seconds!
[tester] 
AGNewsMetric: acc=0.8442105263157895, hinge=3.740778042642694, ce=10.395250709935238
Local test acc @ epoch 304: 0.8442
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901160305669237e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.2351738238057806e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.2 seconds!
[tester] 
AGNewsMetric: acc=0.8317105263157895, hinge=4.224717390913712, ce=10.799771734538831
Local test acc @ epoch 304: 0.8317
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.09 seconds!
[tester] 
AGNewsMetric: acc=0.8497368421052631, hinge=3.667153353189167, ce=10.54604387383712
Local test acc @ epoch 304: 0.8497
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.008846712298691273
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.517207834922374e-07
Local loss @ local epoch 4: 0.4540397524833679
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.19 seconds!
[tester] 
AGNewsMetric: acc=0.6867105263157894, hinge=7.651115568060624, ce=14.14362830513402
Local test acc @ epoch 304: 0.6867
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 5.563098781635745e-08
Local loss @ local epoch 3: 7.947285496356926e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.92 seconds!
[tester] 
AGNewsMetric: acc=0.8363157894736842, hinge=3.988097412586212, ce=10.787544425161261
Local test acc @ epoch 304: 0.8363
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.7029897492193413e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.0 seconds!
[tester] 
AGNewsMetric: acc=0.7203947368421053, hinge=6.40475658015201, ce=12.74052961449874
Local test acc @ epoch 304: 0.7204
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0030991346575319767
Local loss @ local epoch 1: 1.0837207575775665e-08
Local loss @ local epoch 2: 1.213759787788149e-06
Local loss @ local epoch 3: 2.167441515155133e-08
Local loss @ local epoch 4: 4.0097603459798847e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.67 seconds!
[tester] 
AGNewsMetric: acc=0.6039473684210527, hinge=10.018620599445544, ce=16.118531739084343
Local test acc @ epoch 304: 0.6039
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.65 seconds!
[tester] 
AGNewsMetric: acc=0.8469736842105263, hinge=3.7495569630673056, ce=10.542318199559261
Local test acc @ epoch 304: 0.847
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.17 seconds!
[tester] 
AGNewsMetric: acc=0.8028947368421052, hinge=5.14830429604179, ce=11.41752244848954
Local test acc @ epoch 304: 0.8029
Global evaluate on test data...
Evaluate data in 124.48 seconds!
[tester] 
AGNewsMetric: acc=0.8476315789473684, hinge=3.663534789587322, ce=10.347254602532638
Global test acc @ epoch 304: 0.8476
Global epoch 305...
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.4901159417490817e-08
Local loss @ local epoch 2: 3.725289587919178e-08
Local loss @ local epoch 3: 2.2351740014414645e-08
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.05 seconds!
[tester] 
AGNewsMetric: acc=0.8306578947368422, hinge=4.0810708786311904, ce=10.632288894653321
Local test acc @ epoch 305: 0.8307
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.01 seconds!
[tester] 
AGNewsMetric: acc=0.8453947368421053, hinge=3.7083901138054696, ce=10.277317683571264
Local test acc @ epoch 305: 0.8454
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 3.973642748178463e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.81 seconds!
[tester] 
AGNewsMetric: acc=0.6664473684210527, hinge=8.41100072358784, ce=13.699475286383377
Local test acc @ epoch 305: 0.6664
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 5.108969247658024e-08
Local loss @ local epoch 1: 1.7029897492193413e-08
Local loss @ local epoch 2: 1.7029897492193413e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.7029897492193413e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.82 seconds!
[tester] 
AGNewsMetric: acc=0.7803947368421053, hinge=5.350939910788285, ce=11.775783069008275
Local test acc @ epoch 305: 0.7804
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 9.934106870446158e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 9.934106870446158e-09
Local loss @ local epoch 4: 2.3841823804104934e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.65 seconds!
[tester] 
AGNewsMetric: acc=0.8388157894736842, hinge=3.8174593733486377, ce=10.49102977150365
Local test acc @ epoch 305: 0.8388
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 3.1789138432714026e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 5.32466060576553e-07
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.97 seconds!
[tester] 
AGNewsMetric: acc=0.795921052631579, hinge=5.151468443870544, ce=11.773880880255447
Local test acc @ epoch 305: 0.7959
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.44 seconds!
[tester] 
AGNewsMetric: acc=0.8465789473684211, hinge=3.661438303997642, ce=10.330700514943976
Local test acc @ epoch 305: 0.8466
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 3.2511621839148575e-08
Local loss @ local epoch 2: 5.418602455620203e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.86 seconds!
[tester] 
AGNewsMetric: acc=0.8409210526315789, hinge=3.6891373308081374, ce=10.508904916863692
Local test acc @ epoch 305: 0.8409
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 5.4186035214343065e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.0837207575775665e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.89 seconds!
[tester] 
AGNewsMetric: acc=0.8330263157894737, hinge=3.848841188204916, ce=10.644889554475483
Local test acc @ epoch 305: 0.833
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.9868211964535476e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.31 seconds!
[tester] 
AGNewsMetric: acc=0.8453947368421053, hinge=3.645831939421202, ce=10.504737177397075
Local test acc @ epoch 305: 0.8454
Global evaluate on test data...
Evaluate data in 124.55 seconds!
[tester] 
AGNewsMetric: acc=0.848421052631579, hinge=3.594963893639414, ce=10.221172234384637
Global test acc @ epoch 305: 0.8484
Global epoch 306...
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.7029897492193413e-08
Local loss @ local epoch 2: 1.7029897492193413e-08
Local loss @ local epoch 3: 1.7029897492193413e-08
Local loss @ local epoch 4: 1.7029897492193413e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.25 seconds!
[tester] 
AGNewsMetric: acc=0.8448684210526316, hinge=3.5371017986849735, ce=10.560714386387875
Local test acc @ epoch 306: 0.8449
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 1.1920928244535389e-07
Local loss @ local epoch 1: 7.94728478581419e-08
Local loss @ local epoch 2: 1.5497172398681869e-06
Local loss @ local epoch 3: 3.973642748178463e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.25 seconds!
[tester] 
AGNewsMetric: acc=0.6456578947368421, hinge=9.467409348738821, ce=14.233660011291503
Local test acc @ epoch 306: 0.6457
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.2351738238057806e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.55 seconds!
[tester] 
AGNewsMetric: acc=0.844078947368421, hinge=3.763919822793258, ce=10.480538522820723
Local test acc @ epoch 306: 0.8441
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.26234713196754456
Local loss @ local epoch 3: 1.30046402091466e-07
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.78 seconds!
[tester] 
AGNewsMetric: acc=0.5701315789473684, hinge=11.348649550990055, ce=16.993870604665656
Local test acc @ epoch 306: 0.5701
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.94 seconds!
[tester] 
AGNewsMetric: acc=0.841842105263158, hinge=3.7206404478926407, ce=10.414295236687911
Local test acc @ epoch 306: 0.8418
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 3.973642392907095e-08
Local loss @ local epoch 4: 3.973642392907095e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.55 seconds!
[tester] 
AGNewsMetric: acc=0.8489473684210527, hinge=3.538598136525405, ce=10.187211127030222
Local test acc @ epoch 306: 0.8489
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.384185648907078e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.45 seconds!
[tester] 
AGNewsMetric: acc=0.8477631578947369, hinge=3.5169566498304667, ce=10.683860664367677
Local test acc @ epoch 306: 0.8478
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 8.669762507906853e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 6.502323657286979e-08
Local loss @ local epoch 4: 2.167441337519449e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.83 seconds!
[tester] 
AGNewsMetric: acc=0.5272368421052631, hinge=13.699934235623008, ce=18.2692472076416
Local test acc @ epoch 306: 0.5272
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 3.1789138432714026e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.947285496356926e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.74 seconds!
[tester] 
AGNewsMetric: acc=0.8386842105263158, hinge=3.927453005439357, ce=10.64805823075144
Local test acc @ epoch 306: 0.8387
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 2.1656071567122126e-06
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 6.556485345754481e-07
Local loss @ local epoch 4: 3.973642037635727e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.93 seconds!
[tester] 
AGNewsMetric: acc=0.5402631578947369, hinge=15.033102135909232, ce=18.077358085230777
Local test acc @ epoch 306: 0.5403
Global evaluate on test data...
Evaluate data in 123.96 seconds!
[tester] 
AGNewsMetric: acc=0.8213157894736842, hinge=4.256522210522702, ce=10.912305050900107
Global test acc @ epoch 306: 0.8213
Global epoch 307...
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 8.344639468305104e-07
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.72 seconds!
[tester] 
AGNewsMetric: acc=0.781578947368421, hinge=5.379831382851852, ce=11.646396990324321
Local test acc @ epoch 307: 0.7816
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 1.4901159417490817e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.450580152834618e-09
Local loss @ local epoch 4: 1.4901159417490817e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.8 seconds!
[tester] 
AGNewsMetric: acc=0.8215789473684211, hinge=4.429860825287668, ce=11.0089662672344
Local test acc @ epoch 307: 0.8216
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 2.167441337519449e-08
Local loss @ local epoch 1: 1.0837207575775665e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.93 seconds!
[tester] 
AGNewsMetric: acc=0.8261842105263157, hinge=3.993307001214278, ce=11.030202243202611
Local test acc @ epoch 307: 0.8262
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 4.334882675038898e-08
Local loss @ local epoch 1: 1.0837207575775665e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.23 seconds!
[tester] 
AGNewsMetric: acc=0.8192105263157895, hinge=4.0335794300782055, ce=10.776632670352333
Local test acc @ epoch 307: 0.8192
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.9868211964535476e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.56 seconds!
[tester] 
AGNewsMetric: acc=0.8201315789473684, hinge=4.273851118840669, ce=11.03084525058144
Local test acc @ epoch 307: 0.8201
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.9802268386447395e-07
Local loss @ local epoch 4: 9.934106870446158e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.62 seconds!
[tester] 
AGNewsMetric: acc=0.8043421052631579, hinge=4.60578618099815, ce=11.232850325734992
Local test acc @ epoch 307: 0.8043
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 3.405979143167315e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.71 seconds!
[tester] 
AGNewsMetric: acc=0.6322368421052632, hinge=8.588600902557372, ce=14.547232674046567
Local test acc @ epoch 307: 0.6322
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 3.27825318890973e-07
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.79 seconds!
[tester] 
AGNewsMetric: acc=0.7557894736842106, hinge=5.671437899187992, ce=12.1768033740395
Local test acc @ epoch 307: 0.7558
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 1.112619756327149e-07
Local loss @ local epoch 1: 7.947285496356926e-09
Local loss @ local epoch 2: 1.5894569216357013e-08
Local loss @ local epoch 3: 7.947285496356926e-09
Local loss @ local epoch 4: 1.5894570992713852e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.33 seconds!
[tester] 
AGNewsMetric: acc=0.6222368421052632, hinge=9.577300017005518, ce=15.489786911010743
Local test acc @ epoch 307: 0.6222
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.384185648907078e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.54 seconds!
[tester] 
AGNewsMetric: acc=0.8328947368421052, hinge=3.9588965676960193, ce=10.514344944201017
Local test acc @ epoch 307: 0.8329
Global evaluate on test data...
Evaluate data in 123.58 seconds!
[tester] 
AGNewsMetric: acc=0.8485526315789473, hinge=3.6229546594619753, ce=10.291032469900031
Global test acc @ epoch 307: 0.8486
Global epoch 308...
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 4.768370942542788e-08
Local loss @ local epoch 2: 4.768370942542788e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.52 seconds!
[tester] 
AGNewsMetric: acc=0.8459210526315789, hinge=3.718554811979595, ce=10.36331261283473
Local test acc @ epoch 308: 0.8459
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 6.983386356296251e-06
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0016218734672293067
Local loss @ local epoch 3: 2.9802317058624794e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.69 seconds!
[tester] 
AGNewsMetric: acc=0.814078947368421, hinge=4.18722869295823, ce=10.998412198518452
Local test acc @ epoch 308: 0.8141
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 1.0837207575775665e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.19 seconds!
[tester] 
AGNewsMetric: acc=0.8494736842105263, hinge=3.6027525348412364, ce=10.146648186131527
Local test acc @ epoch 308: 0.8495
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 9.934106870446158e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0011863793479278684
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.03 seconds!
[tester] 
AGNewsMetric: acc=0.6688157894736843, hinge=8.9557371430648, ce=15.079160622044613
Local test acc @ epoch 308: 0.6688
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 6.502323657286979e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.81 seconds!
[tester] 
AGNewsMetric: acc=0.704078947368421, hinge=7.818999992169832, ce=13.211840671740081
Local test acc @ epoch 308: 0.7041
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 7.947285496356926e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.5894570992713852e-08
Local loss @ local epoch 4: 4.768370232000052e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.31 seconds!
[tester] 
AGNewsMetric: acc=0.8482894736842105, hinge=3.7342773291939184, ce=10.31012461210552
Local test acc @ epoch 308: 0.8483
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 2.3096757217899722e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.8 seconds!
[tester] 
AGNewsMetric: acc=0.6077631578947369, hinge=12.112342255240993, ce=16.674448760183235
Local test acc @ epoch 308: 0.6078
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 1.7029897492193413e-08
Local loss @ local epoch 1: 5.108969247658024e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.3623915151583788e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.65 seconds!
[tester] 
AGNewsMetric: acc=0.689078947368421, hinge=8.276072062442177, ce=14.028255890294124
Local test acc @ epoch 308: 0.6891
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.3841850804728892e-07
Local loss @ local epoch 3: 7.94728478581419e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.85 seconds!
[tester] 
AGNewsMetric: acc=0.6313157894736842, hinge=8.574842036397834, ce=14.66187948929636
Local test acc @ epoch 308: 0.6313
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.39 seconds!
[tester] 
AGNewsMetric: acc=0.8460526315789474, hinge=3.7521632884678087, ce=10.055661305879292
Local test acc @ epoch 308: 0.8461
Global evaluate on test data...
Evaluate data in 123.55 seconds!
[tester] 
AGNewsMetric: acc=0.8451315789473685, hinge=3.687880859124033, ce=10.275347101311935
Global test acc @ epoch 308: 0.8451
Global epoch 309...
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.7 seconds!
[tester] 
AGNewsMetric: acc=0.8427631578947369, hinge=3.8612997023682847, ce=10.537433262875206
Local test acc @ epoch 309: 0.8428
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 3.054732928831072e-07
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.450580152834618e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.38 seconds!
[tester] 
AGNewsMetric: acc=0.8243421052631579, hinge=4.08451028623079, ce=10.860650293450606
Local test acc @ epoch 309: 0.8243
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.7029897492193413e-08
Local loss @ local epoch 3: 6.811957575791894e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.02 seconds!
[tester] 
AGNewsMetric: acc=0.8084210526315789, hinge=4.887306177490636, ce=11.547038977773566
Local test acc @ epoch 309: 0.8084
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.92 seconds!
[tester] 
AGNewsMetric: acc=0.8288157894736842, hinge=3.7767625966824983, ce=11.156530597084448
Local test acc @ epoch 309: 0.8288
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 1.0837207575775665e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.39 seconds!
[tester] 
AGNewsMetric: acc=0.8468421052631578, hinge=3.685559688492825, ce=10.195055782920436
Local test acc @ epoch 309: 0.8468
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 8.129589332384057e-06
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.0331468303093061e-07
Local loss @ local epoch 4: 7.947281943643247e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.16 seconds!
[tester] 
AGNewsMetric: acc=0.5738157894736842, hinge=11.169342485729016, ce=16.031584388331364
Local test acc @ epoch 309: 0.5738
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 9.934106870446158e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.69 seconds!
[tester] 
AGNewsMetric: acc=0.8459210526315789, hinge=3.6110270891691507, ce=10.36493326086747
Local test acc @ epoch 309: 0.8459
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 1.0837207575775665e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.167441337519449e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.5 seconds!
[tester] 
AGNewsMetric: acc=0.8373684210526315, hinge=3.738485291129664, ce=10.500313550045616
Local test acc @ epoch 309: 0.8374
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.9868211964535476e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.75 seconds!
[tester] 
AGNewsMetric: acc=0.8409210526315789, hinge=3.797990537693626, ce=10.417295140718158
Local test acc @ epoch 309: 0.8409
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.66 seconds!
[tester] 
AGNewsMetric: acc=0.8501315789473685, hinge=3.5688187665688362, ce=10.500121279264752
Local test acc @ epoch 309: 0.8501
Global evaluate on test data...
Evaluate data in 124.14 seconds!
[tester] 
AGNewsMetric: acc=0.8492105263157895, hinge=3.585353067925102, ce=10.348545831379138
Global test acc @ epoch 309: 0.8492
Global epoch 310...
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 9.934103673003847e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.61 seconds!
[tester] 
AGNewsMetric: acc=0.8401315789473685, hinge=3.863873026496486, ce=10.476028466475638
Local test acc @ epoch 310: 0.8401
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 4.33488231976753e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.01 seconds!
[tester] 
AGNewsMetric: acc=0.7118421052631579, hinge=7.293543676577117, ce=13.892523239537288
Local test acc @ epoch 310: 0.7118
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.52 seconds!
[tester] 
AGNewsMetric: acc=0.8481578947368421, hinge=3.7284198397084287, ce=10.345457187451814
Local test acc @ epoch 310: 0.8482
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 4.4703469370688254e-08
Local loss @ local epoch 2: 7.450580152834618e-09
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.87 seconds!
[tester] 
AGNewsMetric: acc=0.8432894736842105, hinge=3.789511246053796, ce=10.439218211926912
Local test acc @ epoch 310: 0.8433
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 5.108969247658024e-08
Local loss @ local epoch 4: 2.502556324005127
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.51 seconds!
[tester] 
AGNewsMetric: acc=0.6330263157894737, hinge=8.564292061454372, ce=14.773680612664474
Local test acc @ epoch 310: 0.633
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 9.934106870446158e-09
Local loss @ local epoch 1: 9.934106870446158e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.18 seconds!
[tester] 
AGNewsMetric: acc=0.8375, hinge=3.9063675413633647, ce=10.662341603730853
Local test acc @ epoch 310: 0.8375
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 1.5894556781859137e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.0490334716450889e-06
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.81 seconds!
[tester] 
AGNewsMetric: acc=0.7828947368421053, hinge=5.518705992949636, ce=12.42618566814222
Local test acc @ epoch 310: 0.7829
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.81 seconds!
[tester] 
AGNewsMetric: acc=0.8485526315789473, hinge=3.6531634480074833, ce=10.49778778477719
Local test acc @ epoch 310: 0.8486
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 1.7801523426896892e-05
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 9.139366170529684e-07
Local loss @ local epoch 3: 1.112618406295951e-06
Local loss @ local epoch 4: 5.563096010519075e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.57 seconds!
[tester] 
AGNewsMetric: acc=0.5272368421052631, hinge=12.198090270193, ce=16.325064689234683
Local test acc @ epoch 310: 0.5272
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.91 seconds!
[tester] 
AGNewsMetric: acc=0.8489473684210527, hinge=3.5894707354746367, ce=10.420437652186344
Local test acc @ epoch 310: 0.8489
Global evaluate on test data...
Evaluate data in 123.93 seconds!
[tester] 
AGNewsMetric: acc=0.8342105263157895, hinge=4.02405771104913, ce=10.598990837900262
Global test acc @ epoch 310: 0.8342
Global epoch 311...
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 8.940691742509443e-08
Local loss @ local epoch 3: 9.934106870446158e-09
Local loss @ local epoch 4: 9.934106870446158e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.57 seconds!
[tester] 
AGNewsMetric: acc=0.8315789473684211, hinge=3.8543809290936117, ce=10.977023313421952
Local test acc @ epoch 311: 0.8316
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 1.2711507081985474
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.9311639789520996e-06
Local loss @ local epoch 3: 9.536741885085576e-08
Local loss @ local epoch 4: 7.947277254061191e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.86 seconds!
[tester] 
AGNewsMetric: acc=0.6307894736842106, hinge=8.322502154300087, ce=15.773987846374512
Local test acc @ epoch 311: 0.6308
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0032436654437333345
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.0837207575775665e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.9 seconds!
[tester] 
AGNewsMetric: acc=0.4371052631578947, hinge=14.826805213125128, ce=20.270754478856137
Local test acc @ epoch 311: 0.4371
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.9802320611338473e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.78 seconds!
[tester] 
AGNewsMetric: acc=0.8503947368421053, hinge=3.6073083518680775, ce=10.49996943222849
Local test acc @ epoch 311: 0.8504
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 4.967052191773291e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.9868191714067507e-07
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.77 seconds!
[tester] 
AGNewsMetric: acc=0.8288157894736842, hinge=4.052236029725326, ce=10.571451695090847
Local test acc @ epoch 311: 0.8288
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.46197310090065
Local loss @ local epoch 1: 7.450580152834618e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 5.215405707303944e-08
Local loss @ local epoch 4: 7.52507673951186e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.61 seconds!
[tester] 
AGNewsMetric: acc=0.6114473684210526, hinge=8.54037776495281, ce=15.15343353873805
Local test acc @ epoch 311: 0.6114
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 2.384185648907078e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.95 seconds!
[tester] 
AGNewsMetric: acc=0.8381578947368421, hinge=3.8360315325385645, ce=10.620529969867906
Local test acc @ epoch 311: 0.8382
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.6255798129805044e-07
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.0837207575775665e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.78 seconds!
[tester] 
AGNewsMetric: acc=0.8330263157894737, hinge=4.061462066361779, ce=10.857103540520919
Local test acc @ epoch 311: 0.833
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 3.973642748178463e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 7.94728478581419e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.38 seconds!
[tester] 
AGNewsMetric: acc=0.8210526315789474, hinge=4.250636773485886, ce=10.929742018047133
Local test acc @ epoch 311: 0.8211
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 5.108968892386656e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 125.37 seconds!
[tester] 
AGNewsMetric: acc=0.8078947368421052, hinge=4.665900214094865, ce=11.021618620219984
Local test acc @ epoch 311: 0.8079
Global evaluate on test data...
Evaluate data in 124.63 seconds!
[tester] 
AGNewsMetric: acc=0.8342105263157895, hinge=3.999325452854759, ce=10.971468893352307
Global test acc @ epoch 311: 0.8342
Global epoch 312...
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.25 seconds!
[tester] 
AGNewsMetric: acc=0.8432894736842105, hinge=4.0210590088994875, ce=10.350411967227334
Local test acc @ epoch 312: 0.8433
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 9.934106870446158e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.02 seconds!
[tester] 
AGNewsMetric: acc=0.8305263157894737, hinge=4.0341519104807, ce=11.084160324899774
Local test acc @ epoch 312: 0.8305
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0002324168017366901
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.68 seconds!
[tester] 
AGNewsMetric: acc=0.7196052631578947, hinge=6.592842593444021, ce=12.524242421200402
Local test acc @ epoch 312: 0.7196
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 2.2351740014414645e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.35 seconds!
[tester] 
AGNewsMetric: acc=0.8265789473684211, hinge=4.168168731112229, ce=11.069981558950325
Local test acc @ epoch 312: 0.8266
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 1.0837207575775665e-08
Local loss @ local epoch 1: 1.0837207575775665e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 3.2511618286434896e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.41 seconds!
[tester] 
AGNewsMetric: acc=0.8330263157894737, hinge=4.008475737822684, ce=10.77772435640034
Local test acc @ epoch 312: 0.833
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.0837207575775665e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.167441337519449e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.85 seconds!
[tester] 
AGNewsMetric: acc=0.8371052631578947, hinge=3.7542129948264673, ce=10.872320849769993
Local test acc @ epoch 312: 0.8371
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 4.768370232000052e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.1126193300015075e-07
Local loss @ local epoch 4: 7.947285496356926e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.7 seconds!
[tester] 
AGNewsMetric: acc=0.8268421052631579, hinge=3.9309396182863336, ce=10.979700267189427
Local test acc @ epoch 312: 0.8268
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 3.2356780366171733e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.66 seconds!
[tester] 
AGNewsMetric: acc=0.6636842105263158, hinge=9.660326334300795, ce=14.233723216809725
Local test acc @ epoch 312: 0.6637
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 9.934106870446158e-09
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.86 seconds!
[tester] 
AGNewsMetric: acc=0.834078947368421, hinge=3.8787679044823897, ce=11.005631780122457
Local test acc @ epoch 312: 0.8341
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.16 seconds!
[tester] 
AGNewsMetric: acc=0.8393421052631579, hinge=4.003809393581591, ce=11.18253270801745
Local test acc @ epoch 312: 0.8393
Global evaluate on test data...
Evaluate data in 123.32 seconds!
[tester] 
AGNewsMetric: acc=0.8467105263157895, hinge=3.6867098943810714, ce=10.52942714691162
Global test acc @ epoch 312: 0.8467
Global epoch 313...
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 3.725289943190546e-08
Local loss @ local epoch 3: 2.45868676529426e-07
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.54 seconds!
[tester] 
AGNewsMetric: acc=0.8335526315789473, hinge=4.102186239518617, ce=10.638903603804739
Local test acc @ epoch 313: 0.8336
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.1920926823449918e-07
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.03 seconds!
[tester] 
AGNewsMetric: acc=0.7582894736842105, hinge=5.968854825873124, ce=13.137484586615312
Local test acc @ epoch 313: 0.7583
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.96 seconds!
[tester] 
AGNewsMetric: acc=0.8469736842105263, hinge=3.7621162523093976, ce=10.749137968766062
Local test acc @ epoch 313: 0.847
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.7029897492193413e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.56 seconds!
[tester] 
AGNewsMetric: acc=0.8417105263157895, hinge=3.522366800182744, ce=11.105758713170102
Local test acc @ epoch 313: 0.8417
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 1.9073459611718135e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 1.5894570992713852e-08
Local loss @ local epoch 4: 3.973642748178463e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.37 seconds!
[tester] 
AGNewsMetric: acc=0.5623684210526316, hinge=11.591167515202573, ce=17.717104998136822
Local test acc @ epoch 313: 0.5624
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 1.0837207575775665e-08
Local loss @ local epoch 1: 1.0837207575775665e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.31 seconds!
[tester] 
AGNewsMetric: acc=0.8476315789473684, hinge=3.6450394045679193, ce=10.40823286759226
Local test acc @ epoch 313: 0.8476
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 9.536729521641973e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 3.973642748178463e-08
Local loss @ local epoch 3: 3.973642748178463e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.23 seconds!
[tester] 
AGNewsMetric: acc=0.7543421052631579, hinge=5.9250514432003625, ce=12.285938353287547
Local test acc @ epoch 313: 0.7543
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 8.669762507906853e-08
Local loss @ local epoch 1: 3.2511618286434896e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 6.502323657286979e-08
Local loss @ local epoch 4: 9.753484420116365e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.96 seconds!
[tester] 
AGNewsMetric: acc=0.7160526315789474, hinge=7.235172675283332, ce=13.835437897130063
Local test acc @ epoch 313: 0.7161
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 9.934106870446158e-09
Local loss @ local epoch 1: 1.9868211964535476e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.98 seconds!
[tester] 
AGNewsMetric: acc=0.8476315789473684, hinge=3.6641705324775296, ce=10.263042901691637
Local test acc @ epoch 313: 0.8476
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 1.9868211964535476e-08
Local loss @ local epoch 1: 2.9802317058624794e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 125.21 seconds!
[tester] 
AGNewsMetric: acc=0.734078947368421, hinge=6.752505557411595, ce=12.924672110708137
Local test acc @ epoch 313: 0.7341
Global evaluate on test data...
Evaluate data in 124.09 seconds!
[tester] 
AGNewsMetric: acc=0.8463157894736842, hinge=3.7474873881590995, ce=10.511953080829821
Global test acc @ epoch 313: 0.8463
Global epoch 314...
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.0837207575775665e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.1920920428565296e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.02 seconds!
[tester] 
AGNewsMetric: acc=0.8359210526315789, hinge=3.950732065752933, ce=10.685611813193873
Local test acc @ epoch 314: 0.8359
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 7.947285496356926e-08
Local loss @ local epoch 1: 3.973642748178463e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.01 seconds!
[tester] 
AGNewsMetric: acc=0.5909210526315789, hinge=10.485083206578304, ce=15.341768333033512
Local test acc @ epoch 314: 0.5909
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 2.2351740014414645e-08
Local loss @ local epoch 1: 3.725289587919178e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 2.2351740014414645e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.41 seconds!
[tester] 
AGNewsMetric: acc=0.8377631578947369, hinge=3.823250222331599, ce=10.489106479444002
Local test acc @ epoch 314: 0.8378
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 1.9868213740892315e-08
Local loss @ local epoch 1: 9.934106870446158e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.37 seconds!
[tester] 
AGNewsMetric: acc=0.7494736842105263, hinge=6.308199112540797, ce=12.63016138177169
Local test acc @ epoch 314: 0.7495
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.7 seconds!
[tester] 
AGNewsMetric: acc=0.8305263157894737, hinge=4.153104657875864, ce=10.91496490277742
Local test acc @ epoch 314: 0.8305
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.05 seconds!
[tester] 
AGNewsMetric: acc=0.8469736842105263, hinge=3.7157823440903113, ce=10.799249620939555
Local test acc @ epoch 314: 0.847
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 3.2511618286434896e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.0837207575775665e-08
Local loss @ local epoch 3: 1.0837207575775665e-08
Local loss @ local epoch 4: 2.167441337519449e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.99 seconds!
[tester] 
AGNewsMetric: acc=0.8432894736842105, hinge=3.605495243197993, ce=10.494931901630602
Local test acc @ epoch 314: 0.8433
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.13 seconds!
[tester] 
AGNewsMetric: acc=0.8398684210526316, hinge=3.840297525807431, ce=10.761761237696598
Local test acc @ epoch 314: 0.8399
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 3.0994365829428716e-07
Local loss @ local epoch 1: 1.5894569216357013e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.384185471271394e-08
Local loss @ local epoch 4: 4.927299528389995e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 122.39 seconds!
[tester] 
AGNewsMetric: acc=0.6807894736842105, hinge=8.439763570584748, ce=14.768182868957519
Local test acc @ epoch 314: 0.6808
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 9.934106870446158e-09
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.72 seconds!
[tester] 
AGNewsMetric: acc=0.8460526315789474, hinge=3.651017140463779, ce=10.60069400988127
Local test acc @ epoch 314: 0.8461
Global evaluate on test data...
Evaluate data in 123.96 seconds!
[tester] 
AGNewsMetric: acc=0.8469736842105263, hinge=3.658967196690409, ce=10.403445257889597
Global test acc @ epoch 314: 0.847
Global epoch 315...
Client 9 execute local training on 16 samples...
Local loss @ local epoch 0: 7.450580152834618e-09
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 3.7252892326478104e-08
Local loss @ local epoch 4: 1.4901159417490817e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.08 seconds!
[tester] 
AGNewsMetric: acc=0.8163157894736842, hinge=4.58019805393721, ce=11.472730088484914
Local test acc @ epoch 315: 0.8163
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 1.1920920428565296e-07
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.0837207575775665e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 9.31995373321115e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.45 seconds!
[tester] 
AGNewsMetric: acc=0.8289473684210527, hinge=4.399927511466177, ce=10.532011861299214
Local test acc @ epoch 315: 0.8289
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.9802320611338473e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.78 seconds!
[tester] 
AGNewsMetric: acc=0.8460526315789474, hinge=3.7357404684393027, ce=10.62156619021767
Local test acc @ epoch 315: 0.8461
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.7029897492193413e-08
Local loss @ local epoch 3: 1.7029897492193413e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.32 seconds!
[tester] 
AGNewsMetric: acc=0.8180263157894737, hinge=4.35239036572607, ce=10.9701445449026
Local test acc @ epoch 315: 0.818
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 3.973642748178463e-08
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.1 seconds!
[tester] 
AGNewsMetric: acc=0.8380263157894737, hinge=3.736869123483959, ce=10.617311419436806
Local test acc @ epoch 315: 0.838
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 7.947285496356926e-09
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 7.152554815093026e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.81 seconds!
[tester] 
AGNewsMetric: acc=0.8431578947368421, hinge=3.818384803094362, ce=10.621351181833367
Local test acc @ epoch 315: 0.8432
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 1.9868213740892315e-08
Local loss @ local epoch 2: 4.967052191773291e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.37 seconds!
[tester] 
AGNewsMetric: acc=0.8388157894736842, hinge=4.05008438235835, ce=10.541173800418251
Local test acc @ epoch 315: 0.8388
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 2.167441337519449e-08
Local loss @ local epoch 4: 1.0837207575775665e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.44 seconds!
[tester] 
AGNewsMetric: acc=0.8223684210526315, hinge=4.391801862967641, ce=11.202737264131246
Local test acc @ epoch 315: 0.8224
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.46 seconds!
[tester] 
AGNewsMetric: acc=0.8481578947368421, hinge=3.6140400064618965, ce=10.683964080810547
Local test acc @ epoch 315: 0.8482
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 9.934106870446158e-09
Local loss @ local epoch 2: 1.1920925402364446e-07
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.05 seconds!
[tester] 
AGNewsMetric: acc=0.8407894736842105, hinge=3.720310540450247, ce=10.495877822072883
Local test acc @ epoch 315: 0.8408
Global evaluate on test data...
Evaluate data in 122.42 seconds!
[tester] 
AGNewsMetric: acc=0.8469736842105263, hinge=3.7584328533473768, ce=10.470331453022204
Global test acc @ epoch 315: 0.847
Global epoch 316...
Client 4 execute local training on 21 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 122.18 seconds!
[tester] 
AGNewsMetric: acc=0.8419736842105263, hinge=3.919315842954736, ce=10.848337958486457
Local test acc @ epoch 316: 0.842
Client 5 execute local training on 19 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 3.973642748178463e-08
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 122.66 seconds!
[tester] 
AGNewsMetric: acc=0.4685526315789474, hinge=11.850866012573242, ce=17.60303172864412
Local test acc @ epoch 316: 0.4686
Client 0 execute local training on 15 samples...
Local loss @ local epoch 0: 7.152553394007555e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.08 seconds!
[tester] 
AGNewsMetric: acc=0.786578947368421, hinge=5.392573779507687, ce=11.922377269142553
Local test acc @ epoch 316: 0.7866
Client 6 execute local training on 20 samples...
Local loss @ local epoch 0: 8.940695295223122e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.54 seconds!
[tester] 
AGNewsMetric: acc=0.834078947368421, hinge=4.097912167624424, ce=10.571872373882092
Local test acc @ epoch 316: 0.8341
Client 7 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 4.332766911829822e-05
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.17 seconds!
[tester] 
AGNewsMetric: acc=0.5160526315789473, hinge=12.470437477513363, ce=18.331706486752157
Local test acc @ epoch 316: 0.5161
Client 3 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.9868211964535476e-08
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 124.88 seconds!
[tester] 
AGNewsMetric: acc=0.8446052631578947, hinge=3.7289534360484073, ce=10.555134283366955
Local test acc @ epoch 316: 0.8446
Client 8 execute local training on 23 samples...
Local loss @ local epoch 0: 5.108969247658024e-08
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 1.7029897492193413e-08
Local loss @ local epoch 3: 1.7029897492193413e-08
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 122.87 seconds!
[tester] 
AGNewsMetric: acc=0.8339473684210527, hinge=3.967847374865883, ce=10.381595354582133
Local test acc @ epoch 316: 0.8339
Client 2 execute local training on 11 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 1.3004641630232072e-07
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Evaluate data in 123.9 seconds!
[tester] 
AGNewsMetric: acc=0.8285526315789473, hinge=4.2049830326281095, ce=10.95252029619719
Local test acc @ epoch 316: 0.8286
Client 1 execute local training on 12 samples...
Local loss @ local epoch 0: 0.0
Local loss @ local epoch 1: 0.0
Local loss @ local epoch 2: 0.0
Local loss @ local epoch 3: 0.0
Local loss @ local epoch 4: 0.0
/root/anaconda3/envs/bbt/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
